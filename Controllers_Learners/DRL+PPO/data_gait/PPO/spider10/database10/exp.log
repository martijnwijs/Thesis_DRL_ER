[2022-11-25 00:05:51,992] [INFO] [optimize] Starting learning
[2022-11-25 00:05:52,001] [INFO] [optimize] Starting learning process..
[2022-11-25 00:05:52,100] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:05:52,100] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:05:59,001] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:06:04,987] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:06:11,071] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:06:16,909] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:06:22,779] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:06:28,714] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:06:34,622] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:06:40,875] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:06:47,060] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:06:53,030] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.544109242765825
[2022-11-25 00:06:53,031] [INFO] [runner_train_mujoco] Average state value: -0.12360454747453334
[2022-11-25 00:06:53,031] [INFO] [controller] ITERATION NUM: 1
[2022-11-25 00:06:53,094] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.50764
[2022-11-25 00:06:53,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.04866, loss val: 0.45640
[2022-11-25 00:06:53,187] [INFO] [controller] EPOCH 3 loss ppo:  -0.05946, loss val: 0.40263
[2022-11-25 00:06:53,235] [INFO] [controller] EPOCH 4 loss ppo:  -0.06628, loss val: 0.36156
[2022-11-25 00:06:53,246] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:06:53,319] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:06:53,319] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:07:00,072] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:07:06,405] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:07:12,835] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:07:18,926] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:07:25,104] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:07:31,266] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:07:39,130] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:07:46,555] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:07:53,574] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:08:00,003] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4925502288475233
[2022-11-25 00:08:00,003] [INFO] [runner_train_mujoco] Average state value: 0.0354421227692316
[2022-11-25 00:08:00,003] [INFO] [controller] ITERATION NUM: 2
[2022-11-25 00:08:00,073] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.29873
[2022-11-25 00:08:00,118] [INFO] [controller] EPOCH 2 loss ppo:  -0.04081, loss val: 0.27241
[2022-11-25 00:08:00,170] [INFO] [controller] EPOCH 3 loss ppo:  -0.05610, loss val: 0.22380
[2022-11-25 00:08:00,224] [INFO] [controller] EPOCH 4 loss ppo:  -0.06536, loss val: 0.19493
[2022-11-25 00:08:00,235] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:08:00,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:08:00,304] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:08:06,931] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:08:13,373] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:08:19,927] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:08:26,402] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:08:33,129] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:08:39,755] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:08:46,488] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:08:53,159] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:08:59,916] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:09:06,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.45922977538172205
[2022-11-25 00:09:06,385] [INFO] [runner_train_mujoco] Average state value: 0.21051217682659623
[2022-11-25 00:09:06,385] [INFO] [controller] ITERATION NUM: 3
[2022-11-25 00:09:06,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01556, loss val: 0.22345
[2022-11-25 00:09:06,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.03916, loss val: 0.19141
[2022-11-25 00:09:06,549] [INFO] [controller] EPOCH 3 loss ppo:  -0.05329, loss val: 0.16735
[2022-11-25 00:09:06,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.06364, loss val: 0.15257
[2022-11-25 00:09:06,612] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:09:06,681] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:09:06,682] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:09:13,707] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:09:20,364] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:09:27,025] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:09:33,827] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:09:40,707] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:09:48,073] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:09:55,369] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:10:02,284] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:10:08,793] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:10:15,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3926487688317483
[2022-11-25 00:10:15,464] [INFO] [runner_train_mujoco] Average state value: 0.3543863539478432
[2022-11-25 00:10:15,464] [INFO] [controller] ITERATION NUM: 4
[2022-11-25 00:10:15,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.12190
[2022-11-25 00:10:15,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.04172, loss val: 0.11096
[2022-11-25 00:10:15,659] [INFO] [controller] EPOCH 3 loss ppo:  -0.05199, loss val: 0.09636
[2022-11-25 00:10:15,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.05883, loss val: 0.08775
[2022-11-25 00:10:15,727] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:10:15,817] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:10:15,818] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:10:22,775] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:10:29,959] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:10:36,544] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:10:43,048] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:10:49,541] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:10:56,064] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:11:02,431] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:11:08,635] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:11:15,159] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:11:21,714] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46521866264851147
[2022-11-25 00:11:21,714] [INFO] [runner_train_mujoco] Average state value: 0.5025364028712114
[2022-11-25 00:11:21,714] [INFO] [controller] ITERATION NUM: 5
[2022-11-25 00:11:21,768] [INFO] [controller] EPOCH 1 loss ppo:  -0.01194, loss val: 0.09082
[2022-11-25 00:11:21,808] [INFO] [controller] EPOCH 2 loss ppo:  -0.03163, loss val: 0.08187
[2022-11-25 00:11:21,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.04479, loss val: 0.07476
[2022-11-25 00:11:21,886] [INFO] [controller] EPOCH 4 loss ppo:  -0.05475, loss val: 0.07196
[2022-11-25 00:11:21,893] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:11:21,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:11:21,950] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:11:28,282] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:11:34,591] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:11:40,961] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:11:47,192] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:11:53,492] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:11:59,423] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:12:05,316] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:12:11,413] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:12:17,352] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:12:23,355] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.30747216589063175
[2022-11-25 00:12:23,355] [INFO] [runner_train_mujoco] Average state value: 0.5766884074658156
[2022-11-25 00:12:23,356] [INFO] [controller] ITERATION NUM: 6
[2022-11-25 00:12:23,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01081, loss val: 0.06727
[2022-11-25 00:12:23,457] [INFO] [controller] EPOCH 2 loss ppo:  -0.03753, loss val: 0.06553
[2022-11-25 00:12:23,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.04644, loss val: 0.06406
[2022-11-25 00:12:23,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.05264, loss val: 0.06085
[2022-11-25 00:12:23,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:12:23,637] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:12:23,637] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:12:29,724] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:12:36,018] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:12:42,351] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:12:48,657] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:12:54,549] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:13:00,292] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:13:05,998] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:13:11,783] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:13:17,513] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:13:23,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40606481961698015
[2022-11-25 00:13:23,404] [INFO] [runner_train_mujoco] Average state value: 0.6001688072780768
[2022-11-25 00:13:23,404] [INFO] [controller] ITERATION NUM: 7
[2022-11-25 00:13:23,456] [INFO] [controller] EPOCH 1 loss ppo:  -0.00833, loss val: 0.05568
[2022-11-25 00:13:23,499] [INFO] [controller] EPOCH 2 loss ppo:  -0.02884, loss val: 0.05347
[2022-11-25 00:13:23,548] [INFO] [controller] EPOCH 3 loss ppo:  -0.03868, loss val: 0.04824
[2022-11-25 00:13:23,600] [INFO] [controller] EPOCH 4 loss ppo:  -0.04804, loss val: 0.04305
[2022-11-25 00:13:23,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:13:23,688] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:13:23,688] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:13:29,899] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:13:35,721] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:13:41,575] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:13:47,521] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:13:53,233] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:13:59,204] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:14:04,754] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:14:10,681] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:14:16,441] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:14:22,395] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5501596318010306
[2022-11-25 00:14:22,396] [INFO] [runner_train_mujoco] Average state value: 0.5413262612322967
[2022-11-25 00:14:22,396] [INFO] [controller] ITERATION NUM: 8
[2022-11-25 00:14:22,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04926
[2022-11-25 00:14:22,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.03533, loss val: 0.05055
[2022-11-25 00:14:22,527] [INFO] [controller] EPOCH 3 loss ppo:  -0.04311, loss val: 0.04914
[2022-11-25 00:14:22,560] [INFO] [controller] EPOCH 4 loss ppo:  -0.05240, loss val: 0.04785
[2022-11-25 00:14:22,567] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:14:22,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:14:22,642] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:14:28,313] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:14:33,991] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:14:39,529] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:14:44,994] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:14:50,572] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:14:56,332] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:15:02,229] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:15:08,213] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:15:14,032] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:15:19,631] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4675743187796516
[2022-11-25 00:15:19,631] [INFO] [runner_train_mujoco] Average state value: 0.5219945993026098
[2022-11-25 00:15:19,631] [INFO] [controller] ITERATION NUM: 9
[2022-11-25 00:15:19,681] [INFO] [controller] EPOCH 1 loss ppo:  -0.01088, loss val: 0.04381
[2022-11-25 00:15:19,725] [INFO] [controller] EPOCH 2 loss ppo:  -0.03131, loss val: 0.04184
[2022-11-25 00:15:19,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.04282, loss val: 0.04114
[2022-11-25 00:15:19,806] [INFO] [controller] EPOCH 4 loss ppo:  -0.05269, loss val: 0.03925
[2022-11-25 00:15:19,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:15:19,878] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:15:19,878] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:15:25,636] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:15:31,058] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:15:36,655] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:15:42,064] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:15:47,522] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:15:53,022] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:15:58,619] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:16:04,360] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:16:10,153] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:16:15,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5966342625826323
[2022-11-25 00:16:15,887] [INFO] [runner_train_mujoco] Average state value: 0.5651536908944448
[2022-11-25 00:16:15,887] [INFO] [controller] ITERATION NUM: 10
[2022-11-25 00:16:15,939] [INFO] [controller] EPOCH 1 loss ppo:  -0.01064, loss val: 0.04502
[2022-11-25 00:16:15,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.03611, loss val: 0.04243
[2022-11-25 00:16:16,028] [INFO] [controller] EPOCH 3 loss ppo:  -0.04570, loss val: 0.04114
[2022-11-25 00:16:16,076] [INFO] [controller] EPOCH 4 loss ppo:  -0.05308, loss val: 0.04128
[2022-11-25 00:16:16,087] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:16:16,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:16:16,159] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:16:22,218] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:16:27,905] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:16:33,650] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:16:39,307] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:16:45,000] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:16:50,499] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:16:56,374] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:17:02,086] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:17:08,046] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:17:13,502] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7227098838244228
[2022-11-25 00:17:13,503] [INFO] [runner_train_mujoco] Average state value: 0.5991409281690915
[2022-11-25 00:17:13,503] [INFO] [controller] ITERATION NUM: 11
[2022-11-25 00:17:13,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.00979, loss val: 0.03759
[2022-11-25 00:17:13,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.03178, loss val: 0.03557
[2022-11-25 00:17:13,643] [INFO] [controller] EPOCH 3 loss ppo:  -0.04317, loss val: 0.03492
[2022-11-25 00:17:13,685] [INFO] [controller] EPOCH 4 loss ppo:  -0.05283, loss val: 0.03387
[2022-11-25 00:17:13,695] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:17:13,757] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:17:13,757] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:17:19,603] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:17:25,541] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:17:31,524] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:17:39,034] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:17:46,300] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:17:52,355] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:17:58,278] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:18:04,242] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:18:10,220] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:18:16,402] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.651271185964986
[2022-11-25 00:18:16,403] [INFO] [runner_train_mujoco] Average state value: 0.5725149080952009
[2022-11-25 00:18:16,403] [INFO] [controller] ITERATION NUM: 12
[2022-11-25 00:18:16,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.00982, loss val: 0.02755
[2022-11-25 00:18:16,503] [INFO] [controller] EPOCH 2 loss ppo:  -0.03339, loss val: 0.02895
[2022-11-25 00:18:16,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.04355, loss val: 0.02715
[2022-11-25 00:18:16,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.05158, loss val: 0.02821
[2022-11-25 00:18:16,667] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:18:16,737] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:18:16,737] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:18:22,614] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:18:28,575] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:18:34,619] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:18:41,000] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:18:46,983] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:18:53,460] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:18:59,670] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:19:05,887] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:19:11,869] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:19:18,097] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.008030965370018
[2022-11-25 00:19:18,098] [INFO] [runner_train_mujoco] Average state value: 0.5442627780437468
[2022-11-25 00:19:18,098] [INFO] [controller] ITERATION NUM: 13
[2022-11-25 00:19:18,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.03465
[2022-11-25 00:19:18,195] [INFO] [controller] EPOCH 2 loss ppo:  -0.03844, loss val: 0.03572
[2022-11-25 00:19:18,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.04501, loss val: 0.03418
[2022-11-25 00:19:18,287] [INFO] [controller] EPOCH 4 loss ppo:  -0.05123, loss val: 0.03173
[2022-11-25 00:19:18,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:19:18,352] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:19:18,352] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:19:24,789] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:19:31,150] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:19:37,607] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:19:43,884] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:19:50,353] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:19:56,572] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:20:03,291] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:20:10,228] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:20:17,148] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:20:23,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0276718579721895
[2022-11-25 00:20:23,483] [INFO] [runner_train_mujoco] Average state value: 0.5073023415605228
[2022-11-25 00:20:23,483] [INFO] [controller] ITERATION NUM: 14
[2022-11-25 00:20:23,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.04093
[2022-11-25 00:20:23,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.03560, loss val: 0.04176
[2022-11-25 00:20:23,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.04694, loss val: 0.04079
[2022-11-25 00:20:23,654] [INFO] [controller] EPOCH 4 loss ppo:  -0.05560, loss val: 0.03917
[2022-11-25 00:20:23,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:20:23,745] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:20:23,746] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:20:30,220] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:20:36,883] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:20:43,135] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:20:49,740] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:20:55,966] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:21:02,127] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:21:08,225] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:21:14,322] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:21:20,856] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:21:26,944] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.156667975490702
[2022-11-25 00:21:26,944] [INFO] [runner_train_mujoco] Average state value: 0.5209324137171109
[2022-11-25 00:21:26,944] [INFO] [controller] ITERATION NUM: 15
[2022-11-25 00:21:27,016] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.03464
[2022-11-25 00:21:27,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.03645, loss val: 0.03664
[2022-11-25 00:21:27,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.04432, loss val: 0.03555
[2022-11-25 00:21:27,168] [INFO] [controller] EPOCH 4 loss ppo:  -0.05090, loss val: 0.03588
[2022-11-25 00:21:27,179] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:21:27,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:21:27,244] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:21:33,598] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:21:40,015] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:21:46,186] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:21:52,322] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:21:58,076] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:22:03,835] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:22:09,560] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:22:15,427] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:22:21,613] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:22:27,321] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5440677901282809
[2022-11-25 00:22:27,321] [INFO] [runner_train_mujoco] Average state value: 0.5417950115700563
[2022-11-25 00:22:27,321] [INFO] [controller] ITERATION NUM: 16
[2022-11-25 00:22:27,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.04000
[2022-11-25 00:22:27,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.03904, loss val: 0.03873
[2022-11-25 00:22:27,455] [INFO] [controller] EPOCH 3 loss ppo:  -0.05125, loss val: 0.03848
[2022-11-25 00:22:27,493] [INFO] [controller] EPOCH 4 loss ppo:  -0.05836, loss val: 0.03889
[2022-11-25 00:22:27,499] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:22:27,564] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:22:27,565] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:22:33,924] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:22:40,177] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:22:46,068] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:22:51,776] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:22:57,234] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:23:02,991] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:23:08,606] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:23:14,472] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:23:20,109] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:23:25,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5500994899836071
[2022-11-25 00:23:25,769] [INFO] [runner_train_mujoco] Average state value: 0.5349996573626996
[2022-11-25 00:23:25,769] [INFO] [controller] ITERATION NUM: 17
[2022-11-25 00:23:25,822] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.03231
[2022-11-25 00:23:25,867] [INFO] [controller] EPOCH 2 loss ppo:  -0.03974, loss val: 0.03220
[2022-11-25 00:23:25,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.05086, loss val: 0.03320
[2022-11-25 00:23:25,955] [INFO] [controller] EPOCH 4 loss ppo:  -0.06223, loss val: 0.03539
[2022-11-25 00:23:25,965] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:23:26,039] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:23:26,040] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:23:31,697] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:23:37,501] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:23:43,327] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:23:48,962] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:23:54,714] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:24:00,257] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:24:05,872] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:24:11,479] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:24:17,437] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:24:22,947] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.853314960222725
[2022-11-25 00:24:22,947] [INFO] [runner_train_mujoco] Average state value: 0.542226798971494
[2022-11-25 00:24:22,947] [INFO] [controller] ITERATION NUM: 18
[2022-11-25 00:24:23,006] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03647
[2022-11-25 00:24:23,052] [INFO] [controller] EPOCH 2 loss ppo:  -0.03773, loss val: 0.03704
[2022-11-25 00:24:23,092] [INFO] [controller] EPOCH 3 loss ppo:  -0.05259, loss val: 0.03720
[2022-11-25 00:24:23,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.06254, loss val: 0.03766
[2022-11-25 00:24:23,150] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:24:23,204] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:24:23,205] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:24:29,205] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:24:34,675] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:24:40,365] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:24:45,680] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:24:51,114] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:24:56,660] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:25:02,338] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:25:07,554] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:25:12,875] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:25:18,122] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1046374317754344
[2022-11-25 00:25:18,122] [INFO] [runner_train_mujoco] Average state value: 0.5277299309968948
[2022-11-25 00:25:18,123] [INFO] [controller] ITERATION NUM: 19
[2022-11-25 00:25:18,172] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.03996
[2022-11-25 00:25:18,214] [INFO] [controller] EPOCH 2 loss ppo:  -0.03510, loss val: 0.03989
[2022-11-25 00:25:18,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.04958, loss val: 0.04145
[2022-11-25 00:25:18,298] [INFO] [controller] EPOCH 4 loss ppo:  -0.05681, loss val: 0.03994
[2022-11-25 00:25:18,307] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:25:18,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:25:18,361] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:25:24,171] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:25:29,710] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:25:35,301] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:25:40,961] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:25:46,382] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:25:51,934] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:25:57,298] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:26:02,716] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:26:08,320] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:26:13,788] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4531189292585953
[2022-11-25 00:26:13,788] [INFO] [runner_train_mujoco] Average state value: 0.5399983857274055
[2022-11-25 00:26:13,788] [INFO] [controller] ITERATION NUM: 20
[2022-11-25 00:26:13,837] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.04622
[2022-11-25 00:26:13,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.03750, loss val: 0.04703
[2022-11-25 00:26:13,907] [INFO] [controller] EPOCH 3 loss ppo:  -0.04832, loss val: 0.04566
[2022-11-25 00:26:13,949] [INFO] [controller] EPOCH 4 loss ppo:  -0.05672, loss val: 0.04393
[2022-11-25 00:26:13,959] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:26:14,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:26:14,018] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:26:19,867] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:26:25,875] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:26:31,668] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:26:37,684] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:26:43,564] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:26:49,335] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:26:54,998] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:27:00,592] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:27:06,132] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:27:11,749] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7447312476631756
[2022-11-25 00:27:11,750] [INFO] [runner_train_mujoco] Average state value: 0.5541941894690197
[2022-11-25 00:27:11,750] [INFO] [controller] ITERATION NUM: 21
[2022-11-25 00:27:11,797] [INFO] [controller] EPOCH 1 loss ppo:  -0.01603, loss val: 0.04063
[2022-11-25 00:27:11,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.03766, loss val: 0.04014
[2022-11-25 00:27:11,878] [INFO] [controller] EPOCH 3 loss ppo:  -0.04926, loss val: 0.03954
[2022-11-25 00:27:11,917] [INFO] [controller] EPOCH 4 loss ppo:  -0.06103, loss val: 0.03933
[2022-11-25 00:27:11,927] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:27:11,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:27:11,992] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:27:18,409] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:27:24,796] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:27:31,001] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:27:36,784] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:27:42,422] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:27:48,106] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:27:54,019] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:27:59,885] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:28:05,803] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:28:11,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8128925751618903
[2022-11-25 00:28:11,799] [INFO] [runner_train_mujoco] Average state value: 0.5262043931682905
[2022-11-25 00:28:11,799] [INFO] [controller] ITERATION NUM: 22
[2022-11-25 00:28:11,856] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.03764
[2022-11-25 00:28:11,902] [INFO] [controller] EPOCH 2 loss ppo:  -0.03541, loss val: 0.03796
[2022-11-25 00:28:11,949] [INFO] [controller] EPOCH 3 loss ppo:  -0.04292, loss val: 0.03829
[2022-11-25 00:28:11,991] [INFO] [controller] EPOCH 4 loss ppo:  -0.05394, loss val: 0.03897
[2022-11-25 00:28:11,998] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:28:12,058] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:28:12,058] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:28:17,989] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:28:24,225] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:28:30,197] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:28:36,381] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:28:42,541] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:28:48,801] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:28:54,858] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:29:01,205] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:29:07,537] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:29:13,900] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1110996288767856
[2022-11-25 00:29:13,900] [INFO] [runner_train_mujoco] Average state value: 0.5093486788272857
[2022-11-25 00:29:13,900] [INFO] [controller] ITERATION NUM: 23
[2022-11-25 00:29:13,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.01906, loss val: 0.04018
[2022-11-25 00:29:13,999] [INFO] [controller] EPOCH 2 loss ppo:  -0.03561, loss val: 0.04020
[2022-11-25 00:29:14,049] [INFO] [controller] EPOCH 3 loss ppo:  -0.04986, loss val: 0.04111
[2022-11-25 00:29:14,091] [INFO] [controller] EPOCH 4 loss ppo:  -0.05919, loss val: 0.04130
[2022-11-25 00:29:14,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:29:14,164] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:29:14,165] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:29:20,280] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:29:28,072] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:29:35,317] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:29:42,227] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:29:48,256] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:29:55,152] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:30:02,891] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:30:09,586] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:30:16,154] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:30:22,501] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4161975242567544
[2022-11-25 00:30:22,501] [INFO] [runner_train_mujoco] Average state value: 0.5178551487723986
[2022-11-25 00:30:22,501] [INFO] [controller] ITERATION NUM: 24
[2022-11-25 00:30:22,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01781, loss val: 0.04790
[2022-11-25 00:30:22,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.03052, loss val: 0.04608
[2022-11-25 00:30:22,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.04364, loss val: 0.04737
[2022-11-25 00:30:22,717] [INFO] [controller] EPOCH 4 loss ppo:  -0.05393, loss val: 0.04764
[2022-11-25 00:30:22,729] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:30:22,797] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:30:22,797] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:30:29,304] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:30:36,095] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:30:42,619] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:30:49,161] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:30:56,097] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:31:02,724] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:31:09,086] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:31:15,332] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:31:22,141] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:31:29,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4852824699706106
[2022-11-25 00:31:29,051] [INFO] [runner_train_mujoco] Average state value: 0.4965700711607933
[2022-11-25 00:31:29,051] [INFO] [controller] ITERATION NUM: 25
[2022-11-25 00:31:29,101] [INFO] [controller] EPOCH 1 loss ppo:  -0.01644, loss val: 0.04389
[2022-11-25 00:31:29,140] [INFO] [controller] EPOCH 2 loss ppo:  -0.02897, loss val: 0.04358
[2022-11-25 00:31:29,260] [INFO] [controller] EPOCH 3 loss ppo:  -0.04354, loss val: 0.04364
[2022-11-25 00:31:29,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.05382, loss val: 0.04389
[2022-11-25 00:31:29,326] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:31:29,398] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:31:29,399] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:31:35,726] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:31:42,275] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:31:48,438] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:31:54,703] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:32:00,598] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:32:06,679] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:32:12,880] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:32:19,036] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:32:25,214] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:32:31,087] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7411642070969577
[2022-11-25 00:32:31,088] [INFO] [runner_train_mujoco] Average state value: 0.4829626968304316
[2022-11-25 00:32:31,088] [INFO] [controller] ITERATION NUM: 26
[2022-11-25 00:32:31,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.03709
[2022-11-25 00:32:31,185] [INFO] [controller] EPOCH 2 loss ppo:  -0.03464, loss val: 0.03713
[2022-11-25 00:32:31,231] [INFO] [controller] EPOCH 3 loss ppo:  -0.04317, loss val: 0.03729
[2022-11-25 00:32:31,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.05639, loss val: 0.03677
[2022-11-25 00:32:31,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:32:31,360] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:32:31,360] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:32:37,354] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:32:43,307] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:32:49,647] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:32:55,952] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:33:01,944] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:33:07,548] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:33:13,471] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:33:19,086] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:33:24,969] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:33:30,878] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.774700665285342
[2022-11-25 00:33:30,878] [INFO] [runner_train_mujoco] Average state value: 0.47364700428644824
[2022-11-25 00:33:30,879] [INFO] [controller] ITERATION NUM: 27
[2022-11-25 00:33:30,932] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.03491
[2022-11-25 00:33:30,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.02911, loss val: 0.03448
[2022-11-25 00:33:31,008] [INFO] [controller] EPOCH 3 loss ppo:  -0.04310, loss val: 0.03442
[2022-11-25 00:33:31,053] [INFO] [controller] EPOCH 4 loss ppo:  -0.05670, loss val: 0.03403
[2022-11-25 00:33:31,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:33:31,141] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:33:31,141] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:33:36,989] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:33:42,928] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:33:48,750] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:33:54,235] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:33:59,642] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:34:05,288] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:34:10,713] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:34:16,228] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:34:21,894] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:34:27,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6610967513954074
[2022-11-25 00:34:27,841] [INFO] [runner_train_mujoco] Average state value: 0.44849430479605995
[2022-11-25 00:34:27,841] [INFO] [controller] ITERATION NUM: 28
[2022-11-25 00:34:27,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.01549, loss val: 0.04498
[2022-11-25 00:34:27,932] [INFO] [controller] EPOCH 2 loss ppo:  -0.03322, loss val: 0.04504
[2022-11-25 00:34:27,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.04398, loss val: 0.04480
[2022-11-25 00:34:28,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.05418, loss val: 0.04751
[2022-11-25 00:34:28,027] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:34:28,098] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:34:28,099] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:34:33,650] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:34:38,924] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:34:44,789] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:34:50,249] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:34:55,688] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:35:00,896] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:35:06,099] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:35:11,313] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:35:16,926] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:35:22,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.075171204957634
[2022-11-25 00:35:22,741] [INFO] [runner_train_mujoco] Average state value: 0.46376402447621035
[2022-11-25 00:35:22,742] [INFO] [controller] ITERATION NUM: 29
[2022-11-25 00:35:22,784] [INFO] [controller] EPOCH 1 loss ppo:  -0.01588, loss val: 0.05185
[2022-11-25 00:35:22,831] [INFO] [controller] EPOCH 2 loss ppo:  -0.02865, loss val: 0.05087
[2022-11-25 00:35:22,878] [INFO] [controller] EPOCH 3 loss ppo:  -0.04088, loss val: 0.05160
[2022-11-25 00:35:22,919] [INFO] [controller] EPOCH 4 loss ppo:  -0.05606, loss val: 0.05112
[2022-11-25 00:35:22,929] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:35:23,006] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:35:23,006] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:35:28,664] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:35:33,983] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:35:39,180] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:35:44,337] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:35:49,583] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:35:55,293] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:36:00,678] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:36:06,141] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:36:11,270] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:36:16,454] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.017329665631865
[2022-11-25 00:36:16,455] [INFO] [runner_train_mujoco] Average state value: 0.5146558935046197
[2022-11-25 00:36:16,455] [INFO] [controller] ITERATION NUM: 30
[2022-11-25 00:36:16,505] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04153
[2022-11-25 00:36:16,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.02823, loss val: 0.04173
[2022-11-25 00:36:16,591] [INFO] [controller] EPOCH 3 loss ppo:  -0.03852, loss val: 0.04142
[2022-11-25 00:36:16,636] [INFO] [controller] EPOCH 4 loss ppo:  -0.05006, loss val: 0.04036
[2022-11-25 00:36:16,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:36:16,701] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:36:16,702] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:36:22,067] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:36:27,494] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:36:32,702] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:36:38,116] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:36:43,104] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:36:48,152] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:36:53,344] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:36:58,574] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:37:03,908] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:37:09,321] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.115896157122818
[2022-11-25 00:37:09,321] [INFO] [runner_train_mujoco] Average state value: 0.500642584323883
[2022-11-25 00:37:09,321] [INFO] [controller] ITERATION NUM: 31
[2022-11-25 00:37:09,379] [INFO] [controller] EPOCH 1 loss ppo:  -0.01643, loss val: 0.04700
[2022-11-25 00:37:09,435] [INFO] [controller] EPOCH 2 loss ppo:  -0.03036, loss val: 0.04599
[2022-11-25 00:37:09,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.04330, loss val: 0.04530
[2022-11-25 00:37:09,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.05503, loss val: 0.04526
[2022-11-25 00:37:09,545] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:37:09,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:37:09,615] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:37:14,866] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:37:20,133] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:37:25,549] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:37:30,950] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:37:36,750] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:37:42,217] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:37:47,671] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:37:53,000] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:37:58,337] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:38:03,609] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.539820772824204
[2022-11-25 00:38:03,609] [INFO] [runner_train_mujoco] Average state value: 0.4746158887048562
[2022-11-25 00:38:03,609] [INFO] [controller] ITERATION NUM: 32
[2022-11-25 00:38:03,660] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.04038
[2022-11-25 00:38:03,704] [INFO] [controller] EPOCH 2 loss ppo:  -0.02693, loss val: 0.03982
[2022-11-25 00:38:03,743] [INFO] [controller] EPOCH 3 loss ppo:  -0.04130, loss val: 0.03984
[2022-11-25 00:38:03,788] [INFO] [controller] EPOCH 4 loss ppo:  -0.05142, loss val: 0.03933
[2022-11-25 00:38:03,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:38:03,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:38:03,852] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:38:09,376] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:38:14,753] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:38:20,347] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:38:25,791] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:38:31,418] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:38:37,060] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:38:42,386] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:38:48,053] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:38:53,658] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:38:59,164] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.631968897285912
[2022-11-25 00:38:59,164] [INFO] [runner_train_mujoco] Average state value: 0.4784143179655075
[2022-11-25 00:38:59,164] [INFO] [controller] ITERATION NUM: 33
[2022-11-25 00:38:59,278] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04731
[2022-11-25 00:38:59,322] [INFO] [controller] EPOCH 2 loss ppo:  -0.02634, loss val: 0.04765
[2022-11-25 00:38:59,371] [INFO] [controller] EPOCH 3 loss ppo:  -0.03936, loss val: 0.04758
[2022-11-25 00:38:59,431] [INFO] [controller] EPOCH 4 loss ppo:  -0.05058, loss val: 0.04696
[2022-11-25 00:38:59,439] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:38:59,504] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:38:59,504] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:39:05,234] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:39:10,948] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:39:16,765] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:39:22,223] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:39:27,925] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:39:33,505] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:39:39,429] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:39:44,990] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:39:50,670] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:39:56,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.911593030259445
[2022-11-25 00:39:56,389] [INFO] [runner_train_mujoco] Average state value: 0.49581260774532954
[2022-11-25 00:39:56,390] [INFO] [controller] ITERATION NUM: 34
[2022-11-25 00:39:56,440] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04345
[2022-11-25 00:39:56,472] [INFO] [controller] EPOCH 2 loss ppo:  -0.02697, loss val: 0.04296
[2022-11-25 00:39:56,511] [INFO] [controller] EPOCH 3 loss ppo:  -0.03993, loss val: 0.04254
[2022-11-25 00:39:56,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.04811, loss val: 0.04266
[2022-11-25 00:39:56,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:39:56,605] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:39:56,606] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:40:02,599] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:40:08,666] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:40:14,459] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:40:20,441] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:40:26,491] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:40:32,451] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:40:38,577] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:40:44,245] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:40:49,965] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:40:55,734] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.928508200297784
[2022-11-25 00:40:55,734] [INFO] [runner_train_mujoco] Average state value: 0.4909773315985997
[2022-11-25 00:40:55,734] [INFO] [controller] ITERATION NUM: 35
[2022-11-25 00:40:55,785] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.04420
[2022-11-25 00:40:55,833] [INFO] [controller] EPOCH 2 loss ppo:  -0.02582, loss val: 0.03959
[2022-11-25 00:40:55,884] [INFO] [controller] EPOCH 3 loss ppo:  -0.03665, loss val: 0.03947
[2022-11-25 00:40:55,933] [INFO] [controller] EPOCH 4 loss ppo:  -0.04691, loss val: 0.04046
[2022-11-25 00:40:55,945] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:40:56,022] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:40:56,023] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:41:02,324] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:41:08,556] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:41:14,720] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:41:20,722] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:41:26,809] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:41:32,623] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:41:38,756] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:41:44,497] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:41:50,350] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:41:56,594] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0851274501481525
[2022-11-25 00:41:56,594] [INFO] [runner_train_mujoco] Average state value: 0.46485305384794867
[2022-11-25 00:41:56,594] [INFO] [controller] ITERATION NUM: 36
[2022-11-25 00:41:56,646] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.05671
[2022-11-25 00:41:56,697] [INFO] [controller] EPOCH 2 loss ppo:  -0.02620, loss val: 0.05737
[2022-11-25 00:41:56,742] [INFO] [controller] EPOCH 3 loss ppo:  -0.03802, loss val: 0.05705
[2022-11-25 00:41:56,781] [INFO] [controller] EPOCH 4 loss ppo:  -0.04514, loss val: 0.05617
[2022-11-25 00:41:56,788] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:41:56,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:41:56,861] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:42:02,701] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:42:08,715] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:42:14,487] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:42:20,209] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:42:25,855] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:42:31,616] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:42:37,394] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:42:42,983] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:42:48,779] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:42:54,593] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.385860674804886
[2022-11-25 00:42:54,593] [INFO] [runner_train_mujoco] Average state value: 0.46760617504517243
[2022-11-25 00:42:54,593] [INFO] [controller] ITERATION NUM: 37
[2022-11-25 00:42:54,644] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.03950
[2022-11-25 00:42:54,690] [INFO] [controller] EPOCH 2 loss ppo:  -0.02294, loss val: 0.03998
[2022-11-25 00:42:54,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.03060, loss val: 0.03879
[2022-11-25 00:42:54,783] [INFO] [controller] EPOCH 4 loss ppo:  -0.04049, loss val: 0.03801
[2022-11-25 00:42:54,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:42:54,869] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:42:54,869] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:43:00,622] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:43:06,028] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:43:11,741] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:43:17,153] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:43:22,606] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:43:28,069] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:43:33,831] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:43:39,230] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:43:44,849] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:43:50,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.304681129225416
[2022-11-25 00:43:50,231] [INFO] [runner_train_mujoco] Average state value: 0.46824699177344636
[2022-11-25 00:43:50,231] [INFO] [controller] ITERATION NUM: 38
[2022-11-25 00:43:50,283] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.05158
[2022-11-25 00:43:50,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.02289, loss val: 0.05375
[2022-11-25 00:43:50,368] [INFO] [controller] EPOCH 3 loss ppo:  -0.03510, loss val: 0.05158
[2022-11-25 00:43:50,413] [INFO] [controller] EPOCH 4 loss ppo:  -0.04644, loss val: 0.05406
[2022-11-25 00:43:50,424] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:43:50,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:43:50,485] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:43:56,241] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:44:01,730] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:44:06,851] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:44:12,264] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:44:17,459] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:44:22,729] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:44:27,976] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:44:33,389] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:44:39,056] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:44:44,510] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.567467757101378
[2022-11-25 00:44:44,510] [INFO] [runner_train_mujoco] Average state value: 0.47311812835931777
[2022-11-25 00:44:44,510] [INFO] [controller] ITERATION NUM: 39
[2022-11-25 00:44:44,561] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.04307
[2022-11-25 00:44:44,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.02249, loss val: 0.04371
[2022-11-25 00:44:44,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.02871, loss val: 0.04282
[2022-11-25 00:44:44,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.03700, loss val: 0.04279
[2022-11-25 00:44:44,717] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:44:44,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:44:44,770] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:44:49,910] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:44:55,157] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:45:00,649] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:45:06,034] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:45:11,601] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:45:16,579] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:45:21,851] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:45:26,867] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:45:31,881] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:45:37,044] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5499871123421105
[2022-11-25 00:45:37,044] [INFO] [runner_train_mujoco] Average state value: 0.4799992145697276
[2022-11-25 00:45:37,044] [INFO] [controller] ITERATION NUM: 40
[2022-11-25 00:45:37,093] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04680
[2022-11-25 00:45:37,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.02116, loss val: 0.04711
[2022-11-25 00:45:37,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.03257, loss val: 0.04677
[2022-11-25 00:45:37,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.03542, loss val: 0.04641
[2022-11-25 00:45:37,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:45:37,301] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:45:37,301] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:45:42,630] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:45:47,695] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:45:52,919] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:45:58,065] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:46:03,004] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:46:08,329] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:46:13,620] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:46:18,903] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:46:24,111] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:46:29,491] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.640173006040433
[2022-11-25 00:46:29,491] [INFO] [runner_train_mujoco] Average state value: 0.4822759518027306
[2022-11-25 00:46:29,491] [INFO] [controller] ITERATION NUM: 41
[2022-11-25 00:46:29,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.04792
[2022-11-25 00:46:29,576] [INFO] [controller] EPOCH 2 loss ppo:  -0.02298, loss val: 0.04886
[2022-11-25 00:46:29,616] [INFO] [controller] EPOCH 3 loss ppo:  -0.03042, loss val: 0.04727
[2022-11-25 00:46:29,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.03927, loss val: 0.04720
[2022-11-25 00:46:29,665] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:46:29,727] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:46:29,727] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:46:34,964] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:46:40,461] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:46:45,600] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:46:50,508] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:46:55,663] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:47:00,801] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:47:05,950] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:47:10,972] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:47:15,986] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:47:20,956] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.535906137917701
[2022-11-25 00:47:20,956] [INFO] [runner_train_mujoco] Average state value: 0.4843662750323614
[2022-11-25 00:47:20,956] [INFO] [controller] ITERATION NUM: 42
[2022-11-25 00:47:21,006] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.05182
[2022-11-25 00:47:21,048] [INFO] [controller] EPOCH 2 loss ppo:  -0.02087, loss val: 0.05387
[2022-11-25 00:47:21,090] [INFO] [controller] EPOCH 3 loss ppo:  -0.02640, loss val: 0.05170
[2022-11-25 00:47:21,125] [INFO] [controller] EPOCH 4 loss ppo:  -0.03708, loss val: 0.05164
[2022-11-25 00:47:21,131] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:47:21,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:47:21,182] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:47:26,577] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:47:32,379] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:47:37,754] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:47:43,096] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:47:48,329] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:47:53,897] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:47:58,787] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:48:03,990] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:48:09,003] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:48:14,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.840945622110674
[2022-11-25 00:48:14,190] [INFO] [runner_train_mujoco] Average state value: 0.4820217059055964
[2022-11-25 00:48:14,191] [INFO] [controller] ITERATION NUM: 43
[2022-11-25 00:48:14,241] [INFO] [controller] EPOCH 1 loss ppo:  -0.01586, loss val: 0.04577
[2022-11-25 00:48:14,283] [INFO] [controller] EPOCH 2 loss ppo:  -0.02262, loss val: 0.04481
[2022-11-25 00:48:14,323] [INFO] [controller] EPOCH 3 loss ppo:  -0.02610, loss val: 0.04522
[2022-11-25 00:48:14,365] [INFO] [controller] EPOCH 4 loss ppo:  -0.03678, loss val: 0.04532
[2022-11-25 00:48:14,375] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:48:14,426] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:48:14,426] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:48:19,712] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:48:24,790] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:48:29,927] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:48:35,093] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:48:40,270] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:48:45,475] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:48:50,526] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:48:55,526] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:49:00,646] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:49:05,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.751238010449557
[2022-11-25 00:49:05,636] [INFO] [runner_train_mujoco] Average state value: 0.48649878235658006
[2022-11-25 00:49:05,636] [INFO] [controller] ITERATION NUM: 44
[2022-11-25 00:49:05,685] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04937
[2022-11-25 00:49:05,729] [INFO] [controller] EPOCH 2 loss ppo:  -0.01912, loss val: 0.04834
[2022-11-25 00:49:05,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.02477, loss val: 0.04905
[2022-11-25 00:49:05,800] [INFO] [controller] EPOCH 4 loss ppo:  -0.03370, loss val: 0.04882
[2022-11-25 00:49:05,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:49:05,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:49:05,869] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:49:10,886] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:49:15,768] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:49:20,872] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:49:26,040] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:49:30,884] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:49:35,891] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:49:40,697] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:49:45,922] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:49:50,750] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:49:55,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.624447141499828
[2022-11-25 00:49:55,515] [INFO] [runner_train_mujoco] Average state value: 0.4996397896409035
[2022-11-25 00:49:55,515] [INFO] [controller] ITERATION NUM: 45
[2022-11-25 00:49:55,553] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.04873
[2022-11-25 00:49:55,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.01836, loss val: 0.04876
[2022-11-25 00:49:55,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.02303, loss val: 0.04858
[2022-11-25 00:49:55,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.03256, loss val: 0.04848
[2022-11-25 00:49:55,656] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:49:55,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:49:55,712] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:50:00,397] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:50:04,893] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:50:09,470] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:50:13,825] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:50:18,333] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:50:22,676] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:50:27,127] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:50:31,498] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:50:36,186] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:50:40,694] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.738652363549
[2022-11-25 00:50:40,694] [INFO] [runner_train_mujoco] Average state value: 0.49563944059610365
[2022-11-25 00:50:40,694] [INFO] [controller] ITERATION NUM: 46
[2022-11-25 00:50:40,738] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.04919
[2022-11-25 00:50:40,768] [INFO] [controller] EPOCH 2 loss ppo:  -0.02335, loss val: 0.04965
[2022-11-25 00:50:40,843] [INFO] [controller] EPOCH 3 loss ppo:  -0.02681, loss val: 0.04943
[2022-11-25 00:50:40,884] [INFO] [controller] EPOCH 4 loss ppo:  -0.03307, loss val: 0.04931
[2022-11-25 00:50:40,893] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:50:40,935] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:50:40,935] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:50:45,542] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:50:50,077] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:50:54,844] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:50:59,453] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:51:04,007] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:51:08,401] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:51:12,721] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:51:17,213] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:51:21,559] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:51:25,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.84079791947814
[2022-11-25 00:51:25,886] [INFO] [runner_train_mujoco] Average state value: 0.48104160408178964
[2022-11-25 00:51:25,886] [INFO] [controller] ITERATION NUM: 47
[2022-11-25 00:51:25,930] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.05240
[2022-11-25 00:51:25,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.02468, loss val: 0.05385
[2022-11-25 00:51:25,993] [INFO] [controller] EPOCH 3 loss ppo:  -0.03121, loss val: 0.05116
[2022-11-25 00:51:26,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.03523, loss val: 0.05305
[2022-11-25 00:51:26,038] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:51:26,104] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:51:26,105] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:51:30,593] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:51:34,916] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:51:39,435] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:51:43,909] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:51:48,714] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:51:53,024] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:51:57,597] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:52:02,060] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:52:06,429] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:52:10,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.852861479342852
[2022-11-25 00:52:10,774] [INFO] [runner_train_mujoco] Average state value: 0.46672708809375757
[2022-11-25 00:52:10,774] [INFO] [controller] ITERATION NUM: 48
[2022-11-25 00:52:10,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.04717
[2022-11-25 00:52:10,854] [INFO] [controller] EPOCH 2 loss ppo:  -0.02173, loss val: 0.04699
[2022-11-25 00:52:10,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.02792, loss val: 0.04973
[2022-11-25 00:52:10,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.03061, loss val: 0.04710
[2022-11-25 00:52:10,939] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:52:10,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:52:10,999] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:52:15,511] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:52:19,938] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:52:24,697] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:52:29,200] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:52:33,563] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:52:38,295] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:52:42,775] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:52:47,830] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:52:52,498] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:52:57,089] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.971717955930535
[2022-11-25 00:52:57,089] [INFO] [runner_train_mujoco] Average state value: 0.4541309453050295
[2022-11-25 00:52:57,089] [INFO] [controller] ITERATION NUM: 49
[2022-11-25 00:52:57,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.05033
[2022-11-25 00:52:57,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.01852, loss val: 0.05050
[2022-11-25 00:52:57,224] [INFO] [controller] EPOCH 3 loss ppo:  -0.02489, loss val: 0.05260
[2022-11-25 00:52:57,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.03061, loss val: 0.05120
[2022-11-25 00:52:57,275] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:52:57,336] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:52:57,336] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:53:01,905] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:53:06,505] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:53:10,864] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:53:15,361] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:53:19,814] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:53:24,154] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:53:28,476] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:53:32,756] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:53:37,105] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:53:41,422] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.923703456227533
[2022-11-25 00:53:41,423] [INFO] [runner_train_mujoco] Average state value: 0.4555292632579803
[2022-11-25 00:53:41,423] [INFO] [controller] ITERATION NUM: 50
[2022-11-25 00:53:41,465] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.04613
[2022-11-25 00:53:41,501] [INFO] [controller] EPOCH 2 loss ppo:  -0.01747, loss val: 0.04567
[2022-11-25 00:53:41,534] [INFO] [controller] EPOCH 3 loss ppo:  -0.02130, loss val: 0.04841
[2022-11-25 00:53:41,564] [INFO] [controller] EPOCH 4 loss ppo:  -0.02542, loss val: 0.04568
[2022-11-25 00:53:41,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:53:41,615] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:53:41,616] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:53:46,300] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:53:50,915] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:53:55,446] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:53:59,873] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:54:04,155] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:54:08,461] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:54:12,775] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:54:16,991] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:54:21,188] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:54:26,217] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.211864598644558
[2022-11-25 00:54:26,217] [INFO] [runner_train_mujoco] Average state value: 0.4599776028792064
[2022-11-25 00:54:26,217] [INFO] [controller] ITERATION NUM: 51
[2022-11-25 00:54:26,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.04791
[2022-11-25 00:54:26,339] [INFO] [controller] EPOCH 2 loss ppo:  -0.01674, loss val: 0.04790
[2022-11-25 00:54:26,397] [INFO] [controller] EPOCH 3 loss ppo:  -0.02283, loss val: 0.04676
[2022-11-25 00:54:26,461] [INFO] [controller] EPOCH 4 loss ppo:  -0.02740, loss val: 0.04806
[2022-11-25 00:54:26,472] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:54:26,549] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:54:26,550] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:54:32,237] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:54:36,789] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:54:41,260] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:54:45,565] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:54:49,931] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:54:54,191] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:54:58,504] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:55:02,875] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:55:07,253] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:55:11,526] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.208395245291994
[2022-11-25 00:55:11,526] [INFO] [runner_train_mujoco] Average state value: 0.4585891028841337
[2022-11-25 00:55:11,526] [INFO] [controller] ITERATION NUM: 52
[2022-11-25 00:55:11,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.05233
[2022-11-25 00:55:11,605] [INFO] [controller] EPOCH 2 loss ppo:  -0.01725, loss val: 0.05186
[2022-11-25 00:55:11,643] [INFO] [controller] EPOCH 3 loss ppo:  -0.02131, loss val: 0.05178
[2022-11-25 00:55:11,678] [INFO] [controller] EPOCH 4 loss ppo:  -0.02512, loss val: 0.05162
[2022-11-25 00:55:11,687] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:55:11,751] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:55:11,752] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:55:16,094] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:55:20,306] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:55:24,814] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:55:29,424] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:55:33,802] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:55:38,353] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:55:42,918] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:55:47,333] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:55:51,852] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:55:56,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.1972101150680015
[2022-11-25 00:55:56,177] [INFO] [runner_train_mujoco] Average state value: 0.4628534535169601
[2022-11-25 00:55:56,177] [INFO] [controller] ITERATION NUM: 53
[2022-11-25 00:55:56,218] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.05049
[2022-11-25 00:55:56,255] [INFO] [controller] EPOCH 2 loss ppo:  -0.01809, loss val: 0.05016
[2022-11-25 00:55:56,289] [INFO] [controller] EPOCH 3 loss ppo:  -0.02674, loss val: 0.05065
[2022-11-25 00:55:56,325] [INFO] [controller] EPOCH 4 loss ppo:  -0.02949, loss val: 0.05013
[2022-11-25 00:55:56,334] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:55:56,387] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:55:56,387] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:56:00,866] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:56:05,158] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:56:09,723] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:56:13,989] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:56:18,174] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:56:22,514] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:56:26,816] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:56:31,186] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:56:35,440] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:56:39,967] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.222122704589822
[2022-11-25 00:56:39,968] [INFO] [runner_train_mujoco] Average state value: 0.46798697803417844
[2022-11-25 00:56:39,968] [INFO] [controller] ITERATION NUM: 54
[2022-11-25 00:56:40,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04849
[2022-11-25 00:56:40,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.01556, loss val: 0.04864
[2022-11-25 00:56:40,065] [INFO] [controller] EPOCH 3 loss ppo:  -0.01976, loss val: 0.04951
[2022-11-25 00:56:40,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.02269, loss val: 0.04878
[2022-11-25 00:56:40,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:56:40,161] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:56:40,162] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:56:44,641] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:56:49,015] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:56:53,091] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:56:57,107] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:57:01,328] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:57:05,376] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:57:09,441] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:57:13,352] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:57:17,299] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:57:21,220] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.2751790457104715
[2022-11-25 00:57:21,220] [INFO] [runner_train_mujoco] Average state value: 0.4690088053345681
[2022-11-25 00:57:21,221] [INFO] [controller] ITERATION NUM: 55
[2022-11-25 00:57:21,254] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.05449
[2022-11-25 00:57:21,282] [INFO] [controller] EPOCH 2 loss ppo:  -0.01790, loss val: 0.05202
[2022-11-25 00:57:21,308] [INFO] [controller] EPOCH 3 loss ppo:  -0.02269, loss val: 0.05179
[2022-11-25 00:57:21,333] [INFO] [controller] EPOCH 4 loss ppo:  -0.02389, loss val: 0.05318
[2022-11-25 00:57:21,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:57:21,385] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:57:21,386] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:57:28,811] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:57:35,850] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:57:42,061] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:57:47,956] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:57:53,572] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:57:59,211] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:58:04,875] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:58:10,574] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:58:16,420] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:58:22,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.3773745479404305
[2022-11-25 00:58:22,106] [INFO] [runner_train_mujoco] Average state value: 0.46485634636878964
[2022-11-25 00:58:22,106] [INFO] [controller] ITERATION NUM: 56
[2022-11-25 00:58:22,189] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.05658
[2022-11-25 00:58:22,261] [INFO] [controller] EPOCH 2 loss ppo:  -0.01829, loss val: 0.05674
[2022-11-25 00:58:22,331] [INFO] [controller] EPOCH 3 loss ppo:  -0.02384, loss val: 0.05618
[2022-11-25 00:58:22,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.02626, loss val: 0.05782
[2022-11-25 00:58:22,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:58:22,518] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:58:22,518] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:58:29,023] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:58:35,214] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:58:41,893] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:58:48,506] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:58:55,227] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:59:00,979] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:59:07,668] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:59:13,903] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:59:21,002] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:59:28,150] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.329514990077078
[2022-11-25 00:59:28,151] [INFO] [runner_train_mujoco] Average state value: 0.46321159434318543
[2022-11-25 00:59:28,151] [INFO] [controller] ITERATION NUM: 57
[2022-11-25 00:59:28,230] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04772
[2022-11-25 00:59:28,305] [INFO] [controller] EPOCH 2 loss ppo:  -0.01472, loss val: 0.04526
[2022-11-25 00:59:28,389] [INFO] [controller] EPOCH 3 loss ppo:  -0.01737, loss val: 0.04728
[2022-11-25 00:59:28,545] [INFO] [controller] EPOCH 4 loss ppo:  -0.02054, loss val: 0.04567
[2022-11-25 00:59:28,566] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:59:28,683] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:59:28,684] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:59:36,941] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:59:43,215] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:59:48,394] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:59:55,792] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:00:02,031] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:00:07,651] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:00:13,044] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:00:17,806] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:00:22,344] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:00:26,690] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.43548244604596
[2022-11-25 01:00:26,690] [INFO] [runner_train_mujoco] Average state value: 0.45931898242235186
[2022-11-25 01:00:26,690] [INFO] [controller] ITERATION NUM: 58
[2022-11-25 01:00:26,732] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04649
[2022-11-25 01:00:26,771] [INFO] [controller] EPOCH 2 loss ppo:  -0.01360, loss val: 0.04598
[2022-11-25 01:00:26,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.01468, loss val: 0.04633
[2022-11-25 01:00:26,830] [INFO] [controller] EPOCH 4 loss ppo:  -0.01601, loss val: 0.04618
[2022-11-25 01:00:26,836] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:00:26,841] [INFO] [optimize] Finished learning.
