[2022-11-25 00:54:24,347] [INFO] [optimize] Starting learning
[2022-11-25 00:54:24,357] [INFO] [optimize] Starting learning process..
[2022-11-25 00:54:24,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:54:24,422] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:54:32,615] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:54:39,020] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:54:45,215] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:54:51,347] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:54:57,337] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:55:03,420] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:55:09,479] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:55:15,632] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:55:21,760] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:55:27,987] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5107217577461405
[2022-11-25 00:55:27,988] [INFO] [runner_train_mujoco] Average state value: -0.08964800454924504
[2022-11-25 00:55:27,988] [INFO] [controller] ITERATION NUM: 1
[2022-11-25 00:55:28,036] [INFO] [controller] EPOCH 1 loss ppo:  -0.00960, loss val: 0.49313
[2022-11-25 00:55:28,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.04420, loss val: 0.44818
[2022-11-25 00:55:28,104] [INFO] [controller] EPOCH 3 loss ppo:  -0.06678, loss val: 0.38369
[2022-11-25 00:55:28,138] [INFO] [controller] EPOCH 4 loss ppo:  -0.07814, loss val: 0.34445
[2022-11-25 00:55:28,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:55:28,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:55:28,226] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:55:34,503] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:55:40,820] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:55:47,080] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:55:53,352] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:55:59,690] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:56:05,844] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:56:11,998] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:56:17,950] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:56:24,053] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:56:30,096] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4796283041306519
[2022-11-25 00:56:30,096] [INFO] [runner_train_mujoco] Average state value: 0.04921806825014453
[2022-11-25 00:56:30,096] [INFO] [controller] ITERATION NUM: 2
[2022-11-25 00:56:30,136] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.38157
[2022-11-25 00:56:30,174] [INFO] [controller] EPOCH 2 loss ppo:  -0.04672, loss val: 0.33836
[2022-11-25 00:56:30,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.06411, loss val: 0.29213
[2022-11-25 00:56:30,239] [INFO] [controller] EPOCH 4 loss ppo:  -0.07513, loss val: 0.25446
[2022-11-25 00:56:30,245] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:56:30,296] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:56:30,296] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:56:36,541] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:56:43,195] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:56:49,335] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:56:55,023] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:57:00,753] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:57:06,578] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:57:12,216] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:57:17,920] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:57:25,435] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:57:35,286] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.558351459833083
[2022-11-25 00:57:35,286] [INFO] [runner_train_mujoco] Average state value: 0.23648708035362262
[2022-11-25 00:57:35,286] [INFO] [controller] ITERATION NUM: 3
[2022-11-25 00:57:35,347] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.17074
[2022-11-25 00:57:35,401] [INFO] [controller] EPOCH 2 loss ppo:  -0.05078, loss val: 0.16463
[2022-11-25 00:57:35,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.06833, loss val: 0.12634
[2022-11-25 00:57:35,514] [INFO] [controller] EPOCH 4 loss ppo:  -0.08019, loss val: 0.11239
[2022-11-25 00:57:35,526] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:57:35,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:57:35,649] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:57:44,206] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:57:52,240] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:58:00,216] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:58:07,965] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:58:16,161] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:58:24,846] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 00:58:33,352] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 00:58:42,782] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 00:58:51,880] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 00:59:00,379] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6833850886770373
[2022-11-25 00:59:00,379] [INFO] [runner_train_mujoco] Average state value: 0.3589368942112972
[2022-11-25 00:59:00,379] [INFO] [controller] ITERATION NUM: 4
[2022-11-25 00:59:00,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.14003
[2022-11-25 00:59:00,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.04372, loss val: 0.12457
[2022-11-25 00:59:00,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.06040, loss val: 0.10836
[2022-11-25 00:59:00,612] [INFO] [controller] EPOCH 4 loss ppo:  -0.07303, loss val: 0.09419
[2022-11-25 00:59:00,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 00:59:00,735] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 00:59:00,736] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 00:59:09,935] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 00:59:19,572] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 00:59:30,291] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 00:59:40,841] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 00:59:48,568] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 00:59:58,540] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:00:06,647] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:00:14,152] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:00:20,751] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:00:27,158] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5970002953016557
[2022-11-25 01:00:27,158] [INFO] [runner_train_mujoco] Average state value: 0.5082001637679835
[2022-11-25 01:00:27,158] [INFO] [controller] ITERATION NUM: 5
[2022-11-25 01:00:27,198] [INFO] [controller] EPOCH 1 loss ppo:  -0.00889, loss val: 0.08770
[2022-11-25 01:00:27,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.04706, loss val: 0.08054
[2022-11-25 01:00:27,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.06659, loss val: 0.07669
[2022-11-25 01:00:27,291] [INFO] [controller] EPOCH 4 loss ppo:  -0.07498, loss val: 0.07329
[2022-11-25 01:00:27,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:00:27,366] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:00:27,367] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:00:33,341] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:00:39,162] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:00:45,105] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:00:50,860] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:00:59,286] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:01:04,943] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:01:10,529] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:01:16,092] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:01:21,789] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:01:27,382] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8316617633811859
[2022-11-25 01:01:27,383] [INFO] [runner_train_mujoco] Average state value: 0.5748267838569979
[2022-11-25 01:01:27,383] [INFO] [controller] ITERATION NUM: 6
[2022-11-25 01:01:27,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.07448
[2022-11-25 01:01:27,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.04441, loss val: 0.06963
[2022-11-25 01:01:27,489] [INFO] [controller] EPOCH 3 loss ppo:  -0.06178, loss val: 0.06668
[2022-11-25 01:01:27,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.07317, loss val: 0.06368
[2022-11-25 01:01:27,522] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:01:27,578] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:01:27,579] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:01:33,285] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:01:38,944] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:01:44,517] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:01:50,136] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:01:55,754] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:02:01,323] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:02:06,775] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:02:12,440] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:02:17,971] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:02:23,578] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5636046666983322
[2022-11-25 01:02:23,578] [INFO] [runner_train_mujoco] Average state value: 0.5609152274330457
[2022-11-25 01:02:23,578] [INFO] [controller] ITERATION NUM: 7
[2022-11-25 01:02:23,620] [INFO] [controller] EPOCH 1 loss ppo:  -0.00917, loss val: 0.05085
[2022-11-25 01:02:23,654] [INFO] [controller] EPOCH 2 loss ppo:  -0.04118, loss val: 0.04880
[2022-11-25 01:02:23,693] [INFO] [controller] EPOCH 3 loss ppo:  -0.06261, loss val: 0.04638
[2022-11-25 01:02:23,727] [INFO] [controller] EPOCH 4 loss ppo:  -0.07662, loss val: 0.04921
[2022-11-25 01:02:23,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:02:23,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:02:23,779] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:02:29,444] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:02:35,073] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:02:40,660] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:02:46,159] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:02:51,793] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:02:57,355] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:03:02,894] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:03:08,489] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:03:14,117] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:03:19,645] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48976426616664315
[2022-11-25 01:03:19,646] [INFO] [runner_train_mujoco] Average state value: 0.5312858157604933
[2022-11-25 01:03:19,646] [INFO] [controller] ITERATION NUM: 8
[2022-11-25 01:03:19,682] [INFO] [controller] EPOCH 1 loss ppo:  -0.00923, loss val: 0.06080
[2022-11-25 01:03:19,707] [INFO] [controller] EPOCH 2 loss ppo:  -0.04053, loss val: 0.05959
[2022-11-25 01:03:19,742] [INFO] [controller] EPOCH 3 loss ppo:  -0.06220, loss val: 0.05807
[2022-11-25 01:03:19,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.07156, loss val: 0.05709
[2022-11-25 01:03:19,786] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:03:19,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:03:19,835] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:03:25,656] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:03:31,193] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:03:36,788] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:03:42,324] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:03:47,858] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:03:53,418] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:03:58,866] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:04:04,403] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:04:09,889] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:04:15,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5904328487370568
[2022-11-25 01:04:15,309] [INFO] [runner_train_mujoco] Average state value: 0.48979636108751096
[2022-11-25 01:04:15,309] [INFO] [controller] ITERATION NUM: 9
[2022-11-25 01:04:15,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01061, loss val: 0.03899
[2022-11-25 01:04:15,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.04467, loss val: 0.03813
[2022-11-25 01:04:15,421] [INFO] [controller] EPOCH 3 loss ppo:  -0.06145, loss val: 0.03782
[2022-11-25 01:04:15,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.07433, loss val: 0.03699
[2022-11-25 01:04:15,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:04:15,519] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:04:15,519] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:04:21,111] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:04:26,821] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:04:32,436] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:04:37,884] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:04:43,413] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:04:48,894] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:04:54,350] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:04:59,823] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:05:05,502] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:05:11,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6480675955182417
[2022-11-25 01:05:11,045] [INFO] [runner_train_mujoco] Average state value: 0.4722656902174155
[2022-11-25 01:05:11,045] [INFO] [controller] ITERATION NUM: 10
[2022-11-25 01:05:11,080] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04431
[2022-11-25 01:05:11,106] [INFO] [controller] EPOCH 2 loss ppo:  -0.04474, loss val: 0.04344
[2022-11-25 01:05:11,135] [INFO] [controller] EPOCH 3 loss ppo:  -0.06239, loss val: 0.04299
[2022-11-25 01:05:11,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.07320, loss val: 0.04436
[2022-11-25 01:05:11,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:05:11,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:05:11,226] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:05:16,992] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:05:22,476] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:05:28,155] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:05:33,477] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:05:38,993] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:05:44,540] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:05:50,013] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:05:55,751] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:06:01,299] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:06:07,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5249347899188958
[2022-11-25 01:06:07,088] [INFO] [runner_train_mujoco] Average state value: 0.4823081504603226
[2022-11-25 01:06:07,088] [INFO] [controller] ITERATION NUM: 11
[2022-11-25 01:06:07,131] [INFO] [controller] EPOCH 1 loss ppo:  -0.01032, loss val: 0.04468
[2022-11-25 01:06:07,169] [INFO] [controller] EPOCH 2 loss ppo:  -0.04321, loss val: 0.04386
[2022-11-25 01:06:07,214] [INFO] [controller] EPOCH 3 loss ppo:  -0.06217, loss val: 0.04707
[2022-11-25 01:06:07,264] [INFO] [controller] EPOCH 4 loss ppo:  -0.07457, loss val: 0.04144
[2022-11-25 01:06:07,270] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:06:07,344] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:06:07,345] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:06:13,682] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:06:19,976] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:06:25,883] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:06:31,351] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:06:36,947] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:06:42,839] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:06:48,501] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:06:53,954] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:06:59,507] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:07:04,998] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7316070778564894
[2022-11-25 01:07:04,998] [INFO] [runner_train_mujoco] Average state value: 0.5058513433237871
[2022-11-25 01:07:04,998] [INFO] [controller] ITERATION NUM: 12
[2022-11-25 01:07:05,041] [INFO] [controller] EPOCH 1 loss ppo:  -0.01155, loss val: 0.03500
[2022-11-25 01:07:05,080] [INFO] [controller] EPOCH 2 loss ppo:  -0.04668, loss val: 0.03456
[2022-11-25 01:07:05,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.06528, loss val: 0.03796
[2022-11-25 01:07:05,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.07730, loss val: 0.03330
[2022-11-25 01:07:05,146] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:07:05,206] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:07:05,206] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:07:10,870] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:07:16,488] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:07:22,138] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:07:29,769] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:07:35,979] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:07:41,870] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:07:47,388] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:07:52,817] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:07:58,487] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:08:04,187] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6253382925866495
[2022-11-25 01:08:04,187] [INFO] [runner_train_mujoco] Average state value: 0.5262461698849996
[2022-11-25 01:08:04,187] [INFO] [controller] ITERATION NUM: 13
[2022-11-25 01:08:04,227] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.04332
[2022-11-25 01:08:04,254] [INFO] [controller] EPOCH 2 loss ppo:  -0.03993, loss val: 0.04377
[2022-11-25 01:08:04,289] [INFO] [controller] EPOCH 3 loss ppo:  -0.05680, loss val: 0.04198
[2022-11-25 01:08:04,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.07027, loss val: 0.04229
[2022-11-25 01:08:04,333] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:08:04,381] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:08:04,381] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:08:10,162] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:08:15,715] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:08:21,275] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:08:26,761] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:08:32,371] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:08:37,843] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:08:43,422] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:08:49,085] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:08:54,767] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:09:00,392] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7506989675771171
[2022-11-25 01:09:00,392] [INFO] [runner_train_mujoco] Average state value: 0.49378672426939013
[2022-11-25 01:09:00,392] [INFO] [controller] ITERATION NUM: 14
[2022-11-25 01:09:00,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.03584
[2022-11-25 01:09:00,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.04850, loss val: 0.03589
[2022-11-25 01:09:00,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.06646, loss val: 0.03592
[2022-11-25 01:09:00,594] [INFO] [controller] EPOCH 4 loss ppo:  -0.08091, loss val: 0.03751
[2022-11-25 01:09:00,603] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:09:00,670] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:09:00,671] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:09:06,385] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:09:12,050] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:09:17,740] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:09:23,399] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:09:28,864] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:09:34,608] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:09:40,114] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:09:45,722] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:09:51,219] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:09:56,695] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9923095692439533
[2022-11-25 01:09:56,695] [INFO] [runner_train_mujoco] Average state value: 0.48992891763647395
[2022-11-25 01:09:56,695] [INFO] [controller] ITERATION NUM: 15
[2022-11-25 01:09:56,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04616
[2022-11-25 01:09:56,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.04555, loss val: 0.04521
[2022-11-25 01:09:56,815] [INFO] [controller] EPOCH 3 loss ppo:  -0.06525, loss val: 0.04679
[2022-11-25 01:09:56,853] [INFO] [controller] EPOCH 4 loss ppo:  -0.07592, loss val: 0.04294
[2022-11-25 01:09:56,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:09:56,927] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:09:56,927] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:10:02,662] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:10:08,243] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:10:13,934] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:10:19,435] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:10:25,083] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:10:30,501] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:10:36,034] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:10:41,701] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:10:47,289] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:10:52,680] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8833349515103327
[2022-11-25 01:10:52,680] [INFO] [runner_train_mujoco] Average state value: 0.5281542290945848
[2022-11-25 01:10:52,680] [INFO] [controller] ITERATION NUM: 16
[2022-11-25 01:10:52,713] [INFO] [controller] EPOCH 1 loss ppo:  -0.01088, loss val: 0.04506
[2022-11-25 01:10:52,742] [INFO] [controller] EPOCH 2 loss ppo:  -0.03872, loss val: 0.04535
[2022-11-25 01:10:52,779] [INFO] [controller] EPOCH 3 loss ppo:  -0.05944, loss val: 0.04372
[2022-11-25 01:10:52,816] [INFO] [controller] EPOCH 4 loss ppo:  -0.07620, loss val: 0.04226
[2022-11-25 01:10:52,822] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:10:52,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:10:52,876] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:10:58,538] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:11:04,142] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:11:09,733] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:11:15,288] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:11:20,795] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:11:26,297] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:11:31,763] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:11:37,130] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:11:42,556] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:11:48,085] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7933902981728209
[2022-11-25 01:11:48,085] [INFO] [runner_train_mujoco] Average state value: 0.5201199405590693
[2022-11-25 01:11:48,085] [INFO] [controller] ITERATION NUM: 17
[2022-11-25 01:11:48,128] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.03951
[2022-11-25 01:11:48,164] [INFO] [controller] EPOCH 2 loss ppo:  -0.04662, loss val: 0.03823
[2022-11-25 01:11:48,198] [INFO] [controller] EPOCH 3 loss ppo:  -0.06773, loss val: 0.03435
[2022-11-25 01:11:48,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.07761, loss val: 0.03757
[2022-11-25 01:11:48,238] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:11:48,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:11:48,302] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:11:53,926] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:11:59,549] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:12:05,115] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:12:10,650] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:12:16,072] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:12:21,476] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:12:26,850] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:12:32,379] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:12:37,846] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:12:43,224] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4195558956760328
[2022-11-25 01:12:43,224] [INFO] [runner_train_mujoco] Average state value: 0.4805168510178725
[2022-11-25 01:12:43,224] [INFO] [controller] ITERATION NUM: 18
[2022-11-25 01:12:43,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.03906
[2022-11-25 01:12:43,298] [INFO] [controller] EPOCH 2 loss ppo:  -0.04734, loss val: 0.03863
[2022-11-25 01:12:43,328] [INFO] [controller] EPOCH 3 loss ppo:  -0.06506, loss val: 0.03835
[2022-11-25 01:12:43,366] [INFO] [controller] EPOCH 4 loss ppo:  -0.07895, loss val: 0.04092
[2022-11-25 01:12:43,376] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:12:43,453] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:12:43,454] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:12:49,097] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:12:54,532] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:13:00,167] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:13:05,545] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:13:10,887] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:13:16,298] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:13:21,706] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:13:27,257] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:13:32,674] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:13:38,209] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4102119360112775
[2022-11-25 01:13:38,210] [INFO] [runner_train_mujoco] Average state value: 0.459497001906236
[2022-11-25 01:13:38,210] [INFO] [controller] ITERATION NUM: 19
[2022-11-25 01:13:38,256] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04342
[2022-11-25 01:13:38,285] [INFO] [controller] EPOCH 2 loss ppo:  -0.04343, loss val: 0.04445
[2022-11-25 01:13:38,315] [INFO] [controller] EPOCH 3 loss ppo:  -0.05881, loss val: 0.04217
[2022-11-25 01:13:38,355] [INFO] [controller] EPOCH 4 loss ppo:  -0.07117, loss val: 0.04280
[2022-11-25 01:13:38,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:13:38,436] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:13:38,436] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:13:44,027] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:13:49,573] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:13:55,255] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:14:00,746] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:14:06,084] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:14:11,512] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:14:17,043] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:14:22,445] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:14:27,739] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:14:33,053] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8180692030008896
[2022-11-25 01:14:33,053] [INFO] [runner_train_mujoco] Average state value: 0.4893555828730265
[2022-11-25 01:14:33,053] [INFO] [controller] ITERATION NUM: 20
[2022-11-25 01:14:33,093] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.04176
[2022-11-25 01:14:33,124] [INFO] [controller] EPOCH 2 loss ppo:  -0.04623, loss val: 0.04193
[2022-11-25 01:14:33,155] [INFO] [controller] EPOCH 3 loss ppo:  -0.06516, loss val: 0.04342
[2022-11-25 01:14:33,186] [INFO] [controller] EPOCH 4 loss ppo:  -0.07774, loss val: 0.04251
[2022-11-25 01:14:33,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:14:33,252] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:14:33,252] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:14:38,772] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:14:44,141] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:14:49,962] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:14:55,584] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:15:01,251] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:15:06,715] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:15:12,357] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:15:17,861] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:15:23,318] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:15:28,805] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.671883117580857
[2022-11-25 01:15:28,806] [INFO] [runner_train_mujoco] Average state value: 0.505987322350343
[2022-11-25 01:15:28,806] [INFO] [controller] ITERATION NUM: 21
[2022-11-25 01:15:28,844] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04503
[2022-11-25 01:15:28,873] [INFO] [controller] EPOCH 2 loss ppo:  -0.04724, loss val: 0.04452
[2022-11-25 01:15:28,909] [INFO] [controller] EPOCH 3 loss ppo:  -0.06815, loss val: 0.04464
[2022-11-25 01:15:28,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.07866, loss val: 0.04511
[2022-11-25 01:15:28,943] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:15:29,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:15:29,015] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:15:34,528] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:15:39,869] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:15:45,518] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:15:51,018] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:15:56,510] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:16:01,817] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:16:07,102] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:16:12,502] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:16:17,783] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:16:23,152] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.957886716124176
[2022-11-25 01:16:23,153] [INFO] [runner_train_mujoco] Average state value: 0.5035833000739416
[2022-11-25 01:16:23,153] [INFO] [controller] ITERATION NUM: 22
[2022-11-25 01:16:23,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.03162
[2022-11-25 01:16:23,219] [INFO] [controller] EPOCH 2 loss ppo:  -0.04533, loss val: 0.03228
[2022-11-25 01:16:23,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.06357, loss val: 0.03060
[2022-11-25 01:16:23,284] [INFO] [controller] EPOCH 4 loss ppo:  -0.07789, loss val: 0.03000
[2022-11-25 01:16:23,289] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:16:23,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:16:23,333] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:16:28,418] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:16:33,598] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:16:38,759] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:16:43,834] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:16:49,058] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:16:54,143] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:16:59,261] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:17:04,312] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:17:09,985] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:17:15,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3329349015432252
[2022-11-25 01:17:15,089] [INFO] [runner_train_mujoco] Average state value: 0.4688927402198314
[2022-11-25 01:17:15,089] [INFO] [controller] ITERATION NUM: 23
[2022-11-25 01:17:15,122] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.05848
[2022-11-25 01:17:15,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.04489, loss val: 0.05944
[2022-11-25 01:17:15,176] [INFO] [controller] EPOCH 3 loss ppo:  -0.06172, loss val: 0.05954
[2022-11-25 01:17:15,204] [INFO] [controller] EPOCH 4 loss ppo:  -0.07228, loss val: 0.05539
[2022-11-25 01:17:15,209] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:17:15,256] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:17:15,257] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:17:20,401] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:17:25,595] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:17:31,366] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:17:39,534] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:17:45,040] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:17:50,224] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:17:55,534] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:18:00,688] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:18:05,742] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:18:10,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.160060546923452
[2022-11-25 01:18:10,979] [INFO] [runner_train_mujoco] Average state value: 0.48999426357199755
[2022-11-25 01:18:10,979] [INFO] [controller] ITERATION NUM: 24
[2022-11-25 01:18:11,012] [INFO] [controller] EPOCH 1 loss ppo:  -0.01489, loss val: 0.04904
[2022-11-25 01:18:11,036] [INFO] [controller] EPOCH 2 loss ppo:  -0.04228, loss val: 0.04763
[2022-11-25 01:18:11,062] [INFO] [controller] EPOCH 3 loss ppo:  -0.06234, loss val: 0.04663
[2022-11-25 01:18:11,088] [INFO] [controller] EPOCH 4 loss ppo:  -0.07534, loss val: 0.04593
[2022-11-25 01:18:11,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:18:11,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:18:11,147] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:18:16,211] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:18:21,193] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:18:26,312] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:18:31,369] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:18:36,393] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:18:41,500] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:18:46,754] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:18:51,926] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:18:57,032] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:19:02,145] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.687805777600988
[2022-11-25 01:19:02,145] [INFO] [runner_train_mujoco] Average state value: 0.5635188627243042
[2022-11-25 01:19:02,145] [INFO] [controller] ITERATION NUM: 25
[2022-11-25 01:19:02,183] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04213
[2022-11-25 01:19:02,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.04616, loss val: 0.04315
[2022-11-25 01:19:02,239] [INFO] [controller] EPOCH 3 loss ppo:  -0.06523, loss val: 0.04236
[2022-11-25 01:19:02,270] [INFO] [controller] EPOCH 4 loss ppo:  -0.07797, loss val: 0.04287
[2022-11-25 01:19:02,275] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:19:02,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:19:02,331] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:19:07,591] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:19:12,674] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:19:17,916] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:19:22,947] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:19:28,319] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:19:33,544] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:19:38,936] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:19:44,241] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:19:49,518] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:19:54,774] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.601441097294271
[2022-11-25 01:19:54,775] [INFO] [runner_train_mujoco] Average state value: 0.5548519159095984
[2022-11-25 01:19:54,775] [INFO] [controller] ITERATION NUM: 26
[2022-11-25 01:19:54,807] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.05415
[2022-11-25 01:19:54,832] [INFO] [controller] EPOCH 2 loss ppo:  -0.04138, loss val: 0.05421
[2022-11-25 01:19:54,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.05773, loss val: 0.05314
[2022-11-25 01:19:54,885] [INFO] [controller] EPOCH 4 loss ppo:  -0.07677, loss val: 0.05307
[2022-11-25 01:19:54,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:19:54,940] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:19:54,941] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:20:00,315] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:20:05,505] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:20:10,749] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:20:15,846] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:20:20,910] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:20:25,971] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:20:31,064] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:20:36,132] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:20:41,197] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:20:46,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.534474077122188
[2022-11-25 01:20:46,160] [INFO] [runner_train_mujoco] Average state value: 0.5697349526435136
[2022-11-25 01:20:46,160] [INFO] [controller] ITERATION NUM: 27
[2022-11-25 01:20:46,193] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.03956
[2022-11-25 01:20:46,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.03858, loss val: 0.03908
[2022-11-25 01:20:46,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.05688, loss val: 0.03884
[2022-11-25 01:20:46,270] [INFO] [controller] EPOCH 4 loss ppo:  -0.07371, loss val: 0.03694
[2022-11-25 01:20:46,278] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:20:46,338] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:20:46,338] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:20:51,651] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:20:56,946] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:21:02,202] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:21:07,525] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:21:12,590] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:21:17,667] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:21:22,731] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:21:27,784] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:21:32,938] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:21:38,120] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.660932810008503
[2022-11-25 01:21:38,120] [INFO] [runner_train_mujoco] Average state value: 0.5462336012721061
[2022-11-25 01:21:38,120] [INFO] [controller] ITERATION NUM: 28
[2022-11-25 01:21:38,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.04402
[2022-11-25 01:21:38,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.04326, loss val: 0.04322
[2022-11-25 01:21:38,224] [INFO] [controller] EPOCH 3 loss ppo:  -0.06120, loss val: 0.04076
[2022-11-25 01:21:38,262] [INFO] [controller] EPOCH 4 loss ppo:  -0.07547, loss val: 0.03850
[2022-11-25 01:21:38,271] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:21:38,322] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:21:38,322] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:21:43,581] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:21:48,735] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:21:53,924] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:21:58,954] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:22:03,947] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:22:08,904] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:22:13,988] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:22:18,927] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:22:24,041] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:22:29,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9702502572656
[2022-11-25 01:22:29,115] [INFO] [runner_train_mujoco] Average state value: 0.49186046970884006
[2022-11-25 01:22:29,115] [INFO] [controller] ITERATION NUM: 29
[2022-11-25 01:22:29,148] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04549
[2022-11-25 01:22:29,180] [INFO] [controller] EPOCH 2 loss ppo:  -0.04024, loss val: 0.04747
[2022-11-25 01:22:29,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.05786, loss val: 0.04733
[2022-11-25 01:22:29,237] [INFO] [controller] EPOCH 4 loss ppo:  -0.07056, loss val: 0.04612
[2022-11-25 01:22:29,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:22:29,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:22:29,293] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:22:34,444] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:22:39,497] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:22:44,549] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:22:49,671] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:22:54,712] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:22:59,860] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:23:04,984] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:23:10,105] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:23:15,113] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:23:20,210] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6161296980837094
[2022-11-25 01:23:20,211] [INFO] [runner_train_mujoco] Average state value: 0.49392111218472323
[2022-11-25 01:23:20,211] [INFO] [controller] ITERATION NUM: 30
[2022-11-25 01:23:20,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.03866
[2022-11-25 01:23:20,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.04324, loss val: 0.03709
[2022-11-25 01:23:20,297] [INFO] [controller] EPOCH 3 loss ppo:  -0.06282, loss val: 0.03516
[2022-11-25 01:23:20,322] [INFO] [controller] EPOCH 4 loss ppo:  -0.07442, loss val: 0.03476
[2022-11-25 01:23:20,326] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:23:20,383] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:23:20,383] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:23:25,552] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:23:30,932] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:23:36,006] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:23:40,904] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:23:45,963] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:23:51,140] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:23:56,145] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:24:01,171] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:24:06,207] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:24:11,226] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3631842666489007
[2022-11-25 01:24:11,226] [INFO] [runner_train_mujoco] Average state value: 0.5482189352611699
[2022-11-25 01:24:11,226] [INFO] [controller] ITERATION NUM: 31
[2022-11-25 01:24:11,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.04830
[2022-11-25 01:24:11,284] [INFO] [controller] EPOCH 2 loss ppo:  -0.03594, loss val: 0.04970
[2022-11-25 01:24:11,357] [INFO] [controller] EPOCH 3 loss ppo:  -0.05478, loss val: 0.05607
[2022-11-25 01:24:11,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.06683, loss val: 0.04740
[2022-11-25 01:24:11,391] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:24:11,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:24:11,431] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:24:16,521] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:24:21,587] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:24:26,614] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:24:31,690] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:24:36,605] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:24:41,648] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:24:46,751] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:24:51,895] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:24:57,027] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:25:02,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3788126983941824
[2022-11-25 01:25:02,065] [INFO] [runner_train_mujoco] Average state value: 0.5378032080928484
[2022-11-25 01:25:02,065] [INFO] [controller] ITERATION NUM: 32
[2022-11-25 01:25:02,105] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.04110
[2022-11-25 01:25:02,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.03599, loss val: 0.04033
[2022-11-25 01:25:02,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.05522, loss val: 0.04262
[2022-11-25 01:25:02,190] [INFO] [controller] EPOCH 4 loss ppo:  -0.07041, loss val: 0.03957
[2022-11-25 01:25:02,194] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:25:02,258] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:25:02,259] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:25:09,020] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:25:14,087] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:25:19,180] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:25:24,313] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:25:29,425] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:25:34,438] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:25:39,651] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:25:44,857] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:25:50,020] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:25:55,143] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1658434121498753
[2022-11-25 01:25:55,144] [INFO] [runner_train_mujoco] Average state value: 0.5102557981510957
[2022-11-25 01:25:55,144] [INFO] [controller] ITERATION NUM: 33
[2022-11-25 01:25:55,176] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.03659
[2022-11-25 01:25:55,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.03891, loss val: 0.03812
[2022-11-25 01:25:55,227] [INFO] [controller] EPOCH 3 loss ppo:  -0.05904, loss val: 0.03612
[2022-11-25 01:25:55,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.07398, loss val: 0.03828
[2022-11-25 01:25:55,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:25:55,312] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:25:55,312] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:26:00,385] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:26:05,432] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:26:10,597] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:26:15,596] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:26:20,639] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:26:25,769] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:26:30,817] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:26:35,922] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:26:41,283] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:26:46,301] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.475230823711251
[2022-11-25 01:26:46,301] [INFO] [runner_train_mujoco] Average state value: 0.4983720147013665
[2022-11-25 01:26:46,301] [INFO] [controller] ITERATION NUM: 34
[2022-11-25 01:26:46,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.03334
[2022-11-25 01:26:46,377] [INFO] [controller] EPOCH 2 loss ppo:  -0.03592, loss val: 0.03389
[2022-11-25 01:26:46,409] [INFO] [controller] EPOCH 3 loss ppo:  -0.05289, loss val: 0.03347
[2022-11-25 01:26:46,439] [INFO] [controller] EPOCH 4 loss ppo:  -0.06702, loss val: 0.03279
[2022-11-25 01:26:46,445] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:26:46,518] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:26:46,519] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:26:51,897] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:26:57,176] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:27:02,318] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:27:07,348] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:27:12,338] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:27:17,273] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:27:22,267] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:27:27,612] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:27:32,813] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:27:37,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.81983784020125
[2022-11-25 01:27:37,841] [INFO] [runner_train_mujoco] Average state value: 0.5051892702976862
[2022-11-25 01:27:37,841] [INFO] [controller] ITERATION NUM: 35
[2022-11-25 01:27:37,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04243
[2022-11-25 01:27:37,914] [INFO] [controller] EPOCH 2 loss ppo:  -0.03602, loss val: 0.04418
[2022-11-25 01:27:37,946] [INFO] [controller] EPOCH 3 loss ppo:  -0.05119, loss val: 0.04287
[2022-11-25 01:27:37,975] [INFO] [controller] EPOCH 4 loss ppo:  -0.06983, loss val: 0.04380
[2022-11-25 01:27:37,980] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:27:38,019] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:27:38,020] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:27:43,071] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:27:48,059] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:27:53,259] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:27:58,312] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:28:03,337] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:28:08,372] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:28:13,429] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:28:18,442] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:28:23,535] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:28:28,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.855075109946763
[2022-11-25 01:28:28,670] [INFO] [runner_train_mujoco] Average state value: 0.5044316196242968
[2022-11-25 01:28:28,670] [INFO] [controller] ITERATION NUM: 36
[2022-11-25 01:28:28,705] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.03458
[2022-11-25 01:28:28,729] [INFO] [controller] EPOCH 2 loss ppo:  -0.03078, loss val: 0.03268
[2022-11-25 01:28:28,754] [INFO] [controller] EPOCH 3 loss ppo:  -0.04833, loss val: 0.03250
[2022-11-25 01:28:28,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.06410, loss val: 0.03337
[2022-11-25 01:28:28,792] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:28:28,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:28:28,838] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:28:34,062] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:28:39,039] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:28:44,297] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:28:49,301] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:28:54,449] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:28:59,386] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:29:04,329] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:29:09,327] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:29:14,317] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:29:19,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.425093091150498
[2022-11-25 01:29:19,264] [INFO] [runner_train_mujoco] Average state value: 0.4896639833350977
[2022-11-25 01:29:19,264] [INFO] [controller] ITERATION NUM: 37
[2022-11-25 01:29:19,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01510, loss val: 0.03926
[2022-11-25 01:29:19,320] [INFO] [controller] EPOCH 2 loss ppo:  -0.03152, loss val: 0.04123
[2022-11-25 01:29:19,351] [INFO] [controller] EPOCH 3 loss ppo:  -0.04455, loss val: 0.03899
[2022-11-25 01:29:19,385] [INFO] [controller] EPOCH 4 loss ppo:  -0.06211, loss val: 0.03870
[2022-11-25 01:29:19,391] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:29:19,441] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:29:19,442] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:29:24,734] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:29:30,208] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:29:36,453] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:29:41,625] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:29:46,801] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:29:51,957] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:29:57,913] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:30:03,263] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:30:08,274] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:30:13,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.174982083892388
[2022-11-25 01:30:13,309] [INFO] [runner_train_mujoco] Average state value: 0.44457711053639654
[2022-11-25 01:30:13,309] [INFO] [controller] ITERATION NUM: 38
[2022-11-25 01:30:13,348] [INFO] [controller] EPOCH 1 loss ppo:  -0.01584, loss val: 0.05845
[2022-11-25 01:30:13,375] [INFO] [controller] EPOCH 2 loss ppo:  -0.03097, loss val: 0.05920
[2022-11-25 01:30:13,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.04692, loss val: 0.05816
[2022-11-25 01:30:13,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.06476, loss val: 0.05854
[2022-11-25 01:30:13,441] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:30:13,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:30:13,494] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:30:18,745] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:30:23,789] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:30:28,912] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:30:33,900] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:30:38,805] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:30:43,801] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:30:48,823] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:30:53,844] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:30:58,976] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:31:04,210] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.445075246807564
[2022-11-25 01:31:04,210] [INFO] [runner_train_mujoco] Average state value: 0.44484348023931186
[2022-11-25 01:31:04,210] [INFO] [controller] ITERATION NUM: 39
[2022-11-25 01:31:04,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.05907
[2022-11-25 01:31:04,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.03010, loss val: 0.05937
[2022-11-25 01:31:04,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.04578, loss val: 0.05748
[2022-11-25 01:31:04,333] [INFO] [controller] EPOCH 4 loss ppo:  -0.05958, loss val: 0.05606
[2022-11-25 01:31:04,341] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:31:04,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:31:04,397] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:31:10,228] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:31:15,289] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:31:20,407] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:31:25,657] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:31:30,710] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:31:35,665] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:31:40,727] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:31:45,662] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:31:50,675] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:31:55,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.238578698317459
[2022-11-25 01:31:55,996] [INFO] [runner_train_mujoco] Average state value: 0.47866324662665527
[2022-11-25 01:31:55,996] [INFO] [controller] ITERATION NUM: 40
[2022-11-25 01:31:56,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.04514
[2022-11-25 01:31:56,055] [INFO] [controller] EPOCH 2 loss ppo:  -0.03410, loss val: 0.04300
[2022-11-25 01:31:56,079] [INFO] [controller] EPOCH 3 loss ppo:  -0.04920, loss val: 0.04332
[2022-11-25 01:31:56,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.06209, loss val: 0.03977
[2022-11-25 01:31:56,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:31:56,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:31:56,170] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:32:01,343] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:32:06,407] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:32:11,573] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:32:16,616] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:32:21,491] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:32:26,502] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:32:31,516] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:32:36,547] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:32:41,482] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:32:46,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.147267641841835
[2022-11-25 01:32:46,530] [INFO] [runner_train_mujoco] Average state value: 0.5172965699446699
[2022-11-25 01:32:46,530] [INFO] [controller] ITERATION NUM: 41
[2022-11-25 01:32:46,563] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04951
[2022-11-25 01:32:46,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.02879, loss val: 0.04817
[2022-11-25 01:32:46,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.04538, loss val: 0.04887
[2022-11-25 01:32:46,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.06120, loss val: 0.04672
[2022-11-25 01:32:46,641] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:32:46,682] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:32:46,682] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:32:51,841] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:32:57,064] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:33:02,151] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:33:07,133] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:33:12,131] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:33:17,061] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:33:22,055] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:33:27,174] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:33:32,267] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:33:37,293] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.670030781798647
[2022-11-25 01:33:37,294] [INFO] [runner_train_mujoco] Average state value: 0.5656734159986179
[2022-11-25 01:33:37,294] [INFO] [controller] ITERATION NUM: 42
[2022-11-25 01:33:37,328] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.07738
[2022-11-25 01:33:37,354] [INFO] [controller] EPOCH 2 loss ppo:  -0.02558, loss val: 0.08130
[2022-11-25 01:33:37,378] [INFO] [controller] EPOCH 3 loss ppo:  -0.03716, loss val: 0.07747
[2022-11-25 01:33:37,405] [INFO] [controller] EPOCH 4 loss ppo:  -0.04691, loss val: 0.07494
[2022-11-25 01:33:37,410] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:33:37,450] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:33:37,451] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:33:42,455] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:33:47,440] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:33:52,449] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:33:57,566] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:34:02,517] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:34:07,479] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:34:12,427] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:34:17,505] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:34:22,532] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:34:27,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.892519998500003
[2022-11-25 01:34:27,738] [INFO] [runner_train_mujoco] Average state value: 0.5574874014854431
[2022-11-25 01:34:27,738] [INFO] [controller] ITERATION NUM: 43
[2022-11-25 01:34:27,771] [INFO] [controller] EPOCH 1 loss ppo:  -0.01590, loss val: 0.04416
[2022-11-25 01:34:27,802] [INFO] [controller] EPOCH 2 loss ppo:  -0.03004, loss val: 0.04302
[2022-11-25 01:34:27,830] [INFO] [controller] EPOCH 3 loss ppo:  -0.04331, loss val: 0.04230
[2022-11-25 01:34:27,856] [INFO] [controller] EPOCH 4 loss ppo:  -0.06082, loss val: 0.04153
[2022-11-25 01:34:27,861] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:34:27,906] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:34:27,907] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:34:33,150] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:34:38,340] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:34:43,456] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:34:48,485] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:34:53,504] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:34:58,547] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:35:03,528] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:35:08,477] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:35:13,376] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:35:18,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.852086669870835
[2022-11-25 01:35:18,364] [INFO] [runner_train_mujoco] Average state value: 0.4946457519518832
[2022-11-25 01:35:18,364] [INFO] [controller] ITERATION NUM: 44
[2022-11-25 01:35:18,397] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.05509
[2022-11-25 01:35:18,423] [INFO] [controller] EPOCH 2 loss ppo:  -0.02763, loss val: 0.05784
[2022-11-25 01:35:18,457] [INFO] [controller] EPOCH 3 loss ppo:  -0.04526, loss val: 0.05815
[2022-11-25 01:35:18,490] [INFO] [controller] EPOCH 4 loss ppo:  -0.05614, loss val: 0.05333
[2022-11-25 01:35:18,498] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:35:18,559] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:35:18,559] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:35:23,781] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:35:28,910] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:35:34,699] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:35:39,620] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:35:44,684] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:35:49,717] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:35:55,008] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:35:59,980] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:36:04,982] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:36:10,006] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.770102229602331
[2022-11-25 01:36:10,006] [INFO] [runner_train_mujoco] Average state value: 0.5193407943248749
[2022-11-25 01:36:10,006] [INFO] [controller] ITERATION NUM: 45
[2022-11-25 01:36:10,042] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.03014
[2022-11-25 01:36:10,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.03020, loss val: 0.03035
[2022-11-25 01:36:10,100] [INFO] [controller] EPOCH 3 loss ppo:  -0.04634, loss val: 0.03016
[2022-11-25 01:36:10,131] [INFO] [controller] EPOCH 4 loss ppo:  -0.05895, loss val: 0.03012
[2022-11-25 01:36:10,136] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:36:10,190] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:36:10,190] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:36:15,449] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:36:20,455] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:36:25,597] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:36:30,586] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:36:35,458] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:36:40,480] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:36:45,508] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:36:50,411] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:36:55,448] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:37:00,470] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.061758155015349
[2022-11-25 01:37:00,470] [INFO] [runner_train_mujoco] Average state value: 0.531321206331253
[2022-11-25 01:37:00,470] [INFO] [controller] ITERATION NUM: 46
[2022-11-25 01:37:00,504] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.04386
[2022-11-25 01:37:00,532] [INFO] [controller] EPOCH 2 loss ppo:  -0.02904, loss val: 0.04312
[2022-11-25 01:37:00,561] [INFO] [controller] EPOCH 3 loss ppo:  -0.04320, loss val: 0.04193
[2022-11-25 01:37:00,586] [INFO] [controller] EPOCH 4 loss ppo:  -0.05486, loss val: 0.04127
[2022-11-25 01:37:00,592] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:37:00,663] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:37:00,663] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:37:05,771] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:37:10,792] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:37:15,996] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:37:21,038] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:37:26,142] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:37:31,214] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:37:36,290] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:37:41,310] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:37:46,289] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:37:51,319] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.085487668677343
[2022-11-25 01:37:51,319] [INFO] [runner_train_mujoco] Average state value: 0.5187770272294681
[2022-11-25 01:37:51,319] [INFO] [controller] ITERATION NUM: 47
[2022-11-25 01:37:51,361] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.05247
[2022-11-25 01:37:51,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.02765, loss val: 0.05324
[2022-11-25 01:37:51,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.04153, loss val: 0.05156
[2022-11-25 01:37:51,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.05228, loss val: 0.05153
[2022-11-25 01:37:51,448] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:37:51,509] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:37:51,510] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:37:56,742] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:38:01,864] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:38:06,994] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:38:12,057] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:38:17,078] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:38:22,165] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:38:27,188] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:38:32,254] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:38:37,303] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:38:42,317] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.412018046608411
[2022-11-25 01:38:42,317] [INFO] [runner_train_mujoco] Average state value: 0.5068238166173299
[2022-11-25 01:38:42,318] [INFO] [controller] ITERATION NUM: 48
[2022-11-25 01:38:42,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.04498
[2022-11-25 01:38:42,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.02487, loss val: 0.04253
[2022-11-25 01:38:42,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.03367, loss val: 0.04167
[2022-11-25 01:38:42,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.04293, loss val: 0.04092
[2022-11-25 01:38:42,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:38:42,530] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:38:42,530] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:38:48,199] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:38:53,380] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:38:58,749] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:39:03,801] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:39:08,928] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:39:13,991] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:39:19,097] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:39:24,113] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:39:29,182] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:39:34,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.695843468027917
[2022-11-25 01:39:34,258] [INFO] [runner_train_mujoco] Average state value: 0.47858845653136567
[2022-11-25 01:39:34,258] [INFO] [controller] ITERATION NUM: 49
[2022-11-25 01:39:34,294] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04138
[2022-11-25 01:39:34,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.02565, loss val: 0.04142
[2022-11-25 01:39:34,352] [INFO] [controller] EPOCH 3 loss ppo:  -0.03924, loss val: 0.03993
[2022-11-25 01:39:34,380] [INFO] [controller] EPOCH 4 loss ppo:  -0.04996, loss val: 0.04122
[2022-11-25 01:39:34,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:39:34,424] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:39:34,424] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:39:39,536] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:39:44,576] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:39:49,683] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:39:54,754] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:39:59,863] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:40:04,806] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:40:09,900] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:40:14,853] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:40:19,882] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:40:25,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.512618743150091
[2022-11-25 01:40:25,014] [INFO] [runner_train_mujoco] Average state value: 0.46084725801150006
[2022-11-25 01:40:25,014] [INFO] [controller] ITERATION NUM: 50
[2022-11-25 01:40:25,048] [INFO] [controller] EPOCH 1 loss ppo:  -0.01533, loss val: 0.05843
[2022-11-25 01:40:25,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.02859, loss val: 0.05804
[2022-11-25 01:40:25,113] [INFO] [controller] EPOCH 3 loss ppo:  -0.03707, loss val: 0.05588
[2022-11-25 01:40:25,144] [INFO] [controller] EPOCH 4 loss ppo:  -0.04321, loss val: 0.05849
[2022-11-25 01:40:25,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:40:25,197] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:40:25,197] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:40:30,353] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:40:35,530] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:40:40,574] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:40:45,958] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:40:51,287] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:40:56,454] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:41:01,508] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:41:06,668] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:41:11,836] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:41:18,311] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.133741254992673
[2022-11-25 01:41:18,311] [INFO] [runner_train_mujoco] Average state value: 0.4560778218110403
[2022-11-25 01:41:18,311] [INFO] [controller] ITERATION NUM: 51
[2022-11-25 01:41:18,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.04830
[2022-11-25 01:41:18,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.02311, loss val: 0.04824
[2022-11-25 01:41:18,398] [INFO] [controller] EPOCH 3 loss ppo:  -0.02967, loss val: 0.04801
[2022-11-25 01:41:18,427] [INFO] [controller] EPOCH 4 loss ppo:  -0.03806, loss val: 0.04794
[2022-11-25 01:41:18,433] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:41:18,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:41:18,481] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:41:23,779] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:41:29,137] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:41:34,453] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:41:39,762] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:41:46,098] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:41:52,172] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:41:57,564] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:42:02,569] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:42:07,614] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:42:12,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.855845184540231
[2022-11-25 01:42:12,633] [INFO] [runner_train_mujoco] Average state value: 0.4529599266250928
[2022-11-25 01:42:12,633] [INFO] [controller] ITERATION NUM: 52
[2022-11-25 01:42:12,681] [INFO] [controller] EPOCH 1 loss ppo:  -0.01494, loss val: 0.05326
[2022-11-25 01:42:12,718] [INFO] [controller] EPOCH 2 loss ppo:  -0.02282, loss val: 0.05564
[2022-11-25 01:42:12,751] [INFO] [controller] EPOCH 3 loss ppo:  -0.03022, loss val: 0.05584
[2022-11-25 01:42:12,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.04039, loss val: 0.05568
[2022-11-25 01:42:12,792] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:42:12,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:42:12,839] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:42:18,158] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:42:25,134] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:42:30,335] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:42:35,302] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:42:40,300] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:42:45,301] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:42:50,313] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:42:55,232] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:43:00,392] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:43:05,497] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.966423069563365
[2022-11-25 01:43:05,497] [INFO] [runner_train_mujoco] Average state value: 0.4503954852918784
[2022-11-25 01:43:05,497] [INFO] [controller] ITERATION NUM: 53
[2022-11-25 01:43:05,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.05219
[2022-11-25 01:43:05,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.02045, loss val: 0.05178
[2022-11-25 01:43:05,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.05171
[2022-11-25 01:43:05,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.03827, loss val: 0.05255
[2022-11-25 01:43:05,615] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:43:05,677] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:43:05,678] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:43:11,033] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:43:16,181] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:43:21,395] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:43:26,584] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:43:31,675] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:43:36,775] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:43:41,829] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:43:46,920] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:43:52,017] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:43:57,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.22913527081599
[2022-11-25 01:43:57,170] [INFO] [runner_train_mujoco] Average state value: 0.45758883082866675
[2022-11-25 01:43:57,170] [INFO] [controller] ITERATION NUM: 54
[2022-11-25 01:43:57,214] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.04534
[2022-11-25 01:43:57,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.02131, loss val: 0.04412
[2022-11-25 01:43:57,286] [INFO] [controller] EPOCH 3 loss ppo:  -0.02659, loss val: 0.04520
[2022-11-25 01:43:57,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.03437, loss val: 0.04510
[2022-11-25 01:43:57,336] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:43:57,408] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:43:57,409] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:44:02,765] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:44:07,844] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:44:13,060] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:44:18,197] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:44:23,328] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:44:28,436] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:44:33,494] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:44:38,567] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:44:43,694] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:44:48,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.327621336001535
[2022-11-25 01:44:48,721] [INFO] [runner_train_mujoco] Average state value: 0.45748008473714197
[2022-11-25 01:44:48,721] [INFO] [controller] ITERATION NUM: 55
[2022-11-25 01:44:48,761] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.03709
[2022-11-25 01:44:48,788] [INFO] [controller] EPOCH 2 loss ppo:  -0.01715, loss val: 0.03596
[2022-11-25 01:44:48,823] [INFO] [controller] EPOCH 3 loss ppo:  -0.02459, loss val: 0.03791
[2022-11-25 01:44:48,849] [INFO] [controller] EPOCH 4 loss ppo:  -0.03212, loss val: 0.03899
[2022-11-25 01:44:48,853] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:44:48,919] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:44:48,919] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:44:54,084] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:44:59,477] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:45:04,824] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:45:09,802] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:45:14,915] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:45:20,037] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:45:25,119] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:45:30,235] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:45:35,286] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:45:40,399] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.3531273616418025
[2022-11-25 01:45:40,399] [INFO] [runner_train_mujoco] Average state value: 0.4527336385448774
[2022-11-25 01:45:40,399] [INFO] [controller] ITERATION NUM: 56
[2022-11-25 01:45:40,433] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.05213
[2022-11-25 01:45:40,457] [INFO] [controller] EPOCH 2 loss ppo:  -0.01780, loss val: 0.05126
[2022-11-25 01:45:40,484] [INFO] [controller] EPOCH 3 loss ppo:  -0.02373, loss val: 0.05184
[2022-11-25 01:45:40,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.02831, loss val: 0.05184
[2022-11-25 01:45:40,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:45:40,562] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:45:40,562] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:45:45,665] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:45:50,992] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:45:56,135] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:46:01,300] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:46:06,346] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:46:11,553] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:46:16,708] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:46:21,795] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:46:27,093] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:46:32,122] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.32699223407632
[2022-11-25 01:46:32,122] [INFO] [runner_train_mujoco] Average state value: 0.45272792617479957
[2022-11-25 01:46:32,123] [INFO] [controller] ITERATION NUM: 57
[2022-11-25 01:46:32,155] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04339
[2022-11-25 01:46:32,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.01576, loss val: 0.04363
[2022-11-25 01:46:32,205] [INFO] [controller] EPOCH 3 loss ppo:  -0.01925, loss val: 0.04335
[2022-11-25 01:46:32,230] [INFO] [controller] EPOCH 4 loss ppo:  -0.02392, loss val: 0.04401
[2022-11-25 01:46:32,236] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:46:32,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-11-25 01:46:32,289] [INFO] [runner_train_mujoco] Environment 0
[2022-11-25 01:46:37,860] [INFO] [runner_train_mujoco] Environment 1
[2022-11-25 01:46:43,201] [INFO] [runner_train_mujoco] Environment 2
[2022-11-25 01:46:48,573] [INFO] [runner_train_mujoco] Environment 3
[2022-11-25 01:46:53,822] [INFO] [runner_train_mujoco] Environment 4
[2022-11-25 01:46:58,967] [INFO] [runner_train_mujoco] Environment 5
[2022-11-25 01:47:04,275] [INFO] [runner_train_mujoco] Environment 6
[2022-11-25 01:47:09,348] [INFO] [runner_train_mujoco] Environment 7
[2022-11-25 01:47:14,458] [INFO] [runner_train_mujoco] Environment 8
[2022-11-25 01:47:19,474] [INFO] [runner_train_mujoco] Environment 9
[2022-11-25 01:47:24,683] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.1257281151597285
[2022-11-25 01:47:24,684] [INFO] [runner_train_mujoco] Average state value: 0.4541439432501793
[2022-11-25 01:47:24,684] [INFO] [controller] ITERATION NUM: 58
[2022-11-25 01:47:24,716] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.04350
[2022-11-25 01:47:24,743] [INFO] [controller] EPOCH 2 loss ppo:  -0.01543, loss val: 0.04453
[2022-11-25 01:47:24,778] [INFO] [controller] EPOCH 3 loss ppo:  -0.01775, loss val: 0.04301
[2022-11-25 01:47:24,806] [INFO] [controller] EPOCH 4 loss ppo:  -0.02094, loss val: 0.04301
[2022-11-25 01:47:24,812] [INFO] [runner_train_mujoco] Finished batch.
[2022-11-25 01:47:24,816] [INFO] [optimize] Finished learning.
