[2022-12-06 23:03:31,398] [INFO] [optimize] Starting learning
[2022-12-06 23:03:31,442] [INFO] [optimize] Starting learning process..
[2022-12-06 23:03:31,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:03:31,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:03:49,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:04:04,025] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:04:20,642] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:04:34,500] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:04:48,420] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:05:02,690] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:05:16,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:05:30,819] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:05:45,620] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:05:59,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6234305550559054
[2022-12-06 23:05:59,099] [INFO] [runner_train_mujoco] Average state value: -0.06453203183040024
[2022-12-06 23:05:59,099] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 23:05:59,215] [INFO] [controller] EPOCH 1 loss ppo:  -0.00573, loss val: 0.47045
[2022-12-06 23:05:59,287] [INFO] [controller] EPOCH 2 loss ppo:  -0.04856, loss val: 0.41782
[2022-12-06 23:05:59,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.06540, loss val: 0.37049
[2022-12-06 23:05:59,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.07755, loss val: 0.32476
[2022-12-06 23:05:59,495] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:05:59,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:05:59,814] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:06:14,144] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:06:27,950] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:06:43,561] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:06:57,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:07:13,061] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:07:28,432] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:07:42,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:07:56,010] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:08:09,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:08:25,073] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5801953953293133
[2022-12-06 23:08:25,073] [INFO] [runner_train_mujoco] Average state value: 0.09789965530857445
[2022-12-06 23:08:25,074] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 23:08:25,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.36901
[2022-12-06 23:08:25,275] [INFO] [controller] EPOCH 2 loss ppo:  -0.05146, loss val: 0.32083
[2022-12-06 23:08:25,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.06978, loss val: 0.28690
[2022-12-06 23:08:25,636] [INFO] [controller] EPOCH 4 loss ppo:  -0.07942, loss val: 0.25279
[2022-12-06 23:08:25,657] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:08:25,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:08:25,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:08:41,608] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:08:58,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:09:12,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:09:27,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:09:41,266] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:09:55,533] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:10:09,088] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:10:22,825] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:10:36,352] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:10:50,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5479253882099948
[2022-12-06 23:10:50,267] [INFO] [runner_train_mujoco] Average state value: 0.2541075962577015
[2022-12-06 23:10:50,267] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 23:10:50,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.22981
[2022-12-06 23:10:50,459] [INFO] [controller] EPOCH 2 loss ppo:  -0.04855, loss val: 0.20364
[2022-12-06 23:10:50,532] [INFO] [controller] EPOCH 3 loss ppo:  -0.06346, loss val: 0.18105
[2022-12-06 23:10:50,612] [INFO] [controller] EPOCH 4 loss ppo:  -0.07597, loss val: 0.16021
[2022-12-06 23:10:50,633] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:10:50,966] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:10:50,967] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:11:05,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:11:20,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:11:33,785] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:11:48,106] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:12:02,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:12:16,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:12:30,524] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:12:45,085] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:12:59,372] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:13:12,629] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5869942797515205
[2022-12-06 23:13:12,630] [INFO] [runner_train_mujoco] Average state value: 0.4144997501249114
[2022-12-06 23:13:12,630] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 23:13:12,728] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.13145
[2022-12-06 23:13:12,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.05670, loss val: 0.11981
[2022-12-06 23:13:12,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.07606, loss val: 0.11198
[2022-12-06 23:13:13,007] [INFO] [controller] EPOCH 4 loss ppo:  -0.08434, loss val: 0.10314
[2022-12-06 23:13:13,020] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:13:13,340] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:13:13,341] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:13:27,584] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:13:41,593] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:13:55,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:14:09,090] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:14:23,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:14:38,012] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:14:51,863] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:15:05,302] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:15:18,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:15:32,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5901355158503927
[2022-12-06 23:15:32,633] [INFO] [runner_train_mujoco] Average state value: 0.4910225341251742
[2022-12-06 23:15:32,633] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 23:15:32,729] [INFO] [controller] EPOCH 1 loss ppo:  -0.01051, loss val: 0.10099
[2022-12-06 23:15:32,818] [INFO] [controller] EPOCH 2 loss ppo:  -0.04512, loss val: 0.09369
[2022-12-06 23:15:32,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.06227, loss val: 0.08805
[2022-12-06 23:15:33,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.07390, loss val: 0.08334
[2022-12-06 23:15:33,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:15:33,396] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:15:33,396] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:15:48,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:16:03,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:16:17,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:16:32,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:16:46,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:17:00,291] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:17:13,972] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:17:27,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:17:41,974] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:17:58,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5601972262648408
[2022-12-06 23:17:58,834] [INFO] [runner_train_mujoco] Average state value: 0.5316934040685494
[2022-12-06 23:17:58,834] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 23:17:58,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.09013
[2022-12-06 23:17:59,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.04262, loss val: 0.08327
[2022-12-06 23:17:59,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.06131, loss val: 0.07752
[2022-12-06 23:17:59,507] [INFO] [controller] EPOCH 4 loss ppo:  -0.07440, loss val: 0.07112
[2022-12-06 23:17:59,521] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:17:59,874] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:17:59,874] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:18:13,246] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:18:25,148] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:18:37,752] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:18:49,370] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:19:01,401] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:19:13,692] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:19:30,459] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:19:44,082] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:19:57,314] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:20:10,547] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5915653647600989
[2022-12-06 23:20:10,548] [INFO] [runner_train_mujoco] Average state value: 0.5877373885400593
[2022-12-06 23:20:10,548] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 23:20:10,672] [INFO] [controller] EPOCH 1 loss ppo:  -0.01169, loss val: 0.07350
[2022-12-06 23:20:10,752] [INFO] [controller] EPOCH 2 loss ppo:  -0.03733, loss val: 0.07007
[2022-12-06 23:20:10,830] [INFO] [controller] EPOCH 3 loss ppo:  -0.05757, loss val: 0.06951
[2022-12-06 23:20:10,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.07214, loss val: 0.06501
[2022-12-06 23:20:10,914] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:20:11,241] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:20:11,242] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:20:25,875] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:20:39,667] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:20:53,579] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:21:07,756] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:21:20,623] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:21:33,523] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:21:46,519] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:21:59,006] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:22:12,283] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:22:25,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5539746512073483
[2022-12-06 23:22:25,113] [INFO] [runner_train_mujoco] Average state value: 0.587417699975272
[2022-12-06 23:22:25,119] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 23:22:25,207] [INFO] [controller] EPOCH 1 loss ppo:  -0.01168, loss val: 0.07002
[2022-12-06 23:22:25,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.03685, loss val: 0.06709
[2022-12-06 23:22:25,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.05627, loss val: 0.06292
[2022-12-06 23:22:25,536] [INFO] [controller] EPOCH 4 loss ppo:  -0.06852, loss val: 0.06090
[2022-12-06 23:22:25,550] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:22:25,856] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:22:25,856] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:22:38,418] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:22:49,860] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:23:01,405] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:23:13,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:23:25,201] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:23:36,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:23:49,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:24:01,035] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:24:12,528] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:24:24,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7159985620319176
[2022-12-06 23:24:24,329] [INFO] [runner_train_mujoco] Average state value: 0.49399201195438697
[2022-12-06 23:24:24,329] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 23:24:24,413] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.06566
[2022-12-06 23:24:24,467] [INFO] [controller] EPOCH 2 loss ppo:  -0.04058, loss val: 0.06477
[2022-12-06 23:24:24,532] [INFO] [controller] EPOCH 3 loss ppo:  -0.05860, loss val: 0.06281
[2022-12-06 23:24:24,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.07332, loss val: 0.05648
[2022-12-06 23:24:24,603] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:24:24,880] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:24:24,881] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:24:37,037] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:24:48,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:25:00,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:25:12,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:25:24,643] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:25:36,003] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:25:47,824] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:25:59,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:26:11,729] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:26:23,244] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8218196209016119
[2022-12-06 23:26:23,244] [INFO] [runner_train_mujoco] Average state value: 0.5204928882022699
[2022-12-06 23:26:23,245] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 23:26:23,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01088, loss val: 0.06054
[2022-12-06 23:26:23,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.04292, loss val: 0.05717
[2022-12-06 23:26:23,480] [INFO] [controller] EPOCH 3 loss ppo:  -0.05792, loss val: 0.05785
[2022-12-06 23:26:23,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.06989, loss val: 0.05527
[2022-12-06 23:26:23,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:26:23,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:26:23,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:26:35,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:26:47,759] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:26:59,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:27:11,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:27:22,970] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:27:34,723] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:27:46,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:27:58,069] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:28:08,177] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:28:17,583] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8043048237894845
[2022-12-06 23:28:17,583] [INFO] [runner_train_mujoco] Average state value: 0.4730957767292857
[2022-12-06 23:28:17,583] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 23:28:17,648] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.06969
[2022-12-06 23:28:17,700] [INFO] [controller] EPOCH 2 loss ppo:  -0.04981, loss val: 0.06967
[2022-12-06 23:28:17,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.06716, loss val: 0.06858
[2022-12-06 23:28:17,821] [INFO] [controller] EPOCH 4 loss ppo:  -0.07908, loss val: 0.06635
[2022-12-06 23:28:17,833] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:28:18,097] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:28:18,098] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:28:28,082] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:28:37,958] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:28:47,250] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:28:56,340] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:29:05,638] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:29:15,154] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:29:24,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:29:34,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:29:43,750] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:29:53,059] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7365321513912961
[2022-12-06 23:29:53,059] [INFO] [runner_train_mujoco] Average state value: 0.47266078651199733
[2022-12-06 23:29:53,059] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 23:29:53,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.01083, loss val: 0.04676
[2022-12-06 23:29:53,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.03930, loss val: 0.04725
[2022-12-06 23:29:53,236] [INFO] [controller] EPOCH 3 loss ppo:  -0.05832, loss val: 0.04584
[2022-12-06 23:29:53,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.07203, loss val: 0.04406
[2022-12-06 23:29:53,303] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:29:53,539] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:29:53,540] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:30:03,215] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:30:12,411] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:30:21,820] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:30:30,854] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:30:39,971] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:30:50,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:31:00,001] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:31:09,208] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:31:18,620] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:31:27,486] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6619974691017216
[2022-12-06 23:31:27,486] [INFO] [runner_train_mujoco] Average state value: 0.4691144899750749
[2022-12-06 23:31:27,486] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 23:31:27,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01037, loss val: 0.07569
[2022-12-06 23:31:27,602] [INFO] [controller] EPOCH 2 loss ppo:  -0.03589, loss val: 0.06863
[2022-12-06 23:31:27,655] [INFO] [controller] EPOCH 3 loss ppo:  -0.05301, loss val: 0.06619
[2022-12-06 23:31:27,709] [INFO] [controller] EPOCH 4 loss ppo:  -0.06521, loss val: 0.06339
[2022-12-06 23:31:27,720] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:31:27,959] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:31:27,960] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:31:37,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:31:47,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:31:56,794] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:32:05,985] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:32:15,320] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:32:26,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:33:24,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:33:34,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:33:44,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:33:53,535] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8590806774370389
[2022-12-06 23:33:53,535] [INFO] [runner_train_mujoco] Average state value: 0.5666605318685372
[2022-12-06 23:33:53,535] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 23:33:53,601] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04206
[2022-12-06 23:33:53,662] [INFO] [controller] EPOCH 2 loss ppo:  -0.04440, loss val: 0.04279
[2022-12-06 23:33:53,715] [INFO] [controller] EPOCH 3 loss ppo:  -0.06035, loss val: 0.04169
[2022-12-06 23:33:53,769] [INFO] [controller] EPOCH 4 loss ppo:  -0.07155, loss val: 0.04126
[2022-12-06 23:33:53,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:33:54,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:33:54,018] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:34:03,540] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:34:13,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:34:22,861] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:34:31,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:34:42,746] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:34:54,055] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:35:04,919] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:35:14,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:35:24,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:35:35,236] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8529257753827164
[2022-12-06 23:35:35,236] [INFO] [runner_train_mujoco] Average state value: 0.5748887395163377
[2022-12-06 23:35:35,236] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 23:35:35,314] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.04637
[2022-12-06 23:35:35,392] [INFO] [controller] EPOCH 2 loss ppo:  -0.04043, loss val: 0.04405
[2022-12-06 23:35:35,447] [INFO] [controller] EPOCH 3 loss ppo:  -0.05813, loss val: 0.03975
[2022-12-06 23:35:35,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.07333, loss val: 0.04145
[2022-12-06 23:35:35,516] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:35:35,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:35:35,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:35:45,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:35:55,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:36:05,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:36:14,969] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:36:24,948] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:36:34,915] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:36:45,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:36:57,228] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:37:07,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:37:16,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6255553588759714
[2022-12-06 23:37:16,284] [INFO] [runner_train_mujoco] Average state value: 0.527986698269844
[2022-12-06 23:37:16,284] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 23:37:16,350] [INFO] [controller] EPOCH 1 loss ppo:  -0.01156, loss val: 0.03999
[2022-12-06 23:37:16,404] [INFO] [controller] EPOCH 2 loss ppo:  -0.04411, loss val: 0.04188
[2022-12-06 23:37:16,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.06423, loss val: 0.03824
[2022-12-06 23:37:16,502] [INFO] [controller] EPOCH 4 loss ppo:  -0.08032, loss val: 0.03965
[2022-12-06 23:37:16,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:37:16,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:37:16,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:37:25,822] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:37:34,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:37:43,399] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:37:52,279] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:38:05,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:38:18,464] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:38:30,681] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:38:43,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:38:55,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:39:06,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.824678919672096
[2022-12-06 23:39:06,773] [INFO] [runner_train_mujoco] Average state value: 0.47085462137063344
[2022-12-06 23:39:06,774] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 23:39:06,883] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.03783
[2022-12-06 23:39:06,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.04812, loss val: 0.03643
[2022-12-06 23:39:07,024] [INFO] [controller] EPOCH 3 loss ppo:  -0.06579, loss val: 0.03553
[2022-12-06 23:39:07,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.07733, loss val: 0.03485
[2022-12-06 23:39:07,120] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:39:07,403] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:39:07,403] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:39:19,602] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:39:31,773] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:39:44,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:39:56,253] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:40:08,132] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:40:20,451] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:40:32,778] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:40:45,101] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:40:57,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:41:09,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9314206302978434
[2022-12-06 23:41:09,931] [INFO] [runner_train_mujoco] Average state value: 0.43830816419919333
[2022-12-06 23:41:09,932] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 23:41:10,042] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.04968
[2022-12-06 23:41:10,120] [INFO] [controller] EPOCH 2 loss ppo:  -0.04573, loss val: 0.04958
[2022-12-06 23:41:10,215] [INFO] [controller] EPOCH 3 loss ppo:  -0.06357, loss val: 0.04993
[2022-12-06 23:41:10,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.07473, loss val: 0.04789
[2022-12-06 23:41:10,313] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:41:10,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:41:10,622] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:41:23,264] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:41:35,216] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:41:46,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:41:58,727] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:42:10,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:42:22,669] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:42:34,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:42:46,193] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:42:58,638] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:43:11,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.130445400817017
[2022-12-06 23:43:11,029] [INFO] [runner_train_mujoco] Average state value: 0.43864315718909114
[2022-12-06 23:43:11,029] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 23:43:11,128] [INFO] [controller] EPOCH 1 loss ppo:  -0.01101, loss val: 0.04213
[2022-12-06 23:43:11,212] [INFO] [controller] EPOCH 2 loss ppo:  -0.04519, loss val: 0.04170
[2022-12-06 23:43:11,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.06553, loss val: 0.04218
[2022-12-06 23:43:11,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.07909, loss val: 0.04051
[2022-12-06 23:43:11,542] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:43:11,827] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:43:11,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:43:25,517] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:43:37,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:43:49,359] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:44:01,220] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:44:12,896] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:44:25,152] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:44:37,039] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:44:49,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:45:01,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:45:13,752] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1311170315189933
[2022-12-06 23:45:13,752] [INFO] [runner_train_mujoco] Average state value: 0.4631854239205519
[2022-12-06 23:45:13,752] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 23:45:13,839] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.03513
[2022-12-06 23:45:13,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.04758, loss val: 0.03470
[2022-12-06 23:45:13,989] [INFO] [controller] EPOCH 3 loss ppo:  -0.06752, loss val: 0.03268
[2022-12-06 23:45:14,081] [INFO] [controller] EPOCH 4 loss ppo:  -0.08055, loss val: 0.03364
[2022-12-06 23:45:14,094] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:45:14,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:45:14,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:45:26,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:45:39,988] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:45:51,342] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:46:04,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:46:16,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:46:27,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:46:39,984] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:46:51,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:47:03,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:47:16,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2414955852342762
[2022-12-06 23:47:16,440] [INFO] [runner_train_mujoco] Average state value: 0.48973461052775374
[2022-12-06 23:47:16,441] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 23:47:16,531] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.03566
[2022-12-06 23:47:16,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.04635, loss val: 0.03551
[2022-12-06 23:47:16,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.06586, loss val: 0.03636
[2022-12-06 23:47:16,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.07610, loss val: 0.03989
[2022-12-06 23:47:16,787] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:47:17,067] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:47:17,067] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:47:29,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:47:42,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:47:54,683] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:48:04,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:48:13,700] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:48:23,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:48:35,249] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:48:46,363] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:48:55,980] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:49:05,434] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0145115203220008
[2022-12-06 23:49:05,434] [INFO] [runner_train_mujoco] Average state value: 0.4798516762405634
[2022-12-06 23:49:05,434] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 23:49:05,499] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04502
[2022-12-06 23:49:05,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.03992, loss val: 0.04151
[2022-12-06 23:49:05,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.05565, loss val: 0.04235
[2022-12-06 23:49:05,678] [INFO] [controller] EPOCH 4 loss ppo:  -0.07055, loss val: 0.04221
[2022-12-06 23:49:05,690] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:49:05,935] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:49:05,935] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:49:15,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:49:25,161] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:49:35,052] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:49:44,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:49:53,746] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:50:03,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:50:16,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:50:28,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:50:38,423] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:50:48,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4183571931009982
[2022-12-06 23:50:48,919] [INFO] [runner_train_mujoco] Average state value: 0.5141134535471598
[2022-12-06 23:50:48,920] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 23:50:48,999] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.04134
[2022-12-06 23:50:49,056] [INFO] [controller] EPOCH 2 loss ppo:  -0.04680, loss val: 0.04015
[2022-12-06 23:50:49,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.06649, loss val: 0.03993
[2022-12-06 23:50:49,192] [INFO] [controller] EPOCH 4 loss ppo:  -0.07978, loss val: 0.04160
[2022-12-06 23:50:49,207] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:50:49,475] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:50:49,475] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:51:00,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:51:09,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:51:18,917] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:51:28,434] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:51:38,628] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:51:48,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:51:57,663] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:52:07,958] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:52:17,350] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:52:27,221] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5820888190151228
[2022-12-06 23:52:27,221] [INFO] [runner_train_mujoco] Average state value: 0.491684867615501
[2022-12-06 23:52:27,221] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 23:52:27,285] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.04264
[2022-12-06 23:52:27,342] [INFO] [controller] EPOCH 2 loss ppo:  -0.04239, loss val: 0.03995
[2022-12-06 23:52:27,403] [INFO] [controller] EPOCH 3 loss ppo:  -0.06094, loss val: 0.03896
[2022-12-06 23:52:27,466] [INFO] [controller] EPOCH 4 loss ppo:  -0.07633, loss val: 0.03976
[2022-12-06 23:52:27,485] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:52:27,786] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:52:27,787] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:52:37,789] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:52:48,337] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:52:58,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:53:08,022] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:53:18,476] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:53:31,071] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:53:43,231] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:53:54,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:54:06,668] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:54:19,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8261884332584262
[2022-12-06 23:54:19,161] [INFO] [runner_train_mujoco] Average state value: 0.45887974512577057
[2022-12-06 23:54:19,162] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 23:54:19,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.04214
[2022-12-06 23:54:19,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.04172, loss val: 0.04236
[2022-12-06 23:54:19,428] [INFO] [controller] EPOCH 3 loss ppo:  -0.06296, loss val: 0.04236
[2022-12-06 23:54:19,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.08157, loss val: 0.04249
[2022-12-06 23:54:19,530] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:54:19,824] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:54:19,825] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:54:32,767] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:54:44,501] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:54:55,699] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:55:07,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:55:18,726] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:55:30,408] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:55:43,672] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:55:55,433] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:56:07,325] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:56:19,161] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9417401364500289
[2022-12-06 23:56:19,162] [INFO] [runner_train_mujoco] Average state value: 0.4392202856739361
[2022-12-06 23:56:19,162] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 23:56:19,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.04546
[2022-12-06 23:56:19,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.04215, loss val: 0.04932
[2022-12-06 23:56:19,464] [INFO] [controller] EPOCH 3 loss ppo:  -0.05866, loss val: 0.04443
[2022-12-06 23:56:19,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.07245, loss val: 0.04714
[2022-12-06 23:56:19,562] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:56:19,857] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:56:19,858] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:56:32,123] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:56:44,766] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:56:58,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:57:12,909] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:57:25,088] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:57:37,106] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:57:48,340] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:58:00,168] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:58:12,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:58:25,078] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.96387017058855
[2022-12-06 23:58:25,078] [INFO] [runner_train_mujoco] Average state value: 0.46234860159953434
[2022-12-06 23:58:25,078] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 23:58:25,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.01564, loss val: 0.02894
[2022-12-06 23:58:25,278] [INFO] [controller] EPOCH 2 loss ppo:  -0.04410, loss val: 0.02711
[2022-12-06 23:58:25,362] [INFO] [controller] EPOCH 3 loss ppo:  -0.06275, loss val: 0.02639
[2022-12-06 23:58:25,461] [INFO] [controller] EPOCH 4 loss ppo:  -0.08047, loss val: 0.02738
[2022-12-06 23:58:25,478] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:58:25,815] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:58:25,815] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:58:41,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:58:53,094] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:59:05,736] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:59:19,337] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:59:31,066] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:59:43,689] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:59:55,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:00:05,482] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:00:15,137] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:00:25,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.021462760841403
[2022-12-07 00:00:25,105] [INFO] [runner_train_mujoco] Average state value: 0.5080191672643025
[2022-12-07 00:00:25,105] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 00:00:25,187] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.03932
[2022-12-07 00:00:25,320] [INFO] [controller] EPOCH 2 loss ppo:  -0.03537, loss val: 0.03959
[2022-12-07 00:00:25,397] [INFO] [controller] EPOCH 3 loss ppo:  -0.05193, loss val: 0.04023
[2022-12-07 00:00:25,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.07061, loss val: 0.03811
[2022-12-07 00:00:25,542] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:00:25,848] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:00:25,849] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:00:38,138] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:00:47,950] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:00:58,098] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:01:09,063] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:01:18,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:01:27,139] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:01:35,812] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:01:45,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:01:54,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:02:01,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.714107303502751
[2022-12-07 00:02:01,626] [INFO] [runner_train_mujoco] Average state value: 0.43296274661024414
[2022-12-07 00:02:01,626] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 00:02:01,679] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.07480
[2022-12-07 00:02:01,717] [INFO] [controller] EPOCH 2 loss ppo:  -0.03943, loss val: 0.07555
[2022-12-07 00:02:01,754] [INFO] [controller] EPOCH 3 loss ppo:  -0.05556, loss val: 0.07574
[2022-12-07 00:02:01,793] [INFO] [controller] EPOCH 4 loss ppo:  -0.07241, loss val: 0.07326
[2022-12-07 00:02:01,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:02:01,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:02:01,973] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:02:08,658] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:02:16,033] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:02:23,258] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:02:29,843] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:02:36,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:02:44,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:02:51,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:02:57,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:03:04,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:03:10,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.075706037031002
[2022-12-07 00:03:10,979] [INFO] [runner_train_mujoco] Average state value: 0.4758932196994623
[2022-12-07 00:03:10,979] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 00:03:11,026] [INFO] [controller] EPOCH 1 loss ppo:  -0.01531, loss val: 0.04619
[2022-12-07 00:03:11,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.03381, loss val: 0.04341
[2022-12-07 00:03:11,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.05160, loss val: 0.04593
[2022-12-07 00:03:11,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.06979, loss val: 0.04417
[2022-12-07 00:03:11,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:03:11,420] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:03:11,421] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:03:18,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:03:25,139] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:03:32,046] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:03:39,230] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:03:46,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:03:53,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:03:59,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:04:06,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:04:13,217] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:04:20,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2047588120492483
[2022-12-07 00:04:20,054] [INFO] [runner_train_mujoco] Average state value: 0.42986484043796863
[2022-12-07 00:04:20,054] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 00:04:20,101] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.06859
[2022-12-07 00:04:20,141] [INFO] [controller] EPOCH 2 loss ppo:  -0.03508, loss val: 0.06328
[2022-12-07 00:04:20,182] [INFO] [controller] EPOCH 3 loss ppo:  -0.05282, loss val: 0.06179
[2022-12-07 00:04:20,223] [INFO] [controller] EPOCH 4 loss ppo:  -0.06711, loss val: 0.06145
[2022-12-07 00:04:20,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:04:20,414] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:04:20,415] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:04:27,261] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:04:34,441] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:04:41,509] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:04:49,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:04:55,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:05:03,058] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:05:09,881] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:05:16,624] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:05:23,400] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:05:30,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5516794538697
[2022-12-07 00:05:30,015] [INFO] [runner_train_mujoco] Average state value: 0.48879799487938486
[2022-12-07 00:05:30,015] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 00:05:30,060] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.04171
[2022-12-07 00:05:30,107] [INFO] [controller] EPOCH 2 loss ppo:  -0.04129, loss val: 0.04051
[2022-12-07 00:05:30,161] [INFO] [controller] EPOCH 3 loss ppo:  -0.06150, loss val: 0.04010
[2022-12-07 00:05:30,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.07435, loss val: 0.03904
[2022-12-07 00:05:30,213] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:05:30,404] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:05:30,405] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:05:37,520] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:05:44,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:05:51,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:05:58,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:06:04,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:06:11,766] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:06:17,830] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:06:24,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:06:30,183] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:06:36,101] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.264825556364508
[2022-12-07 00:06:36,101] [INFO] [runner_train_mujoco] Average state value: 0.4815802505537867
[2022-12-07 00:06:36,102] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 00:06:36,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.05664
[2022-12-07 00:06:36,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.04015, loss val: 0.05791
[2022-12-07 00:06:36,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.05922, loss val: 0.05652
[2022-12-07 00:06:36,257] [INFO] [controller] EPOCH 4 loss ppo:  -0.07183, loss val: 0.05620
[2022-12-07 00:06:36,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:06:36,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:06:36,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:06:43,057] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:06:49,718] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:06:56,054] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:07:02,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:07:10,175] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:07:17,090] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:07:23,567] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:07:29,750] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:07:35,853] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:07:41,840] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5703652877681753
[2022-12-07 00:07:41,840] [INFO] [runner_train_mujoco] Average state value: 0.5121348453586301
[2022-12-07 00:07:41,840] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 00:07:41,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01603, loss val: 0.05471
[2022-12-07 00:07:41,935] [INFO] [controller] EPOCH 2 loss ppo:  -0.03774, loss val: 0.05234
[2022-12-07 00:07:41,977] [INFO] [controller] EPOCH 3 loss ppo:  -0.05326, loss val: 0.05194
[2022-12-07 00:07:42,014] [INFO] [controller] EPOCH 4 loss ppo:  -0.06391, loss val: 0.04978
[2022-12-07 00:07:42,022] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:07:42,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:07:42,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:07:48,284] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:07:54,669] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:08:00,875] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:08:07,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:08:13,326] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:08:19,658] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:08:26,035] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:08:32,205] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:08:38,897] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:08:45,000] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.503675618772752
[2022-12-07 00:08:45,000] [INFO] [runner_train_mujoco] Average state value: 0.49642616083845503
[2022-12-07 00:08:45,000] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 00:08:45,052] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.07301
[2022-12-07 00:08:45,085] [INFO] [controller] EPOCH 2 loss ppo:  -0.03232, loss val: 0.07286
[2022-12-07 00:08:45,122] [INFO] [controller] EPOCH 3 loss ppo:  -0.04950, loss val: 0.07168
[2022-12-07 00:08:45,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.06323, loss val: 0.07142
[2022-12-07 00:08:45,170] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:08:45,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:08:45,355] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:08:51,711] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:08:58,326] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:09:04,650] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:09:10,841] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:09:17,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:09:23,227] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:09:29,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:09:36,215] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:09:42,515] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:09:48,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1421403557624727
[2022-12-07 00:09:48,904] [INFO] [runner_train_mujoco] Average state value: 0.5458985003332296
[2022-12-07 00:09:48,904] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 00:09:48,954] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.05929
[2022-12-07 00:09:48,996] [INFO] [controller] EPOCH 2 loss ppo:  -0.03824, loss val: 0.05854
[2022-12-07 00:09:49,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.05796, loss val: 0.05689
[2022-12-07 00:09:49,071] [INFO] [controller] EPOCH 4 loss ppo:  -0.07215, loss val: 0.05418
[2022-12-07 00:09:49,078] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:09:49,264] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:09:49,264] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:09:55,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:10:02,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:10:08,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:10:15,410] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:10:21,776] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:10:28,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:10:34,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:10:41,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:10:48,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:10:54,839] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1737712693599796
[2022-12-07 00:10:54,839] [INFO] [runner_train_mujoco] Average state value: 0.526009978550176
[2022-12-07 00:10:54,839] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 00:10:54,882] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.03552
[2022-12-07 00:10:54,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.03698, loss val: 0.03404
[2022-12-07 00:10:54,967] [INFO] [controller] EPOCH 3 loss ppo:  -0.05200, loss val: 0.03276
[2022-12-07 00:10:55,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.06821, loss val: 0.03187
[2022-12-07 00:10:55,021] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:10:55,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:10:55,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:11:01,691] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:11:08,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:11:14,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:11:21,236] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:11:27,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:11:33,736] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:11:40,241] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:11:46,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:11:53,427] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:12:00,136] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.357652102473444
[2022-12-07 00:12:00,136] [INFO] [runner_train_mujoco] Average state value: 0.47452320360143985
[2022-12-07 00:12:00,137] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 00:12:00,184] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.08069
[2022-12-07 00:12:00,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.02257, loss val: 0.08081
[2022-12-07 00:12:00,271] [INFO] [controller] EPOCH 3 loss ppo:  -0.03551, loss val: 0.07967
[2022-12-07 00:12:00,315] [INFO] [controller] EPOCH 4 loss ppo:  -0.04555, loss val: 0.07597
[2022-12-07 00:12:00,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:12:00,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:12:00,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:12:06,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:12:13,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:12:19,792] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:12:26,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:12:32,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:12:38,476] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:12:44,546] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:12:50,595] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:12:57,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:13:03,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.568226420086911
[2022-12-07 00:13:03,344] [INFO] [runner_train_mujoco] Average state value: 0.4976462261080742
[2022-12-07 00:13:03,344] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 00:13:03,391] [INFO] [controller] EPOCH 1 loss ppo:  -0.01567, loss val: 0.04316
[2022-12-07 00:13:03,427] [INFO] [controller] EPOCH 2 loss ppo:  -0.03717, loss val: 0.04128
[2022-12-07 00:13:03,470] [INFO] [controller] EPOCH 3 loss ppo:  -0.05181, loss val: 0.03970
[2022-12-07 00:13:03,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.06547, loss val: 0.03920
[2022-12-07 00:13:03,521] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:13:03,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:13:03,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:13:10,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:13:16,396] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:13:22,797] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:13:29,022] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:13:35,330] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:13:41,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:13:47,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:13:53,841] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:14:00,268] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:14:06,987] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.358777920750652
[2022-12-07 00:14:06,987] [INFO] [runner_train_mujoco] Average state value: 0.5228643789316217
[2022-12-07 00:14:06,987] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 00:14:07,032] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04733
[2022-12-07 00:14:07,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.03128, loss val: 0.04897
[2022-12-07 00:14:07,115] [INFO] [controller] EPOCH 3 loss ppo:  -0.04954, loss val: 0.04914
[2022-12-07 00:14:07,159] [INFO] [controller] EPOCH 4 loss ppo:  -0.06789, loss val: 0.04863
[2022-12-07 00:14:07,169] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:14:07,368] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:14:07,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:14:13,858] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:14:20,324] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:14:26,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:14:33,023] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:14:39,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:14:45,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:14:52,146] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:14:58,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:15:04,740] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:15:11,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.144180488694353
[2022-12-07 00:15:11,563] [INFO] [runner_train_mujoco] Average state value: 0.5301558309967319
[2022-12-07 00:15:11,563] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 00:15:11,612] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.05614
[2022-12-07 00:15:11,650] [INFO] [controller] EPOCH 2 loss ppo:  -0.03237, loss val: 0.05567
[2022-12-07 00:15:11,749] [INFO] [controller] EPOCH 3 loss ppo:  -0.05308, loss val: 0.05629
[2022-12-07 00:15:11,792] [INFO] [controller] EPOCH 4 loss ppo:  -0.06374, loss val: 0.05574
[2022-12-07 00:15:11,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:15:12,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:15:12,002] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:15:18,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:15:25,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:15:32,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:15:39,403] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:15:45,948] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:15:52,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:15:58,873] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:16:05,275] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:16:11,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:16:18,103] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.483589623732052
[2022-12-07 00:16:18,104] [INFO] [runner_train_mujoco] Average state value: 0.5597016917218764
[2022-12-07 00:16:18,104] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 00:16:18,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.03561
[2022-12-07 00:16:18,193] [INFO] [controller] EPOCH 2 loss ppo:  -0.03361, loss val: 0.03482
[2022-12-07 00:16:18,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.04556, loss val: 0.03455
[2022-12-07 00:16:18,282] [INFO] [controller] EPOCH 4 loss ppo:  -0.05859, loss val: 0.03442
[2022-12-07 00:16:18,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:16:18,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:16:18,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:16:25,391] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:16:32,063] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:16:38,850] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:16:45,626] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:16:52,341] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:16:58,542] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:17:04,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:17:10,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:17:17,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:17:23,413] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8159927946776735
[2022-12-07 00:17:23,414] [INFO] [runner_train_mujoco] Average state value: 0.5389447026699782
[2022-12-07 00:17:23,414] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 00:17:23,461] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04688
[2022-12-07 00:17:23,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.02876, loss val: 0.04679
[2022-12-07 00:17:23,544] [INFO] [controller] EPOCH 3 loss ppo:  -0.04668, loss val: 0.04634
[2022-12-07 00:17:23,587] [INFO] [controller] EPOCH 4 loss ppo:  -0.06173, loss val: 0.04560
[2022-12-07 00:17:23,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:17:23,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:17:23,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:17:30,790] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:17:40,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:17:48,483] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:17:55,469] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:18:02,594] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:18:09,432] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:18:16,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:18:24,171] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:18:31,375] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:18:38,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6809678973293303
[2022-12-07 00:18:38,191] [INFO] [runner_train_mujoco] Average state value: 0.5355869901279607
[2022-12-07 00:18:38,191] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 00:18:38,242] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04859
[2022-12-07 00:18:38,292] [INFO] [controller] EPOCH 2 loss ppo:  -0.02884, loss val: 0.04888
[2022-12-07 00:18:38,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.04529, loss val: 0.05021
[2022-12-07 00:18:38,372] [INFO] [controller] EPOCH 4 loss ppo:  -0.05534, loss val: 0.04986
[2022-12-07 00:18:38,381] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:18:38,575] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:18:38,575] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:18:45,918] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:18:53,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:19:01,528] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:19:09,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:19:16,520] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:19:24,172] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:19:32,082] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:19:39,275] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:19:46,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:19:54,025] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5829217797194817
[2022-12-07 00:19:54,026] [INFO] [runner_train_mujoco] Average state value: 0.5337580242604018
[2022-12-07 00:19:54,026] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 00:19:54,076] [INFO] [controller] EPOCH 1 loss ppo:  -0.01518, loss val: 0.05058
[2022-12-07 00:19:54,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.03135, loss val: 0.04802
[2022-12-07 00:19:54,164] [INFO] [controller] EPOCH 3 loss ppo:  -0.04618, loss val: 0.05061
[2022-12-07 00:19:54,208] [INFO] [controller] EPOCH 4 loss ppo:  -0.05929, loss val: 0.04589
[2022-12-07 00:19:54,219] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:19:54,423] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:19:54,424] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:20:01,739] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:20:09,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:20:17,343] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:20:25,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:20:33,378] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:20:40,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:20:48,187] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:20:55,678] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:21:03,395] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:21:10,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7841817755743774
[2022-12-07 00:21:10,651] [INFO] [runner_train_mujoco] Average state value: 0.5222875282963118
[2022-12-07 00:21:10,651] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 00:21:10,706] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.04642
[2022-12-07 00:21:10,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.02734, loss val: 0.04490
[2022-12-07 00:21:10,802] [INFO] [controller] EPOCH 3 loss ppo:  -0.04338, loss val: 0.04319
[2022-12-07 00:21:10,847] [INFO] [controller] EPOCH 4 loss ppo:  -0.05541, loss val: 0.04486
[2022-12-07 00:21:10,857] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:21:11,067] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:21:11,067] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:21:18,620] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:21:26,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:21:34,714] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:21:42,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:21:50,199] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:21:57,335] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:22:04,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:22:12,381] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:22:20,303] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:22:27,895] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6277617460410054
[2022-12-07 00:22:27,896] [INFO] [runner_train_mujoco] Average state value: 0.5162980258936684
[2022-12-07 00:22:27,896] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 00:22:27,963] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.05656
[2022-12-07 00:22:28,012] [INFO] [controller] EPOCH 2 loss ppo:  -0.03152, loss val: 0.05529
[2022-12-07 00:22:28,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.04779, loss val: 0.05647
[2022-12-07 00:22:28,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.05882, loss val: 0.05465
[2022-12-07 00:22:28,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:22:28,316] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:22:28,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:22:35,292] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:22:42,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:22:50,064] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:22:57,578] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:23:05,277] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:23:12,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:23:19,979] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:23:26,964] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:23:33,975] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:23:41,238] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.957335543762768
[2022-12-07 00:23:41,238] [INFO] [runner_train_mujoco] Average state value: 0.5204111185868581
[2022-12-07 00:23:41,238] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 00:23:41,289] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.03976
[2022-12-07 00:23:41,334] [INFO] [controller] EPOCH 2 loss ppo:  -0.02656, loss val: 0.03966
[2022-12-07 00:23:41,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.04212, loss val: 0.04129
[2022-12-07 00:23:41,422] [INFO] [controller] EPOCH 4 loss ppo:  -0.05344, loss val: 0.03950
[2022-12-07 00:23:41,432] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:23:41,638] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:23:41,639] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:23:48,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:23:56,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:24:03,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:24:10,984] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:24:18,484] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:24:26,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:24:32,906] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:24:40,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:24:47,108] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:24:54,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7406055901185966
[2022-12-07 00:24:54,448] [INFO] [runner_train_mujoco] Average state value: 0.4909794761141141
[2022-12-07 00:24:54,448] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 00:24:54,500] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04054
[2022-12-07 00:24:54,545] [INFO] [controller] EPOCH 2 loss ppo:  -0.02798, loss val: 0.04122
[2022-12-07 00:24:54,588] [INFO] [controller] EPOCH 3 loss ppo:  -0.04295, loss val: 0.04174
[2022-12-07 00:24:54,635] [INFO] [controller] EPOCH 4 loss ppo:  -0.05440, loss val: 0.04033
[2022-12-07 00:24:54,645] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:24:54,867] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:24:54,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:25:02,658] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:25:10,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:25:17,230] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:25:24,791] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:25:32,545] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:25:40,470] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:25:47,514] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:25:54,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:26:02,130] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:26:09,794] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8398653871379005
[2022-12-07 00:26:09,794] [INFO] [runner_train_mujoco] Average state value: 0.4991763059198856
[2022-12-07 00:26:09,794] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 00:26:09,844] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04945
[2022-12-07 00:26:09,884] [INFO] [controller] EPOCH 2 loss ppo:  -0.02671, loss val: 0.04900
[2022-12-07 00:26:09,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.03811, loss val: 0.04933
[2022-12-07 00:26:09,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.04925, loss val: 0.04861
[2022-12-07 00:26:09,984] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:26:10,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:26:10,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:26:17,744] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:26:24,970] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:26:32,126] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:26:39,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:26:47,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:26:56,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:27:04,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:27:11,670] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:27:18,993] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:27:26,434] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.551635432960976
[2022-12-07 00:27:26,435] [INFO] [runner_train_mujoco] Average state value: 0.5221862731526297
[2022-12-07 00:27:26,435] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 00:27:26,490] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.04558
[2022-12-07 00:27:26,537] [INFO] [controller] EPOCH 2 loss ppo:  -0.02277, loss val: 0.04886
[2022-12-07 00:27:26,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.03656, loss val: 0.04565
[2022-12-07 00:27:26,640] [INFO] [controller] EPOCH 4 loss ppo:  -0.04970, loss val: 0.04894
[2022-12-07 00:27:26,648] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:27:26,890] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:27:26,890] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:27:35,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:27:43,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:27:50,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:27:58,041] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:28:06,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:28:13,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:28:21,515] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:28:28,706] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:28:36,125] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:28:43,245] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.4399353011856135
[2022-12-07 00:28:43,245] [INFO] [runner_train_mujoco] Average state value: 0.5007780444299181
[2022-12-07 00:28:43,246] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 00:28:43,298] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.04543
[2022-12-07 00:28:43,339] [INFO] [controller] EPOCH 2 loss ppo:  -0.02500, loss val: 0.04475
[2022-12-07 00:28:43,449] [INFO] [controller] EPOCH 3 loss ppo:  -0.03717, loss val: 0.04377
[2022-12-07 00:28:43,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.04653, loss val: 0.04450
[2022-12-07 00:28:43,505] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:28:43,705] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:28:43,706] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:28:51,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:28:58,711] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:29:05,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:29:12,712] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:29:20,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:29:27,026] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:29:35,161] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:29:42,594] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:29:49,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:29:57,083] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9641233438385997
[2022-12-07 00:29:57,083] [INFO] [runner_train_mujoco] Average state value: 0.5345185952881971
[2022-12-07 00:29:57,083] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 00:29:57,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.03997
[2022-12-07 00:29:57,180] [INFO] [controller] EPOCH 2 loss ppo:  -0.02039, loss val: 0.04076
[2022-12-07 00:29:57,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.03225, loss val: 0.03955
[2022-12-07 00:29:57,266] [INFO] [controller] EPOCH 4 loss ppo:  -0.04253, loss val: 0.03995
[2022-12-07 00:29:57,276] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:29:57,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:29:57,471] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:30:04,874] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:30:12,121] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:30:18,939] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:30:25,673] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:30:32,643] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:30:40,100] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:30:47,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:30:54,580] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:31:01,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:31:08,888] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.458537285974726
[2022-12-07 00:31:08,888] [INFO] [runner_train_mujoco] Average state value: 0.5263931343952815
[2022-12-07 00:31:08,888] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 00:31:08,940] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.05452
[2022-12-07 00:31:08,986] [INFO] [controller] EPOCH 2 loss ppo:  -0.01934, loss val: 0.05489
[2022-12-07 00:31:09,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.02828, loss val: 0.05551
[2022-12-07 00:31:09,074] [INFO] [controller] EPOCH 4 loss ppo:  -0.03664, loss val: 0.05487
[2022-12-07 00:31:09,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:31:09,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:31:09,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:31:16,558] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:31:23,762] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:31:31,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:31:38,130] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:31:45,209] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:31:52,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:32:00,737] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:32:08,203] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:32:15,382] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:32:22,417] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.41273516635447
[2022-12-07 00:32:22,417] [INFO] [runner_train_mujoco] Average state value: 0.49596936400234704
[2022-12-07 00:32:22,417] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 00:32:22,474] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.05148
[2022-12-07 00:32:22,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.02065, loss val: 0.05043
[2022-12-07 00:32:22,566] [INFO] [controller] EPOCH 3 loss ppo:  -0.03004, loss val: 0.05278
[2022-12-07 00:32:22,612] [INFO] [controller] EPOCH 4 loss ppo:  -0.03888, loss val: 0.05111
[2022-12-07 00:32:22,622] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:32:22,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:32:22,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:32:30,401] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:32:38,143] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:32:45,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:32:53,093] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:33:00,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:33:08,384] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:33:15,684] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:33:23,638] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:33:30,787] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:33:38,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.525190622013999
[2022-12-07 00:33:38,315] [INFO] [runner_train_mujoco] Average state value: 0.5255781545241673
[2022-12-07 00:33:38,315] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 00:33:38,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.03915
[2022-12-07 00:33:38,419] [INFO] [controller] EPOCH 2 loss ppo:  -0.01891, loss val: 0.03925
[2022-12-07 00:33:38,467] [INFO] [controller] EPOCH 3 loss ppo:  -0.02705, loss val: 0.03925
[2022-12-07 00:33:38,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.03463, loss val: 0.03945
[2022-12-07 00:33:38,528] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:33:38,748] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:33:38,748] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:33:46,343] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:33:53,905] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:34:01,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:34:09,582] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:34:17,181] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:34:26,402] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:34:37,804] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:34:47,039] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:34:55,921] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:35:04,800] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.495043602755548
[2022-12-07 00:35:04,801] [INFO] [runner_train_mujoco] Average state value: 0.5333940716882547
[2022-12-07 00:35:04,801] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 00:35:04,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04472
[2022-12-07 00:35:04,909] [INFO] [controller] EPOCH 2 loss ppo:  -0.01675, loss val: 0.04607
[2022-12-07 00:35:04,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.02161, loss val: 0.04466
[2022-12-07 00:35:05,004] [INFO] [controller] EPOCH 4 loss ppo:  -0.02790, loss val: 0.04508
[2022-12-07 00:35:05,014] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:35:05,238] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:35:05,238] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:35:13,848] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:35:22,867] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:35:31,461] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:35:39,955] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:35:48,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:35:56,885] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:36:05,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:36:13,422] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:36:22,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:36:30,535] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.21066090406666
[2022-12-07 00:36:30,535] [INFO] [runner_train_mujoco] Average state value: 0.5287507277751964
[2022-12-07 00:36:30,535] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 00:36:30,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04549
[2022-12-07 00:36:30,661] [INFO] [controller] EPOCH 2 loss ppo:  -0.01474, loss val: 0.04549
[2022-12-07 00:36:30,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.01667, loss val: 0.04544
[2022-12-07 00:36:30,766] [INFO] [controller] EPOCH 4 loss ppo:  -0.01956, loss val: 0.04589
[2022-12-07 00:36:30,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:36:30,900] [INFO] [optimize] Finished learning.
