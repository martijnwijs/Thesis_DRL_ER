[2022-12-06 17:12:54,059] [INFO] [optimize] Starting learning
[2022-12-06 17:12:54,087] [INFO] [optimize] Starting learning process..
[2022-12-06 17:12:54,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:12:54,276] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:13:12,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:13:27,039] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:13:42,847] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:13:57,178] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:14:10,649] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:14:25,418] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:14:39,742] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:14:51,947] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:15:05,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:15:21,016] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.656274749511034
[2022-12-06 17:15:21,017] [INFO] [runner_train_mujoco] Average state value: -0.07018891465415558
[2022-12-06 17:15:21,017] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 17:15:21,147] [INFO] [controller] EPOCH 1 loss ppo:  -0.01096, loss val: 0.44173
[2022-12-06 17:15:21,492] [INFO] [controller] EPOCH 2 loss ppo:  -0.05102, loss val: 0.43618
[2022-12-06 17:15:21,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.07029, loss val: 0.32930
[2022-12-06 17:15:22,259] [INFO] [controller] EPOCH 4 loss ppo:  -0.08131, loss val: 0.29083
[2022-12-06 17:15:22,272] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:15:22,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:15:22,583] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:15:34,676] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:15:46,694] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:15:58,568] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:16:11,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:16:23,271] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:16:34,947] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:16:47,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:16:59,819] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:17:11,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:17:23,406] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6899076370346278
[2022-12-06 17:17:23,406] [INFO] [runner_train_mujoco] Average state value: 0.07209607395157216
[2022-12-06 17:17:23,406] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 17:17:23,495] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.24687
[2022-12-06 17:17:23,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.05111, loss val: 0.20524
[2022-12-06 17:17:23,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.06732, loss val: 0.19189
[2022-12-06 17:17:23,778] [INFO] [controller] EPOCH 4 loss ppo:  -0.07851, loss val: 0.15572
[2022-12-06 17:17:23,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:17:24,082] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:17:24,083] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:17:37,232] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:17:49,110] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:18:00,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:18:10,508] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:18:21,062] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:18:31,651] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:18:42,467] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:18:52,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:19:02,814] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:19:13,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5780661680323383
[2022-12-06 17:19:13,173] [INFO] [runner_train_mujoco] Average state value: 0.237568308374534
[2022-12-06 17:19:13,173] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 17:19:13,237] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.13347
[2022-12-06 17:19:13,292] [INFO] [controller] EPOCH 2 loss ppo:  -0.04757, loss val: 0.11598
[2022-12-06 17:19:13,340] [INFO] [controller] EPOCH 3 loss ppo:  -0.06508, loss val: 0.10134
[2022-12-06 17:19:13,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.07973, loss val: 0.09600
[2022-12-06 17:19:13,400] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:19:13,616] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:19:13,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:19:24,352] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:19:35,337] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:19:45,360] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:19:55,253] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:20:06,613] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:20:16,300] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:20:26,259] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:20:39,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:20:51,814] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:21:05,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5447836263843789
[2022-12-06 17:21:05,123] [INFO] [runner_train_mujoco] Average state value: 0.3854144659812252
[2022-12-06 17:21:05,123] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 17:21:05,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.08150
[2022-12-06 17:21:05,276] [INFO] [controller] EPOCH 2 loss ppo:  -0.05100, loss val: 0.08057
[2022-12-06 17:21:05,351] [INFO] [controller] EPOCH 3 loss ppo:  -0.06802, loss val: 0.07380
[2022-12-06 17:21:05,411] [INFO] [controller] EPOCH 4 loss ppo:  -0.07816, loss val: 0.07162
[2022-12-06 17:21:05,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:21:05,672] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:21:05,673] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:21:17,004] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:21:28,589] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:21:38,743] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:21:48,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:21:58,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:22:08,636] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:22:18,973] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:22:29,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:22:39,382] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:22:49,700] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5122098998271876
[2022-12-06 17:22:49,700] [INFO] [runner_train_mujoco] Average state value: 0.4495713713591297
[2022-12-06 17:22:49,700] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 17:22:49,771] [INFO] [controller] EPOCH 1 loss ppo:  -0.00922, loss val: 0.08079
[2022-12-06 17:22:49,824] [INFO] [controller] EPOCH 2 loss ppo:  -0.04278, loss val: 0.07328
[2022-12-06 17:22:49,878] [INFO] [controller] EPOCH 3 loss ppo:  -0.06229, loss val: 0.07687
[2022-12-06 17:22:49,935] [INFO] [controller] EPOCH 4 loss ppo:  -0.07277, loss val: 0.06324
[2022-12-06 17:22:49,947] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:22:50,192] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:22:50,192] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:23:00,685] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:23:10,864] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:23:21,393] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:23:32,008] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:23:42,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:23:53,052] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:24:03,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:24:14,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:24:24,571] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:24:34,290] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5205773451478191
[2022-12-06 17:24:34,291] [INFO] [runner_train_mujoco] Average state value: 0.5212967250309885
[2022-12-06 17:24:34,291] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 17:24:34,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.06185
[2022-12-06 17:24:34,421] [INFO] [controller] EPOCH 2 loss ppo:  -0.04519, loss val: 0.05712
[2022-12-06 17:24:34,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.06046, loss val: 0.05414
[2022-12-06 17:24:34,525] [INFO] [controller] EPOCH 4 loss ppo:  -0.07452, loss val: 0.05214
[2022-12-06 17:24:34,536] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:24:34,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:24:34,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:24:45,046] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:24:55,415] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:25:05,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:25:15,742] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:25:25,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:25:35,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:25:44,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:25:53,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:26:03,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:26:13,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5145744219085389
[2022-12-06 17:26:13,401] [INFO] [runner_train_mujoco] Average state value: 0.5747864763935407
[2022-12-06 17:26:13,401] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 17:26:13,467] [INFO] [controller] EPOCH 1 loss ppo:  -0.01133, loss val: 0.05779
[2022-12-06 17:26:13,522] [INFO] [controller] EPOCH 2 loss ppo:  -0.04393, loss val: 0.06053
[2022-12-06 17:26:13,575] [INFO] [controller] EPOCH 3 loss ppo:  -0.06080, loss val: 0.05753
[2022-12-06 17:26:13,632] [INFO] [controller] EPOCH 4 loss ppo:  -0.07450, loss val: 0.05471
[2022-12-06 17:26:13,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:26:13,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:26:13,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:26:23,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:26:32,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:26:42,382] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:26:51,956] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:27:01,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:27:10,028] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:27:18,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:27:25,886] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:27:33,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:27:41,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5342221859256275
[2022-12-06 17:27:41,014] [INFO] [runner_train_mujoco] Average state value: 0.5684911692366005
[2022-12-06 17:27:41,014] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 17:27:41,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01096, loss val: 0.05370
[2022-12-06 17:27:41,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.04031, loss val: 0.05167
[2022-12-06 17:27:41,263] [INFO] [controller] EPOCH 3 loss ppo:  -0.05628, loss val: 0.04840
[2022-12-06 17:27:41,318] [INFO] [controller] EPOCH 4 loss ppo:  -0.06984, loss val: 0.04608
[2022-12-06 17:27:41,330] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:27:41,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:27:41,562] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:27:49,319] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:27:57,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:28:06,186] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:28:21,358] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:28:29,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:28:37,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:28:47,032] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:28:58,349] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:29:06,990] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:29:14,733] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.45080472349730716
[2022-12-06 17:29:14,734] [INFO] [runner_train_mujoco] Average state value: 0.503129972934723
[2022-12-06 17:29:14,734] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 17:29:14,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01106, loss val: 0.04667
[2022-12-06 17:29:14,878] [INFO] [controller] EPOCH 2 loss ppo:  -0.04698, loss val: 0.04454
[2022-12-06 17:29:14,925] [INFO] [controller] EPOCH 3 loss ppo:  -0.06366, loss val: 0.04392
[2022-12-06 17:29:14,980] [INFO] [controller] EPOCH 4 loss ppo:  -0.07576, loss val: 0.04368
[2022-12-06 17:29:14,991] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:29:15,222] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:29:15,222] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:29:22,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:29:30,767] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:29:38,298] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:29:46,455] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:29:54,203] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:30:02,715] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:30:10,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:30:18,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:30:26,193] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:30:33,877] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4325222188245153
[2022-12-06 17:30:33,877] [INFO] [runner_train_mujoco] Average state value: 0.46086709246287744
[2022-12-06 17:30:33,877] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 17:30:33,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.03968
[2022-12-06 17:30:33,988] [INFO] [controller] EPOCH 2 loss ppo:  -0.04106, loss val: 0.04014
[2022-12-06 17:30:34,032] [INFO] [controller] EPOCH 3 loss ppo:  -0.06077, loss val: 0.03859
[2022-12-06 17:30:34,074] [INFO] [controller] EPOCH 4 loss ppo:  -0.07372, loss val: 0.03855
[2022-12-06 17:30:34,085] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:30:34,300] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:30:34,301] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:30:42,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:30:50,052] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:30:58,483] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:31:07,392] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:31:15,853] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:31:23,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:31:31,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:31:40,098] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:31:48,145] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:31:56,157] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.594592654061961
[2022-12-06 17:31:56,158] [INFO] [runner_train_mujoco] Average state value: 0.4685670597652594
[2022-12-06 17:31:56,158] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 17:31:56,225] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.04339
[2022-12-06 17:31:56,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.04894, loss val: 0.04275
[2022-12-06 17:31:56,312] [INFO] [controller] EPOCH 3 loss ppo:  -0.07153, loss val: 0.04314
[2022-12-06 17:31:56,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.08355, loss val: 0.04207
[2022-12-06 17:31:56,367] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:31:56,593] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:31:56,593] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:32:04,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:32:13,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:32:20,758] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:32:28,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:32:36,701] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:32:44,526] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:32:52,445] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:33:00,415] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:33:08,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:33:15,736] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5790136195756725
[2022-12-06 17:33:15,736] [INFO] [runner_train_mujoco] Average state value: 0.4929839039444923
[2022-12-06 17:33:15,737] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 17:33:15,789] [INFO] [controller] EPOCH 1 loss ppo:  -0.01154, loss val: 0.03968
[2022-12-06 17:33:15,832] [INFO] [controller] EPOCH 2 loss ppo:  -0.04423, loss val: 0.04059
[2022-12-06 17:33:15,877] [INFO] [controller] EPOCH 3 loss ppo:  -0.06422, loss val: 0.03928
[2022-12-06 17:33:15,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.07797, loss val: 0.03983
[2022-12-06 17:33:15,933] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:33:16,144] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:33:16,144] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:33:23,771] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:33:31,040] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:33:39,292] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:33:48,015] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:33:55,548] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:34:03,530] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:34:11,388] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:34:19,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:34:26,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:34:33,612] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6190359845504141
[2022-12-06 17:34:33,613] [INFO] [runner_train_mujoco] Average state value: 0.48957609179615974
[2022-12-06 17:34:33,613] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 17:34:33,671] [INFO] [controller] EPOCH 1 loss ppo:  -0.01182, loss val: 0.05067
[2022-12-06 17:34:33,717] [INFO] [controller] EPOCH 2 loss ppo:  -0.04554, loss val: 0.04955
[2022-12-06 17:34:33,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.06892, loss val: 0.05006
[2022-12-06 17:34:33,806] [INFO] [controller] EPOCH 4 loss ppo:  -0.07918, loss val: 0.04664
[2022-12-06 17:34:33,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:34:34,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:34:34,018] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:34:41,339] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:34:48,533] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:34:55,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:35:03,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:35:11,364] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:35:18,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:35:26,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:35:33,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:35:41,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:35:48,465] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4972768086135707
[2022-12-06 17:35:48,465] [INFO] [runner_train_mujoco] Average state value: 0.5182579268217087
[2022-12-06 17:35:48,465] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 17:35:48,521] [INFO] [controller] EPOCH 1 loss ppo:  -0.01210, loss val: 0.03945
[2022-12-06 17:35:48,565] [INFO] [controller] EPOCH 2 loss ppo:  -0.04302, loss val: 0.03924
[2022-12-06 17:35:48,607] [INFO] [controller] EPOCH 3 loss ppo:  -0.05809, loss val: 0.03934
[2022-12-06 17:35:48,651] [INFO] [controller] EPOCH 4 loss ppo:  -0.07069, loss val: 0.03831
[2022-12-06 17:35:48,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:35:48,880] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:35:48,880] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:35:56,872] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:36:04,746] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:36:12,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:36:19,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:36:27,422] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:36:35,165] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:36:43,574] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:36:51,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:36:59,276] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:37:07,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5981152059233674
[2022-12-06 17:37:07,571] [INFO] [runner_train_mujoco] Average state value: 0.5311102259953816
[2022-12-06 17:37:07,571] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 17:37:07,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01002, loss val: 0.04767
[2022-12-06 17:37:07,667] [INFO] [controller] EPOCH 2 loss ppo:  -0.04070, loss val: 0.04548
[2022-12-06 17:37:07,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.06350, loss val: 0.04532
[2022-12-06 17:37:07,753] [INFO] [controller] EPOCH 4 loss ppo:  -0.07915, loss val: 0.04595
[2022-12-06 17:37:07,761] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:37:07,984] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:37:07,984] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:37:15,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:37:23,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:37:31,527] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:37:39,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:37:47,153] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:37:55,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:38:03,251] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:38:11,361] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:38:19,050] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:38:26,429] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6036512679331197
[2022-12-06 17:38:26,429] [INFO] [runner_train_mujoco] Average state value: 0.5309377129971982
[2022-12-06 17:38:26,429] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 17:38:26,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.03759
[2022-12-06 17:38:26,529] [INFO] [controller] EPOCH 2 loss ppo:  -0.04056, loss val: 0.03602
[2022-12-06 17:38:26,574] [INFO] [controller] EPOCH 3 loss ppo:  -0.05613, loss val: 0.03419
[2022-12-06 17:38:26,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.06950, loss val: 0.03408
[2022-12-06 17:38:26,632] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:38:26,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:38:26,839] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:38:34,625] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:38:42,118] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:38:49,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:38:57,008] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:39:04,595] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:39:12,527] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:39:19,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:39:27,510] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:39:34,927] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:39:42,079] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6549901900170345
[2022-12-06 17:39:42,079] [INFO] [runner_train_mujoco] Average state value: 0.5189284465163946
[2022-12-06 17:39:42,079] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 17:39:42,128] [INFO] [controller] EPOCH 1 loss ppo:  -0.01063, loss val: 0.04216
[2022-12-06 17:39:42,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.03727, loss val: 0.04216
[2022-12-06 17:39:42,211] [INFO] [controller] EPOCH 3 loss ppo:  -0.05968, loss val: 0.03735
[2022-12-06 17:39:42,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.07504, loss val: 0.03554
[2022-12-06 17:39:42,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:39:42,447] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:39:42,447] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:39:49,795] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:39:56,443] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:40:03,281] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:40:10,037] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:40:16,712] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:40:23,550] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:40:30,251] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:40:36,714] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:40:43,255] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:40:49,728] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6638464359299416
[2022-12-06 17:40:49,728] [INFO] [runner_train_mujoco] Average state value: 0.4506472507119178
[2022-12-06 17:40:49,728] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 17:40:49,774] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04424
[2022-12-06 17:40:49,817] [INFO] [controller] EPOCH 2 loss ppo:  -0.04111, loss val: 0.04568
[2022-12-06 17:40:49,859] [INFO] [controller] EPOCH 3 loss ppo:  -0.06207, loss val: 0.04869
[2022-12-06 17:40:49,903] [INFO] [controller] EPOCH 4 loss ppo:  -0.07499, loss val: 0.04581
[2022-12-06 17:40:49,912] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:40:50,124] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:40:50,125] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:40:56,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:41:03,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:41:09,781] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:41:16,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:41:22,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:41:29,523] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:41:36,578] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:41:43,499] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:41:50,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:41:56,794] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7697846835162971
[2022-12-06 17:41:56,795] [INFO] [runner_train_mujoco] Average state value: 0.44348000074923044
[2022-12-06 17:41:56,795] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 17:41:56,843] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.03841
[2022-12-06 17:41:56,886] [INFO] [controller] EPOCH 2 loss ppo:  -0.04342, loss val: 0.03968
[2022-12-06 17:41:56,992] [INFO] [controller] EPOCH 3 loss ppo:  -0.05966, loss val: 0.03820
[2022-12-06 17:41:57,030] [INFO] [controller] EPOCH 4 loss ppo:  -0.07176, loss val: 0.03977
[2022-12-06 17:41:57,041] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:41:57,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:41:57,243] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:42:04,158] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:42:10,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:42:17,357] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:42:23,931] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:42:30,504] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:42:37,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:42:43,968] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:42:50,933] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:42:57,797] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:43:04,800] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.766564212511856
[2022-12-06 17:43:04,800] [INFO] [runner_train_mujoco] Average state value: 0.4688467078705629
[2022-12-06 17:43:04,801] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 17:43:04,851] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.04374
[2022-12-06 17:43:04,893] [INFO] [controller] EPOCH 2 loss ppo:  -0.03957, loss val: 0.04258
[2022-12-06 17:43:04,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.06087, loss val: 0.04117
[2022-12-06 17:43:04,983] [INFO] [controller] EPOCH 4 loss ppo:  -0.07568, loss val: 0.03766
[2022-12-06 17:43:04,994] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:43:05,198] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:43:05,199] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:43:12,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:43:20,284] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:43:27,869] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:43:34,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:43:41,445] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:43:48,357] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:43:55,609] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:44:02,648] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:44:09,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:44:16,487] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1417768067257648
[2022-12-06 17:44:16,487] [INFO] [runner_train_mujoco] Average state value: 0.5203866069217523
[2022-12-06 17:44:16,487] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 17:44:16,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.05126
[2022-12-06 17:44:16,583] [INFO] [controller] EPOCH 2 loss ppo:  -0.04322, loss val: 0.05302
[2022-12-06 17:44:16,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.06027, loss val: 0.05614
[2022-12-06 17:44:16,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.07099, loss val: 0.05159
[2022-12-06 17:44:16,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:44:16,890] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:44:16,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:44:24,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:44:31,125] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:44:38,018] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:44:44,752] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:44:51,526] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:44:58,056] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:45:04,538] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:45:11,717] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:45:18,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:45:26,150] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1383411007482966
[2022-12-06 17:45:26,150] [INFO] [runner_train_mujoco] Average state value: 0.500535948852698
[2022-12-06 17:45:26,150] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 17:45:26,195] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.04206
[2022-12-06 17:45:26,236] [INFO] [controller] EPOCH 2 loss ppo:  -0.04373, loss val: 0.04260
[2022-12-06 17:45:26,273] [INFO] [controller] EPOCH 3 loss ppo:  -0.06255, loss val: 0.04228
[2022-12-06 17:45:26,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.07496, loss val: 0.04213
[2022-12-06 17:45:26,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:45:26,497] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:45:26,497] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:45:33,343] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:45:39,976] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:45:46,583] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:45:54,058] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:46:00,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:46:07,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:46:13,834] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:46:20,712] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:46:27,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:46:33,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7784529178420051
[2022-12-06 17:46:33,806] [INFO] [runner_train_mujoco] Average state value: 0.4615295393268267
[2022-12-06 17:46:33,806] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 17:46:33,848] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.03788
[2022-12-06 17:46:33,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.04223, loss val: 0.04017
[2022-12-06 17:46:33,930] [INFO] [controller] EPOCH 3 loss ppo:  -0.05961, loss val: 0.03388
[2022-12-06 17:46:33,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.07248, loss val: 0.03913
[2022-12-06 17:46:33,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:46:34,185] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:46:34,185] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:46:40,815] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:46:47,423] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:46:53,922] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:47:00,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:47:06,750] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:47:13,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:47:19,508] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:47:25,990] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:47:32,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:47:39,796] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4304512150366504
[2022-12-06 17:47:39,796] [INFO] [runner_train_mujoco] Average state value: 0.46102729549010596
[2022-12-06 17:47:39,796] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 17:47:39,848] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.03889
[2022-12-06 17:47:39,886] [INFO] [controller] EPOCH 2 loss ppo:  -0.04360, loss val: 0.03644
[2022-12-06 17:47:39,930] [INFO] [controller] EPOCH 3 loss ppo:  -0.06376, loss val: 0.03542
[2022-12-06 17:47:39,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.07801, loss val: 0.03463
[2022-12-06 17:47:39,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:47:40,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:47:40,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:47:46,621] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:47:53,387] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:47:59,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:48:06,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:48:13,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:48:19,580] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:48:26,043] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:48:32,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:48:40,164] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:48:47,172] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6436232134601045
[2022-12-06 17:48:47,172] [INFO] [runner_train_mujoco] Average state value: 0.47596426022549465
[2022-12-06 17:48:47,172] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 17:48:47,226] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.07698
[2022-12-06 17:48:47,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.04051, loss val: 0.07503
[2022-12-06 17:48:47,318] [INFO] [controller] EPOCH 3 loss ppo:  -0.05823, loss val: 0.07425
[2022-12-06 17:48:47,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.07329, loss val: 0.06952
[2022-12-06 17:48:47,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:48:47,592] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:48:47,592] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:48:54,343] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:49:01,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:49:08,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:49:14,982] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:49:22,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:49:28,749] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:49:35,353] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:49:41,925] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:49:48,817] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:49:55,954] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.03265657983844
[2022-12-06 17:49:55,954] [INFO] [runner_train_mujoco] Average state value: 0.5517622774106761
[2022-12-06 17:49:55,954] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 17:49:55,999] [INFO] [controller] EPOCH 1 loss ppo:  -0.01515, loss val: 0.04741
[2022-12-06 17:49:56,035] [INFO] [controller] EPOCH 2 loss ppo:  -0.03989, loss val: 0.05432
[2022-12-06 17:49:56,073] [INFO] [controller] EPOCH 3 loss ppo:  -0.05812, loss val: 0.04897
[2022-12-06 17:49:56,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.07114, loss val: 0.04796
[2022-12-06 17:49:56,121] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:49:56,314] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:49:56,314] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:50:03,368] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:50:10,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:50:17,021] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:50:24,042] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:50:31,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:50:38,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:50:45,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:50:51,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:50:58,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:51:05,787] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.396361940321451
[2022-12-06 17:51:05,788] [INFO] [runner_train_mujoco] Average state value: 0.5177275450875362
[2022-12-06 17:51:05,788] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 17:51:05,840] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.07646
[2022-12-06 17:51:05,879] [INFO] [controller] EPOCH 2 loss ppo:  -0.04105, loss val: 0.07493
[2022-12-06 17:51:05,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.05914, loss val: 0.07435
[2022-12-06 17:51:05,960] [INFO] [controller] EPOCH 4 loss ppo:  -0.07457, loss val: 0.07321
[2022-12-06 17:51:05,970] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:51:06,149] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:51:06,149] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:51:13,013] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:51:19,889] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:51:26,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:51:33,207] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:51:39,923] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:51:46,464] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:51:52,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:51:59,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:52:06,542] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:52:13,290] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9222433768095981
[2022-12-06 17:52:13,290] [INFO] [runner_train_mujoco] Average state value: 0.5284190840870142
[2022-12-06 17:52:13,290] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 17:52:13,341] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.03966
[2022-12-06 17:52:13,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.03721, loss val: 0.03941
[2022-12-06 17:52:13,422] [INFO] [controller] EPOCH 3 loss ppo:  -0.05536, loss val: 0.03701
[2022-12-06 17:52:13,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.06841, loss val: 0.03393
[2022-12-06 17:52:13,472] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:52:13,639] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:52:13,639] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:52:20,566] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:52:27,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:52:33,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:52:40,407] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:52:47,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:52:54,436] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:53:00,780] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:53:07,170] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:53:13,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:53:20,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.966986675261407
[2022-12-06 17:53:20,230] [INFO] [runner_train_mujoco] Average state value: 0.4829571170210839
[2022-12-06 17:53:20,230] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 17:53:20,278] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.04122
[2022-12-06 17:53:20,321] [INFO] [controller] EPOCH 2 loss ppo:  -0.04496, loss val: 0.04112
[2022-12-06 17:53:20,362] [INFO] [controller] EPOCH 3 loss ppo:  -0.06424, loss val: 0.04388
[2022-12-06 17:53:20,395] [INFO] [controller] EPOCH 4 loss ppo:  -0.07822, loss val: 0.04082
[2022-12-06 17:53:20,405] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:53:20,582] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:53:20,583] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:53:27,265] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:53:33,954] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:53:40,837] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:53:47,071] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:53:53,606] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:53:59,936] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:54:06,470] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:54:12,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:54:19,565] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:54:26,143] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.018734910814558
[2022-12-06 17:54:26,144] [INFO] [runner_train_mujoco] Average state value: 0.33528883199766274
[2022-12-06 17:54:26,144] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 17:54:26,196] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.15046
[2022-12-06 17:54:26,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.03260, loss val: 0.14359
[2022-12-06 17:54:26,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.04859, loss val: 0.14390
[2022-12-06 17:54:26,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.06172, loss val: 0.14205
[2022-12-06 17:54:26,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:54:26,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:54:26,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:54:33,213] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:54:40,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:54:46,677] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:54:53,128] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:54:59,557] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:55:06,513] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:55:13,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:55:19,938] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:55:26,676] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:55:33,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.51120041338491
[2022-12-06 17:55:33,171] [INFO] [runner_train_mujoco] Average state value: 0.4397723327204585
[2022-12-06 17:55:33,171] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 17:55:33,228] [INFO] [controller] EPOCH 1 loss ppo:  -0.01512, loss val: 0.03773
[2022-12-06 17:55:33,276] [INFO] [controller] EPOCH 2 loss ppo:  -0.04259, loss val: 0.03731
[2022-12-06 17:55:33,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.06573, loss val: 0.03777
[2022-12-06 17:55:33,371] [INFO] [controller] EPOCH 4 loss ppo:  -0.07830, loss val: 0.03768
[2022-12-06 17:55:33,381] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:55:33,591] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:55:33,592] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:55:40,295] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:55:46,973] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:55:53,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:56:00,749] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:56:07,306] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:56:14,294] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:56:21,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:56:28,085] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:56:35,488] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:56:43,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.250218938547834
[2022-12-06 17:56:43,267] [INFO] [runner_train_mujoco] Average state value: 0.4521349181930224
[2022-12-06 17:56:43,267] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 17:56:43,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01556, loss val: 0.06034
[2022-12-06 17:56:43,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.03876, loss val: 0.05893
[2022-12-06 17:56:43,415] [INFO] [controller] EPOCH 3 loss ppo:  -0.05653, loss val: 0.05743
[2022-12-06 17:56:43,464] [INFO] [controller] EPOCH 4 loss ppo:  -0.06981, loss val: 0.05538
[2022-12-06 17:56:43,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:56:43,696] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:56:43,697] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:56:50,586] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:56:57,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:57:04,725] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:57:11,754] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:57:18,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:57:25,181] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:57:32,412] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:57:39,278] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:57:46,130] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:57:52,611] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.205759013361776
[2022-12-06 17:57:52,611] [INFO] [runner_train_mujoco] Average state value: 0.4987689109668135
[2022-12-06 17:57:52,612] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 17:57:52,668] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.05387
[2022-12-06 17:57:52,710] [INFO] [controller] EPOCH 2 loss ppo:  -0.03970, loss val: 0.05211
[2022-12-06 17:57:52,756] [INFO] [controller] EPOCH 3 loss ppo:  -0.05834, loss val: 0.05126
[2022-12-06 17:57:52,797] [INFO] [controller] EPOCH 4 loss ppo:  -0.07482, loss val: 0.05089
[2022-12-06 17:57:52,806] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:57:53,007] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:57:53,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:57:59,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:58:06,646] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:58:13,318] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:58:20,222] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:58:26,944] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:58:33,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:58:40,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:58:46,648] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:58:53,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:58:59,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4644934859191414
[2022-12-06 17:58:59,986] [INFO] [runner_train_mujoco] Average state value: 0.5102708591446279
[2022-12-06 17:58:59,986] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 17:59:00,045] [INFO] [controller] EPOCH 1 loss ppo:  -0.01546, loss val: 0.05932
[2022-12-06 17:59:00,088] [INFO] [controller] EPOCH 2 loss ppo:  -0.04209, loss val: 0.06060
[2022-12-06 17:59:00,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.06043, loss val: 0.05976
[2022-12-06 17:59:00,182] [INFO] [controller] EPOCH 4 loss ppo:  -0.07347, loss val: 0.05965
[2022-12-06 17:59:00,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:59:00,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:59:00,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:59:07,341] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:59:14,127] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:59:20,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:59:27,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:59:33,855] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:59:40,384] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:59:46,685] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:59:53,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:59:59,883] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:00:06,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8830454144601836
[2022-12-06 18:00:06,354] [INFO] [runner_train_mujoco] Average state value: 0.558415616452694
[2022-12-06 18:00:06,355] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 18:00:06,399] [INFO] [controller] EPOCH 1 loss ppo:  -0.01550, loss val: 0.05246
[2022-12-06 18:00:06,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.03768, loss val: 0.05323
[2022-12-06 18:00:06,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.05648, loss val: 0.04798
[2022-12-06 18:00:06,509] [INFO] [controller] EPOCH 4 loss ppo:  -0.07192, loss val: 0.04678
[2022-12-06 18:00:06,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:00:06,695] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:00:06,696] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:00:13,254] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:00:19,965] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:00:26,441] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:00:32,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:00:39,257] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:00:45,742] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:00:52,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:00:58,367] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:01:04,955] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:01:11,669] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3813854906909357
[2022-12-06 18:01:11,669] [INFO] [runner_train_mujoco] Average state value: 0.4433565826192498
[2022-12-06 18:01:11,670] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 18:01:11,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.06853
[2022-12-06 18:01:11,758] [INFO] [controller] EPOCH 2 loss ppo:  -0.03707, loss val: 0.06757
[2022-12-06 18:01:11,790] [INFO] [controller] EPOCH 3 loss ppo:  -0.05559, loss val: 0.07048
[2022-12-06 18:01:11,832] [INFO] [controller] EPOCH 4 loss ppo:  -0.07041, loss val: 0.06682
[2022-12-06 18:01:11,842] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:01:12,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:01:12,032] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:01:18,644] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:01:25,247] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:01:31,576] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:01:37,876] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:01:44,429] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:01:51,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:01:57,529] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:02:03,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:02:10,646] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:02:17,290] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.500213748782601
[2022-12-06 18:02:17,290] [INFO] [runner_train_mujoco] Average state value: 0.46216147681077324
[2022-12-06 18:02:17,290] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 18:02:17,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.03737
[2022-12-06 18:02:17,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.03974, loss val: 0.03734
[2022-12-06 18:02:17,425] [INFO] [controller] EPOCH 3 loss ppo:  -0.05901, loss val: 0.03691
[2022-12-06 18:02:17,458] [INFO] [controller] EPOCH 4 loss ppo:  -0.07370, loss val: 0.03723
[2022-12-06 18:02:17,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:02:17,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:02:17,680] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:02:24,606] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:02:31,461] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:02:38,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:02:44,545] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:02:51,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:02:57,787] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:03:04,522] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:03:11,059] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:03:17,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:03:24,756] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.724770291204299
[2022-12-06 18:03:24,757] [INFO] [runner_train_mujoco] Average state value: 0.43673039619127907
[2022-12-06 18:03:24,757] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 18:03:24,811] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.05487
[2022-12-06 18:03:24,854] [INFO] [controller] EPOCH 2 loss ppo:  -0.03566, loss val: 0.05084
[2022-12-06 18:03:24,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.05006, loss val: 0.04688
[2022-12-06 18:03:24,941] [INFO] [controller] EPOCH 4 loss ppo:  -0.06327, loss val: 0.04505
[2022-12-06 18:03:24,952] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:03:25,156] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:03:25,156] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:03:31,994] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:03:38,680] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:03:45,313] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:03:51,823] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:03:58,369] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:04:05,434] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:04:12,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:04:18,825] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:04:25,592] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:04:32,729] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8471097188676393
[2022-12-06 18:04:32,729] [INFO] [runner_train_mujoco] Average state value: 0.4656510207826893
[2022-12-06 18:04:32,729] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 18:04:32,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.04961
[2022-12-06 18:04:32,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.03114, loss val: 0.04777
[2022-12-06 18:04:32,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.05170, loss val: 0.04607
[2022-12-06 18:04:32,897] [INFO] [controller] EPOCH 4 loss ppo:  -0.06735, loss val: 0.04511
[2022-12-06 18:04:32,906] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:04:33,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:04:33,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:04:40,206] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:04:47,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:04:53,769] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:05:00,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:05:06,686] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:05:13,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:05:20,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:05:27,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:05:33,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:05:40,478] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0542381597833286
[2022-12-06 18:05:40,478] [INFO] [runner_train_mujoco] Average state value: 0.5042360530023774
[2022-12-06 18:05:40,478] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 18:05:40,531] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.05600
[2022-12-06 18:05:40,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.03290, loss val: 0.05619
[2022-12-06 18:05:40,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.05101, loss val: 0.05720
[2022-12-06 18:05:40,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.06637, loss val: 0.05745
[2022-12-06 18:05:40,650] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:05:40,810] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:05:40,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:05:47,544] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:05:54,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:06:01,032] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:06:07,554] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:06:14,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:06:20,312] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:06:26,807] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:06:37,054] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:06:43,788] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:06:50,409] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8476742019528283
[2022-12-06 18:06:50,409] [INFO] [runner_train_mujoco] Average state value: 0.49968696890523046
[2022-12-06 18:06:50,410] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 18:06:50,461] [INFO] [controller] EPOCH 1 loss ppo:  -0.01573, loss val: 0.05331
[2022-12-06 18:06:50,501] [INFO] [controller] EPOCH 2 loss ppo:  -0.03567, loss val: 0.05166
[2022-12-06 18:06:50,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.05264, loss val: 0.05090
[2022-12-06 18:06:50,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.06454, loss val: 0.05240
[2022-12-06 18:06:50,646] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:06:50,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:06:50,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:06:57,662] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:07:05,504] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:07:14,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:07:22,756] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:07:28,979] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:07:35,386] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:07:41,532] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:07:47,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:07:54,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:08:00,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.289528505973655
[2022-12-06 18:08:00,920] [INFO] [runner_train_mujoco] Average state value: 0.5185211381614209
[2022-12-06 18:08:00,920] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 18:08:00,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04270
[2022-12-06 18:08:01,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.03375, loss val: 0.04192
[2022-12-06 18:08:01,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.05190, loss val: 0.04218
[2022-12-06 18:08:01,098] [INFO] [controller] EPOCH 4 loss ppo:  -0.06378, loss val: 0.04349
[2022-12-06 18:08:01,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:08:01,296] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:08:01,296] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:08:07,760] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:08:14,624] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:08:21,090] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:08:27,571] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:08:34,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:08:40,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:08:46,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:08:53,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:08:59,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:09:06,373] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.424839955464016
[2022-12-06 18:09:06,373] [INFO] [runner_train_mujoco] Average state value: 0.49673538455863786
[2022-12-06 18:09:06,373] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 18:09:06,431] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04430
[2022-12-06 18:09:06,468] [INFO] [controller] EPOCH 2 loss ppo:  -0.03148, loss val: 0.04523
[2022-12-06 18:09:06,510] [INFO] [controller] EPOCH 3 loss ppo:  -0.04990, loss val: 0.04519
[2022-12-06 18:09:06,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.06424, loss val: 0.04561
[2022-12-06 18:09:06,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:09:06,743] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:09:06,743] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:09:13,615] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:09:20,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:09:27,418] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:09:33,959] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:09:40,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:09:46,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:09:53,106] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:10:00,535] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:10:07,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:10:14,394] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.963362455658366
[2022-12-06 18:10:14,394] [INFO] [runner_train_mujoco] Average state value: 0.45507733552654583
[2022-12-06 18:10:14,394] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 18:10:14,445] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.06967
[2022-12-06 18:10:14,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.03156, loss val: 0.07014
[2022-12-06 18:10:14,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.04747, loss val: 0.07256
[2022-12-06 18:10:14,573] [INFO] [controller] EPOCH 4 loss ppo:  -0.06012, loss val: 0.07028
[2022-12-06 18:10:14,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:10:14,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:10:14,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:10:21,726] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:10:28,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:10:36,045] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:10:43,052] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:10:49,649] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:10:56,257] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:11:02,895] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:11:09,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:11:16,252] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:11:22,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6807908432135674
[2022-12-06 18:11:22,806] [INFO] [runner_train_mujoco] Average state value: 0.45070675690472123
[2022-12-06 18:11:22,806] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 18:11:22,859] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.07307
[2022-12-06 18:11:22,904] [INFO] [controller] EPOCH 2 loss ppo:  -0.02893, loss val: 0.07612
[2022-12-06 18:11:22,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.04619, loss val: 0.06939
[2022-12-06 18:11:22,998] [INFO] [controller] EPOCH 4 loss ppo:  -0.05777, loss val: 0.06896
[2022-12-06 18:11:23,007] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:11:23,224] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:11:23,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:11:30,238] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:11:37,250] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:11:43,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:11:50,304] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:11:56,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:12:03,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:12:09,608] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:12:16,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:12:22,225] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:12:28,793] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2215605207325027
[2022-12-06 18:12:28,793] [INFO] [runner_train_mujoco] Average state value: 0.5037976176316539
[2022-12-06 18:12:28,793] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 18:12:28,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.05091
[2022-12-06 18:12:28,884] [INFO] [controller] EPOCH 2 loss ppo:  -0.02693, loss val: 0.05097
[2022-12-06 18:12:28,922] [INFO] [controller] EPOCH 3 loss ppo:  -0.04642, loss val: 0.05114
[2022-12-06 18:12:28,960] [INFO] [controller] EPOCH 4 loss ppo:  -0.05986, loss val: 0.05264
[2022-12-06 18:12:28,970] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:12:29,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:12:29,158] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:12:35,496] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:12:42,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:12:49,145] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:12:55,648] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:13:01,951] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:13:08,601] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:13:14,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:13:20,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:13:27,359] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:13:33,689] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.353198196893112
[2022-12-06 18:13:33,690] [INFO] [runner_train_mujoco] Average state value: 0.4873549217929442
[2022-12-06 18:13:33,690] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 18:13:33,733] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.05285
[2022-12-06 18:13:33,771] [INFO] [controller] EPOCH 2 loss ppo:  -0.02810, loss val: 0.05225
[2022-12-06 18:13:33,807] [INFO] [controller] EPOCH 3 loss ppo:  -0.04468, loss val: 0.05192
[2022-12-06 18:13:33,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.05657, loss val: 0.05158
[2022-12-06 18:13:33,853] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:13:34,037] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:13:34,037] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:13:40,740] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:13:47,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:13:53,986] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:14:00,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:14:07,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:14:13,399] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:14:19,590] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:14:25,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:14:32,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:14:39,164] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.028591851875667
[2022-12-06 18:14:39,164] [INFO] [runner_train_mujoco] Average state value: 0.5137853891452153
[2022-12-06 18:14:39,164] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 18:14:39,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.03797
[2022-12-06 18:14:39,253] [INFO] [controller] EPOCH 2 loss ppo:  -0.02795, loss val: 0.03989
[2022-12-06 18:14:39,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.04409, loss val: 0.03726
[2022-12-06 18:14:39,332] [INFO] [controller] EPOCH 4 loss ppo:  -0.05674, loss val: 0.03840
[2022-12-06 18:14:39,342] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:14:39,544] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:14:39,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:14:46,178] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:14:53,027] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:14:59,783] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:15:06,392] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:15:12,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:15:19,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:15:27,389] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:15:33,846] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:15:40,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:15:46,907] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2669332026541276
[2022-12-06 18:15:46,907] [INFO] [runner_train_mujoco] Average state value: 0.5008323653489353
[2022-12-06 18:15:46,907] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 18:15:46,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.03893
[2022-12-06 18:15:47,000] [INFO] [controller] EPOCH 2 loss ppo:  -0.02952, loss val: 0.03904
[2022-12-06 18:15:47,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.04377, loss val: 0.03864
[2022-12-06 18:15:47,089] [INFO] [controller] EPOCH 4 loss ppo:  -0.05410, loss val: 0.03997
[2022-12-06 18:15:47,098] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:15:47,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:15:47,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:15:53,972] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:16:00,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:16:08,193] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:16:15,177] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:16:21,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:16:28,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:16:35,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:16:42,934] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:16:49,721] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:16:56,155] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2085040176664115
[2022-12-06 18:16:56,155] [INFO] [runner_train_mujoco] Average state value: 0.49445464241504666
[2022-12-06 18:16:56,156] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 18:16:56,206] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.05346
[2022-12-06 18:16:56,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.02265, loss val: 0.05228
[2022-12-06 18:16:56,284] [INFO] [controller] EPOCH 3 loss ppo:  -0.03674, loss val: 0.05157
[2022-12-06 18:16:56,329] [INFO] [controller] EPOCH 4 loss ppo:  -0.04940, loss val: 0.05198
[2022-12-06 18:16:56,336] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:16:56,533] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:16:56,534] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:17:03,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:17:09,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:17:16,813] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:17:23,965] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:17:31,035] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:17:37,661] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:17:45,028] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:17:54,247] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:18:01,580] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:18:09,030] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.218012385396687
[2022-12-06 18:18:09,031] [INFO] [runner_train_mujoco] Average state value: 0.49502226293087004
[2022-12-06 18:18:09,031] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 18:18:09,082] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.04687
[2022-12-06 18:18:09,129] [INFO] [controller] EPOCH 2 loss ppo:  -0.02442, loss val: 0.04646
[2022-12-06 18:18:09,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.03801, loss val: 0.04627
[2022-12-06 18:18:09,218] [INFO] [controller] EPOCH 4 loss ppo:  -0.04893, loss val: 0.04686
[2022-12-06 18:18:09,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:18:09,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:18:09,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:18:16,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:18:24,279] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:18:31,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:18:39,398] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:18:47,809] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:18:55,362] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:19:02,591] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:19:09,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:19:16,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:19:24,457] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.430307780968446
[2022-12-06 18:19:24,457] [INFO] [runner_train_mujoco] Average state value: 0.5095960760464271
[2022-12-06 18:19:24,457] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 18:19:24,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.05020
[2022-12-06 18:19:24,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.02190, loss val: 0.04940
[2022-12-06 18:19:24,714] [INFO] [controller] EPOCH 3 loss ppo:  -0.03336, loss val: 0.04941
[2022-12-06 18:19:24,777] [INFO] [controller] EPOCH 4 loss ppo:  -0.04391, loss val: 0.04932
[2022-12-06 18:19:24,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:19:25,024] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:19:25,025] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:19:32,519] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:19:40,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:19:47,205] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:19:54,403] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:20:02,141] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:20:09,267] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:20:16,577] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:20:23,806] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:20:31,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:20:39,101] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4379816645664407
[2022-12-06 18:20:39,101] [INFO] [runner_train_mujoco] Average state value: 0.5096787191430727
[2022-12-06 18:20:39,101] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 18:20:39,155] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04692
[2022-12-06 18:20:39,199] [INFO] [controller] EPOCH 2 loss ppo:  -0.02163, loss val: 0.04847
[2022-12-06 18:20:39,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.03412, loss val: 0.04733
[2022-12-06 18:20:39,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.04449, loss val: 0.04734
[2022-12-06 18:20:39,300] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:20:39,516] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:20:39,516] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:20:47,024] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:20:54,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:21:01,716] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:21:09,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:21:17,160] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:21:24,408] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:21:31,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:21:39,671] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:21:47,395] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:21:54,725] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0551869722835305
[2022-12-06 18:21:54,725] [INFO] [runner_train_mujoco] Average state value: 0.5127572113623222
[2022-12-06 18:21:54,725] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 18:21:54,783] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04839
[2022-12-06 18:21:54,837] [INFO] [controller] EPOCH 2 loss ppo:  -0.02197, loss val: 0.04952
[2022-12-06 18:21:54,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.03327, loss val: 0.04846
[2022-12-06 18:21:54,941] [INFO] [controller] EPOCH 4 loss ppo:  -0.04514, loss val: 0.04832
[2022-12-06 18:21:54,952] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:21:55,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:21:55,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:22:03,201] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:22:10,988] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:22:18,681] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:22:26,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:22:34,733] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:22:43,169] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:22:50,721] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:23:00,452] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:23:10,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:23:20,107] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.573560821328081
[2022-12-06 18:23:20,108] [INFO] [runner_train_mujoco] Average state value: 0.5183526414285102
[2022-12-06 18:23:20,108] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 18:23:20,170] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.03761
[2022-12-06 18:23:20,239] [INFO] [controller] EPOCH 2 loss ppo:  -0.01956, loss val: 0.03755
[2022-12-06 18:23:20,299] [INFO] [controller] EPOCH 3 loss ppo:  -0.02940, loss val: 0.03750
[2022-12-06 18:23:20,418] [INFO] [controller] EPOCH 4 loss ppo:  -0.04050, loss val: 0.03827
[2022-12-06 18:23:20,429] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:23:20,665] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:23:20,666] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:23:31,368] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:23:40,776] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:23:49,107] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:23:57,881] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:24:06,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:24:14,671] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:24:23,541] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:24:31,468] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:24:39,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:24:47,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8444434199224475
[2022-12-06 18:24:47,274] [INFO] [runner_train_mujoco] Average state value: 0.48718496280660234
[2022-12-06 18:24:47,274] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 18:24:47,356] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.05081
[2022-12-06 18:24:47,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.01697, loss val: 0.05068
[2022-12-06 18:24:47,471] [INFO] [controller] EPOCH 3 loss ppo:  -0.02321, loss val: 0.05080
[2022-12-06 18:24:47,531] [INFO] [controller] EPOCH 4 loss ppo:  -0.03028, loss val: 0.05049
[2022-12-06 18:24:47,543] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:24:47,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:24:47,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:24:56,005] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:25:03,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:25:11,783] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:25:19,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:25:27,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:25:35,551] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:25:43,842] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:25:51,236] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:25:59,126] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:26:06,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.802202930528334
[2022-12-06 18:26:06,568] [INFO] [runner_train_mujoco] Average state value: 0.5299484333992004
[2022-12-06 18:26:06,568] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 18:26:06,618] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.03930
[2022-12-06 18:26:06,657] [INFO] [controller] EPOCH 2 loss ppo:  -0.01623, loss val: 0.04016
[2022-12-06 18:26:06,702] [INFO] [controller] EPOCH 3 loss ppo:  -0.02017, loss val: 0.03898
[2022-12-06 18:26:06,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.02578, loss val: 0.03871
[2022-12-06 18:26:06,759] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:26:06,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:26:06,978] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:26:15,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:26:22,860] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:26:29,867] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:26:38,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:26:48,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:26:57,811] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:27:06,373] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:27:14,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:27:23,630] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:27:31,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.213079909382489
[2022-12-06 18:27:31,971] [INFO] [runner_train_mujoco] Average state value: 0.5057552842994532
[2022-12-06 18:27:31,971] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 18:27:32,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.03957
[2022-12-06 18:27:32,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.01616, loss val: 0.03965
[2022-12-06 18:27:32,123] [INFO] [controller] EPOCH 3 loss ppo:  -0.01899, loss val: 0.04037
[2022-12-06 18:27:32,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.02262, loss val: 0.03983
[2022-12-06 18:27:32,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:27:32,321] [INFO] [optimize] Finished learning.
