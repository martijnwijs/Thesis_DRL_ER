[2022-12-06 19:46:07,914] [INFO] [optimize] Starting learning
[2022-12-06 19:46:07,943] [INFO] [optimize] Starting learning process..
[2022-12-06 19:46:08,103] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:46:08,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:46:20,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:46:31,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:46:43,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:46:54,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:47:05,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:47:18,373] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:47:29,346] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:47:40,480] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:47:51,537] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:48:03,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6341989795311587
[2022-12-06 19:48:03,809] [INFO] [runner_train_mujoco] Average state value: 0.4583063561494152
[2022-12-06 19:48:03,809] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 19:48:03,902] [INFO] [controller] EPOCH 1 loss ppo:  -0.00890, loss val: 0.18040
[2022-12-06 19:48:03,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.04979, loss val: 0.17015
[2022-12-06 19:48:04,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.06570, loss val: 0.15707
[2022-12-06 19:48:04,086] [INFO] [controller] EPOCH 4 loss ppo:  -0.07715, loss val: 0.14828
[2022-12-06 19:48:04,099] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:48:04,373] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:48:04,374] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:48:17,508] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:48:28,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:48:39,733] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:48:51,085] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:49:02,721] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:49:14,161] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:49:25,220] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:49:37,355] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:49:48,787] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:50:01,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5807062067661052
[2022-12-06 19:50:01,300] [INFO] [runner_train_mujoco] Average state value: 0.46191700120844564
[2022-12-06 19:50:01,300] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 19:50:01,391] [INFO] [controller] EPOCH 1 loss ppo:  -0.01140, loss val: 0.14620
[2022-12-06 19:50:01,457] [INFO] [controller] EPOCH 2 loss ppo:  -0.03864, loss val: 0.13690
[2022-12-06 19:50:01,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.05603, loss val: 0.12204
[2022-12-06 19:50:01,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.06927, loss val: 0.11206
[2022-12-06 19:50:01,587] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:50:01,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:50:01,860] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:50:14,158] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:50:25,574] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:50:36,585] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:50:47,505] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:50:58,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:51:09,072] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:51:19,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:51:30,642] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:51:41,034] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:51:51,745] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6040766980121703
[2022-12-06 19:51:51,746] [INFO] [runner_train_mujoco] Average state value: 0.5520387440702568
[2022-12-06 19:51:51,746] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 19:51:51,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01072, loss val: 0.11529
[2022-12-06 19:51:51,874] [INFO] [controller] EPOCH 2 loss ppo:  -0.03885, loss val: 0.11166
[2022-12-06 19:51:51,932] [INFO] [controller] EPOCH 3 loss ppo:  -0.05604, loss val: 0.10592
[2022-12-06 19:51:51,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.06976, loss val: 0.10186
[2022-12-06 19:51:52,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:51:52,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:51:52,246] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:52:03,165] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:52:14,928] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:52:24,997] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:52:34,987] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:52:45,044] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:52:54,732] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:53:05,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:53:15,052] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:53:24,762] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:53:34,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5644386841841957
[2022-12-06 19:53:34,284] [INFO] [runner_train_mujoco] Average state value: 0.5676810805813098
[2022-12-06 19:53:34,284] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 19:53:34,345] [INFO] [controller] EPOCH 1 loss ppo:  -0.01023, loss val: 0.09421
[2022-12-06 19:53:34,395] [INFO] [controller] EPOCH 2 loss ppo:  -0.03694, loss val: 0.08818
[2022-12-06 19:53:34,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.05855, loss val: 0.08336
[2022-12-06 19:53:34,507] [INFO] [controller] EPOCH 4 loss ppo:  -0.07160, loss val: 0.07827
[2022-12-06 19:53:34,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:53:34,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:53:34,770] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:53:44,970] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:53:54,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:54:04,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:54:14,552] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:54:24,025] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:54:33,776] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:54:43,161] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:54:52,588] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:55:01,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:55:10,697] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6378600118504637
[2022-12-06 19:55:10,697] [INFO] [runner_train_mujoco] Average state value: 0.6196844734592984
[2022-12-06 19:55:10,697] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 19:55:10,757] [INFO] [controller] EPOCH 1 loss ppo:  -0.01136, loss val: 0.08392
[2022-12-06 19:55:10,803] [INFO] [controller] EPOCH 2 loss ppo:  -0.04084, loss val: 0.08269
[2022-12-06 19:55:10,851] [INFO] [controller] EPOCH 3 loss ppo:  -0.05939, loss val: 0.07874
[2022-12-06 19:55:10,898] [INFO] [controller] EPOCH 4 loss ppo:  -0.07255, loss val: 0.07530
[2022-12-06 19:55:10,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:55:11,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:55:11,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:55:20,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:55:30,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:55:40,456] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:55:49,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:55:58,731] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:56:07,874] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:56:16,697] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:56:25,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:56:34,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:56:43,968] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6724297132803815
[2022-12-06 19:56:43,969] [INFO] [runner_train_mujoco] Average state value: 0.6048204933175196
[2022-12-06 19:56:43,969] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 19:56:44,035] [INFO] [controller] EPOCH 1 loss ppo:  -0.00998, loss val: 0.05935
[2022-12-06 19:56:44,087] [INFO] [controller] EPOCH 2 loss ppo:  -0.04201, loss val: 0.05571
[2022-12-06 19:56:44,144] [INFO] [controller] EPOCH 3 loss ppo:  -0.06155, loss val: 0.05365
[2022-12-06 19:56:44,210] [INFO] [controller] EPOCH 4 loss ppo:  -0.07311, loss val: 0.05203
[2022-12-06 19:56:44,220] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:56:44,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:56:44,465] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:56:53,553] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:57:03,413] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:57:12,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:57:21,272] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:57:29,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:57:38,561] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:57:46,532] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:57:54,540] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:58:02,379] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:58:10,099] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.542074317731809
[2022-12-06 19:58:10,100] [INFO] [runner_train_mujoco] Average state value: 0.5437772704164188
[2022-12-06 19:58:10,100] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 19:58:10,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.05555
[2022-12-06 19:58:10,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.03818, loss val: 0.05159
[2022-12-06 19:58:10,239] [INFO] [controller] EPOCH 3 loss ppo:  -0.05590, loss val: 0.05118
[2022-12-06 19:58:10,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.06725, loss val: 0.04520
[2022-12-06 19:58:10,294] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:58:10,510] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:58:10,510] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:58:17,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:58:25,577] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:58:32,678] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:58:39,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:58:47,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:58:53,816] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:59:00,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:59:07,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:59:14,244] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:59:21,143] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6387878642281536
[2022-12-06 19:59:21,143] [INFO] [runner_train_mujoco] Average state value: 0.46766563730190197
[2022-12-06 19:59:21,143] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 19:59:21,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.05534
[2022-12-06 19:59:21,241] [INFO] [controller] EPOCH 2 loss ppo:  -0.04600, loss val: 0.05700
[2022-12-06 19:59:21,339] [INFO] [controller] EPOCH 3 loss ppo:  -0.06422, loss val: 0.05556
[2022-12-06 19:59:21,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.07384, loss val: 0.05462
[2022-12-06 19:59:21,386] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:59:21,591] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:59:21,592] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:59:28,396] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:59:35,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:59:43,146] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:59:50,291] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:59:57,126] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:00:04,207] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:00:11,459] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:00:18,334] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:00:25,491] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:00:32,577] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6132539111615165
[2022-12-06 20:00:32,577] [INFO] [runner_train_mujoco] Average state value: 0.4439052181737497
[2022-12-06 20:00:32,577] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 20:00:32,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.04223
[2022-12-06 20:00:32,662] [INFO] [controller] EPOCH 2 loss ppo:  -0.04577, loss val: 0.04100
[2022-12-06 20:00:32,700] [INFO] [controller] EPOCH 3 loss ppo:  -0.06050, loss val: 0.04495
[2022-12-06 20:00:32,743] [INFO] [controller] EPOCH 4 loss ppo:  -0.07140, loss val: 0.03929
[2022-12-06 20:00:32,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:00:32,970] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:00:32,970] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:00:40,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:00:47,436] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:00:54,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:01:02,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:01:09,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:01:16,842] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:01:23,971] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:01:31,074] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:01:38,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:01:45,802] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7660194540753036
[2022-12-06 20:01:45,802] [INFO] [runner_train_mujoco] Average state value: 0.47166888943562907
[2022-12-06 20:01:45,802] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 20:01:45,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01233, loss val: 0.05876
[2022-12-06 20:01:45,903] [INFO] [controller] EPOCH 2 loss ppo:  -0.03849, loss val: 0.05585
[2022-12-06 20:01:45,947] [INFO] [controller] EPOCH 3 loss ppo:  -0.05686, loss val: 0.05319
[2022-12-06 20:01:45,995] [INFO] [controller] EPOCH 4 loss ppo:  -0.07006, loss val: 0.04631
[2022-12-06 20:01:46,005] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:01:46,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:01:46,214] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:01:53,852] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:02:01,828] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:02:09,321] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:02:17,057] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:02:24,551] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:02:32,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:02:39,825] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:02:47,380] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:02:54,903] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:03:02,366] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48604317658206914
[2022-12-06 20:03:02,366] [INFO] [runner_train_mujoco] Average state value: 0.5423620262046654
[2022-12-06 20:03:02,366] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 20:03:02,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.05261
[2022-12-06 20:03:02,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.03966, loss val: 0.04878
[2022-12-06 20:03:02,502] [INFO] [controller] EPOCH 3 loss ppo:  -0.05763, loss val: 0.04843
[2022-12-06 20:03:02,548] [INFO] [controller] EPOCH 4 loss ppo:  -0.07089, loss val: 0.04826
[2022-12-06 20:03:02,559] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:03:02,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:03:02,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:03:10,319] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:03:17,801] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:03:25,682] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:03:33,343] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:03:41,190] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:03:48,455] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:03:55,464] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:04:02,711] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:04:09,896] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:04:17,386] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6704504036123875
[2022-12-06 20:04:17,386] [INFO] [runner_train_mujoco] Average state value: 0.6239732367495696
[2022-12-06 20:04:17,386] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 20:04:17,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01079, loss val: 0.06527
[2022-12-06 20:04:17,476] [INFO] [controller] EPOCH 2 loss ppo:  -0.03413, loss val: 0.06570
[2022-12-06 20:04:17,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.04733, loss val: 0.06318
[2022-12-06 20:04:17,564] [INFO] [controller] EPOCH 4 loss ppo:  -0.05952, loss val: 0.06062
[2022-12-06 20:04:17,574] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:04:17,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:04:17,772] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:04:25,438] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:04:32,675] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:04:40,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:04:47,310] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:04:55,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:05:02,311] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:05:09,703] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:05:17,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:05:24,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:05:31,253] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4918562052394133
[2022-12-06 20:05:31,254] [INFO] [runner_train_mujoco] Average state value: 0.6112220080296199
[2022-12-06 20:05:31,254] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 20:05:31,301] [INFO] [controller] EPOCH 1 loss ppo:  -0.01078, loss val: 0.04460
[2022-12-06 20:05:31,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.03947, loss val: 0.04147
[2022-12-06 20:05:31,383] [INFO] [controller] EPOCH 3 loss ppo:  -0.05274, loss val: 0.04387
[2022-12-06 20:05:31,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.06707, loss val: 0.04457
[2022-12-06 20:05:31,427] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:05:31,629] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:05:31,629] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:05:38,485] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:05:45,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:05:52,382] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:05:59,607] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:06:06,766] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:06:14,237] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:06:21,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:06:28,111] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:06:34,868] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:06:41,942] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5709960482669715
[2022-12-06 20:06:41,943] [INFO] [runner_train_mujoco] Average state value: 0.5638631003402794
[2022-12-06 20:06:41,943] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 20:06:41,986] [INFO] [controller] EPOCH 1 loss ppo:  -0.00961, loss val: 0.05001
[2022-12-06 20:06:42,028] [INFO] [controller] EPOCH 2 loss ppo:  -0.03707, loss val: 0.05073
[2022-12-06 20:06:42,069] [INFO] [controller] EPOCH 3 loss ppo:  -0.05590, loss val: 0.04696
[2022-12-06 20:06:42,112] [INFO] [controller] EPOCH 4 loss ppo:  -0.06974, loss val: 0.04698
[2022-12-06 20:06:42,121] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:06:42,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:06:42,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:06:49,472] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:06:56,592] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:07:04,249] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:07:12,385] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:07:20,003] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:07:27,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:07:34,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:07:41,111] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:07:47,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:07:54,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7340221354389712
[2022-12-06 20:07:54,984] [INFO] [runner_train_mujoco] Average state value: 0.5205433312356472
[2022-12-06 20:07:54,984] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 20:07:55,035] [INFO] [controller] EPOCH 1 loss ppo:  -0.01090, loss val: 0.03934
[2022-12-06 20:07:55,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.04211, loss val: 0.03983
[2022-12-06 20:07:55,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.06026, loss val: 0.04516
[2022-12-06 20:07:55,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.06832, loss val: 0.04390
[2022-12-06 20:07:55,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:07:55,385] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:07:55,386] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:08:02,503] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:08:09,646] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:08:16,700] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:08:23,710] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:08:30,742] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:08:37,784] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:08:45,074] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:08:52,181] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:08:59,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:09:06,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6109533108188273
[2022-12-06 20:09:06,604] [INFO] [runner_train_mujoco] Average state value: 0.5320577190121015
[2022-12-06 20:09:06,604] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 20:09:06,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.00964, loss val: 0.04355
[2022-12-06 20:09:06,699] [INFO] [controller] EPOCH 2 loss ppo:  -0.04092, loss val: 0.04469
[2022-12-06 20:09:06,734] [INFO] [controller] EPOCH 3 loss ppo:  -0.05636, loss val: 0.04250
[2022-12-06 20:09:06,775] [INFO] [controller] EPOCH 4 loss ppo:  -0.06786, loss val: 0.04278
[2022-12-06 20:09:06,785] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:09:06,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:09:06,998] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:09:14,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:09:21,559] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:09:28,685] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:09:35,784] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:09:43,397] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:09:51,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:09:58,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:10:05,866] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:10:13,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:10:20,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6703669867728965
[2022-12-06 20:10:20,375] [INFO] [runner_train_mujoco] Average state value: 0.5694157169957956
[2022-12-06 20:10:20,375] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 20:10:20,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.03951
[2022-12-06 20:10:20,475] [INFO] [controller] EPOCH 2 loss ppo:  -0.04303, loss val: 0.03970
[2022-12-06 20:10:20,522] [INFO] [controller] EPOCH 3 loss ppo:  -0.06172, loss val: 0.03935
[2022-12-06 20:10:20,562] [INFO] [controller] EPOCH 4 loss ppo:  -0.07416, loss val: 0.03879
[2022-12-06 20:10:20,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:10:20,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:10:20,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:10:27,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:10:35,470] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:10:43,201] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:10:50,826] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:10:58,516] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:11:05,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:11:13,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:11:21,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:11:28,910] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:11:36,747] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5697089288873525
[2022-12-06 20:11:36,747] [INFO] [runner_train_mujoco] Average state value: 0.5175252838830153
[2022-12-06 20:11:36,747] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 20:11:36,794] [INFO] [controller] EPOCH 1 loss ppo:  -0.01089, loss val: 0.12618
[2022-12-06 20:11:36,838] [INFO] [controller] EPOCH 2 loss ppo:  -0.03886, loss val: 0.12351
[2022-12-06 20:11:36,886] [INFO] [controller] EPOCH 3 loss ppo:  -0.05589, loss val: 0.12088
[2022-12-06 20:11:36,931] [INFO] [controller] EPOCH 4 loss ppo:  -0.07004, loss val: 0.11842
[2022-12-06 20:11:36,942] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:11:37,163] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:11:37,164] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:11:45,815] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:11:53,385] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:12:00,576] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:12:07,798] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:12:15,208] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:12:22,802] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:12:30,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:12:37,699] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:12:45,064] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:12:52,555] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7657593076534204
[2022-12-06 20:12:52,555] [INFO] [runner_train_mujoco] Average state value: 0.5583078543345134
[2022-12-06 20:12:52,555] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 20:12:52,611] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.02904
[2022-12-06 20:12:52,651] [INFO] [controller] EPOCH 2 loss ppo:  -0.03782, loss val: 0.03038
[2022-12-06 20:12:52,747] [INFO] [controller] EPOCH 3 loss ppo:  -0.05788, loss val: 0.03146
[2022-12-06 20:12:52,790] [INFO] [controller] EPOCH 4 loss ppo:  -0.06985, loss val: 0.03257
[2022-12-06 20:12:52,800] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:12:53,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:12:53,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:13:00,271] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:13:07,559] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:13:14,691] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:13:21,749] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:13:29,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:13:36,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:13:43,659] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:13:50,621] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:13:58,061] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:14:05,579] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9070671605845153
[2022-12-06 20:14:05,580] [INFO] [runner_train_mujoco] Average state value: 0.5440401853124301
[2022-12-06 20:14:05,580] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 20:14:05,629] [INFO] [controller] EPOCH 1 loss ppo:  -0.00984, loss val: 0.04024
[2022-12-06 20:14:05,674] [INFO] [controller] EPOCH 2 loss ppo:  -0.03978, loss val: 0.03992
[2022-12-06 20:14:05,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.06056, loss val: 0.03949
[2022-12-06 20:14:05,760] [INFO] [controller] EPOCH 4 loss ppo:  -0.07302, loss val: 0.03935
[2022-12-06 20:14:05,770] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:14:05,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:14:05,979] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:14:14,601] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:14:21,767] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:14:28,760] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:14:35,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:14:42,413] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:14:49,426] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:14:56,503] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:15:03,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:15:10,259] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:15:17,710] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8879694564632373
[2022-12-06 20:15:17,710] [INFO] [runner_train_mujoco] Average state value: 0.5229190543393294
[2022-12-06 20:15:17,710] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 20:15:17,769] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.03985
[2022-12-06 20:15:17,815] [INFO] [controller] EPOCH 2 loss ppo:  -0.04142, loss val: 0.04075
[2022-12-06 20:15:17,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.05760, loss val: 0.03969
[2022-12-06 20:15:17,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.07289, loss val: 0.03349
[2022-12-06 20:15:17,911] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:15:18,107] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:15:18,108] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:15:25,697] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:15:33,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:15:40,166] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:15:47,174] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:15:54,217] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:16:01,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:16:08,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:16:15,480] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:16:22,260] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:16:29,531] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6942250219061348
[2022-12-06 20:16:29,531] [INFO] [runner_train_mujoco] Average state value: 0.4984545692851146
[2022-12-06 20:16:29,531] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 20:16:29,583] [INFO] [controller] EPOCH 1 loss ppo:  -0.00992, loss val: 0.04150
[2022-12-06 20:16:29,624] [INFO] [controller] EPOCH 2 loss ppo:  -0.04030, loss val: 0.04148
[2022-12-06 20:16:29,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.06102, loss val: 0.04101
[2022-12-06 20:16:29,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.07281, loss val: 0.04043
[2022-12-06 20:16:29,722] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:16:29,931] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:16:29,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:16:37,281] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:16:44,574] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:16:51,750] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:16:58,940] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:17:06,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:17:13,617] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:17:20,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:17:27,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:17:34,958] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:17:42,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6948252263697168
[2022-12-06 20:17:42,173] [INFO] [runner_train_mujoco] Average state value: 0.5191360216196627
[2022-12-06 20:17:42,173] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 20:17:42,226] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.03116
[2022-12-06 20:17:42,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.03947, loss val: 0.03104
[2022-12-06 20:17:42,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.05661, loss val: 0.03080
[2022-12-06 20:17:42,358] [INFO] [controller] EPOCH 4 loss ppo:  -0.07242, loss val: 0.03147
[2022-12-06 20:17:42,366] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:17:42,571] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:17:42,572] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:17:50,100] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:17:57,647] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:18:04,929] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:18:12,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:18:19,380] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:18:27,094] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:18:34,704] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:18:41,902] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:18:49,557] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:18:57,027] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7774804313743742
[2022-12-06 20:18:57,027] [INFO] [runner_train_mujoco] Average state value: 0.5495613051553567
[2022-12-06 20:18:57,027] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 20:18:57,077] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.03239
[2022-12-06 20:18:57,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.03733, loss val: 0.02913
[2022-12-06 20:18:57,173] [INFO] [controller] EPOCH 3 loss ppo:  -0.05519, loss val: 0.02729
[2022-12-06 20:18:57,221] [INFO] [controller] EPOCH 4 loss ppo:  -0.06853, loss val: 0.02692
[2022-12-06 20:18:57,231] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:18:57,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:18:57,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:19:05,537] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:19:13,316] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:19:20,858] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:19:28,448] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:19:35,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:19:43,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:19:50,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:19:56,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:20:03,680] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:20:10,242] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.002215446019107
[2022-12-06 20:20:10,242] [INFO] [runner_train_mujoco] Average state value: 0.5240170184373856
[2022-12-06 20:20:10,242] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 20:20:10,288] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04460
[2022-12-06 20:20:10,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.04228, loss val: 0.04205
[2022-12-06 20:20:10,360] [INFO] [controller] EPOCH 3 loss ppo:  -0.06024, loss val: 0.04541
[2022-12-06 20:20:10,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.07034, loss val: 0.04505
[2022-12-06 20:20:10,412] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:20:10,616] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:20:10,616] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:20:17,468] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:20:24,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:20:30,761] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:20:37,240] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:20:43,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:20:50,457] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:20:56,911] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:21:03,286] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:21:09,794] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:21:16,129] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7820389119351836
[2022-12-06 20:21:16,129] [INFO] [runner_train_mujoco] Average state value: 0.5154445350070794
[2022-12-06 20:21:16,129] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 20:21:16,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01073, loss val: 0.03837
[2022-12-06 20:21:16,233] [INFO] [controller] EPOCH 2 loss ppo:  -0.03778, loss val: 0.03824
[2022-12-06 20:21:16,273] [INFO] [controller] EPOCH 3 loss ppo:  -0.05653, loss val: 0.03882
[2022-12-06 20:21:16,319] [INFO] [controller] EPOCH 4 loss ppo:  -0.06995, loss val: 0.04047
[2022-12-06 20:21:16,329] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:21:16,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:21:16,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:21:22,856] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:21:29,945] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:21:36,161] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:21:42,754] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:21:49,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:21:55,691] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:22:01,987] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:22:08,278] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:22:14,445] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:22:20,690] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8112834681474993
[2022-12-06 20:22:20,691] [INFO] [runner_train_mujoco] Average state value: 0.4998292856117089
[2022-12-06 20:22:20,691] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 20:22:20,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01037, loss val: 0.03905
[2022-12-06 20:22:20,781] [INFO] [controller] EPOCH 2 loss ppo:  -0.03541, loss val: 0.03635
[2022-12-06 20:22:20,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.05088, loss val: 0.03942
[2022-12-06 20:22:20,857] [INFO] [controller] EPOCH 4 loss ppo:  -0.06678, loss val: 0.03913
[2022-12-06 20:22:20,866] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:22:21,054] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:22:21,055] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:22:27,379] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:22:33,765] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:22:40,409] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:22:46,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:22:52,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:22:59,522] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:23:05,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:23:12,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:23:18,864] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:23:25,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.847849304161838
[2022-12-06 20:23:25,109] [INFO] [runner_train_mujoco] Average state value: 0.48412259637316063
[2022-12-06 20:23:25,109] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 20:23:25,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01071, loss val: 0.03551
[2022-12-06 20:23:25,188] [INFO] [controller] EPOCH 2 loss ppo:  -0.03484, loss val: 0.03439
[2022-12-06 20:23:25,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.05245, loss val: 0.03395
[2022-12-06 20:23:25,254] [INFO] [controller] EPOCH 4 loss ppo:  -0.06543, loss val: 0.03475
[2022-12-06 20:23:25,260] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:23:25,457] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:23:25,458] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:23:31,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:23:38,081] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:23:44,849] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:23:51,517] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:23:57,894] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:24:04,474] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:24:10,975] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:24:17,291] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:24:23,924] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:24:30,474] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9704404496224601
[2022-12-06 20:24:30,474] [INFO] [runner_train_mujoco] Average state value: 0.4875811960001787
[2022-12-06 20:24:30,474] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 20:24:30,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.03203
[2022-12-06 20:24:30,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.03821, loss val: 0.03188
[2022-12-06 20:24:30,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.05706, loss val: 0.03114
[2022-12-06 20:24:30,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.07080, loss val: 0.03106
[2022-12-06 20:24:30,645] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:24:30,827] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:24:30,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:24:37,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:24:43,927] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:24:50,695] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:24:57,410] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:25:04,107] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:25:10,884] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:25:17,415] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:25:24,116] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:25:30,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:25:37,038] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.097049972101572
[2022-12-06 20:25:37,039] [INFO] [runner_train_mujoco] Average state value: 0.4872154511511325
[2022-12-06 20:25:37,039] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 20:25:37,081] [INFO] [controller] EPOCH 1 loss ppo:  -0.01170, loss val: 0.03232
[2022-12-06 20:25:37,118] [INFO] [controller] EPOCH 2 loss ppo:  -0.03633, loss val: 0.03040
[2022-12-06 20:25:37,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.05430, loss val: 0.03050
[2022-12-06 20:25:37,275] [INFO] [controller] EPOCH 4 loss ppo:  -0.07137, loss val: 0.02975
[2022-12-06 20:25:37,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:25:37,465] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:25:37,466] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:25:44,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:25:50,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:25:56,955] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:26:03,962] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:26:10,574] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:26:17,263] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:26:23,751] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:26:30,346] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:26:36,584] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:26:42,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.977015642694045
[2022-12-06 20:26:42,978] [INFO] [runner_train_mujoco] Average state value: 0.46709054203766087
[2022-12-06 20:26:42,978] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 20:26:43,028] [INFO] [controller] EPOCH 1 loss ppo:  -0.01131, loss val: 0.03839
[2022-12-06 20:26:43,078] [INFO] [controller] EPOCH 2 loss ppo:  -0.03716, loss val: 0.03762
[2022-12-06 20:26:43,109] [INFO] [controller] EPOCH 3 loss ppo:  -0.05693, loss val: 0.03764
[2022-12-06 20:26:43,145] [INFO] [controller] EPOCH 4 loss ppo:  -0.06946, loss val: 0.03832
[2022-12-06 20:26:43,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:26:43,326] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:26:43,327] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:26:49,693] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:26:56,089] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:27:02,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:27:08,888] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:27:15,402] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:27:21,925] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:27:28,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:27:34,995] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:27:41,237] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:27:47,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2266034871270302
[2022-12-06 20:27:47,384] [INFO] [runner_train_mujoco] Average state value: 0.4466613878707091
[2022-12-06 20:27:47,384] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 20:27:47,431] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04225
[2022-12-06 20:27:47,471] [INFO] [controller] EPOCH 2 loss ppo:  -0.03720, loss val: 0.04184
[2022-12-06 20:27:47,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.05314, loss val: 0.04100
[2022-12-06 20:27:47,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.06798, loss val: 0.04046
[2022-12-06 20:27:47,549] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:27:47,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:27:47,736] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:27:53,903] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:28:00,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:28:06,220] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:28:12,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:28:18,971] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:28:25,291] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:28:31,604] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:28:37,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:28:43,975] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:28:50,142] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2171299920094731
[2022-12-06 20:28:50,142] [INFO] [runner_train_mujoco] Average state value: 0.46841566749165453
[2022-12-06 20:28:50,143] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 20:28:50,189] [INFO] [controller] EPOCH 1 loss ppo:  -0.01101, loss val: 0.04358
[2022-12-06 20:28:50,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.02705, loss val: 0.03679
[2022-12-06 20:28:50,269] [INFO] [controller] EPOCH 3 loss ppo:  -0.04376, loss val: 0.03360
[2022-12-06 20:28:50,309] [INFO] [controller] EPOCH 4 loss ppo:  -0.05880, loss val: 0.03341
[2022-12-06 20:28:50,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:28:50,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:28:50,495] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:28:56,881] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:29:03,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:29:09,656] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:29:15,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:29:22,408] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:29:28,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:29:35,572] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:29:41,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:29:48,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:29:54,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3419623828631972
[2022-12-06 20:29:54,459] [INFO] [runner_train_mujoco] Average state value: 0.5238001929918925
[2022-12-06 20:29:54,459] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 20:29:54,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04130
[2022-12-06 20:29:54,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.03311, loss val: 0.04298
[2022-12-06 20:29:54,590] [INFO] [controller] EPOCH 3 loss ppo:  -0.05287, loss val: 0.04451
[2022-12-06 20:29:54,634] [INFO] [controller] EPOCH 4 loss ppo:  -0.06688, loss val: 0.04461
[2022-12-06 20:29:54,643] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:29:54,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:29:54,834] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:30:01,229] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:30:07,519] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:30:13,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:30:20,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:30:26,603] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:30:33,354] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:30:40,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:30:46,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:30:53,519] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:31:00,129] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1144149470997757
[2022-12-06 20:31:00,130] [INFO] [runner_train_mujoco] Average state value: 0.5219533721506596
[2022-12-06 20:31:00,130] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 20:31:00,179] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.05339
[2022-12-06 20:31:00,218] [INFO] [controller] EPOCH 2 loss ppo:  -0.03479, loss val: 0.05371
[2022-12-06 20:31:00,264] [INFO] [controller] EPOCH 3 loss ppo:  -0.05639, loss val: 0.05414
[2022-12-06 20:31:00,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.07118, loss val: 0.05272
[2022-12-06 20:31:00,320] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:31:00,519] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:31:00,519] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:31:07,173] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:31:13,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:31:20,073] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:31:26,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:31:33,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:31:40,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:31:47,274] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:31:54,222] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:32:00,743] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:32:07,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1786969825929412
[2022-12-06 20:32:07,040] [INFO] [runner_train_mujoco] Average state value: 0.545310218182703
[2022-12-06 20:32:07,040] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 20:32:07,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.03617
[2022-12-06 20:32:07,119] [INFO] [controller] EPOCH 2 loss ppo:  -0.03486, loss val: 0.03683
[2022-12-06 20:32:07,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.05086, loss val: 0.03691
[2022-12-06 20:32:07,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.06530, loss val: 0.03523
[2022-12-06 20:32:07,211] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:32:07,383] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:32:07,383] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:32:13,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:32:20,422] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:32:26,839] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:32:33,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:32:39,396] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:32:45,705] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:32:52,324] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:32:58,717] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:33:05,109] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:33:11,494] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3775706053693662
[2022-12-06 20:33:11,494] [INFO] [runner_train_mujoco] Average state value: 0.5358598658144474
[2022-12-06 20:33:11,494] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 20:33:11,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.03743
[2022-12-06 20:33:11,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.04021, loss val: 0.03669
[2022-12-06 20:33:11,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.05800, loss val: 0.03517
[2022-12-06 20:33:11,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.07273, loss val: 0.03451
[2022-12-06 20:33:11,670] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:33:11,841] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:33:11,842] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:33:18,264] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:33:24,740] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:33:30,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:33:36,796] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:33:42,862] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:33:48,872] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:33:55,147] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:34:01,931] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:34:08,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:34:14,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4947909657518876
[2022-12-06 20:34:14,659] [INFO] [runner_train_mujoco] Average state value: 0.4971960471173128
[2022-12-06 20:34:14,659] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 20:34:14,706] [INFO] [controller] EPOCH 1 loss ppo:  -0.01182, loss val: 0.03601
[2022-12-06 20:34:14,746] [INFO] [controller] EPOCH 2 loss ppo:  -0.03021, loss val: 0.03607
[2022-12-06 20:34:14,786] [INFO] [controller] EPOCH 3 loss ppo:  -0.04669, loss val: 0.03579
[2022-12-06 20:34:14,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.06114, loss val: 0.04198
[2022-12-06 20:34:14,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:34:15,003] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:34:15,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:34:21,219] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:34:27,604] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:34:33,703] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:34:39,763] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:34:45,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:34:52,015] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:34:58,290] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:35:05,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:35:11,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:35:17,876] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8981197946866857
[2022-12-06 20:35:17,876] [INFO] [runner_train_mujoco] Average state value: 0.4905571669023484
[2022-12-06 20:35:17,876] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 20:35:17,925] [INFO] [controller] EPOCH 1 loss ppo:  -0.01147, loss val: 0.03039
[2022-12-06 20:35:17,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.02748, loss val: 0.03120
[2022-12-06 20:35:17,998] [INFO] [controller] EPOCH 3 loss ppo:  -0.04815, loss val: 0.03107
[2022-12-06 20:35:18,038] [INFO] [controller] EPOCH 4 loss ppo:  -0.06433, loss val: 0.02888
[2022-12-06 20:35:18,046] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:35:18,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:35:18,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:35:24,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:35:31,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:35:37,292] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:35:43,595] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:35:49,812] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:35:55,968] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:36:02,210] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:36:08,866] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:36:15,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:36:22,132] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8130207608911835
[2022-12-06 20:36:22,132] [INFO] [runner_train_mujoco] Average state value: 0.5191485072076322
[2022-12-06 20:36:22,132] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 20:36:22,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.04208
[2022-12-06 20:36:22,221] [INFO] [controller] EPOCH 2 loss ppo:  -0.03855, loss val: 0.04162
[2022-12-06 20:36:22,267] [INFO] [controller] EPOCH 3 loss ppo:  -0.05754, loss val: 0.04281
[2022-12-06 20:36:22,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.07061, loss val: 0.04170
[2022-12-06 20:36:22,320] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:36:22,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:36:22,488] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:36:29,168] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:36:35,700] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:36:42,046] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:36:48,276] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:36:54,717] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:37:01,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:37:07,489] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:37:14,505] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:37:21,148] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:37:27,985] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7346399228978258
[2022-12-06 20:37:27,986] [INFO] [runner_train_mujoco] Average state value: 0.49638249374926086
[2022-12-06 20:37:27,986] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 20:37:28,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.05653
[2022-12-06 20:37:28,079] [INFO] [controller] EPOCH 2 loss ppo:  -0.03502, loss val: 0.05588
[2022-12-06 20:37:28,188] [INFO] [controller] EPOCH 3 loss ppo:  -0.05345, loss val: 0.05576
[2022-12-06 20:37:28,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.06621, loss val: 0.05656
[2022-12-06 20:37:28,243] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:37:28,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:37:28,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:37:35,115] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:37:41,652] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:37:48,109] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:37:54,672] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:38:01,180] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:38:07,626] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:38:13,989] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:38:20,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:38:27,212] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:38:33,976] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0812755847755637
[2022-12-06 20:38:33,976] [INFO] [runner_train_mujoco] Average state value: 0.5233324191868304
[2022-12-06 20:38:33,976] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 20:38:34,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.01267, loss val: 0.04334
[2022-12-06 20:38:34,071] [INFO] [controller] EPOCH 2 loss ppo:  -0.03010, loss val: 0.04436
[2022-12-06 20:38:34,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.05100, loss val: 0.04278
[2022-12-06 20:38:34,165] [INFO] [controller] EPOCH 4 loss ppo:  -0.06519, loss val: 0.04254
[2022-12-06 20:38:34,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:38:34,372] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:38:34,372] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:38:40,931] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:38:47,550] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:38:53,782] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:39:00,071] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:39:06,436] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:39:12,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:39:18,997] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:39:25,455] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:39:32,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:39:38,571] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8328039944901948
[2022-12-06 20:39:38,572] [INFO] [runner_train_mujoco] Average state value: 0.4885008186871806
[2022-12-06 20:39:38,572] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 20:39:38,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.07428
[2022-12-06 20:39:38,657] [INFO] [controller] EPOCH 2 loss ppo:  -0.03189, loss val: 0.07318
[2022-12-06 20:39:38,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.04971, loss val: 0.07128
[2022-12-06 20:39:38,737] [INFO] [controller] EPOCH 4 loss ppo:  -0.06178, loss val: 0.07200
[2022-12-06 20:39:38,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:39:38,931] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:39:38,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:39:45,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:39:52,165] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:39:58,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:40:05,036] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:40:11,321] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:40:17,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:40:23,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:40:29,963] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:40:36,505] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:40:42,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7962538760517393
[2022-12-06 20:40:42,626] [INFO] [runner_train_mujoco] Average state value: 0.4748602216268579
[2022-12-06 20:40:42,626] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 20:40:42,674] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.06931
[2022-12-06 20:40:42,716] [INFO] [controller] EPOCH 2 loss ppo:  -0.02896, loss val: 0.07505
[2022-12-06 20:40:42,759] [INFO] [controller] EPOCH 3 loss ppo:  -0.04721, loss val: 0.07450
[2022-12-06 20:40:42,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.05893, loss val: 0.07390
[2022-12-06 20:40:42,812] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:40:43,003] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:40:43,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:40:49,584] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:40:55,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:41:02,260] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:41:09,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:41:15,921] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:41:21,880] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:41:27,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:41:34,259] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:41:40,608] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:41:46,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.256557028273409
[2022-12-06 20:41:46,919] [INFO] [runner_train_mujoco] Average state value: 0.48803859678407513
[2022-12-06 20:41:46,919] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 20:41:46,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.06905
[2022-12-06 20:41:47,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.02999, loss val: 0.06811
[2022-12-06 20:41:47,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.05079, loss val: 0.06796
[2022-12-06 20:41:47,083] [INFO] [controller] EPOCH 4 loss ppo:  -0.06453, loss val: 0.06661
[2022-12-06 20:41:47,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:41:47,276] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:41:47,276] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:41:53,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:41:59,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:42:06,095] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:42:12,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:42:18,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:42:24,513] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:42:30,851] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:42:37,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:42:43,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:42:50,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5398267571446995
[2022-12-06 20:42:50,367] [INFO] [runner_train_mujoco] Average state value: 0.5418205293118954
[2022-12-06 20:42:50,367] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 20:42:50,410] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04502
[2022-12-06 20:42:50,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.03067, loss val: 0.04478
[2022-12-06 20:42:50,495] [INFO] [controller] EPOCH 3 loss ppo:  -0.05257, loss val: 0.04491
[2022-12-06 20:42:50,540] [INFO] [controller] EPOCH 4 loss ppo:  -0.06527, loss val: 0.04562
[2022-12-06 20:42:50,549] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:42:50,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:42:50,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:42:57,249] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:43:03,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:43:10,092] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:43:16,511] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:43:23,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:43:30,067] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:43:36,358] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:43:42,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:43:49,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:43:56,125] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3281284831121485
[2022-12-06 20:43:56,125] [INFO] [runner_train_mujoco] Average state value: 0.504123933378607
[2022-12-06 20:43:56,125] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 20:43:56,172] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.06920
[2022-12-06 20:43:56,216] [INFO] [controller] EPOCH 2 loss ppo:  -0.02763, loss val: 0.06879
[2022-12-06 20:43:56,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.04324, loss val: 0.06823
[2022-12-06 20:43:56,301] [INFO] [controller] EPOCH 4 loss ppo:  -0.05224, loss val: 0.06766
[2022-12-06 20:43:56,308] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:43:56,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:43:56,483] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:44:03,143] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:44:10,054] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:44:17,281] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:44:24,796] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:44:32,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:44:40,200] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:44:47,652] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:44:55,380] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:45:03,035] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:45:12,056] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7365303856619647
[2022-12-06 20:45:12,056] [INFO] [runner_train_mujoco] Average state value: 0.49901727934926743
[2022-12-06 20:45:12,057] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 20:45:12,108] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.07593
[2022-12-06 20:45:12,155] [INFO] [controller] EPOCH 2 loss ppo:  -0.02765, loss val: 0.07687
[2022-12-06 20:45:12,199] [INFO] [controller] EPOCH 3 loss ppo:  -0.04433, loss val: 0.07889
[2022-12-06 20:45:12,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.05465, loss val: 0.07666
[2022-12-06 20:45:12,262] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:45:12,508] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:45:12,509] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:45:20,483] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:45:29,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:45:38,206] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:45:46,451] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:45:54,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:46:02,517] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:46:10,609] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:46:19,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:46:27,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:46:35,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6303858299834095
[2022-12-06 20:46:35,971] [INFO] [runner_train_mujoco] Average state value: 0.44066385681306314
[2022-12-06 20:46:35,971] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 20:46:36,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.11866
[2022-12-06 20:46:36,059] [INFO] [controller] EPOCH 2 loss ppo:  -0.02390, loss val: 0.11501
[2022-12-06 20:46:36,103] [INFO] [controller] EPOCH 3 loss ppo:  -0.03903, loss val: 0.11319
[2022-12-06 20:46:36,148] [INFO] [controller] EPOCH 4 loss ppo:  -0.05145, loss val: 0.11369
[2022-12-06 20:46:36,158] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:46:36,360] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:46:36,360] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:46:43,706] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:46:50,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:46:57,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:47:05,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:47:12,226] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:47:19,456] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:47:26,515] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:47:33,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:47:40,815] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:47:48,134] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0983971470859135
[2022-12-06 20:47:48,134] [INFO] [runner_train_mujoco] Average state value: 0.5275223793710271
[2022-12-06 20:47:48,134] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 20:47:48,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.04513
[2022-12-06 20:47:48,231] [INFO] [controller] EPOCH 2 loss ppo:  -0.02606, loss val: 0.04510
[2022-12-06 20:47:48,275] [INFO] [controller] EPOCH 3 loss ppo:  -0.04309, loss val: 0.04498
[2022-12-06 20:47:48,316] [INFO] [controller] EPOCH 4 loss ppo:  -0.05661, loss val: 0.04498
[2022-12-06 20:47:48,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:47:48,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:47:48,535] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:47:55,985] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:48:02,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:48:10,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:48:17,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:48:24,980] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:48:32,486] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:48:39,645] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:48:46,990] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:48:54,482] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:49:02,130] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.906765684368965
[2022-12-06 20:49:02,130] [INFO] [runner_train_mujoco] Average state value: 0.41352959583575527
[2022-12-06 20:49:02,130] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 20:49:02,185] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.10716
[2022-12-06 20:49:02,231] [INFO] [controller] EPOCH 2 loss ppo:  -0.02354, loss val: 0.10640
[2022-12-06 20:49:02,274] [INFO] [controller] EPOCH 3 loss ppo:  -0.03785, loss val: 0.10543
[2022-12-06 20:49:02,322] [INFO] [controller] EPOCH 4 loss ppo:  -0.04954, loss val: 0.10642
[2022-12-06 20:49:02,332] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:49:02,547] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:49:02,547] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:49:10,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:49:18,472] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:49:26,170] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:49:33,389] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:49:40,898] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:49:47,905] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:49:55,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:50:02,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:50:10,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:50:17,277] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1745544193029707
[2022-12-06 20:50:17,277] [INFO] [runner_train_mujoco] Average state value: 0.4806831070159873
[2022-12-06 20:50:17,277] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 20:50:17,327] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04997
[2022-12-06 20:50:17,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.02276, loss val: 0.04977
[2022-12-06 20:50:17,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.03727, loss val: 0.04900
[2022-12-06 20:50:17,512] [INFO] [controller] EPOCH 4 loss ppo:  -0.05036, loss val: 0.04872
[2022-12-06 20:50:17,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:50:17,727] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:50:17,727] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:50:25,273] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:50:32,933] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:50:40,122] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:50:47,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:50:54,020] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:51:01,502] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:51:08,858] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:51:15,961] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:51:22,846] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:51:29,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5435556736889273
[2022-12-06 20:51:29,721] [INFO] [runner_train_mujoco] Average state value: 0.4645135018924872
[2022-12-06 20:51:29,721] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 20:51:29,770] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.06360
[2022-12-06 20:51:29,813] [INFO] [controller] EPOCH 2 loss ppo:  -0.02152, loss val: 0.06336
[2022-12-06 20:51:29,855] [INFO] [controller] EPOCH 3 loss ppo:  -0.03298, loss val: 0.06366
[2022-12-06 20:51:29,898] [INFO] [controller] EPOCH 4 loss ppo:  -0.04267, loss val: 0.06323
[2022-12-06 20:51:29,908] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:51:30,113] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:51:30,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:51:37,612] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:51:45,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:51:52,604] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:51:59,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:52:06,418] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:52:13,315] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:52:19,996] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:52:26,860] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:52:33,580] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:52:40,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.788295751771534
[2022-12-06 20:52:40,633] [INFO] [runner_train_mujoco] Average state value: 0.40707704922805227
[2022-12-06 20:52:40,634] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 20:52:40,680] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.11996
[2022-12-06 20:52:40,722] [INFO] [controller] EPOCH 2 loss ppo:  -0.01754, loss val: 0.11178
[2022-12-06 20:52:40,764] [INFO] [controller] EPOCH 3 loss ppo:  -0.02585, loss val: 0.10978
[2022-12-06 20:52:40,816] [INFO] [controller] EPOCH 4 loss ppo:  -0.03610, loss val: 0.11065
[2022-12-06 20:52:40,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:52:41,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:52:41,069] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:52:48,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:52:55,417] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:53:02,653] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:53:09,564] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:53:16,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:53:23,569] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:53:30,261] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:53:37,881] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:53:44,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:53:51,694] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.312658204751551
[2022-12-06 20:53:51,695] [INFO] [runner_train_mujoco] Average state value: 0.40499421860525997
[2022-12-06 20:53:51,695] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 20:53:51,753] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.11343
[2022-12-06 20:53:51,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.01802, loss val: 0.11333
[2022-12-06 20:53:51,833] [INFO] [controller] EPOCH 3 loss ppo:  -0.02546, loss val: 0.11350
[2022-12-06 20:53:51,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.03500, loss val: 0.11244
[2022-12-06 20:53:51,883] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:53:52,097] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:53:52,098] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:53:59,038] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:54:06,439] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:54:13,895] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:54:20,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:54:28,092] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:54:35,316] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:54:42,584] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:54:49,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:54:57,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:55:04,311] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1186278609994624
[2022-12-06 20:55:04,311] [INFO] [runner_train_mujoco] Average state value: 0.4646502688154578
[2022-12-06 20:55:04,311] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 20:55:04,364] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.07321
[2022-12-06 20:55:04,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.01825, loss val: 0.07206
[2022-12-06 20:55:04,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.02502, loss val: 0.07198
[2022-12-06 20:55:04,500] [INFO] [controller] EPOCH 4 loss ppo:  -0.03391, loss val: 0.07218
[2022-12-06 20:55:04,509] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:55:04,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:55:04,722] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:55:12,127] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:55:19,949] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:55:27,944] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:55:35,245] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:55:42,652] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:55:49,852] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:55:57,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:56:05,043] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:56:13,630] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:56:22,142] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.293484353791861
[2022-12-06 20:56:22,142] [INFO] [runner_train_mujoco] Average state value: 0.42379722557092697
[2022-12-06 20:56:22,142] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 20:56:22,211] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.10153
[2022-12-06 20:56:22,263] [INFO] [controller] EPOCH 2 loss ppo:  -0.01619, loss val: 0.10116
[2022-12-06 20:56:22,318] [INFO] [controller] EPOCH 3 loss ppo:  -0.01981, loss val: 0.10015
[2022-12-06 20:56:22,372] [INFO] [controller] EPOCH 4 loss ppo:  -0.02550, loss val: 0.10041
[2022-12-06 20:56:22,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:56:22,593] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:56:22,593] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:56:31,157] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:56:39,842] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:56:48,004] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:56:56,023] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:57:04,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:57:14,327] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:57:23,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:57:32,258] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:57:40,492] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:57:48,296] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1210352941341126
[2022-12-06 20:57:48,296] [INFO] [runner_train_mujoco] Average state value: 0.3824073968107502
[2022-12-06 20:57:48,296] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 20:57:48,362] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.14978
[2022-12-06 20:57:48,407] [INFO] [controller] EPOCH 2 loss ppo:  -0.01452, loss val: 0.14929
[2022-12-06 20:57:48,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.01613, loss val: 0.14663
[2022-12-06 20:57:48,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.01838, loss val: 0.14889
[2022-12-06 20:57:48,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:57:48,627] [INFO] [optimize] Finished learning.
