[2022-12-06 14:43:17,058] [INFO] [optimize] Starting learning
[2022-12-06 14:43:17,075] [INFO] [optimize] Starting learning process..
[2022-12-06 14:43:17,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:43:17,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:43:30,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:43:42,292] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:43:53,541] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:44:05,005] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:44:16,224] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:44:27,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:44:38,244] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:44:49,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:45:01,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:45:14,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5865566588094238
[2022-12-06 14:45:14,171] [INFO] [runner_train_mujoco] Average state value: 0.301400091116627
[2022-12-06 14:45:14,171] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 14:45:15,099] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.27740
[2022-12-06 14:45:15,883] [INFO] [controller] EPOCH 2 loss ppo:  -0.05046, loss val: 0.25230
[2022-12-06 14:45:16,198] [INFO] [controller] EPOCH 3 loss ppo:  -0.06523, loss val: 0.22146
[2022-12-06 14:45:16,348] [INFO] [controller] EPOCH 4 loss ppo:  -0.07544, loss val: 0.20639
[2022-12-06 14:45:16,365] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:45:16,685] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:45:16,686] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:45:28,974] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:45:40,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:45:52,566] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:46:04,905] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:46:16,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:46:28,939] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:46:41,627] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:46:53,745] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:47:06,278] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:47:18,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7042837892742966
[2022-12-06 14:47:18,272] [INFO] [runner_train_mujoco] Average state value: 0.443518635119622
[2022-12-06 14:47:18,272] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 14:47:18,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.17770
[2022-12-06 14:47:18,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.04731, loss val: 0.16151
[2022-12-06 14:47:18,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.06402, loss val: 0.14990
[2022-12-06 14:47:18,541] [INFO] [controller] EPOCH 4 loss ppo:  -0.07294, loss val: 0.13937
[2022-12-06 14:47:18,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:47:18,828] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:47:18,828] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:47:32,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:47:44,351] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:47:57,261] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:48:09,745] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:48:21,537] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:48:33,636] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:48:45,217] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:48:57,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:49:08,680] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:49:20,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5537269432408377
[2022-12-06 14:49:20,819] [INFO] [runner_train_mujoco] Average state value: 0.5705060259389381
[2022-12-06 14:49:20,819] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 14:49:20,989] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.13723
[2022-12-06 14:49:21,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.04843, loss val: 0.12954
[2022-12-06 14:49:21,300] [INFO] [controller] EPOCH 3 loss ppo:  -0.06640, loss val: 0.12315
[2022-12-06 14:49:21,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.07865, loss val: 0.11600
[2022-12-06 14:49:21,403] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:49:21,670] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:49:21,671] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:49:33,379] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:49:44,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:49:55,779] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:50:06,381] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:50:17,444] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:50:28,348] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:50:38,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:50:50,917] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:51:02,295] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:51:13,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5105161810091287
[2022-12-06 14:51:13,521] [INFO] [runner_train_mujoco] Average state value: 0.5801145003189643
[2022-12-06 14:51:13,521] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 14:51:13,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.00945, loss val: 0.11263
[2022-12-06 14:51:13,661] [INFO] [controller] EPOCH 2 loss ppo:  -0.03816, loss val: 0.10535
[2022-12-06 14:51:13,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.05625, loss val: 0.09976
[2022-12-06 14:51:13,819] [INFO] [controller] EPOCH 4 loss ppo:  -0.07072, loss val: 0.09150
[2022-12-06 14:51:13,832] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:51:14,098] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:51:14,099] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:51:25,451] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:51:36,326] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:51:46,834] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:51:58,101] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:52:09,963] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:52:20,817] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:52:32,572] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:52:44,161] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:52:55,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:53:06,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.59515346594556
[2022-12-06 14:53:06,986] [INFO] [runner_train_mujoco] Average state value: 0.49299822649918507
[2022-12-06 14:53:06,986] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 14:53:07,070] [INFO] [controller] EPOCH 1 loss ppo:  -0.01262, loss val: 0.08092
[2022-12-06 14:53:07,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.04587, loss val: 0.08102
[2022-12-06 14:53:07,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.06306, loss val: 0.07296
[2022-12-06 14:53:07,366] [INFO] [controller] EPOCH 4 loss ppo:  -0.07411, loss val: 0.07037
[2022-12-06 14:53:07,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:53:07,659] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:53:07,660] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:53:20,200] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:53:33,484] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:53:45,851] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:53:57,781] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:54:09,417] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:54:21,429] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:54:34,470] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:54:46,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:54:59,035] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:55:11,193] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6353277536895405
[2022-12-06 14:55:11,194] [INFO] [runner_train_mujoco] Average state value: 0.45293875747794904
[2022-12-06 14:55:11,194] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 14:55:11,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.09324
[2022-12-06 14:55:11,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.03564, loss val: 0.08945
[2022-12-06 14:55:11,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.05061, loss val: 0.08524
[2022-12-06 14:55:11,501] [INFO] [controller] EPOCH 4 loss ppo:  -0.06736, loss val: 0.07875
[2022-12-06 14:55:11,517] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:55:11,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:55:11,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:55:23,123] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:55:33,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:55:43,512] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:55:52,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:56:01,897] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:56:11,630] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:56:21,007] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:56:29,962] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:56:39,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:56:49,443] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.524196258981845
[2022-12-06 14:56:49,444] [INFO] [runner_train_mujoco] Average state value: 0.5021472925795242
[2022-12-06 14:56:49,444] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 14:56:49,515] [INFO] [controller] EPOCH 1 loss ppo:  -0.01146, loss val: 0.06193
[2022-12-06 14:56:49,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.04462, loss val: 0.06037
[2022-12-06 14:56:49,627] [INFO] [controller] EPOCH 3 loss ppo:  -0.05754, loss val: 0.06044
[2022-12-06 14:56:49,681] [INFO] [controller] EPOCH 4 loss ppo:  -0.07235, loss val: 0.05705
[2022-12-06 14:56:49,693] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:56:49,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:56:49,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:56:58,806] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:57:08,292] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:57:16,796] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:57:25,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:57:33,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:57:40,418] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:57:48,247] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:57:55,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:58:03,398] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:58:11,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6671009523985102
[2022-12-06 14:58:11,169] [INFO] [runner_train_mujoco] Average state value: 0.5505258810197314
[2022-12-06 14:58:11,169] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 14:58:11,223] [INFO] [controller] EPOCH 1 loss ppo:  -0.00884, loss val: 0.06687
[2022-12-06 14:58:11,264] [INFO] [controller] EPOCH 2 loss ppo:  -0.03883, loss val: 0.06514
[2022-12-06 14:58:11,383] [INFO] [controller] EPOCH 3 loss ppo:  -0.06092, loss val: 0.06378
[2022-12-06 14:58:11,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.07426, loss val: 0.06138
[2022-12-06 14:58:11,437] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:58:11,659] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:58:11,659] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:58:20,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:58:28,181] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:58:35,851] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:58:43,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:58:51,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:58:59,540] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:59:07,506] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:59:15,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:59:23,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:59:31,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7363081630485259
[2022-12-06 14:59:31,516] [INFO] [runner_train_mujoco] Average state value: 0.5164108612822991
[2022-12-06 14:59:31,516] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 14:59:31,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.05984
[2022-12-06 14:59:31,611] [INFO] [controller] EPOCH 2 loss ppo:  -0.03979, loss val: 0.05919
[2022-12-06 14:59:31,658] [INFO] [controller] EPOCH 3 loss ppo:  -0.05727, loss val: 0.05750
[2022-12-06 14:59:31,703] [INFO] [controller] EPOCH 4 loss ppo:  -0.06838, loss val: 0.05551
[2022-12-06 14:59:31,713] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:59:31,927] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:59:31,928] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:59:39,965] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:59:48,038] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:59:56,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:00:04,532] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:00:12,573] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:00:20,391] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:00:27,868] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:00:35,314] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:00:43,085] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:00:50,709] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6375174564872902
[2022-12-06 15:00:50,709] [INFO] [runner_train_mujoco] Average state value: 0.5355133834040412
[2022-12-06 15:00:50,709] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 15:00:50,759] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.05219
[2022-12-06 15:00:50,802] [INFO] [controller] EPOCH 2 loss ppo:  -0.04327, loss val: 0.05227
[2022-12-06 15:00:50,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.05870, loss val: 0.05309
[2022-12-06 15:00:50,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.07338, loss val: 0.04987
[2022-12-06 15:00:50,899] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:00:51,106] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:00:51,106] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:01:00,098] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:01:09,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:01:19,727] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:01:28,570] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:01:35,699] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:01:43,024] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:01:50,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:01:57,914] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:02:08,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:02:18,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7222099538665147
[2022-12-06 15:02:18,505] [INFO] [runner_train_mujoco] Average state value: 0.5412346962690353
[2022-12-06 15:02:18,506] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 15:02:18,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.05495
[2022-12-06 15:02:18,613] [INFO] [controller] EPOCH 2 loss ppo:  -0.04203, loss val: 0.05500
[2022-12-06 15:02:18,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.05858, loss val: 0.05336
[2022-12-06 15:02:18,716] [INFO] [controller] EPOCH 4 loss ppo:  -0.07072, loss val: 0.05047
[2022-12-06 15:02:18,724] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:02:18,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:02:18,950] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:02:27,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:02:35,593] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:02:43,213] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:02:51,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:02:59,144] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:03:06,963] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:03:14,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:03:22,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:03:29,616] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:03:37,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6978747100414108
[2022-12-06 15:03:37,254] [INFO] [runner_train_mujoco] Average state value: 0.5714983364741009
[2022-12-06 15:03:37,254] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 15:03:37,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01071, loss val: 0.05240
[2022-12-06 15:03:37,354] [INFO] [controller] EPOCH 2 loss ppo:  -0.04011, loss val: 0.05706
[2022-12-06 15:03:37,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.05534, loss val: 0.05282
[2022-12-06 15:03:37,451] [INFO] [controller] EPOCH 4 loss ppo:  -0.06827, loss val: 0.05367
[2022-12-06 15:03:37,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:03:37,662] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:03:37,663] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:03:45,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:03:53,684] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:04:01,653] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:04:10,111] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:04:19,594] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:04:26,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:04:33,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:04:40,777] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:04:48,821] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:04:57,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.751731621634039
[2022-12-06 15:04:57,515] [INFO] [runner_train_mujoco] Average state value: 0.5642868907948335
[2022-12-06 15:04:57,515] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 15:04:57,596] [INFO] [controller] EPOCH 1 loss ppo:  -0.01090, loss val: 0.03664
[2022-12-06 15:04:57,689] [INFO] [controller] EPOCH 2 loss ppo:  -0.04583, loss val: 0.03870
[2022-12-06 15:04:57,754] [INFO] [controller] EPOCH 3 loss ppo:  -0.06626, loss val: 0.03837
[2022-12-06 15:04:57,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.07932, loss val: 0.03783
[2022-12-06 15:04:57,822] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:04:58,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:04:58,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:05:07,531] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:05:15,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:05:22,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:05:29,816] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:05:36,916] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:05:44,535] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:05:52,262] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:06:01,875] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:06:09,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:06:16,099] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7530410681952825
[2022-12-06 15:06:16,099] [INFO] [runner_train_mujoco] Average state value: 0.5484672311941782
[2022-12-06 15:06:16,100] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 15:06:16,148] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.05011
[2022-12-06 15:06:16,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.04620, loss val: 0.04728
[2022-12-06 15:06:16,231] [INFO] [controller] EPOCH 3 loss ppo:  -0.06479, loss val: 0.04705
[2022-12-06 15:06:16,275] [INFO] [controller] EPOCH 4 loss ppo:  -0.07802, loss val: 0.04674
[2022-12-06 15:06:16,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:06:16,488] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:06:16,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:06:24,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:06:31,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:06:39,918] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:06:48,179] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:06:55,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:07:02,943] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:07:10,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:07:18,466] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:07:25,231] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:07:31,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7587678117078344
[2022-12-06 15:07:31,780] [INFO] [runner_train_mujoco] Average state value: 0.5403413900832336
[2022-12-06 15:07:31,781] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 15:07:31,841] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.04200
[2022-12-06 15:07:31,881] [INFO] [controller] EPOCH 2 loss ppo:  -0.04191, loss val: 0.04156
[2022-12-06 15:07:31,923] [INFO] [controller] EPOCH 3 loss ppo:  -0.05909, loss val: 0.04047
[2022-12-06 15:07:31,971] [INFO] [controller] EPOCH 4 loss ppo:  -0.06814, loss val: 0.03932
[2022-12-06 15:07:31,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:07:32,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:07:32,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:07:39,160] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:07:46,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:07:53,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:07:59,841] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:08:06,952] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:08:14,056] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:08:21,019] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:08:28,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:08:35,199] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:08:41,896] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0834670619052837
[2022-12-06 15:08:41,896] [INFO] [runner_train_mujoco] Average state value: 0.5709695871273677
[2022-12-06 15:08:41,896] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 15:08:41,941] [INFO] [controller] EPOCH 1 loss ppo:  -0.01220, loss val: 0.03527
[2022-12-06 15:08:41,978] [INFO] [controller] EPOCH 2 loss ppo:  -0.03988, loss val: 0.03523
[2022-12-06 15:08:42,022] [INFO] [controller] EPOCH 3 loss ppo:  -0.05696, loss val: 0.03528
[2022-12-06 15:08:42,065] [INFO] [controller] EPOCH 4 loss ppo:  -0.06937, loss val: 0.03406
[2022-12-06 15:08:42,074] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:08:42,253] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:08:42,253] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:08:50,110] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:08:56,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:09:05,551] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:09:12,486] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:09:19,544] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:09:26,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:09:33,595] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:09:40,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:09:47,448] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:09:56,204] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6433470739788655
[2022-12-06 15:09:56,204] [INFO] [runner_train_mujoco] Average state value: 0.5579995023409525
[2022-12-06 15:09:56,204] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 15:09:56,260] [INFO] [controller] EPOCH 1 loss ppo:  -0.01070, loss val: 0.04099
[2022-12-06 15:09:56,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.03781, loss val: 0.03685
[2022-12-06 15:09:56,345] [INFO] [controller] EPOCH 3 loss ppo:  -0.05590, loss val: 0.03950
[2022-12-06 15:09:56,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.06955, loss val: 0.03126
[2022-12-06 15:09:56,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:09:56,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:09:56,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:10:06,312] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:10:13,071] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:10:19,949] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:10:27,806] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:10:34,536] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:10:42,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:10:49,644] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:10:57,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:11:04,320] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:11:11,428] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8639518656652567
[2022-12-06 15:11:11,429] [INFO] [runner_train_mujoco] Average state value: 0.4769958814332882
[2022-12-06 15:11:11,429] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 15:11:11,479] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.05471
[2022-12-06 15:11:11,521] [INFO] [controller] EPOCH 2 loss ppo:  -0.03953, loss val: 0.04862
[2022-12-06 15:11:11,565] [INFO] [controller] EPOCH 3 loss ppo:  -0.05552, loss val: 0.04971
[2022-12-06 15:11:11,604] [INFO] [controller] EPOCH 4 loss ppo:  -0.06769, loss val: 0.05604
[2022-12-06 15:11:11,613] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:11:11,825] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:11:11,825] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:11:19,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:11:27,903] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:11:37,434] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:11:44,899] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:11:51,864] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:11:59,369] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:12:06,915] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:12:16,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:12:25,440] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:12:33,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.218333923613163
[2022-12-06 15:12:33,640] [INFO] [runner_train_mujoco] Average state value: 0.46636521409203596
[2022-12-06 15:12:33,641] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 15:12:33,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04968
[2022-12-06 15:12:33,749] [INFO] [controller] EPOCH 2 loss ppo:  -0.04768, loss val: 0.04757
[2022-12-06 15:12:33,873] [INFO] [controller] EPOCH 3 loss ppo:  -0.06605, loss val: 0.04659
[2022-12-06 15:12:33,928] [INFO] [controller] EPOCH 4 loss ppo:  -0.07934, loss val: 0.04461
[2022-12-06 15:12:33,940] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:12:34,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:12:34,170] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:12:43,730] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:12:51,440] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:12:59,813] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:13:07,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:13:16,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:13:24,436] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:13:32,088] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:13:39,601] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:13:46,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:13:54,429] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2089012594356743
[2022-12-06 15:13:54,430] [INFO] [runner_train_mujoco] Average state value: 0.5368519894387573
[2022-12-06 15:13:54,430] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 15:13:54,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01166, loss val: 0.03796
[2022-12-06 15:13:54,535] [INFO] [controller] EPOCH 2 loss ppo:  -0.03989, loss val: 0.03899
[2022-12-06 15:13:54,582] [INFO] [controller] EPOCH 3 loss ppo:  -0.05825, loss val: 0.03844
[2022-12-06 15:13:54,628] [INFO] [controller] EPOCH 4 loss ppo:  -0.07325, loss val: 0.03815
[2022-12-06 15:13:54,638] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:13:54,857] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:13:54,857] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:14:02,649] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:14:10,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:14:17,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:14:25,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:14:33,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:14:41,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:14:49,650] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:14:58,480] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:15:07,577] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:15:17,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0881158936687083
[2022-12-06 15:15:17,042] [INFO] [runner_train_mujoco] Average state value: 0.5519330578247706
[2022-12-06 15:15:17,042] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 15:15:17,201] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.03694
[2022-12-06 15:15:17,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.04146, loss val: 0.03831
[2022-12-06 15:15:17,389] [INFO] [controller] EPOCH 3 loss ppo:  -0.05932, loss val: 0.03909
[2022-12-06 15:15:17,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.07449, loss val: 0.03674
[2022-12-06 15:15:17,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:15:17,748] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:15:17,748] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:15:27,050] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:15:35,503] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:15:43,249] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:15:50,948] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:15:58,727] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:16:06,514] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:16:14,303] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:16:21,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:16:31,821] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:16:41,823] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2895833006722053
[2022-12-06 15:16:41,824] [INFO] [runner_train_mujoco] Average state value: 0.5582932331164677
[2022-12-06 15:16:41,824] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 15:16:41,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01346, loss val: 0.04011
[2022-12-06 15:16:41,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.04073, loss val: 0.04377
[2022-12-06 15:16:42,061] [INFO] [controller] EPOCH 3 loss ppo:  -0.06089, loss val: 0.03956
[2022-12-06 15:16:42,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.07674, loss val: 0.03988
[2022-12-06 15:16:42,156] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:16:42,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:16:42,440] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:16:50,763] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:16:58,008] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:17:05,253] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:17:13,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:17:19,999] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:17:27,451] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:17:34,756] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:17:41,623] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:17:48,604] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:17:55,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.320382842448055
[2022-12-06 15:17:55,884] [INFO] [runner_train_mujoco] Average state value: 0.5352542949567238
[2022-12-06 15:17:55,884] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 15:17:55,937] [INFO] [controller] EPOCH 1 loss ppo:  -0.01194, loss val: 0.03593
[2022-12-06 15:17:55,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.03757, loss val: 0.03653
[2022-12-06 15:17:56,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.05712, loss val: 0.03673
[2022-12-06 15:17:56,077] [INFO] [controller] EPOCH 4 loss ppo:  -0.07312, loss val: 0.03690
[2022-12-06 15:17:56,088] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:17:56,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:17:56,293] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:18:03,751] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:18:11,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:18:17,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:18:24,682] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:18:31,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:18:38,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:18:44,952] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:18:51,959] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:18:58,683] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:19:05,484] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1337137972194522
[2022-12-06 15:19:05,484] [INFO] [runner_train_mujoco] Average state value: 0.5283274999558926
[2022-12-06 15:19:05,484] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 15:19:05,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01110, loss val: 0.04134
[2022-12-06 15:19:05,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.03862, loss val: 0.03726
[2022-12-06 15:19:05,611] [INFO] [controller] EPOCH 3 loss ppo:  -0.05741, loss val: 0.03926
[2022-12-06 15:19:05,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.07049, loss val: 0.03924
[2022-12-06 15:19:05,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:19:05,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:19:05,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:19:12,662] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:19:19,405] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:19:26,185] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:19:33,095] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:19:39,709] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:19:46,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:19:52,817] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:20:00,492] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:20:07,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:20:13,762] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4274681343007705
[2022-12-06 15:20:13,763] [INFO] [runner_train_mujoco] Average state value: 0.5171965070168177
[2022-12-06 15:20:13,763] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 15:20:13,811] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.04305
[2022-12-06 15:20:13,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.04249, loss val: 0.04172
[2022-12-06 15:20:13,880] [INFO] [controller] EPOCH 3 loss ppo:  -0.05945, loss val: 0.03921
[2022-12-06 15:20:13,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.07346, loss val: 0.04027
[2022-12-06 15:20:13,925] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:20:14,096] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:20:14,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:20:20,902] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:20:27,757] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:20:34,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:20:40,560] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:20:47,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:20:53,575] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:20:59,927] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:21:06,600] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:21:12,987] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:21:19,365] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4251283974302518
[2022-12-06 15:21:19,365] [INFO] [runner_train_mujoco] Average state value: 0.48255714680751166
[2022-12-06 15:21:19,365] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 15:21:19,413] [INFO] [controller] EPOCH 1 loss ppo:  -0.01504, loss val: 0.03174
[2022-12-06 15:21:19,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.04379, loss val: 0.03181
[2022-12-06 15:21:19,484] [INFO] [controller] EPOCH 3 loss ppo:  -0.06144, loss val: 0.03201
[2022-12-06 15:21:19,524] [INFO] [controller] EPOCH 4 loss ppo:  -0.07481, loss val: 0.03382
[2022-12-06 15:21:19,533] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:21:19,678] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:21:19,678] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:21:26,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:21:32,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:21:39,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:21:45,964] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:21:52,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:21:59,766] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:22:07,079] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:22:16,021] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:22:23,260] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:22:30,215] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6061959372191474
[2022-12-06 15:22:30,215] [INFO] [runner_train_mujoco] Average state value: 0.4715795380218576
[2022-12-06 15:22:30,215] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 15:22:30,274] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04183
[2022-12-06 15:22:30,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.03359, loss val: 0.03499
[2022-12-06 15:22:30,360] [INFO] [controller] EPOCH 3 loss ppo:  -0.04990, loss val: 0.03491
[2022-12-06 15:22:30,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.06746, loss val: 0.04022
[2022-12-06 15:22:30,412] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:22:30,598] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:22:30,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:22:38,001] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:22:45,875] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:22:54,753] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:23:01,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:23:08,216] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:23:14,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:23:21,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:23:28,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:23:35,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:23:42,347] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6348587194360071
[2022-12-06 15:23:42,347] [INFO] [runner_train_mujoco] Average state value: 0.5054591220120589
[2022-12-06 15:23:42,347] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 15:23:42,397] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.03832
[2022-12-06 15:23:42,440] [INFO] [controller] EPOCH 2 loss ppo:  -0.03634, loss val: 0.03875
[2022-12-06 15:23:42,482] [INFO] [controller] EPOCH 3 loss ppo:  -0.05586, loss val: 0.03900
[2022-12-06 15:23:42,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.07078, loss val: 0.03949
[2022-12-06 15:23:42,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:23:42,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:23:42,712] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:23:49,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:23:56,477] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:24:03,543] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:24:10,439] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:24:17,284] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:24:25,431] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:24:33,345] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:24:40,263] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:24:47,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:24:54,725] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7367408821272239
[2022-12-06 15:24:54,726] [INFO] [runner_train_mujoco] Average state value: 0.5075469181934993
[2022-12-06 15:24:54,726] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 15:24:54,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.03907
[2022-12-06 15:24:54,822] [INFO] [controller] EPOCH 2 loss ppo:  -0.03921, loss val: 0.03873
[2022-12-06 15:24:54,865] [INFO] [controller] EPOCH 3 loss ppo:  -0.05791, loss val: 0.03854
[2022-12-06 15:24:54,903] [INFO] [controller] EPOCH 4 loss ppo:  -0.07048, loss val: 0.03853
[2022-12-06 15:24:54,910] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:24:55,085] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:24:55,086] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:25:02,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:25:09,945] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:25:16,928] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:25:24,345] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:25:31,521] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:25:38,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:25:45,867] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:25:52,888] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:26:00,116] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:26:06,922] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6141914875235237
[2022-12-06 15:26:06,923] [INFO] [runner_train_mujoco] Average state value: 0.49542580623428034
[2022-12-06 15:26:06,923] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 15:26:06,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.04231
[2022-12-06 15:26:07,020] [INFO] [controller] EPOCH 2 loss ppo:  -0.04102, loss val: 0.04200
[2022-12-06 15:26:07,143] [INFO] [controller] EPOCH 3 loss ppo:  -0.05953, loss val: 0.04103
[2022-12-06 15:26:07,191] [INFO] [controller] EPOCH 4 loss ppo:  -0.07545, loss val: 0.04416
[2022-12-06 15:26:07,201] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:26:07,416] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:26:07,416] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:26:14,340] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:26:21,436] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:26:28,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:26:36,279] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:26:44,244] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:26:51,362] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:26:58,378] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:27:05,763] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:27:12,691] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:27:19,896] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0015373343016076
[2022-12-06 15:27:19,896] [INFO] [runner_train_mujoco] Average state value: 0.48966935203224426
[2022-12-06 15:27:19,896] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 15:27:19,948] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.04380
[2022-12-06 15:27:19,990] [INFO] [controller] EPOCH 2 loss ppo:  -0.03710, loss val: 0.04364
[2022-12-06 15:27:20,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.05543, loss val: 0.04275
[2022-12-06 15:27:20,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.07114, loss val: 0.04441
[2022-12-06 15:27:20,089] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:27:20,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:27:20,302] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:27:27,320] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:27:34,281] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:27:41,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:27:48,033] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:27:54,889] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:28:01,930] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:28:08,923] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:28:15,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:28:22,577] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:28:29,365] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.003554354026863
[2022-12-06 15:28:29,365] [INFO] [runner_train_mujoco] Average state value: 0.4555276441959043
[2022-12-06 15:28:29,365] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 15:28:29,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.03856
[2022-12-06 15:28:29,459] [INFO] [controller] EPOCH 2 loss ppo:  -0.03763, loss val: 0.03912
[2022-12-06 15:28:29,493] [INFO] [controller] EPOCH 3 loss ppo:  -0.05340, loss val: 0.03813
[2022-12-06 15:28:29,527] [INFO] [controller] EPOCH 4 loss ppo:  -0.06945, loss val: 0.03841
[2022-12-06 15:28:29,536] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:28:29,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:28:29,722] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:28:36,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:28:43,517] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:28:50,183] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:28:56,774] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:29:03,508] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:29:10,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:29:16,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:29:24,307] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:29:33,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:29:42,586] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3495074776196647
[2022-12-06 15:29:42,586] [INFO] [runner_train_mujoco] Average state value: 0.37970571705698963
[2022-12-06 15:29:42,586] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 15:29:42,683] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.11896
[2022-12-06 15:29:42,765] [INFO] [controller] EPOCH 2 loss ppo:  -0.03531, loss val: 0.11601
[2022-12-06 15:29:42,827] [INFO] [controller] EPOCH 3 loss ppo:  -0.04960, loss val: 0.11484
[2022-12-06 15:29:42,928] [INFO] [controller] EPOCH 4 loss ppo:  -0.06519, loss val: 0.11274
[2022-12-06 15:29:42,943] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:29:43,194] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:29:43,194] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:29:50,976] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:29:58,108] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:30:05,595] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:30:12,797] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:30:21,736] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:30:28,919] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:30:35,715] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:30:42,197] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:30:48,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:30:55,610] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3768234016230165
[2022-12-06 15:30:55,610] [INFO] [runner_train_mujoco] Average state value: 0.47918980192144717
[2022-12-06 15:30:55,610] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 15:30:55,659] [INFO] [controller] EPOCH 1 loss ppo:  -0.01561, loss val: 0.04591
[2022-12-06 15:30:55,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.04039, loss val: 0.04786
[2022-12-06 15:30:55,740] [INFO] [controller] EPOCH 3 loss ppo:  -0.05964, loss val: 0.04563
[2022-12-06 15:30:55,783] [INFO] [controller] EPOCH 4 loss ppo:  -0.07513, loss val: 0.04584
[2022-12-06 15:30:55,792] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:30:56,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:30:56,005] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:31:03,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:31:10,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:31:16,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:31:25,623] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:31:34,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:31:42,021] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:31:49,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:31:58,924] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:32:06,581] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:32:14,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.486136840339853
[2022-12-06 15:32:14,291] [INFO] [runner_train_mujoco] Average state value: 0.4594818626244863
[2022-12-06 15:32:14,291] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 15:32:14,336] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04489
[2022-12-06 15:32:14,382] [INFO] [controller] EPOCH 2 loss ppo:  -0.02961, loss val: 0.04313
[2022-12-06 15:32:14,427] [INFO] [controller] EPOCH 3 loss ppo:  -0.04662, loss val: 0.04236
[2022-12-06 15:32:14,473] [INFO] [controller] EPOCH 4 loss ppo:  -0.06388, loss val: 0.04148
[2022-12-06 15:32:14,483] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:32:14,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:32:14,679] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:32:23,812] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:32:32,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:32:39,060] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:32:46,006] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:32:53,014] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:33:00,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:33:07,386] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:33:16,796] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:33:24,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:33:34,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1899044605626914
[2022-12-06 15:33:34,108] [INFO] [runner_train_mujoco] Average state value: 0.4580736533583452
[2022-12-06 15:33:34,109] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 15:33:34,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.01277, loss val: 0.05285
[2022-12-06 15:33:34,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.03380, loss val: 0.05200
[2022-12-06 15:33:34,297] [INFO] [controller] EPOCH 3 loss ppo:  -0.04842, loss val: 0.05073
[2022-12-06 15:33:34,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.06202, loss val: 0.04927
[2022-12-06 15:33:34,372] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:33:34,612] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:33:34,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:33:43,193] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:33:53,163] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:34:03,194] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:34:12,634] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:34:20,298] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:34:29,903] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:34:39,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:34:49,992] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:34:58,146] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:35:05,764] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.368466286213103
[2022-12-06 15:35:05,764] [INFO] [runner_train_mujoco] Average state value: 0.4809916213179628
[2022-12-06 15:35:05,764] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 15:35:05,813] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.07785
[2022-12-06 15:35:05,852] [INFO] [controller] EPOCH 2 loss ppo:  -0.03178, loss val: 0.07679
[2022-12-06 15:35:05,910] [INFO] [controller] EPOCH 3 loss ppo:  -0.04655, loss val: 0.07591
[2022-12-06 15:35:05,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.06083, loss val: 0.07518
[2022-12-06 15:35:05,985] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:35:06,204] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:35:06,204] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:35:14,690] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:35:26,182] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:35:36,010] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:35:46,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:35:57,345] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:36:05,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:36:14,290] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:36:24,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:36:32,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:36:41,675] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5583787886357463
[2022-12-06 15:36:41,675] [INFO] [runner_train_mujoco] Average state value: 0.5221344838837783
[2022-12-06 15:36:41,675] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 15:36:41,742] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.06390
[2022-12-06 15:36:41,797] [INFO] [controller] EPOCH 2 loss ppo:  -0.03282, loss val: 0.06314
[2022-12-06 15:36:41,853] [INFO] [controller] EPOCH 3 loss ppo:  -0.04818, loss val: 0.06349
[2022-12-06 15:36:41,905] [INFO] [controller] EPOCH 4 loss ppo:  -0.06312, loss val: 0.06252
[2022-12-06 15:36:41,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:36:42,136] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:36:42,136] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:36:50,419] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:36:58,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:37:07,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:37:15,750] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:37:24,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:37:32,312] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:37:40,506] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:37:48,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:37:56,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:38:06,636] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1974335014617585
[2022-12-06 15:38:06,636] [INFO] [runner_train_mujoco] Average state value: 0.5803834182247519
[2022-12-06 15:38:06,636] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 15:38:06,732] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.03991
[2022-12-06 15:38:06,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.03080, loss val: 0.04033
[2022-12-06 15:38:06,915] [INFO] [controller] EPOCH 3 loss ppo:  -0.04417, loss val: 0.04018
[2022-12-06 15:38:06,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.05771, loss val: 0.03907
[2022-12-06 15:38:06,997] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:38:07,309] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:38:07,310] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:38:15,237] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:38:22,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:38:30,475] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:38:38,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:38:45,764] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:38:52,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:38:59,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:39:06,751] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:39:13,975] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:39:21,730] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9375901083936133
[2022-12-06 15:39:21,731] [INFO] [runner_train_mujoco] Average state value: 0.5318313906863331
[2022-12-06 15:39:21,731] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 15:39:21,783] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.07665
[2022-12-06 15:39:21,829] [INFO] [controller] EPOCH 2 loss ppo:  -0.03486, loss val: 0.07506
[2022-12-06 15:39:21,876] [INFO] [controller] EPOCH 3 loss ppo:  -0.04990, loss val: 0.07465
[2022-12-06 15:39:21,919] [INFO] [controller] EPOCH 4 loss ppo:  -0.06437, loss val: 0.07391
[2022-12-06 15:39:21,929] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:39:22,122] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:39:22,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:39:30,364] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:39:40,521] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:39:48,945] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:39:56,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:40:05,065] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:40:12,160] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:40:19,065] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:40:25,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:40:32,446] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:40:39,573] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5210492473932424
[2022-12-06 15:40:39,573] [INFO] [runner_train_mujoco] Average state value: 0.5603714907467365
[2022-12-06 15:40:39,573] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 15:40:39,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01537, loss val: 0.04456
[2022-12-06 15:40:39,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.03288, loss val: 0.04455
[2022-12-06 15:40:39,772] [INFO] [controller] EPOCH 3 loss ppo:  -0.04342, loss val: 0.04480
[2022-12-06 15:40:39,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.05863, loss val: 0.04443
[2022-12-06 15:40:39,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:40:40,042] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:40:40,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:40:46,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:40:53,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:41:00,494] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:41:08,172] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:41:15,653] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:41:25,586] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:41:35,557] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:41:44,337] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:41:53,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:42:01,953] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5154762257002643
[2022-12-06 15:42:01,954] [INFO] [runner_train_mujoco] Average state value: 0.552544816017151
[2022-12-06 15:42:01,954] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 15:42:02,021] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.04568
[2022-12-06 15:42:02,186] [INFO] [controller] EPOCH 2 loss ppo:  -0.02731, loss val: 0.04581
[2022-12-06 15:42:02,262] [INFO] [controller] EPOCH 3 loss ppo:  -0.04015, loss val: 0.04430
[2022-12-06 15:42:02,323] [INFO] [controller] EPOCH 4 loss ppo:  -0.05643, loss val: 0.04575
[2022-12-06 15:42:02,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:42:02,607] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:42:02,608] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:42:10,831] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:42:18,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:42:25,682] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:42:33,157] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:42:40,852] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:42:49,229] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:42:57,828] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:43:06,177] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:43:14,305] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:43:23,379] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0894292451496455
[2022-12-06 15:43:23,379] [INFO] [runner_train_mujoco] Average state value: 0.5420187110702196
[2022-12-06 15:43:23,379] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 15:43:23,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01735, loss val: 0.05364
[2022-12-06 15:43:23,503] [INFO] [controller] EPOCH 2 loss ppo:  -0.03164, loss val: 0.05162
[2022-12-06 15:43:23,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.04035, loss val: 0.04969
[2022-12-06 15:43:23,618] [INFO] [controller] EPOCH 4 loss ppo:  -0.05182, loss val: 0.04774
[2022-12-06 15:43:23,629] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:43:23,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:43:23,852] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:43:31,992] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:43:40,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:43:48,335] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:43:56,525] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:44:04,604] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:44:13,052] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:44:22,023] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:44:31,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:44:39,604] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:44:48,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8350288695306474
[2022-12-06 15:44:48,006] [INFO] [runner_train_mujoco] Average state value: 0.44120409932856763
[2022-12-06 15:44:48,006] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 15:44:48,068] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.08381
[2022-12-06 15:44:48,117] [INFO] [controller] EPOCH 2 loss ppo:  -0.02496, loss val: 0.08605
[2022-12-06 15:44:48,175] [INFO] [controller] EPOCH 3 loss ppo:  -0.03843, loss val: 0.08408
[2022-12-06 15:44:48,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.04936, loss val: 0.08527
[2022-12-06 15:44:48,243] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:44:48,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:44:48,469] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:44:57,335] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:45:06,177] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:45:14,629] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:45:23,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:45:30,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:45:38,395] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:45:45,597] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:45:53,086] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:46:00,836] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:46:08,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9314627697407816
[2022-12-06 15:46:08,477] [INFO] [runner_train_mujoco] Average state value: 0.4725685692032179
[2022-12-06 15:46:08,477] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 15:46:08,539] [INFO] [controller] EPOCH 1 loss ppo:  -0.01632, loss val: 0.03460
[2022-12-06 15:46:08,585] [INFO] [controller] EPOCH 2 loss ppo:  -0.03443, loss val: 0.03718
[2022-12-06 15:46:08,632] [INFO] [controller] EPOCH 3 loss ppo:  -0.04453, loss val: 0.03624
[2022-12-06 15:46:08,679] [INFO] [controller] EPOCH 4 loss ppo:  -0.05561, loss val: 0.03573
[2022-12-06 15:46:08,689] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:46:08,881] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:46:08,881] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:46:16,534] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:46:23,979] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:46:31,189] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:46:38,564] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:46:46,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:46:53,431] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:47:00,664] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:47:07,965] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:47:15,056] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:47:22,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.251380988928008
[2022-12-06 15:47:22,354] [INFO] [runner_train_mujoco] Average state value: 0.47442389346162483
[2022-12-06 15:47:22,354] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 15:47:22,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.03659
[2022-12-06 15:47:22,466] [INFO] [controller] EPOCH 2 loss ppo:  -0.02879, loss val: 0.03872
[2022-12-06 15:47:22,516] [INFO] [controller] EPOCH 3 loss ppo:  -0.04310, loss val: 0.03852
[2022-12-06 15:47:22,573] [INFO] [controller] EPOCH 4 loss ppo:  -0.05445, loss val: 0.03645
[2022-12-06 15:47:22,584] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:47:22,785] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:47:22,786] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:47:29,873] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:47:36,970] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:47:44,395] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:47:51,575] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:47:58,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:48:05,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:48:12,865] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:48:19,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:48:26,850] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:48:33,636] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.283543593680506
[2022-12-06 15:48:33,636] [INFO] [runner_train_mujoco] Average state value: 0.4469285443499684
[2022-12-06 15:48:33,636] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 15:48:33,685] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.06695
[2022-12-06 15:48:33,728] [INFO] [controller] EPOCH 2 loss ppo:  -0.02368, loss val: 0.06241
[2022-12-06 15:48:33,768] [INFO] [controller] EPOCH 3 loss ppo:  -0.03778, loss val: 0.06202
[2022-12-06 15:48:33,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.04859, loss val: 0.06532
[2022-12-06 15:48:33,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:48:33,994] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:48:33,995] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:48:40,782] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:48:47,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:48:54,542] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:49:01,632] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:49:08,560] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:49:15,388] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:49:22,486] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:49:29,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:49:35,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:49:42,497] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.701044389330205
[2022-12-06 15:49:42,497] [INFO] [runner_train_mujoco] Average state value: 0.46149843777095273
[2022-12-06 15:49:42,497] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 15:49:42,546] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.05744
[2022-12-06 15:49:42,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.02656, loss val: 0.05505
[2022-12-06 15:49:42,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.03788, loss val: 0.05602
[2022-12-06 15:49:42,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.04641, loss val: 0.05504
[2022-12-06 15:49:42,673] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:49:42,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:49:42,851] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:49:49,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:49:56,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:50:02,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:50:11,324] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:50:20,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:50:28,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:50:35,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:50:41,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:50:48,294] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:50:55,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.794472136274861
[2022-12-06 15:50:55,111] [INFO] [runner_train_mujoco] Average state value: 0.487887222846349
[2022-12-06 15:50:55,111] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 15:50:55,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.03933
[2022-12-06 15:50:55,202] [INFO] [controller] EPOCH 2 loss ppo:  -0.02347, loss val: 0.04087
[2022-12-06 15:50:55,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.03593, loss val: 0.03875
[2022-12-06 15:50:55,282] [INFO] [controller] EPOCH 4 loss ppo:  -0.04321, loss val: 0.04171
[2022-12-06 15:50:55,289] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:50:55,460] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:50:55,461] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:51:02,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:51:08,461] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:51:14,706] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:51:21,172] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:51:28,036] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:51:35,148] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:51:41,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:51:48,598] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:51:55,473] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:52:02,118] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.705412939706094
[2022-12-06 15:52:02,118] [INFO] [runner_train_mujoco] Average state value: 0.4852957171301047
[2022-12-06 15:52:02,118] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 15:52:02,167] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.03670
[2022-12-06 15:52:02,208] [INFO] [controller] EPOCH 2 loss ppo:  -0.02409, loss val: 0.03672
[2022-12-06 15:52:02,245] [INFO] [controller] EPOCH 3 loss ppo:  -0.03723, loss val: 0.03660
[2022-12-06 15:52:02,289] [INFO] [controller] EPOCH 4 loss ppo:  -0.04511, loss val: 0.03671
[2022-12-06 15:52:02,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:52:02,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:52:02,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:52:09,339] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:52:16,163] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:52:23,188] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:52:29,937] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:52:36,933] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:52:43,964] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:52:51,542] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:52:59,103] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:53:06,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:53:13,239] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.416955240015307
[2022-12-06 15:53:13,239] [INFO] [runner_train_mujoco] Average state value: 0.4878751554091772
[2022-12-06 15:53:13,239] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 15:53:13,285] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04870
[2022-12-06 15:53:13,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.02170, loss val: 0.04950
[2022-12-06 15:53:13,363] [INFO] [controller] EPOCH 3 loss ppo:  -0.03337, loss val: 0.05188
[2022-12-06 15:53:13,407] [INFO] [controller] EPOCH 4 loss ppo:  -0.04234, loss val: 0.04860
[2022-12-06 15:53:13,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:53:13,581] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:53:13,581] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:53:20,626] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:53:28,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:53:35,924] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:53:43,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:53:50,358] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:53:57,910] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:54:06,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:54:13,410] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:54:20,668] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:54:27,938] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.875272569408576
[2022-12-06 15:54:27,938] [INFO] [runner_train_mujoco] Average state value: 0.47811716580142577
[2022-12-06 15:54:27,938] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 15:54:27,992] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04478
[2022-12-06 15:54:28,037] [INFO] [controller] EPOCH 2 loss ppo:  -0.02196, loss val: 0.04675
[2022-12-06 15:54:28,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.03331, loss val: 0.04325
[2022-12-06 15:54:28,186] [INFO] [controller] EPOCH 4 loss ppo:  -0.04070, loss val: 0.04607
[2022-12-06 15:54:28,193] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:54:28,399] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:54:28,400] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:54:35,842] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:54:43,158] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:54:50,674] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:54:58,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:55:05,977] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:55:13,691] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:55:22,106] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:55:31,323] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:55:41,975] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:55:50,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.55860973675563
[2022-12-06 15:55:50,105] [INFO] [runner_train_mujoco] Average state value: 0.4861576231867075
[2022-12-06 15:55:50,106] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 15:55:50,166] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.03568
[2022-12-06 15:55:50,214] [INFO] [controller] EPOCH 2 loss ppo:  -0.02670, loss val: 0.03587
[2022-12-06 15:55:50,267] [INFO] [controller] EPOCH 3 loss ppo:  -0.03778, loss val: 0.03599
[2022-12-06 15:55:50,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.04171, loss val: 0.03588
[2022-12-06 15:55:50,322] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:55:50,524] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:55:50,525] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:55:58,635] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:56:06,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:56:14,332] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:56:22,676] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:56:30,821] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:56:38,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:56:48,304] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:57:00,669] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:57:11,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:57:20,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.042598142834194
[2022-12-06 15:57:20,331] [INFO] [runner_train_mujoco] Average state value: 0.4936688042084376
[2022-12-06 15:57:20,331] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 15:57:20,394] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.05227
[2022-12-06 15:57:20,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.02118, loss val: 0.05237
[2022-12-06 15:57:20,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.03006, loss val: 0.05141
[2022-12-06 15:57:20,539] [INFO] [controller] EPOCH 4 loss ppo:  -0.03476, loss val: 0.05135
[2022-12-06 15:57:20,547] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:57:20,767] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:57:20,767] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:57:29,578] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:57:37,594] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:57:45,368] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:57:53,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:58:00,854] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:58:08,765] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:58:16,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:58:24,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:58:32,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:58:39,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.311724947075553
[2022-12-06 15:58:39,703] [INFO] [runner_train_mujoco] Average state value: 0.4756724500084917
[2022-12-06 15:58:39,703] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 15:58:39,758] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.05022
[2022-12-06 15:58:39,861] [INFO] [controller] EPOCH 2 loss ppo:  -0.01892, loss val: 0.05174
[2022-12-06 15:58:39,955] [INFO] [controller] EPOCH 3 loss ppo:  -0.02525, loss val: 0.05072
[2022-12-06 15:58:40,038] [INFO] [controller] EPOCH 4 loss ppo:  -0.03160, loss val: 0.05044
[2022-12-06 15:58:40,048] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:58:40,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:58:40,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:58:47,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:58:55,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:59:02,589] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:59:10,261] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:59:18,928] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:59:27,382] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:59:35,548] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:59:43,023] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:59:50,847] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:59:58,516] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.4099869269147405
[2022-12-06 15:59:58,517] [INFO] [runner_train_mujoco] Average state value: 0.4641187362174192
[2022-12-06 15:59:58,517] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 15:59:58,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01457, loss val: 0.05463
[2022-12-06 15:59:58,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.01804, loss val: 0.05200
[2022-12-06 15:59:58,664] [INFO] [controller] EPOCH 3 loss ppo:  -0.02336, loss val: 0.04812
[2022-12-06 15:59:58,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.02998, loss val: 0.04809
[2022-12-06 15:59:58,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:59:58,941] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:59:58,941] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:00:06,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:00:14,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:00:21,464] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:00:28,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:00:35,628] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:00:42,748] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:00:49,900] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:00:58,015] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:01:07,362] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:01:15,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.142085287043931
[2022-12-06 16:01:15,415] [INFO] [runner_train_mujoco] Average state value: 0.4894455574254194
[2022-12-06 16:01:15,415] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 16:01:15,470] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.03461
[2022-12-06 16:01:15,518] [INFO] [controller] EPOCH 2 loss ppo:  -0.01697, loss val: 0.03426
[2022-12-06 16:01:15,570] [INFO] [controller] EPOCH 3 loss ppo:  -0.02116, loss val: 0.03431
[2022-12-06 16:01:15,617] [INFO] [controller] EPOCH 4 loss ppo:  -0.02592, loss val: 0.03462
[2022-12-06 16:01:15,628] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:01:15,850] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:01:15,851] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:01:23,534] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:01:30,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:01:39,070] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:01:46,541] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:01:54,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:02:02,730] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:02:09,886] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:02:17,126] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:02:26,161] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:02:37,907] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.558585909778991
[2022-12-06 16:02:37,907] [INFO] [runner_train_mujoco] Average state value: 0.47393264741947255
[2022-12-06 16:02:37,907] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 16:02:37,976] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04548
[2022-12-06 16:02:38,372] [INFO] [controller] EPOCH 2 loss ppo:  -0.01556, loss val: 0.04545
[2022-12-06 16:02:38,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.01747, loss val: 0.04877
[2022-12-06 16:02:38,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.02031, loss val: 0.04542
[2022-12-06 16:02:38,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:02:38,680] [INFO] [optimize] Finished learning.
