[2022-12-07 03:33:17,417] [INFO] [optimize] Starting learning
[2022-12-07 03:33:17,428] [INFO] [optimize] Starting learning process..
[2022-12-07 03:33:17,539] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:33:17,539] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:33:27,471] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:33:37,812] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:33:46,780] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:33:55,359] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:34:04,113] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:34:12,595] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:34:21,235] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:34:30,018] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:34:39,135] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:34:48,205] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5428989541510613
[2022-12-07 03:34:48,205] [INFO] [runner_train_mujoco] Average state value: 0.08390204121420781
[2022-12-07 03:34:48,205] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 03:34:48,267] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.30187
[2022-12-07 03:34:48,316] [INFO] [controller] EPOCH 2 loss ppo:  -0.04841, loss val: 0.26800
[2022-12-07 03:34:48,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.06053, loss val: 0.25169
[2022-12-07 03:34:48,419] [INFO] [controller] EPOCH 4 loss ppo:  -0.07489, loss val: 0.20035
[2022-12-07 03:34:48,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:34:48,643] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:34:48,644] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:34:58,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:35:06,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:35:15,567] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:35:24,368] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:35:32,876] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:35:41,444] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:35:50,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:35:59,554] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:36:08,311] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:36:16,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6036755027643335
[2022-12-07 03:36:16,619] [INFO] [runner_train_mujoco] Average state value: 0.2645491076959297
[2022-12-07 03:36:16,620] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 03:36:16,683] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.21772
[2022-12-07 03:36:16,742] [INFO] [controller] EPOCH 2 loss ppo:  -0.04470, loss val: 0.18610
[2022-12-07 03:36:16,789] [INFO] [controller] EPOCH 3 loss ppo:  -0.06238, loss val: 0.17091
[2022-12-07 03:36:16,839] [INFO] [controller] EPOCH 4 loss ppo:  -0.07462, loss val: 0.15244
[2022-12-07 03:36:16,849] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:36:17,066] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:36:17,067] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:36:26,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:36:34,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:36:43,289] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:36:52,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:37:00,905] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:37:09,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:37:18,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:37:26,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:37:34,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:37:43,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7405126774689835
[2022-12-07 03:37:43,033] [INFO] [runner_train_mujoco] Average state value: 0.40353663829341524
[2022-12-07 03:37:43,033] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 03:37:43,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.11699
[2022-12-07 03:37:43,134] [INFO] [controller] EPOCH 2 loss ppo:  -0.04955, loss val: 0.10687
[2022-12-07 03:37:43,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.06908, loss val: 0.09884
[2022-12-07 03:37:43,237] [INFO] [controller] EPOCH 4 loss ppo:  -0.08143, loss val: 0.09179
[2022-12-07 03:37:43,246] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:37:43,461] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:37:43,462] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:37:52,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:38:01,446] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:38:09,705] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:38:18,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:38:28,056] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:38:36,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:38:45,050] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:38:53,575] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:39:01,717] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:39:09,998] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6742132914850589
[2022-12-07 03:39:09,998] [INFO] [runner_train_mujoco] Average state value: 0.5202036690811316
[2022-12-07 03:39:09,998] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 03:39:10,059] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.09727
[2022-12-07 03:39:10,106] [INFO] [controller] EPOCH 2 loss ppo:  -0.04187, loss val: 0.09369
[2022-12-07 03:39:10,161] [INFO] [controller] EPOCH 3 loss ppo:  -0.05989, loss val: 0.08835
[2022-12-07 03:39:10,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.07334, loss val: 0.08292
[2022-12-07 03:39:10,219] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:39:10,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:39:10,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:39:19,117] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:39:27,841] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:39:36,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:39:45,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:39:53,867] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:40:02,753] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:40:10,940] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:40:19,386] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:40:27,292] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:40:35,852] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5507195410644701
[2022-12-07 03:40:35,852] [INFO] [runner_train_mujoco] Average state value: 0.5229893127698452
[2022-12-07 03:40:35,853] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 03:40:35,912] [INFO] [controller] EPOCH 1 loss ppo:  -0.01053, loss val: 0.08739
[2022-12-07 03:40:35,959] [INFO] [controller] EPOCH 2 loss ppo:  -0.04127, loss val: 0.08367
[2022-12-07 03:40:36,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.06055, loss val: 0.07916
[2022-12-07 03:40:36,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.07185, loss val: 0.07706
[2022-12-07 03:40:36,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:40:36,296] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:40:36,297] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:40:44,875] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:40:54,002] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:41:02,400] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:41:10,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:41:19,451] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:41:28,052] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:41:36,554] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:41:45,478] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:41:54,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:42:03,151] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7185750462150817
[2022-12-07 03:42:03,151] [INFO] [runner_train_mujoco] Average state value: 0.5043691794518381
[2022-12-07 03:42:03,152] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 03:42:03,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01029, loss val: 0.06898
[2022-12-07 03:42:03,256] [INFO] [controller] EPOCH 2 loss ppo:  -0.04276, loss val: 0.06601
[2022-12-07 03:42:03,304] [INFO] [controller] EPOCH 3 loss ppo:  -0.05940, loss val: 0.06590
[2022-12-07 03:42:03,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.06930, loss val: 0.06238
[2022-12-07 03:42:03,359] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:42:03,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:42:03,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:42:12,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:42:20,461] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:42:30,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:42:38,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:42:46,120] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:42:54,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:43:02,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:43:10,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:43:18,232] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:43:26,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5544425850662558
[2022-12-07 03:43:26,728] [INFO] [runner_train_mujoco] Average state value: 0.5105907171691457
[2022-12-07 03:43:26,728] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 03:43:26,776] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.06011
[2022-12-07 03:43:26,818] [INFO] [controller] EPOCH 2 loss ppo:  -0.04149, loss val: 0.05464
[2022-12-07 03:43:26,859] [INFO] [controller] EPOCH 3 loss ppo:  -0.05801, loss val: 0.05340
[2022-12-07 03:43:26,900] [INFO] [controller] EPOCH 4 loss ppo:  -0.06814, loss val: 0.05270
[2022-12-07 03:43:26,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:43:27,118] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:43:27,118] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:43:34,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:43:42,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:43:49,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:43:57,716] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:44:05,923] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:44:14,284] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:44:22,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:44:29,500] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:44:37,004] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:44:44,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5502021404974156
[2022-12-07 03:44:44,651] [INFO] [runner_train_mujoco] Average state value: 0.5041140719999869
[2022-12-07 03:44:44,651] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 03:44:44,706] [INFO] [controller] EPOCH 1 loss ppo:  -0.01174, loss val: 0.05467
[2022-12-07 03:44:44,757] [INFO] [controller] EPOCH 2 loss ppo:  -0.04329, loss val: 0.05444
[2022-12-07 03:44:44,865] [INFO] [controller] EPOCH 3 loss ppo:  -0.06128, loss val: 0.05324
[2022-12-07 03:44:44,908] [INFO] [controller] EPOCH 4 loss ppo:  -0.07308, loss val: 0.05237
[2022-12-07 03:44:44,917] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:44:45,132] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:44:45,132] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:44:53,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:45:00,289] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:45:07,145] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:45:13,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:45:20,640] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:45:27,607] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:45:34,546] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:45:41,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:45:48,687] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:45:55,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6542920277206953
[2022-12-07 03:45:55,507] [INFO] [runner_train_mujoco] Average state value: 0.517907139663895
[2022-12-07 03:45:55,507] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 03:45:55,558] [INFO] [controller] EPOCH 1 loss ppo:  -0.01075, loss val: 0.04249
[2022-12-07 03:45:55,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.04040, loss val: 0.04158
[2022-12-07 03:45:55,640] [INFO] [controller] EPOCH 3 loss ppo:  -0.05674, loss val: 0.04078
[2022-12-07 03:45:55,681] [INFO] [controller] EPOCH 4 loss ppo:  -0.06762, loss val: 0.03979
[2022-12-07 03:45:55,688] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:45:55,904] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:45:55,904] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:46:02,866] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:46:09,948] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:46:16,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:46:23,441] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:46:30,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:46:37,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:46:45,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:46:53,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:47:00,459] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:47:07,248] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5306863227628776
[2022-12-07 03:47:07,248] [INFO] [runner_train_mujoco] Average state value: 0.5080795677155256
[2022-12-07 03:47:07,248] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 03:47:07,297] [INFO] [controller] EPOCH 1 loss ppo:  -0.01156, loss val: 0.04558
[2022-12-07 03:47:07,336] [INFO] [controller] EPOCH 2 loss ppo:  -0.04577, loss val: 0.05063
[2022-12-07 03:47:07,383] [INFO] [controller] EPOCH 3 loss ppo:  -0.06095, loss val: 0.04474
[2022-12-07 03:47:07,425] [INFO] [controller] EPOCH 4 loss ppo:  -0.07180, loss val: 0.04358
[2022-12-07 03:47:07,434] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:47:07,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:47:07,624] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:47:14,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:47:21,364] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:47:28,132] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:47:34,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:47:41,533] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:47:48,415] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:47:55,798] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:48:03,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:48:10,068] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:48:16,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5586546604000422
[2022-12-07 03:48:16,884] [INFO] [runner_train_mujoco] Average state value: 0.515588032712539
[2022-12-07 03:48:16,884] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 03:48:16,939] [INFO] [controller] EPOCH 1 loss ppo:  -0.00917, loss val: 0.04893
[2022-12-07 03:48:16,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.03426, loss val: 0.04462
[2022-12-07 03:48:17,018] [INFO] [controller] EPOCH 3 loss ppo:  -0.05366, loss val: 0.04898
[2022-12-07 03:48:17,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.06577, loss val: 0.04456
[2022-12-07 03:48:17,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:48:17,254] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:48:17,255] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:48:23,960] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:48:30,901] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:48:37,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:48:44,380] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:48:51,301] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:48:58,238] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:49:05,417] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:49:12,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:49:19,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:49:26,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.543798499624322
[2022-12-07 03:49:26,004] [INFO] [runner_train_mujoco] Average state value: 0.5281812346875668
[2022-12-07 03:49:26,004] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 03:49:26,053] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.04304
[2022-12-07 03:49:26,095] [INFO] [controller] EPOCH 2 loss ppo:  -0.04049, loss val: 0.04271
[2022-12-07 03:49:26,136] [INFO] [controller] EPOCH 3 loss ppo:  -0.05778, loss val: 0.04231
[2022-12-07 03:49:26,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.06970, loss val: 0.04307
[2022-12-07 03:49:26,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:49:26,391] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:49:26,391] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:49:33,074] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:49:40,300] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:49:47,158] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:49:53,965] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:50:00,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:50:07,429] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:50:14,232] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:50:21,045] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:50:28,048] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:50:34,625] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6567730279329302
[2022-12-07 03:50:34,625] [INFO] [runner_train_mujoco] Average state value: 0.5156219669083754
[2022-12-07 03:50:34,625] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 03:50:34,686] [INFO] [controller] EPOCH 1 loss ppo:  -0.01092, loss val: 0.04674
[2022-12-07 03:50:34,729] [INFO] [controller] EPOCH 2 loss ppo:  -0.03561, loss val: 0.04405
[2022-12-07 03:50:34,771] [INFO] [controller] EPOCH 3 loss ppo:  -0.05038, loss val: 0.04223
[2022-12-07 03:50:34,813] [INFO] [controller] EPOCH 4 loss ppo:  -0.06342, loss val: 0.04262
[2022-12-07 03:50:34,823] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:50:35,037] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:50:35,037] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:50:42,209] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:50:49,333] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:50:56,175] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:51:02,848] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:51:09,445] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:51:16,526] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:51:23,194] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:51:30,517] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:51:37,635] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:51:44,754] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46383160206219715
[2022-12-07 03:51:44,754] [INFO] [runner_train_mujoco] Average state value: 0.5501860661407312
[2022-12-07 03:51:44,754] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 03:51:44,804] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.06405
[2022-12-07 03:51:44,849] [INFO] [controller] EPOCH 2 loss ppo:  -0.03309, loss val: 0.06276
[2022-12-07 03:51:44,890] [INFO] [controller] EPOCH 3 loss ppo:  -0.04730, loss val: 0.06086
[2022-12-07 03:51:44,924] [INFO] [controller] EPOCH 4 loss ppo:  -0.06081, loss val: 0.05550
[2022-12-07 03:51:44,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:51:45,131] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:51:45,132] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:51:52,095] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:51:58,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:52:05,739] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:52:12,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:52:19,718] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:52:26,780] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:52:33,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:52:40,611] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:52:47,393] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:52:54,517] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8232934006722417
[2022-12-07 03:52:54,518] [INFO] [runner_train_mujoco] Average state value: 0.5230870636701586
[2022-12-07 03:52:54,518] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 03:52:54,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01175, loss val: 0.04470
[2022-12-07 03:52:54,607] [INFO] [controller] EPOCH 2 loss ppo:  -0.04265, loss val: 0.04576
[2022-12-07 03:52:54,651] [INFO] [controller] EPOCH 3 loss ppo:  -0.06385, loss val: 0.04659
[2022-12-07 03:52:54,694] [INFO] [controller] EPOCH 4 loss ppo:  -0.07712, loss val: 0.04644
[2022-12-07 03:52:54,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:52:54,897] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:52:54,898] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:53:02,154] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:53:09,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:53:16,170] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:53:22,911] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:53:29,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:53:36,496] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:53:43,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:53:50,599] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:53:57,620] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:54:04,578] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7342417854827368
[2022-12-07 03:54:04,579] [INFO] [runner_train_mujoco] Average state value: 0.49380161141852535
[2022-12-07 03:54:04,579] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 03:54:04,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.03702
[2022-12-07 03:54:04,669] [INFO] [controller] EPOCH 2 loss ppo:  -0.04407, loss val: 0.04077
[2022-12-07 03:54:04,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.06347, loss val: 0.03560
[2022-12-07 03:54:04,749] [INFO] [controller] EPOCH 4 loss ppo:  -0.07595, loss val: 0.03855
[2022-12-07 03:54:04,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:54:04,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:54:04,952] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:54:11,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:54:18,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:54:25,487] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:54:33,597] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:54:40,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:54:46,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:54:53,776] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:55:00,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:55:07,269] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:55:14,591] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5881569976983323
[2022-12-07 03:55:14,591] [INFO] [runner_train_mujoco] Average state value: 0.5334006681044896
[2022-12-07 03:55:14,592] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 03:55:14,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.04454
[2022-12-07 03:55:14,673] [INFO] [controller] EPOCH 2 loss ppo:  -0.04172, loss val: 0.04489
[2022-12-07 03:55:14,707] [INFO] [controller] EPOCH 3 loss ppo:  -0.05745, loss val: 0.04395
[2022-12-07 03:55:14,747] [INFO] [controller] EPOCH 4 loss ppo:  -0.06964, loss val: 0.04465
[2022-12-07 03:55:14,757] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:55:14,954] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:55:14,954] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:55:22,582] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:55:29,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:55:36,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:55:43,637] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:55:50,186] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:55:57,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:56:04,182] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:56:11,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:56:18,582] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:56:25,239] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6654730809671208
[2022-12-07 03:56:25,240] [INFO] [runner_train_mujoco] Average state value: 0.5078055698027214
[2022-12-07 03:56:25,240] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 03:56:25,291] [INFO] [controller] EPOCH 1 loss ppo:  -0.01155, loss val: 0.04648
[2022-12-07 03:56:25,334] [INFO] [controller] EPOCH 2 loss ppo:  -0.03916, loss val: 0.04678
[2022-12-07 03:56:25,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.05595, loss val: 0.04373
[2022-12-07 03:56:25,422] [INFO] [controller] EPOCH 4 loss ppo:  -0.06983, loss val: 0.04238
[2022-12-07 03:56:25,431] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:56:25,628] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:56:25,628] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:56:32,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:56:39,572] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:56:46,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:56:53,381] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:57:00,601] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:57:07,396] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:57:14,329] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:57:21,048] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:57:27,782] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:57:34,600] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6317381478522635
[2022-12-07 03:57:34,600] [INFO] [runner_train_mujoco] Average state value: 0.5250004482964675
[2022-12-07 03:57:34,600] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 03:57:34,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.05166
[2022-12-07 03:57:34,695] [INFO] [controller] EPOCH 2 loss ppo:  -0.04193, loss val: 0.04778
[2022-12-07 03:57:34,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.06066, loss val: 0.04810
[2022-12-07 03:57:34,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.07404, loss val: 0.04789
[2022-12-07 03:57:34,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:57:35,166] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:57:35,166] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:57:42,610] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:57:50,539] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:57:57,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:58:04,575] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:58:11,290] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:58:18,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:58:25,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:58:32,026] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:58:39,365] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:58:45,861] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8168999250235955
[2022-12-07 03:58:45,861] [INFO] [runner_train_mujoco] Average state value: 0.5560452309449514
[2022-12-07 03:58:45,861] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 03:58:45,913] [INFO] [controller] EPOCH 1 loss ppo:  -0.01201, loss val: 0.03503
[2022-12-07 03:58:45,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.04015, loss val: 0.03587
[2022-12-07 03:58:45,997] [INFO] [controller] EPOCH 3 loss ppo:  -0.05943, loss val: 0.03541
[2022-12-07 03:58:46,041] [INFO] [controller] EPOCH 4 loss ppo:  -0.07291, loss val: 0.03793
[2022-12-07 03:58:46,049] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:58:46,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:58:46,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:58:53,542] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:59:00,645] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:59:07,662] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:59:14,483] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:59:21,283] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:59:27,884] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:59:34,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:59:41,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:59:48,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:59:55,419] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6967886670832564
[2022-12-07 03:59:55,419] [INFO] [runner_train_mujoco] Average state value: 0.5475054576173425
[2022-12-07 03:59:55,419] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 03:59:55,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01024, loss val: 0.04197
[2022-12-07 03:59:55,543] [INFO] [controller] EPOCH 2 loss ppo:  -0.03836, loss val: 0.03613
[2022-12-07 03:59:55,592] [INFO] [controller] EPOCH 3 loss ppo:  -0.05631, loss val: 0.03487
[2022-12-07 03:59:55,633] [INFO] [controller] EPOCH 4 loss ppo:  -0.06762, loss val: 0.03420
[2022-12-07 03:59:55,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:59:55,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:59:55,839] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:00:03,145] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:00:10,623] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:00:17,700] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:00:24,215] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:00:30,718] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:00:37,477] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:00:44,288] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:00:51,584] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:00:58,837] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:01:05,877] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7586291446861828
[2022-12-07 04:01:05,877] [INFO] [runner_train_mujoco] Average state value: 0.49604186746478074
[2022-12-07 04:01:05,877] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 04:01:05,924] [INFO] [controller] EPOCH 1 loss ppo:  -0.00980, loss val: 0.02773
[2022-12-07 04:01:05,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.03387, loss val: 0.02993
[2022-12-07 04:01:05,995] [INFO] [controller] EPOCH 3 loss ppo:  -0.05542, loss val: 0.02618
[2022-12-07 04:01:06,037] [INFO] [controller] EPOCH 4 loss ppo:  -0.06972, loss val: 0.02625
[2022-12-07 04:01:06,045] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:01:06,235] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:01:06,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:01:13,549] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:01:20,663] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:01:27,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:01:34,304] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:01:41,561] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:01:48,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:01:55,445] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:02:02,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:02:09,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:02:15,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7761509698273799
[2022-12-07 04:02:15,979] [INFO] [runner_train_mujoco] Average state value: 0.46680619053045913
[2022-12-07 04:02:15,979] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 04:02:16,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.03291
[2022-12-07 04:02:16,068] [INFO] [controller] EPOCH 2 loss ppo:  -0.03922, loss val: 0.03024
[2022-12-07 04:02:16,104] [INFO] [controller] EPOCH 3 loss ppo:  -0.05627, loss val: 0.03106
[2022-12-07 04:02:16,149] [INFO] [controller] EPOCH 4 loss ppo:  -0.06965, loss val: 0.03019
[2022-12-07 04:02:16,158] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:02:16,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:02:16,349] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:02:23,301] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:02:30,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:02:37,594] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:02:44,672] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:02:51,480] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:02:58,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:03:05,155] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:03:12,139] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:03:18,789] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:03:26,281] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7132307572490142
[2022-12-07 04:03:26,281] [INFO] [runner_train_mujoco] Average state value: 0.4366204814414183
[2022-12-07 04:03:26,281] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 04:03:26,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.03896
[2022-12-07 04:03:26,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.03732, loss val: 0.03929
[2022-12-07 04:03:26,410] [INFO] [controller] EPOCH 3 loss ppo:  -0.05653, loss val: 0.04252
[2022-12-07 04:03:26,455] [INFO] [controller] EPOCH 4 loss ppo:  -0.07022, loss val: 0.04198
[2022-12-07 04:03:26,463] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:03:26,658] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:03:26,658] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:03:33,519] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:03:40,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:03:47,782] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:03:54,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:04:01,926] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:04:08,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:04:16,076] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:04:23,134] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:04:30,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:04:37,178] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7470464984894091
[2022-12-07 04:04:37,179] [INFO] [runner_train_mujoco] Average state value: 0.43770000828305883
[2022-12-07 04:04:37,179] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 04:04:37,228] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.04765
[2022-12-07 04:04:37,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.03112, loss val: 0.04692
[2022-12-07 04:04:37,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.04762, loss val: 0.04417
[2022-12-07 04:04:37,358] [INFO] [controller] EPOCH 4 loss ppo:  -0.06339, loss val: 0.03828
[2022-12-07 04:04:37,365] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:04:37,568] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:04:37,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:04:44,649] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:04:51,548] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:04:58,459] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:05:05,339] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:05:12,180] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:05:18,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:05:25,738] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:05:32,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:05:39,795] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:05:46,711] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7137403894518154
[2022-12-07 04:05:46,711] [INFO] [runner_train_mujoco] Average state value: 0.5054224520226319
[2022-12-07 04:05:46,711] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 04:05:46,764] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04395
[2022-12-07 04:05:46,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.03446, loss val: 0.04329
[2022-12-07 04:05:46,851] [INFO] [controller] EPOCH 3 loss ppo:  -0.05439, loss val: 0.04097
[2022-12-07 04:05:46,894] [INFO] [controller] EPOCH 4 loss ppo:  -0.07181, loss val: 0.03950
[2022-12-07 04:05:46,903] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:05:47,107] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:05:47,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:05:53,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:06:01,074] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:06:07,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:06:14,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:06:21,960] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:06:28,513] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:06:35,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:06:42,141] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:06:48,589] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:06:55,525] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8603339987250586
[2022-12-07 04:06:55,526] [INFO] [runner_train_mujoco] Average state value: 0.5638134530782699
[2022-12-07 04:06:55,526] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 04:06:55,571] [INFO] [controller] EPOCH 1 loss ppo:  -0.01162, loss val: 0.03863
[2022-12-07 04:06:55,613] [INFO] [controller] EPOCH 2 loss ppo:  -0.03868, loss val: 0.03881
[2022-12-07 04:06:55,652] [INFO] [controller] EPOCH 3 loss ppo:  -0.05543, loss val: 0.03966
[2022-12-07 04:06:55,692] [INFO] [controller] EPOCH 4 loss ppo:  -0.06842, loss val: 0.03882
[2022-12-07 04:06:55,701] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:06:55,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:06:55,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:07:04,368] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:07:12,519] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:07:20,069] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:07:26,773] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:07:33,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:07:40,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:07:46,723] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:07:53,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:08:01,058] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:08:08,217] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8635904691315959
[2022-12-07 04:08:08,218] [INFO] [runner_train_mujoco] Average state value: 0.562004511428376
[2022-12-07 04:08:08,218] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 04:08:08,266] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.03974
[2022-12-07 04:08:08,304] [INFO] [controller] EPOCH 2 loss ppo:  -0.03971, loss val: 0.03974
[2022-12-07 04:08:08,346] [INFO] [controller] EPOCH 3 loss ppo:  -0.05890, loss val: 0.03963
[2022-12-07 04:08:08,387] [INFO] [controller] EPOCH 4 loss ppo:  -0.07285, loss val: 0.04075
[2022-12-07 04:08:08,396] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:08:08,580] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:08:08,580] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:08:15,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:08:21,822] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:08:28,584] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:08:35,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:08:42,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:08:49,561] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:08:56,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:09:03,007] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:09:10,298] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:09:17,189] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8607430450654077
[2022-12-07 04:09:17,189] [INFO] [runner_train_mujoco] Average state value: 0.5651423736612002
[2022-12-07 04:09:17,189] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 04:09:17,238] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.03577
[2022-12-07 04:09:17,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.03799, loss val: 0.03568
[2022-12-07 04:09:17,341] [INFO] [controller] EPOCH 3 loss ppo:  -0.05818, loss val: 0.03724
[2022-12-07 04:09:17,385] [INFO] [controller] EPOCH 4 loss ppo:  -0.07263, loss val: 0.03640
[2022-12-07 04:09:17,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:09:17,593] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:09:17,594] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:09:24,700] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:09:31,735] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:09:38,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:09:45,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:09:52,130] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:09:59,081] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:10:06,073] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:10:12,698] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:10:19,818] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:10:26,422] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8688152195012588
[2022-12-07 04:10:26,422] [INFO] [runner_train_mujoco] Average state value: 0.538339316000541
[2022-12-07 04:10:26,422] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 04:10:26,468] [INFO] [controller] EPOCH 1 loss ppo:  -0.01004, loss val: 0.03876
[2022-12-07 04:10:26,517] [INFO] [controller] EPOCH 2 loss ppo:  -0.03227, loss val: 0.03908
[2022-12-07 04:10:26,653] [INFO] [controller] EPOCH 3 loss ppo:  -0.05019, loss val: 0.03924
[2022-12-07 04:10:26,698] [INFO] [controller] EPOCH 4 loss ppo:  -0.06636, loss val: 0.03936
[2022-12-07 04:10:26,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:10:26,900] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:10:26,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:10:34,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:10:41,216] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:10:47,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:10:54,774] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:11:01,714] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:11:08,418] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:11:15,171] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:11:21,689] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:11:28,475] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:11:35,720] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7108373705489034
[2022-12-07 04:11:35,720] [INFO] [runner_train_mujoco] Average state value: 0.5272556725740433
[2022-12-07 04:11:35,721] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 04:11:35,774] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.03939
[2022-12-07 04:11:35,824] [INFO] [controller] EPOCH 2 loss ppo:  -0.03758, loss val: 0.03881
[2022-12-07 04:11:35,873] [INFO] [controller] EPOCH 3 loss ppo:  -0.05380, loss val: 0.03845
[2022-12-07 04:11:35,920] [INFO] [controller] EPOCH 4 loss ppo:  -0.06917, loss val: 0.03937
[2022-12-07 04:11:35,929] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:11:36,139] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:11:36,139] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:11:43,775] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:11:50,532] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:11:57,199] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:12:04,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:12:10,652] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:12:17,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:12:24,928] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:12:31,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:12:38,289] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:12:45,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9900305413860151
[2022-12-07 04:12:45,014] [INFO] [runner_train_mujoco] Average state value: 0.4895837674240271
[2022-12-07 04:12:45,014] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 04:12:45,066] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.04693
[2022-12-07 04:12:45,110] [INFO] [controller] EPOCH 2 loss ppo:  -0.03531, loss val: 0.04615
[2022-12-07 04:12:45,160] [INFO] [controller] EPOCH 3 loss ppo:  -0.05333, loss val: 0.04663
[2022-12-07 04:12:45,201] [INFO] [controller] EPOCH 4 loss ppo:  -0.07075, loss val: 0.04529
[2022-12-07 04:12:45,209] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:12:45,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:12:45,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:12:52,213] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:12:59,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:13:06,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:13:12,844] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:13:19,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:13:26,771] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:13:33,445] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:13:40,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:13:47,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:13:54,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0693226965818259
[2022-12-07 04:13:54,040] [INFO] [runner_train_mujoco] Average state value: 0.471775083800157
[2022-12-07 04:13:54,040] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 04:13:54,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.03381
[2022-12-07 04:13:54,128] [INFO] [controller] EPOCH 2 loss ppo:  -0.03547, loss val: 0.03613
[2022-12-07 04:13:54,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.05538, loss val: 0.03368
[2022-12-07 04:13:54,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.06880, loss val: 0.03290
[2022-12-07 04:13:54,223] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:13:54,412] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:13:54,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:14:01,334] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:14:08,286] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:14:15,159] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:14:21,821] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:14:28,535] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:14:35,231] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:14:42,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:14:49,030] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:14:55,654] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:15:02,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.219879459799254
[2022-12-07 04:15:02,885] [INFO] [runner_train_mujoco] Average state value: 0.481869843373696
[2022-12-07 04:15:02,885] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 04:15:02,938] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04625
[2022-12-07 04:15:02,981] [INFO] [controller] EPOCH 2 loss ppo:  -0.03408, loss val: 0.04351
[2022-12-07 04:15:03,027] [INFO] [controller] EPOCH 3 loss ppo:  -0.05159, loss val: 0.04087
[2022-12-07 04:15:03,073] [INFO] [controller] EPOCH 4 loss ppo:  -0.06346, loss val: 0.03858
[2022-12-07 04:15:03,082] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:15:03,296] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:15:03,297] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:15:10,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:15:17,844] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:15:24,432] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:15:30,850] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:15:37,686] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:15:45,001] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:15:51,857] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:16:00,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:16:09,060] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:16:16,873] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2522669734683256
[2022-12-07 04:16:16,874] [INFO] [runner_train_mujoco] Average state value: 0.5478369157910348
[2022-12-07 04:16:16,874] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 04:16:16,926] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.03371
[2022-12-07 04:16:16,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.03504, loss val: 0.03422
[2022-12-07 04:16:17,025] [INFO] [controller] EPOCH 3 loss ppo:  -0.05242, loss val: 0.03529
[2022-12-07 04:16:17,072] [INFO] [controller] EPOCH 4 loss ppo:  -0.06669, loss val: 0.03488
[2022-12-07 04:16:17,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:16:17,290] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:16:17,291] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:16:25,414] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:16:33,389] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:16:40,739] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:16:48,440] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:16:56,348] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:17:04,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:17:12,482] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:17:19,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:17:27,687] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:17:35,779] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2448130028726354
[2022-12-07 04:17:35,779] [INFO] [runner_train_mujoco] Average state value: 0.5631897876660029
[2022-12-07 04:17:35,779] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 04:17:35,832] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.03944
[2022-12-07 04:17:35,874] [INFO] [controller] EPOCH 2 loss ppo:  -0.03420, loss val: 0.04152
[2022-12-07 04:17:35,915] [INFO] [controller] EPOCH 3 loss ppo:  -0.05416, loss val: 0.03928
[2022-12-07 04:17:35,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.06657, loss val: 0.04219
[2022-12-07 04:17:35,980] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:17:36,211] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:17:36,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:17:43,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:17:52,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:18:00,073] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:18:08,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:18:16,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:18:23,522] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:18:30,981] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:18:38,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:18:46,555] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:18:54,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2349686363745092
[2022-12-07 04:18:54,309] [INFO] [runner_train_mujoco] Average state value: 0.5608774074750642
[2022-12-07 04:18:54,310] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 04:18:54,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04029
[2022-12-07 04:18:54,423] [INFO] [controller] EPOCH 2 loss ppo:  -0.03520, loss val: 0.03995
[2022-12-07 04:18:54,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.05266, loss val: 0.03963
[2022-12-07 04:18:54,523] [INFO] [controller] EPOCH 4 loss ppo:  -0.06761, loss val: 0.03912
[2022-12-07 04:18:54,535] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:18:54,748] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:18:54,748] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:19:03,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:19:11,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:19:19,151] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:19:27,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:19:34,986] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:19:42,841] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:19:50,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:19:58,390] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:20:06,551] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:20:14,671] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6183442120115354
[2022-12-07 04:20:14,671] [INFO] [runner_train_mujoco] Average state value: 0.5486490103105705
[2022-12-07 04:20:14,671] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 04:20:14,727] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.04373
[2022-12-07 04:20:14,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.03309, loss val: 0.04419
[2022-12-07 04:20:14,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.04980, loss val: 0.04255
[2022-12-07 04:20:14,868] [INFO] [controller] EPOCH 4 loss ppo:  -0.06116, loss val: 0.04312
[2022-12-07 04:20:14,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:20:15,083] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:20:15,084] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:20:22,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:20:31,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:20:38,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:20:46,197] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:20:54,101] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:21:02,403] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:21:10,053] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:21:17,898] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:21:25,417] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:21:32,946] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.820377003858542
[2022-12-07 04:21:32,946] [INFO] [runner_train_mujoco] Average state value: 0.5220149109363555
[2022-12-07 04:21:32,946] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 04:21:33,000] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.03460
[2022-12-07 04:21:33,043] [INFO] [controller] EPOCH 2 loss ppo:  -0.03161, loss val: 0.03409
[2022-12-07 04:21:33,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.05173, loss val: 0.03416
[2022-12-07 04:21:33,131] [INFO] [controller] EPOCH 4 loss ppo:  -0.06630, loss val: 0.03297
[2022-12-07 04:21:33,140] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:21:33,342] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:21:33,342] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:21:41,456] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:21:49,448] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:21:57,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:22:06,386] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:22:14,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:22:21,795] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:22:29,659] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:22:36,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:22:44,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:22:52,239] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9792985420829794
[2022-12-07 04:22:52,239] [INFO] [runner_train_mujoco] Average state value: 0.5219028146266937
[2022-12-07 04:22:52,239] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 04:22:52,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.03836
[2022-12-07 04:22:52,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.02896, loss val: 0.03659
[2022-12-07 04:22:52,386] [INFO] [controller] EPOCH 3 loss ppo:  -0.04384, loss val: 0.03605
[2022-12-07 04:22:52,432] [INFO] [controller] EPOCH 4 loss ppo:  -0.05819, loss val: 0.03645
[2022-12-07 04:22:52,441] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:22:52,647] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:22:52,647] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:23:01,311] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:23:09,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:23:17,189] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:23:24,629] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:23:32,213] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:23:39,823] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:23:47,978] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:23:55,171] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:24:02,989] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:24:10,574] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9227414118488295
[2022-12-07 04:24:10,574] [INFO] [runner_train_mujoco] Average state value: 0.5250822658625742
[2022-12-07 04:24:10,574] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 04:24:10,643] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.05923
[2022-12-07 04:24:10,695] [INFO] [controller] EPOCH 2 loss ppo:  -0.03209, loss val: 0.06473
[2022-12-07 04:24:10,819] [INFO] [controller] EPOCH 3 loss ppo:  -0.05182, loss val: 0.06052
[2022-12-07 04:24:10,869] [INFO] [controller] EPOCH 4 loss ppo:  -0.06536, loss val: 0.05982
[2022-12-07 04:24:10,879] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:24:11,092] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:24:11,093] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:24:19,045] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:24:26,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:24:34,503] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:24:42,072] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:24:49,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:24:57,897] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:25:05,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:25:13,470] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:25:21,196] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:25:28,895] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.828087230537174
[2022-12-07 04:25:28,896] [INFO] [runner_train_mujoco] Average state value: 0.4684460463561118
[2022-12-07 04:25:28,896] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 04:25:28,963] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.10965
[2022-12-07 04:25:29,029] [INFO] [controller] EPOCH 2 loss ppo:  -0.03184, loss val: 0.10731
[2022-12-07 04:25:29,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.05178, loss val: 0.10599
[2022-12-07 04:25:29,135] [INFO] [controller] EPOCH 4 loss ppo:  -0.06360, loss val: 0.10576
[2022-12-07 04:25:29,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:25:29,348] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:25:29,349] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:25:37,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:25:45,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:25:53,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:26:01,092] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:26:09,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:26:17,188] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:26:24,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:26:32,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:26:40,019] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:26:47,775] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9299687159738366
[2022-12-07 04:26:47,776] [INFO] [runner_train_mujoco] Average state value: 0.5429168292408189
[2022-12-07 04:26:47,776] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 04:26:47,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.03902
[2022-12-07 04:26:47,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.03055, loss val: 0.03896
[2022-12-07 04:26:47,943] [INFO] [controller] EPOCH 3 loss ppo:  -0.04983, loss val: 0.04054
[2022-12-07 04:26:47,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.06414, loss val: 0.03849
[2022-12-07 04:26:48,004] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:26:48,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:26:48,208] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:26:55,728] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:27:03,904] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:27:11,789] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:27:19,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:27:27,504] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:27:35,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:27:42,853] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:27:50,521] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:27:58,057] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:28:05,428] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1362650200017828
[2022-12-07 04:28:05,429] [INFO] [runner_train_mujoco] Average state value: 0.548353668720772
[2022-12-07 04:28:05,429] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 04:28:05,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.03852
[2022-12-07 04:28:05,542] [INFO] [controller] EPOCH 2 loss ppo:  -0.03094, loss val: 0.04373
[2022-12-07 04:28:05,589] [INFO] [controller] EPOCH 3 loss ppo:  -0.04588, loss val: 0.03739
[2022-12-07 04:28:05,634] [INFO] [controller] EPOCH 4 loss ppo:  -0.06028, loss val: 0.03697
[2022-12-07 04:28:05,643] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:28:05,846] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:28:05,847] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:28:14,117] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:28:21,735] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:28:29,507] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:28:37,399] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:28:45,234] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:28:52,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:29:00,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:29:08,648] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:29:16,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:29:23,848] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.876810923247475
[2022-12-07 04:29:23,848] [INFO] [runner_train_mujoco] Average state value: 0.5484852583408355
[2022-12-07 04:29:23,848] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 04:29:23,905] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04327
[2022-12-07 04:29:23,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.03075, loss val: 0.04170
[2022-12-07 04:29:23,998] [INFO] [controller] EPOCH 3 loss ppo:  -0.04571, loss val: 0.04088
[2022-12-07 04:29:24,044] [INFO] [controller] EPOCH 4 loss ppo:  -0.05939, loss val: 0.04025
[2022-12-07 04:29:24,054] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:29:24,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:29:24,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:29:31,721] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:29:39,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:29:47,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:29:55,525] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:30:03,200] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:30:10,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:30:18,229] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:30:25,346] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:30:31,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:30:38,834] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.35989877961999
[2022-12-07 04:30:38,834] [INFO] [runner_train_mujoco] Average state value: 0.4579934587577979
[2022-12-07 04:30:38,834] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 04:30:38,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.07826
[2022-12-07 04:30:38,930] [INFO] [controller] EPOCH 2 loss ppo:  -0.02691, loss val: 0.07842
[2022-12-07 04:30:38,971] [INFO] [controller] EPOCH 3 loss ppo:  -0.04126, loss val: 0.07778
[2022-12-07 04:30:39,013] [INFO] [controller] EPOCH 4 loss ppo:  -0.05435, loss val: 0.07722
[2022-12-07 04:30:39,021] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:30:39,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:30:39,215] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:30:45,736] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:30:52,605] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:30:59,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:31:06,978] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:31:13,987] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:31:21,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:31:28,387] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:31:35,617] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:31:42,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:31:49,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6509626277105705
[2022-12-07 04:31:49,285] [INFO] [runner_train_mujoco] Average state value: 0.49942428557823104
[2022-12-07 04:31:49,285] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 04:31:49,333] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.04137
[2022-12-07 04:31:49,376] [INFO] [controller] EPOCH 2 loss ppo:  -0.02616, loss val: 0.04135
[2022-12-07 04:31:49,413] [INFO] [controller] EPOCH 3 loss ppo:  -0.04050, loss val: 0.04112
[2022-12-07 04:31:49,451] [INFO] [controller] EPOCH 4 loss ppo:  -0.05327, loss val: 0.03984
[2022-12-07 04:31:49,460] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:31:49,656] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:31:49,656] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:31:56,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:32:03,982] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:32:11,466] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:32:18,386] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:32:25,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:32:31,748] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:32:38,852] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:32:45,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:32:52,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:32:59,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8016104608635755
[2022-12-07 04:32:59,372] [INFO] [runner_train_mujoco] Average state value: 0.49864249617978923
[2022-12-07 04:32:59,372] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 04:32:59,425] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04022
[2022-12-07 04:32:59,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.02705, loss val: 0.04190
[2022-12-07 04:32:59,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.04293, loss val: 0.04151
[2022-12-07 04:32:59,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.05568, loss val: 0.04059
[2022-12-07 04:32:59,574] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:32:59,790] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:32:59,790] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:33:06,868] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:33:14,257] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:33:21,526] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:33:28,427] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:33:35,205] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:33:41,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:33:48,425] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:33:55,537] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:34:02,280] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:34:09,203] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7599160153703814
[2022-12-07 04:34:09,203] [INFO] [runner_train_mujoco] Average state value: 0.5052907246984542
[2022-12-07 04:34:09,204] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 04:34:09,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.05097
[2022-12-07 04:34:09,301] [INFO] [controller] EPOCH 2 loss ppo:  -0.02830, loss val: 0.05357
[2022-12-07 04:34:09,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.04371, loss val: 0.05148
[2022-12-07 04:34:09,381] [INFO] [controller] EPOCH 4 loss ppo:  -0.05483, loss val: 0.05711
[2022-12-07 04:34:09,390] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:34:09,573] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:34:09,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:34:16,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:34:23,971] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:34:31,086] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:34:37,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:34:44,727] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:34:51,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:34:58,417] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:35:05,558] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:35:12,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:35:19,144] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6883407715778547
[2022-12-07 04:35:19,144] [INFO] [runner_train_mujoco] Average state value: 0.49585248743991056
[2022-12-07 04:35:19,144] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 04:35:19,193] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.04916
[2022-12-07 04:35:19,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.02287, loss val: 0.05156
[2022-12-07 04:35:19,277] [INFO] [controller] EPOCH 3 loss ppo:  -0.03735, loss val: 0.04750
[2022-12-07 04:35:19,318] [INFO] [controller] EPOCH 4 loss ppo:  -0.05067, loss val: 0.04870
[2022-12-07 04:35:19,327] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:35:19,525] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:35:19,526] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:35:26,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:35:33,891] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:35:40,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:35:47,942] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:35:54,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:36:02,047] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:36:08,909] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:36:15,803] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:36:22,723] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:36:30,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.056382841312274
[2022-12-07 04:36:30,047] [INFO] [runner_train_mujoco] Average state value: 0.5270541650851568
[2022-12-07 04:36:30,048] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 04:36:30,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.03602
[2022-12-07 04:36:30,147] [INFO] [controller] EPOCH 2 loss ppo:  -0.02231, loss val: 0.03468
[2022-12-07 04:36:30,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.03816, loss val: 0.03431
[2022-12-07 04:36:30,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.05162, loss val: 0.03458
[2022-12-07 04:36:30,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:36:30,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:36:30,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:36:37,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:36:45,344] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:36:52,020] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:36:58,511] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:37:05,459] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:37:12,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:37:19,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:37:26,559] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:37:33,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:37:40,470] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.141046870624677
[2022-12-07 04:37:40,470] [INFO] [runner_train_mujoco] Average state value: 0.4675352738375465
[2022-12-07 04:37:40,470] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 04:37:40,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.06147
[2022-12-07 04:37:40,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.02185, loss val: 0.06302
[2022-12-07 04:37:40,672] [INFO] [controller] EPOCH 3 loss ppo:  -0.03447, loss val: 0.06179
[2022-12-07 04:37:40,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.04436, loss val: 0.06051
[2022-12-07 04:37:40,723] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:37:40,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:37:40,930] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:37:47,694] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:37:54,203] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:38:01,136] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:38:07,727] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:38:14,738] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:38:21,852] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:38:28,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:38:35,514] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:38:42,005] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:38:48,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.199457750143779
[2022-12-07 04:38:48,971] [INFO] [runner_train_mujoco] Average state value: 0.49550038497895005
[2022-12-07 04:38:48,971] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 04:38:49,020] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.05015
[2022-12-07 04:38:49,062] [INFO] [controller] EPOCH 2 loss ppo:  -0.02304, loss val: 0.04677
[2022-12-07 04:38:49,098] [INFO] [controller] EPOCH 3 loss ppo:  -0.03623, loss val: 0.04673
[2022-12-07 04:38:49,139] [INFO] [controller] EPOCH 4 loss ppo:  -0.04749, loss val: 0.05027
[2022-12-07 04:38:49,148] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:38:49,326] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:38:49,327] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:38:55,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:39:03,231] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:39:10,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:39:16,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:39:23,396] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:39:30,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:39:37,414] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:39:44,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:39:51,188] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:39:58,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3874779952076866
[2022-12-07 04:39:58,126] [INFO] [runner_train_mujoco] Average state value: 0.5176322983702024
[2022-12-07 04:39:58,126] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 04:39:58,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.03475
[2022-12-07 04:39:58,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.02097, loss val: 0.03492
[2022-12-07 04:39:58,263] [INFO] [controller] EPOCH 3 loss ppo:  -0.03228, loss val: 0.03488
[2022-12-07 04:39:58,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.04363, loss val: 0.03721
[2022-12-07 04:39:58,315] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:39:58,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:39:58,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:40:05,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:40:13,332] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:40:20,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:40:26,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:40:33,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:40:40,796] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:40:47,586] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:40:54,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:41:01,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:41:08,645] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3349587618583265
[2022-12-07 04:41:08,645] [INFO] [runner_train_mujoco] Average state value: 0.4608856734856963
[2022-12-07 04:41:08,645] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 04:41:08,694] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.06950
[2022-12-07 04:41:08,736] [INFO] [controller] EPOCH 2 loss ppo:  -0.01987, loss val: 0.06741
[2022-12-07 04:41:08,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.02833, loss val: 0.06900
[2022-12-07 04:41:08,815] [INFO] [controller] EPOCH 4 loss ppo:  -0.03841, loss val: 0.06863
[2022-12-07 04:41:08,824] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:41:09,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:41:09,020] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:41:16,454] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:41:23,581] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:41:30,466] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:41:37,692] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:41:44,716] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:41:51,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:41:59,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:42:05,928] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:42:12,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:42:19,865] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2925035917122676
[2022-12-07 04:42:19,865] [INFO] [runner_train_mujoco] Average state value: 0.45383725147073467
[2022-12-07 04:42:19,865] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 04:42:19,940] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.07773
[2022-12-07 04:42:19,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.01784, loss val: 0.07746
[2022-12-07 04:42:20,049] [INFO] [controller] EPOCH 3 loss ppo:  -0.02470, loss val: 0.07745
[2022-12-07 04:42:20,096] [INFO] [controller] EPOCH 4 loss ppo:  -0.03310, loss val: 0.07718
[2022-12-07 04:42:20,107] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:42:20,310] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:42:20,310] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:42:27,443] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:42:34,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:42:41,368] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:42:48,089] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:42:54,760] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:43:01,328] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:43:08,428] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:43:17,837] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:43:27,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:43:35,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6565478487783607
[2022-12-07 04:43:35,066] [INFO] [runner_train_mujoco] Average state value: 0.47896165425578757
[2022-12-07 04:43:35,067] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 04:43:35,127] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.07197
[2022-12-07 04:43:35,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.01673, loss val: 0.07301
[2022-12-07 04:43:35,216] [INFO] [controller] EPOCH 3 loss ppo:  -0.02132, loss val: 0.07178
[2022-12-07 04:43:35,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.02725, loss val: 0.07164
[2022-12-07 04:43:35,269] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:43:35,473] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:43:35,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:43:44,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:43:52,470] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:44:00,566] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:44:08,224] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:44:16,567] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:44:24,441] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:44:32,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:44:39,612] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:44:47,172] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:44:55,012] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3841866965396066
[2022-12-07 04:44:55,012] [INFO] [runner_train_mujoco] Average state value: 0.504265029600511
[2022-12-07 04:44:55,012] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 04:44:55,072] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04157
[2022-12-07 04:44:55,137] [INFO] [controller] EPOCH 2 loss ppo:  -0.01585, loss val: 0.04070
[2022-12-07 04:44:55,211] [INFO] [controller] EPOCH 3 loss ppo:  -0.01857, loss val: 0.04114
[2022-12-07 04:44:55,271] [INFO] [controller] EPOCH 4 loss ppo:  -0.02247, loss val: 0.04152
[2022-12-07 04:44:55,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:44:55,402] [INFO] [optimize] Finished learning.
