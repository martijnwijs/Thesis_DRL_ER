[2022-12-07 05:34:46,941] [INFO] [optimize] Starting learning
[2022-12-07 05:34:46,961] [INFO] [optimize] Starting learning process..
[2022-12-07 05:34:47,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:34:47,075] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:34:56,551] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:35:04,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:35:11,512] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:35:19,071] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:35:27,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:35:35,205] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:35:43,154] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:35:51,458] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:35:58,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:36:06,155] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5130301642085702
[2022-12-07 05:36:06,156] [INFO] [runner_train_mujoco] Average state value: 0.223133760544161
[2022-12-07 05:36:06,156] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 05:36:06,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01065, loss val: 0.27564
[2022-12-07 05:36:06,261] [INFO] [controller] EPOCH 2 loss ppo:  -0.05257, loss val: 0.24422
[2022-12-07 05:36:06,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.07198, loss val: 0.20801
[2022-12-07 05:36:06,358] [INFO] [controller] EPOCH 4 loss ppo:  -0.08311, loss val: 0.18330
[2022-12-07 05:36:06,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:36:06,586] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:36:06,586] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:36:13,830] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:36:21,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:36:28,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:36:36,669] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:36:45,145] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:36:53,164] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:37:00,377] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:37:07,955] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:37:15,382] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:37:22,877] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5402567716075083
[2022-12-07 05:37:22,877] [INFO] [runner_train_mujoco] Average state value: 0.40401510993080836
[2022-12-07 05:37:22,877] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 05:37:22,934] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.15252
[2022-12-07 05:37:22,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.05338, loss val: 0.13489
[2022-12-07 05:37:23,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.07075, loss val: 0.12303
[2022-12-07 05:37:23,085] [INFO] [controller] EPOCH 4 loss ppo:  -0.08208, loss val: 0.11600
[2022-12-07 05:37:23,097] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:37:23,303] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:37:23,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:37:31,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:37:39,444] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:37:47,007] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:37:54,443] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:38:01,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:38:09,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:38:17,877] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:38:25,935] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:38:33,259] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:38:40,667] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5591961781097433
[2022-12-07 05:38:40,667] [INFO] [runner_train_mujoco] Average state value: 0.5465570309245958
[2022-12-07 05:38:40,667] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 05:38:40,726] [INFO] [controller] EPOCH 1 loss ppo:  -0.01122, loss val: 0.10785
[2022-12-07 05:38:40,768] [INFO] [controller] EPOCH 2 loss ppo:  -0.04627, loss val: 0.10252
[2022-12-07 05:38:40,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.06629, loss val: 0.10206
[2022-12-07 05:38:40,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.07731, loss val: 0.09222
[2022-12-07 05:38:40,871] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:38:41,079] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:38:41,080] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:38:48,664] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:38:56,392] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:39:03,421] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:39:11,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:39:18,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:39:26,695] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:39:34,875] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:39:42,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:39:49,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:39:56,581] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8293226587402136
[2022-12-07 05:39:56,581] [INFO] [runner_train_mujoco] Average state value: 0.5654835871035855
[2022-12-07 05:39:56,581] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 05:39:56,637] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.09961
[2022-12-07 05:39:56,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.04367, loss val: 0.09672
[2022-12-07 05:39:56,739] [INFO] [controller] EPOCH 3 loss ppo:  -0.06063, loss val: 0.09269
[2022-12-07 05:39:56,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.07250, loss val: 0.08786
[2022-12-07 05:39:56,791] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:39:56,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:39:56,998] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:40:04,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:40:12,108] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:40:20,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:40:27,795] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:40:35,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:40:42,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:40:50,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:40:58,535] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:41:06,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:41:14,082] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48345689767595423
[2022-12-07 05:41:14,083] [INFO] [runner_train_mujoco] Average state value: 0.5928602717183531
[2022-12-07 05:41:14,083] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 05:41:14,134] [INFO] [controller] EPOCH 1 loss ppo:  -0.01018, loss val: 0.07211
[2022-12-07 05:41:14,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.04367, loss val: 0.07224
[2022-12-07 05:41:14,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.06235, loss val: 0.06671
[2022-12-07 05:41:14,261] [INFO] [controller] EPOCH 4 loss ppo:  -0.07287, loss val: 0.06491
[2022-12-07 05:41:14,269] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:41:14,465] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:41:14,465] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:41:22,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:41:29,867] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:41:37,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:41:44,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:41:52,603] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:42:02,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:42:11,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:42:20,933] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:42:29,456] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:42:37,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5773577702039094
[2022-12-07 05:42:37,907] [INFO] [runner_train_mujoco] Average state value: 0.5963973488857349
[2022-12-07 05:42:37,907] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 05:42:37,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.06391
[2022-12-07 05:42:38,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.04104, loss val: 0.06101
[2022-12-07 05:42:38,072] [INFO] [controller] EPOCH 3 loss ppo:  -0.05801, loss val: 0.05854
[2022-12-07 05:42:38,125] [INFO] [controller] EPOCH 4 loss ppo:  -0.07087, loss val: 0.05639
[2022-12-07 05:42:38,135] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:42:38,350] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:42:38,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:42:47,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:42:55,775] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:43:03,609] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:43:12,031] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:43:20,655] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:43:29,174] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:43:36,889] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:43:44,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:43:52,123] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:43:59,648] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.766765656714958
[2022-12-07 05:43:59,648] [INFO] [runner_train_mujoco] Average state value: 0.5291838528936108
[2022-12-07 05:43:59,648] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 05:43:59,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.05522
[2022-12-07 05:43:59,741] [INFO] [controller] EPOCH 2 loss ppo:  -0.04112, loss val: 0.05374
[2022-12-07 05:43:59,785] [INFO] [controller] EPOCH 3 loss ppo:  -0.06100, loss val: 0.04996
[2022-12-07 05:43:59,829] [INFO] [controller] EPOCH 4 loss ppo:  -0.07367, loss val: 0.05144
[2022-12-07 05:43:59,839] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:44:00,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:44:00,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:44:08,247] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:44:15,409] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:44:22,561] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:44:29,304] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:44:36,233] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:44:43,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:44:50,336] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:44:57,513] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:45:04,634] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:45:11,412] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9164354074085711
[2022-12-07 05:45:11,413] [INFO] [runner_train_mujoco] Average state value: 0.5420934049934149
[2022-12-07 05:45:11,413] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 05:45:11,461] [INFO] [controller] EPOCH 1 loss ppo:  -0.01121, loss val: 0.05255
[2022-12-07 05:45:11,503] [INFO] [controller] EPOCH 2 loss ppo:  -0.03986, loss val: 0.04919
[2022-12-07 05:45:11,608] [INFO] [controller] EPOCH 3 loss ppo:  -0.05845, loss val: 0.04849
[2022-12-07 05:45:11,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.07269, loss val: 0.04996
[2022-12-07 05:45:11,659] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:45:11,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:45:11,862] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:45:18,644] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:45:25,415] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:45:32,136] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:45:39,005] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:45:46,546] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:45:53,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:46:00,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:46:07,579] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:46:14,666] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:46:21,618] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6596167117142182
[2022-12-07 05:46:21,619] [INFO] [runner_train_mujoco] Average state value: 0.5008277941793204
[2022-12-07 05:46:21,619] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 05:46:21,668] [INFO] [controller] EPOCH 1 loss ppo:  -0.01232, loss val: 0.05089
[2022-12-07 05:46:21,708] [INFO] [controller] EPOCH 2 loss ppo:  -0.04030, loss val: 0.05308
[2022-12-07 05:46:21,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.05828, loss val: 0.05229
[2022-12-07 05:46:21,793] [INFO] [controller] EPOCH 4 loss ppo:  -0.07381, loss val: 0.05010
[2022-12-07 05:46:21,804] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:46:22,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:46:22,010] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:46:28,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:46:36,412] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:46:43,639] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:46:50,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:46:57,289] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:47:04,105] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:47:10,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:47:18,220] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:47:24,845] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:47:32,106] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6494235936309316
[2022-12-07 05:47:32,106] [INFO] [runner_train_mujoco] Average state value: 0.5236529827614625
[2022-12-07 05:47:32,106] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 05:47:32,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01044, loss val: 0.04380
[2022-12-07 05:47:32,205] [INFO] [controller] EPOCH 2 loss ppo:  -0.04359, loss val: 0.04335
[2022-12-07 05:47:32,250] [INFO] [controller] EPOCH 3 loss ppo:  -0.06165, loss val: 0.04401
[2022-12-07 05:47:32,296] [INFO] [controller] EPOCH 4 loss ppo:  -0.07559, loss val: 0.04284
[2022-12-07 05:47:32,303] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:47:32,508] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:47:32,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:47:39,141] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:47:46,192] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:47:52,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:47:59,647] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:48:06,877] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:48:13,947] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:48:21,403] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:48:28,019] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:48:35,050] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:48:42,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6643007097081036
[2022-12-07 05:48:42,191] [INFO] [runner_train_mujoco] Average state value: 0.5566771372358004
[2022-12-07 05:48:42,191] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 05:48:42,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01249, loss val: 0.04170
[2022-12-07 05:48:42,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.04292, loss val: 0.04170
[2022-12-07 05:48:42,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.06154, loss val: 0.04108
[2022-12-07 05:48:42,380] [INFO] [controller] EPOCH 4 loss ppo:  -0.07381, loss val: 0.04042
[2022-12-07 05:48:42,390] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:48:42,591] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:48:42,591] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:48:49,474] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:48:56,730] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:49:04,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:49:11,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:49:18,283] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:49:25,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:49:31,991] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:49:38,539] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:49:45,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:49:52,410] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5699740428615999
[2022-12-07 05:49:52,411] [INFO] [runner_train_mujoco] Average state value: 0.5601866897195579
[2022-12-07 05:49:52,411] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 05:49:52,459] [INFO] [controller] EPOCH 1 loss ppo:  -0.00931, loss val: 0.03913
[2022-12-07 05:49:52,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.03952, loss val: 0.04014
[2022-12-07 05:49:52,545] [INFO] [controller] EPOCH 3 loss ppo:  -0.05660, loss val: 0.04008
[2022-12-07 05:49:52,585] [INFO] [controller] EPOCH 4 loss ppo:  -0.06979, loss val: 0.03745
[2022-12-07 05:49:52,594] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:49:52,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:49:52,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:50:00,416] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:50:07,610] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:50:14,150] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:50:20,687] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:50:27,718] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:50:34,603] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:50:42,183] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:50:48,795] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:50:55,722] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:51:02,903] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6838988009287335
[2022-12-07 05:51:02,903] [INFO] [runner_train_mujoco] Average state value: 0.5332571773131688
[2022-12-07 05:51:02,903] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 05:51:02,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.04936
[2022-12-07 05:51:02,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.03778, loss val: 0.04644
[2022-12-07 05:51:03,042] [INFO] [controller] EPOCH 3 loss ppo:  -0.05233, loss val: 0.04563
[2022-12-07 05:51:03,084] [INFO] [controller] EPOCH 4 loss ppo:  -0.06460, loss val: 0.04373
[2022-12-07 05:51:03,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:51:03,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:51:03,288] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:51:10,116] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:51:17,150] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:51:23,766] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:51:30,389] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:51:37,005] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:51:43,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:51:50,994] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:51:57,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:52:04,581] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:52:11,621] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.645785438864307
[2022-12-07 05:52:11,621] [INFO] [runner_train_mujoco] Average state value: 0.46490335971117025
[2022-12-07 05:52:11,622] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 05:52:11,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.00998, loss val: 0.04504
[2022-12-07 05:52:11,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.04045, loss val: 0.04587
[2022-12-07 05:52:11,759] [INFO] [controller] EPOCH 3 loss ppo:  -0.05901, loss val: 0.04544
[2022-12-07 05:52:11,797] [INFO] [controller] EPOCH 4 loss ppo:  -0.07246, loss val: 0.04613
[2022-12-07 05:52:11,806] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:52:11,976] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:52:11,976] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:52:19,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:52:26,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:52:33,381] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:52:39,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:52:46,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:52:53,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:53:00,626] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:53:07,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:53:14,137] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:53:20,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.674643467452755
[2022-12-07 05:53:20,651] [INFO] [runner_train_mujoco] Average state value: 0.47262911071379987
[2022-12-07 05:53:20,652] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 05:53:20,702] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.03729
[2022-12-07 05:53:20,746] [INFO] [controller] EPOCH 2 loss ppo:  -0.04227, loss val: 0.03573
[2022-12-07 05:53:20,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.05980, loss val: 0.03654
[2022-12-07 05:53:20,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.07517, loss val: 0.03654
[2022-12-07 05:53:20,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:53:21,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:53:21,056] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:53:28,315] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:53:35,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:53:42,486] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:53:49,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:53:56,473] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:54:03,364] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:54:10,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:54:17,137] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:54:23,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:54:30,156] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9518181391862841
[2022-12-07 05:54:30,156] [INFO] [runner_train_mujoco] Average state value: 0.5283296992580095
[2022-12-07 05:54:30,157] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 05:54:30,204] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.02724
[2022-12-07 05:54:30,246] [INFO] [controller] EPOCH 2 loss ppo:  -0.04060, loss val: 0.02784
[2022-12-07 05:54:30,281] [INFO] [controller] EPOCH 3 loss ppo:  -0.05777, loss val: 0.02954
[2022-12-07 05:54:30,315] [INFO] [controller] EPOCH 4 loss ppo:  -0.06884, loss val: 0.02878
[2022-12-07 05:54:30,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:54:30,523] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:54:30,523] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:54:38,112] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:54:45,504] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:54:52,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:54:59,129] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:55:05,890] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:55:12,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:55:19,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:55:26,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:55:33,973] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:55:40,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7498155769173362
[2022-12-07 05:55:40,702] [INFO] [runner_train_mujoco] Average state value: 0.534813454379638
[2022-12-07 05:55:40,702] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 05:55:40,762] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.04380
[2022-12-07 05:55:40,802] [INFO] [controller] EPOCH 2 loss ppo:  -0.03895, loss val: 0.04262
[2022-12-07 05:55:40,844] [INFO] [controller] EPOCH 3 loss ppo:  -0.05924, loss val: 0.04243
[2022-12-07 05:55:40,887] [INFO] [controller] EPOCH 4 loss ppo:  -0.07556, loss val: 0.04310
[2022-12-07 05:55:40,896] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:55:41,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:55:41,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:55:48,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:55:55,104] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:56:02,069] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:56:08,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:56:15,272] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:56:22,240] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:56:29,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:56:35,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:56:42,705] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:56:49,582] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7992434692136724
[2022-12-07 05:56:49,582] [INFO] [runner_train_mujoco] Average state value: 0.5230038740237555
[2022-12-07 05:56:49,582] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 05:56:49,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.02742
[2022-12-07 05:56:49,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.04599, loss val: 0.02711
[2022-12-07 05:56:49,727] [INFO] [controller] EPOCH 3 loss ppo:  -0.06762, loss val: 0.02740
[2022-12-07 05:56:49,773] [INFO] [controller] EPOCH 4 loss ppo:  -0.08107, loss val: 0.02901
[2022-12-07 05:56:49,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:56:49,999] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:56:49,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:56:56,994] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:57:04,468] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:57:11,372] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:57:18,183] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:57:24,985] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:57:31,554] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:57:38,710] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:57:45,612] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:57:52,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:57:59,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7783209211041116
[2022-12-07 05:57:59,343] [INFO] [runner_train_mujoco] Average state value: 0.5474230224688847
[2022-12-07 05:57:59,343] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 05:57:59,397] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.03211
[2022-12-07 05:57:59,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.04189, loss val: 0.03339
[2022-12-07 05:57:59,590] [INFO] [controller] EPOCH 3 loss ppo:  -0.05767, loss val: 0.03167
[2022-12-07 05:57:59,631] [INFO] [controller] EPOCH 4 loss ppo:  -0.07083, loss val: 0.03619
[2022-12-07 05:57:59,641] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:57:59,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:57:59,852] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:58:06,761] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:58:14,990] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:58:21,770] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:58:28,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:58:35,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:58:42,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:58:49,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:58:55,978] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:59:03,033] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:59:09,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7034156232857641
[2022-12-07 05:59:09,751] [INFO] [runner_train_mujoco] Average state value: 0.5564818951388201
[2022-12-07 05:59:09,751] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:59:09,808] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.03685
[2022-12-07 05:59:09,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.03764, loss val: 0.03637
[2022-12-07 05:59:09,888] [INFO] [controller] EPOCH 3 loss ppo:  -0.05571, loss val: 0.03987
[2022-12-07 05:59:09,940] [INFO] [controller] EPOCH 4 loss ppo:  -0.06613, loss val: 0.03274
[2022-12-07 05:59:09,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:59:10,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:59:10,143] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:59:17,121] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:59:23,812] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:59:30,960] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:59:37,547] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:59:44,867] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:59:51,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:59:58,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:00:05,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:00:12,577] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:00:19,748] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9389895329856855
[2022-12-07 06:00:19,748] [INFO] [runner_train_mujoco] Average state value: 0.5060188212494054
[2022-12-07 06:00:19,748] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 06:00:19,800] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.03456
[2022-12-07 06:00:19,843] [INFO] [controller] EPOCH 2 loss ppo:  -0.03853, loss val: 0.04359
[2022-12-07 06:00:19,887] [INFO] [controller] EPOCH 3 loss ppo:  -0.05709, loss val: 0.03707
[2022-12-07 06:00:19,931] [INFO] [controller] EPOCH 4 loss ppo:  -0.07221, loss val: 0.03719
[2022-12-07 06:00:19,940] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:00:20,146] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:00:20,146] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:00:27,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:00:34,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:00:41,145] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:00:47,856] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:00:54,690] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:01:01,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:01:08,370] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:01:15,772] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:01:22,656] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:01:29,242] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8314414208356056
[2022-12-07 06:01:29,242] [INFO] [runner_train_mujoco] Average state value: 0.5221923887232939
[2022-12-07 06:01:29,242] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 06:01:29,283] [INFO] [controller] EPOCH 1 loss ppo:  -0.01175, loss val: 0.03406
[2022-12-07 06:01:29,322] [INFO] [controller] EPOCH 2 loss ppo:  -0.04055, loss val: 0.03379
[2022-12-07 06:01:29,364] [INFO] [controller] EPOCH 3 loss ppo:  -0.05775, loss val: 0.03424
[2022-12-07 06:01:29,401] [INFO] [controller] EPOCH 4 loss ppo:  -0.07242, loss val: 0.03429
[2022-12-07 06:01:29,410] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:01:29,625] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:01:29,625] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:01:36,427] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:01:43,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:01:49,704] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:01:56,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:02:04,124] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:02:10,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:02:18,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:02:24,897] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:02:31,723] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:02:38,816] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0441680361720103
[2022-12-07 06:02:38,816] [INFO] [runner_train_mujoco] Average state value: 0.5585519521931807
[2022-12-07 06:02:38,816] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 06:02:38,859] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.03302
[2022-12-07 06:02:38,898] [INFO] [controller] EPOCH 2 loss ppo:  -0.03533, loss val: 0.03443
[2022-12-07 06:02:38,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.05121, loss val: 0.03353
[2022-12-07 06:02:38,978] [INFO] [controller] EPOCH 4 loss ppo:  -0.06831, loss val: 0.03537
[2022-12-07 06:02:38,987] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:02:39,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:02:39,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:02:46,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:02:53,376] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:03:00,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:03:07,275] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:03:14,279] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:03:21,174] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:03:27,902] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:03:34,377] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:03:41,386] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:03:48,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9896143948596355
[2022-12-07 06:03:48,201] [INFO] [runner_train_mujoco] Average state value: 0.5708382987678051
[2022-12-07 06:03:48,201] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 06:03:48,256] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.04436
[2022-12-07 06:03:48,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.03597, loss val: 0.04281
[2022-12-07 06:03:48,343] [INFO] [controller] EPOCH 3 loss ppo:  -0.05395, loss val: 0.04060
[2022-12-07 06:03:48,387] [INFO] [controller] EPOCH 4 loss ppo:  -0.06789, loss val: 0.03907
[2022-12-07 06:03:48,397] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:03:48,603] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:03:48,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:03:55,364] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:04:02,720] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:04:09,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:04:16,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:04:23,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:04:30,064] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:04:37,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:04:44,316] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:04:51,472] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:04:58,080] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.03697037115242
[2022-12-07 06:04:58,080] [INFO] [runner_train_mujoco] Average state value: 0.5158207263449828
[2022-12-07 06:04:58,080] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 06:04:58,131] [INFO] [controller] EPOCH 1 loss ppo:  -0.01151, loss val: 0.04039
[2022-12-07 06:04:58,178] [INFO] [controller] EPOCH 2 loss ppo:  -0.03893, loss val: 0.04095
[2022-12-07 06:04:58,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.05873, loss val: 0.03964
[2022-12-07 06:04:58,270] [INFO] [controller] EPOCH 4 loss ppo:  -0.07531, loss val: 0.04072
[2022-12-07 06:04:58,280] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:04:58,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:04:58,483] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:05:06,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:05:13,125] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:05:19,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:05:26,091] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:05:32,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:05:39,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:05:46,645] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:05:53,605] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:06:00,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:06:07,690] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8087729867586398
[2022-12-07 06:06:07,690] [INFO] [runner_train_mujoco] Average state value: 0.4593768238176902
[2022-12-07 06:06:07,691] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 06:06:07,737] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.05283
[2022-12-07 06:06:07,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.03786, loss val: 0.05291
[2022-12-07 06:06:07,823] [INFO] [controller] EPOCH 3 loss ppo:  -0.05504, loss val: 0.05071
[2022-12-07 06:06:07,867] [INFO] [controller] EPOCH 4 loss ppo:  -0.06966, loss val: 0.04977
[2022-12-07 06:06:07,876] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:06:08,076] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:06:08,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:06:15,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:06:21,888] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:06:28,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:06:35,157] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:06:42,405] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:06:49,740] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:06:56,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:07:03,406] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:07:11,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:07:18,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1477894997604818
[2022-12-07 06:07:18,739] [INFO] [runner_train_mujoco] Average state value: 0.4931965491573016
[2022-12-07 06:07:18,739] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 06:07:18,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.04508
[2022-12-07 06:07:18,846] [INFO] [controller] EPOCH 2 loss ppo:  -0.03956, loss val: 0.04463
[2022-12-07 06:07:18,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.06200, loss val: 0.04391
[2022-12-07 06:07:18,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.07647, loss val: 0.04375
[2022-12-07 06:07:18,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:07:19,162] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:07:19,162] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:07:26,271] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:07:33,593] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:07:40,649] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:07:47,498] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:07:54,090] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:08:00,542] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:08:07,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:08:15,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:08:22,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:08:29,217] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1932528104293578
[2022-12-07 06:08:29,218] [INFO] [runner_train_mujoco] Average state value: 0.5293760515153407
[2022-12-07 06:08:29,218] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 06:08:29,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.04180
[2022-12-07 06:08:29,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.03990, loss val: 0.04162
[2022-12-07 06:08:29,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.06437, loss val: 0.04262
[2022-12-07 06:08:29,413] [INFO] [controller] EPOCH 4 loss ppo:  -0.07718, loss val: 0.04066
[2022-12-07 06:08:29,422] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:08:29,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:08:29,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:08:36,997] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:08:44,186] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:08:51,376] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:08:57,965] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:09:04,849] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:09:11,695] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:09:18,575] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:09:25,115] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:09:32,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:09:39,454] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5222019717654085
[2022-12-07 06:09:39,454] [INFO] [runner_train_mujoco] Average state value: 0.5525984833141169
[2022-12-07 06:09:39,454] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 06:09:39,505] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03921
[2022-12-07 06:09:39,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.03685, loss val: 0.03888
[2022-12-07 06:09:39,595] [INFO] [controller] EPOCH 3 loss ppo:  -0.05494, loss val: 0.04004
[2022-12-07 06:09:39,639] [INFO] [controller] EPOCH 4 loss ppo:  -0.06724, loss val: 0.03556
[2022-12-07 06:09:39,649] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:09:39,845] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:09:39,846] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:09:46,655] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:09:54,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:10:01,392] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:10:07,989] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:10:14,494] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:10:21,283] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:10:28,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:10:35,586] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:10:42,796] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:10:49,292] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6818866008113489
[2022-12-07 06:10:49,292] [INFO] [runner_train_mujoco] Average state value: 0.5253599557677904
[2022-12-07 06:10:49,292] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 06:10:49,342] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.03403
[2022-12-07 06:10:49,380] [INFO] [controller] EPOCH 2 loss ppo:  -0.03894, loss val: 0.03624
[2022-12-07 06:10:49,487] [INFO] [controller] EPOCH 3 loss ppo:  -0.05654, loss val: 0.03791
[2022-12-07 06:10:49,531] [INFO] [controller] EPOCH 4 loss ppo:  -0.07059, loss val: 0.03878
[2022-12-07 06:10:49,540] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:10:49,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:10:49,738] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:10:56,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:11:03,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:11:10,432] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:11:17,532] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:11:24,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:11:31,089] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:11:37,590] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:11:45,031] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:11:54,773] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:12:02,243] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3721114512892094
[2022-12-07 06:12:02,243] [INFO] [runner_train_mujoco] Average state value: 0.4554251234531403
[2022-12-07 06:12:02,243] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 06:12:02,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.05910
[2022-12-07 06:12:02,337] [INFO] [controller] EPOCH 2 loss ppo:  -0.03829, loss val: 0.07152
[2022-12-07 06:12:02,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.05456, loss val: 0.06756
[2022-12-07 06:12:02,423] [INFO] [controller] EPOCH 4 loss ppo:  -0.06900, loss val: 0.05686
[2022-12-07 06:12:02,432] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:12:02,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:12:02,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:12:10,888] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:12:18,923] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:12:26,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:12:34,984] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:12:42,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:12:51,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:12:59,491] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:13:07,426] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:13:15,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:13:23,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5503535877800143
[2022-12-07 06:13:23,818] [INFO] [runner_train_mujoco] Average state value: 0.47473417489975694
[2022-12-07 06:13:23,818] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 06:13:23,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.06966
[2022-12-07 06:13:23,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.03579, loss val: 0.07428
[2022-12-07 06:13:23,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.05445, loss val: 0.06810
[2022-12-07 06:13:24,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.07150, loss val: 0.07170
[2022-12-07 06:13:24,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:13:24,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:13:24,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:13:32,284] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:13:40,058] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:13:48,154] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:13:55,772] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:14:03,898] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:14:11,878] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:14:19,328] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:14:26,920] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:14:35,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:14:42,932] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.688541503157202
[2022-12-07 06:14:42,932] [INFO] [runner_train_mujoco] Average state value: 0.5492261438171069
[2022-12-07 06:14:42,932] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 06:14:42,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.04377
[2022-12-07 06:14:43,032] [INFO] [controller] EPOCH 2 loss ppo:  -0.03417, loss val: 0.04545
[2022-12-07 06:14:43,080] [INFO] [controller] EPOCH 3 loss ppo:  -0.05252, loss val: 0.04339
[2022-12-07 06:14:43,133] [INFO] [controller] EPOCH 4 loss ppo:  -0.06767, loss val: 0.04249
[2022-12-07 06:14:43,143] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:14:43,365] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:14:43,365] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:14:51,489] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:14:59,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:15:07,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:15:15,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:15:22,858] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:15:30,824] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:15:38,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:15:46,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:15:54,911] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:16:02,193] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4524685370441626
[2022-12-07 06:16:02,193] [INFO] [runner_train_mujoco] Average state value: 0.5048601996675134
[2022-12-07 06:16:02,193] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 06:16:02,245] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.06113
[2022-12-07 06:16:02,292] [INFO] [controller] EPOCH 2 loss ppo:  -0.03607, loss val: 0.06113
[2022-12-07 06:16:02,341] [INFO] [controller] EPOCH 3 loss ppo:  -0.05771, loss val: 0.06101
[2022-12-07 06:16:02,382] [INFO] [controller] EPOCH 4 loss ppo:  -0.07039, loss val: 0.05942
[2022-12-07 06:16:02,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:16:02,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:16:02,597] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:16:10,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:16:18,381] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:16:26,183] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:16:34,473] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:16:43,268] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:16:51,266] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:16:59,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:17:06,310] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:17:14,356] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:17:22,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0741661130357483
[2022-12-07 06:17:22,468] [INFO] [runner_train_mujoco] Average state value: 0.5443076983094215
[2022-12-07 06:17:22,468] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 06:17:22,528] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.03754
[2022-12-07 06:17:22,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.03393, loss val: 0.03833
[2022-12-07 06:17:22,625] [INFO] [controller] EPOCH 3 loss ppo:  -0.05080, loss val: 0.03646
[2022-12-07 06:17:22,671] [INFO] [controller] EPOCH 4 loss ppo:  -0.06272, loss val: 0.03626
[2022-12-07 06:17:22,681] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:17:22,886] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:17:22,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:17:30,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:17:38,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:17:46,895] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:17:54,807] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:18:02,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:18:10,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:18:18,536] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:18:25,495] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:18:33,117] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:18:40,757] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.209698558151799
[2022-12-07 06:18:40,758] [INFO] [runner_train_mujoco] Average state value: 0.4921572142913937
[2022-12-07 06:18:40,758] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 06:18:40,813] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.06340
[2022-12-07 06:18:40,864] [INFO] [controller] EPOCH 2 loss ppo:  -0.03729, loss val: 0.06196
[2022-12-07 06:18:40,912] [INFO] [controller] EPOCH 3 loss ppo:  -0.05670, loss val: 0.06102
[2022-12-07 06:18:40,958] [INFO] [controller] EPOCH 4 loss ppo:  -0.07002, loss val: 0.05858
[2022-12-07 06:18:40,969] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:18:41,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:18:41,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:18:49,621] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:18:57,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:19:05,363] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:19:13,376] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:19:21,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:19:29,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:19:38,089] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:19:46,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:19:54,325] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:20:01,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.381726084231095
[2022-12-07 06:20:01,697] [INFO] [runner_train_mujoco] Average state value: 0.4946517697572708
[2022-12-07 06:20:01,697] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 06:20:01,748] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04498
[2022-12-07 06:20:01,798] [INFO] [controller] EPOCH 2 loss ppo:  -0.03231, loss val: 0.04663
[2022-12-07 06:20:01,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.05024, loss val: 0.04376
[2022-12-07 06:20:01,889] [INFO] [controller] EPOCH 4 loss ppo:  -0.06486, loss val: 0.04079
[2022-12-07 06:20:01,899] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:20:02,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:20:02,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:20:10,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:20:18,686] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:20:25,899] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:20:33,844] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:20:41,563] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:20:50,032] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:20:57,535] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:21:05,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:21:12,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:21:20,421] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4044513294737087
[2022-12-07 06:21:20,422] [INFO] [runner_train_mujoco] Average state value: 0.5173825457195441
[2022-12-07 06:21:20,422] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 06:21:20,482] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04184
[2022-12-07 06:21:20,529] [INFO] [controller] EPOCH 2 loss ppo:  -0.03593, loss val: 0.04458
[2022-12-07 06:21:20,574] [INFO] [controller] EPOCH 3 loss ppo:  -0.05021, loss val: 0.04491
[2022-12-07 06:21:20,625] [INFO] [controller] EPOCH 4 loss ppo:  -0.06400, loss val: 0.04228
[2022-12-07 06:21:20,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:21:20,843] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:21:20,843] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:21:28,854] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:21:37,513] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:21:45,847] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:21:53,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:22:01,277] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:22:09,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:22:17,657] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:22:25,919] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:22:33,938] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:22:41,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.306309385487247
[2022-12-07 06:22:41,005] [INFO] [runner_train_mujoco] Average state value: 0.45179188555106525
[2022-12-07 06:22:41,005] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 06:22:41,056] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.11549
[2022-12-07 06:22:41,102] [INFO] [controller] EPOCH 2 loss ppo:  -0.03091, loss val: 0.11585
[2022-12-07 06:22:41,153] [INFO] [controller] EPOCH 3 loss ppo:  -0.04546, loss val: 0.11073
[2022-12-07 06:22:41,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.06045, loss val: 0.11257
[2022-12-07 06:22:41,208] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:22:41,424] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:22:41,425] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:22:49,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:22:57,906] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:23:05,431] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:23:13,229] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:23:21,147] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:23:28,927] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:23:36,966] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:23:45,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:23:53,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:24:01,301] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2749686199088703
[2022-12-07 06:24:01,302] [INFO] [runner_train_mujoco] Average state value: 0.47410150633503995
[2022-12-07 06:24:01,302] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 06:24:01,359] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.07908
[2022-12-07 06:24:01,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.03122, loss val: 0.07660
[2022-12-07 06:24:01,475] [INFO] [controller] EPOCH 3 loss ppo:  -0.05067, loss val: 0.07587
[2022-12-07 06:24:01,526] [INFO] [controller] EPOCH 4 loss ppo:  -0.06582, loss val: 0.07931
[2022-12-07 06:24:01,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:24:01,758] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:24:01,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:24:10,072] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:24:17,863] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:24:25,774] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:24:33,498] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:24:41,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:24:49,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:24:57,308] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:25:05,391] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:25:13,268] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:25:21,282] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.49040899291571
[2022-12-07 06:25:21,282] [INFO] [runner_train_mujoco] Average state value: 0.5167466892736654
[2022-12-07 06:25:21,282] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 06:25:21,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.07276
[2022-12-07 06:25:21,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.03079, loss val: 0.07173
[2022-12-07 06:25:21,499] [INFO] [controller] EPOCH 3 loss ppo:  -0.05167, loss val: 0.07021
[2022-12-07 06:25:21,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.06437, loss val: 0.06946
[2022-12-07 06:25:21,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:25:21,755] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:25:21,756] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:25:29,504] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:25:37,635] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:25:45,680] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:25:53,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:26:00,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:26:08,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:26:16,692] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:26:24,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:26:32,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:26:41,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.527479013485204
[2022-12-07 06:26:41,550] [INFO] [runner_train_mujoco] Average state value: 0.5110638140315811
[2022-12-07 06:26:41,550] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 06:26:41,611] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.08192
[2022-12-07 06:26:41,659] [INFO] [controller] EPOCH 2 loss ppo:  -0.03381, loss val: 0.08066
[2022-12-07 06:26:41,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.05079, loss val: 0.07616
[2022-12-07 06:26:41,758] [INFO] [controller] EPOCH 4 loss ppo:  -0.06101, loss val: 0.07380
[2022-12-07 06:26:41,768] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:26:41,979] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:26:41,979] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:26:50,361] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:26:58,320] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:27:06,565] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:27:14,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:27:21,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:29,568] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:27:37,548] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:27:45,458] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:27:53,495] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:28:01,406] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.713355359762624
[2022-12-07 06:28:01,406] [INFO] [runner_train_mujoco] Average state value: 0.5503654976474742
[2022-12-07 06:28:01,406] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 06:28:01,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.06995
[2022-12-07 06:28:01,507] [INFO] [controller] EPOCH 2 loss ppo:  -0.03163, loss val: 0.06894
[2022-12-07 06:28:01,554] [INFO] [controller] EPOCH 3 loss ppo:  -0.04786, loss val: 0.06938
[2022-12-07 06:28:01,600] [INFO] [controller] EPOCH 4 loss ppo:  -0.06150, loss val: 0.06886
[2022-12-07 06:28:01,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:28:01,821] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:28:01,821] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:28:09,501] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:28:17,349] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:28:25,478] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:28:33,571] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:28:41,026] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:28:48,199] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:28:56,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:29:04,099] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:29:12,106] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:29:20,629] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9016725457436423
[2022-12-07 06:29:20,629] [INFO] [runner_train_mujoco] Average state value: 0.5145395044734081
[2022-12-07 06:29:20,629] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 06:29:20,686] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.05521
[2022-12-07 06:29:20,742] [INFO] [controller] EPOCH 2 loss ppo:  -0.03391, loss val: 0.05515
[2022-12-07 06:29:20,797] [INFO] [controller] EPOCH 3 loss ppo:  -0.05152, loss val: 0.05282
[2022-12-07 06:29:20,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.06226, loss val: 0.05216
[2022-12-07 06:29:20,856] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:29:21,067] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:29:21,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:29:28,427] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:29:36,512] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:29:44,083] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:29:51,871] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:29:59,871] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:30:09,528] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:30:17,644] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:30:25,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:30:33,715] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:30:42,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.781807695029305
[2022-12-07 06:30:42,027] [INFO] [runner_train_mujoco] Average state value: 0.5224746241668861
[2022-12-07 06:30:42,027] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 06:30:42,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.05288
[2022-12-07 06:30:42,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.03160, loss val: 0.05590
[2022-12-07 06:30:42,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.04911, loss val: 0.05426
[2022-12-07 06:30:42,423] [INFO] [controller] EPOCH 4 loss ppo:  -0.06060, loss val: 0.05188
[2022-12-07 06:30:42,434] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:30:42,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:30:42,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:30:50,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:30:58,641] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:31:06,773] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:31:14,314] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:31:22,252] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:31:29,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:31:37,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:31:45,426] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:31:52,340] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:31:59,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.679588031503796
[2022-12-07 06:31:59,814] [INFO] [runner_train_mujoco] Average state value: 0.4839494605536262
[2022-12-07 06:31:59,814] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 06:31:59,871] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.07112
[2022-12-07 06:31:59,925] [INFO] [controller] EPOCH 2 loss ppo:  -0.03158, loss val: 0.07452
[2022-12-07 06:31:59,969] [INFO] [controller] EPOCH 3 loss ppo:  -0.04898, loss val: 0.07779
[2022-12-07 06:32:00,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.05812, loss val: 0.07297
[2022-12-07 06:32:00,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:32:00,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:32:00,242] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:32:07,565] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:32:15,718] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:32:24,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:32:31,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:32:38,859] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:32:46,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:32:54,347] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:33:02,016] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:33:09,598] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:33:17,453] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0434291776278153
[2022-12-07 06:33:17,453] [INFO] [runner_train_mujoco] Average state value: 0.49071147068093224
[2022-12-07 06:33:17,453] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 06:33:17,514] [INFO] [controller] EPOCH 1 loss ppo:  -0.01385, loss val: 0.07155
[2022-12-07 06:33:17,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.02764, loss val: 0.06930
[2022-12-07 06:33:17,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.04461, loss val: 0.06812
[2022-12-07 06:33:17,669] [INFO] [controller] EPOCH 4 loss ppo:  -0.05727, loss val: 0.06809
[2022-12-07 06:33:17,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:33:17,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:33:17,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:33:26,154] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:33:34,180] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:33:41,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:33:48,901] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:33:56,189] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:34:03,586] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:34:11,406] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:34:19,675] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:34:28,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:34:35,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0449616611594648
[2022-12-07 06:34:35,077] [INFO] [runner_train_mujoco] Average state value: 0.48714362214754026
[2022-12-07 06:34:35,078] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 06:34:35,131] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.07617
[2022-12-07 06:34:35,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.02842, loss val: 0.07502
[2022-12-07 06:34:35,228] [INFO] [controller] EPOCH 3 loss ppo:  -0.04460, loss val: 0.07342
[2022-12-07 06:34:35,271] [INFO] [controller] EPOCH 4 loss ppo:  -0.05589, loss val: 0.07243
[2022-12-07 06:34:35,280] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:34:35,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:34:35,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:34:42,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:34:51,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:34:58,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:35:06,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:35:13,848] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:35:21,676] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:35:29,264] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:35:36,635] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:35:44,355] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:35:51,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.777035097121785
[2022-12-07 06:35:51,886] [INFO] [runner_train_mujoco] Average state value: 0.5242762113710244
[2022-12-07 06:35:51,886] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 06:35:51,941] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.05667
[2022-12-07 06:35:51,989] [INFO] [controller] EPOCH 2 loss ppo:  -0.02550, loss val: 0.05613
[2022-12-07 06:35:52,033] [INFO] [controller] EPOCH 3 loss ppo:  -0.04290, loss val: 0.05507
[2022-12-07 06:35:52,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.05710, loss val: 0.05476
[2022-12-07 06:35:52,087] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:35:52,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:35:52,289] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:35:59,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:36:08,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:36:16,327] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:36:24,061] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:36:31,068] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:36:38,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:36:46,142] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:36:53,748] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:37:01,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:37:09,382] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.464953165115459
[2022-12-07 06:37:09,382] [INFO] [runner_train_mujoco] Average state value: 0.503300445297112
[2022-12-07 06:37:09,383] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 06:37:09,435] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.07417
[2022-12-07 06:37:09,481] [INFO] [controller] EPOCH 2 loss ppo:  -0.02600, loss val: 0.07082
[2022-12-07 06:37:09,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.04041, loss val: 0.07042
[2022-12-07 06:37:09,648] [INFO] [controller] EPOCH 4 loss ppo:  -0.05262, loss val: 0.07036
[2022-12-07 06:37:09,657] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:37:09,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:37:09,860] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:37:17,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:37:26,014] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:37:33,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:37:40,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:37:48,143] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:37:55,940] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:38:03,548] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:38:11,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:38:18,938] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:38:26,470] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2137858978505713
[2022-12-07 06:38:26,470] [INFO] [runner_train_mujoco] Average state value: 0.49897262833764155
[2022-12-07 06:38:26,471] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 06:38:26,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.05958
[2022-12-07 06:38:26,586] [INFO] [controller] EPOCH 2 loss ppo:  -0.02618, loss val: 0.05978
[2022-12-07 06:38:26,639] [INFO] [controller] EPOCH 3 loss ppo:  -0.03971, loss val: 0.05820
[2022-12-07 06:38:26,691] [INFO] [controller] EPOCH 4 loss ppo:  -0.05101, loss val: 0.05948
[2022-12-07 06:38:26,700] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:38:26,906] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:38:26,906] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:38:34,472] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:38:42,476] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:38:50,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:38:58,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:39:05,733] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:39:12,855] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:39:20,026] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:39:27,322] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:39:33,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:39:40,594] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1452063956880627
[2022-12-07 06:39:40,594] [INFO] [runner_train_mujoco] Average state value: 0.5127984439507127
[2022-12-07 06:39:40,594] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 06:39:40,650] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.06127
[2022-12-07 06:39:40,693] [INFO] [controller] EPOCH 2 loss ppo:  -0.02318, loss val: 0.05906
[2022-12-07 06:39:40,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.03695, loss val: 0.05961
[2022-12-07 06:39:40,833] [INFO] [controller] EPOCH 4 loss ppo:  -0.04885, loss val: 0.05763
[2022-12-07 06:39:40,842] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:39:41,035] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:39:41,036] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:39:48,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:39:55,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:40:02,155] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:40:09,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:40:15,730] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:40:22,846] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:40:29,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:40:36,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:40:43,194] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:40:49,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7047444507616882
[2022-12-07 06:40:49,813] [INFO] [runner_train_mujoco] Average state value: 0.5286746551071604
[2022-12-07 06:40:49,813] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 06:40:49,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.06096
[2022-12-07 06:40:49,921] [INFO] [controller] EPOCH 2 loss ppo:  -0.02691, loss val: 0.06266
[2022-12-07 06:40:49,967] [INFO] [controller] EPOCH 3 loss ppo:  -0.03889, loss val: 0.05997
[2022-12-07 06:40:50,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.04994, loss val: 0.06071
[2022-12-07 06:40:50,022] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:40:50,235] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:40:50,235] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:40:57,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:41:03,659] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:41:10,837] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:41:17,625] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:41:24,625] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:41:31,931] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:41:38,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:41:45,581] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:41:52,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:41:58,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.364162297049455
[2022-12-07 06:41:58,828] [INFO] [runner_train_mujoco] Average state value: 0.5385401863058409
[2022-12-07 06:41:58,829] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 06:41:58,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04356
[2022-12-07 06:41:58,913] [INFO] [controller] EPOCH 2 loss ppo:  -0.01999, loss val: 0.04484
[2022-12-07 06:41:58,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.03016, loss val: 0.04364
[2022-12-07 06:41:58,995] [INFO] [controller] EPOCH 4 loss ppo:  -0.04001, loss val: 0.04457
[2022-12-07 06:41:59,004] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:41:59,194] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:41:59,194] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:42:06,075] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:42:13,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:42:20,945] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:42:28,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:42:34,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:42:42,097] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:42:48,875] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:42:55,405] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:43:01,941] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:43:08,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6050468548970356
[2022-12-07 06:43:08,918] [INFO] [runner_train_mujoco] Average state value: 0.5342757602731386
[2022-12-07 06:43:08,918] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 06:43:08,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04113
[2022-12-07 06:43:09,005] [INFO] [controller] EPOCH 2 loss ppo:  -0.02033, loss val: 0.04100
[2022-12-07 06:43:09,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.02989, loss val: 0.04250
[2022-12-07 06:43:09,080] [INFO] [controller] EPOCH 4 loss ppo:  -0.03955, loss val: 0.04079
[2022-12-07 06:43:09,090] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:43:09,284] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:43:09,284] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:43:16,924] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:43:25,456] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:43:32,004] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:43:38,646] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:43:45,524] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:43:52,450] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:44:00,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:44:07,174] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:44:13,921] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:44:20,698] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6413041773397956
[2022-12-07 06:44:20,698] [INFO] [runner_train_mujoco] Average state value: 0.5408242709934712
[2022-12-07 06:44:20,698] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 06:44:20,751] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.04409
[2022-12-07 06:44:20,797] [INFO] [controller] EPOCH 2 loss ppo:  -0.01858, loss val: 0.04476
[2022-12-07 06:44:20,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.02562, loss val: 0.04572
[2022-12-07 06:44:20,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.03380, loss val: 0.04729
[2022-12-07 06:44:20,900] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:44:21,095] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:44:21,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:44:27,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:44:35,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:44:42,734] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:44:49,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:44:57,023] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:45:03,847] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:45:13,115] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:45:21,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:45:28,746] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:45:36,337] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7070004990433487
[2022-12-07 06:45:36,337] [INFO] [runner_train_mujoco] Average state value: 0.534751688460509
[2022-12-07 06:45:36,337] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 06:45:36,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.05555
[2022-12-07 06:45:36,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.01560, loss val: 0.05517
[2022-12-07 06:45:36,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.01868, loss val: 0.05513
[2022-12-07 06:45:36,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.02323, loss val: 0.05484
[2022-12-07 06:45:36,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:45:36,754] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:45:36,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:45:44,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:45:52,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:46:01,197] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:46:08,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:46:16,715] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:46:25,147] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:46:32,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:46:40,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:46:49,061] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:46:57,140] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.4039138931026365
[2022-12-07 06:46:57,140] [INFO] [runner_train_mujoco] Average state value: 0.5257299309422572
[2022-12-07 06:46:57,140] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 06:46:57,204] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.05094
[2022-12-07 06:46:57,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.01565, loss val: 0.05054
[2022-12-07 06:46:57,299] [INFO] [controller] EPOCH 3 loss ppo:  -0.01781, loss val: 0.05062
[2022-12-07 06:46:57,354] [INFO] [controller] EPOCH 4 loss ppo:  -0.02099, loss val: 0.05028
[2022-12-07 06:46:57,362] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:46:57,480] [INFO] [optimize] Finished learning.
