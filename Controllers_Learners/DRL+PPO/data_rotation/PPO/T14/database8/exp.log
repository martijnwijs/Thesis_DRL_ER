[2022-12-07 07:37:13,220] [INFO] [optimize] Starting learning
[2022-12-07 07:37:13,240] [INFO] [optimize] Starting learning process..
[2022-12-07 07:37:13,348] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:37:13,350] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:37:23,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:37:30,709] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:37:38,082] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:37:45,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:37:52,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:38:00,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:38:07,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:38:15,131] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:38:23,162] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:38:31,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6048272181823753
[2022-12-07 07:38:31,150] [INFO] [runner_train_mujoco] Average state value: 0.27004932827129957
[2022-12-07 07:38:31,150] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 07:38:31,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.28889
[2022-12-07 07:38:31,246] [INFO] [controller] EPOCH 2 loss ppo:  -0.04951, loss val: 0.26553
[2022-12-07 07:38:31,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.06839, loss val: 0.24134
[2022-12-07 07:38:31,334] [INFO] [controller] EPOCH 4 loss ppo:  -0.08003, loss val: 0.22286
[2022-12-07 07:38:31,346] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:38:31,558] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:38:31,558] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:38:39,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:38:47,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:38:55,261] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:39:02,924] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:39:10,480] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:39:17,995] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:39:25,039] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:39:32,254] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:39:39,919] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:39:48,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5646528760563618
[2022-12-07 07:39:48,146] [INFO] [runner_train_mujoco] Average state value: 0.4381173423863947
[2022-12-07 07:39:48,146] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 07:39:48,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.21740
[2022-12-07 07:39:48,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.04433, loss val: 0.20494
[2022-12-07 07:39:48,295] [INFO] [controller] EPOCH 3 loss ppo:  -0.06503, loss val: 0.18997
[2022-12-07 07:39:48,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.07587, loss val: 0.17943
[2022-12-07 07:39:48,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:39:48,565] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:39:48,565] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:39:56,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:40:04,910] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:40:12,597] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:40:19,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:40:27,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:40:34,694] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:40:42,499] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:40:50,182] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:40:57,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:41:05,879] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6558356825478568
[2022-12-07 07:41:05,880] [INFO] [runner_train_mujoco] Average state value: 0.5720143332316852
[2022-12-07 07:41:05,880] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 07:41:05,930] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.16190
[2022-12-07 07:41:05,974] [INFO] [controller] EPOCH 2 loss ppo:  -0.04211, loss val: 0.14963
[2022-12-07 07:41:06,018] [INFO] [controller] EPOCH 3 loss ppo:  -0.06191, loss val: 0.14135
[2022-12-07 07:41:06,060] [INFO] [controller] EPOCH 4 loss ppo:  -0.07448, loss val: 0.13515
[2022-12-07 07:41:06,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:41:06,295] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:41:06,296] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:41:13,960] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:41:21,316] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:41:29,125] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:41:37,446] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:41:45,409] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:41:52,972] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:42:00,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:42:07,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:42:15,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:42:23,405] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6335910412417076
[2022-12-07 07:42:23,405] [INFO] [runner_train_mujoco] Average state value: 0.5488089690400908
[2022-12-07 07:42:23,406] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 07:42:23,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.13677
[2022-12-07 07:42:23,540] [INFO] [controller] EPOCH 2 loss ppo:  -0.04210, loss val: 0.12861
[2022-12-07 07:42:23,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.06056, loss val: 0.12181
[2022-12-07 07:42:23,642] [INFO] [controller] EPOCH 4 loss ppo:  -0.07132, loss val: 0.11645
[2022-12-07 07:42:23,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:42:23,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:42:23,843] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:42:32,122] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:42:40,173] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:42:48,376] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:42:56,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:43:03,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:43:11,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:43:18,581] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:43:27,179] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:43:34,104] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:43:41,497] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8486335946187307
[2022-12-07 07:43:41,497] [INFO] [runner_train_mujoco] Average state value: 0.5130732609747598
[2022-12-07 07:43:41,497] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 07:43:41,550] [INFO] [controller] EPOCH 1 loss ppo:  -0.01182, loss val: 0.11594
[2022-12-07 07:43:41,589] [INFO] [controller] EPOCH 2 loss ppo:  -0.04666, loss val: 0.11035
[2022-12-07 07:43:41,629] [INFO] [controller] EPOCH 3 loss ppo:  -0.07031, loss val: 0.10514
[2022-12-07 07:43:41,670] [INFO] [controller] EPOCH 4 loss ppo:  -0.08116, loss val: 0.10120
[2022-12-07 07:43:41,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:43:41,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:43:41,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:43:49,099] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:43:56,293] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:44:03,093] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:44:10,205] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:44:17,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:44:24,153] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:44:30,692] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:44:37,138] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:44:43,634] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:44:50,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.740787285466044
[2022-12-07 07:44:50,769] [INFO] [runner_train_mujoco] Average state value: 0.5456102382801473
[2022-12-07 07:44:50,769] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 07:44:50,819] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.08930
[2022-12-07 07:44:50,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.03940, loss val: 0.09279
[2022-12-07 07:44:50,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.05455, loss val: 0.07808
[2022-12-07 07:44:50,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.06543, loss val: 0.07064
[2022-12-07 07:44:50,952] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:44:51,143] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:44:51,143] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:44:58,011] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:45:04,510] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:45:10,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:45:17,291] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:45:23,540] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:45:29,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:45:35,461] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:45:41,453] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:45:47,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:45:54,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6728631230223142
[2022-12-07 07:45:54,543] [INFO] [runner_train_mujoco] Average state value: 0.48813665081063906
[2022-12-07 07:45:54,543] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 07:45:54,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.07661
[2022-12-07 07:45:54,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.04854, loss val: 0.07545
[2022-12-07 07:45:54,670] [INFO] [controller] EPOCH 3 loss ppo:  -0.06701, loss val: 0.07526
[2022-12-07 07:45:54,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.07844, loss val: 0.07400
[2022-12-07 07:45:54,720] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:45:54,902] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:45:54,902] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:46:01,267] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:46:08,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:46:14,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:46:20,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:46:26,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:46:32,912] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:46:39,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:46:45,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:46:51,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:46:57,698] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5829351489230095
[2022-12-07 07:46:57,698] [INFO] [runner_train_mujoco] Average state value: 0.46153581198429067
[2022-12-07 07:46:57,698] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 07:46:57,745] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.06399
[2022-12-07 07:46:57,784] [INFO] [controller] EPOCH 2 loss ppo:  -0.04554, loss val: 0.06233
[2022-12-07 07:46:57,882] [INFO] [controller] EPOCH 3 loss ppo:  -0.06203, loss val: 0.06019
[2022-12-07 07:46:57,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.07562, loss val: 0.05859
[2022-12-07 07:46:57,927] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:46:58,105] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:46:58,106] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:47:04,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:47:11,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:47:17,058] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:47:23,054] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:47:29,258] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:47:35,471] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:47:41,678] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:47:47,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:47:53,800] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:48:00,073] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8071102987956597
[2022-12-07 07:48:00,074] [INFO] [runner_train_mujoco] Average state value: 0.49402092115084323
[2022-12-07 07:48:00,074] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 07:48:00,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.06648
[2022-12-07 07:48:00,221] [INFO] [controller] EPOCH 2 loss ppo:  -0.03810, loss val: 0.06233
[2022-12-07 07:48:00,259] [INFO] [controller] EPOCH 3 loss ppo:  -0.05452, loss val: 0.06048
[2022-12-07 07:48:00,301] [INFO] [controller] EPOCH 4 loss ppo:  -0.06726, loss val: 0.05401
[2022-12-07 07:48:00,309] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:48:00,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:48:00,493] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:48:07,035] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:48:13,358] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:48:19,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:48:25,670] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:48:31,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:48:38,035] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:48:44,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:48:50,726] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:48:56,713] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:49:02,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4954152985826533
[2022-12-07 07:49:02,997] [INFO] [runner_train_mujoco] Average state value: 0.5826546208808819
[2022-12-07 07:49:02,997] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 07:49:03,054] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.06362
[2022-12-07 07:49:03,101] [INFO] [controller] EPOCH 2 loss ppo:  -0.04432, loss val: 0.06325
[2022-12-07 07:49:03,147] [INFO] [controller] EPOCH 3 loss ppo:  -0.06134, loss val: 0.06328
[2022-12-07 07:49:03,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.07586, loss val: 0.06359
[2022-12-07 07:49:03,211] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:49:03,430] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:49:03,430] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:49:11,564] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:49:18,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:49:26,117] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:49:32,812] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:49:39,538] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:49:46,670] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:49:54,081] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:50:01,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:50:08,166] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:50:14,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7916921963951065
[2022-12-07 07:50:14,978] [INFO] [runner_train_mujoco] Average state value: 0.6070579325358072
[2022-12-07 07:50:14,978] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 07:50:15,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01067, loss val: 0.05690
[2022-12-07 07:50:15,070] [INFO] [controller] EPOCH 2 loss ppo:  -0.03993, loss val: 0.05532
[2022-12-07 07:50:15,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.06323, loss val: 0.05595
[2022-12-07 07:50:15,177] [INFO] [controller] EPOCH 4 loss ppo:  -0.07449, loss val: 0.05554
[2022-12-07 07:50:15,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:50:15,380] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:50:15,381] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:50:22,392] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:50:29,234] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:50:36,845] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:50:43,611] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:50:50,889] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:50:57,983] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:51:05,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:51:12,235] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:51:19,098] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:51:25,985] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7196698442754296
[2022-12-07 07:51:25,986] [INFO] [runner_train_mujoco] Average state value: 0.5824248453279336
[2022-12-07 07:51:25,986] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 07:51:26,028] [INFO] [controller] EPOCH 1 loss ppo:  -0.01244, loss val: 0.05391
[2022-12-07 07:51:26,068] [INFO] [controller] EPOCH 2 loss ppo:  -0.04361, loss val: 0.04939
[2022-12-07 07:51:26,111] [INFO] [controller] EPOCH 3 loss ppo:  -0.06139, loss val: 0.04640
[2022-12-07 07:51:26,154] [INFO] [controller] EPOCH 4 loss ppo:  -0.07223, loss val: 0.04431
[2022-12-07 07:51:26,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:51:26,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:51:26,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:51:33,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:51:40,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:51:47,780] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:51:54,450] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:52:01,493] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:52:08,519] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:52:15,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:52:22,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:52:29,167] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:52:36,007] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7605926407568134
[2022-12-07 07:52:36,007] [INFO] [runner_train_mujoco] Average state value: 0.4999099081456661
[2022-12-07 07:52:36,007] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 07:52:36,059] [INFO] [controller] EPOCH 1 loss ppo:  -0.01065, loss val: 0.04014
[2022-12-07 07:52:36,105] [INFO] [controller] EPOCH 2 loss ppo:  -0.03340, loss val: 0.04016
[2022-12-07 07:52:36,148] [INFO] [controller] EPOCH 3 loss ppo:  -0.05406, loss val: 0.04056
[2022-12-07 07:52:36,192] [INFO] [controller] EPOCH 4 loss ppo:  -0.06973, loss val: 0.04029
[2022-12-07 07:52:36,201] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:52:36,402] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:52:36,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:52:43,439] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:52:50,743] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:52:57,961] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:53:04,674] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:53:11,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:53:18,792] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:53:25,785] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:53:33,089] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:53:39,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:53:46,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7346940745285215
[2022-12-07 07:53:46,514] [INFO] [runner_train_mujoco] Average state value: 0.476535482575496
[2022-12-07 07:53:46,514] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 07:53:46,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01038, loss val: 0.05155
[2022-12-07 07:53:46,625] [INFO] [controller] EPOCH 2 loss ppo:  -0.03774, loss val: 0.05107
[2022-12-07 07:53:46,671] [INFO] [controller] EPOCH 3 loss ppo:  -0.06120, loss val: 0.05025
[2022-12-07 07:53:46,716] [INFO] [controller] EPOCH 4 loss ppo:  -0.07335, loss val: 0.04954
[2022-12-07 07:53:46,724] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:53:46,918] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:53:46,918] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:53:54,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:54:01,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:54:09,460] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:54:16,643] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:54:23,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:54:30,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:54:37,403] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:54:44,266] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:54:51,366] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:54:58,333] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6799108016615658
[2022-12-07 07:54:58,333] [INFO] [runner_train_mujoco] Average state value: 0.49657693625241517
[2022-12-07 07:54:58,333] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 07:54:58,380] [INFO] [controller] EPOCH 1 loss ppo:  -0.01036, loss val: 0.05646
[2022-12-07 07:54:58,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.03355, loss val: 0.05524
[2022-12-07 07:54:58,463] [INFO] [controller] EPOCH 3 loss ppo:  -0.05238, loss val: 0.05393
[2022-12-07 07:54:58,505] [INFO] [controller] EPOCH 4 loss ppo:  -0.06736, loss val: 0.05333
[2022-12-07 07:54:58,516] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:54:58,707] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:54:58,707] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:55:06,249] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:55:13,629] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:55:20,518] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:55:27,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:55:34,151] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:55:41,150] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:55:48,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:55:55,333] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:56:02,636] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:56:09,240] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6146463789946907
[2022-12-07 07:56:09,240] [INFO] [runner_train_mujoco] Average state value: 0.54716018324097
[2022-12-07 07:56:09,241] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 07:56:09,290] [INFO] [controller] EPOCH 1 loss ppo:  -0.01120, loss val: 0.04621
[2022-12-07 07:56:09,327] [INFO] [controller] EPOCH 2 loss ppo:  -0.04000, loss val: 0.04623
[2022-12-07 07:56:09,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.06075, loss val: 0.04675
[2022-12-07 07:56:09,406] [INFO] [controller] EPOCH 4 loss ppo:  -0.07486, loss val: 0.04587
[2022-12-07 07:56:09,415] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:56:09,602] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:56:09,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:56:16,882] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:56:24,155] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:56:31,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:56:38,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:56:45,367] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:56:52,339] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:56:59,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:57:06,521] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:57:13,520] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:57:20,627] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6687663104374388
[2022-12-07 07:57:20,628] [INFO] [runner_train_mujoco] Average state value: 0.5627620946566264
[2022-12-07 07:57:20,628] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 07:57:20,676] [INFO] [controller] EPOCH 1 loss ppo:  -0.01115, loss val: 0.04822
[2022-12-07 07:57:20,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.03808, loss val: 0.04849
[2022-12-07 07:57:20,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.05601, loss val: 0.04881
[2022-12-07 07:57:20,810] [INFO] [controller] EPOCH 4 loss ppo:  -0.06988, loss val: 0.04959
[2022-12-07 07:57:20,819] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:57:21,014] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:57:21,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:57:27,929] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:57:34,999] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:57:42,222] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:57:49,563] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:57:56,443] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:58:02,971] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:58:09,858] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:58:16,645] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:58:24,119] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:58:30,848] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9553627217318184
[2022-12-07 07:58:30,848] [INFO] [runner_train_mujoco] Average state value: 0.5610827705214421
[2022-12-07 07:58:30,848] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 07:58:30,905] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.04063
[2022-12-07 07:58:30,947] [INFO] [controller] EPOCH 2 loss ppo:  -0.03900, loss val: 0.03343
[2022-12-07 07:58:30,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.05853, loss val: 0.03895
[2022-12-07 07:58:31,026] [INFO] [controller] EPOCH 4 loss ppo:  -0.06971, loss val: 0.03687
[2022-12-07 07:58:31,036] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:58:31,238] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:58:31,239] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:58:38,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:58:45,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:58:52,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:58:59,227] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:59:05,996] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:59:12,976] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:59:19,762] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:59:26,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:59:33,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:59:40,497] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5567813873577998
[2022-12-07 07:59:40,497] [INFO] [runner_train_mujoco] Average state value: 0.5338719262778759
[2022-12-07 07:59:40,498] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 07:59:40,553] [INFO] [controller] EPOCH 1 loss ppo:  -0.01105, loss val: 0.04143
[2022-12-07 07:59:40,602] [INFO] [controller] EPOCH 2 loss ppo:  -0.04354, loss val: 0.04153
[2022-12-07 07:59:40,775] [INFO] [controller] EPOCH 3 loss ppo:  -0.05865, loss val: 0.03949
[2022-12-07 07:59:40,814] [INFO] [controller] EPOCH 4 loss ppo:  -0.07000, loss val: 0.03998
[2022-12-07 07:59:40,821] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:59:41,016] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:59:41,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:59:48,590] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:59:55,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:00:02,857] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:00:09,907] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:00:16,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:00:23,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:00:30,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:00:37,673] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:00:45,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:00:51,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6779317573345103
[2022-12-07 08:00:51,997] [INFO] [runner_train_mujoco] Average state value: 0.511748068700234
[2022-12-07 08:00:51,998] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 08:00:52,051] [INFO] [controller] EPOCH 1 loss ppo:  -0.00990, loss val: 0.04690
[2022-12-07 08:00:52,092] [INFO] [controller] EPOCH 2 loss ppo:  -0.03380, loss val: 0.04454
[2022-12-07 08:00:52,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.05242, loss val: 0.04325
[2022-12-07 08:00:52,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.06716, loss val: 0.04196
[2022-12-07 08:00:52,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:00:52,380] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:00:52,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:00:59,393] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:01:06,459] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:01:13,520] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:01:20,440] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:01:27,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:01:34,806] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:01:42,222] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:01:49,023] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:01:55,642] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:02:02,577] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2327597608808323
[2022-12-07 08:02:02,577] [INFO] [runner_train_mujoco] Average state value: 0.5477047540545463
[2022-12-07 08:02:02,578] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 08:02:02,641] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.05083
[2022-12-07 08:02:02,686] [INFO] [controller] EPOCH 2 loss ppo:  -0.04082, loss val: 0.05031
[2022-12-07 08:02:02,737] [INFO] [controller] EPOCH 3 loss ppo:  -0.06102, loss val: 0.05078
[2022-12-07 08:02:02,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.07746, loss val: 0.05108
[2022-12-07 08:02:02,795] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:02:03,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:02:03,008] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:02:10,133] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:02:17,324] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:02:23,968] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:02:30,959] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:02:38,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:02:45,118] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:02:51,681] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:02:58,443] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:03:05,327] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:03:12,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8443012800765797
[2022-12-07 08:03:12,389] [INFO] [runner_train_mujoco] Average state value: 0.5742087756594022
[2022-12-07 08:03:12,389] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 08:03:12,439] [INFO] [controller] EPOCH 1 loss ppo:  -0.01217, loss val: 0.05071
[2022-12-07 08:03:12,482] [INFO] [controller] EPOCH 2 loss ppo:  -0.03722, loss val: 0.04831
[2022-12-07 08:03:12,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.05655, loss val: 0.04691
[2022-12-07 08:03:12,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.06844, loss val: 0.04334
[2022-12-07 08:03:12,576] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:03:12,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:03:12,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:03:19,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:03:26,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:03:33,900] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:03:41,057] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:03:48,227] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:03:55,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:04:02,668] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:04:09,415] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:04:16,294] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:04:23,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0065059540909513
[2022-12-07 08:04:23,525] [INFO] [runner_train_mujoco] Average state value: 0.5228663666844369
[2022-12-07 08:04:23,525] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 08:04:23,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01169, loss val: 0.04034
[2022-12-07 08:04:23,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.04226, loss val: 0.04058
[2022-12-07 08:04:23,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.06171, loss val: 0.03966
[2022-12-07 08:04:23,700] [INFO] [controller] EPOCH 4 loss ppo:  -0.07344, loss val: 0.04078
[2022-12-07 08:04:23,708] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:04:23,901] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:04:23,902] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:04:31,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:04:37,724] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:04:44,802] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:04:51,760] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:04:58,356] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:05:05,233] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:05:12,160] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:05:19,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:05:26,329] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:05:33,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.373494193147833
[2022-12-07 08:05:33,065] [INFO] [runner_train_mujoco] Average state value: 0.488691598713398
[2022-12-07 08:05:33,066] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 08:05:33,123] [INFO] [controller] EPOCH 1 loss ppo:  -0.01609, loss val: 0.04397
[2022-12-07 08:05:33,173] [INFO] [controller] EPOCH 2 loss ppo:  -0.04451, loss val: 0.04403
[2022-12-07 08:05:33,218] [INFO] [controller] EPOCH 3 loss ppo:  -0.06221, loss val: 0.04218
[2022-12-07 08:05:33,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.07260, loss val: 0.04138
[2022-12-07 08:05:33,269] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:05:33,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:05:33,468] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:05:40,273] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:05:47,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:05:53,786] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:06:00,805] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:06:07,563] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:06:14,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:06:21,522] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:06:28,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:06:34,810] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:06:41,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2980722910562315
[2022-12-07 08:06:41,751] [INFO] [runner_train_mujoco] Average state value: 0.5265701599915822
[2022-12-07 08:06:41,751] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 08:06:41,802] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04062
[2022-12-07 08:06:41,852] [INFO] [controller] EPOCH 2 loss ppo:  -0.04204, loss val: 0.04082
[2022-12-07 08:06:41,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.05847, loss val: 0.04139
[2022-12-07 08:06:41,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.07351, loss val: 0.03958
[2022-12-07 08:06:41,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:06:42,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:06:42,160] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:06:48,936] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:06:56,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:07:03,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:07:11,666] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:07:19,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:07:26,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:07:33,563] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:07:40,520] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:07:47,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:07:54,448] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7209984042477682
[2022-12-07 08:07:54,448] [INFO] [runner_train_mujoco] Average state value: 0.5139612614015738
[2022-12-07 08:07:54,448] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 08:07:54,500] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.04758
[2022-12-07 08:07:54,545] [INFO] [controller] EPOCH 2 loss ppo:  -0.03915, loss val: 0.04762
[2022-12-07 08:07:54,595] [INFO] [controller] EPOCH 3 loss ppo:  -0.06182, loss val: 0.04758
[2022-12-07 08:07:54,641] [INFO] [controller] EPOCH 4 loss ppo:  -0.07505, loss val: 0.04702
[2022-12-07 08:07:54,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:07:54,856] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:07:54,857] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:08:01,722] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:08:08,751] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:08:17,801] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:08:25,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:08:34,031] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:08:41,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:08:49,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:08:57,811] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:09:05,960] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:09:14,132] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.805788704682644
[2022-12-07 08:09:14,132] [INFO] [runner_train_mujoco] Average state value: 0.5072015533323089
[2022-12-07 08:09:14,132] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 08:09:14,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.01486, loss val: 0.04691
[2022-12-07 08:09:14,269] [INFO] [controller] EPOCH 2 loss ppo:  -0.03801, loss val: 0.04340
[2022-12-07 08:09:14,318] [INFO] [controller] EPOCH 3 loss ppo:  -0.05590, loss val: 0.04777
[2022-12-07 08:09:14,375] [INFO] [controller] EPOCH 4 loss ppo:  -0.07067, loss val: 0.04240
[2022-12-07 08:09:14,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:09:14,600] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:09:14,601] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:09:23,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:09:31,541] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:09:38,979] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:09:46,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:09:54,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:10:01,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:10:09,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:17,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:10:25,459] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:10:33,345] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7800629075415575
[2022-12-07 08:10:33,345] [INFO] [runner_train_mujoco] Average state value: 0.5017122186720371
[2022-12-07 08:10:33,345] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 08:10:33,399] [INFO] [controller] EPOCH 1 loss ppo:  -0.01155, loss val: 0.03759
[2022-12-07 08:10:33,446] [INFO] [controller] EPOCH 2 loss ppo:  -0.03715, loss val: 0.04071
[2022-12-07 08:10:33,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.05510, loss val: 0.04198
[2022-12-07 08:10:33,533] [INFO] [controller] EPOCH 4 loss ppo:  -0.07094, loss val: 0.04440
[2022-12-07 08:10:33,540] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:10:33,746] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:10:33,746] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:10:41,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:10:48,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:10:55,903] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:11:03,601] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:11:11,853] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:11:20,361] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:11:28,377] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:11:35,617] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:11:43,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:11:50,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1811630731638574
[2022-12-07 08:11:50,659] [INFO] [runner_train_mujoco] Average state value: 0.49032926170527935
[2022-12-07 08:11:50,660] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 08:11:50,709] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.06256
[2022-12-07 08:11:50,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.04334, loss val: 0.06036
[2022-12-07 08:11:50,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.06213, loss val: 0.05802
[2022-12-07 08:11:50,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.07690, loss val: 0.05596
[2022-12-07 08:11:50,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:51,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:51,056] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:11:59,015] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:12:06,727] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:12:14,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:12:22,142] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:12:30,111] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:12:37,740] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:12:45,427] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:12:52,963] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:13:00,599] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:13:08,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.550598895089764
[2022-12-07 08:13:08,334] [INFO] [runner_train_mujoco] Average state value: 0.5695739030757296
[2022-12-07 08:13:08,334] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 08:13:08,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04334
[2022-12-07 08:13:08,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.03807, loss val: 0.04256
[2022-12-07 08:13:08,543] [INFO] [controller] EPOCH 3 loss ppo:  -0.05816, loss val: 0.04036
[2022-12-07 08:13:08,594] [INFO] [controller] EPOCH 4 loss ppo:  -0.07316, loss val: 0.04076
[2022-12-07 08:13:08,604] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:13:08,808] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:13:08,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:13:16,820] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:13:24,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:13:32,221] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:13:39,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:13:47,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:13:55,471] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:14:03,308] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:14:11,150] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:14:18,419] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:14:26,064] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6402147716666768
[2022-12-07 08:14:26,064] [INFO] [runner_train_mujoco] Average state value: 0.6408038707574208
[2022-12-07 08:14:26,064] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 08:14:26,133] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.04699
[2022-12-07 08:14:26,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.03860, loss val: 0.04797
[2022-12-07 08:14:26,225] [INFO] [controller] EPOCH 3 loss ppo:  -0.05174, loss val: 0.04748
[2022-12-07 08:14:26,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.06749, loss val: 0.04957
[2022-12-07 08:14:26,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:14:26,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:14:26,495] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:14:34,137] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:14:42,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:14:49,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:57,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:15:05,075] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:15:12,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:15:20,997] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:15:28,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:15:36,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:15:43,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8432146020114601
[2022-12-07 08:15:43,701] [INFO] [runner_train_mujoco] Average state value: 0.6274661916693052
[2022-12-07 08:15:43,701] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 08:15:43,757] [INFO] [controller] EPOCH 1 loss ppo:  -0.01526, loss val: 0.04608
[2022-12-07 08:15:43,802] [INFO] [controller] EPOCH 2 loss ppo:  -0.03740, loss val: 0.04407
[2022-12-07 08:15:43,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.04940, loss val: 0.03961
[2022-12-07 08:15:43,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.06249, loss val: 0.03590
[2022-12-07 08:15:43,900] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:15:44,106] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:15:44,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:15:52,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:16:00,312] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:16:07,972] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:16:15,059] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:16:22,934] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:30,779] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:38,722] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:16:46,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:16:54,539] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:17:02,155] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3901793959296294
[2022-12-07 08:17:02,155] [INFO] [runner_train_mujoco] Average state value: 0.5464004121025404
[2022-12-07 08:17:02,155] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 08:17:02,215] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04447
[2022-12-07 08:17:02,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.03408, loss val: 0.03707
[2022-12-07 08:17:02,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.05146, loss val: 0.03450
[2022-12-07 08:17:02,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.06785, loss val: 0.03437
[2022-12-07 08:17:02,355] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:17:02,566] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:17:02,566] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:17:10,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:17:18,022] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:17:26,106] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:17:33,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:17:41,174] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:17:48,827] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:17:56,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:18:04,665] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:18:12,809] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:18:21,611] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.702003499586385
[2022-12-07 08:18:21,611] [INFO] [runner_train_mujoco] Average state value: 0.4296018793483575
[2022-12-07 08:18:21,611] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 08:18:21,671] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.06413
[2022-12-07 08:18:21,716] [INFO] [controller] EPOCH 2 loss ppo:  -0.03849, loss val: 0.06535
[2022-12-07 08:18:21,760] [INFO] [controller] EPOCH 3 loss ppo:  -0.05634, loss val: 0.06213
[2022-12-07 08:18:21,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.07135, loss val: 0.06515
[2022-12-07 08:18:21,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:18:22,025] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:18:22,025] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:18:30,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:18:38,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:18:45,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:18:53,070] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:19:00,780] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:19:08,346] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:19:15,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:19:23,890] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:19:32,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:39,268] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.771003601019598
[2022-12-07 08:19:39,269] [INFO] [runner_train_mujoco] Average state value: 0.4341801155507564
[2022-12-07 08:19:39,269] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 08:19:39,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.04347
[2022-12-07 08:19:39,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.03827, loss val: 0.04072
[2022-12-07 08:19:39,411] [INFO] [controller] EPOCH 3 loss ppo:  -0.05508, loss val: 0.04070
[2022-12-07 08:19:39,464] [INFO] [controller] EPOCH 4 loss ppo:  -0.07000, loss val: 0.04345
[2022-12-07 08:19:39,474] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:39,681] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:39,682] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:47,393] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:19:55,152] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:20:03,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:20:10,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:20:18,159] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:20:25,888] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:20:33,098] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:20:40,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:20:49,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:20:57,473] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.987720212412854
[2022-12-07 08:20:57,473] [INFO] [runner_train_mujoco] Average state value: 0.42445975231751804
[2022-12-07 08:20:57,473] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 08:20:57,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.05066
[2022-12-07 08:20:57,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.03538, loss val: 0.05085
[2022-12-07 08:20:57,621] [INFO] [controller] EPOCH 3 loss ppo:  -0.05266, loss val: 0.05243
[2022-12-07 08:20:57,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.06689, loss val: 0.05022
[2022-12-07 08:20:57,673] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:20:57,877] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:20:57,877] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:21:05,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:21:13,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:20,859] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:28,466] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:21:35,861] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:21:44,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:21:51,889] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:21:59,308] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:22:06,695] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:22:14,500] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2751271995151825
[2022-12-07 08:22:14,501] [INFO] [runner_train_mujoco] Average state value: 0.4445540841519833
[2022-12-07 08:22:14,501] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 08:22:14,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.04848
[2022-12-07 08:22:14,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.02878, loss val: 0.04947
[2022-12-07 08:22:14,675] [INFO] [controller] EPOCH 3 loss ppo:  -0.04363, loss val: 0.04372
[2022-12-07 08:22:14,726] [INFO] [controller] EPOCH 4 loss ppo:  -0.05924, loss val: 0.04157
[2022-12-07 08:22:14,736] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:22:14,940] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:22:14,940] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:22:22,849] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:22:30,927] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:22:38,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:22:46,373] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:53,840] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:23:01,148] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:23:08,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:23:16,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:23:23,292] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:23:30,915] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5868721306918894
[2022-12-07 08:23:30,915] [INFO] [runner_train_mujoco] Average state value: 0.47635649610559144
[2022-12-07 08:23:30,915] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 08:23:30,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01531, loss val: 0.05183
[2022-12-07 08:23:31,022] [INFO] [controller] EPOCH 2 loss ppo:  -0.03471, loss val: 0.05109
[2022-12-07 08:23:31,066] [INFO] [controller] EPOCH 3 loss ppo:  -0.04830, loss val: 0.05184
[2022-12-07 08:23:31,110] [INFO] [controller] EPOCH 4 loss ppo:  -0.06083, loss val: 0.05394
[2022-12-07 08:23:31,120] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:23:31,321] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:23:31,322] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:23:39,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:23:47,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:23:54,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:24:02,099] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:24:09,722] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:24:17,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:24:24,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:32,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:24:40,476] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:24:47,834] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3142824545289953
[2022-12-07 08:24:47,834] [INFO] [runner_train_mujoco] Average state value: 0.4750529396248361
[2022-12-07 08:24:47,834] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 08:24:47,886] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04698
[2022-12-07 08:24:47,928] [INFO] [controller] EPOCH 2 loss ppo:  -0.03538, loss val: 0.04833
[2022-12-07 08:24:47,982] [INFO] [controller] EPOCH 3 loss ppo:  -0.05051, loss val: 0.04929
[2022-12-07 08:24:48,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.06151, loss val: 0.04684
[2022-12-07 08:24:48,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:24:48,243] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:24:48,243] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:24:55,939] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:25:03,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:25:11,337] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:25:18,612] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:25:26,558] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:34,151] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:25:41,393] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:25:49,423] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:25:56,747] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:26:04,133] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2630462415901507
[2022-12-07 08:26:04,133] [INFO] [runner_train_mujoco] Average state value: 0.47196697239826124
[2022-12-07 08:26:04,133] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 08:26:04,183] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.07662
[2022-12-07 08:26:04,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.02713, loss val: 0.08084
[2022-12-07 08:26:04,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.04377, loss val: 0.07956
[2022-12-07 08:26:04,308] [INFO] [controller] EPOCH 4 loss ppo:  -0.05611, loss val: 0.07773
[2022-12-07 08:26:04,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:26:04,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:26:04,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:12,064] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:26:20,052] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:26:27,796] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:26:35,396] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:26:42,971] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:26:50,695] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:26:58,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:27:06,209] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:27:13,576] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:27:20,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4008998280836393
[2022-12-07 08:27:20,905] [INFO] [runner_train_mujoco] Average state value: 0.46211368405322234
[2022-12-07 08:27:20,905] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 08:27:20,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.06883
[2022-12-07 08:27:20,999] [INFO] [controller] EPOCH 2 loss ppo:  -0.02956, loss val: 0.06914
[2022-12-07 08:27:21,114] [INFO] [controller] EPOCH 3 loss ppo:  -0.04537, loss val: 0.06864
[2022-12-07 08:27:21,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.05919, loss val: 0.06914
[2022-12-07 08:27:21,167] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:27:21,372] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:27:21,372] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:27:29,246] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:27:37,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:27:45,256] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:27:52,630] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:28:00,148] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:28:07,654] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:28:15,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:28:23,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:28:30,696] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:28:38,362] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.1587506694642835
[2022-12-07 08:28:38,362] [INFO] [runner_train_mujoco] Average state value: 0.527920142898957
[2022-12-07 08:28:38,362] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 08:28:38,428] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.04417
[2022-12-07 08:28:38,476] [INFO] [controller] EPOCH 2 loss ppo:  -0.02867, loss val: 0.04010
[2022-12-07 08:28:38,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.04721, loss val: 0.03890
[2022-12-07 08:28:38,590] [INFO] [controller] EPOCH 4 loss ppo:  -0.06054, loss val: 0.03778
[2022-12-07 08:28:38,601] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:28:38,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:28:38,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:28:46,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:28:54,225] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:29:01,645] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:29:08,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:29:16,522] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:24,247] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:29:32,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:29:39,874] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:29:47,532] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:29:55,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.406056461305007
[2022-12-07 08:29:55,196] [INFO] [runner_train_mujoco] Average state value: 0.483561647772789
[2022-12-07 08:29:55,196] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 08:29:55,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.05140
[2022-12-07 08:29:55,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.02750, loss val: 0.04964
[2022-12-07 08:29:55,336] [INFO] [controller] EPOCH 3 loss ppo:  -0.04334, loss val: 0.05011
[2022-12-07 08:29:55,388] [INFO] [controller] EPOCH 4 loss ppo:  -0.05758, loss val: 0.04998
[2022-12-07 08:29:55,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:29:55,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:29:55,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:30:03,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:30:11,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:30:18,792] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:30:26,352] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:30:34,094] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:30:42,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:30:49,554] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:30:56,755] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:04,029] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:11,797] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8263835821596244
[2022-12-07 08:31:11,797] [INFO] [runner_train_mujoco] Average state value: 0.33668164753293
[2022-12-07 08:31:11,797] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 08:31:11,856] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.14307
[2022-12-07 08:31:11,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.02538, loss val: 0.14310
[2022-12-07 08:31:11,947] [INFO] [controller] EPOCH 3 loss ppo:  -0.03716, loss val: 0.14127
[2022-12-07 08:31:11,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.05103, loss val: 0.13656
[2022-12-07 08:31:12,003] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:12,213] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:12,213] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:31:19,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:31:27,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:31:35,429] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:31:42,763] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:31:50,810] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:31:58,483] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:32:06,099] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:32:13,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:32:21,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:32:28,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.198492796553984
[2022-12-07 08:32:28,722] [INFO] [runner_train_mujoco] Average state value: 0.4678250405887763
[2022-12-07 08:32:28,722] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 08:32:28,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.03054
[2022-12-07 08:32:28,824] [INFO] [controller] EPOCH 2 loss ppo:  -0.03204, loss val: 0.03169
[2022-12-07 08:32:28,869] [INFO] [controller] EPOCH 3 loss ppo:  -0.04622, loss val: 0.03038
[2022-12-07 08:32:28,913] [INFO] [controller] EPOCH 4 loss ppo:  -0.06052, loss val: 0.03080
[2022-12-07 08:32:28,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:32:29,124] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:32:29,125] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:32:36,864] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:32:43,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:32:51,008] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:32:58,613] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:33:06,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:33:14,145] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:33:21,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:33:28,686] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:33:35,840] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:33:43,568] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.486908464866067
[2022-12-07 08:33:43,568] [INFO] [runner_train_mujoco] Average state value: 0.41468341692785426
[2022-12-07 08:33:43,568] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 08:33:43,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.08830
[2022-12-07 08:33:43,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.02553, loss val: 0.08784
[2022-12-07 08:33:43,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.03572, loss val: 0.08725
[2022-12-07 08:33:43,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.04779, loss val: 0.08641
[2022-12-07 08:33:43,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:33:43,967] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:33:43,967] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:52,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:33:59,787] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:34:07,206] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:34:14,515] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:34:22,619] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:34:30,176] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:34:37,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:34:45,091] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:34:53,199] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:35:00,946] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.279184901935693
[2022-12-07 08:35:00,946] [INFO] [runner_train_mujoco] Average state value: 0.43229464416454244
[2022-12-07 08:35:00,946] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 08:35:01,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01531, loss val: 0.06429
[2022-12-07 08:35:01,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.02820, loss val: 0.06299
[2022-12-07 08:35:01,085] [INFO] [controller] EPOCH 3 loss ppo:  -0.03932, loss val: 0.06210
[2022-12-07 08:35:01,127] [INFO] [controller] EPOCH 4 loss ppo:  -0.05144, loss val: 0.06174
[2022-12-07 08:35:01,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:35:01,333] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:35:01,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:35:08,542] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:35:16,051] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:35:23,623] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:30,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:35:38,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:35:46,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:35:54,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:36:01,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:36:09,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:36:16,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.162852213265862
[2022-12-07 08:36:16,923] [INFO] [runner_train_mujoco] Average state value: 0.43995519674321015
[2022-12-07 08:36:16,924] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 08:36:16,984] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.07551
[2022-12-07 08:36:17,028] [INFO] [controller] EPOCH 2 loss ppo:  -0.02363, loss val: 0.07483
[2022-12-07 08:36:17,075] [INFO] [controller] EPOCH 3 loss ppo:  -0.03656, loss val: 0.07438
[2022-12-07 08:36:17,117] [INFO] [controller] EPOCH 4 loss ppo:  -0.05008, loss val: 0.07352
[2022-12-07 08:36:17,126] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:36:17,317] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:36:17,318] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:36:24,767] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:36:32,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:36:40,194] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:36:47,989] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:55,863] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:37:03,283] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:37:10,728] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:37:17,936] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:37:26,062] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:37:33,989] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.317943534524433
[2022-12-07 08:37:33,989] [INFO] [runner_train_mujoco] Average state value: 0.4729904555442433
[2022-12-07 08:37:33,989] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 08:37:34,042] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.05547
[2022-12-07 08:37:34,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.02554, loss val: 0.05915
[2022-12-07 08:37:34,132] [INFO] [controller] EPOCH 3 loss ppo:  -0.03539, loss val: 0.05511
[2022-12-07 08:37:34,181] [INFO] [controller] EPOCH 4 loss ppo:  -0.04508, loss val: 0.05722
[2022-12-07 08:37:34,192] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:37:34,420] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:37:34,421] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:37:41,822] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:37:49,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:37:59,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:38:07,599] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:38:15,364] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:38:24,954] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:38:32,652] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:38:40,449] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:38:47,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:38:56,820] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.696493958852235
[2022-12-07 08:38:56,821] [INFO] [runner_train_mujoco] Average state value: 0.43972470776240036
[2022-12-07 08:38:56,821] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 08:38:56,873] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.08068
[2022-12-07 08:38:56,917] [INFO] [controller] EPOCH 2 loss ppo:  -0.02512, loss val: 0.08269
[2022-12-07 08:38:56,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.03448, loss val: 0.07928
[2022-12-07 08:38:56,996] [INFO] [controller] EPOCH 4 loss ppo:  -0.04279, loss val: 0.07834
[2022-12-07 08:38:57,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:38:57,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:38:57,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:39:04,923] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:39:12,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:39:20,185] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:39:27,916] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:39:35,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:39:42,911] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:39:50,895] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:39:58,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:40:06,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:40:13,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.106546542130522
[2022-12-07 08:40:13,913] [INFO] [runner_train_mujoco] Average state value: 0.46240049137920136
[2022-12-07 08:40:13,913] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 08:40:13,982] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.07254
[2022-12-07 08:40:14,037] [INFO] [controller] EPOCH 2 loss ppo:  -0.02189, loss val: 0.07223
[2022-12-07 08:40:14,085] [INFO] [controller] EPOCH 3 loss ppo:  -0.03207, loss val: 0.07357
[2022-12-07 08:40:14,132] [INFO] [controller] EPOCH 4 loss ppo:  -0.04157, loss val: 0.07391
[2022-12-07 08:40:14,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:40:14,363] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:40:14,363] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:40:22,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:40:29,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:40:37,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:40:45,075] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:52,637] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:40:59,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:41:07,517] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:41:15,363] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:41:22,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:41:30,356] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.168221238317462
[2022-12-07 08:41:30,356] [INFO] [runner_train_mujoco] Average state value: 0.5060981536582113
[2022-12-07 08:41:30,356] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 08:41:30,405] [INFO] [controller] EPOCH 1 loss ppo:  -0.01494, loss val: 0.04517
[2022-12-07 08:41:30,445] [INFO] [controller] EPOCH 2 loss ppo:  -0.02332, loss val: 0.03865
[2022-12-07 08:41:30,548] [INFO] [controller] EPOCH 3 loss ppo:  -0.03557, loss val: 0.03877
[2022-12-07 08:41:30,590] [INFO] [controller] EPOCH 4 loss ppo:  -0.04333, loss val: 0.03733
[2022-12-07 08:41:30,599] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:41:30,802] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:41:30,802] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:41:39,027] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:41:46,764] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:41:54,780] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:42:02,396] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:42:10,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:42:17,468] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:42:25,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:42:33,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:42:40,536] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:42:48,307] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.8029219103111
[2022-12-07 08:42:48,307] [INFO] [runner_train_mujoco] Average state value: 0.3988060602098703
[2022-12-07 08:42:48,307] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 08:42:48,359] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.08073
[2022-12-07 08:42:48,400] [INFO] [controller] EPOCH 2 loss ppo:  -0.02103, loss val: 0.08000
[2022-12-07 08:42:48,444] [INFO] [controller] EPOCH 3 loss ppo:  -0.02875, loss val: 0.07940
[2022-12-07 08:42:48,485] [INFO] [controller] EPOCH 4 loss ppo:  -0.03472, loss val: 0.07831
[2022-12-07 08:42:48,494] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:42:48,696] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:42:48,697] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:42:56,404] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:43:04,381] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:43:12,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:43:20,366] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:43:28,526] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:43:36,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:43:43,965] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:43:51,009] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:43:58,837] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:44:06,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.27520328558656
[2022-12-07 08:44:06,640] [INFO] [runner_train_mujoco] Average state value: 0.3997067750270168
[2022-12-07 08:44:06,640] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 08:44:06,697] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.11997
[2022-12-07 08:44:06,746] [INFO] [controller] EPOCH 2 loss ppo:  -0.01897, loss val: 0.11972
[2022-12-07 08:44:06,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.02583, loss val: 0.11908
[2022-12-07 08:44:06,835] [INFO] [controller] EPOCH 4 loss ppo:  -0.03263, loss val: 0.11832
[2022-12-07 08:44:06,844] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:44:07,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:44:07,057] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:44:14,691] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:44:22,453] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:44:29,897] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:44:38,032] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:44:45,365] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:44:52,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:45:00,160] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:45:07,495] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:45:15,378] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:45:23,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.568948885753928
[2022-12-07 08:45:23,603] [INFO] [runner_train_mujoco] Average state value: 0.3930589510103067
[2022-12-07 08:45:23,603] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 08:45:23,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.09198
[2022-12-07 08:45:23,728] [INFO] [controller] EPOCH 2 loss ppo:  -0.01751, loss val: 0.09096
[2022-12-07 08:45:23,778] [INFO] [controller] EPOCH 3 loss ppo:  -0.02468, loss val: 0.09054
[2022-12-07 08:45:23,834] [INFO] [controller] EPOCH 4 loss ppo:  -0.03336, loss val: 0.09010
[2022-12-07 08:45:23,844] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:45:24,067] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:45:24,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:45:34,409] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:45:42,622] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:45:51,144] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:45:59,195] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:46:07,870] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:46:16,781] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:46:25,311] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:46:34,622] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:46:42,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:46:51,410] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.23240038893094
[2022-12-07 08:46:51,410] [INFO] [runner_train_mujoco] Average state value: 0.4770347705458601
[2022-12-07 08:46:51,410] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 08:46:51,468] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.05299
[2022-12-07 08:46:51,524] [INFO] [controller] EPOCH 2 loss ppo:  -0.01767, loss val: 0.05291
[2022-12-07 08:46:51,570] [INFO] [controller] EPOCH 3 loss ppo:  -0.02378, loss val: 0.05299
[2022-12-07 08:46:51,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.03008, loss val: 0.05313
[2022-12-07 08:46:51,625] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:46:51,833] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:46:51,834] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:47:00,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:47:08,732] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:47:17,225] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:47:25,196] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:47:32,589] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:47:40,718] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:47:50,268] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:47:58,509] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:48:06,666] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:48:14,310] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.063313555307095
[2022-12-07 08:48:14,310] [INFO] [runner_train_mujoco] Average state value: 0.3799449874237179
[2022-12-07 08:48:14,310] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 08:48:14,382] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.09058
[2022-12-07 08:48:14,434] [INFO] [controller] EPOCH 2 loss ppo:  -0.01552, loss val: 0.09204
[2022-12-07 08:48:14,484] [INFO] [controller] EPOCH 3 loss ppo:  -0.01871, loss val: 0.09084
[2022-12-07 08:48:14,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.02334, loss val: 0.09080
[2022-12-07 08:48:14,537] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:48:14,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:48:14,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:48:22,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:48:30,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:48:37,810] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:48:45,691] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:48:53,134] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:49:00,992] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:49:07,888] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:49:15,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:49:23,722] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:49:31,261] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.822145291695916
[2022-12-07 08:49:31,261] [INFO] [runner_train_mujoco] Average state value: 0.4537809245511889
[2022-12-07 08:49:31,261] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 08:49:31,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.08260
[2022-12-07 08:49:31,360] [INFO] [controller] EPOCH 2 loss ppo:  -0.01494, loss val: 0.07404
[2022-12-07 08:49:31,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.01649, loss val: 0.08051
[2022-12-07 08:49:31,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.01867, loss val: 0.07883
[2022-12-07 08:49:31,461] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:49:31,581] [INFO] [optimize] Finished learning.
