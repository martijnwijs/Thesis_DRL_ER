[2022-12-07 01:32:06,478] [INFO] [optimize] Starting learning
[2022-12-07 01:32:06,498] [INFO] [optimize] Starting learning process..
[2022-12-07 01:32:06,612] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:32:06,612] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:32:16,409] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:32:25,455] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:32:34,245] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:32:43,310] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:32:52,303] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:33:01,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:33:09,289] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:33:18,087] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:33:27,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:33:35,424] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44260204860874597
[2022-12-07 01:33:35,425] [INFO] [runner_train_mujoco] Average state value: -0.03280605452259382
[2022-12-07 01:33:35,425] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 01:33:35,500] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.54207
[2022-12-07 01:33:35,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.05468, loss val: 0.47627
[2022-12-07 01:33:35,622] [INFO] [controller] EPOCH 3 loss ppo:  -0.07003, loss val: 0.41747
[2022-12-07 01:33:35,674] [INFO] [controller] EPOCH 4 loss ppo:  -0.08213, loss val: 0.36479
[2022-12-07 01:33:35,686] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:33:35,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:33:35,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:33:44,693] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:33:53,827] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:34:02,415] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:34:11,279] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:34:19,872] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:34:28,795] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:34:37,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:34:46,051] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:34:54,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:35:03,648] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6078112211325616
[2022-12-07 01:35:03,648] [INFO] [runner_train_mujoco] Average state value: 0.13824077261735995
[2022-12-07 01:35:03,648] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 01:35:03,710] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.22935
[2022-12-07 01:35:03,764] [INFO] [controller] EPOCH 2 loss ppo:  -0.05411, loss val: 0.20172
[2022-12-07 01:35:03,822] [INFO] [controller] EPOCH 3 loss ppo:  -0.07562, loss val: 0.17524
[2022-12-07 01:35:03,890] [INFO] [controller] EPOCH 4 loss ppo:  -0.08621, loss val: 0.15268
[2022-12-07 01:35:03,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:35:04,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:35:04,111] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:35:13,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:35:22,109] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:35:30,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:35:39,444] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:35:47,877] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:35:56,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:36:05,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:36:13,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:36:22,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:36:31,511] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7387776828135394
[2022-12-07 01:36:31,511] [INFO] [runner_train_mujoco] Average state value: 0.28099832649715245
[2022-12-07 01:36:31,511] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 01:36:31,566] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.17374
[2022-12-07 01:36:31,620] [INFO] [controller] EPOCH 2 loss ppo:  -0.04179, loss val: 0.15911
[2022-12-07 01:36:31,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.06182, loss val: 0.14027
[2022-12-07 01:36:31,731] [INFO] [controller] EPOCH 4 loss ppo:  -0.07461, loss val: 0.12519
[2022-12-07 01:36:31,743] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:36:31,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:36:31,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:36:41,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:36:50,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:36:58,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:37:07,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:37:16,328] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:37:24,495] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:37:33,496] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:37:42,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:37:51,372] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:38:00,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6236900588049532
[2022-12-07 01:38:00,170] [INFO] [runner_train_mujoco] Average state value: 0.4105913071893156
[2022-12-07 01:38:00,170] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 01:38:00,232] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.11107
[2022-12-07 01:38:00,290] [INFO] [controller] EPOCH 2 loss ppo:  -0.04334, loss val: 0.09966
[2022-12-07 01:38:00,342] [INFO] [controller] EPOCH 3 loss ppo:  -0.06216, loss val: 0.09176
[2022-12-07 01:38:00,406] [INFO] [controller] EPOCH 4 loss ppo:  -0.07513, loss val: 0.08431
[2022-12-07 01:38:00,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:38:00,639] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:38:00,639] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:38:09,187] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:38:18,467] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:38:26,893] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:38:35,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:38:44,427] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:38:53,241] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:39:01,961] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:39:11,034] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:39:19,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:39:28,347] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5362257627454754
[2022-12-07 01:39:28,347] [INFO] [runner_train_mujoco] Average state value: 0.4913537165944774
[2022-12-07 01:39:28,347] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 01:39:28,408] [INFO] [controller] EPOCH 1 loss ppo:  -0.01078, loss val: 0.11676
[2022-12-07 01:39:28,454] [INFO] [controller] EPOCH 2 loss ppo:  -0.04411, loss val: 0.11147
[2022-12-07 01:39:28,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.06273, loss val: 0.10720
[2022-12-07 01:39:28,561] [INFO] [controller] EPOCH 4 loss ppo:  -0.07390, loss val: 0.10303
[2022-12-07 01:39:28,571] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:39:28,794] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:39:28,794] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:39:37,997] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:39:46,782] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:39:55,781] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:40:04,735] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:40:13,670] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:40:22,287] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:40:30,427] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:40:39,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:40:47,011] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:40:55,445] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7053634449233371
[2022-12-07 01:40:55,445] [INFO] [runner_train_mujoco] Average state value: 0.5843242052992185
[2022-12-07 01:40:55,445] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 01:40:55,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01041, loss val: 0.08030
[2022-12-07 01:40:55,537] [INFO] [controller] EPOCH 2 loss ppo:  -0.03788, loss val: 0.07500
[2022-12-07 01:40:55,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.05933, loss val: 0.07130
[2022-12-07 01:40:55,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.07087, loss val: 0.06825
[2022-12-07 01:40:55,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:40:55,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:40:55,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:41:04,204] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:41:12,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:41:20,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:41:28,211] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:41:35,496] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:41:43,570] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:41:51,222] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:41:59,159] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:42:06,376] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:42:13,755] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6636755557144685
[2022-12-07 01:42:13,755] [INFO] [runner_train_mujoco] Average state value: 0.5589560368259747
[2022-12-07 01:42:13,755] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 01:42:13,807] [INFO] [controller] EPOCH 1 loss ppo:  -0.01281, loss val: 0.05478
[2022-12-07 01:42:13,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.04481, loss val: 0.05160
[2022-12-07 01:42:13,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.05948, loss val: 0.05027
[2022-12-07 01:42:13,932] [INFO] [controller] EPOCH 4 loss ppo:  -0.07017, loss val: 0.04839
[2022-12-07 01:42:13,942] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:42:14,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:42:14,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:42:21,346] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:42:28,284] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:42:35,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:42:42,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:42:49,361] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:42:56,231] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:43:03,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:43:10,795] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:43:17,646] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:43:25,436] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.71844671395948
[2022-12-07 01:43:25,436] [INFO] [runner_train_mujoco] Average state value: 0.5007425826887288
[2022-12-07 01:43:25,436] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 01:43:25,485] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.05536
[2022-12-07 01:43:25,525] [INFO] [controller] EPOCH 2 loss ppo:  -0.04137, loss val: 0.05399
[2022-12-07 01:43:25,628] [INFO] [controller] EPOCH 3 loss ppo:  -0.05880, loss val: 0.05232
[2022-12-07 01:43:25,671] [INFO] [controller] EPOCH 4 loss ppo:  -0.07084, loss val: 0.05036
[2022-12-07 01:43:25,680] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:43:25,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:43:25,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:43:32,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:43:40,453] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:43:47,434] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:43:54,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:44:01,300] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:44:08,388] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:44:15,194] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:44:21,932] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:44:28,814] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:44:35,654] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7149497641135444
[2022-12-07 01:44:35,654] [INFO] [runner_train_mujoco] Average state value: 0.5221773664404947
[2022-12-07 01:44:35,654] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 01:44:35,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.01152, loss val: 0.04970
[2022-12-07 01:44:35,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.04658, loss val: 0.04781
[2022-12-07 01:44:35,772] [INFO] [controller] EPOCH 3 loss ppo:  -0.06419, loss val: 0.04947
[2022-12-07 01:44:35,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.07862, loss val: 0.04660
[2022-12-07 01:44:35,819] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:44:36,021] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:44:36,021] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:44:43,246] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:44:50,724] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:44:58,095] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:45:05,601] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:45:13,113] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:45:20,222] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:45:27,490] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:45:34,286] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:45:41,840] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:45:48,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7203410359042909
[2022-12-07 01:45:48,972] [INFO] [runner_train_mujoco] Average state value: 0.5164957813881337
[2022-12-07 01:45:48,972] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 01:45:49,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.01154, loss val: 0.04698
[2022-12-07 01:45:49,061] [INFO] [controller] EPOCH 2 loss ppo:  -0.04263, loss val: 0.04524
[2022-12-07 01:45:49,104] [INFO] [controller] EPOCH 3 loss ppo:  -0.06162, loss val: 0.04420
[2022-12-07 01:45:49,145] [INFO] [controller] EPOCH 4 loss ppo:  -0.07235, loss val: 0.04232
[2022-12-07 01:45:49,154] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:45:49,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:45:49,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:45:56,329] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:46:03,872] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:46:11,191] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:46:18,310] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:46:24,787] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:46:31,580] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:46:38,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:46:45,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:46:52,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:46:59,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5596488527580443
[2022-12-07 01:46:59,564] [INFO] [runner_train_mujoco] Average state value: 0.5268605103592077
[2022-12-07 01:46:59,564] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 01:46:59,620] [INFO] [controller] EPOCH 1 loss ppo:  -0.01175, loss val: 0.04524
[2022-12-07 01:46:59,666] [INFO] [controller] EPOCH 2 loss ppo:  -0.04291, loss val: 0.04460
[2022-12-07 01:46:59,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.05931, loss val: 0.04363
[2022-12-07 01:46:59,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.06976, loss val: 0.04471
[2022-12-07 01:46:59,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:46:59,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:46:59,958] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:47:06,923] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:47:14,149] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:47:20,889] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:47:28,044] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:47:34,861] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:47:42,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:47:49,350] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:47:56,233] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:48:03,055] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:48:09,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6464331864534473
[2022-12-07 01:48:09,784] [INFO] [runner_train_mujoco] Average state value: 0.5622961620887119
[2022-12-07 01:48:09,784] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 01:48:09,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.01066, loss val: 0.04162
[2022-12-07 01:48:09,875] [INFO] [controller] EPOCH 2 loss ppo:  -0.03951, loss val: 0.04121
[2022-12-07 01:48:09,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.05459, loss val: 0.04034
[2022-12-07 01:48:09,957] [INFO] [controller] EPOCH 4 loss ppo:  -0.06626, loss val: 0.03951
[2022-12-07 01:48:09,966] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:48:10,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:48:10,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:48:17,001] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:48:24,067] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:48:31,427] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:48:38,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:48:46,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:48:52,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:49:00,115] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:49:06,774] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:49:13,571] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:49:20,568] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8956954979993152
[2022-12-07 01:49:20,568] [INFO] [runner_train_mujoco] Average state value: 0.52432886060824
[2022-12-07 01:49:20,568] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 01:49:20,618] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.04392
[2022-12-07 01:49:20,658] [INFO] [controller] EPOCH 2 loss ppo:  -0.04384, loss val: 0.04384
[2022-12-07 01:49:20,701] [INFO] [controller] EPOCH 3 loss ppo:  -0.06254, loss val: 0.04371
[2022-12-07 01:49:20,742] [INFO] [controller] EPOCH 4 loss ppo:  -0.07402, loss val: 0.04287
[2022-12-07 01:49:20,749] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:49:20,940] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:49:20,941] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:49:28,376] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:49:35,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:49:42,791] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:49:49,469] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:49:56,521] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:50:03,801] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:50:10,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:50:17,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:50:24,618] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:50:31,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9548883139646257
[2022-12-07 01:50:31,507] [INFO] [runner_train_mujoco] Average state value: 0.5396610873440901
[2022-12-07 01:50:31,507] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 01:50:31,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.01069, loss val: 0.03157
[2022-12-07 01:50:31,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.04168, loss val: 0.03255
[2022-12-07 01:50:31,634] [INFO] [controller] EPOCH 3 loss ppo:  -0.06220, loss val: 0.03140
[2022-12-07 01:50:31,675] [INFO] [controller] EPOCH 4 loss ppo:  -0.07259, loss val: 0.03127
[2022-12-07 01:50:31,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:50:31,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:50:31,860] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:50:38,778] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:50:45,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:50:52,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:50:59,947] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:51:07,123] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:51:14,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:51:21,148] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:51:28,019] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:51:34,704] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:51:41,679] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0188618703669718
[2022-12-07 01:51:41,679] [INFO] [runner_train_mujoco] Average state value: 0.5516499418318273
[2022-12-07 01:51:41,679] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 01:51:41,728] [INFO] [controller] EPOCH 1 loss ppo:  -0.01277, loss val: 0.03836
[2022-12-07 01:51:41,766] [INFO] [controller] EPOCH 2 loss ppo:  -0.04399, loss val: 0.03836
[2022-12-07 01:51:41,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.06493, loss val: 0.03777
[2022-12-07 01:51:41,861] [INFO] [controller] EPOCH 4 loss ppo:  -0.07694, loss val: 0.03728
[2022-12-07 01:51:41,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:51:42,070] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:51:42,070] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:51:49,165] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:51:56,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:52:03,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:52:11,101] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:52:18,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:52:25,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:52:32,906] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:52:40,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:52:46,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:52:53,764] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9952696429146096
[2022-12-07 01:52:53,764] [INFO] [runner_train_mujoco] Average state value: 0.5387079370121162
[2022-12-07 01:52:53,764] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 01:52:53,814] [INFO] [controller] EPOCH 1 loss ppo:  -0.01179, loss val: 0.03062
[2022-12-07 01:52:53,853] [INFO] [controller] EPOCH 2 loss ppo:  -0.04212, loss val: 0.02979
[2022-12-07 01:52:53,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.05973, loss val: 0.03070
[2022-12-07 01:52:53,935] [INFO] [controller] EPOCH 4 loss ppo:  -0.06949, loss val: 0.02789
[2022-12-07 01:52:53,942] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:52:54,137] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:52:54,138] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:53:00,928] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:53:08,087] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:53:15,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:53:22,726] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:53:29,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:53:36,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:53:43,967] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:53:51,190] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:53:58,316] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:54:05,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8765206105083324
[2022-12-07 01:54:05,332] [INFO] [runner_train_mujoco] Average state value: 0.49493647817770636
[2022-12-07 01:54:05,332] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 01:54:05,384] [INFO] [controller] EPOCH 1 loss ppo:  -0.00976, loss val: 0.03573
[2022-12-07 01:54:05,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.03931, loss val: 0.03343
[2022-12-07 01:54:05,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.06080, loss val: 0.03532
[2022-12-07 01:54:05,508] [INFO] [controller] EPOCH 4 loss ppo:  -0.07507, loss val: 0.03366
[2022-12-07 01:54:05,516] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:54:05,707] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:54:05,708] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:54:12,916] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:54:20,198] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:54:26,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:54:33,941] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:54:41,123] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:54:48,608] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:54:55,780] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:55:02,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:55:10,234] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:55:17,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7534894567996483
[2022-12-07 01:55:17,013] [INFO] [runner_train_mujoco] Average state value: 0.4722461762626965
[2022-12-07 01:55:17,013] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 01:55:17,061] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.05102
[2022-12-07 01:55:17,098] [INFO] [controller] EPOCH 2 loss ppo:  -0.03745, loss val: 0.05001
[2022-12-07 01:55:17,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.05520, loss val: 0.04846
[2022-12-07 01:55:17,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.06852, loss val: 0.04613
[2022-12-07 01:55:17,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:55:17,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:55:17,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:55:24,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:55:30,927] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:55:37,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:55:44,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:55:52,330] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:55:59,219] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:56:06,144] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:56:12,971] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:56:19,837] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:56:26,750] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6344687127954167
[2022-12-07 01:56:26,750] [INFO] [runner_train_mujoco] Average state value: 0.5115180764148632
[2022-12-07 01:56:26,750] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 01:56:26,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.03458
[2022-12-07 01:56:26,837] [INFO] [controller] EPOCH 2 loss ppo:  -0.04149, loss val: 0.03594
[2022-12-07 01:56:26,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.05780, loss val: 0.03587
[2022-12-07 01:56:26,974] [INFO] [controller] EPOCH 4 loss ppo:  -0.07276, loss val: 0.03471
[2022-12-07 01:56:26,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:56:27,177] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:56:27,177] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:56:34,004] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:56:41,507] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:56:48,561] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:56:55,368] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:57:02,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:57:09,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:57:17,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:57:24,167] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:57:31,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:57:38,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0241337745297368
[2022-12-07 01:57:38,464] [INFO] [runner_train_mujoco] Average state value: 0.45354875215018786
[2022-12-07 01:57:38,464] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 01:57:38,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.13199
[2022-12-07 01:57:38,556] [INFO] [controller] EPOCH 2 loss ppo:  -0.03431, loss val: 0.13207
[2022-12-07 01:57:38,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.04792, loss val: 0.13020
[2022-12-07 01:57:38,641] [INFO] [controller] EPOCH 4 loss ppo:  -0.06063, loss val: 0.12627
[2022-12-07 01:57:38,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:57:38,857] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:57:38,857] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:57:45,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:57:52,856] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:58:00,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:58:07,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:58:14,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:58:21,335] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:58:28,161] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:58:35,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:58:42,129] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:58:49,252] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6948166655878281
[2022-12-07 01:58:49,252] [INFO] [runner_train_mujoco] Average state value: 0.5356557010610898
[2022-12-07 01:58:49,252] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 01:58:49,314] [INFO] [controller] EPOCH 1 loss ppo:  -0.01042, loss val: 0.03594
[2022-12-07 01:58:49,360] [INFO] [controller] EPOCH 2 loss ppo:  -0.04087, loss val: 0.03627
[2022-12-07 01:58:49,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.06162, loss val: 0.03593
[2022-12-07 01:58:49,445] [INFO] [controller] EPOCH 4 loss ppo:  -0.07517, loss val: 0.03678
[2022-12-07 01:58:49,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:58:49,654] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:58:49,655] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:58:56,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:59:03,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:59:10,672] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:59:17,405] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:59:24,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:59:31,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:59:38,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:59:45,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:59:52,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:59:59,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7988167179200765
[2022-12-07 01:59:59,478] [INFO] [runner_train_mujoco] Average state value: 0.5616134603023528
[2022-12-07 01:59:59,478] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 01:59:59,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.01077, loss val: 0.03240
[2022-12-07 01:59:59,564] [INFO] [controller] EPOCH 2 loss ppo:  -0.03821, loss val: 0.03507
[2022-12-07 01:59:59,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.05704, loss val: 0.03210
[2022-12-07 01:59:59,643] [INFO] [controller] EPOCH 4 loss ppo:  -0.06985, loss val: 0.03259
[2022-12-07 01:59:59,649] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:59:59,841] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:59:59,841] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:00:06,633] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:00:13,645] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:00:20,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:00:27,369] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:00:34,097] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:00:41,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:00:48,866] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:00:55,697] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:01:02,702] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:01:09,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8297675047731623
[2022-12-07 02:01:09,670] [INFO] [runner_train_mujoco] Average state value: 0.5721574470996857
[2022-12-07 02:01:09,671] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 02:01:09,721] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.04154
[2022-12-07 02:01:09,761] [INFO] [controller] EPOCH 2 loss ppo:  -0.03780, loss val: 0.04037
[2022-12-07 02:01:09,810] [INFO] [controller] EPOCH 3 loss ppo:  -0.05786, loss val: 0.03931
[2022-12-07 02:01:09,852] [INFO] [controller] EPOCH 4 loss ppo:  -0.07099, loss val: 0.04189
[2022-12-07 02:01:09,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:01:10,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:01:10,053] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:01:16,799] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:01:24,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:01:31,221] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:01:38,128] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:01:44,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:01:51,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:01:58,744] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:02:06,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:02:13,482] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:02:21,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.094460407494924
[2022-12-07 02:02:21,065] [INFO] [runner_train_mujoco] Average state value: 0.5364153629541397
[2022-12-07 02:02:21,065] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 02:02:21,112] [INFO] [controller] EPOCH 1 loss ppo:  -0.01607, loss val: 0.03994
[2022-12-07 02:02:21,155] [INFO] [controller] EPOCH 2 loss ppo:  -0.04971, loss val: 0.03920
[2022-12-07 02:02:21,199] [INFO] [controller] EPOCH 3 loss ppo:  -0.06476, loss val: 0.03918
[2022-12-07 02:02:21,242] [INFO] [controller] EPOCH 4 loss ppo:  -0.07594, loss val: 0.03918
[2022-12-07 02:02:21,252] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:02:21,457] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:02:21,457] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:02:28,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:02:35,110] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:02:41,977] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:02:48,819] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:02:56,364] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:03:03,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:03:10,328] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:03:17,655] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:03:25,181] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:03:32,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8025957708290598
[2022-12-07 02:03:32,118] [INFO] [runner_train_mujoco] Average state value: 0.5359200325409571
[2022-12-07 02:03:32,118] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 02:03:32,176] [INFO] [controller] EPOCH 1 loss ppo:  -0.01103, loss val: 0.03896
[2022-12-07 02:03:32,223] [INFO] [controller] EPOCH 2 loss ppo:  -0.04084, loss val: 0.03846
[2022-12-07 02:03:32,267] [INFO] [controller] EPOCH 3 loss ppo:  -0.06218, loss val: 0.03833
[2022-12-07 02:03:32,308] [INFO] [controller] EPOCH 4 loss ppo:  -0.07179, loss val: 0.03890
[2022-12-07 02:03:32,317] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:03:32,540] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:03:32,540] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:03:39,319] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:03:46,681] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:03:53,872] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:04:00,495] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:04:08,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:04:17,209] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:04:24,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:04:32,980] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:04:40,010] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:04:47,119] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7548177617339595
[2022-12-07 02:04:47,120] [INFO] [runner_train_mujoco] Average state value: 0.5070133454067012
[2022-12-07 02:04:47,120] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 02:04:47,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.06863
[2022-12-07 02:04:47,215] [INFO] [controller] EPOCH 2 loss ppo:  -0.04186, loss val: 0.06832
[2022-12-07 02:04:47,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.05962, loss val: 0.06776
[2022-12-07 02:04:47,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.07368, loss val: 0.06703
[2022-12-07 02:04:47,313] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:04:47,522] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:04:47,522] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:04:54,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:05:01,668] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:05:08,666] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:05:15,684] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:05:22,368] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:05:28,990] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:05:35,455] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:05:42,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:05:49,210] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:05:56,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9269831445023178
[2022-12-07 02:05:56,887] [INFO] [runner_train_mujoco] Average state value: 0.5490112495372692
[2022-12-07 02:05:56,887] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 02:05:56,946] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.04037
[2022-12-07 02:05:56,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.03948, loss val: 0.03884
[2022-12-07 02:05:57,041] [INFO] [controller] EPOCH 3 loss ppo:  -0.05794, loss val: 0.03867
[2022-12-07 02:05:57,089] [INFO] [controller] EPOCH 4 loss ppo:  -0.06782, loss val: 0.03957
[2022-12-07 02:05:57,096] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:05:57,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:05:57,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:06:05,057] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:06:11,923] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:06:18,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:06:25,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:06:32,041] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:06:38,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:06:46,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:06:53,230] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:07:00,490] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:07:09,233] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9383755288956375
[2022-12-07 02:07:09,234] [INFO] [runner_train_mujoco] Average state value: 0.5449972900946934
[2022-12-07 02:07:09,234] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 02:07:09,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04848
[2022-12-07 02:07:09,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.03518, loss val: 0.04959
[2022-12-07 02:07:09,421] [INFO] [controller] EPOCH 3 loss ppo:  -0.05257, loss val: 0.04560
[2022-12-07 02:07:09,497] [INFO] [controller] EPOCH 4 loss ppo:  -0.06550, loss val: 0.04264
[2022-12-07 02:07:09,508] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:07:09,732] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:07:09,732] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:07:17,516] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:07:24,950] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:07:31,899] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:07:39,057] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:07:46,186] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:07:53,247] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:08:00,000] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:08:07,372] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:08:13,953] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:08:21,174] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.191215956250445
[2022-12-07 02:08:21,174] [INFO] [runner_train_mujoco] Average state value: 0.5713977712492148
[2022-12-07 02:08:21,175] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 02:08:21,222] [INFO] [controller] EPOCH 1 loss ppo:  -0.01111, loss val: 0.03775
[2022-12-07 02:08:21,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.03615, loss val: 0.03689
[2022-12-07 02:08:21,297] [INFO] [controller] EPOCH 3 loss ppo:  -0.05849, loss val: 0.03952
[2022-12-07 02:08:21,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.07331, loss val: 0.03763
[2022-12-07 02:08:21,346] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:08:21,544] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:08:21,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:08:28,318] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:08:35,593] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:08:42,327] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:08:49,486] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:08:56,589] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:09:03,548] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:09:10,374] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:09:17,451] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:09:24,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:09:31,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0204096399906593
[2022-12-07 02:09:31,110] [INFO] [runner_train_mujoco] Average state value: 0.6005786725133657
[2022-12-07 02:09:31,110] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 02:09:31,160] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.05831
[2022-12-07 02:09:31,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03192, loss val: 0.05458
[2022-12-07 02:09:31,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.04965, loss val: 0.05318
[2022-12-07 02:09:31,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.06171, loss val: 0.04648
[2022-12-07 02:09:31,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:09:31,563] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:09:31,563] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:09:38,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:09:46,327] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:09:54,013] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:10:01,137] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:10:07,971] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:10:14,891] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:10:21,561] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:10:28,427] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:10:35,220] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:10:42,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2278126519989876
[2022-12-07 02:10:42,432] [INFO] [runner_train_mujoco] Average state value: 0.5682706178724766
[2022-12-07 02:10:42,432] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 02:10:42,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.03930
[2022-12-07 02:10:42,526] [INFO] [controller] EPOCH 2 loss ppo:  -0.03852, loss val: 0.03629
[2022-12-07 02:10:42,568] [INFO] [controller] EPOCH 3 loss ppo:  -0.05695, loss val: 0.03745
[2022-12-07 02:10:42,612] [INFO] [controller] EPOCH 4 loss ppo:  -0.07221, loss val: 0.03672
[2022-12-07 02:10:42,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:10:42,797] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:10:42,798] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:10:50,432] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:10:57,975] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:11:05,217] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:11:11,956] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:11:18,551] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:11:25,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:11:32,143] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:11:39,492] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:11:46,648] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:11:53,755] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1086134462403483
[2022-12-07 02:11:53,756] [INFO] [runner_train_mujoco] Average state value: 0.4539376248841484
[2022-12-07 02:11:53,756] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 02:11:53,817] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.09538
[2022-12-07 02:11:53,864] [INFO] [controller] EPOCH 2 loss ppo:  -0.03562, loss val: 0.09291
[2022-12-07 02:11:53,912] [INFO] [controller] EPOCH 3 loss ppo:  -0.05840, loss val: 0.09091
[2022-12-07 02:11:53,958] [INFO] [controller] EPOCH 4 loss ppo:  -0.07223, loss val: 0.08927
[2022-12-07 02:11:53,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:11:54,177] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:11:54,177] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:12:01,219] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:12:08,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:12:15,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:12:22,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:12:29,879] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:12:36,843] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:12:43,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:12:50,441] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:12:57,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:13:05,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1105336401264887
[2022-12-07 02:13:05,339] [INFO] [runner_train_mujoco] Average state value: 0.5018530607745051
[2022-12-07 02:13:05,339] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 02:13:05,385] [INFO] [controller] EPOCH 1 loss ppo:  -0.01580, loss val: 0.05943
[2022-12-07 02:13:05,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.04524, loss val: 0.05300
[2022-12-07 02:13:05,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.06670, loss val: 0.05176
[2022-12-07 02:13:05,514] [INFO] [controller] EPOCH 4 loss ppo:  -0.08005, loss val: 0.05646
[2022-12-07 02:13:05,522] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:13:05,727] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:13:05,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:13:13,233] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:13:20,499] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:13:27,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:13:34,735] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:13:41,514] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:13:48,233] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:13:55,018] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:14:01,643] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:14:08,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:14:14,870] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.605715162012104
[2022-12-07 02:14:14,870] [INFO] [runner_train_mujoco] Average state value: 0.49666050432374087
[2022-12-07 02:14:14,870] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 02:14:14,921] [INFO] [controller] EPOCH 1 loss ppo:  -0.01495, loss val: 0.05841
[2022-12-07 02:14:14,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.03896, loss val: 0.05677
[2022-12-07 02:14:15,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.05469, loss val: 0.05634
[2022-12-07 02:14:15,048] [INFO] [controller] EPOCH 4 loss ppo:  -0.06880, loss val: 0.05594
[2022-12-07 02:14:15,057] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:14:15,243] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:14:15,244] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:14:21,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:14:29,425] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:14:36,655] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:14:43,812] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:14:50,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:14:57,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:15:03,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:15:10,622] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:15:17,247] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:15:24,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7761725098835712
[2022-12-07 02:15:24,050] [INFO] [runner_train_mujoco] Average state value: 0.545140018582344
[2022-12-07 02:15:24,050] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 02:15:24,101] [INFO] [controller] EPOCH 1 loss ppo:  -0.01619, loss val: 0.03138
[2022-12-07 02:15:24,146] [INFO] [controller] EPOCH 2 loss ppo:  -0.04210, loss val: 0.03119
[2022-12-07 02:15:24,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.05879, loss val: 0.03109
[2022-12-07 02:15:24,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.07309, loss val: 0.03107
[2022-12-07 02:15:24,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:15:24,435] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:15:24,436] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:15:31,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:15:39,019] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:15:46,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:15:52,996] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:15:59,826] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:16:06,592] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:16:13,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:16:20,177] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:16:26,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:16:33,675] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.037496514973905
[2022-12-07 02:16:33,676] [INFO] [runner_train_mujoco] Average state value: 0.5215554220552246
[2022-12-07 02:16:33,676] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 02:16:33,725] [INFO] [controller] EPOCH 1 loss ppo:  -0.01569, loss val: 0.04519
[2022-12-07 02:16:33,768] [INFO] [controller] EPOCH 2 loss ppo:  -0.03972, loss val: 0.04592
[2022-12-07 02:16:33,811] [INFO] [controller] EPOCH 3 loss ppo:  -0.05726, loss val: 0.04424
[2022-12-07 02:16:33,855] [INFO] [controller] EPOCH 4 loss ppo:  -0.06820, loss val: 0.04212
[2022-12-07 02:16:33,865] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:16:34,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:16:34,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:16:41,024] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:16:48,071] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:16:55,173] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:17:02,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:17:08,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:17:15,843] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:17:22,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:17:29,606] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:17:35,907] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:17:42,611] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.933227903568192
[2022-12-07 02:17:42,611] [INFO] [runner_train_mujoco] Average state value: 0.5276646049817403
[2022-12-07 02:17:42,611] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 02:17:42,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.03853
[2022-12-07 02:17:42,699] [INFO] [controller] EPOCH 2 loss ppo:  -0.03739, loss val: 0.03828
[2022-12-07 02:17:42,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.05577, loss val: 0.03709
[2022-12-07 02:17:42,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.06796, loss val: 0.03694
[2022-12-07 02:17:42,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:17:43,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:17:43,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:17:49,691] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:17:56,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:18:03,758] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:18:10,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:18:17,889] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:18:24,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:18:31,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:18:38,270] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:18:44,751] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:18:51,229] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5008415167482054
[2022-12-07 02:18:51,229] [INFO] [runner_train_mujoco] Average state value: 0.490559759358565
[2022-12-07 02:18:51,229] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 02:18:51,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.03641
[2022-12-07 02:18:51,318] [INFO] [controller] EPOCH 2 loss ppo:  -0.03547, loss val: 0.03474
[2022-12-07 02:18:51,360] [INFO] [controller] EPOCH 3 loss ppo:  -0.05398, loss val: 0.03319
[2022-12-07 02:18:51,410] [INFO] [controller] EPOCH 4 loss ppo:  -0.06766, loss val: 0.03162
[2022-12-07 02:18:51,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:18:51,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:18:51,606] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:18:58,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:19:05,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:19:12,481] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:19:19,860] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:19:27,144] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:19:36,935] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:19:44,526] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:19:51,732] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:19:59,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:20:06,774] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0874842943420933
[2022-12-07 02:20:06,774] [INFO] [runner_train_mujoco] Average state value: 0.4124509172737598
[2022-12-07 02:20:06,774] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 02:20:06,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.07032
[2022-12-07 02:20:06,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.03245, loss val: 0.07419
[2022-12-07 02:20:06,960] [INFO] [controller] EPOCH 3 loss ppo:  -0.04809, loss val: 0.07342
[2022-12-07 02:20:07,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.05945, loss val: 0.07146
[2022-12-07 02:20:07,036] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:20:07,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:20:07,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:20:15,356] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:20:22,544] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:20:29,695] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:20:36,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:20:43,740] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:20:50,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:20:57,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:21:04,938] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:21:12,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:21:18,918] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8818363560049645
[2022-12-07 02:21:18,918] [INFO] [runner_train_mujoco] Average state value: 0.3818573024397095
[2022-12-07 02:21:18,918] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 02:21:18,965] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.07131
[2022-12-07 02:21:19,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.03264, loss val: 0.07478
[2022-12-07 02:21:19,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.05281, loss val: 0.06871
[2022-12-07 02:21:19,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.06664, loss val: 0.06871
[2022-12-07 02:21:19,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:21:19,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:21:19,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:21:26,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:21:33,769] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:21:40,656] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:21:47,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:21:54,990] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:22:01,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:22:09,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:22:16,660] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:22:23,530] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:22:30,302] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.271913394666565
[2022-12-07 02:22:30,303] [INFO] [runner_train_mujoco] Average state value: 0.44303064611554144
[2022-12-07 02:22:30,303] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 02:22:30,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.07181
[2022-12-07 02:22:30,392] [INFO] [controller] EPOCH 2 loss ppo:  -0.02915, loss val: 0.06923
[2022-12-07 02:22:30,500] [INFO] [controller] EPOCH 3 loss ppo:  -0.04643, loss val: 0.06688
[2022-12-07 02:22:30,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.05730, loss val: 0.06487
[2022-12-07 02:22:30,551] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:22:30,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:22:30,733] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:22:37,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:22:45,095] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:22:51,905] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:22:58,966] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:23:05,934] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:23:13,221] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:23:20,034] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:23:27,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:23:34,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:23:41,153] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7337818271027494
[2022-12-07 02:23:41,153] [INFO] [runner_train_mujoco] Average state value: 0.48902456666032473
[2022-12-07 02:23:41,154] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 02:23:41,197] [INFO] [controller] EPOCH 1 loss ppo:  -0.01504, loss val: 0.03487
[2022-12-07 02:23:41,241] [INFO] [controller] EPOCH 2 loss ppo:  -0.03623, loss val: 0.03517
[2022-12-07 02:23:41,285] [INFO] [controller] EPOCH 3 loss ppo:  -0.05355, loss val: 0.03422
[2022-12-07 02:23:41,329] [INFO] [controller] EPOCH 4 loss ppo:  -0.06809, loss val: 0.03453
[2022-12-07 02:23:41,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:23:41,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:23:41,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:23:48,516] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:23:55,751] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:24:03,006] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:24:10,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:24:17,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:24:24,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:24:30,954] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:24:37,833] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:24:44,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:24:52,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4439687873058333
[2022-12-07 02:24:52,149] [INFO] [runner_train_mujoco] Average state value: 0.4689735859235128
[2022-12-07 02:24:52,149] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 02:24:52,201] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.06241
[2022-12-07 02:24:52,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.03374, loss val: 0.06170
[2022-12-07 02:24:52,284] [INFO] [controller] EPOCH 3 loss ppo:  -0.04875, loss val: 0.06060
[2022-12-07 02:24:52,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.06196, loss val: 0.05927
[2022-12-07 02:24:52,336] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:24:52,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:24:52,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:24:59,521] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:25:06,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:25:13,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:25:20,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:25:27,481] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:25:34,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:25:41,348] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:25:48,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:25:55,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:26:02,998] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.453706181786104
[2022-12-07 02:26:02,999] [INFO] [runner_train_mujoco] Average state value: 0.48843047562489905
[2022-12-07 02:26:02,999] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 02:26:03,048] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.04380
[2022-12-07 02:26:03,092] [INFO] [controller] EPOCH 2 loss ppo:  -0.03113, loss val: 0.04306
[2022-12-07 02:26:03,135] [INFO] [controller] EPOCH 3 loss ppo:  -0.04879, loss val: 0.04565
[2022-12-07 02:26:03,176] [INFO] [controller] EPOCH 4 loss ppo:  -0.06292, loss val: 0.04271
[2022-12-07 02:26:03,185] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:26:03,372] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:26:03,372] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:26:10,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:26:17,263] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:26:23,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:26:30,379] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:26:37,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:26:44,822] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:26:51,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:26:58,598] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:27:05,691] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:27:12,933] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.28164921681271
[2022-12-07 02:27:12,933] [INFO] [runner_train_mujoco] Average state value: 0.4791991008445621
[2022-12-07 02:27:12,933] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 02:27:12,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.05321
[2022-12-07 02:27:13,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.02693, loss val: 0.05079
[2022-12-07 02:27:13,070] [INFO] [controller] EPOCH 3 loss ppo:  -0.04551, loss val: 0.05018
[2022-12-07 02:27:13,116] [INFO] [controller] EPOCH 4 loss ppo:  -0.05940, loss val: 0.04925
[2022-12-07 02:27:13,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:27:13,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:27:13,323] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:27:20,545] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:27:27,921] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:27:34,877] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:27:41,806] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:27:48,882] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:27:55,997] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:28:02,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:28:09,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:28:17,170] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:28:23,853] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.485958209442791
[2022-12-07 02:28:23,853] [INFO] [runner_train_mujoco] Average state value: 0.5142972969710827
[2022-12-07 02:28:23,854] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 02:28:23,906] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.03316
[2022-12-07 02:28:23,953] [INFO] [controller] EPOCH 2 loss ppo:  -0.03187, loss val: 0.03351
[2022-12-07 02:28:24,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.04733, loss val: 0.03284
[2022-12-07 02:28:24,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.05846, loss val: 0.03271
[2022-12-07 02:28:24,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:28:24,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:28:24,294] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:28:31,589] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:28:38,509] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:28:45,209] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:28:52,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:28:58,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:29:05,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:29:13,107] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:29:20,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:29:27,358] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:29:34,022] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5644466015803493
[2022-12-07 02:29:34,022] [INFO] [runner_train_mujoco] Average state value: 0.5022035640950004
[2022-12-07 02:29:34,022] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 02:29:34,071] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.03740
[2022-12-07 02:29:34,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.02942, loss val: 0.03589
[2022-12-07 02:29:34,156] [INFO] [controller] EPOCH 3 loss ppo:  -0.04762, loss val: 0.03568
[2022-12-07 02:29:34,199] [INFO] [controller] EPOCH 4 loss ppo:  -0.06042, loss val: 0.03538
[2022-12-07 02:29:34,207] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:29:34,395] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:29:34,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:29:41,807] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:29:49,106] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:29:55,945] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:30:03,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:30:10,008] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:30:17,215] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:30:24,617] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:30:31,191] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:30:38,445] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:30:45,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.215263189008259
[2022-12-07 02:30:45,328] [INFO] [runner_train_mujoco] Average state value: 0.46257504200190314
[2022-12-07 02:30:45,328] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 02:30:45,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.04806
[2022-12-07 02:30:45,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.02912, loss val: 0.04956
[2022-12-07 02:30:45,477] [INFO] [controller] EPOCH 3 loss ppo:  -0.04537, loss val: 0.04776
[2022-12-07 02:30:45,522] [INFO] [controller] EPOCH 4 loss ppo:  -0.05494, loss val: 0.04551
[2022-12-07 02:30:45,533] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:30:45,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:30:45,727] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:30:53,123] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:31:00,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:31:07,330] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:31:14,778] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:31:21,568] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:31:28,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:31:35,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:31:42,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:31:49,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:31:56,613] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5577206868016225
[2022-12-07 02:31:56,613] [INFO] [runner_train_mujoco] Average state value: 0.5303785042961439
[2022-12-07 02:31:56,613] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 02:31:56,663] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.04250
[2022-12-07 02:31:56,705] [INFO] [controller] EPOCH 2 loss ppo:  -0.02621, loss val: 0.04125
[2022-12-07 02:31:56,746] [INFO] [controller] EPOCH 3 loss ppo:  -0.04143, loss val: 0.04246
[2022-12-07 02:31:56,787] [INFO] [controller] EPOCH 4 loss ppo:  -0.05285, loss val: 0.04202
[2022-12-07 02:31:56,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:31:56,996] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:31:56,996] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:32:04,576] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:32:11,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:32:19,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:32:25,712] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:32:32,926] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:32:40,195] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:32:47,144] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:32:54,231] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:33:01,560] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:33:08,658] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9481808255346644
[2022-12-07 02:33:08,658] [INFO] [runner_train_mujoco] Average state value: 0.5352012689212958
[2022-12-07 02:33:08,658] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 02:33:08,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01385, loss val: 0.03318
[2022-12-07 02:33:08,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.02352, loss val: 0.03249
[2022-12-07 02:33:08,798] [INFO] [controller] EPOCH 3 loss ppo:  -0.03797, loss val: 0.03243
[2022-12-07 02:33:08,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.05088, loss val: 0.03206
[2022-12-07 02:33:08,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:33:09,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:33:09,061] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:33:16,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:33:22,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:33:29,673] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:33:36,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:33:43,834] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:33:50,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:33:57,808] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:34:04,927] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:34:11,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:34:18,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.164500112634508
[2022-12-07 02:34:18,998] [INFO] [runner_train_mujoco] Average state value: 0.5485764960547288
[2022-12-07 02:34:18,998] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 02:34:19,049] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.05042
[2022-12-07 02:34:19,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.02378, loss val: 0.04626
[2022-12-07 02:34:19,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.03750, loss val: 0.04554
[2022-12-07 02:34:19,185] [INFO] [controller] EPOCH 4 loss ppo:  -0.04863, loss val: 0.04671
[2022-12-07 02:34:19,194] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:34:19,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:34:19,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:34:26,615] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:34:33,411] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:34:40,002] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:34:46,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:34:53,959] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:35:01,065] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:35:07,939] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:35:14,944] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:35:22,170] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:35:29,206] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.606879552585423
[2022-12-07 02:35:29,206] [INFO] [runner_train_mujoco] Average state value: 0.4980894793594877
[2022-12-07 02:35:29,206] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 02:35:29,260] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04896
[2022-12-07 02:35:29,301] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.04912
[2022-12-07 02:35:29,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.03237, loss val: 0.04636
[2022-12-07 02:35:29,458] [INFO] [controller] EPOCH 4 loss ppo:  -0.04705, loss val: 0.04581
[2022-12-07 02:35:29,467] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:35:29,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:35:29,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:35:36,659] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:35:43,762] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:35:50,480] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:35:57,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:36:04,635] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:36:11,884] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:36:18,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:36:25,838] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:36:32,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:36:39,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4000604892205666
[2022-12-07 02:36:39,544] [INFO] [runner_train_mujoco] Average state value: 0.4823188919425011
[2022-12-07 02:36:39,544] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 02:36:39,597] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.05118
[2022-12-07 02:36:39,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.02129, loss val: 0.05086
[2022-12-07 02:36:39,687] [INFO] [controller] EPOCH 3 loss ppo:  -0.03345, loss val: 0.05061
[2022-12-07 02:36:39,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.04586, loss val: 0.04890
[2022-12-07 02:36:39,736] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:36:39,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:36:39,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:36:47,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:36:54,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:37:01,128] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:37:08,066] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:37:14,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:37:22,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:37:28,678] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:37:35,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:37:42,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:37:50,056] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6534069809538474
[2022-12-07 02:37:50,057] [INFO] [runner_train_mujoco] Average state value: 0.49362914027770355
[2022-12-07 02:37:50,057] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 02:37:50,102] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.03804
[2022-12-07 02:37:50,135] [INFO] [controller] EPOCH 2 loss ppo:  -0.01894, loss val: 0.03954
[2022-12-07 02:37:50,177] [INFO] [controller] EPOCH 3 loss ppo:  -0.02712, loss val: 0.03843
[2022-12-07 02:37:50,212] [INFO] [controller] EPOCH 4 loss ppo:  -0.03821, loss val: 0.03612
[2022-12-07 02:37:50,221] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:37:50,415] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:37:50,416] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:37:57,121] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:38:04,329] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:38:11,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:38:18,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:38:24,950] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:38:31,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:38:38,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:38:46,052] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:38:53,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:39:00,209] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2919660440744565
[2022-12-07 02:39:00,209] [INFO] [runner_train_mujoco] Average state value: 0.4899142562548319
[2022-12-07 02:39:00,209] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 02:39:00,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.03821
[2022-12-07 02:39:00,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.01882, loss val: 0.03879
[2022-12-07 02:39:00,343] [INFO] [controller] EPOCH 3 loss ppo:  -0.02729, loss val: 0.03772
[2022-12-07 02:39:00,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.03664, loss val: 0.03765
[2022-12-07 02:39:00,395] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:39:00,598] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:39:00,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:39:07,741] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:39:14,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:39:21,791] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:39:28,600] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:39:35,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:39:42,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:39:49,815] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:39:56,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:40:03,584] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:40:10,860] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8525718444626333
[2022-12-07 02:40:10,861] [INFO] [runner_train_mujoco] Average state value: 0.4895706378867229
[2022-12-07 02:40:10,861] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 02:40:10,930] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04236
[2022-12-07 02:40:10,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.01982, loss val: 0.04250
[2022-12-07 02:40:11,025] [INFO] [controller] EPOCH 3 loss ppo:  -0.02716, loss val: 0.04561
[2022-12-07 02:40:11,064] [INFO] [controller] EPOCH 4 loss ppo:  -0.03584, loss val: 0.04667
[2022-12-07 02:40:11,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:40:11,256] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:40:11,256] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:40:18,412] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:40:25,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:40:32,832] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:40:39,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:40:46,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:40:53,112] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:40:59,523] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:41:06,901] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:41:16,911] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:41:24,529] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7383480738138535
[2022-12-07 02:41:24,530] [INFO] [runner_train_mujoco] Average state value: 0.4839918008744717
[2022-12-07 02:41:24,530] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 02:41:24,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04501
[2022-12-07 02:41:24,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.01724, loss val: 0.04449
[2022-12-07 02:41:24,680] [INFO] [controller] EPOCH 3 loss ppo:  -0.02183, loss val: 0.04441
[2022-12-07 02:41:24,724] [INFO] [controller] EPOCH 4 loss ppo:  -0.02819, loss val: 0.04394
[2022-12-07 02:41:24,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:41:24,931] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:41:24,932] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:41:32,667] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:41:40,786] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:41:48,617] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:41:56,861] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:42:04,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:42:13,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:42:21,038] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:42:28,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:42:36,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:42:43,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.105908318424162
[2022-12-07 02:42:43,979] [INFO] [runner_train_mujoco] Average state value: 0.4965615836282572
[2022-12-07 02:42:43,979] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 02:42:44,035] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.03672
[2022-12-07 02:42:44,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.01611, loss val: 0.03757
[2022-12-07 02:42:44,129] [INFO] [controller] EPOCH 3 loss ppo:  -0.01857, loss val: 0.03644
[2022-12-07 02:42:44,174] [INFO] [controller] EPOCH 4 loss ppo:  -0.02174, loss val: 0.03784
[2022-12-07 02:42:44,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:42:44,306] [INFO] [optimize] Finished learning.
