[2022-12-07 02:42:47,469] [INFO] [optimize] Starting learning
[2022-12-07 02:42:47,474] [INFO] [optimize] Starting learning process..
[2022-12-07 02:42:47,528] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:42:47,528] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:42:54,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:42:59,773] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:43:05,300] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:43:11,092] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:43:16,791] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:43:23,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:43:29,279] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:43:34,921] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:43:40,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:43:45,809] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14813783963937147
[2022-12-07 02:43:45,810] [INFO] [runner_train_mujoco] Average state value: -0.38371838005942605
[2022-12-07 02:43:45,810] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 02:43:45,873] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.80412
[2022-12-07 02:43:45,950] [INFO] [controller] EPOCH 2 loss ppo:  -0.02898, loss val: 0.73126
[2022-12-07 02:43:46,009] [INFO] [controller] EPOCH 3 loss ppo:  -0.03409, loss val: 0.64966
[2022-12-07 02:43:46,069] [INFO] [controller] EPOCH 4 loss ppo:  -0.03714, loss val: 0.57964
[2022-12-07 02:43:46,079] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:43:46,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:43:46,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:43:52,029] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:43:57,468] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:44:03,226] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:44:08,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:44:14,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:44:19,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:44:25,405] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:44:31,589] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:44:37,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:44:43,471] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15132966344519008
[2022-12-07 02:44:43,471] [INFO] [runner_train_mujoco] Average state value: -0.20826110720137758
[2022-12-07 02:44:43,471] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 02:44:43,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01578, loss val: 0.70349
[2022-12-07 02:44:43,585] [INFO] [controller] EPOCH 2 loss ppo:  -0.03116, loss val: 0.64666
[2022-12-07 02:44:43,632] [INFO] [controller] EPOCH 3 loss ppo:  -0.03511, loss val: 0.58153
[2022-12-07 02:44:43,693] [INFO] [controller] EPOCH 4 loss ppo:  -0.03837, loss val: 0.49704
[2022-12-07 02:44:43,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:44:43,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:44:43,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:44:49,274] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:44:54,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:45:00,505] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:45:05,982] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:45:11,685] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:45:17,343] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:45:22,931] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:45:29,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:45:34,834] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:45:41,147] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23216224727016085
[2022-12-07 02:45:41,147] [INFO] [runner_train_mujoco] Average state value: -0.03470322512711088
[2022-12-07 02:45:41,147] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 02:45:41,210] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.35581
[2022-12-07 02:45:41,256] [INFO] [controller] EPOCH 2 loss ppo:  -0.02896, loss val: 0.31894
[2022-12-07 02:45:41,308] [INFO] [controller] EPOCH 3 loss ppo:  -0.03453, loss val: 0.26432
[2022-12-07 02:45:41,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.03754, loss val: 0.22651
[2022-12-07 02:45:41,369] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:45:41,542] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:45:41,542] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:45:47,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:45:52,670] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:45:58,086] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:46:03,486] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:46:09,306] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:46:15,266] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:46:21,179] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:46:26,714] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:46:32,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:46:37,869] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16240276881052645
[2022-12-07 02:46:37,869] [INFO] [runner_train_mujoco] Average state value: 0.1272362926900387
[2022-12-07 02:46:37,869] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 02:46:38,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.24774
[2022-12-07 02:46:38,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.02857, loss val: 0.20433
[2022-12-07 02:46:38,396] [INFO] [controller] EPOCH 3 loss ppo:  -0.03129, loss val: 0.17953
[2022-12-07 02:46:38,632] [INFO] [controller] EPOCH 4 loss ppo:  -0.03549, loss val: 0.14688
[2022-12-07 02:46:38,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:46:38,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:46:38,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:46:44,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:46:50,506] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:46:56,102] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:47:01,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:47:07,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:47:12,498] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:47:18,178] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:47:24,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:47:29,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:47:35,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1746023134798757
[2022-12-07 02:47:35,195] [INFO] [runner_train_mujoco] Average state value: 0.28502246494342887
[2022-12-07 02:47:35,195] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 02:47:35,251] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.15774
[2022-12-07 02:47:35,312] [INFO] [controller] EPOCH 2 loss ppo:  -0.02804, loss val: 0.12460
[2022-12-07 02:47:35,389] [INFO] [controller] EPOCH 3 loss ppo:  -0.03181, loss val: 0.10251
[2022-12-07 02:47:35,446] [INFO] [controller] EPOCH 4 loss ppo:  -0.03530, loss val: 0.08797
[2022-12-07 02:47:35,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:47:35,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:47:35,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:47:41,614] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:47:46,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:47:52,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:47:58,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:48:03,732] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:48:09,416] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:48:15,347] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:48:20,870] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:48:26,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:48:31,531] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2484690200821023
[2022-12-07 02:48:31,531] [INFO] [runner_train_mujoco] Average state value: 0.4571478098829587
[2022-12-07 02:48:31,531] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 02:48:31,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01009, loss val: 0.07924
[2022-12-07 02:48:31,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.02268, loss val: 0.06552
[2022-12-07 02:48:31,686] [INFO] [controller] EPOCH 3 loss ppo:  -0.02786, loss val: 0.05404
[2022-12-07 02:48:31,736] [INFO] [controller] EPOCH 4 loss ppo:  -0.03117, loss val: 0.04720
[2022-12-07 02:48:31,745] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:48:31,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:48:31,911] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:48:37,257] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:48:42,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:48:48,660] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:48:54,383] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:48:59,950] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:49:05,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:49:11,184] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:49:16,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:49:22,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:49:27,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24517902880772574
[2022-12-07 02:49:27,912] [INFO] [runner_train_mujoco] Average state value: 0.6035196331739426
[2022-12-07 02:49:27,912] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 02:49:27,991] [INFO] [controller] EPOCH 1 loss ppo:  -0.00765, loss val: 0.05874
[2022-12-07 02:49:28,047] [INFO] [controller] EPOCH 2 loss ppo:  -0.01797, loss val: 0.04882
[2022-12-07 02:49:28,101] [INFO] [controller] EPOCH 3 loss ppo:  -0.02679, loss val: 0.04519
[2022-12-07 02:49:28,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.02948, loss val: 0.04314
[2022-12-07 02:49:28,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:49:28,354] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:49:28,354] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:49:34,064] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:49:39,656] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:49:45,415] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:49:50,719] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:49:56,123] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:50:01,636] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:50:06,593] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:50:12,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:50:17,475] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:50:22,814] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2272886551562549
[2022-12-07 02:50:22,814] [INFO] [runner_train_mujoco] Average state value: 0.7425714425245921
[2022-12-07 02:50:22,815] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 02:50:22,871] [INFO] [controller] EPOCH 1 loss ppo:  -0.00731, loss val: 0.04260
[2022-12-07 02:50:22,943] [INFO] [controller] EPOCH 2 loss ppo:  -0.01996, loss val: 0.04320
[2022-12-07 02:50:23,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.02483, loss val: 0.04343
[2022-12-07 02:50:23,085] [INFO] [controller] EPOCH 4 loss ppo:  -0.02860, loss val: 0.04342
[2022-12-07 02:50:23,096] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:50:23,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:50:23,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:50:28,733] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:50:34,130] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:50:39,664] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:50:45,353] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:50:51,126] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:50:57,089] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:51:02,685] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:51:08,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:51:13,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:51:19,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2950761180987119
[2022-12-07 02:51:19,328] [INFO] [runner_train_mujoco] Average state value: 0.7902119140625
[2022-12-07 02:51:19,328] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 02:51:19,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.00864, loss val: 0.04440
[2022-12-07 02:51:19,443] [INFO] [controller] EPOCH 2 loss ppo:  -0.01979, loss val: 0.04487
[2022-12-07 02:51:19,501] [INFO] [controller] EPOCH 3 loss ppo:  -0.02121, loss val: 0.04492
[2022-12-07 02:51:19,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.02705, loss val: 0.04482
[2022-12-07 02:51:19,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:51:19,753] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:51:19,753] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:51:25,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:51:30,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:51:36,027] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:51:41,729] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:51:47,044] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:51:52,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:51:58,292] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:52:03,834] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:52:09,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:52:14,849] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3694444452167195
[2022-12-07 02:52:14,849] [INFO] [runner_train_mujoco] Average state value: 0.7925557187795639
[2022-12-07 02:52:14,849] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 02:52:14,901] [INFO] [controller] EPOCH 1 loss ppo:  -0.00770, loss val: 0.04696
[2022-12-07 02:52:14,953] [INFO] [controller] EPOCH 2 loss ppo:  -0.01880, loss val: 0.04659
[2022-12-07 02:52:14,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.02525, loss val: 0.04733
[2022-12-07 02:52:15,045] [INFO] [controller] EPOCH 4 loss ppo:  -0.02998, loss val: 0.04552
[2022-12-07 02:52:15,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:52:15,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:52:15,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:52:20,966] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:52:26,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:52:32,558] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:52:38,082] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:52:43,715] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:52:49,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:52:54,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:53:00,753] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:53:06,076] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:53:12,158] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40475395926907887
[2022-12-07 02:53:12,158] [INFO] [runner_train_mujoco] Average state value: 0.7635333151817322
[2022-12-07 02:53:12,159] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 02:53:12,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01120, loss val: 0.04117
[2022-12-07 02:53:12,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.02582, loss val: 0.04018
[2022-12-07 02:53:12,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02565, loss val: 0.03903
[2022-12-07 02:53:12,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.02950, loss val: 0.03839
[2022-12-07 02:53:12,377] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:53:12,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:53:12,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:53:18,487] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:53:24,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:53:29,367] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:53:34,838] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:53:40,451] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:53:45,699] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:53:51,046] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:53:56,911] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:54:02,376] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:54:07,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40777170352072956
[2022-12-07 02:54:07,991] [INFO] [runner_train_mujoco] Average state value: 0.7074099789857866
[2022-12-07 02:54:07,991] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 02:54:08,048] [INFO] [controller] EPOCH 1 loss ppo:  -0.00657, loss val: 0.03840
[2022-12-07 02:54:08,099] [INFO] [controller] EPOCH 2 loss ppo:  -0.02054, loss val: 0.03971
[2022-12-07 02:54:08,159] [INFO] [controller] EPOCH 3 loss ppo:  -0.02500, loss val: 0.03869
[2022-12-07 02:54:08,206] [INFO] [controller] EPOCH 4 loss ppo:  -0.03085, loss val: 0.03846
[2022-12-07 02:54:08,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:54:08,384] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:54:08,384] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:54:14,193] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:54:20,168] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:54:25,720] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:54:31,196] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:54:36,708] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:54:41,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:54:47,478] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:54:52,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:54:58,127] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:55:03,597] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5415647795290714
[2022-12-07 02:55:03,597] [INFO] [runner_train_mujoco] Average state value: 0.6987961078484852
[2022-12-07 02:55:03,597] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 02:55:03,661] [INFO] [controller] EPOCH 1 loss ppo:  -0.00833, loss val: 0.03736
[2022-12-07 02:55:03,706] [INFO] [controller] EPOCH 2 loss ppo:  -0.01983, loss val: 0.03779
[2022-12-07 02:55:03,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.02111, loss val: 0.03723
[2022-12-07 02:55:03,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.02852, loss val: 0.03732
[2022-12-07 02:55:03,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:55:03,980] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:55:03,981] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:55:09,571] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:55:15,415] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:55:21,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:55:26,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:55:31,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:55:37,353] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:55:43,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:55:48,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:55:53,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:55:59,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6470829117734722
[2022-12-07 02:55:59,634] [INFO] [runner_train_mujoco] Average state value: 0.6938651125033697
[2022-12-07 02:55:59,634] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 02:55:59,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.00604, loss val: 0.03448
[2022-12-07 02:55:59,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.02276, loss val: 0.03592
[2022-12-07 02:55:59,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.02665, loss val: 0.03554
[2022-12-07 02:55:59,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.02908, loss val: 0.03416
[2022-12-07 02:55:59,881] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:56:00,061] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:56:00,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:56:05,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:56:10,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:56:16,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:56:21,837] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:56:27,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:56:34,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:56:39,682] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:56:45,066] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:56:50,613] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:56:56,063] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8215403659727165
[2022-12-07 02:56:56,064] [INFO] [runner_train_mujoco] Average state value: 0.6879103862841924
[2022-12-07 02:56:56,064] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 02:56:56,125] [INFO] [controller] EPOCH 1 loss ppo:  -0.00809, loss val: 0.03942
[2022-12-07 02:56:56,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.02440, loss val: 0.03852
[2022-12-07 02:56:56,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.03082, loss val: 0.04095
[2022-12-07 02:56:56,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.03694, loss val: 0.03946
[2022-12-07 02:56:56,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:56:56,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:56:56,472] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:57:02,315] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:57:07,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:57:13,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:57:19,002] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:57:25,514] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:57:30,880] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:57:36,786] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:57:42,694] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:57:48,106] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:57:53,596] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8827332726411481
[2022-12-07 02:57:53,597] [INFO] [runner_train_mujoco] Average state value: 0.7063100646336873
[2022-12-07 02:57:53,597] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 02:57:53,666] [INFO] [controller] EPOCH 1 loss ppo:  -0.01096, loss val: 0.03940
[2022-12-07 02:57:53,714] [INFO] [controller] EPOCH 2 loss ppo:  -0.02425, loss val: 0.03930
[2022-12-07 02:57:53,760] [INFO] [controller] EPOCH 3 loss ppo:  -0.02890, loss val: 0.03966
[2022-12-07 02:57:53,809] [INFO] [controller] EPOCH 4 loss ppo:  -0.03389, loss val: 0.03968
[2022-12-07 02:57:53,820] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:57:53,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:57:53,991] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:57:59,570] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:58:05,037] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:58:10,782] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:58:16,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:58:22,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:58:27,351] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:58:32,948] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:58:38,522] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:58:43,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:58:49,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8713372052048618
[2022-12-07 02:58:49,292] [INFO] [runner_train_mujoco] Average state value: 0.7247330595652263
[2022-12-07 02:58:49,292] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 02:58:49,364] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.03908
[2022-12-07 02:58:49,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.02309, loss val: 0.03932
[2022-12-07 02:58:49,481] [INFO] [controller] EPOCH 3 loss ppo:  -0.02505, loss val: 0.03942
[2022-12-07 02:58:49,538] [INFO] [controller] EPOCH 4 loss ppo:  -0.02890, loss val: 0.03887
[2022-12-07 02:58:49,548] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:58:49,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:58:49,726] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:58:54,956] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:59:00,161] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:59:05,552] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:59:10,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:59:15,344] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:59:20,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:59:26,367] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:59:32,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:59:37,387] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:59:43,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9589906690536504
[2022-12-07 02:59:43,202] [INFO] [runner_train_mujoco] Average state value: 0.7121531566977501
[2022-12-07 02:59:43,202] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 02:59:43,273] [INFO] [controller] EPOCH 1 loss ppo:  -0.01192, loss val: 0.04394
[2022-12-07 02:59:43,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.02315, loss val: 0.04263
[2022-12-07 02:59:43,382] [INFO] [controller] EPOCH 3 loss ppo:  -0.02562, loss val: 0.04089
[2022-12-07 02:59:43,436] [INFO] [controller] EPOCH 4 loss ppo:  -0.03192, loss val: 0.04196
[2022-12-07 02:59:43,448] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:59:43,622] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:59:43,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:59:48,848] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:59:53,904] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:59:59,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:00:05,047] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:00:10,232] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:00:15,848] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:00:21,051] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:00:26,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:00:32,254] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:00:37,855] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0925355235116385
[2022-12-07 03:00:37,856] [INFO] [runner_train_mujoco] Average state value: 0.7098627623319625
[2022-12-07 03:00:37,856] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 03:00:37,921] [INFO] [controller] EPOCH 1 loss ppo:  -0.01089, loss val: 0.03885
[2022-12-07 03:00:37,981] [INFO] [controller] EPOCH 2 loss ppo:  -0.02137, loss val: 0.04031
[2022-12-07 03:00:38,028] [INFO] [controller] EPOCH 3 loss ppo:  -0.02670, loss val: 0.03855
[2022-12-07 03:00:38,082] [INFO] [controller] EPOCH 4 loss ppo:  -0.03032, loss val: 0.03956
[2022-12-07 03:00:38,093] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:00:38,271] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:00:38,271] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:00:43,820] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:00:49,110] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:00:54,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:00:59,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:01:05,121] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:01:10,565] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:01:16,273] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:01:21,555] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:01:27,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:01:33,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1018095798834406
[2022-12-07 03:01:33,173] [INFO] [runner_train_mujoco] Average state value: 0.7077082441449165
[2022-12-07 03:01:33,173] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 03:01:33,226] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.03982
[2022-12-07 03:01:33,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.01981, loss val: 0.03902
[2022-12-07 03:01:33,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.02565, loss val: 0.03978
[2022-12-07 03:01:33,360] [INFO] [controller] EPOCH 4 loss ppo:  -0.03144, loss val: 0.03960
[2022-12-07 03:01:33,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:01:33,536] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:01:33,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:01:38,863] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:01:44,232] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:01:49,708] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:01:54,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:02:00,514] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:02:05,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:02:11,209] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:02:16,953] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:02:21,976] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:02:27,630] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1640951528179988
[2022-12-07 03:02:27,630] [INFO] [runner_train_mujoco] Average state value: 0.6896091159780819
[2022-12-07 03:02:27,631] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 03:02:27,689] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.03755
[2022-12-07 03:02:27,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.02347, loss val: 0.03739
[2022-12-07 03:02:27,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.02277, loss val: 0.03762
[2022-12-07 03:02:27,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.02850, loss val: 0.03786
[2022-12-07 03:02:27,856] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:02:28,022] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:02:28,022] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:02:33,434] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:02:39,206] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:02:44,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:02:50,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:02:55,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:03:01,415] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:03:07,567] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:03:12,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:03:18,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:03:24,010] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2425300121875007
[2022-12-07 03:03:24,011] [INFO] [runner_train_mujoco] Average state value: 0.683083029806614
[2022-12-07 03:03:24,011] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 03:03:24,066] [INFO] [controller] EPOCH 1 loss ppo:  -0.01027, loss val: 0.03681
[2022-12-07 03:03:24,111] [INFO] [controller] EPOCH 2 loss ppo:  -0.01937, loss val: 0.03674
[2022-12-07 03:03:24,170] [INFO] [controller] EPOCH 3 loss ppo:  -0.02631, loss val: 0.03684
[2022-12-07 03:03:24,217] [INFO] [controller] EPOCH 4 loss ppo:  -0.03137, loss val: 0.03655
[2022-12-07 03:03:24,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:03:24,386] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:03:24,387] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:03:29,508] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:03:35,056] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:03:40,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:03:46,050] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:03:51,510] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:03:56,993] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:04:02,311] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:04:07,449] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:04:12,967] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:04:17,975] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3769713210799481
[2022-12-07 03:04:17,975] [INFO] [runner_train_mujoco] Average state value: 0.6767723034620284
[2022-12-07 03:04:17,975] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 03:04:18,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04000
[2022-12-07 03:04:18,149] [INFO] [controller] EPOCH 2 loss ppo:  -0.02418, loss val: 0.04011
[2022-12-07 03:04:18,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.03151, loss val: 0.04042
[2022-12-07 03:04:18,242] [INFO] [controller] EPOCH 4 loss ppo:  -0.03357, loss val: 0.03947
[2022-12-07 03:04:18,252] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:04:18,416] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:04:18,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:04:23,842] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:04:29,441] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:04:34,900] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:04:40,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:04:45,953] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:04:51,456] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:04:56,998] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:05:02,015] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:05:07,513] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:05:12,771] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4469599232401267
[2022-12-07 03:05:12,772] [INFO] [runner_train_mujoco] Average state value: 0.6976745661099752
[2022-12-07 03:05:12,772] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 03:05:12,836] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.04062
[2022-12-07 03:05:12,886] [INFO] [controller] EPOCH 2 loss ppo:  -0.02080, loss val: 0.04009
[2022-12-07 03:05:12,937] [INFO] [controller] EPOCH 3 loss ppo:  -0.02834, loss val: 0.04011
[2022-12-07 03:05:13,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.03437, loss val: 0.04091
[2022-12-07 03:05:13,056] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:05:13,233] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:05:13,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:05:18,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:05:23,781] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:05:29,128] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:05:34,531] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:05:39,874] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:05:45,647] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:05:50,820] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:05:56,406] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:06:01,590] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:06:07,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.536714649805882
[2022-12-07 03:06:07,065] [INFO] [runner_train_mujoco] Average state value: 0.7044270949761072
[2022-12-07 03:06:07,065] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 03:06:07,146] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.03769
[2022-12-07 03:06:07,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.02033, loss val: 0.03717
[2022-12-07 03:06:07,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.02752, loss val: 0.03810
[2022-12-07 03:06:07,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.03611, loss val: 0.03584
[2022-12-07 03:06:07,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:06:07,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:06:07,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:06:12,994] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:06:18,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:06:23,808] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:06:29,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:06:35,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:06:41,007] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:06:46,379] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:06:51,367] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:06:56,732] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:07:02,205] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5265238836224302
[2022-12-07 03:07:02,205] [INFO] [runner_train_mujoco] Average state value: 0.6733353090683619
[2022-12-07 03:07:02,205] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 03:07:02,312] [INFO] [controller] EPOCH 1 loss ppo:  -0.01283, loss val: 0.03644
[2022-12-07 03:07:02,405] [INFO] [controller] EPOCH 2 loss ppo:  -0.02070, loss val: 0.03751
[2022-12-07 03:07:02,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.02538, loss val: 0.03728
[2022-12-07 03:07:02,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.02862, loss val: 0.03773
[2022-12-07 03:07:02,614] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:07:02,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:07:02,800] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:07:09,276] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:07:15,648] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:07:21,801] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:07:27,365] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:07:32,928] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:07:38,347] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:07:43,792] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:07:49,270] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:07:55,386] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:08:00,889] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5586594628964319
[2022-12-07 03:08:00,889] [INFO] [runner_train_mujoco] Average state value: 0.664603021244208
[2022-12-07 03:08:00,889] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 03:08:00,946] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.04199
[2022-12-07 03:08:00,992] [INFO] [controller] EPOCH 2 loss ppo:  -0.02317, loss val: 0.04168
[2022-12-07 03:08:01,050] [INFO] [controller] EPOCH 3 loss ppo:  -0.03092, loss val: 0.04255
[2022-12-07 03:08:01,111] [INFO] [controller] EPOCH 4 loss ppo:  -0.03679, loss val: 0.04134
[2022-12-07 03:08:01,122] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:08:01,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:08:01,299] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:08:07,019] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:08:12,795] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:08:18,092] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:08:23,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:08:29,124] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:08:34,442] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:08:39,584] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:08:44,665] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:08:49,959] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:08:55,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6581860432244606
[2022-12-07 03:08:55,254] [INFO] [runner_train_mujoco] Average state value: 0.6796257159511248
[2022-12-07 03:08:55,254] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 03:08:55,314] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.03694
[2022-12-07 03:08:55,366] [INFO] [controller] EPOCH 2 loss ppo:  -0.02208, loss val: 0.03797
[2022-12-07 03:08:55,427] [INFO] [controller] EPOCH 3 loss ppo:  -0.02533, loss val: 0.03776
[2022-12-07 03:08:55,483] [INFO] [controller] EPOCH 4 loss ppo:  -0.03549, loss val: 0.03699
[2022-12-07 03:08:55,493] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:08:55,677] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:08:55,678] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:09:01,193] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:09:06,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:09:12,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:09:18,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:09:23,851] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:09:29,123] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:09:34,704] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:09:39,723] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:09:44,687] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:09:49,664] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6817230853271077
[2022-12-07 03:09:49,665] [INFO] [runner_train_mujoco] Average state value: 0.6795373455286026
[2022-12-07 03:09:49,665] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 03:09:49,721] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.04028
[2022-12-07 03:09:49,766] [INFO] [controller] EPOCH 2 loss ppo:  -0.01795, loss val: 0.04180
[2022-12-07 03:09:49,811] [INFO] [controller] EPOCH 3 loss ppo:  -0.02242, loss val: 0.04164
[2022-12-07 03:09:49,876] [INFO] [controller] EPOCH 4 loss ppo:  -0.03246, loss val: 0.04077
[2022-12-07 03:09:49,885] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:09:50,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:09:50,056] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:09:55,416] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:00,955] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:10:06,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:10:12,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:10:17,634] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:10:23,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:10:28,238] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:10:33,928] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:10:39,403] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:10:44,688] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6865577680294481
[2022-12-07 03:10:44,689] [INFO] [runner_train_mujoco] Average state value: 0.6845489858786264
[2022-12-07 03:10:44,689] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 03:10:44,744] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04194
[2022-12-07 03:10:44,787] [INFO] [controller] EPOCH 2 loss ppo:  -0.01899, loss val: 0.04192
[2022-12-07 03:10:44,832] [INFO] [controller] EPOCH 3 loss ppo:  -0.02468, loss val: 0.04388
[2022-12-07 03:10:44,888] [INFO] [controller] EPOCH 4 loss ppo:  -0.03190, loss val: 0.04284
[2022-12-07 03:10:44,897] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:10:45,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:10:45,063] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:10:50,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:56,027] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:01,352] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:11:06,824] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:11:12,160] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:11:17,523] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:11:22,778] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:11:28,187] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:11:33,358] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:11:38,945] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7875813253002844
[2022-12-07 03:11:38,945] [INFO] [runner_train_mujoco] Average state value: 0.6826652438640595
[2022-12-07 03:11:38,946] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 03:11:39,009] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.04011
[2022-12-07 03:11:39,060] [INFO] [controller] EPOCH 2 loss ppo:  -0.02064, loss val: 0.03993
[2022-12-07 03:11:39,108] [INFO] [controller] EPOCH 3 loss ppo:  -0.02646, loss val: 0.04048
[2022-12-07 03:11:39,159] [INFO] [controller] EPOCH 4 loss ppo:  -0.03521, loss val: 0.04055
[2022-12-07 03:11:39,169] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:11:39,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:11:39,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:11:44,461] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:11:49,953] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:55,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:12:00,248] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:05,514] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:12:10,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:12:16,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:12:21,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:12:26,906] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:12:32,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.882475531020989
[2022-12-07 03:12:32,298] [INFO] [runner_train_mujoco] Average state value: 0.6616696178913115
[2022-12-07 03:12:32,298] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 03:12:32,361] [INFO] [controller] EPOCH 1 loss ppo:  -0.01452, loss val: 0.04286
[2022-12-07 03:12:32,411] [INFO] [controller] EPOCH 2 loss ppo:  -0.02025, loss val: 0.04389
[2022-12-07 03:12:32,464] [INFO] [controller] EPOCH 3 loss ppo:  -0.02411, loss val: 0.04243
[2022-12-07 03:12:32,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.03399, loss val: 0.04097
[2022-12-07 03:12:32,524] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:12:32,689] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:12:32,689] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:12:38,143] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:12:43,400] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:12:48,541] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:12:54,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:59,241] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:13:04,694] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:13:09,591] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:13:15,062] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:13:20,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:13:25,439] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9443408160832232
[2022-12-07 03:13:25,439] [INFO] [runner_train_mujoco] Average state value: 0.6771356280247371
[2022-12-07 03:13:25,439] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 03:13:25,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.04134
[2022-12-07 03:13:25,535] [INFO] [controller] EPOCH 2 loss ppo:  -0.02181, loss val: 0.04040
[2022-12-07 03:13:25,582] [INFO] [controller] EPOCH 3 loss ppo:  -0.02445, loss val: 0.04110
[2022-12-07 03:13:25,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.03019, loss val: 0.04065
[2022-12-07 03:13:25,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:13:25,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:13:25,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:13:31,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:13:36,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:13:41,870] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:13:47,351] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:13:52,430] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:13:57,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:14:02,922] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:14:08,154] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:14:13,438] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:14:19,031] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.903631874493223
[2022-12-07 03:14:19,031] [INFO] [runner_train_mujoco] Average state value: 0.687961085518201
[2022-12-07 03:14:19,031] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 03:14:19,100] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04167
[2022-12-07 03:14:19,147] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.04105
[2022-12-07 03:14:19,193] [INFO] [controller] EPOCH 3 loss ppo:  -0.02661, loss val: 0.04114
[2022-12-07 03:14:19,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.03206, loss val: 0.04096
[2022-12-07 03:14:19,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:14:19,429] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:14:19,430] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:14:24,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:14:29,288] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:14:34,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:14:39,955] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:14:45,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:14:50,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:14:55,451] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:15:00,576] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:15:05,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:15:11,262] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9791874412066073
[2022-12-07 03:15:11,263] [INFO] [runner_train_mujoco] Average state value: 0.679290068467458
[2022-12-07 03:15:11,263] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 03:15:11,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04097
[2022-12-07 03:15:11,366] [INFO] [controller] EPOCH 2 loss ppo:  -0.02363, loss val: 0.04113
[2022-12-07 03:15:11,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.02911, loss val: 0.04049
[2022-12-07 03:15:11,459] [INFO] [controller] EPOCH 4 loss ppo:  -0.03544, loss val: 0.04238
[2022-12-07 03:15:11,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:15:11,629] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:15:11,629] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:15:17,023] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:15:22,182] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:15:27,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:15:32,935] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:15:38,515] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:15:43,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:15:49,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:15:54,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:15:59,780] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:16:04,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0127240536978332
[2022-12-07 03:16:04,981] [INFO] [runner_train_mujoco] Average state value: 0.6769515120188395
[2022-12-07 03:16:04,982] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 03:16:05,060] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.04319
[2022-12-07 03:16:05,115] [INFO] [controller] EPOCH 2 loss ppo:  -0.02045, loss val: 0.04399
[2022-12-07 03:16:05,167] [INFO] [controller] EPOCH 3 loss ppo:  -0.02529, loss val: 0.04313
[2022-12-07 03:16:05,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.02886, loss val: 0.04376
[2022-12-07 03:16:05,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:16:05,389] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:16:05,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:16:10,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:16:15,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:16:20,309] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:16:24,814] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:16:29,191] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:16:33,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:16:38,469] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:16:42,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:16:47,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:16:52,592] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.072489215060563
[2022-12-07 03:16:52,593] [INFO] [runner_train_mujoco] Average state value: 0.6790105411211649
[2022-12-07 03:16:52,593] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 03:16:52,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.01535, loss val: 0.03880
[2022-12-07 03:16:52,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.02144, loss val: 0.03984
[2022-12-07 03:16:52,763] [INFO] [controller] EPOCH 3 loss ppo:  -0.02585, loss val: 0.03929
[2022-12-07 03:16:52,818] [INFO] [controller] EPOCH 4 loss ppo:  -0.03205, loss val: 0.03988
[2022-12-07 03:16:52,828] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:16:53,021] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:16:53,022] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:16:57,919] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:17:02,647] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:17:07,576] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:17:12,317] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:17:16,715] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:17:21,300] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:17:25,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:17:30,161] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:17:34,831] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:17:39,600] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0593900992543004
[2022-12-07 03:17:39,601] [INFO] [runner_train_mujoco] Average state value: 0.672742947936058
[2022-12-07 03:17:39,601] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 03:17:39,651] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.03622
[2022-12-07 03:17:39,691] [INFO] [controller] EPOCH 2 loss ppo:  -0.01723, loss val: 0.03631
[2022-12-07 03:17:39,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.02350, loss val: 0.03793
[2022-12-07 03:17:39,770] [INFO] [controller] EPOCH 4 loss ppo:  -0.02931, loss val: 0.03786
[2022-12-07 03:17:39,779] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:17:39,931] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:17:39,932] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:17:44,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:17:49,610] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:17:54,157] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:17:58,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:18:03,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:18:08,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:18:13,408] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:18:18,296] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:18:23,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:18:28,232] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.071356619462362
[2022-12-07 03:18:28,232] [INFO] [runner_train_mujoco] Average state value: 0.660794297893842
[2022-12-07 03:18:28,232] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 03:18:28,282] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04362
[2022-12-07 03:18:28,318] [INFO] [controller] EPOCH 2 loss ppo:  -0.02211, loss val: 0.04259
[2022-12-07 03:18:28,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.03001, loss val: 0.04336
[2022-12-07 03:18:28,406] [INFO] [controller] EPOCH 4 loss ppo:  -0.03203, loss val: 0.04275
[2022-12-07 03:18:28,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:18:28,579] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:18:28,579] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:18:33,213] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:18:37,751] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:18:42,288] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:18:46,940] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:18:51,665] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:18:56,466] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:19:01,124] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:19:06,036] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:19:11,065] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:19:15,467] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0997842016157824
[2022-12-07 03:19:15,467] [INFO] [runner_train_mujoco] Average state value: 0.6566142639319101
[2022-12-07 03:19:15,467] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 03:19:15,519] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.03877
[2022-12-07 03:19:15,562] [INFO] [controller] EPOCH 2 loss ppo:  -0.01964, loss val: 0.03970
[2022-12-07 03:19:15,606] [INFO] [controller] EPOCH 3 loss ppo:  -0.02795, loss val: 0.03884
[2022-12-07 03:19:15,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.03448, loss val: 0.03880
[2022-12-07 03:19:15,655] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:19:15,810] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:19:15,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:19:20,656] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:19:25,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:19:30,235] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:19:35,236] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:19:39,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:19:44,522] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:19:49,586] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:19:54,678] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:19:59,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:20:04,310] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.136293881615225
[2022-12-07 03:20:04,310] [INFO] [runner_train_mujoco] Average state value: 0.6519185304641725
[2022-12-07 03:20:04,310] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 03:20:04,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01494, loss val: 0.03614
[2022-12-07 03:20:04,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.02187, loss val: 0.03626
[2022-12-07 03:20:04,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.02754, loss val: 0.03619
[2022-12-07 03:20:04,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.03214, loss val: 0.03598
[2022-12-07 03:20:04,501] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:20:04,671] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:20:04,672] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:20:09,476] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:20:14,196] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:20:19,139] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:20:23,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:20:28,117] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:20:32,632] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:20:36,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:20:41,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:20:46,203] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:20:50,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1853026232511454
[2022-12-07 03:20:50,914] [INFO] [runner_train_mujoco] Average state value: 0.6441500124931335
[2022-12-07 03:20:50,915] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 03:20:50,971] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04011
[2022-12-07 03:20:51,011] [INFO] [controller] EPOCH 2 loss ppo:  -0.02045, loss val: 0.03848
[2022-12-07 03:20:51,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.02813, loss val: 0.03911
[2022-12-07 03:20:51,120] [INFO] [controller] EPOCH 4 loss ppo:  -0.03002, loss val: 0.03809
[2022-12-07 03:20:51,129] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:20:51,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:20:51,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:20:56,114] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:21:01,155] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:21:06,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:21:10,955] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:21:15,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:21:20,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:21:24,805] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:21:29,347] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:21:33,648] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:21:38,263] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2146095115171605
[2022-12-07 03:21:38,263] [INFO] [runner_train_mujoco] Average state value: 0.6575654685298602
[2022-12-07 03:21:38,263] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 03:21:38,335] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.03730
[2022-12-07 03:21:38,376] [INFO] [controller] EPOCH 2 loss ppo:  -0.02425, loss val: 0.03744
[2022-12-07 03:21:38,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.02804, loss val: 0.03740
[2022-12-07 03:21:38,460] [INFO] [controller] EPOCH 4 loss ppo:  -0.02972, loss val: 0.03675
[2022-12-07 03:21:38,470] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:21:38,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:21:38,610] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:21:43,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:21:47,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:21:52,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:21:57,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:22:02,145] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:22:06,544] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:22:11,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:22:16,073] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:22:20,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:22:25,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1636571881369675
[2022-12-07 03:22:25,640] [INFO] [runner_train_mujoco] Average state value: 0.6783223399718603
[2022-12-07 03:22:25,641] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 03:22:25,703] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.04013
[2022-12-07 03:22:25,752] [INFO] [controller] EPOCH 2 loss ppo:  -0.01984, loss val: 0.03948
[2022-12-07 03:22:25,810] [INFO] [controller] EPOCH 3 loss ppo:  -0.02222, loss val: 0.03963
[2022-12-07 03:22:25,857] [INFO] [controller] EPOCH 4 loss ppo:  -0.02580, loss val: 0.03951
[2022-12-07 03:22:25,867] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:22:26,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:22:26,040] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:22:30,616] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:22:35,306] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:22:40,241] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:22:44,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:22:49,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:22:54,695] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:22:59,532] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:23:04,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:23:09,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:23:13,551] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.224921871539743
[2022-12-07 03:23:13,552] [INFO] [runner_train_mujoco] Average state value: 0.6849136497974395
[2022-12-07 03:23:13,552] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 03:23:13,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04455
[2022-12-07 03:23:13,668] [INFO] [controller] EPOCH 2 loss ppo:  -0.02168, loss val: 0.04452
[2022-12-07 03:23:13,712] [INFO] [controller] EPOCH 3 loss ppo:  -0.02860, loss val: 0.04447
[2022-12-07 03:23:13,757] [INFO] [controller] EPOCH 4 loss ppo:  -0.03485, loss val: 0.04594
[2022-12-07 03:23:13,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:23:13,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:23:13,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:23:18,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:23:23,118] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:23:27,996] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:23:32,522] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:23:37,092] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:23:42,155] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:23:47,415] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:23:51,763] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:23:56,374] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:24:01,170] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.259331982634963
[2022-12-07 03:24:01,170] [INFO] [runner_train_mujoco] Average state value: 0.6848378299077351
[2022-12-07 03:24:01,170] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 03:24:01,225] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04118
[2022-12-07 03:24:01,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.01808, loss val: 0.04042
[2022-12-07 03:24:01,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02577, loss val: 0.04091
[2022-12-07 03:24:01,366] [INFO] [controller] EPOCH 4 loss ppo:  -0.03072, loss val: 0.04084
[2022-12-07 03:24:01,376] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:24:01,547] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:24:01,548] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:24:06,306] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:24:11,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:24:16,039] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:24:20,530] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:24:25,068] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:24:29,676] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:24:33,911] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:24:38,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:24:43,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:24:47,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3876795980986687
[2022-12-07 03:24:47,817] [INFO] [runner_train_mujoco] Average state value: 0.681981238245964
[2022-12-07 03:24:47,817] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 03:24:47,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.04479
[2022-12-07 03:24:47,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.02023, loss val: 0.04476
[2022-12-07 03:24:47,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.02507, loss val: 0.04506
[2022-12-07 03:24:48,019] [INFO] [controller] EPOCH 4 loss ppo:  -0.03179, loss val: 0.04411
[2022-12-07 03:24:48,029] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:24:48,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:24:48,189] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:24:52,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:24:57,492] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:02,119] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:25:06,767] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:25:11,868] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:25:16,491] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:25:21,050] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:25:25,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:25:29,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:25:34,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4123114475574616
[2022-12-07 03:25:34,055] [INFO] [runner_train_mujoco] Average state value: 0.6795798591375352
[2022-12-07 03:25:34,056] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 03:25:34,115] [INFO] [controller] EPOCH 1 loss ppo:  -0.01535, loss val: 0.04339
[2022-12-07 03:25:34,159] [INFO] [controller] EPOCH 2 loss ppo:  -0.01931, loss val: 0.04223
[2022-12-07 03:25:34,204] [INFO] [controller] EPOCH 3 loss ppo:  -0.02164, loss val: 0.04242
[2022-12-07 03:25:34,248] [INFO] [controller] EPOCH 4 loss ppo:  -0.02772, loss val: 0.04279
[2022-12-07 03:25:34,258] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:25:34,405] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:25:34,406] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:25:39,149] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:25:44,208] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:48,969] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:25:53,261] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:25:57,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:26:02,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:26:06,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:26:11,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:26:15,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:26:20,353] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3996710518351567
[2022-12-07 03:26:20,353] [INFO] [runner_train_mujoco] Average state value: 0.6750114265680314
[2022-12-07 03:26:20,353] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 03:26:20,417] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.04067
[2022-12-07 03:26:20,468] [INFO] [controller] EPOCH 2 loss ppo:  -0.01819, loss val: 0.04084
[2022-12-07 03:26:20,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.02323, loss val: 0.04162
[2022-12-07 03:26:20,566] [INFO] [controller] EPOCH 4 loss ppo:  -0.02962, loss val: 0.04176
[2022-12-07 03:26:20,576] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:26:20,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:26:20,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:26:24,835] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:26:29,714] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:26:34,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:26:39,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:26:44,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:26:49,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:26:53,984] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:26:58,643] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:27:03,030] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:27:07,533] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4616881556371175
[2022-12-07 03:27:07,533] [INFO] [runner_train_mujoco] Average state value: 0.667611843029658
[2022-12-07 03:27:07,534] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 03:27:07,588] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04050
[2022-12-07 03:27:07,630] [INFO] [controller] EPOCH 2 loss ppo:  -0.01757, loss val: 0.04229
[2022-12-07 03:27:07,673] [INFO] [controller] EPOCH 3 loss ppo:  -0.02173, loss val: 0.04031
[2022-12-07 03:27:07,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.02585, loss val: 0.04261
[2022-12-07 03:27:07,728] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:27:07,896] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:27:07,896] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:27:12,593] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:27:17,361] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:27:21,951] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:27:26,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:27:31,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:27:35,968] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:27:40,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:27:45,327] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:27:49,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:27:54,463] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.555819096167152
[2022-12-07 03:27:54,463] [INFO] [runner_train_mujoco] Average state value: 0.6545595006942749
[2022-12-07 03:27:54,463] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 03:27:54,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.04153
[2022-12-07 03:27:54,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.01813, loss val: 0.04231
[2022-12-07 03:27:54,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.02095, loss val: 0.04308
[2022-12-07 03:27:54,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.02385, loss val: 0.04143
[2022-12-07 03:27:54,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:27:54,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:27:54,837] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:27:59,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:28:03,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:28:08,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:28:13,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:28:18,405] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:28:22,844] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:28:27,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:28:31,597] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:28:35,926] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:28:40,820] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.567099217289553
[2022-12-07 03:28:40,821] [INFO] [runner_train_mujoco] Average state value: 0.6535335000356038
[2022-12-07 03:28:40,821] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 03:28:40,872] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04280
[2022-12-07 03:28:40,916] [INFO] [controller] EPOCH 2 loss ppo:  -0.01957, loss val: 0.04282
[2022-12-07 03:28:40,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.02688, loss val: 0.04279
[2022-12-07 03:28:41,013] [INFO] [controller] EPOCH 4 loss ppo:  -0.02912, loss val: 0.04432
[2022-12-07 03:28:41,023] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:28:41,192] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:28:41,193] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:28:45,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:28:50,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:28:54,531] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:28:59,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:29:03,762] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:29:08,259] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:29:12,553] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:29:17,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:29:21,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:29:26,891] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6363831866242604
[2022-12-07 03:29:26,892] [INFO] [runner_train_mujoco] Average state value: 0.6558751475016276
[2022-12-07 03:29:26,892] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 03:29:26,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04051
[2022-12-07 03:29:27,005] [INFO] [controller] EPOCH 2 loss ppo:  -0.01525, loss val: 0.03896
[2022-12-07 03:29:27,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.01901, loss val: 0.03907
[2022-12-07 03:29:27,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.02379, loss val: 0.04063
[2022-12-07 03:29:27,116] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:29:27,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:29:27,312] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:29:31,602] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:29:36,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:29:42,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:29:47,043] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:29:51,711] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:29:56,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:30:00,666] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:30:04,846] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:30:09,207] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:30:13,216] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.666529965965291
[2022-12-07 03:30:13,216] [INFO] [runner_train_mujoco] Average state value: 0.6494897884527842
[2022-12-07 03:30:13,216] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 03:30:13,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.04174
[2022-12-07 03:30:13,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.01875, loss val: 0.04149
[2022-12-07 03:30:13,388] [INFO] [controller] EPOCH 3 loss ppo:  -0.02372, loss val: 0.04021
[2022-12-07 03:30:13,436] [INFO] [controller] EPOCH 4 loss ppo:  -0.02803, loss val: 0.04073
[2022-12-07 03:30:13,445] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:30:13,601] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:30:13,601] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:30:17,817] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:30:21,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:30:26,665] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:30:31,199] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:30:35,575] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:30:40,502] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:30:45,181] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:30:49,894] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:30:54,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:30:58,988] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7252663515154603
[2022-12-07 03:30:58,988] [INFO] [runner_train_mujoco] Average state value: 0.6426188338994979
[2022-12-07 03:30:58,988] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 03:30:59,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04294
[2022-12-07 03:30:59,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.01699, loss val: 0.04310
[2022-12-07 03:30:59,128] [INFO] [controller] EPOCH 3 loss ppo:  -0.02126, loss val: 0.04297
[2022-12-07 03:30:59,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.02444, loss val: 0.04326
[2022-12-07 03:30:59,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:30:59,335] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:30:59,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:31:03,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:31:08,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:31:13,050] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:31:17,562] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:31:22,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:31:26,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:31:30,543] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:31:35,321] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:31:39,714] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:31:43,959] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.733960614176463
[2022-12-07 03:31:43,959] [INFO] [runner_train_mujoco] Average state value: 0.642395080367724
[2022-12-07 03:31:43,959] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 03:31:44,008] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04368
[2022-12-07 03:31:44,050] [INFO] [controller] EPOCH 2 loss ppo:  -0.01697, loss val: 0.04311
[2022-12-07 03:31:44,094] [INFO] [controller] EPOCH 3 loss ppo:  -0.02014, loss val: 0.04310
[2022-12-07 03:31:44,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.02234, loss val: 0.04311
[2022-12-07 03:31:44,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:31:44,295] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:31:44,295] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:31:48,870] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:31:53,549] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:31:57,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:32:02,436] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:32:06,784] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:32:11,542] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:32:15,792] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:32:20,618] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:32:24,967] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:32:29,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7908866659073466
[2022-12-07 03:32:29,535] [INFO] [runner_train_mujoco] Average state value: 0.6440299477974574
[2022-12-07 03:32:29,535] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 03:32:29,588] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.04093
[2022-12-07 03:32:29,630] [INFO] [controller] EPOCH 2 loss ppo:  -0.01595, loss val: 0.04078
[2022-12-07 03:32:29,676] [INFO] [controller] EPOCH 3 loss ppo:  -0.01840, loss val: 0.04073
[2022-12-07 03:32:29,720] [INFO] [controller] EPOCH 4 loss ppo:  -0.02070, loss val: 0.04073
[2022-12-07 03:32:29,729] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:32:29,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:32:29,909] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:32:34,540] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:32:39,325] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:32:44,070] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:32:48,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:32:52,398] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:32:56,666] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:33:01,046] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:33:05,386] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:33:09,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:33:14,428] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.68591136930192
[2022-12-07 03:33:14,428] [INFO] [runner_train_mujoco] Average state value: 0.6433212489684423
[2022-12-07 03:33:14,428] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 03:33:14,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.04400
[2022-12-07 03:33:14,529] [INFO] [controller] EPOCH 2 loss ppo:  -0.01596, loss val: 0.04368
[2022-12-07 03:33:14,568] [INFO] [controller] EPOCH 3 loss ppo:  -0.01826, loss val: 0.04364
[2022-12-07 03:33:14,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.02038, loss val: 0.04407
[2022-12-07 03:33:14,622] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:33:14,754] [INFO] [optimize] Finished learning.
