[2022-12-07 06:47:00,882] [INFO] [optimize] Starting learning
[2022-12-07 06:47:00,893] [INFO] [optimize] Starting learning process..
[2022-12-07 06:47:00,953] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:47:00,953] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:47:07,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:47:13,740] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:47:19,446] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:47:25,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:47:31,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:47:37,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:47:43,877] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:47:49,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:47:55,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:48:01,183] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.13739055554115756
[2022-12-07 06:48:01,184] [INFO] [runner_train_mujoco] Average state value: -0.08698223728438219
[2022-12-07 06:48:01,184] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 06:48:01,278] [INFO] [controller] EPOCH 1 loss ppo:  -0.01613, loss val: 0.49961
[2022-12-07 06:48:01,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.03251, loss val: 0.44232
[2022-12-07 06:48:01,376] [INFO] [controller] EPOCH 3 loss ppo:  -0.03926, loss val: 0.38516
[2022-12-07 06:48:01,421] [INFO] [controller] EPOCH 4 loss ppo:  -0.03853, loss val: 0.32864
[2022-12-07 06:48:01,432] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:48:01,609] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:48:01,610] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:48:07,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:48:12,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:48:18,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:48:23,978] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:48:29,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:48:35,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:48:41,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:48:47,304] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:48:53,059] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:48:59,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18194962986371122
[2022-12-07 06:48:59,098] [INFO] [runner_train_mujoco] Average state value: 0.13054994273806614
[2022-12-07 06:48:59,098] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 06:48:59,155] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.25693
[2022-12-07 06:48:59,212] [INFO] [controller] EPOCH 2 loss ppo:  -0.02615, loss val: 0.20672
[2022-12-07 06:48:59,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.03209, loss val: 0.17819
[2022-12-07 06:48:59,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.04025, loss val: 0.14114
[2022-12-07 06:48:59,331] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:48:59,497] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:48:59,498] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:49:05,677] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:49:11,383] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:49:17,114] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:49:23,120] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:49:28,686] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:49:34,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:49:40,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:49:46,322] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:49:53,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:49:59,302] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16040498687372856
[2022-12-07 06:49:59,303] [INFO] [runner_train_mujoco] Average state value: 0.2870978127854566
[2022-12-07 06:49:59,303] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 06:49:59,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01260, loss val: 0.13687
[2022-12-07 06:49:59,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.02408, loss val: 0.10923
[2022-12-07 06:49:59,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.03053, loss val: 0.08698
[2022-12-07 06:49:59,544] [INFO] [controller] EPOCH 4 loss ppo:  -0.03425, loss val: 0.06921
[2022-12-07 06:49:59,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:49:59,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:49:59,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:50:05,284] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:50:11,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:50:16,610] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:50:22,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:50:27,481] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:50:33,481] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:50:39,159] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:50:44,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:50:50,360] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:50:56,039] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16770432250972378
[2022-12-07 06:50:56,039] [INFO] [runner_train_mujoco] Average state value: 0.4874576764255762
[2022-12-07 06:50:56,039] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 06:50:56,102] [INFO] [controller] EPOCH 1 loss ppo:  -0.01011, loss val: 0.10281
[2022-12-07 06:50:56,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.02452, loss val: 0.08418
[2022-12-07 06:50:56,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.02865, loss val: 0.06652
[2022-12-07 06:50:56,241] [INFO] [controller] EPOCH 4 loss ppo:  -0.03120, loss val: 0.05644
[2022-12-07 06:50:56,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:50:56,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:50:56,419] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:51:01,858] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:51:07,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:51:13,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:51:18,618] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:51:23,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:51:29,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:51:35,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:51:41,414] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:51:47,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:51:52,717] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.203774963754847
[2022-12-07 06:51:52,717] [INFO] [runner_train_mujoco] Average state value: 0.6611954967578252
[2022-12-07 06:51:52,717] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 06:51:52,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.00866, loss val: 0.05852
[2022-12-07 06:51:52,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.02211, loss val: 0.05168
[2022-12-07 06:51:52,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.02750, loss val: 0.04837
[2022-12-07 06:51:53,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.02991, loss val: 0.04737
[2022-12-07 06:51:53,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:51:53,229] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:51:53,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:51:59,789] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:52:06,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:52:12,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:52:19,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:52:24,975] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:52:30,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:52:36,424] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:52:41,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:52:47,568] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:52:53,605] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15116295478939343
[2022-12-07 06:52:53,605] [INFO] [runner_train_mujoco] Average state value: 0.7943815281192462
[2022-12-07 06:52:53,605] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 06:52:53,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.00656, loss val: 0.04880
[2022-12-07 06:52:53,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.02023, loss val: 0.04894
[2022-12-07 06:52:53,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.02164, loss val: 0.04771
[2022-12-07 06:52:53,812] [INFO] [controller] EPOCH 4 loss ppo:  -0.02426, loss val: 0.04661
[2022-12-07 06:52:53,822] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:52:53,987] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:52:53,987] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:52:59,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:53:05,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:53:12,037] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:53:17,851] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:53:23,758] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:53:28,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:53:34,271] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:53:39,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:53:45,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:53:51,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.25746028550363526
[2022-12-07 06:53:51,402] [INFO] [runner_train_mujoco] Average state value: 0.7963858631451924
[2022-12-07 06:53:51,402] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 06:53:51,464] [INFO] [controller] EPOCH 1 loss ppo:  -0.00733, loss val: 0.04412
[2022-12-07 06:53:51,531] [INFO] [controller] EPOCH 2 loss ppo:  -0.01996, loss val: 0.04229
[2022-12-07 06:53:51,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.02745, loss val: 0.04184
[2022-12-07 06:53:51,648] [INFO] [controller] EPOCH 4 loss ppo:  -0.02931, loss val: 0.04137
[2022-12-07 06:53:51,664] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:53:51,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:53:51,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:53:57,419] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:54:03,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:54:09,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:54:15,115] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:54:20,594] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:54:26,338] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:54:31,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:54:37,383] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:54:43,175] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:54:49,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16756980556831363
[2022-12-07 06:54:49,109] [INFO] [runner_train_mujoco] Average state value: 0.7360497912963231
[2022-12-07 06:54:49,110] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 06:54:49,177] [INFO] [controller] EPOCH 1 loss ppo:  -0.00804, loss val: 0.04097
[2022-12-07 06:54:49,241] [INFO] [controller] EPOCH 2 loss ppo:  -0.01768, loss val: 0.03918
[2022-12-07 06:54:49,289] [INFO] [controller] EPOCH 3 loss ppo:  -0.01859, loss val: 0.04066
[2022-12-07 06:54:49,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.02228, loss val: 0.03906
[2022-12-07 06:54:49,349] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:54:49,534] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:54:49,535] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:54:55,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:55:01,198] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:55:06,776] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:55:12,879] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:55:18,355] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:55:24,362] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:55:30,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:55:36,158] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:55:42,064] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:55:47,745] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21416865265600044
[2022-12-07 06:55:47,746] [INFO] [runner_train_mujoco] Average state value: 0.7047900585134824
[2022-12-07 06:55:47,746] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 06:55:47,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.00859, loss val: 0.04712
[2022-12-07 06:55:47,931] [INFO] [controller] EPOCH 2 loss ppo:  -0.01929, loss val: 0.04573
[2022-12-07 06:55:47,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.02798, loss val: 0.04532
[2022-12-07 06:55:48,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.02909, loss val: 0.04604
[2022-12-07 06:55:48,050] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:55:48,221] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:55:48,222] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:55:53,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:55:59,396] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:56:04,922] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:56:10,714] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:56:17,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:56:22,971] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:56:28,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:56:34,436] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:56:40,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:56:47,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2533739396765564
[2022-12-07 06:56:47,014] [INFO] [runner_train_mujoco] Average state value: 0.7320244429707526
[2022-12-07 06:56:47,014] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 06:56:47,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.00881, loss val: 0.04110
[2022-12-07 06:56:47,651] [INFO] [controller] EPOCH 2 loss ppo:  -0.02457, loss val: 0.04020
[2022-12-07 06:56:47,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.02740, loss val: 0.04075
[2022-12-07 06:56:47,818] [INFO] [controller] EPOCH 4 loss ppo:  -0.03251, loss val: 0.04103
[2022-12-07 06:56:47,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:56:48,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:56:48,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:56:54,597] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:57:00,520] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:57:06,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:57:11,638] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:57:17,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:57:23,042] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:57:29,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:57:35,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:57:40,854] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:57:46,366] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2325179508090863
[2022-12-07 06:57:46,366] [INFO] [runner_train_mujoco] Average state value: 0.7547049544254938
[2022-12-07 06:57:46,367] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 06:57:46,424] [INFO] [controller] EPOCH 1 loss ppo:  -0.00827, loss val: 0.04028
[2022-12-07 06:57:46,475] [INFO] [controller] EPOCH 2 loss ppo:  -0.01674, loss val: 0.04027
[2022-12-07 06:57:46,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.02018, loss val: 0.03932
[2022-12-07 06:57:46,568] [INFO] [controller] EPOCH 4 loss ppo:  -0.02347, loss val: 0.03876
[2022-12-07 06:57:46,578] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:57:46,743] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:57:46,743] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:57:52,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:57:57,996] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:58:03,993] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:58:09,567] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:58:15,134] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:58:20,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:58:26,696] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:58:32,137] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:58:37,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:58:43,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19424425714156357
[2022-12-07 06:58:43,426] [INFO] [runner_train_mujoco] Average state value: 0.7163063408732413
[2022-12-07 06:58:43,426] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 06:58:43,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.00795, loss val: 0.04783
[2022-12-07 06:58:43,568] [INFO] [controller] EPOCH 2 loss ppo:  -0.02231, loss val: 0.04799
[2022-12-07 06:58:43,616] [INFO] [controller] EPOCH 3 loss ppo:  -0.02814, loss val: 0.04781
[2022-12-07 06:58:43,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.03152, loss val: 0.04734
[2022-12-07 06:58:43,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:58:43,846] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:58:43,846] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:58:49,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:58:54,544] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:58:59,989] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:59:05,424] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:59:11,010] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:59:16,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:59:22,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:59:28,419] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:59:34,126] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:59:39,568] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2190139181558969
[2022-12-07 06:59:39,569] [INFO] [runner_train_mujoco] Average state value: 0.7270287436644237
[2022-12-07 06:59:39,569] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 06:59:39,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.00578, loss val: 0.04357
[2022-12-07 06:59:39,669] [INFO] [controller] EPOCH 2 loss ppo:  -0.01502, loss val: 0.04289
[2022-12-07 06:59:39,721] [INFO] [controller] EPOCH 3 loss ppo:  -0.02036, loss val: 0.04331
[2022-12-07 06:59:39,777] [INFO] [controller] EPOCH 4 loss ppo:  -0.02635, loss val: 0.04262
[2022-12-07 06:59:39,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:59:39,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:59:39,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:59:45,293] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:59:51,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:59:57,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:00:02,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:00:08,233] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:00:14,024] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:00:19,441] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:00:24,834] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:00:30,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:00:36,125] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2563484026376552
[2022-12-07 07:00:36,125] [INFO] [runner_train_mujoco] Average state value: 0.7544454044103621
[2022-12-07 07:00:36,125] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 07:00:36,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.00853, loss val: 0.04217
[2022-12-07 07:00:36,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.02051, loss val: 0.04324
[2022-12-07 07:00:36,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.02226, loss val: 0.04200
[2022-12-07 07:00:36,495] [INFO] [controller] EPOCH 4 loss ppo:  -0.02674, loss val: 0.04287
[2022-12-07 07:00:36,505] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:00:36,695] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:00:36,696] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:00:42,131] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:00:47,846] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:00:53,699] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:00:59,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:01:05,395] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:01:10,988] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:01:16,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:01:22,277] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:01:27,894] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:01:33,369] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.29588738948555504
[2022-12-07 07:01:33,369] [INFO] [runner_train_mujoco] Average state value: 0.7417221032381057
[2022-12-07 07:01:33,369] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 07:01:33,421] [INFO] [controller] EPOCH 1 loss ppo:  -0.00754, loss val: 0.04047
[2022-12-07 07:01:33,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.01734, loss val: 0.04017
[2022-12-07 07:01:33,519] [INFO] [controller] EPOCH 3 loss ppo:  -0.02560, loss val: 0.04222
[2022-12-07 07:01:33,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.02918, loss val: 0.04032
[2022-12-07 07:01:33,578] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:01:33,749] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:01:33,749] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:01:39,742] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:01:45,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:01:50,752] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:01:56,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:02:02,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:02:07,940] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:02:13,309] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:02:18,826] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:02:24,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:02:30,012] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.26504840581005557
[2022-12-07 07:02:30,013] [INFO] [runner_train_mujoco] Average state value: 0.7325040648778278
[2022-12-07 07:02:30,013] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 07:02:30,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.00873, loss val: 0.04118
[2022-12-07 07:02:30,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.02043, loss val: 0.04104
[2022-12-07 07:02:30,185] [INFO] [controller] EPOCH 3 loss ppo:  -0.02504, loss val: 0.03998
[2022-12-07 07:02:30,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.02835, loss val: 0.03956
[2022-12-07 07:02:30,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:02:30,493] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:02:30,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:02:36,301] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:02:42,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:02:47,746] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:02:53,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:02:59,503] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:03:05,212] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:03:10,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:03:16,753] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:03:22,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:03:28,081] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22676712074838537
[2022-12-07 07:03:28,082] [INFO] [runner_train_mujoco] Average state value: 0.7613022517760595
[2022-12-07 07:03:28,082] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 07:03:28,141] [INFO] [controller] EPOCH 1 loss ppo:  -0.00721, loss val: 0.04260
[2022-12-07 07:03:28,190] [INFO] [controller] EPOCH 2 loss ppo:  -0.01392, loss val: 0.04434
[2022-12-07 07:03:28,242] [INFO] [controller] EPOCH 3 loss ppo:  -0.02133, loss val: 0.04328
[2022-12-07 07:03:28,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.02675, loss val: 0.04250
[2022-12-07 07:03:28,347] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:03:28,518] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:03:28,518] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:03:33,900] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:03:39,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:03:45,640] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:03:51,167] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:03:56,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:04:02,286] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:04:07,898] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:04:13,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:04:19,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:04:25,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.27213919814758386
[2022-12-07 07:04:25,257] [INFO] [runner_train_mujoco] Average state value: 0.7742727881272633
[2022-12-07 07:04:25,257] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 07:04:25,315] [INFO] [controller] EPOCH 1 loss ppo:  -0.00613, loss val: 0.04427
[2022-12-07 07:04:25,372] [INFO] [controller] EPOCH 2 loss ppo:  -0.01760, loss val: 0.04372
[2022-12-07 07:04:25,416] [INFO] [controller] EPOCH 3 loss ppo:  -0.01862, loss val: 0.04317
[2022-12-07 07:04:25,468] [INFO] [controller] EPOCH 4 loss ppo:  -0.02127, loss val: 0.04299
[2022-12-07 07:04:25,478] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:04:25,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:04:25,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:04:31,534] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:04:37,295] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:04:42,815] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:04:48,308] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:04:53,966] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:04:59,643] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:05:05,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:05:10,841] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:05:16,700] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:05:22,355] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23435378201131093
[2022-12-07 07:05:22,355] [INFO] [runner_train_mujoco] Average state value: 0.7397141908009847
[2022-12-07 07:05:22,355] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 07:05:22,418] [INFO] [controller] EPOCH 1 loss ppo:  -0.00817, loss val: 0.04428
[2022-12-07 07:05:22,481] [INFO] [controller] EPOCH 2 loss ppo:  -0.01698, loss val: 0.04340
[2022-12-07 07:05:22,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.02522, loss val: 0.04339
[2022-12-07 07:05:22,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.02813, loss val: 0.04347
[2022-12-07 07:05:22,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:05:22,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:05:22,788] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:05:28,650] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:05:34,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:05:40,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:05:46,120] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:05:51,990] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:05:57,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:06:02,961] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:06:08,844] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:06:14,350] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:06:20,211] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3174636328967737
[2022-12-07 07:06:20,211] [INFO] [runner_train_mujoco] Average state value: 0.7372975438435873
[2022-12-07 07:06:20,211] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 07:06:20,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.00816, loss val: 0.04379
[2022-12-07 07:06:20,335] [INFO] [controller] EPOCH 2 loss ppo:  -0.01551, loss val: 0.04332
[2022-12-07 07:06:20,382] [INFO] [controller] EPOCH 3 loss ppo:  -0.02000, loss val: 0.04288
[2022-12-07 07:06:20,429] [INFO] [controller] EPOCH 4 loss ppo:  -0.02705, loss val: 0.04243
[2022-12-07 07:06:20,438] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:06:20,611] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:06:20,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:06:25,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:06:31,848] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:06:37,743] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:06:43,608] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:06:49,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:06:54,526] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:07:00,261] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:07:07,220] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:07:13,525] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:07:20,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3363882684948836
[2022-12-07 07:07:20,111] [INFO] [runner_train_mujoco] Average state value: 0.7826609081427256
[2022-12-07 07:07:20,112] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 07:07:20,177] [INFO] [controller] EPOCH 1 loss ppo:  -0.00742, loss val: 0.04441
[2022-12-07 07:07:20,245] [INFO] [controller] EPOCH 2 loss ppo:  -0.01257, loss val: 0.04439
[2022-12-07 07:07:20,319] [INFO] [controller] EPOCH 3 loss ppo:  -0.01861, loss val: 0.04338
[2022-12-07 07:07:20,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.02761, loss val: 0.04281
[2022-12-07 07:07:20,396] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:07:20,571] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:07:20,572] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:07:26,760] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:07:32,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:07:38,712] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:07:44,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:07:50,271] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:07:55,739] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:08:01,288] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:08:06,743] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:08:11,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:08:17,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.28909990131690533
[2022-12-07 07:08:17,480] [INFO] [runner_train_mujoco] Average state value: 0.7518894631465276
[2022-12-07 07:08:17,480] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 07:08:17,543] [INFO] [controller] EPOCH 1 loss ppo:  -0.00627, loss val: 0.04255
[2022-12-07 07:08:17,590] [INFO] [controller] EPOCH 2 loss ppo:  -0.01405, loss val: 0.04327
[2022-12-07 07:08:17,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.02225, loss val: 0.04294
[2022-12-07 07:08:17,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.02539, loss val: 0.04290
[2022-12-07 07:08:17,706] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:08:17,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:08:17,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:08:23,445] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:08:29,405] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:08:35,251] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:08:40,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:08:47,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:08:53,398] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:08:58,538] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:09:03,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:09:08,732] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:09:13,698] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.31956051726726786
[2022-12-07 07:09:13,698] [INFO] [runner_train_mujoco] Average state value: 0.7285070585807165
[2022-12-07 07:09:13,698] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 07:09:13,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.00950, loss val: 0.04299
[2022-12-07 07:09:13,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.01441, loss val: 0.04238
[2022-12-07 07:09:13,945] [INFO] [controller] EPOCH 3 loss ppo:  -0.01825, loss val: 0.04193
[2022-12-07 07:09:13,995] [INFO] [controller] EPOCH 4 loss ppo:  -0.02452, loss val: 0.04187
[2022-12-07 07:09:14,005] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:09:14,173] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:09:14,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:09:18,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:09:24,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:09:29,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:09:34,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:09:39,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:09:44,455] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:09:49,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:09:55,060] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:10:00,364] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:10:05,213] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.31023266278191886
[2022-12-07 07:10:05,213] [INFO] [runner_train_mujoco] Average state value: 0.754690585454305
[2022-12-07 07:10:05,214] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 07:10:05,272] [INFO] [controller] EPOCH 1 loss ppo:  -0.00803, loss val: 0.04235
[2022-12-07 07:10:05,312] [INFO] [controller] EPOCH 2 loss ppo:  -0.01371, loss val: 0.04260
[2022-12-07 07:10:05,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.02289, loss val: 0.04334
[2022-12-07 07:10:05,463] [INFO] [controller] EPOCH 4 loss ppo:  -0.02710, loss val: 0.04326
[2022-12-07 07:10:05,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:10:05,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:10:05,622] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:10:11,259] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:10:16,672] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:10:21,766] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:10:27,245] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:10:32,574] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:10:37,776] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:10:42,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:10:48,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:10:52,650] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:10:57,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4139491764941208
[2022-12-07 07:10:57,564] [INFO] [runner_train_mujoco] Average state value: 0.760964313308398
[2022-12-07 07:10:57,564] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 07:10:57,620] [INFO] [controller] EPOCH 1 loss ppo:  -0.00674, loss val: 0.04053
[2022-12-07 07:10:57,667] [INFO] [controller] EPOCH 2 loss ppo:  -0.01480, loss val: 0.04021
[2022-12-07 07:10:57,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.02096, loss val: 0.04004
[2022-12-07 07:10:57,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.02615, loss val: 0.03937
[2022-12-07 07:10:57,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:10:57,949] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:10:57,949] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:11:03,080] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:11:08,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:11:13,572] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:11:18,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:11:23,557] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:11:28,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:11:33,994] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:11:39,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:11:44,373] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:11:49,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42359746528200504
[2022-12-07 07:11:49,739] [INFO] [runner_train_mujoco] Average state value: 0.7230105468829473
[2022-12-07 07:11:49,739] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 07:11:49,792] [INFO] [controller] EPOCH 1 loss ppo:  -0.00847, loss val: 0.04037
[2022-12-07 07:11:49,835] [INFO] [controller] EPOCH 2 loss ppo:  -0.01839, loss val: 0.04003
[2022-12-07 07:11:49,879] [INFO] [controller] EPOCH 3 loss ppo:  -0.02453, loss val: 0.04212
[2022-12-07 07:11:49,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.03077, loss val: 0.03977
[2022-12-07 07:11:49,933] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:11:50,097] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:11:50,097] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:11:55,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:12:00,394] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:12:05,730] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:12:10,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:12:15,828] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:12:20,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:12:25,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:12:30,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:12:35,612] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:12:40,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.34588967209354726
[2022-12-07 07:12:40,817] [INFO] [runner_train_mujoco] Average state value: 0.7142614145676295
[2022-12-07 07:12:40,817] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 07:12:40,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.00831, loss val: 0.03982
[2022-12-07 07:12:40,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.01559, loss val: 0.04050
[2022-12-07 07:12:40,972] [INFO] [controller] EPOCH 3 loss ppo:  -0.02205, loss val: 0.03902
[2022-12-07 07:12:41,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.02936, loss val: 0.04035
[2022-12-07 07:12:41,026] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:12:41,192] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:12:41,193] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:12:46,992] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:12:52,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:12:57,357] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:13:02,230] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:13:07,156] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:13:12,161] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:13:17,277] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:13:22,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:13:27,804] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:13:32,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37171130930060103
[2022-12-07 07:13:32,886] [INFO] [runner_train_mujoco] Average state value: 0.7365528325239817
[2022-12-07 07:13:32,887] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 07:13:32,938] [INFO] [controller] EPOCH 1 loss ppo:  -0.00949, loss val: 0.04175
[2022-12-07 07:13:32,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.01650, loss val: 0.04176
[2022-12-07 07:13:33,040] [INFO] [controller] EPOCH 3 loss ppo:  -0.02191, loss val: 0.04162
[2022-12-07 07:13:33,088] [INFO] [controller] EPOCH 4 loss ppo:  -0.02667, loss val: 0.04164
[2022-12-07 07:13:33,098] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:13:33,285] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:13:33,285] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:13:38,485] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:13:43,378] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:13:48,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:13:53,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:13:59,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:14:04,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:14:09,569] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:14:14,423] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:14:19,563] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:14:24,568] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.32432883009167535
[2022-12-07 07:14:24,568] [INFO] [runner_train_mujoco] Average state value: 0.7233078939119975
[2022-12-07 07:14:24,568] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 07:14:24,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.00887, loss val: 0.03993
[2022-12-07 07:14:24,670] [INFO] [controller] EPOCH 2 loss ppo:  -0.01889, loss val: 0.03807
[2022-12-07 07:14:24,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.02190, loss val: 0.03827
[2022-12-07 07:14:24,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.02530, loss val: 0.03799
[2022-12-07 07:14:24,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:14:24,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:14:24,960] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:14:30,144] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:14:35,489] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:14:40,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:14:45,397] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:14:50,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:14:55,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:15:00,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:15:05,714] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:15:10,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:15:15,310] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.475837780026027
[2022-12-07 07:15:15,310] [INFO] [runner_train_mujoco] Average state value: 0.723910832087199
[2022-12-07 07:15:15,310] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 07:15:15,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.00923, loss val: 0.03890
[2022-12-07 07:15:15,402] [INFO] [controller] EPOCH 2 loss ppo:  -0.01907, loss val: 0.03877
[2022-12-07 07:15:15,443] [INFO] [controller] EPOCH 3 loss ppo:  -0.02824, loss val: 0.03869
[2022-12-07 07:15:15,554] [INFO] [controller] EPOCH 4 loss ppo:  -0.03126, loss val: 0.03885
[2022-12-07 07:15:15,563] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:15:15,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:15:15,720] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:15:20,730] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:15:26,085] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:15:31,470] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:15:36,966] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:15:42,200] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:15:47,550] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:15:52,753] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:15:58,069] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:16:02,982] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:16:07,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5050102041027673
[2022-12-07 07:16:07,701] [INFO] [runner_train_mujoco] Average state value: 0.7003133702675501
[2022-12-07 07:16:07,701] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 07:16:07,759] [INFO] [controller] EPOCH 1 loss ppo:  -0.01045, loss val: 0.03730
[2022-12-07 07:16:07,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.01857, loss val: 0.03703
[2022-12-07 07:16:07,851] [INFO] [controller] EPOCH 3 loss ppo:  -0.02220, loss val: 0.03664
[2022-12-07 07:16:07,899] [INFO] [controller] EPOCH 4 loss ppo:  -0.02588, loss val: 0.03666
[2022-12-07 07:16:07,908] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:16:08,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:16:08,060] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:16:13,122] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:16:18,312] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:16:23,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:16:28,454] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:16:33,718] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:16:38,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:16:43,614] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:16:49,020] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:16:53,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:16:58,966] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6341952519943316
[2022-12-07 07:16:58,966] [INFO] [runner_train_mujoco] Average state value: 0.6661901427110035
[2022-12-07 07:16:58,967] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 07:16:59,020] [INFO] [controller] EPOCH 1 loss ppo:  -0.01034, loss val: 0.05062
[2022-12-07 07:16:59,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.01703, loss val: 0.04895
[2022-12-07 07:16:59,113] [INFO] [controller] EPOCH 3 loss ppo:  -0.02427, loss val: 0.04612
[2022-12-07 07:16:59,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.02826, loss val: 0.04458
[2022-12-07 07:16:59,174] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:16:59,333] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:16:59,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:17:04,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:17:09,531] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:17:14,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:17:19,529] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:17:24,484] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:17:29,063] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:17:34,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:17:38,898] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:17:44,019] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:17:49,069] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7198444106899254
[2022-12-07 07:17:49,069] [INFO] [runner_train_mujoco] Average state value: 0.7132156272331873
[2022-12-07 07:17:49,070] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 07:17:49,134] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.03856
[2022-12-07 07:17:49,188] [INFO] [controller] EPOCH 2 loss ppo:  -0.02310, loss val: 0.03800
[2022-12-07 07:17:49,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.02802, loss val: 0.03876
[2022-12-07 07:17:49,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.03066, loss val: 0.03922
[2022-12-07 07:17:49,322] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:17:49,489] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:17:49,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:17:54,707] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:18:00,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:18:06,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:18:11,186] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:18:16,202] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:18:21,358] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:18:26,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:18:31,504] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:18:36,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:18:41,239] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0289532149613454
[2022-12-07 07:18:41,239] [INFO] [runner_train_mujoco] Average state value: 0.7281291245222092
[2022-12-07 07:18:41,239] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 07:18:41,288] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.03951
[2022-12-07 07:18:41,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.02552, loss val: 0.03914
[2022-12-07 07:18:41,374] [INFO] [controller] EPOCH 3 loss ppo:  -0.02963, loss val: 0.03751
[2022-12-07 07:18:41,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.03209, loss val: 0.03695
[2022-12-07 07:18:41,424] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:18:41,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:18:41,587] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:18:46,245] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:18:51,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:18:55,782] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:19:00,494] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:19:05,434] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:19:10,468] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:19:15,663] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:19:20,981] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:19:25,744] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:19:30,607] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0712656094377353
[2022-12-07 07:19:30,608] [INFO] [runner_train_mujoco] Average state value: 0.6798942175507546
[2022-12-07 07:19:30,608] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 07:19:30,659] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.03726
[2022-12-07 07:19:30,700] [INFO] [controller] EPOCH 2 loss ppo:  -0.02127, loss val: 0.03579
[2022-12-07 07:19:30,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.02780, loss val: 0.03569
[2022-12-07 07:19:30,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.03302, loss val: 0.03691
[2022-12-07 07:19:30,790] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:19:30,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:19:30,950] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:19:35,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:19:40,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:19:45,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:19:50,781] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:19:55,685] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:20:00,204] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:20:05,246] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:20:09,786] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:20:14,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:20:19,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.331571695630318
[2022-12-07 07:20:19,331] [INFO] [runner_train_mujoco] Average state value: 0.6240417675773302
[2022-12-07 07:20:19,331] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 07:20:19,386] [INFO] [controller] EPOCH 1 loss ppo:  -0.01688, loss val: 0.03783
[2022-12-07 07:20:19,428] [INFO] [controller] EPOCH 2 loss ppo:  -0.02888, loss val: 0.03810
[2022-12-07 07:20:19,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.02948, loss val: 0.03823
[2022-12-07 07:20:19,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.03020, loss val: 0.03938
[2022-12-07 07:20:19,521] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:20:19,681] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:20:19,682] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:20:24,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:20:29,341] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:20:34,138] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:20:38,786] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:20:43,684] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:20:48,710] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:20:53,262] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:20:58,026] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:21:02,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:21:07,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.430586574528932
[2022-12-07 07:21:07,817] [INFO] [runner_train_mujoco] Average state value: 0.6217591320673624
[2022-12-07 07:21:07,817] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 07:21:07,876] [INFO] [controller] EPOCH 1 loss ppo:  -0.01567, loss val: 0.04166
[2022-12-07 07:21:07,933] [INFO] [controller] EPOCH 2 loss ppo:  -0.02541, loss val: 0.04128
[2022-12-07 07:21:07,979] [INFO] [controller] EPOCH 3 loss ppo:  -0.03082, loss val: 0.04168
[2022-12-07 07:21:08,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.03314, loss val: 0.04223
[2022-12-07 07:21:08,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:21:08,200] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:21:08,200] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:21:12,980] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:21:17,312] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:21:22,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:21:27,433] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:21:32,522] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:21:37,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:21:42,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:21:46,825] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:21:51,434] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:21:55,581] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5508897591945987
[2022-12-07 07:21:55,581] [INFO] [runner_train_mujoco] Average state value: 0.6450218529701234
[2022-12-07 07:21:55,581] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 07:21:55,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.03730
[2022-12-07 07:21:55,670] [INFO] [controller] EPOCH 2 loss ppo:  -0.02489, loss val: 0.03527
[2022-12-07 07:21:55,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.02895, loss val: 0.03469
[2022-12-07 07:21:55,750] [INFO] [controller] EPOCH 4 loss ppo:  -0.03676, loss val: 0.03597
[2022-12-07 07:21:55,759] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:21:55,918] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:21:55,918] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:22:00,607] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:22:05,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:22:10,338] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:22:15,083] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:22:20,347] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:22:25,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:22:29,979] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:22:34,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:22:39,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:22:44,345] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8136854666532287
[2022-12-07 07:22:44,345] [INFO] [runner_train_mujoco] Average state value: 0.6629467765092849
[2022-12-07 07:22:44,345] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 07:22:44,394] [INFO] [controller] EPOCH 1 loss ppo:  -0.01684, loss val: 0.04091
[2022-12-07 07:22:44,431] [INFO] [controller] EPOCH 2 loss ppo:  -0.02139, loss val: 0.04054
[2022-12-07 07:22:44,478] [INFO] [controller] EPOCH 3 loss ppo:  -0.02910, loss val: 0.04109
[2022-12-07 07:22:44,519] [INFO] [controller] EPOCH 4 loss ppo:  -0.03351, loss val: 0.04097
[2022-12-07 07:22:44,526] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:22:44,688] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:22:44,689] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:22:49,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:22:54,078] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:22:58,882] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:23:03,688] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:23:08,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:23:12,906] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:23:17,384] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:23:21,608] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:23:26,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:23:30,525] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9217901396977044
[2022-12-07 07:23:30,526] [INFO] [runner_train_mujoco] Average state value: 0.6640187033414842
[2022-12-07 07:23:30,526] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 07:23:30,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01565, loss val: 0.03771
[2022-12-07 07:23:30,624] [INFO] [controller] EPOCH 2 loss ppo:  -0.02129, loss val: 0.03740
[2022-12-07 07:23:30,666] [INFO] [controller] EPOCH 3 loss ppo:  -0.02705, loss val: 0.03710
[2022-12-07 07:23:30,710] [INFO] [controller] EPOCH 4 loss ppo:  -0.03196, loss val: 0.03710
[2022-12-07 07:23:30,719] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:23:30,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:23:30,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:23:35,694] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:23:40,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:23:45,425] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:23:50,522] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:23:55,233] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:23:59,652] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:04,272] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:24:08,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:24:13,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:24:18,242] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.071372003133955
[2022-12-07 07:24:18,242] [INFO] [runner_train_mujoco] Average state value: 0.6633660362958907
[2022-12-07 07:24:18,242] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 07:24:18,326] [INFO] [controller] EPOCH 1 loss ppo:  -0.01542, loss val: 0.04583
[2022-12-07 07:24:18,369] [INFO] [controller] EPOCH 2 loss ppo:  -0.02046, loss val: 0.04450
[2022-12-07 07:24:18,410] [INFO] [controller] EPOCH 3 loss ppo:  -0.02520, loss val: 0.04531
[2022-12-07 07:24:18,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.02933, loss val: 0.04403
[2022-12-07 07:24:18,464] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:24:18,639] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:24:18,639] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:24:23,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:24:27,785] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:24:32,431] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:24:36,933] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:24:41,371] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:24:45,723] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:50,271] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:24:54,849] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:24:59,150] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:25:04,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0964751905824004
[2022-12-07 07:25:04,071] [INFO] [runner_train_mujoco] Average state value: 0.673907017827034
[2022-12-07 07:25:04,071] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 07:25:04,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.01625, loss val: 0.04185
[2022-12-07 07:25:04,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.02393, loss val: 0.04234
[2022-12-07 07:25:04,221] [INFO] [controller] EPOCH 3 loss ppo:  -0.02496, loss val: 0.04153
[2022-12-07 07:25:04,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.03292, loss val: 0.04157
[2022-12-07 07:25:04,275] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:25:04,438] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:25:04,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:25:09,202] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:25:13,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:25:19,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:25:23,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:25:28,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:25:32,347] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:25:36,732] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:25:41,465] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:25:45,827] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:25:50,580] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.231324536176758
[2022-12-07 07:25:50,580] [INFO] [runner_train_mujoco] Average state value: 0.6824751779635748
[2022-12-07 07:25:50,581] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 07:25:50,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04385
[2022-12-07 07:25:50,677] [INFO] [controller] EPOCH 2 loss ppo:  -0.01659, loss val: 0.04415
[2022-12-07 07:25:50,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.02037, loss val: 0.04374
[2022-12-07 07:25:50,762] [INFO] [controller] EPOCH 4 loss ppo:  -0.02645, loss val: 0.04371
[2022-12-07 07:25:50,771] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:25:50,953] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:25:50,954] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:25:55,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:26:00,422] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:26:04,735] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:26:09,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:26:13,676] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:26:18,050] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:26:22,396] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:26:27,432] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:26:32,079] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:26:36,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.237826992743388
[2022-12-07 07:26:36,701] [INFO] [runner_train_mujoco] Average state value: 0.6921887725989023
[2022-12-07 07:26:36,701] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 07:26:36,754] [INFO] [controller] EPOCH 1 loss ppo:  -0.01566, loss val: 0.04244
[2022-12-07 07:26:36,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.01875, loss val: 0.04212
[2022-12-07 07:26:36,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.01855, loss val: 0.04210
[2022-12-07 07:26:36,897] [INFO] [controller] EPOCH 4 loss ppo:  -0.02275, loss val: 0.04176
[2022-12-07 07:26:36,907] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:26:37,066] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:26:37,067] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:26:41,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:26:46,257] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:26:51,042] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:26:55,592] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:27:00,101] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:27:04,476] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:27:08,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:27:13,355] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:27:17,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:27:22,234] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.252946853191615
[2022-12-07 07:27:22,234] [INFO] [runner_train_mujoco] Average state value: 0.6894923207362493
[2022-12-07 07:27:22,234] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 07:27:22,284] [INFO] [controller] EPOCH 1 loss ppo:  -0.01655, loss val: 0.04375
[2022-12-07 07:27:22,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.02112, loss val: 0.04387
[2022-12-07 07:27:22,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.02146, loss val: 0.04369
[2022-12-07 07:27:22,409] [INFO] [controller] EPOCH 4 loss ppo:  -0.02648, loss val: 0.04414
[2022-12-07 07:27:22,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:27:22,590] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:27:22,590] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:27:27,000] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:27:31,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:27:35,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:27:40,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:27:44,929] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:27:49,497] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:27:54,297] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:27:58,986] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:28:03,555] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:28:08,122] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2557248626748256
[2022-12-07 07:28:08,122] [INFO] [runner_train_mujoco] Average state value: 0.6749804854393006
[2022-12-07 07:28:08,122] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 07:28:08,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.04494
[2022-12-07 07:28:08,215] [INFO] [controller] EPOCH 2 loss ppo:  -0.01545, loss val: 0.04532
[2022-12-07 07:28:08,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.02080, loss val: 0.04491
[2022-12-07 07:28:08,300] [INFO] [controller] EPOCH 4 loss ppo:  -0.02829, loss val: 0.04537
[2022-12-07 07:28:08,309] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:28:08,467] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:28:08,467] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:28:12,976] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:28:17,359] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:28:21,851] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:28:26,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:28:30,655] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:28:34,927] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:28:39,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:28:44,129] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:28:48,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:28:53,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4073611210184764
[2022-12-07 07:28:53,477] [INFO] [runner_train_mujoco] Average state value: 0.6642791525125504
[2022-12-07 07:28:53,477] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 07:28:53,536] [INFO] [controller] EPOCH 1 loss ppo:  -0.01577, loss val: 0.04311
[2022-12-07 07:28:53,585] [INFO] [controller] EPOCH 2 loss ppo:  -0.01897, loss val: 0.04225
[2022-12-07 07:28:53,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.02043, loss val: 0.04222
[2022-12-07 07:28:53,675] [INFO] [controller] EPOCH 4 loss ppo:  -0.02202, loss val: 0.04224
[2022-12-07 07:28:53,684] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:28:53,849] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:28:53,849] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:28:58,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:29:02,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:29:07,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:29:12,355] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:29:17,001] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:29:21,545] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:29:26,005] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:29:30,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:29:34,919] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:29:39,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5180644138936072
[2022-12-07 07:29:39,284] [INFO] [runner_train_mujoco] Average state value: 0.659283016204834
[2022-12-07 07:29:39,284] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 07:29:39,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.01625, loss val: 0.04034
[2022-12-07 07:29:39,396] [INFO] [controller] EPOCH 2 loss ppo:  -0.01855, loss val: 0.04037
[2022-12-07 07:29:39,440] [INFO] [controller] EPOCH 3 loss ppo:  -0.02093, loss val: 0.04036
[2022-12-07 07:29:39,485] [INFO] [controller] EPOCH 4 loss ppo:  -0.02216, loss val: 0.04042
[2022-12-07 07:29:39,495] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:29:39,654] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:29:39,654] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:29:43,826] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:29:48,406] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:29:52,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:29:57,315] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:30:01,794] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:30:06,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:30:10,817] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:30:15,140] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:30:19,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:30:23,859] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5101484007656585
[2022-12-07 07:30:23,859] [INFO] [runner_train_mujoco] Average state value: 0.6557830214500427
[2022-12-07 07:30:23,859] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 07:30:23,913] [INFO] [controller] EPOCH 1 loss ppo:  -0.01589, loss val: 0.04200
[2022-12-07 07:30:23,956] [INFO] [controller] EPOCH 2 loss ppo:  -0.02038, loss val: 0.04408
[2022-12-07 07:30:24,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.02477, loss val: 0.04269
[2022-12-07 07:30:24,045] [INFO] [controller] EPOCH 4 loss ppo:  -0.02561, loss val: 0.04188
[2022-12-07 07:30:24,054] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:30:24,217] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:30:24,218] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:30:28,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:30:33,558] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:30:38,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:30:42,834] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:30:47,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:30:52,166] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:30:56,617] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:31:01,178] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:31:05,893] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:31:10,417] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5602414212948528
[2022-12-07 07:31:10,418] [INFO] [runner_train_mujoco] Average state value: 0.6511327609419821
[2022-12-07 07:31:10,418] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 07:31:10,473] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.04210
[2022-12-07 07:31:10,517] [INFO] [controller] EPOCH 2 loss ppo:  -0.01709, loss val: 0.04146
[2022-12-07 07:31:10,565] [INFO] [controller] EPOCH 3 loss ppo:  -0.02048, loss val: 0.04218
[2022-12-07 07:31:10,611] [INFO] [controller] EPOCH 4 loss ppo:  -0.02322, loss val: 0.04222
[2022-12-07 07:31:10,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:31:10,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:31:10,803] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:31:14,966] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:31:19,195] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:31:23,924] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:31:28,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:31:32,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:31:38,965] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:31:44,052] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:31:48,774] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:31:53,031] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:31:57,605] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5221398422225034
[2022-12-07 07:31:57,605] [INFO] [runner_train_mujoco] Average state value: 0.6436119495828947
[2022-12-07 07:31:57,606] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 07:31:57,657] [INFO] [controller] EPOCH 1 loss ppo:  -0.01566, loss val: 0.04330
[2022-12-07 07:31:57,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.01758, loss val: 0.04294
[2022-12-07 07:31:57,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.02052, loss val: 0.04392
[2022-12-07 07:31:57,810] [INFO] [controller] EPOCH 4 loss ppo:  -0.02221, loss val: 0.04381
[2022-12-07 07:31:57,820] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:31:57,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:31:57,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:32:02,688] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:32:07,312] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:32:11,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:32:15,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:32:20,064] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:32:24,753] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:32:28,880] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:32:33,384] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:32:37,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:32:42,103] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4998942392269545
[2022-12-07 07:32:42,103] [INFO] [runner_train_mujoco] Average state value: 0.6446850943565369
[2022-12-07 07:32:42,103] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 07:32:42,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.01573, loss val: 0.04328
[2022-12-07 07:32:42,193] [INFO] [controller] EPOCH 2 loss ppo:  -0.01855, loss val: 0.04435
[2022-12-07 07:32:42,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.02257, loss val: 0.04292
[2022-12-07 07:32:42,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.02289, loss val: 0.04385
[2022-12-07 07:32:42,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:32:42,447] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:32:42,447] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:32:46,708] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:32:51,234] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:32:55,730] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:33:00,661] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:33:06,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:33:10,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:33:14,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:33:19,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:33:24,115] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:33:28,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5585279407597925
[2022-12-07 07:33:28,722] [INFO] [runner_train_mujoco] Average state value: 0.6516743694146474
[2022-12-07 07:33:28,722] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 07:33:28,773] [INFO] [controller] EPOCH 1 loss ppo:  -0.01541, loss val: 0.04308
[2022-12-07 07:33:28,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.01672, loss val: 0.04221
[2022-12-07 07:33:28,863] [INFO] [controller] EPOCH 3 loss ppo:  -0.01855, loss val: 0.04222
[2022-12-07 07:33:28,915] [INFO] [controller] EPOCH 4 loss ppo:  -0.02141, loss val: 0.04214
[2022-12-07 07:33:28,924] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:33:29,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:33:29,074] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:33:33,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:33:38,088] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:33:42,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:33:46,652] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:33:51,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:33:55,137] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:33:59,282] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:34:03,518] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:34:07,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:34:12,048] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5189737145230167
[2022-12-07 07:34:12,048] [INFO] [runner_train_mujoco] Average state value: 0.6579264158010483
[2022-12-07 07:34:12,048] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 07:34:12,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01537, loss val: 0.04335
[2022-12-07 07:34:12,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.01766, loss val: 0.04246
[2022-12-07 07:34:12,210] [INFO] [controller] EPOCH 3 loss ppo:  -0.02052, loss val: 0.04348
[2022-12-07 07:34:12,258] [INFO] [controller] EPOCH 4 loss ppo:  -0.02151, loss val: 0.04246
[2022-12-07 07:34:12,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:34:12,436] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:34:12,436] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:34:16,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:34:21,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:34:26,211] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:34:30,838] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:34:35,445] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:34:40,312] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:34:44,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:34:49,050] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:34:53,208] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:34:57,562] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.549288522009524
[2022-12-07 07:34:57,562] [INFO] [runner_train_mujoco] Average state value: 0.6585784524877866
[2022-12-07 07:34:57,562] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 07:34:57,609] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.04537
[2022-12-07 07:34:57,648] [INFO] [controller] EPOCH 2 loss ppo:  -0.01587, loss val: 0.04549
[2022-12-07 07:34:57,692] [INFO] [controller] EPOCH 3 loss ppo:  -0.01741, loss val: 0.04533
[2022-12-07 07:34:57,736] [INFO] [controller] EPOCH 4 loss ppo:  -0.01911, loss val: 0.04568
[2022-12-07 07:34:57,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:34:57,899] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:34:57,900] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:35:02,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:35:06,604] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:35:11,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:35:15,529] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:35:19,955] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:35:24,218] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:35:28,317] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:35:32,830] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:35:37,057] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:35:41,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6496875498385757
[2022-12-07 07:35:41,273] [INFO] [runner_train_mujoco] Average state value: 0.6630430155595144
[2022-12-07 07:35:41,273] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 07:35:41,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01531, loss val: 0.03904
[2022-12-07 07:35:41,361] [INFO] [controller] EPOCH 2 loss ppo:  -0.01595, loss val: 0.03892
[2022-12-07 07:35:41,401] [INFO] [controller] EPOCH 3 loss ppo:  -0.01764, loss val: 0.03909
[2022-12-07 07:35:41,442] [INFO] [controller] EPOCH 4 loss ppo:  -0.02031, loss val: 0.03877
[2022-12-07 07:35:41,451] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:35:41,611] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:35:41,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:35:46,211] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:35:50,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:35:54,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:35:59,848] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:36:04,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:36:08,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:36:13,272] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:36:17,645] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:36:21,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:36:26,311] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7014064426853226
[2022-12-07 07:36:26,311] [INFO] [runner_train_mujoco] Average state value: 0.6585334440072377
[2022-12-07 07:36:26,311] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 07:36:26,366] [INFO] [controller] EPOCH 1 loss ppo:  -0.01564, loss val: 0.04279
[2022-12-07 07:36:26,409] [INFO] [controller] EPOCH 2 loss ppo:  -0.01711, loss val: 0.04287
[2022-12-07 07:36:26,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.01842, loss val: 0.04331
[2022-12-07 07:36:26,498] [INFO] [controller] EPOCH 4 loss ppo:  -0.02007, loss val: 0.04292
[2022-12-07 07:36:26,508] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:36:26,660] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:36:26,661] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:36:30,856] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:36:35,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:36:39,387] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:36:43,483] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:36:47,531] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:36:51,668] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:36:56,194] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:37:00,666] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:37:05,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:37:10,100] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6968664416403074
[2022-12-07 07:37:10,100] [INFO] [runner_train_mujoco] Average state value: 0.6569856087764104
[2022-12-07 07:37:10,100] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 07:37:10,164] [INFO] [controller] EPOCH 1 loss ppo:  -0.01535, loss val: 0.04411
[2022-12-07 07:37:10,211] [INFO] [controller] EPOCH 2 loss ppo:  -0.01521, loss val: 0.04506
[2022-12-07 07:37:10,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.01553, loss val: 0.04413
[2022-12-07 07:37:10,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.01622, loss val: 0.04499
[2022-12-07 07:37:10,314] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:37:10,440] [INFO] [optimize] Finished learning.
