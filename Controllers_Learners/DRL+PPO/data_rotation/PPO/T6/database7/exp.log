[2022-12-07 04:44:58,558] [INFO] [optimize] Starting learning
[2022-12-07 04:44:58,564] [INFO] [optimize] Starting learning process..
[2022-12-07 04:44:58,620] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:44:58,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:45:05,861] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:45:11,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:45:17,339] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:45:23,608] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:45:30,006] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:45:36,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:45:42,548] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:45:49,430] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:45:55,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:46:01,575] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18205420517460938
[2022-12-07 04:46:01,575] [INFO] [runner_train_mujoco] Average state value: -0.07279643559455871
[2022-12-07 04:46:01,576] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 04:46:01,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.01645, loss val: 0.57532
[2022-12-07 04:46:01,708] [INFO] [controller] EPOCH 2 loss ppo:  -0.03577, loss val: 0.51835
[2022-12-07 04:46:01,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.04228, loss val: 0.45571
[2022-12-07 04:46:01,822] [INFO] [controller] EPOCH 4 loss ppo:  -0.04463, loss val: 0.40635
[2022-12-07 04:46:01,834] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:46:02,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:46:02,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:46:08,330] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:46:14,910] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:46:21,623] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:46:28,011] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:46:34,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:46:40,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:46:47,321] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:46:53,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:47:00,442] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:47:06,973] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1810067071564134
[2022-12-07 04:47:06,973] [INFO] [runner_train_mujoco] Average state value: 0.12561301355094961
[2022-12-07 04:47:06,973] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 04:47:07,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.32249
[2022-12-07 04:47:07,141] [INFO] [controller] EPOCH 2 loss ppo:  -0.02876, loss val: 0.28875
[2022-12-07 04:47:07,204] [INFO] [controller] EPOCH 3 loss ppo:  -0.03452, loss val: 0.24811
[2022-12-07 04:47:07,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.03684, loss val: 0.21906
[2022-12-07 04:47:07,270] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:47:07,486] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:47:07,486] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:47:13,753] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:47:20,051] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:47:26,527] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:47:33,025] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:47:39,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:47:45,231] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:47:51,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:47:57,085] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:48:02,993] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:48:08,528] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18377831181586102
[2022-12-07 04:48:08,529] [INFO] [runner_train_mujoco] Average state value: 0.2711101310128967
[2022-12-07 04:48:08,529] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 04:48:08,597] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.24333
[2022-12-07 04:48:08,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.02495, loss val: 0.20653
[2022-12-07 04:48:08,690] [INFO] [controller] EPOCH 3 loss ppo:  -0.02813, loss val: 0.18815
[2022-12-07 04:48:08,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.03352, loss val: 0.16700
[2022-12-07 04:48:08,747] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:48:08,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:48:08,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:48:14,740] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:48:20,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:48:26,035] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:48:31,791] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:48:37,521] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:48:43,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:48:49,188] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:48:54,818] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:49:00,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:49:06,493] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20503415718774093
[2022-12-07 04:49:06,494] [INFO] [runner_train_mujoco] Average state value: 0.44110610072687273
[2022-12-07 04:49:06,494] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 04:49:06,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.15174
[2022-12-07 04:49:06,627] [INFO] [controller] EPOCH 2 loss ppo:  -0.02772, loss val: 0.13332
[2022-12-07 04:49:06,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.02875, loss val: 0.11802
[2022-12-07 04:49:06,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.03402, loss val: 0.10676
[2022-12-07 04:49:06,852] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:49:07,027] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:49:07,027] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:49:12,622] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:49:18,347] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:49:24,083] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:49:29,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:49:35,095] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:49:41,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:49:46,623] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:49:52,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:49:58,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:50:04,276] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17209339381205374
[2022-12-07 04:50:04,276] [INFO] [runner_train_mujoco] Average state value: 0.6124431509741892
[2022-12-07 04:50:04,276] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 04:50:04,336] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.09432
[2022-12-07 04:50:04,382] [INFO] [controller] EPOCH 2 loss ppo:  -0.02525, loss val: 0.08323
[2022-12-07 04:50:04,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.02997, loss val: 0.07427
[2022-12-07 04:50:04,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.03305, loss val: 0.06782
[2022-12-07 04:50:04,499] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:50:04,686] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:50:04,687] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:50:10,003] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:50:15,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:50:21,600] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:50:27,510] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:50:32,711] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:50:38,364] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:43,871] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:50:49,597] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:50:55,056] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:51:00,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17715624550174597
[2022-12-07 04:51:00,912] [INFO] [runner_train_mujoco] Average state value: 0.7278155556817849
[2022-12-07 04:51:00,913] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 04:51:00,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01062, loss val: 0.06891
[2022-12-07 04:51:01,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.02120, loss val: 0.06480
[2022-12-07 04:51:01,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.02357, loss val: 0.05910
[2022-12-07 04:51:01,147] [INFO] [controller] EPOCH 4 loss ppo:  -0.02713, loss val: 0.05714
[2022-12-07 04:51:01,157] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:51:01,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:51:01,333] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:51:07,186] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:51:13,042] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:51:18,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:51:24,805] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:51:30,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:51:36,015] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:51:41,876] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:51:47,686] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:51:53,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:51:59,471] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1944131699512734
[2022-12-07 04:51:59,471] [INFO] [runner_train_mujoco] Average state value: 0.7709479189117749
[2022-12-07 04:51:59,471] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 04:51:59,545] [INFO] [controller] EPOCH 1 loss ppo:  -0.00784, loss val: 0.05427
[2022-12-07 04:51:59,597] [INFO] [controller] EPOCH 2 loss ppo:  -0.01783, loss val: 0.05286
[2022-12-07 04:51:59,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.02082, loss val: 0.05045
[2022-12-07 04:51:59,712] [INFO] [controller] EPOCH 4 loss ppo:  -0.02440, loss val: 0.04914
[2022-12-07 04:51:59,722] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:51:59,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:51:59,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:52:05,613] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:52:11,365] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:52:17,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:52:22,627] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:52:28,398] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:52:33,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:52:39,649] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:52:45,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:52:50,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:52:55,558] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2652071743691363
[2022-12-07 04:52:55,559] [INFO] [runner_train_mujoco] Average state value: 0.7727140825390816
[2022-12-07 04:52:55,559] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 04:52:55,645] [INFO] [controller] EPOCH 1 loss ppo:  -0.00660, loss val: 0.04570
[2022-12-07 04:52:55,715] [INFO] [controller] EPOCH 2 loss ppo:  -0.02107, loss val: 0.04464
[2022-12-07 04:52:55,775] [INFO] [controller] EPOCH 3 loss ppo:  -0.02649, loss val: 0.04300
[2022-12-07 04:52:55,836] [INFO] [controller] EPOCH 4 loss ppo:  -0.02903, loss val: 0.04294
[2022-12-07 04:52:55,848] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:52:56,041] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:52:56,041] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:01,937] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:53:07,583] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:53:15,023] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:53:20,776] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:53:26,290] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:53:31,622] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:53:36,880] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:53:42,331] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:53:47,957] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:53:53,522] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18291354096091672
[2022-12-07 04:53:53,522] [INFO] [runner_train_mujoco] Average state value: 0.7461082870960236
[2022-12-07 04:53:53,522] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 04:53:53,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.00563, loss val: 0.04436
[2022-12-07 04:53:53,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.01470, loss val: 0.04568
[2022-12-07 04:53:53,739] [INFO] [controller] EPOCH 3 loss ppo:  -0.02183, loss val: 0.04564
[2022-12-07 04:53:53,790] [INFO] [controller] EPOCH 4 loss ppo:  -0.02524, loss val: 0.04442
[2022-12-07 04:53:53,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:53:53,977] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:53:53,978] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:59,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:54:04,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:54:10,329] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:54:15,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:54:21,132] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:54:26,599] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:54:31,862] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:54:37,344] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:54:42,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:54:48,428] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16851287625393985
[2022-12-07 04:54:48,429] [INFO] [runner_train_mujoco] Average state value: 0.7565438637932143
[2022-12-07 04:54:48,429] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 04:54:48,506] [INFO] [controller] EPOCH 1 loss ppo:  -0.00623, loss val: 0.04205
[2022-12-07 04:54:48,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.01744, loss val: 0.04216
[2022-12-07 04:54:48,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.02259, loss val: 0.03978
[2022-12-07 04:54:48,654] [INFO] [controller] EPOCH 4 loss ppo:  -0.02500, loss val: 0.03924
[2022-12-07 04:54:48,664] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:54:48,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:54:48,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:54:54,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:55:00,285] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:55:05,710] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:55:11,034] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:55:16,556] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:55:22,056] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:55:27,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:55:33,203] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:55:38,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:55:44,145] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3045179626949726
[2022-12-07 04:55:44,145] [INFO] [runner_train_mujoco] Average state value: 0.7301945728460948
[2022-12-07 04:55:44,145] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 04:55:44,235] [INFO] [controller] EPOCH 1 loss ppo:  -0.00772, loss val: 0.04101
[2022-12-07 04:55:44,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.02325, loss val: 0.04259
[2022-12-07 04:55:44,368] [INFO] [controller] EPOCH 3 loss ppo:  -0.02832, loss val: 0.04115
[2022-12-07 04:55:44,427] [INFO] [controller] EPOCH 4 loss ppo:  -0.03237, loss val: 0.04174
[2022-12-07 04:55:44,438] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:55:44,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:55:44,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:55:49,949] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:55:55,069] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:56:00,679] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:56:06,390] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:56:11,518] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:56:17,359] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:56:22,956] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:56:28,758] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:56:33,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:56:39,566] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.190051491692839
[2022-12-07 04:56:39,566] [INFO] [runner_train_mujoco] Average state value: 0.7226822136640548
[2022-12-07 04:56:39,566] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 04:56:39,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.00712, loss val: 0.04468
[2022-12-07 04:56:39,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.01758, loss val: 0.04500
[2022-12-07 04:56:39,772] [INFO] [controller] EPOCH 3 loss ppo:  -0.02311, loss val: 0.04397
[2022-12-07 04:56:39,874] [INFO] [controller] EPOCH 4 loss ppo:  -0.02615, loss val: 0.04556
[2022-12-07 04:56:39,884] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:56:40,059] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:56:40,060] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:56:45,609] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:56:51,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:56:56,391] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:57:01,714] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:57:07,269] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:57:12,313] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:57:18,048] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:57:23,475] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:57:28,882] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:57:34,203] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22423020992787354
[2022-12-07 04:57:34,204] [INFO] [runner_train_mujoco] Average state value: 0.7541768267949422
[2022-12-07 04:57:34,204] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 04:57:34,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.00725, loss val: 0.04509
[2022-12-07 04:57:34,307] [INFO] [controller] EPOCH 2 loss ppo:  -0.01921, loss val: 0.04591
[2022-12-07 04:57:34,370] [INFO] [controller] EPOCH 3 loss ppo:  -0.02509, loss val: 0.04484
[2022-12-07 04:57:34,417] [INFO] [controller] EPOCH 4 loss ppo:  -0.02733, loss val: 0.04603
[2022-12-07 04:57:34,427] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:57:34,601] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:57:34,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:57:39,818] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:57:45,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:57:51,782] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:57:57,826] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:58:03,760] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:58:09,401] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:58:15,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:58:20,686] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:58:26,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:58:31,954] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4087880738109117
[2022-12-07 04:58:31,955] [INFO] [runner_train_mujoco] Average state value: 0.7785979778369267
[2022-12-07 04:58:31,955] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 04:58:32,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.00904, loss val: 0.04598
[2022-12-07 04:58:32,064] [INFO] [controller] EPOCH 2 loss ppo:  -0.01966, loss val: 0.04277
[2022-12-07 04:58:32,115] [INFO] [controller] EPOCH 3 loss ppo:  -0.02428, loss val: 0.04376
[2022-12-07 04:58:32,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.02855, loss val: 0.04310
[2022-12-07 04:58:32,176] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:58:32,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:58:32,359] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:58:37,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:58:43,221] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:58:48,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:58:54,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:58:59,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:59:04,721] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:59:10,092] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:59:15,828] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:59:21,438] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:59:27,172] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.393797856761731
[2022-12-07 04:59:27,172] [INFO] [runner_train_mujoco] Average state value: 0.7333736991882324
[2022-12-07 04:59:27,172] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 04:59:27,225] [INFO] [controller] EPOCH 1 loss ppo:  -0.00731, loss val: 0.04370
[2022-12-07 04:59:27,276] [INFO] [controller] EPOCH 2 loss ppo:  -0.01992, loss val: 0.04393
[2022-12-07 04:59:27,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.02537, loss val: 0.04456
[2022-12-07 04:59:27,378] [INFO] [controller] EPOCH 4 loss ppo:  -0.02971, loss val: 0.04402
[2022-12-07 04:59:27,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:59:27,560] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:59:27,560] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:59:33,071] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:59:38,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:59:43,578] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:59:49,015] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:59:54,450] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:59:59,932] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:00:05,707] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:00:11,225] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:00:16,259] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:00:21,460] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5263936560805736
[2022-12-07 05:00:21,460] [INFO] [runner_train_mujoco] Average state value: 0.7131419989267986
[2022-12-07 05:00:21,460] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 05:00:21,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.00886, loss val: 0.04123
[2022-12-07 05:00:21,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.01696, loss val: 0.04162
[2022-12-07 05:00:21,603] [INFO] [controller] EPOCH 3 loss ppo:  -0.02231, loss val: 0.04114
[2022-12-07 05:00:21,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.02913, loss val: 0.04206
[2022-12-07 05:00:21,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:00:21,830] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:00:21,831] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:00:27,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:00:33,124] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:00:38,669] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:00:43,646] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:00:48,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:00:53,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:00:59,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:01:05,204] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:01:10,636] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:01:16,176] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6183871236544842
[2022-12-07 05:01:16,176] [INFO] [runner_train_mujoco] Average state value: 0.7206063406864802
[2022-12-07 05:01:16,176] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 05:01:16,233] [INFO] [controller] EPOCH 1 loss ppo:  -0.00993, loss val: 0.04266
[2022-12-07 05:01:16,281] [INFO] [controller] EPOCH 2 loss ppo:  -0.01937, loss val: 0.04221
[2022-12-07 05:01:16,327] [INFO] [controller] EPOCH 3 loss ppo:  -0.02104, loss val: 0.04237
[2022-12-07 05:01:16,381] [INFO] [controller] EPOCH 4 loss ppo:  -0.02595, loss val: 0.04219
[2022-12-07 05:01:16,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:01:16,559] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:01:16,559] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:01:21,833] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:01:27,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:01:32,703] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:01:38,416] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:01:44,032] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:01:49,625] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:01:54,824] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:01:59,881] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:02:05,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:02:10,737] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5879357115857122
[2022-12-07 05:02:10,738] [INFO] [runner_train_mujoco] Average state value: 0.7424277339577675
[2022-12-07 05:02:10,738] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 05:02:10,811] [INFO] [controller] EPOCH 1 loss ppo:  -0.00967, loss val: 0.04235
[2022-12-07 05:02:10,857] [INFO] [controller] EPOCH 2 loss ppo:  -0.01711, loss val: 0.04115
[2022-12-07 05:02:10,907] [INFO] [controller] EPOCH 3 loss ppo:  -0.02190, loss val: 0.04209
[2022-12-07 05:02:10,954] [INFO] [controller] EPOCH 4 loss ppo:  -0.02685, loss val: 0.04150
[2022-12-07 05:02:10,969] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:02:11,145] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:02:11,146] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:02:16,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:02:22,002] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:02:27,792] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:02:33,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:02:39,065] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:02:44,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:02:49,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:02:54,790] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:02:59,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:03:05,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6137544967008972
[2022-12-07 05:03:05,045] [INFO] [runner_train_mujoco] Average state value: 0.7428979869286219
[2022-12-07 05:03:05,045] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 05:03:05,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.00726, loss val: 0.04153
[2022-12-07 05:03:05,156] [INFO] [controller] EPOCH 2 loss ppo:  -0.01429, loss val: 0.04186
[2022-12-07 05:03:05,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.02356, loss val: 0.04109
[2022-12-07 05:03:05,254] [INFO] [controller] EPOCH 4 loss ppo:  -0.02850, loss val: 0.04156
[2022-12-07 05:03:05,264] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:03:05,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:03:05,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:03:10,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:03:16,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:03:22,140] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:03:27,386] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:03:32,868] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:03:38,096] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:03:43,462] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:03:49,069] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:03:54,322] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:03:59,876] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7175282453642557
[2022-12-07 05:03:59,876] [INFO] [runner_train_mujoco] Average state value: 0.7144315056403479
[2022-12-07 05:03:59,876] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:03:59,942] [INFO] [controller] EPOCH 1 loss ppo:  -0.00987, loss val: 0.04248
[2022-12-07 05:03:59,991] [INFO] [controller] EPOCH 2 loss ppo:  -0.02193, loss val: 0.04251
[2022-12-07 05:04:00,069] [INFO] [controller] EPOCH 3 loss ppo:  -0.02565, loss val: 0.04285
[2022-12-07 05:04:00,123] [INFO] [controller] EPOCH 4 loss ppo:  -0.03253, loss val: 0.04246
[2022-12-07 05:04:00,134] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:00,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:00,312] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:04:05,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:04:10,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:04:16,769] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:04:22,124] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:04:27,358] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:04:32,708] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:04:37,977] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:04:43,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:04:48,418] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:04:53,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7345536546852363
[2022-12-07 05:04:53,626] [INFO] [runner_train_mujoco] Average state value: 0.7100957272847495
[2022-12-07 05:04:53,626] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 05:04:53,690] [INFO] [controller] EPOCH 1 loss ppo:  -0.00827, loss val: 0.04187
[2022-12-07 05:04:53,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.01443, loss val: 0.04278
[2022-12-07 05:04:53,785] [INFO] [controller] EPOCH 3 loss ppo:  -0.02079, loss val: 0.04235
[2022-12-07 05:04:53,833] [INFO] [controller] EPOCH 4 loss ppo:  -0.02771, loss val: 0.04192
[2022-12-07 05:04:53,843] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:54,013] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:54,013] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:04:59,352] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:05:04,699] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:05:10,260] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:05:16,092] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:05:21,673] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:05:26,953] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:05:32,499] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:05:37,998] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:05:43,293] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:05:48,897] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8076800510985069
[2022-12-07 05:05:48,898] [INFO] [runner_train_mujoco] Average state value: 0.7208733156720797
[2022-12-07 05:05:48,898] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 05:05:48,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.00963, loss val: 0.03918
[2022-12-07 05:05:49,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.02080, loss val: 0.03925
[2022-12-07 05:05:49,069] [INFO] [controller] EPOCH 3 loss ppo:  -0.02476, loss val: 0.03881
[2022-12-07 05:05:49,122] [INFO] [controller] EPOCH 4 loss ppo:  -0.03081, loss val: 0.03776
[2022-12-07 05:05:49,132] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:05:49,297] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:05:49,298] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:05:54,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:06:00,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:06:05,585] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:06:10,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:06:16,404] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:06:21,503] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:06:27,001] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:06:32,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:06:38,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:06:43,731] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7946330864382471
[2022-12-07 05:06:43,731] [INFO] [runner_train_mujoco] Average state value: 0.6983750046491624
[2022-12-07 05:06:43,731] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 05:06:43,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.00781, loss val: 0.03768
[2022-12-07 05:06:43,923] [INFO] [controller] EPOCH 2 loss ppo:  -0.01589, loss val: 0.03687
[2022-12-07 05:06:43,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.02551, loss val: 0.03779
[2022-12-07 05:06:44,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.03268, loss val: 0.03662
[2022-12-07 05:06:44,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:06:44,199] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:06:44,199] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:06:49,502] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:06:54,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:06:59,655] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:07:06,006] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:07:12,089] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:07:18,043] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:07:24,242] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:07:29,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:07:35,717] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:07:41,588] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9087665478416722
[2022-12-07 05:07:41,589] [INFO] [runner_train_mujoco] Average state value: 0.6831189726193746
[2022-12-07 05:07:41,589] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 05:07:41,651] [INFO] [controller] EPOCH 1 loss ppo:  -0.01069, loss val: 0.03933
[2022-12-07 05:07:41,701] [INFO] [controller] EPOCH 2 loss ppo:  -0.02326, loss val: 0.03959
[2022-12-07 05:07:41,758] [INFO] [controller] EPOCH 3 loss ppo:  -0.02660, loss val: 0.03945
[2022-12-07 05:07:41,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.02991, loss val: 0.04029
[2022-12-07 05:07:41,883] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:07:42,067] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:07:42,067] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:07:47,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:07:52,644] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:07:57,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:08:02,906] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:08:08,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:08:13,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:08:19,445] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:08:25,098] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:08:30,458] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:08:36,046] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9738319774469817
[2022-12-07 05:08:36,047] [INFO] [runner_train_mujoco] Average state value: 0.6785976977547009
[2022-12-07 05:08:36,047] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 05:08:36,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.01083, loss val: 0.03934
[2022-12-07 05:08:36,167] [INFO] [controller] EPOCH 2 loss ppo:  -0.02162, loss val: 0.03931
[2022-12-07 05:08:36,216] [INFO] [controller] EPOCH 3 loss ppo:  -0.02519, loss val: 0.04006
[2022-12-07 05:08:36,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.03274, loss val: 0.04088
[2022-12-07 05:08:36,279] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:08:36,459] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:08:36,459] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:08:42,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:08:48,191] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:08:53,642] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:08:59,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:09:04,332] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:09:09,979] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:09:15,166] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:09:20,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:09:25,874] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:09:31,080] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.031708206980585
[2022-12-07 05:09:31,080] [INFO] [runner_train_mujoco] Average state value: 0.6930882766842842
[2022-12-07 05:09:31,080] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 05:09:31,146] [INFO] [controller] EPOCH 1 loss ppo:  -0.00986, loss val: 0.04361
[2022-12-07 05:09:31,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.01911, loss val: 0.04383
[2022-12-07 05:09:31,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.02446, loss val: 0.04301
[2022-12-07 05:09:31,301] [INFO] [controller] EPOCH 4 loss ppo:  -0.02600, loss val: 0.04396
[2022-12-07 05:09:31,310] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:09:31,476] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:09:31,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:09:36,806] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:09:42,698] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:09:47,640] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:09:53,241] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:09:58,615] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:10:04,076] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:10:09,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:10:14,985] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:10:20,449] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:10:25,868] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2239705981612718
[2022-12-07 05:10:25,868] [INFO] [runner_train_mujoco] Average state value: 0.6838412481149038
[2022-12-07 05:10:25,869] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 05:10:25,935] [INFO] [controller] EPOCH 1 loss ppo:  -0.01025, loss val: 0.04272
[2022-12-07 05:10:25,988] [INFO] [controller] EPOCH 2 loss ppo:  -0.02124, loss val: 0.04258
[2022-12-07 05:10:26,042] [INFO] [controller] EPOCH 3 loss ppo:  -0.02981, loss val: 0.04299
[2022-12-07 05:10:26,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.03578, loss val: 0.04274
[2022-12-07 05:10:26,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:10:26,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:10:26,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:10:31,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:10:36,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:10:42,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:10:47,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:10:53,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:10:58,539] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:11:04,267] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:11:09,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:11:14,740] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:11:19,922] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3205122736613915
[2022-12-07 05:11:19,922] [INFO] [runner_train_mujoco] Average state value: 0.6833336449662843
[2022-12-07 05:11:19,922] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 05:11:19,993] [INFO] [controller] EPOCH 1 loss ppo:  -0.01097, loss val: 0.04348
[2022-12-07 05:11:20,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.02616, loss val: 0.04287
[2022-12-07 05:11:20,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.03314, loss val: 0.04264
[2022-12-07 05:11:20,142] [INFO] [controller] EPOCH 4 loss ppo:  -0.03823, loss val: 0.04257
[2022-12-07 05:11:20,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:11:20,322] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:11:20,323] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:11:25,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:11:30,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:11:36,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:11:41,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:11:47,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:11:52,928] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:11:58,233] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:12:03,746] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:12:08,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:12:14,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.287958301796102
[2022-12-07 05:12:14,065] [INFO] [runner_train_mujoco] Average state value: 0.6798514953255654
[2022-12-07 05:12:14,065] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 05:12:14,127] [INFO] [controller] EPOCH 1 loss ppo:  -0.01014, loss val: 0.04015
[2022-12-07 05:12:14,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.01998, loss val: 0.03944
[2022-12-07 05:12:14,229] [INFO] [controller] EPOCH 3 loss ppo:  -0.02533, loss val: 0.03944
[2022-12-07 05:12:14,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.02997, loss val: 0.03941
[2022-12-07 05:12:14,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:12:14,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:12:14,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:12:19,648] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:12:24,817] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:12:30,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:12:35,597] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:12:40,660] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:12:45,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:12:50,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:12:55,976] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:13:00,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:13:05,481] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4070814699940766
[2022-12-07 05:13:05,481] [INFO] [runner_train_mujoco] Average state value: 0.6870434577465057
[2022-12-07 05:13:05,481] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 05:13:05,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01215, loss val: 0.03947
[2022-12-07 05:13:05,569] [INFO] [controller] EPOCH 2 loss ppo:  -0.02146, loss val: 0.03887
[2022-12-07 05:13:05,611] [INFO] [controller] EPOCH 3 loss ppo:  -0.02668, loss val: 0.03862
[2022-12-07 05:13:05,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.03255, loss val: 0.03904
[2022-12-07 05:13:05,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:13:05,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:13:05,806] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:13:10,547] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:13:15,365] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:13:20,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:13:25,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:13:29,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:13:34,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:13:38,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:13:43,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:13:48,548] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:13:53,454] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.403875495222564
[2022-12-07 05:13:53,454] [INFO] [runner_train_mujoco] Average state value: 0.6972608901262283
[2022-12-07 05:13:53,454] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 05:13:53,502] [INFO] [controller] EPOCH 1 loss ppo:  -0.01582, loss val: 0.04016
[2022-12-07 05:13:53,544] [INFO] [controller] EPOCH 2 loss ppo:  -0.02330, loss val: 0.04116
[2022-12-07 05:13:53,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.02224, loss val: 0.04085
[2022-12-07 05:13:53,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.03101, loss val: 0.03986
[2022-12-07 05:13:53,641] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:13:53,819] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:13:53,819] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:13:58,338] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:03,070] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:14:07,993] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:14:13,035] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:14:17,433] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:14:22,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:14:26,737] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:14:31,082] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:14:35,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:14:40,528] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.491738037517632
[2022-12-07 05:14:40,528] [INFO] [runner_train_mujoco] Average state value: 0.6736302968263626
[2022-12-07 05:14:40,529] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 05:14:40,593] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.04419
[2022-12-07 05:14:40,644] [INFO] [controller] EPOCH 2 loss ppo:  -0.02070, loss val: 0.04264
[2022-12-07 05:14:40,688] [INFO] [controller] EPOCH 3 loss ppo:  -0.02973, loss val: 0.04136
[2022-12-07 05:14:40,734] [INFO] [controller] EPOCH 4 loss ppo:  -0.03171, loss val: 0.04285
[2022-12-07 05:14:40,745] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:14:40,916] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:14:40,916] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:14:45,551] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:50,684] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:14:55,513] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:15:00,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:15:04,986] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:15:09,448] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:15:13,610] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:15:18,033] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:15:22,508] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:15:26,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5287837334363856
[2022-12-07 05:15:26,919] [INFO] [runner_train_mujoco] Average state value: 0.6825888004104297
[2022-12-07 05:15:26,919] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 05:15:26,979] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04537
[2022-12-07 05:15:27,022] [INFO] [controller] EPOCH 2 loss ppo:  -0.02714, loss val: 0.04441
[2022-12-07 05:15:27,065] [INFO] [controller] EPOCH 3 loss ppo:  -0.03521, loss val: 0.04397
[2022-12-07 05:15:27,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.03779, loss val: 0.04401
[2022-12-07 05:15:27,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:15:27,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:15:27,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:15:32,464] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:15:37,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:15:42,197] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:15:47,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:15:51,807] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:15:56,276] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:16:00,885] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:16:05,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:16:09,967] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:16:14,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6450455509542306
[2022-12-07 05:16:14,981] [INFO] [runner_train_mujoco] Average state value: 0.7071909100214641
[2022-12-07 05:16:14,981] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 05:16:15,033] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04307
[2022-12-07 05:16:15,081] [INFO] [controller] EPOCH 2 loss ppo:  -0.02404, loss val: 0.04309
[2022-12-07 05:16:15,133] [INFO] [controller] EPOCH 3 loss ppo:  -0.02600, loss val: 0.04310
[2022-12-07 05:16:15,180] [INFO] [controller] EPOCH 4 loss ppo:  -0.03203, loss val: 0.04335
[2022-12-07 05:16:15,190] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:16:15,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:16:15,357] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:16:20,156] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:16:24,609] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:16:29,571] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:16:34,016] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:16:38,898] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:16:43,532] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:16:48,705] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:16:53,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:16:58,446] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:17:03,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7752769674145141
[2022-12-07 05:17:03,391] [INFO] [runner_train_mujoco] Average state value: 0.7142507104873658
[2022-12-07 05:17:03,392] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 05:17:03,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.01235, loss val: 0.04124
[2022-12-07 05:17:03,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.01794, loss val: 0.04071
[2022-12-07 05:17:03,546] [INFO] [controller] EPOCH 3 loss ppo:  -0.02321, loss val: 0.03967
[2022-12-07 05:17:03,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.03067, loss val: 0.04007
[2022-12-07 05:17:03,598] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:17:03,743] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:17:03,743] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:17:08,399] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:17:12,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:17:17,370] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:17:21,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:17:26,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:17:30,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:17:35,558] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:17:40,501] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:17:45,532] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:17:50,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8061918679100426
[2022-12-07 05:17:50,173] [INFO] [runner_train_mujoco] Average state value: 0.6787397835254669
[2022-12-07 05:17:50,174] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 05:17:50,222] [INFO] [controller] EPOCH 1 loss ppo:  -0.01457, loss val: 0.04292
[2022-12-07 05:17:50,264] [INFO] [controller] EPOCH 2 loss ppo:  -0.02684, loss val: 0.04291
[2022-12-07 05:17:50,309] [INFO] [controller] EPOCH 3 loss ppo:  -0.03231, loss val: 0.04368
[2022-12-07 05:17:50,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.03195, loss val: 0.04281
[2022-12-07 05:17:50,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:17:50,519] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:17:50,519] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:17:55,151] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:17:59,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:18:04,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:18:08,877] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:18:13,582] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:18:18,342] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:18:22,981] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:18:27,870] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:18:32,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:18:37,212] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7843017154687566
[2022-12-07 05:18:37,213] [INFO] [runner_train_mujoco] Average state value: 0.6768892678221067
[2022-12-07 05:18:37,213] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 05:18:37,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.04114
[2022-12-07 05:18:37,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.01750, loss val: 0.04185
[2022-12-07 05:18:37,377] [INFO] [controller] EPOCH 3 loss ppo:  -0.02259, loss val: 0.04145
[2022-12-07 05:18:37,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.02956, loss val: 0.04111
[2022-12-07 05:18:37,429] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:18:37,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:18:37,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:18:42,339] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:18:47,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:18:52,043] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:18:56,501] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:19:01,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:19:06,283] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:19:10,912] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:19:15,857] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:19:20,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:19:24,826] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8715934140864647
[2022-12-07 05:19:24,826] [INFO] [runner_train_mujoco] Average state value: 0.6793925765752792
[2022-12-07 05:19:24,827] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 05:19:24,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04003
[2022-12-07 05:19:24,943] [INFO] [controller] EPOCH 2 loss ppo:  -0.02203, loss val: 0.03968
[2022-12-07 05:19:25,042] [INFO] [controller] EPOCH 3 loss ppo:  -0.02323, loss val: 0.04003
[2022-12-07 05:19:25,088] [INFO] [controller] EPOCH 4 loss ppo:  -0.02856, loss val: 0.04030
[2022-12-07 05:19:25,099] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:19:25,263] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:19:25,263] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:19:29,703] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:19:34,979] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:19:39,266] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:19:43,996] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:19:48,620] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:19:53,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:19:57,778] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:20:02,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:20:06,766] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:20:11,053] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9525866584682965
[2022-12-07 05:20:11,054] [INFO] [runner_train_mujoco] Average state value: 0.6769286311467488
[2022-12-07 05:20:11,054] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 05:20:11,104] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04127
[2022-12-07 05:20:11,145] [INFO] [controller] EPOCH 2 loss ppo:  -0.01834, loss val: 0.04177
[2022-12-07 05:20:11,188] [INFO] [controller] EPOCH 3 loss ppo:  -0.02651, loss val: 0.04132
[2022-12-07 05:20:11,241] [INFO] [controller] EPOCH 4 loss ppo:  -0.03227, loss val: 0.04124
[2022-12-07 05:20:11,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:20:11,415] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:20:11,416] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:20:16,132] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:20:20,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:20:26,095] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:20:30,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:20:35,606] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:20:40,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:20:45,276] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:20:50,044] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:20:54,245] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:20:58,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9704657749898509
[2022-12-07 05:20:58,958] [INFO] [runner_train_mujoco] Average state value: 0.6794303159713746
[2022-12-07 05:20:58,958] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 05:20:59,005] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.04387
[2022-12-07 05:20:59,056] [INFO] [controller] EPOCH 2 loss ppo:  -0.02504, loss val: 0.04538
[2022-12-07 05:20:59,100] [INFO] [controller] EPOCH 3 loss ppo:  -0.02596, loss val: 0.04401
[2022-12-07 05:20:59,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.03065, loss val: 0.04529
[2022-12-07 05:20:59,152] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:20:59,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:20:59,315] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:21:04,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:21:08,644] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:21:13,290] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:21:18,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:21:22,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:21:26,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:21:31,594] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:21:36,157] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:21:41,017] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:21:46,060] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.000698523681109
[2022-12-07 05:21:46,060] [INFO] [runner_train_mujoco] Average state value: 0.6767290433446567
[2022-12-07 05:21:46,060] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 05:21:46,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04283
[2022-12-07 05:21:46,169] [INFO] [controller] EPOCH 2 loss ppo:  -0.01966, loss val: 0.04276
[2022-12-07 05:21:46,215] [INFO] [controller] EPOCH 3 loss ppo:  -0.02819, loss val: 0.04286
[2022-12-07 05:21:46,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.03126, loss val: 0.04397
[2022-12-07 05:21:46,269] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:21:46,437] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:21:46,437] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:21:50,882] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:21:55,687] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:22:00,301] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:22:05,131] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:22:09,624] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:22:14,103] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:22:18,919] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:22:23,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:22:28,188] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:22:32,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.128985457379012
[2022-12-07 05:22:32,619] [INFO] [runner_train_mujoco] Average state value: 0.6733390167355537
[2022-12-07 05:22:32,619] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 05:22:32,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04604
[2022-12-07 05:22:32,723] [INFO] [controller] EPOCH 2 loss ppo:  -0.02243, loss val: 0.04612
[2022-12-07 05:22:32,770] [INFO] [controller] EPOCH 3 loss ppo:  -0.02548, loss val: 0.04599
[2022-12-07 05:22:32,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.02924, loss val: 0.04582
[2022-12-07 05:22:32,825] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:22:32,984] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:22:32,985] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:22:37,876] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:22:42,595] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:22:46,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:22:51,773] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:22:56,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:23:00,675] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:23:05,280] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:23:09,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:23:14,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:23:18,840] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1661832313101663
[2022-12-07 05:23:18,840] [INFO] [runner_train_mujoco] Average state value: 0.6804011602203051
[2022-12-07 05:23:18,840] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 05:23:18,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.04411
[2022-12-07 05:23:18,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.02014, loss val: 0.04410
[2022-12-07 05:23:18,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.02519, loss val: 0.04440
[2022-12-07 05:23:19,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.02755, loss val: 0.04455
[2022-12-07 05:23:19,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:23:19,205] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:23:19,205] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:23:24,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:23:28,934] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:23:33,813] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:23:38,835] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:23:43,641] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:23:48,436] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:23:52,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:23:57,157] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:24:01,539] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:24:05,994] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.240995884308056
[2022-12-07 05:24:05,994] [INFO] [runner_train_mujoco] Average state value: 0.6892387450536093
[2022-12-07 05:24:05,995] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 05:24:06,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.03967
[2022-12-07 05:24:06,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.01925, loss val: 0.04042
[2022-12-07 05:24:06,130] [INFO] [controller] EPOCH 3 loss ppo:  -0.02205, loss val: 0.03950
[2022-12-07 05:24:06,174] [INFO] [controller] EPOCH 4 loss ppo:  -0.02602, loss val: 0.03937
[2022-12-07 05:24:06,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:24:06,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:24:06,349] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:24:10,767] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:24:15,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:24:20,194] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:24:25,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:24:29,375] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:24:33,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:24:38,758] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:24:43,500] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:24:47,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:24:52,517] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.305593566735197
[2022-12-07 05:24:52,517] [INFO] [runner_train_mujoco] Average state value: 0.6816083572506904
[2022-12-07 05:24:52,517] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 05:24:52,572] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.03964
[2022-12-07 05:24:52,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.01734, loss val: 0.04010
[2022-12-07 05:24:52,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.02182, loss val: 0.03984
[2022-12-07 05:24:52,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.02576, loss val: 0.03979
[2022-12-07 05:24:52,711] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:24:52,878] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:24:52,878] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:24:57,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:25:02,204] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:25:06,931] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:25:11,084] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:25:15,544] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:25:20,448] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:25:24,801] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:25:29,385] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:25:34,027] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:25:38,454] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.258424357785143
[2022-12-07 05:25:38,455] [INFO] [runner_train_mujoco] Average state value: 0.6730403896570206
[2022-12-07 05:25:38,455] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 05:25:38,516] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.04481
[2022-12-07 05:25:38,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.01934, loss val: 0.04409
[2022-12-07 05:25:38,607] [INFO] [controller] EPOCH 3 loss ppo:  -0.02748, loss val: 0.04492
[2022-12-07 05:25:38,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.02921, loss val: 0.04472
[2022-12-07 05:25:38,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:25:38,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:25:38,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:25:43,270] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:25:47,924] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:25:52,460] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:25:57,007] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:26:01,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:26:05,532] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:26:09,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:26:14,306] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:26:19,203] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:26:23,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.410222482279408
[2022-12-07 05:26:23,971] [INFO] [runner_train_mujoco] Average state value: 0.6772785166700681
[2022-12-07 05:26:23,971] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 05:26:24,029] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04158
[2022-12-07 05:26:24,079] [INFO] [controller] EPOCH 2 loss ppo:  -0.01946, loss val: 0.04143
[2022-12-07 05:26:24,128] [INFO] [controller] EPOCH 3 loss ppo:  -0.02189, loss val: 0.04124
[2022-12-07 05:26:24,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.02486, loss val: 0.04149
[2022-12-07 05:26:24,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:26:24,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:26:24,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:26:29,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:26:33,748] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:26:38,707] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:26:43,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:26:47,762] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:26:51,928] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:26:56,402] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:27:00,668] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:27:05,010] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:27:10,036] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.473273659871261
[2022-12-07 05:27:10,036] [INFO] [runner_train_mujoco] Average state value: 0.6755062617063523
[2022-12-07 05:27:10,036] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 05:27:10,087] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04367
[2022-12-07 05:27:10,128] [INFO] [controller] EPOCH 2 loss ppo:  -0.01922, loss val: 0.04397
[2022-12-07 05:27:10,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.02564, loss val: 0.04391
[2022-12-07 05:27:10,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.02777, loss val: 0.04390
[2022-12-07 05:27:10,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:27:10,404] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:27:10,404] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:27:14,974] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:27:19,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:27:24,354] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:27:29,148] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:27:33,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:27:38,113] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:27:42,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:27:46,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:27:51,194] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:27:55,734] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4934212594579686
[2022-12-07 05:27:55,734] [INFO] [runner_train_mujoco] Average state value: 0.6684091331164043
[2022-12-07 05:27:55,734] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 05:27:55,796] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04351
[2022-12-07 05:27:55,853] [INFO] [controller] EPOCH 2 loss ppo:  -0.01455, loss val: 0.04491
[2022-12-07 05:27:55,900] [INFO] [controller] EPOCH 3 loss ppo:  -0.01790, loss val: 0.04360
[2022-12-07 05:27:55,953] [INFO] [controller] EPOCH 4 loss ppo:  -0.02333, loss val: 0.04478
[2022-12-07 05:27:55,964] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:27:56,111] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:27:56,111] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:28:00,586] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:28:04,945] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:28:10,116] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:28:14,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:28:19,575] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:28:24,045] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:28:28,497] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:28:32,951] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:28:37,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:28:42,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.495885289962274
[2022-12-07 05:28:42,191] [INFO] [runner_train_mujoco] Average state value: 0.6756194200913112
[2022-12-07 05:28:42,191] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 05:28:42,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01235, loss val: 0.04200
[2022-12-07 05:28:42,287] [INFO] [controller] EPOCH 2 loss ppo:  -0.01707, loss val: 0.04212
[2022-12-07 05:28:42,331] [INFO] [controller] EPOCH 3 loss ppo:  -0.02206, loss val: 0.04229
[2022-12-07 05:28:42,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.02687, loss val: 0.04060
[2022-12-07 05:28:42,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:28:42,547] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:28:42,547] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:28:47,199] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:28:51,807] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:28:56,247] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:29:00,760] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:29:05,480] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:29:10,199] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:29:14,707] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:29:19,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:29:23,742] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:29:28,100] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.47000222754024
[2022-12-07 05:29:28,100] [INFO] [runner_train_mujoco] Average state value: 0.6831594282388688
[2022-12-07 05:29:28,101] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 05:29:28,169] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.04277
[2022-12-07 05:29:28,229] [INFO] [controller] EPOCH 2 loss ppo:  -0.01659, loss val: 0.04291
[2022-12-07 05:29:28,278] [INFO] [controller] EPOCH 3 loss ppo:  -0.02005, loss val: 0.04256
[2022-12-07 05:29:28,322] [INFO] [controller] EPOCH 4 loss ppo:  -0.02187, loss val: 0.04244
[2022-12-07 05:29:28,331] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:29:28,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:29:28,488] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:29:32,788] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:29:37,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:29:41,770] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:29:46,194] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:29:50,762] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:29:56,307] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:30:01,846] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:30:06,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:30:11,382] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:30:15,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.503340334080317
[2022-12-07 05:30:15,923] [INFO] [runner_train_mujoco] Average state value: 0.6691616359154383
[2022-12-07 05:30:15,923] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 05:30:15,991] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04393
[2022-12-07 05:30:16,041] [INFO] [controller] EPOCH 2 loss ppo:  -0.01924, loss val: 0.04343
[2022-12-07 05:30:16,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.02716, loss val: 0.04284
[2022-12-07 05:30:16,133] [INFO] [controller] EPOCH 4 loss ppo:  -0.03023, loss val: 0.04261
[2022-12-07 05:30:16,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:30:16,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:30:16,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:30:20,974] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:30:25,485] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:30:30,465] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:30:34,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:30:39,149] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:30:43,502] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:30:47,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:30:51,832] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:30:55,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:31:00,540] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.656415807756505
[2022-12-07 05:31:00,540] [INFO] [runner_train_mujoco] Average state value: 0.6566772656440735
[2022-12-07 05:31:00,541] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 05:31:00,604] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.04231
[2022-12-07 05:31:00,650] [INFO] [controller] EPOCH 2 loss ppo:  -0.01697, loss val: 0.04260
[2022-12-07 05:31:00,698] [INFO] [controller] EPOCH 3 loss ppo:  -0.02166, loss val: 0.04237
[2022-12-07 05:31:00,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.02434, loss val: 0.04229
[2022-12-07 05:31:00,765] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:31:00,941] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:31:00,942] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:31:05,379] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:31:10,204] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:31:14,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:31:19,472] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:31:23,773] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:31:28,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:31:32,779] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:31:37,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:31:41,406] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:31:45,873] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5634895338758543
[2022-12-07 05:31:45,873] [INFO] [runner_train_mujoco] Average state value: 0.6493377682367961
[2022-12-07 05:31:45,873] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 05:31:45,929] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04166
[2022-12-07 05:31:45,973] [INFO] [controller] EPOCH 2 loss ppo:  -0.01759, loss val: 0.04277
[2022-12-07 05:31:46,019] [INFO] [controller] EPOCH 3 loss ppo:  -0.02264, loss val: 0.04314
[2022-12-07 05:31:46,062] [INFO] [controller] EPOCH 4 loss ppo:  -0.02413, loss val: 0.04419
[2022-12-07 05:31:46,071] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:31:46,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:31:46,244] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:31:50,704] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:31:55,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:31:59,699] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:32:04,070] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:32:08,709] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:32:12,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:32:17,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:32:21,237] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:32:25,273] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:32:29,299] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6585838108062125
[2022-12-07 05:32:29,299] [INFO] [runner_train_mujoco] Average state value: 0.6462000406384468
[2022-12-07 05:32:29,299] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 05:32:29,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04077
[2022-12-07 05:32:29,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.01470, loss val: 0.04043
[2022-12-07 05:32:29,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.01757, loss val: 0.04046
[2022-12-07 05:32:29,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.02036, loss val: 0.04100
[2022-12-07 05:32:29,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:32:29,652] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:32:29,652] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:32:34,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:32:38,421] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:32:42,807] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:32:47,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:32:52,706] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:32:57,275] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:33:02,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:33:06,316] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:33:10,691] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:33:14,776] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.706311406508378
[2022-12-07 05:33:14,776] [INFO] [runner_train_mujoco] Average state value: 0.6467680930693944
[2022-12-07 05:33:14,777] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 05:33:14,825] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04511
[2022-12-07 05:33:14,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.01560, loss val: 0.04658
[2022-12-07 05:33:14,907] [INFO] [controller] EPOCH 3 loss ppo:  -0.01861, loss val: 0.04568
[2022-12-07 05:33:14,951] [INFO] [controller] EPOCH 4 loss ppo:  -0.02089, loss val: 0.04540
[2022-12-07 05:33:14,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:33:15,134] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:33:15,134] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:33:19,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:33:23,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:33:27,988] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:33:32,099] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:33:36,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:33:40,221] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:33:44,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:33:49,506] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:33:54,391] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:33:58,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.681827637004323
[2022-12-07 05:33:58,819] [INFO] [runner_train_mujoco] Average state value: 0.6484274259408315
[2022-12-07 05:33:58,819] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 05:33:58,873] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04461
[2022-12-07 05:33:58,925] [INFO] [controller] EPOCH 2 loss ppo:  -0.01509, loss val: 0.04441
[2022-12-07 05:33:58,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.01789, loss val: 0.04426
[2022-12-07 05:33:59,044] [INFO] [controller] EPOCH 4 loss ppo:  -0.02027, loss val: 0.04449
[2022-12-07 05:33:59,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:33:59,224] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:33:59,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:34:03,884] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:34:08,169] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:34:12,858] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:34:17,637] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:34:22,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:34:26,622] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:34:30,961] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:34:34,944] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:34:39,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:34:43,717] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7036112737038964
[2022-12-07 05:34:43,717] [INFO] [runner_train_mujoco] Average state value: 0.6532754818201065
[2022-12-07 05:34:43,717] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 05:34:43,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04322
[2022-12-07 05:34:43,812] [INFO] [controller] EPOCH 2 loss ppo:  -0.01456, loss val: 0.04138
[2022-12-07 05:34:43,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.01568, loss val: 0.04211
[2022-12-07 05:34:43,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.01703, loss val: 0.04129
[2022-12-07 05:34:43,912] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:34:44,041] [INFO] [optimize] Finished learning.
