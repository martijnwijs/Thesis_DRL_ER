[2022-12-06 16:02:43,019] [INFO] [optimize] Starting learning
[2022-12-06 16:02:43,025] [INFO] [optimize] Starting learning process..
[2022-12-06 16:02:43,094] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:02:43,094] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:02:51,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:02:59,040] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:03:06,389] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:03:13,376] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:03:19,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:03:26,652] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:03:33,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:03:40,699] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:03:47,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:03:54,410] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.12684944897703804
[2022-12-06 16:03:54,410] [INFO] [runner_train_mujoco] Average state value: -0.05626175845166047
[2022-12-06 16:03:54,410] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 16:03:54,479] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.48189
[2022-12-06 16:03:54,548] [INFO] [controller] EPOCH 2 loss ppo:  -0.03546, loss val: 0.41381
[2022-12-06 16:03:54,608] [INFO] [controller] EPOCH 3 loss ppo:  -0.03634, loss val: 0.36690
[2022-12-06 16:03:54,676] [INFO] [controller] EPOCH 4 loss ppo:  -0.03995, loss val: 0.30237
[2022-12-06 16:03:54,689] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:03:54,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:03:54,911] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:04:02,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:04:09,257] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:04:16,599] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:04:24,356] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:04:31,554] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:04:38,943] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:04:46,277] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:04:53,886] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:05:02,306] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:05:09,593] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14874854308055044
[2022-12-06 16:05:09,593] [INFO] [runner_train_mujoco] Average state value: 0.13532673136175918
[2022-12-06 16:05:09,593] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 16:05:09,674] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.28747
[2022-12-06 16:05:09,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.02664, loss val: 0.25670
[2022-12-06 16:05:09,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.03143, loss val: 0.23114
[2022-12-06 16:05:09,861] [INFO] [controller] EPOCH 4 loss ppo:  -0.03683, loss val: 0.18861
[2022-12-06 16:05:09,873] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:05:10,077] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:05:10,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:05:16,918] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:05:24,127] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:05:31,517] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:05:38,508] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:05:45,476] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:05:52,789] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:05:59,706] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:06:06,216] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:06:12,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:06:18,901] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1785715871300395
[2022-12-06 16:06:18,901] [INFO] [runner_train_mujoco] Average state value: 0.3101901767340799
[2022-12-06 16:06:18,901] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 16:06:18,996] [INFO] [controller] EPOCH 1 loss ppo:  -0.01248, loss val: 0.19812
[2022-12-06 16:06:19,056] [INFO] [controller] EPOCH 2 loss ppo:  -0.02553, loss val: 0.16043
[2022-12-06 16:06:19,114] [INFO] [controller] EPOCH 3 loss ppo:  -0.03296, loss val: 0.13331
[2022-12-06 16:06:19,171] [INFO] [controller] EPOCH 4 loss ppo:  -0.03841, loss val: 0.11671
[2022-12-06 16:06:19,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:06:19,400] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:06:19,401] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:06:26,148] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:06:32,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:06:39,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:06:45,444] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:06:52,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:06:58,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:07:06,721] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:07:13,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:07:20,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:07:27,487] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14472887720914931
[2022-12-06 16:07:27,487] [INFO] [runner_train_mujoco] Average state value: 0.49114792816527186
[2022-12-06 16:07:27,487] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 16:07:27,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01084, loss val: 0.11406
[2022-12-06 16:07:27,616] [INFO] [controller] EPOCH 2 loss ppo:  -0.02504, loss val: 0.09354
[2022-12-06 16:07:27,670] [INFO] [controller] EPOCH 3 loss ppo:  -0.03108, loss val: 0.07921
[2022-12-06 16:07:27,723] [INFO] [controller] EPOCH 4 loss ppo:  -0.03497, loss val: 0.06549
[2022-12-06 16:07:27,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:07:27,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:07:27,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:07:33,969] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:07:40,223] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:07:46,165] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:07:52,224] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:07:58,132] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:08:04,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:08:10,865] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:08:17,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:08:23,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:08:29,791] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14859915168984267
[2022-12-06 16:08:29,792] [INFO] [runner_train_mujoco] Average state value: 0.6609429451823234
[2022-12-06 16:08:29,792] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 16:08:29,864] [INFO] [controller] EPOCH 1 loss ppo:  -0.00913, loss val: 0.06931
[2022-12-06 16:08:29,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.02519, loss val: 0.05869
[2022-12-06 16:08:30,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.02975, loss val: 0.05446
[2022-12-06 16:08:30,096] [INFO] [controller] EPOCH 4 loss ppo:  -0.03113, loss val: 0.05257
[2022-12-06 16:08:30,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:08:30,294] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:08:30,294] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:08:36,041] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:08:42,130] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:08:47,687] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:08:53,536] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:08:59,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:09:05,701] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:09:11,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:09:17,540] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:09:23,574] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:09:29,573] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17419190996347758
[2022-12-06 16:09:29,573] [INFO] [runner_train_mujoco] Average state value: 0.7795229189594586
[2022-12-06 16:09:29,573] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 16:09:29,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.00662, loss val: 0.05123
[2022-12-06 16:09:29,728] [INFO] [controller] EPOCH 2 loss ppo:  -0.01969, loss val: 0.05001
[2022-12-06 16:09:29,800] [INFO] [controller] EPOCH 3 loss ppo:  -0.02540, loss val: 0.04852
[2022-12-06 16:09:29,868] [INFO] [controller] EPOCH 4 loss ppo:  -0.02806, loss val: 0.04744
[2022-12-06 16:09:29,879] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:09:30,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:09:30,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:09:36,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:09:42,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:09:48,982] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:09:55,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:10:01,991] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:10:07,929] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:10:13,553] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:10:19,397] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:10:25,598] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:10:31,789] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16253270386577795
[2022-12-06 16:10:31,789] [INFO] [runner_train_mujoco] Average state value: 0.7847784995635351
[2022-12-06 16:10:31,789] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 16:10:31,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.00586, loss val: 0.04490
[2022-12-06 16:10:31,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.01995, loss val: 0.04458
[2022-12-06 16:10:31,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.02446, loss val: 0.04602
[2022-12-06 16:10:32,043] [INFO] [controller] EPOCH 4 loss ppo:  -0.02996, loss val: 0.04466
[2022-12-06 16:10:32,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:10:32,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:10:32,245] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:10:38,592] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:10:45,205] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:10:52,153] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:10:58,884] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:11:04,896] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:11:10,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:11:16,800] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:11:23,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:11:29,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:11:36,231] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1751335231870318
[2022-12-06 16:11:36,232] [INFO] [runner_train_mujoco] Average state value: 0.7527166982690494
[2022-12-06 16:11:36,232] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 16:11:36,302] [INFO] [controller] EPOCH 1 loss ppo:  -0.00632, loss val: 0.04195
[2022-12-06 16:11:36,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.01832, loss val: 0.04201
[2022-12-06 16:11:36,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.02580, loss val: 0.04155
[2022-12-06 16:11:36,471] [INFO] [controller] EPOCH 4 loss ppo:  -0.03184, loss val: 0.04171
[2022-12-06 16:11:36,482] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:11:36,673] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:11:36,673] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:11:43,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:11:50,297] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:11:56,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:12:03,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:12:10,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:12:16,988] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:12:23,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:12:29,867] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:12:36,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:12:42,805] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18430093858178137
[2022-12-06 16:12:42,805] [INFO] [runner_train_mujoco] Average state value: 0.7381431131958961
[2022-12-06 16:12:42,805] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 16:12:42,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.00723, loss val: 0.04276
[2022-12-06 16:12:42,932] [INFO] [controller] EPOCH 2 loss ppo:  -0.01912, loss val: 0.04213
[2022-12-06 16:12:42,984] [INFO] [controller] EPOCH 3 loss ppo:  -0.02147, loss val: 0.04199
[2022-12-06 16:12:43,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.02365, loss val: 0.04184
[2022-12-06 16:12:43,050] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:12:43,243] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:12:43,243] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:12:49,873] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:12:56,441] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:13:02,513] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:13:09,343] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:13:15,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:13:22,388] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:13:28,901] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:13:35,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:13:41,025] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:13:47,351] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19049905119847477
[2022-12-06 16:13:47,351] [INFO] [runner_train_mujoco] Average state value: 0.7337539681196212
[2022-12-06 16:13:47,352] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 16:13:47,425] [INFO] [controller] EPOCH 1 loss ppo:  -0.00578, loss val: 0.04586
[2022-12-06 16:13:47,476] [INFO] [controller] EPOCH 2 loss ppo:  -0.01817, loss val: 0.04494
[2022-12-06 16:13:47,525] [INFO] [controller] EPOCH 3 loss ppo:  -0.02351, loss val: 0.04442
[2022-12-06 16:13:47,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.02389, loss val: 0.04397
[2022-12-06 16:13:47,589] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:13:47,776] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:13:47,777] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:13:54,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:13:59,797] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:14:05,715] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:14:11,369] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:14:17,663] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:14:23,508] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:14:29,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:14:35,525] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:14:41,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:14:48,008] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17427388501705343
[2022-12-06 16:14:48,008] [INFO] [runner_train_mujoco] Average state value: 0.7719004385073981
[2022-12-06 16:14:48,008] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 16:14:48,073] [INFO] [controller] EPOCH 1 loss ppo:  -0.00537, loss val: 0.04585
[2022-12-06 16:14:48,125] [INFO] [controller] EPOCH 2 loss ppo:  -0.02014, loss val: 0.04573
[2022-12-06 16:14:48,200] [INFO] [controller] EPOCH 3 loss ppo:  -0.02596, loss val: 0.04619
[2022-12-06 16:14:48,258] [INFO] [controller] EPOCH 4 loss ppo:  -0.03024, loss val: 0.04573
[2022-12-06 16:14:48,270] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:14:48,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:48,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:14:55,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:15:04,116] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:15:10,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:15:17,603] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:15:24,869] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:15:31,283] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:15:37,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:15:44,095] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:15:51,241] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:15:58,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19014668706453328
[2022-12-06 16:15:58,274] [INFO] [runner_train_mujoco] Average state value: 0.7738828444480896
[2022-12-06 16:15:58,274] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 16:15:58,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.00700, loss val: 0.04104
[2022-12-06 16:15:58,449] [INFO] [controller] EPOCH 2 loss ppo:  -0.01608, loss val: 0.04138
[2022-12-06 16:15:58,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.02267, loss val: 0.03817
[2022-12-06 16:15:58,570] [INFO] [controller] EPOCH 4 loss ppo:  -0.02690, loss val: 0.04031
[2022-12-06 16:15:58,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:15:58,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:15:58,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:16:06,209] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:16:13,317] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:16:19,907] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:16:26,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:16:33,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:16:40,529] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:16:47,345] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:16:54,508] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:17:02,115] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:17:09,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18730374302834962
[2022-12-06 16:17:09,177] [INFO] [runner_train_mujoco] Average state value: 0.7479916233221691
[2022-12-06 16:17:09,178] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 16:17:09,256] [INFO] [controller] EPOCH 1 loss ppo:  -0.00766, loss val: 0.04207
[2022-12-06 16:17:09,319] [INFO] [controller] EPOCH 2 loss ppo:  -0.02170, loss val: 0.04087
[2022-12-06 16:17:09,383] [INFO] [controller] EPOCH 3 loss ppo:  -0.02614, loss val: 0.04086
[2022-12-06 16:17:09,441] [INFO] [controller] EPOCH 4 loss ppo:  -0.02973, loss val: 0.04080
[2022-12-06 16:17:09,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:17:09,660] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:17:09,660] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:17:16,588] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:17:23,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:17:30,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:17:37,793] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:17:44,923] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:17:52,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:17:59,840] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:18:07,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:18:14,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:18:21,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.12656993959048576
[2022-12-06 16:18:21,257] [INFO] [runner_train_mujoco] Average state value: 0.6974006046454111
[2022-12-06 16:18:21,257] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 16:18:21,329] [INFO] [controller] EPOCH 1 loss ppo:  -0.00681, loss val: 0.04206
[2022-12-06 16:18:21,397] [INFO] [controller] EPOCH 2 loss ppo:  -0.01720, loss val: 0.04067
[2022-12-06 16:18:21,452] [INFO] [controller] EPOCH 3 loss ppo:  -0.02236, loss val: 0.04093
[2022-12-06 16:18:21,532] [INFO] [controller] EPOCH 4 loss ppo:  -0.02630, loss val: 0.04001
[2022-12-06 16:18:21,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:18:21,742] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:18:21,742] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:18:28,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:18:35,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:18:42,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:18:49,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:18:56,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:19:03,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:19:10,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:19:17,452] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:19:23,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:19:30,204] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22948519880505822
[2022-12-06 16:19:30,204] [INFO] [runner_train_mujoco] Average state value: 0.7082742290496826
[2022-12-06 16:19:30,204] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 16:19:30,281] [INFO] [controller] EPOCH 1 loss ppo:  -0.00728, loss val: 0.03866
[2022-12-06 16:19:30,357] [INFO] [controller] EPOCH 2 loss ppo:  -0.01617, loss val: 0.04016
[2022-12-06 16:19:30,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.02326, loss val: 0.03845
[2022-12-06 16:19:30,472] [INFO] [controller] EPOCH 4 loss ppo:  -0.02915, loss val: 0.03847
[2022-12-06 16:19:30,483] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:19:30,676] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:19:30,676] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:19:37,014] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:19:44,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:51,008] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:19:57,513] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:20:04,195] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:20:10,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:20:17,314] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:20:24,085] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:20:30,887] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:20:37,652] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20649830178904768
[2022-12-06 16:20:37,652] [INFO] [runner_train_mujoco] Average state value: 0.7295407476027806
[2022-12-06 16:20:37,653] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 16:20:37,732] [INFO] [controller] EPOCH 1 loss ppo:  -0.00704, loss val: 0.04185
[2022-12-06 16:20:37,789] [INFO] [controller] EPOCH 2 loss ppo:  -0.01572, loss val: 0.04273
[2022-12-06 16:20:37,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.02280, loss val: 0.04239
[2022-12-06 16:20:37,984] [INFO] [controller] EPOCH 4 loss ppo:  -0.02712, loss val: 0.04157
[2022-12-06 16:20:37,995] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:20:38,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:20:38,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:20:44,707] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:20:51,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:20:57,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:21:04,045] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:21:10,515] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:16,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:21:23,800] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:21:30,438] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:21:37,376] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:21:43,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2334092857627929
[2022-12-06 16:21:43,846] [INFO] [runner_train_mujoco] Average state value: 0.7503590433200201
[2022-12-06 16:21:43,847] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 16:21:43,920] [INFO] [controller] EPOCH 1 loss ppo:  -0.00896, loss val: 0.03977
[2022-12-06 16:21:43,978] [INFO] [controller] EPOCH 2 loss ppo:  -0.02088, loss val: 0.03984
[2022-12-06 16:21:44,039] [INFO] [controller] EPOCH 3 loss ppo:  -0.02448, loss val: 0.03939
[2022-12-06 16:21:44,098] [INFO] [controller] EPOCH 4 loss ppo:  -0.02861, loss val: 0.04127
[2022-12-06 16:21:44,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:21:44,301] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:21:44,301] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:21:51,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:21:57,654] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:22:04,002] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:22:10,191] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:22:16,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:22:23,617] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:22:30,624] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:22:37,146] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:22:43,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:22:49,630] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22998948115688528
[2022-12-06 16:22:49,630] [INFO] [runner_train_mujoco] Average state value: 0.7345425144831339
[2022-12-06 16:22:49,630] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 16:22:49,709] [INFO] [controller] EPOCH 1 loss ppo:  -0.00829, loss val: 0.04207
[2022-12-06 16:22:49,769] [INFO] [controller] EPOCH 2 loss ppo:  -0.01883, loss val: 0.04313
[2022-12-06 16:22:49,832] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.04346
[2022-12-06 16:22:49,892] [INFO] [controller] EPOCH 4 loss ppo:  -0.02960, loss val: 0.04299
[2022-12-06 16:22:49,904] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:22:50,105] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:22:50,105] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:22:56,769] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:23:03,429] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:23:10,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:23:17,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:23:24,057] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:23:30,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:23:37,772] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:23:44,737] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:23:51,964] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:23:58,776] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.29031588662727453
[2022-12-06 16:23:58,776] [INFO] [runner_train_mujoco] Average state value: 0.7249892284075419
[2022-12-06 16:23:58,776] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 16:23:58,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.00697, loss val: 0.04045
[2022-12-06 16:23:58,971] [INFO] [controller] EPOCH 2 loss ppo:  -0.01798, loss val: 0.04160
[2022-12-06 16:23:59,091] [INFO] [controller] EPOCH 3 loss ppo:  -0.02479, loss val: 0.04055
[2022-12-06 16:23:59,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.02641, loss val: 0.04048
[2022-12-06 16:23:59,180] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:23:59,387] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:23:59,387] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:24:06,762] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:24:14,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:24:21,304] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:24:28,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:24:36,099] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:24:43,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:24:50,428] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:24:57,180] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:25:04,236] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:25:11,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.31208174983399295
[2022-12-06 16:25:11,633] [INFO] [runner_train_mujoco] Average state value: 0.7258564528028171
[2022-12-06 16:25:11,633] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 16:25:11,734] [INFO] [controller] EPOCH 1 loss ppo:  -0.00867, loss val: 0.04133
[2022-12-06 16:25:11,812] [INFO] [controller] EPOCH 2 loss ppo:  -0.01911, loss val: 0.04111
[2022-12-06 16:25:11,988] [INFO] [controller] EPOCH 3 loss ppo:  -0.02629, loss val: 0.04113
[2022-12-06 16:25:12,102] [INFO] [controller] EPOCH 4 loss ppo:  -0.02775, loss val: 0.04072
[2022-12-06 16:25:12,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:25:12,325] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:25:12,326] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:25:19,604] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:25:26,602] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:25:33,660] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:25:41,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:25:53,936] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:26:05,062] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:26:15,922] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:26:26,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:26:35,782] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:26:44,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41693740698794046
[2022-12-06 16:26:44,832] [INFO] [runner_train_mujoco] Average state value: 0.7217932217121124
[2022-12-06 16:26:44,833] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 16:26:44,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.00969, loss val: 0.03901
[2022-12-06 16:26:45,071] [INFO] [controller] EPOCH 2 loss ppo:  -0.02430, loss val: 0.03753
[2022-12-06 16:26:45,184] [INFO] [controller] EPOCH 3 loss ppo:  -0.03277, loss val: 0.03727
[2022-12-06 16:26:45,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.03510, loss val: 0.03748
[2022-12-06 16:26:45,349] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:26:45,625] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:26:45,626] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:26:54,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:27:03,120] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:27:12,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:27:18,904] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:27:25,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:27:33,291] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:27:41,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:27:51,374] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:28:02,588] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:28:10,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5052167279230965
[2022-12-06 16:28:10,112] [INFO] [runner_train_mujoco] Average state value: 0.6927242557605108
[2022-12-06 16:28:10,112] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 16:28:10,270] [INFO] [controller] EPOCH 1 loss ppo:  -0.01021, loss val: 0.04159
[2022-12-06 16:28:10,519] [INFO] [controller] EPOCH 2 loss ppo:  -0.02049, loss val: 0.04228
[2022-12-06 16:28:10,979] [INFO] [controller] EPOCH 3 loss ppo:  -0.02801, loss val: 0.04134
[2022-12-06 16:28:11,072] [INFO] [controller] EPOCH 4 loss ppo:  -0.03073, loss val: 0.04189
[2022-12-06 16:28:11,085] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:28:11,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:28:11,312] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:28:18,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:28:26,459] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:28:34,089] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:28:41,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:28:48,856] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:28:56,305] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:29:03,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:29:11,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:29:19,642] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:29:27,749] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6074982913141913
[2022-12-06 16:29:27,750] [INFO] [runner_train_mujoco] Average state value: 0.7108710440397262
[2022-12-06 16:29:27,750] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 16:29:27,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.01177, loss val: 0.03883
[2022-12-06 16:29:28,171] [INFO] [controller] EPOCH 2 loss ppo:  -0.02249, loss val: 0.03896
[2022-12-06 16:29:28,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.02546, loss val: 0.03828
[2022-12-06 16:29:28,292] [INFO] [controller] EPOCH 4 loss ppo:  -0.02687, loss val: 0.03900
[2022-12-06 16:29:28,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:29:28,524] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:29:28,524] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:29:36,180] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:29:44,260] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:29:51,821] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:29:58,775] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:30:05,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:30:12,590] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:30:19,726] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:30:26,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:30:33,872] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:30:40,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6796227403662969
[2022-12-06 16:30:40,819] [INFO] [runner_train_mujoco] Average state value: 0.7167775779565174
[2022-12-06 16:30:40,820] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 16:30:40,918] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.04039
[2022-12-06 16:30:40,983] [INFO] [controller] EPOCH 2 loss ppo:  -0.01958, loss val: 0.04046
[2022-12-06 16:30:41,064] [INFO] [controller] EPOCH 3 loss ppo:  -0.02543, loss val: 0.04259
[2022-12-06 16:30:41,197] [INFO] [controller] EPOCH 4 loss ppo:  -0.03236, loss val: 0.04057
[2022-12-06 16:30:41,210] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:30:41,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:30:41,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:30:48,052] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:30:55,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:31:02,098] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:31:08,583] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:31:15,337] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:31:22,118] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:31:28,664] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:31:35,166] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:31:41,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:31:48,458] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8099339113659679
[2022-12-06 16:31:48,459] [INFO] [runner_train_mujoco] Average state value: 0.7178158921003341
[2022-12-06 16:31:48,459] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 16:31:48,533] [INFO] [controller] EPOCH 1 loss ppo:  -0.01184, loss val: 0.04034
[2022-12-06 16:31:48,593] [INFO] [controller] EPOCH 2 loss ppo:  -0.02078, loss val: 0.04057
[2022-12-06 16:31:48,670] [INFO] [controller] EPOCH 3 loss ppo:  -0.02500, loss val: 0.03899
[2022-12-06 16:31:48,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.02920, loss val: 0.03885
[2022-12-06 16:31:48,759] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:31:48,953] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:31:48,954] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:31:55,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:32:02,672] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:32:09,521] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:32:15,680] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:32:22,342] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:32:29,038] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:32:35,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:32:42,472] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:32:49,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:32:55,588] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6872533643398941
[2022-12-06 16:32:55,588] [INFO] [runner_train_mujoco] Average state value: 0.7135203541914622
[2022-12-06 16:32:55,588] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 16:32:55,679] [INFO] [controller] EPOCH 1 loss ppo:  -0.01221, loss val: 0.03976
[2022-12-06 16:32:55,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.02305, loss val: 0.03944
[2022-12-06 16:32:55,786] [INFO] [controller] EPOCH 3 loss ppo:  -0.02435, loss val: 0.03883
[2022-12-06 16:32:55,861] [INFO] [controller] EPOCH 4 loss ppo:  -0.02745, loss val: 0.03969
[2022-12-06 16:32:55,873] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:32:56,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:32:56,075] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:33:02,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:33:08,967] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:33:15,209] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:33:21,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:33:27,594] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:33:34,087] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:33:39,903] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:33:45,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:33:52,480] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:33:59,097] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8638301948519113
[2022-12-06 16:33:59,098] [INFO] [runner_train_mujoco] Average state value: 0.6966254915396373
[2022-12-06 16:33:59,098] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 16:33:59,176] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.04226
[2022-12-06 16:33:59,231] [INFO] [controller] EPOCH 2 loss ppo:  -0.02008, loss val: 0.04239
[2022-12-06 16:33:59,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.02716, loss val: 0.04153
[2022-12-06 16:33:59,356] [INFO] [controller] EPOCH 4 loss ppo:  -0.03472, loss val: 0.04274
[2022-12-06 16:33:59,367] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:33:59,568] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:33:59,569] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:34:06,286] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:34:12,856] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:34:20,084] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:34:27,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:34:35,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:34:42,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:34:49,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:34:59,762] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:35:10,173] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:35:17,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8941631062785513
[2022-12-06 16:35:17,531] [INFO] [runner_train_mujoco] Average state value: 0.7130973089138666
[2022-12-06 16:35:17,531] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 16:35:17,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.01167, loss val: 0.04386
[2022-12-06 16:35:17,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.02167, loss val: 0.04383
[2022-12-06 16:35:17,727] [INFO] [controller] EPOCH 3 loss ppo:  -0.02701, loss val: 0.04293
[2022-12-06 16:35:17,800] [INFO] [controller] EPOCH 4 loss ppo:  -0.03250, loss val: 0.04236
[2022-12-06 16:35:17,811] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:35:18,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:35:18,002] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:35:25,070] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:35:32,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:35:39,205] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:35:46,120] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:35:52,746] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:35:59,092] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:36:06,236] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:36:12,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:36:21,019] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:36:30,536] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0112535405459655
[2022-12-06 16:36:30,536] [INFO] [runner_train_mujoco] Average state value: 0.7009607350428898
[2022-12-06 16:36:30,537] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 16:36:30,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.01179, loss val: 0.04276
[2022-12-06 16:36:30,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.01947, loss val: 0.04104
[2022-12-06 16:36:30,771] [INFO] [controller] EPOCH 3 loss ppo:  -0.03128, loss val: 0.04200
[2022-12-06 16:36:30,835] [INFO] [controller] EPOCH 4 loss ppo:  -0.03714, loss val: 0.04136
[2022-12-06 16:36:30,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:36:31,066] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:36:31,066] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:36:40,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:36:48,332] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:36:55,474] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:37:03,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:37:10,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:37:18,247] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:37:25,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:37:33,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:37:40,562] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:37:47,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.007114194999679
[2022-12-06 16:37:47,480] [INFO] [runner_train_mujoco] Average state value: 0.6863970340887705
[2022-12-06 16:37:47,480] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 16:37:47,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.03951
[2022-12-06 16:37:47,630] [INFO] [controller] EPOCH 2 loss ppo:  -0.02285, loss val: 0.03973
[2022-12-06 16:37:47,712] [INFO] [controller] EPOCH 3 loss ppo:  -0.02617, loss val: 0.03974
[2022-12-06 16:37:47,774] [INFO] [controller] EPOCH 4 loss ppo:  -0.02883, loss val: 0.03936
[2022-12-06 16:37:47,786] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:37:48,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:37:48,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:37:55,346] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:38:02,578] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:38:09,896] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:38:17,255] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:38:27,309] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:38:39,340] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:38:48,774] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:38:56,863] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:39:05,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:39:14,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.06227164181175
[2022-12-06 16:39:14,530] [INFO] [runner_train_mujoco] Average state value: 0.6741173195044199
[2022-12-06 16:39:14,530] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 16:39:14,643] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04305
[2022-12-06 16:39:14,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.02405, loss val: 0.04142
[2022-12-06 16:39:14,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.02935, loss val: 0.04042
[2022-12-06 16:39:14,836] [INFO] [controller] EPOCH 4 loss ppo:  -0.03406, loss val: 0.04002
[2022-12-06 16:39:14,850] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:39:15,080] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:39:15,080] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:39:24,466] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:39:33,859] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:39:42,002] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:39:50,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:39:57,413] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:40:05,495] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:40:15,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:40:24,072] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:40:31,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:40:39,268] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1081628032610715
[2022-12-06 16:40:39,268] [INFO] [runner_train_mujoco] Average state value: 0.6882264127333959
[2022-12-06 16:40:39,268] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 16:40:39,379] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.04076
[2022-12-06 16:40:39,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.02436, loss val: 0.04058
[2022-12-06 16:40:39,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.02766, loss val: 0.04050
[2022-12-06 16:40:39,681] [INFO] [controller] EPOCH 4 loss ppo:  -0.03617, loss val: 0.03930
[2022-12-06 16:40:39,693] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:40:39,889] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:40:39,890] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:40:47,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:40:54,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:41:02,406] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:41:09,323] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:41:16,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:23,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:41:30,792] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:41:37,871] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:41:44,710] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:41:51,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2318711195197258
[2022-12-06 16:41:51,997] [INFO] [runner_train_mujoco] Average state value: 0.7015568231344224
[2022-12-06 16:41:51,997] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 16:41:52,103] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.04180
[2022-12-06 16:41:52,157] [INFO] [controller] EPOCH 2 loss ppo:  -0.01862, loss val: 0.04213
[2022-12-06 16:41:52,211] [INFO] [controller] EPOCH 3 loss ppo:  -0.02805, loss val: 0.04186
[2022-12-06 16:41:52,264] [INFO] [controller] EPOCH 4 loss ppo:  -0.03389, loss val: 0.04083
[2022-12-06 16:41:52,277] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:41:52,475] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:41:52,476] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:41:59,810] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:42:07,538] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:42:14,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:42:21,177] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:42:28,590] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:42:35,315] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:42:42,000] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:42:48,428] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:42:55,427] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:43:02,609] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.311226806097959
[2022-12-06 16:43:02,609] [INFO] [runner_train_mujoco] Average state value: 0.7273407069047293
[2022-12-06 16:43:02,609] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 16:43:02,683] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04221
[2022-12-06 16:43:02,740] [INFO] [controller] EPOCH 2 loss ppo:  -0.02407, loss val: 0.04230
[2022-12-06 16:43:02,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.03165, loss val: 0.04266
[2022-12-06 16:43:02,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.03688, loss val: 0.04276
[2022-12-06 16:43:02,904] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:43:03,120] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:43:03,120] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:43:10,138] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:43:17,212] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:43:25,380] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:43:32,214] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:43:39,005] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:43:45,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:43:52,538] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:43:59,429] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:44:06,405] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:44:13,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3164653051516921
[2022-12-06 16:44:13,516] [INFO] [runner_train_mujoco] Average state value: 0.7233884669542313
[2022-12-06 16:44:13,516] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 16:44:13,599] [INFO] [controller] EPOCH 1 loss ppo:  -0.01096, loss val: 0.03973
[2022-12-06 16:44:13,693] [INFO] [controller] EPOCH 2 loss ppo:  -0.01851, loss val: 0.03992
[2022-12-06 16:44:13,784] [INFO] [controller] EPOCH 3 loss ppo:  -0.02781, loss val: 0.04044
[2022-12-06 16:44:13,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.03007, loss val: 0.03968
[2022-12-06 16:44:13,881] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:44:14,081] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:44:14,082] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:44:21,360] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:44:28,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:44:35,950] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:44:43,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:44:50,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:44:57,642] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:45:04,635] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:45:11,858] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:45:19,799] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:45:28,581] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4600132143082465
[2022-12-06 16:45:28,581] [INFO] [runner_train_mujoco] Average state value: 0.6916739816268285
[2022-12-06 16:45:28,581] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 16:45:28,712] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.04041
[2022-12-06 16:45:28,803] [INFO] [controller] EPOCH 2 loss ppo:  -0.02453, loss val: 0.03892
[2022-12-06 16:45:28,882] [INFO] [controller] EPOCH 3 loss ppo:  -0.02772, loss val: 0.03879
[2022-12-06 16:45:28,975] [INFO] [controller] EPOCH 4 loss ppo:  -0.03351, loss val: 0.03851
[2022-12-06 16:45:28,988] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:45:29,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:45:29,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:45:37,004] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:45:45,424] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:45:53,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:46:01,317] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:46:09,403] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:46:17,747] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:46:26,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:46:33,886] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:46:41,498] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:46:49,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5770243773321497
[2022-12-06 16:46:49,305] [INFO] [runner_train_mujoco] Average state value: 0.6602005506356556
[2022-12-06 16:46:49,305] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 16:46:49,382] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.04276
[2022-12-06 16:46:49,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.02503, loss val: 0.04291
[2022-12-06 16:46:49,515] [INFO] [controller] EPOCH 3 loss ppo:  -0.03006, loss val: 0.04325
[2022-12-06 16:46:49,648] [INFO] [controller] EPOCH 4 loss ppo:  -0.03233, loss val: 0.04285
[2022-12-06 16:46:49,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:46:49,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:46:49,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:46:58,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:47:05,855] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:47:13,301] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:47:22,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:47:29,985] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:47:37,747] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:47:44,898] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:47:52,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:48:00,387] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:48:08,103] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5419488071333851
[2022-12-06 16:48:08,103] [INFO] [runner_train_mujoco] Average state value: 0.6672477326393127
[2022-12-06 16:48:08,103] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 16:48:08,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.03582
[2022-12-06 16:48:08,230] [INFO] [controller] EPOCH 2 loss ppo:  -0.02635, loss val: 0.03756
[2022-12-06 16:48:08,285] [INFO] [controller] EPOCH 3 loss ppo:  -0.02874, loss val: 0.03758
[2022-12-06 16:48:08,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.03217, loss val: 0.03656
[2022-12-06 16:48:08,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:48:08,571] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:48:08,571] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:48:15,481] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:48:23,629] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:48:32,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:48:40,048] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:48:47,503] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:48:54,466] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:49:01,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:49:08,558] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:49:15,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:49:23,933] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.609251733136924
[2022-12-06 16:49:23,933] [INFO] [runner_train_mujoco] Average state value: 0.663663786550363
[2022-12-06 16:49:23,933] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 16:49:23,995] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.03666
[2022-12-06 16:49:24,052] [INFO] [controller] EPOCH 2 loss ppo:  -0.01980, loss val: 0.03636
[2022-12-06 16:49:24,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.02830, loss val: 0.03561
[2022-12-06 16:49:24,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.03264, loss val: 0.03579
[2022-12-06 16:49:24,169] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:49:24,391] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:49:24,391] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:49:31,905] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:49:40,074] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:49:47,774] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:49:54,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:50:01,791] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:50:08,466] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:50:15,285] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:50:23,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:50:32,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:50:39,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7166326454101462
[2022-12-06 16:50:39,666] [INFO] [runner_train_mujoco] Average state value: 0.6393666527072589
[2022-12-06 16:50:39,666] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 16:50:39,789] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.04850
[2022-12-06 16:50:39,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.01978, loss val: 0.04814
[2022-12-06 16:50:39,960] [INFO] [controller] EPOCH 3 loss ppo:  -0.02641, loss val: 0.04723
[2022-12-06 16:50:40,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.03227, loss val: 0.04637
[2022-12-06 16:50:40,057] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:50:40,310] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:50:40,311] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:50:47,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:50:54,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:51:02,357] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:51:09,887] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:51:17,890] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:51:25,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:51:33,870] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:51:42,120] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:51:49,087] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:51:56,182] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7509853499780814
[2022-12-06 16:51:56,182] [INFO] [runner_train_mujoco] Average state value: 0.6659902379910151
[2022-12-06 16:51:56,182] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 16:51:56,304] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.04001
[2022-12-06 16:51:56,378] [INFO] [controller] EPOCH 2 loss ppo:  -0.02145, loss val: 0.04006
[2022-12-06 16:51:56,449] [INFO] [controller] EPOCH 3 loss ppo:  -0.03053, loss val: 0.04030
[2022-12-06 16:51:56,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.03249, loss val: 0.04087
[2022-12-06 16:51:56,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:51:56,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:51:56,763] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:52:04,274] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:52:11,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:52:19,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:52:26,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:52:32,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:52:39,992] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:52:47,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:52:53,858] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:53:00,697] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:53:07,406] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8495306005632048
[2022-12-06 16:53:07,406] [INFO] [runner_train_mujoco] Average state value: 0.683364767273267
[2022-12-06 16:53:07,406] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 16:53:07,507] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.04112
[2022-12-06 16:53:07,565] [INFO] [controller] EPOCH 2 loss ppo:  -0.01853, loss val: 0.04067
[2022-12-06 16:53:07,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.02410, loss val: 0.04110
[2022-12-06 16:53:07,679] [INFO] [controller] EPOCH 4 loss ppo:  -0.02884, loss val: 0.03982
[2022-12-06 16:53:07,690] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:53:07,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:53:07,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:53:14,774] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:53:21,510] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:53:28,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:53:34,981] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:53:41,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:53:48,364] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:53:54,966] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:54:01,811] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:54:08,584] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:54:15,620] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8991034221294725
[2022-12-06 16:54:15,620] [INFO] [runner_train_mujoco] Average state value: 0.6858978150288264
[2022-12-06 16:54:15,620] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 16:54:15,724] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.03622
[2022-12-06 16:54:15,780] [INFO] [controller] EPOCH 2 loss ppo:  -0.02070, loss val: 0.03911
[2022-12-06 16:54:15,841] [INFO] [controller] EPOCH 3 loss ppo:  -0.02549, loss val: 0.03577
[2022-12-06 16:54:15,908] [INFO] [controller] EPOCH 4 loss ppo:  -0.02885, loss val: 0.03664
[2022-12-06 16:54:15,919] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:54:16,116] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:54:16,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:54:23,220] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:54:30,014] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:54:36,567] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:54:43,137] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:54:49,660] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:54:55,842] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:55:02,381] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:55:08,647] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:55:14,861] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:55:21,182] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.940203258969485
[2022-12-06 16:55:21,183] [INFO] [runner_train_mujoco] Average state value: 0.6646124661366144
[2022-12-06 16:55:21,183] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 16:55:21,242] [INFO] [controller] EPOCH 1 loss ppo:  -0.01594, loss val: 0.04231
[2022-12-06 16:55:21,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.02239, loss val: 0.04274
[2022-12-06 16:55:21,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.02608, loss val: 0.04280
[2022-12-06 16:55:21,411] [INFO] [controller] EPOCH 4 loss ppo:  -0.02900, loss val: 0.04294
[2022-12-06 16:55:21,422] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:55:21,612] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:55:21,612] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:55:28,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:55:34,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:55:41,057] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:55:47,579] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:55:53,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:56:00,037] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:56:06,283] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:56:12,412] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:56:18,638] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:56:25,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0251622872534667
[2022-12-06 16:56:25,258] [INFO] [runner_train_mujoco] Average state value: 0.6571691287755966
[2022-12-06 16:56:25,258] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 16:56:25,326] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.03767
[2022-12-06 16:56:25,375] [INFO] [controller] EPOCH 2 loss ppo:  -0.02538, loss val: 0.03902
[2022-12-06 16:56:25,428] [INFO] [controller] EPOCH 3 loss ppo:  -0.03392, loss val: 0.03752
[2022-12-06 16:56:25,488] [INFO] [controller] EPOCH 4 loss ppo:  -0.03369, loss val: 0.03736
[2022-12-06 16:56:25,499] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:56:25,712] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:56:25,713] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:56:32,145] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:56:39,324] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:56:46,221] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:56:52,761] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:56:59,701] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:57:06,351] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:57:13,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:57:19,520] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:57:25,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:57:32,366] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0367297555203807
[2022-12-06 16:57:32,366] [INFO] [runner_train_mujoco] Average state value: 0.6466248653332393
[2022-12-06 16:57:32,366] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 16:57:32,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01496, loss val: 0.03957
[2022-12-06 16:57:32,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.01873, loss val: 0.04020
[2022-12-06 16:57:32,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.02346, loss val: 0.03988
[2022-12-06 16:57:32,855] [INFO] [controller] EPOCH 4 loss ppo:  -0.02511, loss val: 0.04125
[2022-12-06 16:57:32,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:57:33,089] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:57:33,089] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:57:39,772] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:57:46,309] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:57:52,733] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:58:00,111] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:58:07,020] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:58:14,089] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:58:20,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:58:27,323] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:58:34,061] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:58:41,496] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1550240311994924
[2022-12-06 16:58:41,497] [INFO] [runner_train_mujoco] Average state value: 0.6322157106598219
[2022-12-06 16:58:41,497] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 16:58:41,581] [INFO] [controller] EPOCH 1 loss ppo:  -0.01578, loss val: 0.04243
[2022-12-06 16:58:41,642] [INFO] [controller] EPOCH 2 loss ppo:  -0.02200, loss val: 0.04259
[2022-12-06 16:58:41,707] [INFO] [controller] EPOCH 3 loss ppo:  -0.03006, loss val: 0.04184
[2022-12-06 16:58:41,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.03296, loss val: 0.04207
[2022-12-06 16:58:41,785] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:58:41,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:58:41,991] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:58:49,514] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:58:57,107] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:59:04,618] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:59:11,859] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:59:19,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:59:26,548] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:59:33,569] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:59:41,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:59:48,548] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:59:56,263] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.270442579077224
[2022-12-06 16:59:56,263] [INFO] [runner_train_mujoco] Average state value: 0.6306411308646203
[2022-12-06 16:59:56,263] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 16:59:56,347] [INFO] [controller] EPOCH 1 loss ppo:  -0.01539, loss val: 0.04590
[2022-12-06 16:59:56,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.01972, loss val: 0.04483
[2022-12-06 16:59:56,534] [INFO] [controller] EPOCH 3 loss ppo:  -0.02384, loss val: 0.04519
[2022-12-06 16:59:56,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.02694, loss val: 0.04509
[2022-12-06 16:59:56,656] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:59:56,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:59:56,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:00:04,613] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:00:11,692] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:00:18,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:00:25,922] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:00:33,033] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:00:39,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:00:46,853] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:00:54,486] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:01:01,435] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:01:08,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2650802651071467
[2022-12-06 17:01:08,542] [INFO] [runner_train_mujoco] Average state value: 0.649145420531432
[2022-12-06 17:01:08,542] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 17:01:08,604] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.03787
[2022-12-06 17:01:08,685] [INFO] [controller] EPOCH 2 loss ppo:  -0.01671, loss val: 0.03769
[2022-12-06 17:01:08,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.02190, loss val: 0.03815
[2022-12-06 17:01:08,810] [INFO] [controller] EPOCH 4 loss ppo:  -0.02620, loss val: 0.03692
[2022-12-06 17:01:08,823] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:01:09,039] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:01:09,039] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:01:15,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:01:22,589] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:01:29,350] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:01:36,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:01:44,178] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:01:51,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:01:58,058] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:02:05,538] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:02:12,891] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:02:19,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.232564967316569
[2022-12-06 17:02:19,760] [INFO] [runner_train_mujoco] Average state value: 0.6608837480942409
[2022-12-06 17:02:19,760] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 17:02:19,828] [INFO] [controller] EPOCH 1 loss ppo:  -0.01605, loss val: 0.04005
[2022-12-06 17:02:19,885] [INFO] [controller] EPOCH 2 loss ppo:  -0.02312, loss val: 0.04007
[2022-12-06 17:02:19,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.02578, loss val: 0.04073
[2022-12-06 17:02:20,005] [INFO] [controller] EPOCH 4 loss ppo:  -0.02600, loss val: 0.04004
[2022-12-06 17:02:20,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:02:20,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:02:20,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:02:27,634] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:02:34,403] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:02:41,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:02:47,669] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:02:54,293] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:03:00,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:03:07,806] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:03:14,320] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:03:21,101] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:03:27,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3430559025366753
[2022-12-06 17:03:27,440] [INFO] [runner_train_mujoco] Average state value: 0.6592157232364019
[2022-12-06 17:03:27,440] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 17:03:27,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.04070
[2022-12-06 17:03:27,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.01716, loss val: 0.04045
[2022-12-06 17:03:27,739] [INFO] [controller] EPOCH 3 loss ppo:  -0.02207, loss val: 0.04050
[2022-12-06 17:03:27,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.02620, loss val: 0.04093
[2022-12-06 17:03:27,849] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:03:28,043] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:03:28,044] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:03:34,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:03:40,810] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:03:47,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:03:53,691] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:04:00,062] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:04:06,472] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:04:13,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:04:19,395] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:04:25,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:04:32,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.375140770545703
[2022-12-06 17:04:32,231] [INFO] [runner_train_mujoco] Average state value: 0.6519362111886342
[2022-12-06 17:04:32,231] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 17:04:32,321] [INFO] [controller] EPOCH 1 loss ppo:  -0.01580, loss val: 0.03971
[2022-12-06 17:04:32,378] [INFO] [controller] EPOCH 2 loss ppo:  -0.01983, loss val: 0.03970
[2022-12-06 17:04:32,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.02217, loss val: 0.03976
[2022-12-06 17:04:32,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.02336, loss val: 0.03996
[2022-12-06 17:04:32,657] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:04:32,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:04:32,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:04:39,259] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:04:45,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:04:52,349] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:04:59,450] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:05:05,608] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:05:11,714] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:05:17,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:05:24,132] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:05:30,666] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:05:37,246] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.326251494506867
[2022-12-06 17:05:37,247] [INFO] [runner_train_mujoco] Average state value: 0.6431304158965747
[2022-12-06 17:05:37,247] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 17:05:37,331] [INFO] [controller] EPOCH 1 loss ppo:  -0.01571, loss val: 0.04166
[2022-12-06 17:05:37,391] [INFO] [controller] EPOCH 2 loss ppo:  -0.01849, loss val: 0.04261
[2022-12-06 17:05:37,450] [INFO] [controller] EPOCH 3 loss ppo:  -0.02283, loss val: 0.04259
[2022-12-06 17:05:37,536] [INFO] [controller] EPOCH 4 loss ppo:  -0.02408, loss val: 0.04162
[2022-12-06 17:05:37,549] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:05:37,774] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:05:37,774] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:05:44,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:05:51,361] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:05:58,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:06:05,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:06:11,913] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:06:19,279] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:06:27,319] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:06:34,498] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:06:40,637] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:06:47,425] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3556096132777347
[2022-12-06 17:06:47,425] [INFO] [runner_train_mujoco] Average state value: 0.6398798500498135
[2022-12-06 17:06:47,426] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 17:06:47,531] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.04147
[2022-12-06 17:06:47,650] [INFO] [controller] EPOCH 2 loss ppo:  -0.01801, loss val: 0.04139
[2022-12-06 17:06:47,793] [INFO] [controller] EPOCH 3 loss ppo:  -0.02307, loss val: 0.04166
[2022-12-06 17:06:48,064] [INFO] [controller] EPOCH 4 loss ppo:  -0.02348, loss val: 0.04161
[2022-12-06 17:06:48,080] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:06:48,291] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:06:48,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:06:56,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:07:04,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:07:13,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:07:21,282] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:07:29,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:07:40,605] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:07:49,463] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:07:58,141] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:08:06,779] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:08:15,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4023051283768555
[2022-12-06 17:08:15,371] [INFO] [runner_train_mujoco] Average state value: 0.6414658579428991
[2022-12-06 17:08:15,371] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 17:08:15,475] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.03989
[2022-12-06 17:08:15,546] [INFO] [controller] EPOCH 2 loss ppo:  -0.01874, loss val: 0.03963
[2022-12-06 17:08:15,675] [INFO] [controller] EPOCH 3 loss ppo:  -0.02189, loss val: 0.03937
[2022-12-06 17:08:15,743] [INFO] [controller] EPOCH 4 loss ppo:  -0.02475, loss val: 0.03926
[2022-12-06 17:08:15,756] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:08:16,043] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:08:16,044] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:08:25,483] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:08:33,703] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:08:41,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:08:49,463] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:08:57,976] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:09:07,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:09:16,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:09:25,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:09:32,778] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:09:40,629] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.535642739400056
[2022-12-06 17:09:40,629] [INFO] [runner_train_mujoco] Average state value: 0.6426245307922362
[2022-12-06 17:09:40,629] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 17:09:40,730] [INFO] [controller] EPOCH 1 loss ppo:  -0.01572, loss val: 0.04508
[2022-12-06 17:09:40,888] [INFO] [controller] EPOCH 2 loss ppo:  -0.01804, loss val: 0.04415
[2022-12-06 17:09:40,995] [INFO] [controller] EPOCH 3 loss ppo:  -0.02185, loss val: 0.04538
[2022-12-06 17:09:41,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.02424, loss val: 0.04585
[2022-12-06 17:09:41,107] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:09:41,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:09:41,355] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:09:49,932] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:09:58,591] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:10:09,533] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:10:18,480] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:10:27,370] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:10:35,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:10:46,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:10:55,623] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:11:05,198] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:11:13,843] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5355320676539073
[2022-12-06 17:11:13,844] [INFO] [runner_train_mujoco] Average state value: 0.6384050574302673
[2022-12-06 17:11:13,844] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 17:11:13,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01552, loss val: 0.04108
[2022-12-06 17:11:14,046] [INFO] [controller] EPOCH 2 loss ppo:  -0.01717, loss val: 0.04256
[2022-12-06 17:11:14,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.02023, loss val: 0.04127
[2022-12-06 17:11:14,212] [INFO] [controller] EPOCH 4 loss ppo:  -0.02270, loss val: 0.04071
[2022-12-06 17:11:14,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:11:14,495] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:11:14,496] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:11:23,192] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:11:33,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:11:43,769] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:11:53,258] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:12:02,409] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:12:11,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:12:21,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:12:29,485] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:12:37,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:12:46,820] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.607067162297389
[2022-12-06 17:12:46,821] [INFO] [runner_train_mujoco] Average state value: 0.639483975927035
[2022-12-06 17:12:46,821] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 17:12:46,902] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.04111
[2022-12-06 17:12:46,980] [INFO] [controller] EPOCH 2 loss ppo:  -0.01570, loss val: 0.04073
[2022-12-06 17:12:47,074] [INFO] [controller] EPOCH 3 loss ppo:  -0.01634, loss val: 0.04072
[2022-12-06 17:12:47,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.01718, loss val: 0.04101
[2022-12-06 17:12:47,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:12:47,364] [INFO] [optimize] Finished learning.
