[2022-12-06 20:57:52,337] [INFO] [optimize] Starting learning
[2022-12-06 20:57:52,346] [INFO] [optimize] Starting learning process..
[2022-12-06 20:57:52,406] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:57:52,406] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:57:58,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:58:04,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:58:11,915] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:58:17,684] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:58:23,657] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:58:29,077] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:58:34,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:58:41,268] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:58:47,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:58:52,785] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17057225012987703
[2022-12-06 20:58:52,785] [INFO] [runner_train_mujoco] Average state value: 0.2639726059921086
[2022-12-06 20:58:52,785] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 20:58:52,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.32184
[2022-12-06 20:58:52,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.02985, loss val: 0.28292
[2022-12-06 20:58:52,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.03613, loss val: 0.24764
[2022-12-06 20:58:53,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.03623, loss val: 0.21442
[2022-12-06 20:58:53,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:58:53,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:58:53,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:58:59,960] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:59:05,972] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:59:11,955] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:59:17,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:59:23,653] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:59:30,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:59:36,235] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:59:42,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:59:49,189] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:59:55,698] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.09405768567333021
[2022-12-06 20:59:55,698] [INFO] [runner_train_mujoco] Average state value: 0.4265929379379377
[2022-12-06 20:59:55,698] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 20:59:55,772] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.18650
[2022-12-06 20:59:55,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.02601, loss val: 0.16811
[2022-12-06 20:59:55,882] [INFO] [controller] EPOCH 3 loss ppo:  -0.03258, loss val: 0.15032
[2022-12-06 20:59:55,961] [INFO] [controller] EPOCH 4 loss ppo:  -0.03417, loss val: 0.13460
[2022-12-06 20:59:55,972] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:59:56,162] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:59:56,163] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:00:02,441] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:00:08,472] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:00:14,767] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:00:20,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:00:27,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:00:33,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:00:39,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:00:46,209] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:00:52,586] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:00:59,259] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17430043427243425
[2022-12-06 21:00:59,259] [INFO] [runner_train_mujoco] Average state value: 0.5621645924958091
[2022-12-06 21:00:59,260] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 21:00:59,346] [INFO] [controller] EPOCH 1 loss ppo:  -0.01166, loss val: 0.14091
[2022-12-06 21:00:59,407] [INFO] [controller] EPOCH 2 loss ppo:  -0.02527, loss val: 0.12640
[2022-12-06 21:00:59,467] [INFO] [controller] EPOCH 3 loss ppo:  -0.03153, loss val: 0.11351
[2022-12-06 21:00:59,522] [INFO] [controller] EPOCH 4 loss ppo:  -0.03641, loss val: 0.10292
[2022-12-06 21:00:59,536] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:00:59,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:00:59,732] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:01:05,767] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:01:12,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:01:18,885] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:01:24,925] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:01:31,166] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:01:37,971] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:01:45,062] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:01:51,295] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:01:57,636] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:02:03,998] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15099244004416695
[2022-12-06 21:02:03,998] [INFO] [runner_train_mujoco] Average state value: 0.6983445925141373
[2022-12-06 21:02:03,999] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 21:02:04,068] [INFO] [controller] EPOCH 1 loss ppo:  -0.01085, loss val: 0.09581
[2022-12-06 21:02:04,127] [INFO] [controller] EPOCH 2 loss ppo:  -0.02525, loss val: 0.08891
[2022-12-06 21:02:04,193] [INFO] [controller] EPOCH 3 loss ppo:  -0.02839, loss val: 0.08252
[2022-12-06 21:02:04,248] [INFO] [controller] EPOCH 4 loss ppo:  -0.03241, loss val: 0.07786
[2022-12-06 21:02:04,259] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:02:04,448] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:02:04,448] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:02:10,755] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:02:17,282] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:02:23,497] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:02:29,464] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:02:35,597] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:02:41,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:02:47,981] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:02:54,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:03:00,072] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:03:06,012] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.12522536685876176
[2022-12-06 21:03:06,012] [INFO] [runner_train_mujoco] Average state value: 0.7201331502000491
[2022-12-06 21:03:06,012] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 21:03:06,069] [INFO] [controller] EPOCH 1 loss ppo:  -0.01037, loss val: 0.07566
[2022-12-06 21:03:06,125] [INFO] [controller] EPOCH 2 loss ppo:  -0.02429, loss val: 0.07174
[2022-12-06 21:03:06,175] [INFO] [controller] EPOCH 3 loss ppo:  -0.02716, loss val: 0.06938
[2022-12-06 21:03:06,235] [INFO] [controller] EPOCH 4 loss ppo:  -0.02921, loss val: 0.06424
[2022-12-06 21:03:06,248] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:03:06,449] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:03:06,449] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:03:12,372] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:03:18,359] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:03:24,807] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:03:31,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:03:37,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:03:43,252] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:03:49,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:03:54,998] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:04:00,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:04:06,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18299980741244842
[2022-12-06 21:04:06,812] [INFO] [runner_train_mujoco] Average state value: 0.7403178527156512
[2022-12-06 21:04:06,812] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 21:04:06,899] [INFO] [controller] EPOCH 1 loss ppo:  -0.00873, loss val: 0.05733
[2022-12-06 21:04:06,950] [INFO] [controller] EPOCH 2 loss ppo:  -0.02409, loss val: 0.05658
[2022-12-06 21:04:06,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.02727, loss val: 0.05472
[2022-12-06 21:04:07,053] [INFO] [controller] EPOCH 4 loss ppo:  -0.02903, loss val: 0.05247
[2022-12-06 21:04:07,063] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:04:07,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:04:07,244] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:04:13,146] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:04:19,038] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:04:24,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:04:30,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:04:36,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:04:42,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:04:48,140] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:04:53,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:04:59,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:05:05,558] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2049809980914025
[2022-12-06 21:05:05,559] [INFO] [runner_train_mujoco] Average state value: 0.753408835808436
[2022-12-06 21:05:05,559] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 21:05:05,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.00877, loss val: 0.04934
[2022-12-06 21:05:05,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.01882, loss val: 0.04896
[2022-12-06 21:05:05,748] [INFO] [controller] EPOCH 3 loss ppo:  -0.02351, loss val: 0.04704
[2022-12-06 21:05:05,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.02800, loss val: 0.04609
[2022-12-06 21:05:05,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:05:05,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:05:05,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:05:11,789] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:05:17,776] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:05:23,544] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:05:29,326] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:05:34,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:05:40,992] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:05:47,018] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:05:52,737] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:05:58,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:06:04,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1999189587832387
[2022-12-06 21:06:04,215] [INFO] [runner_train_mujoco] Average state value: 0.7628343607385952
[2022-12-06 21:06:04,215] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 21:06:04,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.00876, loss val: 0.04365
[2022-12-06 21:06:04,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.01993, loss val: 0.04295
[2022-12-06 21:06:04,376] [INFO] [controller] EPOCH 3 loss ppo:  -0.02229, loss val: 0.04409
[2022-12-06 21:06:04,424] [INFO] [controller] EPOCH 4 loss ppo:  -0.02449, loss val: 0.04310
[2022-12-06 21:06:04,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:06:04,622] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:06:04,622] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:06:10,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:06:16,787] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:06:22,766] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:06:29,260] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:06:35,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:06:41,749] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:06:47,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:06:53,823] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:06:59,686] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:07:07,343] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15843366909143447
[2022-12-06 21:07:07,343] [INFO] [runner_train_mujoco] Average state value: 0.7687980451186498
[2022-12-06 21:07:07,343] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 21:07:07,406] [INFO] [controller] EPOCH 1 loss ppo:  -0.00734, loss val: 0.04704
[2022-12-06 21:07:07,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.01977, loss val: 0.04609
[2022-12-06 21:07:07,558] [INFO] [controller] EPOCH 3 loss ppo:  -0.02150, loss val: 0.04599
[2022-12-06 21:07:07,643] [INFO] [controller] EPOCH 4 loss ppo:  -0.02486, loss val: 0.04492
[2022-12-06 21:07:07,654] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:07:07,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:07:07,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:07:14,411] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:07:21,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:07:28,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:07:34,429] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:07:40,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:07:47,238] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:07:53,568] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:08:00,196] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:08:06,567] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:08:12,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19274591240665145
[2022-12-06 21:08:12,774] [INFO] [runner_train_mujoco] Average state value: 0.7376351584990819
[2022-12-06 21:08:12,774] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 21:08:12,864] [INFO] [controller] EPOCH 1 loss ppo:  -0.00923, loss val: 0.04075
[2022-12-06 21:08:12,923] [INFO] [controller] EPOCH 2 loss ppo:  -0.02351, loss val: 0.04338
[2022-12-06 21:08:12,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.02782, loss val: 0.04069
[2022-12-06 21:08:13,045] [INFO] [controller] EPOCH 4 loss ppo:  -0.02888, loss val: 0.04150
[2022-12-06 21:08:13,056] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:08:13,251] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:08:13,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:08:19,286] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:08:26,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:08:32,635] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:08:39,138] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:08:45,356] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:08:51,503] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:08:57,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:09:03,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:09:09,898] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:09:15,960] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2435535871680318
[2022-12-06 21:09:15,961] [INFO] [runner_train_mujoco] Average state value: 0.7018055661122005
[2022-12-06 21:09:15,961] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 21:09:16,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.00669, loss val: 0.03909
[2022-12-06 21:09:16,079] [INFO] [controller] EPOCH 2 loss ppo:  -0.01692, loss val: 0.03944
[2022-12-06 21:09:16,127] [INFO] [controller] EPOCH 3 loss ppo:  -0.02446, loss val: 0.03898
[2022-12-06 21:09:16,184] [INFO] [controller] EPOCH 4 loss ppo:  -0.02693, loss val: 0.03973
[2022-12-06 21:09:16,194] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:09:16,387] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:09:16,387] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:09:22,413] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:09:28,901] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:09:35,199] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:09:41,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:09:47,206] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:09:53,441] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:09:59,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:10:04,876] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:10:10,688] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:10:16,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42624282637614874
[2022-12-06 21:10:16,818] [INFO] [runner_train_mujoco] Average state value: 0.6779034406940141
[2022-12-06 21:10:16,818] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 21:10:16,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.00852, loss val: 0.04282
[2022-12-06 21:10:16,947] [INFO] [controller] EPOCH 2 loss ppo:  -0.01891, loss val: 0.04102
[2022-12-06 21:10:17,000] [INFO] [controller] EPOCH 3 loss ppo:  -0.02256, loss val: 0.04093
[2022-12-06 21:10:17,057] [INFO] [controller] EPOCH 4 loss ppo:  -0.03157, loss val: 0.04100
[2022-12-06 21:10:17,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:10:17,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:10:17,263] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:10:23,028] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:10:29,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:10:35,398] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:10:40,974] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:10:46,853] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:10:52,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:10:58,456] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:11:04,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:11:10,244] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:11:16,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.45714017513930816
[2022-12-06 21:11:16,331] [INFO] [runner_train_mujoco] Average state value: 0.7073052187363307
[2022-12-06 21:11:16,331] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 21:11:16,400] [INFO] [controller] EPOCH 1 loss ppo:  -0.00766, loss val: 0.04554
[2022-12-06 21:11:16,450] [INFO] [controller] EPOCH 2 loss ppo:  -0.01536, loss val: 0.04452
[2022-12-06 21:11:16,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.02253, loss val: 0.04329
[2022-12-06 21:11:16,544] [INFO] [controller] EPOCH 4 loss ppo:  -0.02681, loss val: 0.04411
[2022-12-06 21:11:16,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:11:16,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:11:16,731] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:11:22,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:11:28,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:11:34,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:11:40,590] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:11:46,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:11:51,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:11:57,765] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:12:03,423] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:12:09,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:12:15,255] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.32347789250901615
[2022-12-06 21:12:15,255] [INFO] [runner_train_mujoco] Average state value: 0.7811045135259628
[2022-12-06 21:12:15,255] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 21:12:15,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.00803, loss val: 0.04384
[2022-12-06 21:12:15,366] [INFO] [controller] EPOCH 2 loss ppo:  -0.02046, loss val: 0.04539
[2022-12-06 21:12:15,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.02604, loss val: 0.04415
[2022-12-06 21:12:15,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.02958, loss val: 0.04287
[2022-12-06 21:12:15,482] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:12:15,670] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:12:15,670] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:12:21,502] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:12:27,293] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:12:32,848] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:12:38,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:12:44,620] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:12:50,418] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:12:55,934] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:13:02,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:13:07,671] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:13:13,868] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4324044534603271
[2022-12-06 21:13:13,868] [INFO] [runner_train_mujoco] Average state value: 0.7444036692380906
[2022-12-06 21:13:13,868] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 21:13:13,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.00964, loss val: 0.04241
[2022-12-06 21:13:13,985] [INFO] [controller] EPOCH 2 loss ppo:  -0.02100, loss val: 0.04180
[2022-12-06 21:13:14,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.02517, loss val: 0.04227
[2022-12-06 21:13:14,083] [INFO] [controller] EPOCH 4 loss ppo:  -0.02787, loss val: 0.04297
[2022-12-06 21:13:14,094] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:13:14,286] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:13:14,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:13:20,588] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:13:26,427] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:13:32,040] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:13:37,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:13:43,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:13:49,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:13:56,090] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:14:02,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:14:08,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:14:14,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40549378661273405
[2022-12-06 21:14:14,047] [INFO] [runner_train_mujoco] Average state value: 0.6931228148539861
[2022-12-06 21:14:14,047] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 21:14:14,119] [INFO] [controller] EPOCH 1 loss ppo:  -0.00741, loss val: 0.04224
[2022-12-06 21:14:14,177] [INFO] [controller] EPOCH 2 loss ppo:  -0.01682, loss val: 0.04100
[2022-12-06 21:14:14,230] [INFO] [controller] EPOCH 3 loss ppo:  -0.02437, loss val: 0.04058
[2022-12-06 21:14:14,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.02880, loss val: 0.04095
[2022-12-06 21:14:14,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:14:14,490] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:14:14,491] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:14:20,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:14:26,382] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:14:32,249] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:14:38,632] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:14:44,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:14:51,341] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:14:57,703] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:15:04,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:15:10,799] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:15:17,027] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4193352722498568
[2022-12-06 21:15:17,028] [INFO] [runner_train_mujoco] Average state value: 0.6832561002572378
[2022-12-06 21:15:17,028] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 21:15:17,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.00769, loss val: 0.03846
[2022-12-06 21:15:17,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.01881, loss val: 0.03886
[2022-12-06 21:15:17,233] [INFO] [controller] EPOCH 3 loss ppo:  -0.02583, loss val: 0.03835
[2022-12-06 21:15:17,291] [INFO] [controller] EPOCH 4 loss ppo:  -0.02979, loss val: 0.03869
[2022-12-06 21:15:17,302] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:15:17,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:15:17,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:15:23,734] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:15:30,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:15:37,109] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:15:43,097] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:15:49,217] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:15:55,290] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:16:01,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:16:07,571] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:16:13,405] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:16:19,581] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47271507244042166
[2022-12-06 21:16:19,581] [INFO] [runner_train_mujoco] Average state value: 0.6763428201675414
[2022-12-06 21:16:19,581] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 21:16:19,638] [INFO] [controller] EPOCH 1 loss ppo:  -0.00962, loss val: 0.04023
[2022-12-06 21:16:19,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.01714, loss val: 0.04128
[2022-12-06 21:16:19,736] [INFO] [controller] EPOCH 3 loss ppo:  -0.02386, loss val: 0.04053
[2022-12-06 21:16:19,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.03047, loss val: 0.04048
[2022-12-06 21:16:19,795] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:16:19,975] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:16:19,975] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:16:25,740] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:16:32,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:16:38,107] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:16:44,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:16:50,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:16:56,228] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:17:02,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:17:07,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:17:13,740] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:17:19,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.721044853833237
[2022-12-06 21:17:19,667] [INFO] [runner_train_mujoco] Average state value: 0.6971378882924715
[2022-12-06 21:17:19,667] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 21:17:19,722] [INFO] [controller] EPOCH 1 loss ppo:  -0.01029, loss val: 0.04177
[2022-12-06 21:17:19,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.02684, loss val: 0.04212
[2022-12-06 21:17:19,822] [INFO] [controller] EPOCH 3 loss ppo:  -0.03045, loss val: 0.04156
[2022-12-06 21:17:19,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.03385, loss val: 0.04157
[2022-12-06 21:17:19,881] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:17:20,059] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:17:20,059] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:17:25,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:17:31,802] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:17:37,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:17:42,610] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:17:48,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:17:53,540] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:17:59,166] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:18:04,719] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:18:10,398] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:18:16,239] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9614393144238947
[2022-12-06 21:18:16,239] [INFO] [runner_train_mujoco] Average state value: 0.7113907657066981
[2022-12-06 21:18:16,240] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 21:18:16,309] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.04079
[2022-12-06 21:18:16,363] [INFO] [controller] EPOCH 2 loss ppo:  -0.01946, loss val: 0.04246
[2022-12-06 21:18:16,420] [INFO] [controller] EPOCH 3 loss ppo:  -0.02371, loss val: 0.04193
[2022-12-06 21:18:16,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.02921, loss val: 0.04183
[2022-12-06 21:18:16,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:18:16,666] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:18:16,666] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:18:21,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:18:27,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:18:33,552] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:18:39,503] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:18:45,150] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:18:51,157] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:18:56,814] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:19:02,480] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:19:08,068] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:19:13,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.141952107339185
[2022-12-06 21:19:13,760] [INFO] [runner_train_mujoco] Average state value: 0.6837462073167165
[2022-12-06 21:19:13,760] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 21:19:13,819] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04048
[2022-12-06 21:19:13,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.02364, loss val: 0.03908
[2022-12-06 21:19:13,920] [INFO] [controller] EPOCH 3 loss ppo:  -0.02736, loss val: 0.03787
[2022-12-06 21:19:13,970] [INFO] [controller] EPOCH 4 loss ppo:  -0.03389, loss val: 0.03740
[2022-12-06 21:19:13,980] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:19:14,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:19:14,169] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:19:19,962] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:19:25,998] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:19:31,988] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:19:37,392] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:19:43,151] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:19:49,012] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:19:54,980] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:20:00,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:20:06,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:20:12,213] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0811772578247043
[2022-12-06 21:20:12,214] [INFO] [runner_train_mujoco] Average state value: 0.6176663914720217
[2022-12-06 21:20:12,214] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 21:20:12,282] [INFO] [controller] EPOCH 1 loss ppo:  -0.01121, loss val: 0.04584
[2022-12-06 21:20:12,332] [INFO] [controller] EPOCH 2 loss ppo:  -0.02202, loss val: 0.04777
[2022-12-06 21:20:12,388] [INFO] [controller] EPOCH 3 loss ppo:  -0.02717, loss val: 0.04568
[2022-12-06 21:20:12,441] [INFO] [controller] EPOCH 4 loss ppo:  -0.03203, loss val: 0.04454
[2022-12-06 21:20:12,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:20:12,643] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:20:12,643] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:20:18,283] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:20:24,101] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:20:30,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:20:36,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:20:42,119] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:20:47,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:20:53,852] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:20:59,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:21:05,377] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:21:11,229] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2594069207819913
[2022-12-06 21:21:11,229] [INFO] [runner_train_mujoco] Average state value: 0.6412191416621209
[2022-12-06 21:21:11,229] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 21:21:11,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01473, loss val: 0.03928
[2022-12-06 21:21:11,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.02690, loss val: 0.03918
[2022-12-06 21:21:11,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.02994, loss val: 0.03985
[2022-12-06 21:21:11,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.03857, loss val: 0.03981
[2022-12-06 21:21:11,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:21:11,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:21:11,766] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:21:17,853] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:21:23,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:21:30,093] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:21:36,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:21:42,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:21:48,312] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:21:54,527] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:22:00,885] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:22:06,972] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:22:12,961] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3601433038248496
[2022-12-06 21:22:12,961] [INFO] [runner_train_mujoco] Average state value: 0.6618834877411524
[2022-12-06 21:22:12,962] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 21:22:13,034] [INFO] [controller] EPOCH 1 loss ppo:  -0.00859, loss val: 0.04198
[2022-12-06 21:22:13,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.01736, loss val: 0.04103
[2022-12-06 21:22:13,152] [INFO] [controller] EPOCH 3 loss ppo:  -0.02873, loss val: 0.04079
[2022-12-06 21:22:13,275] [INFO] [controller] EPOCH 4 loss ppo:  -0.02898, loss val: 0.03972
[2022-12-06 21:22:13,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:22:13,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:22:13,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:22:19,865] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:22:25,993] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:22:32,376] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:22:38,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:22:44,149] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:22:50,160] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:22:56,010] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:23:01,903] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:23:07,958] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:23:13,941] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5252906069256835
[2022-12-06 21:23:13,941] [INFO] [runner_train_mujoco] Average state value: 0.6863238120675088
[2022-12-06 21:23:13,941] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 21:23:14,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04360
[2022-12-06 21:23:14,072] [INFO] [controller] EPOCH 2 loss ppo:  -0.02436, loss val: 0.04293
[2022-12-06 21:23:14,149] [INFO] [controller] EPOCH 3 loss ppo:  -0.02729, loss val: 0.04278
[2022-12-06 21:23:14,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.03540, loss val: 0.04276
[2022-12-06 21:23:14,229] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:23:14,416] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:23:14,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:23:20,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:23:26,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:23:32,594] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:23:38,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:23:43,603] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:23:49,649] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:23:55,402] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:24:00,762] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:24:06,093] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:24:11,943] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.538117494745713
[2022-12-06 21:24:11,943] [INFO] [runner_train_mujoco] Average state value: 0.7123350098530452
[2022-12-06 21:24:11,943] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 21:24:12,032] [INFO] [controller] EPOCH 1 loss ppo:  -0.01215, loss val: 0.04795
[2022-12-06 21:24:12,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.02060, loss val: 0.04777
[2022-12-06 21:24:12,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.02933, loss val: 0.04799
[2022-12-06 21:24:12,194] [INFO] [controller] EPOCH 4 loss ppo:  -0.03246, loss val: 0.04800
[2022-12-06 21:24:12,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:24:12,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:24:12,394] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:24:18,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:24:24,272] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:24:30,274] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:24:35,827] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:24:41,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:24:46,969] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:24:52,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:24:58,377] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:25:03,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:25:09,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7640586650897365
[2022-12-06 21:25:09,118] [INFO] [runner_train_mujoco] Average state value: 0.7007393763065337
[2022-12-06 21:25:09,118] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 21:25:09,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.04473
[2022-12-06 21:25:09,223] [INFO] [controller] EPOCH 2 loss ppo:  -0.01995, loss val: 0.04247
[2022-12-06 21:25:09,270] [INFO] [controller] EPOCH 3 loss ppo:  -0.02572, loss val: 0.04162
[2022-12-06 21:25:09,322] [INFO] [controller] EPOCH 4 loss ppo:  -0.03207, loss val: 0.04112
[2022-12-06 21:25:09,332] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:25:09,509] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:25:09,509] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:25:14,842] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:25:20,465] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:25:26,184] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:25:31,592] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:25:36,823] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:25:42,320] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:25:47,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:25:52,893] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:25:58,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:26:04,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9275200779684067
[2022-12-06 21:26:04,339] [INFO] [runner_train_mujoco] Average state value: 0.6431773373683293
[2022-12-06 21:26:04,339] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 21:26:04,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04150
[2022-12-06 21:26:04,451] [INFO] [controller] EPOCH 2 loss ppo:  -0.02031, loss val: 0.04136
[2022-12-06 21:26:04,500] [INFO] [controller] EPOCH 3 loss ppo:  -0.02495, loss val: 0.04238
[2022-12-06 21:26:04,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.03002, loss val: 0.04125
[2022-12-06 21:26:04,557] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:26:04,734] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:26:04,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:26:11,778] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:26:17,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:26:22,269] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:26:27,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:26:33,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:26:38,867] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:26:44,154] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:26:49,344] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:26:54,522] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:26:59,761] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.859973125186946
[2022-12-06 21:26:59,761] [INFO] [runner_train_mujoco] Average state value: 0.6353909239371618
[2022-12-06 21:26:59,761] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 21:26:59,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04190
[2022-12-06 21:26:59,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.02120, loss val: 0.04163
[2022-12-06 21:26:59,936] [INFO] [controller] EPOCH 3 loss ppo:  -0.02397, loss val: 0.04243
[2022-12-06 21:26:59,987] [INFO] [controller] EPOCH 4 loss ppo:  -0.03127, loss val: 0.04197
[2022-12-06 21:26:59,999] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:27:00,185] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:27:00,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:27:05,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:27:11,427] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:27:16,785] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:27:22,652] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:27:28,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:27:33,707] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:27:39,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:27:44,970] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:27:50,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:27:56,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9909061548164224
[2022-12-06 21:27:56,304] [INFO] [runner_train_mujoco] Average state value: 0.6542157244682312
[2022-12-06 21:27:56,304] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 21:27:56,371] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.04237
[2022-12-06 21:27:56,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.01677, loss val: 0.04132
[2022-12-06 21:27:56,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.02096, loss val: 0.04108
[2022-12-06 21:27:56,557] [INFO] [controller] EPOCH 4 loss ppo:  -0.03200, loss val: 0.04159
[2022-12-06 21:27:56,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:27:56,754] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:27:56,754] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:28:02,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:28:07,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:28:13,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:28:19,119] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:28:24,894] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:28:30,000] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:28:35,610] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:28:41,138] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:28:46,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:28:52,788] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0323839557845838
[2022-12-06 21:28:52,789] [INFO] [runner_train_mujoco] Average state value: 0.6751516754428546
[2022-12-06 21:28:52,789] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 21:28:52,853] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.04208
[2022-12-06 21:28:52,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.01443, loss val: 0.04308
[2022-12-06 21:28:52,965] [INFO] [controller] EPOCH 3 loss ppo:  -0.02344, loss val: 0.04130
[2022-12-06 21:28:53,017] [INFO] [controller] EPOCH 4 loss ppo:  -0.02761, loss val: 0.04221
[2022-12-06 21:28:53,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:28:53,215] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:28:53,215] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:28:59,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:29:05,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:29:10,727] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:29:16,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:29:21,603] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:29:27,623] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:29:33,312] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:29:39,420] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:29:45,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:29:50,771] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.964206917681027
[2022-12-06 21:29:50,771] [INFO] [runner_train_mujoco] Average state value: 0.6902912244002024
[2022-12-06 21:29:50,771] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 21:29:50,838] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.04426
[2022-12-06 21:29:50,889] [INFO] [controller] EPOCH 2 loss ppo:  -0.02556, loss val: 0.04440
[2022-12-06 21:29:50,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.02674, loss val: 0.04481
[2022-12-06 21:29:51,001] [INFO] [controller] EPOCH 4 loss ppo:  -0.03442, loss val: 0.04349
[2022-12-06 21:29:51,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:29:51,205] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:29:51,205] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:29:57,339] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:30:03,116] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:30:09,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:30:14,911] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:30:20,470] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:30:26,632] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:30:32,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:30:38,579] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:30:44,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:30:50,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.024297336330724
[2022-12-06 21:30:50,327] [INFO] [runner_train_mujoco] Average state value: 0.670312114795049
[2022-12-06 21:30:50,328] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 21:30:50,402] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04338
[2022-12-06 21:30:50,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.02081, loss val: 0.04397
[2022-12-06 21:30:50,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.02526, loss val: 0.04249
[2022-12-06 21:30:50,571] [INFO] [controller] EPOCH 4 loss ppo:  -0.03110, loss val: 0.04217
[2022-12-06 21:30:50,582] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:30:50,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:30:50,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:30:56,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:31:02,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:31:08,698] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:31:14,329] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:31:20,156] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:31:25,775] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:31:31,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:31:37,306] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:31:43,407] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:31:49,267] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.067673100654416
[2022-12-06 21:31:49,267] [INFO] [runner_train_mujoco] Average state value: 0.6704604563713075
[2022-12-06 21:31:49,268] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 21:31:49,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04116
[2022-12-06 21:31:49,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.02447, loss val: 0.04109
[2022-12-06 21:31:49,439] [INFO] [controller] EPOCH 3 loss ppo:  -0.02884, loss val: 0.04085
[2022-12-06 21:31:49,486] [INFO] [controller] EPOCH 4 loss ppo:  -0.03426, loss val: 0.04078
[2022-12-06 21:31:49,496] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:31:49,675] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:31:49,676] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:31:55,253] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:32:01,378] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:32:06,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:32:12,171] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:32:17,866] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:32:23,533] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:32:29,141] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:32:34,704] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:32:40,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:32:45,879] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1820959027367537
[2022-12-06 21:32:45,879] [INFO] [runner_train_mujoco] Average state value: 0.6691342625220617
[2022-12-06 21:32:45,880] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 21:32:45,955] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04186
[2022-12-06 21:32:46,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.01690, loss val: 0.04174
[2022-12-06 21:32:46,072] [INFO] [controller] EPOCH 3 loss ppo:  -0.02067, loss val: 0.04191
[2022-12-06 21:32:46,137] [INFO] [controller] EPOCH 4 loss ppo:  -0.02831, loss val: 0.04175
[2022-12-06 21:32:46,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:32:46,359] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:32:46,360] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:32:52,655] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:32:58,604] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:33:04,928] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:33:12,062] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:33:17,913] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:33:23,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:33:29,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:33:35,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:33:41,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:33:47,393] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2826472846086814
[2022-12-06 21:33:47,394] [INFO] [runner_train_mujoco] Average state value: 0.657522271792094
[2022-12-06 21:33:47,394] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 21:33:47,541] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.04257
[2022-12-06 21:33:47,608] [INFO] [controller] EPOCH 2 loss ppo:  -0.01921, loss val: 0.04303
[2022-12-06 21:33:47,680] [INFO] [controller] EPOCH 3 loss ppo:  -0.02363, loss val: 0.04300
[2022-12-06 21:33:47,731] [INFO] [controller] EPOCH 4 loss ppo:  -0.02852, loss val: 0.04252
[2022-12-06 21:33:47,742] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:33:47,923] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:33:47,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:33:53,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:33:59,904] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:34:06,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:34:12,810] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:34:18,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:34:24,872] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:34:31,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:34:37,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:34:43,331] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:34:49,120] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.234744325514577
[2022-12-06 21:34:49,120] [INFO] [runner_train_mujoco] Average state value: 0.6584464616974196
[2022-12-06 21:34:49,120] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 21:34:49,207] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.04811
[2022-12-06 21:34:49,257] [INFO] [controller] EPOCH 2 loss ppo:  -0.01953, loss val: 0.04705
[2022-12-06 21:34:49,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.02150, loss val: 0.04694
[2022-12-06 21:34:49,381] [INFO] [controller] EPOCH 4 loss ppo:  -0.02913, loss val: 0.04717
[2022-12-06 21:34:49,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:34:49,576] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:34:49,576] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:34:55,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:35:01,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:35:07,831] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:35:13,752] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:35:20,096] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:35:26,253] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:35:32,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:35:38,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:35:44,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:35:50,893] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.283152723435373
[2022-12-06 21:35:50,894] [INFO] [runner_train_mujoco] Average state value: 0.668795654753844
[2022-12-06 21:35:50,894] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 21:35:50,980] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.04186
[2022-12-06 21:35:51,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.01546, loss val: 0.04206
[2022-12-06 21:35:51,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.01897, loss val: 0.04215
[2022-12-06 21:35:51,189] [INFO] [controller] EPOCH 4 loss ppo:  -0.02803, loss val: 0.04353
[2022-12-06 21:35:51,200] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:35:51,395] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:35:51,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:35:57,665] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:36:04,122] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:36:10,167] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:36:16,230] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:36:22,048] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:36:28,483] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:36:34,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:36:41,542] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:36:47,823] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:36:54,238] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3881888808656266
[2022-12-06 21:36:54,238] [INFO] [runner_train_mujoco] Average state value: 0.6721354097127915
[2022-12-06 21:36:54,239] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 21:36:54,314] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04495
[2022-12-06 21:36:54,372] [INFO] [controller] EPOCH 2 loss ppo:  -0.01558, loss val: 0.04502
[2022-12-06 21:36:54,431] [INFO] [controller] EPOCH 3 loss ppo:  -0.01500, loss val: 0.04485
[2022-12-06 21:36:54,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.02727, loss val: 0.04594
[2022-12-06 21:36:54,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:36:54,706] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:36:54,706] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:37:00,844] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:37:07,743] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:37:14,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:37:20,874] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:37:27,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:37:33,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:37:40,275] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:37:47,020] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:37:53,325] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:38:00,258] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.222067589588305
[2022-12-06 21:38:00,258] [INFO] [runner_train_mujoco] Average state value: 0.6777685263951618
[2022-12-06 21:38:00,258] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 21:38:00,388] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04564
[2022-12-06 21:38:00,451] [INFO] [controller] EPOCH 2 loss ppo:  -0.01858, loss val: 0.04559
[2022-12-06 21:38:00,520] [INFO] [controller] EPOCH 3 loss ppo:  -0.02064, loss val: 0.04587
[2022-12-06 21:38:00,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.02580, loss val: 0.04591
[2022-12-06 21:38:00,625] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:38:00,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:38:00,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:38:07,416] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:38:14,158] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:38:20,275] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:38:26,481] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:38:32,730] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:38:39,125] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:38:45,640] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:38:52,089] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:38:58,229] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:39:04,140] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.360228091570984
[2022-12-06 21:39:04,140] [INFO] [runner_train_mujoco] Average state value: 0.6778484983444214
[2022-12-06 21:39:04,140] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 21:39:04,212] [INFO] [controller] EPOCH 1 loss ppo:  -0.01526, loss val: 0.04394
[2022-12-06 21:39:04,284] [INFO] [controller] EPOCH 2 loss ppo:  -0.01713, loss val: 0.04363
[2022-12-06 21:39:04,335] [INFO] [controller] EPOCH 3 loss ppo:  -0.01810, loss val: 0.04372
[2022-12-06 21:39:04,412] [INFO] [controller] EPOCH 4 loss ppo:  -0.02564, loss val: 0.04386
[2022-12-06 21:39:04,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:39:04,622] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:39:04,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:39:10,820] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:39:17,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:39:23,104] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:39:29,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:39:35,349] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:39:41,712] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:39:47,948] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:39:53,983] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:39:59,946] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:40:05,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3903596110714993
[2022-12-06 21:40:05,818] [INFO] [runner_train_mujoco] Average state value: 0.678043043911457
[2022-12-06 21:40:05,819] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 21:40:05,910] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04512
[2022-12-06 21:40:05,993] [INFO] [controller] EPOCH 2 loss ppo:  -0.01539, loss val: 0.04499
[2022-12-06 21:40:06,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.02116, loss val: 0.04499
[2022-12-06 21:40:06,135] [INFO] [controller] EPOCH 4 loss ppo:  -0.02851, loss val: 0.04510
[2022-12-06 21:40:06,146] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:40:06,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:40:06,342] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:40:12,334] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:40:18,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:40:23,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:40:29,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:40:37,225] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:40:49,832] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:42:40,118] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:42:55,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:43:06,222] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:43:16,155] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3540056343161977
[2022-12-06 21:43:16,156] [INFO] [runner_train_mujoco] Average state value: 0.6786448734998702
[2022-12-06 21:43:16,156] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 21:43:16,321] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.04796
[2022-12-06 21:43:16,429] [INFO] [controller] EPOCH 2 loss ppo:  -0.01815, loss val: 0.04749
[2022-12-06 21:43:16,550] [INFO] [controller] EPOCH 3 loss ppo:  -0.01738, loss val: 0.04628
[2022-12-06 21:43:16,641] [INFO] [controller] EPOCH 4 loss ppo:  -0.02401, loss val: 0.04626
[2022-12-06 21:43:16,655] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:43:16,900] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:43:16,900] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:43:26,969] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:43:37,895] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:43:46,705] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:43:56,257] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:44:03,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:44:11,274] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:44:18,783] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:44:26,203] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:44:33,596] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:44:41,281] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4121021516986065
[2022-12-06 21:44:41,281] [INFO] [runner_train_mujoco] Average state value: 0.6824569242000579
[2022-12-06 21:44:41,281] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 21:44:41,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01262, loss val: 0.04522
[2022-12-06 21:44:41,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.01350, loss val: 0.04570
[2022-12-06 21:44:41,550] [INFO] [controller] EPOCH 3 loss ppo:  -0.01738, loss val: 0.04544
[2022-12-06 21:44:41,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.02257, loss val: 0.04531
[2022-12-06 21:44:41,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:44:41,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:44:41,905] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:44:49,287] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:44:57,855] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:45:05,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:45:13,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:45:20,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:45:27,966] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:45:35,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:45:42,955] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:45:50,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:45:57,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.468048894628072
[2022-12-06 21:45:57,065] [INFO] [runner_train_mujoco] Average state value: 0.6743063364426295
[2022-12-06 21:45:57,066] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 21:45:57,156] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.04062
[2022-12-06 21:45:57,220] [INFO] [controller] EPOCH 2 loss ppo:  -0.01763, loss val: 0.04205
[2022-12-06 21:45:57,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.01862, loss val: 0.04147
[2022-12-06 21:45:57,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.02455, loss val: 0.04058
[2022-12-06 21:45:57,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:45:57,605] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:45:57,606] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:46:05,090] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:46:12,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:46:19,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:46:27,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:46:34,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:46:42,464] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:46:49,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:46:57,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:47:04,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:47:12,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4662575196048917
[2022-12-06 21:47:12,056] [INFO] [runner_train_mujoco] Average state value: 0.6447472374240556
[2022-12-06 21:47:12,056] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 21:47:12,167] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04571
[2022-12-06 21:47:12,243] [INFO] [controller] EPOCH 2 loss ppo:  -0.01949, loss val: 0.04576
[2022-12-06 21:47:12,337] [INFO] [controller] EPOCH 3 loss ppo:  -0.02440, loss val: 0.04600
[2022-12-06 21:47:12,399] [INFO] [controller] EPOCH 4 loss ppo:  -0.02941, loss val: 0.04576
[2022-12-06 21:47:12,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:47:12,662] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:47:12,662] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:47:19,693] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:47:26,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:47:34,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:47:41,390] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:47:48,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:47:56,150] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:48:04,143] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:48:11,550] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:48:18,866] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:48:26,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.43863652053201
[2022-12-06 21:48:26,567] [INFO] [runner_train_mujoco] Average state value: 0.64676369202137
[2022-12-06 21:48:26,567] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 21:48:26,642] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.04568
[2022-12-06 21:48:26,706] [INFO] [controller] EPOCH 2 loss ppo:  -0.01410, loss val: 0.04520
[2022-12-06 21:48:26,836] [INFO] [controller] EPOCH 3 loss ppo:  -0.01825, loss val: 0.04463
[2022-12-06 21:48:26,935] [INFO] [controller] EPOCH 4 loss ppo:  -0.02375, loss val: 0.04485
[2022-12-06 21:48:26,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:48:27,157] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:48:27,158] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:48:34,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:48:41,629] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:48:48,831] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:48:55,840] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:49:02,870] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:49:10,330] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:49:17,616] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:49:24,823] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:49:32,846] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:49:40,141] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5182594003307734
[2022-12-06 21:49:40,141] [INFO] [runner_train_mujoco] Average state value: 0.6629699077606201
[2022-12-06 21:49:40,141] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 21:49:40,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01281, loss val: 0.04479
[2022-12-06 21:49:40,278] [INFO] [controller] EPOCH 2 loss ppo:  -0.01556, loss val: 0.04461
[2022-12-06 21:49:40,340] [INFO] [controller] EPOCH 3 loss ppo:  -0.01795, loss val: 0.04446
[2022-12-06 21:49:40,405] [INFO] [controller] EPOCH 4 loss ppo:  -0.02350, loss val: 0.04447
[2022-12-06 21:49:40,418] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:49:40,620] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:49:40,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:49:48,512] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:49:58,097] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:50:05,743] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:50:15,987] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:50:25,209] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:50:34,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:50:43,519] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:50:52,668] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:51:01,988] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:51:11,121] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.503330596977871
[2022-12-06 21:51:11,121] [INFO] [runner_train_mujoco] Average state value: 0.6739111510515212
[2022-12-06 21:51:11,121] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 21:51:11,255] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.04736
[2022-12-06 21:51:11,342] [INFO] [controller] EPOCH 2 loss ppo:  -0.01603, loss val: 0.04621
[2022-12-06 21:51:11,444] [INFO] [controller] EPOCH 3 loss ppo:  -0.01964, loss val: 0.04607
[2022-12-06 21:51:11,548] [INFO] [controller] EPOCH 4 loss ppo:  -0.02389, loss val: 0.04667
[2022-12-06 21:51:11,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:51:11,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:51:11,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:51:20,894] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:51:29,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:51:38,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:51:47,681] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:51:56,974] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:52:05,542] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:52:14,213] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:52:22,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:52:32,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:52:41,002] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.592565801376972
[2022-12-06 21:52:41,002] [INFO] [runner_train_mujoco] Average state value: 0.6721304535468419
[2022-12-06 21:52:41,003] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 21:52:41,162] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04689
[2022-12-06 21:52:41,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.01703, loss val: 0.04605
[2022-12-06 21:52:41,369] [INFO] [controller] EPOCH 3 loss ppo:  -0.01827, loss val: 0.04626
[2022-12-06 21:52:41,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.02261, loss val: 0.04619
[2022-12-06 21:52:41,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:52:41,730] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:52:41,730] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:52:50,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:52:59,005] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:53:08,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:53:16,922] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:53:26,394] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:53:34,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:53:42,180] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:53:49,964] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:53:57,373] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:54:05,024] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.515630976136854
[2022-12-06 21:54:05,025] [INFO] [runner_train_mujoco] Average state value: 0.6705248728990555
[2022-12-06 21:54:05,025] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 21:54:05,105] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04561
[2022-12-06 21:54:05,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.01575, loss val: 0.04534
[2022-12-06 21:54:05,361] [INFO] [controller] EPOCH 3 loss ppo:  -0.01634, loss val: 0.04546
[2022-12-06 21:54:05,431] [INFO] [controller] EPOCH 4 loss ppo:  -0.01851, loss val: 0.04540
[2022-12-06 21:54:05,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:54:05,655] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:54:05,656] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:54:13,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:54:20,863] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:54:28,272] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:54:35,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:54:43,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:54:50,388] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:54:58,087] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:55:05,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:55:13,051] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:55:20,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.609384385712939
[2022-12-06 21:55:20,098] [INFO] [runner_train_mujoco] Average state value: 0.6663582273523013
[2022-12-06 21:55:20,099] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 21:55:20,184] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.04548
[2022-12-06 21:55:20,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.01665, loss val: 0.04509
[2022-12-06 21:55:20,328] [INFO] [controller] EPOCH 3 loss ppo:  -0.01619, loss val: 0.04441
[2022-12-06 21:55:20,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.01805, loss val: 0.04438
[2022-12-06 21:55:20,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:55:20,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:55:20,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:55:27,050] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:55:34,204] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:55:40,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:55:47,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:55:54,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:56:01,372] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:56:07,939] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:56:14,354] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:56:20,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:56:28,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.589617655209094
[2022-12-06 21:56:28,885] [INFO] [runner_train_mujoco] Average state value: 0.6537354201078415
[2022-12-06 21:56:28,885] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 21:56:29,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.04684
[2022-12-06 21:56:29,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.01622, loss val: 0.04748
[2022-12-06 21:56:29,857] [INFO] [controller] EPOCH 3 loss ppo:  -0.01993, loss val: 0.04675
[2022-12-06 21:56:30,122] [INFO] [controller] EPOCH 4 loss ppo:  -0.02247, loss val: 0.04701
[2022-12-06 21:56:30,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:56:30,471] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:56:30,471] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:56:41,112] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:56:49,538] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:56:57,619] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:57:05,930] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:57:14,628] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:57:22,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:57:30,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:57:38,500] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:57:46,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:57:54,187] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.614677358499242
[2022-12-06 21:57:54,187] [INFO] [runner_train_mujoco] Average state value: 0.6529923392534257
[2022-12-06 21:57:54,188] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 21:57:54,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.04578
[2022-12-06 21:57:54,363] [INFO] [controller] EPOCH 2 loss ppo:  -0.01638, loss val: 0.04577
[2022-12-06 21:57:54,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.02009, loss val: 0.04574
[2022-12-06 21:57:54,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.02230, loss val: 0.04532
[2022-12-06 21:57:54,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:57:54,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:57:54,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:58:02,645] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:58:12,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:58:20,495] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:58:28,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:58:36,733] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:58:44,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:58:52,741] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:59:01,298] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:59:09,951] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:59:17,899] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6654700477724496
[2022-12-06 21:59:17,899] [INFO] [runner_train_mujoco] Average state value: 0.6554442662596703
[2022-12-06 21:59:17,899] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 21:59:17,998] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.04588
[2022-12-06 21:59:18,070] [INFO] [controller] EPOCH 2 loss ppo:  -0.01563, loss val: 0.04542
[2022-12-06 21:59:18,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.01879, loss val: 0.04590
[2022-12-06 21:59:18,259] [INFO] [controller] EPOCH 4 loss ppo:  -0.02235, loss val: 0.04536
[2022-12-06 21:59:18,273] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:59:18,522] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:59:18,522] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:59:26,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:59:34,946] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:59:43,084] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:59:51,243] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:59:59,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 22:00:07,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 22:00:16,102] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 22:00:24,359] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 22:00:32,423] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 22:00:40,513] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.683659743860866
[2022-12-06 22:00:40,514] [INFO] [runner_train_mujoco] Average state value: 0.6555766045252482
[2022-12-06 22:00:40,514] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 22:00:40,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.04641
[2022-12-06 22:00:40,701] [INFO] [controller] EPOCH 2 loss ppo:  -0.01368, loss val: 0.04652
[2022-12-06 22:00:40,775] [INFO] [controller] EPOCH 3 loss ppo:  -0.01453, loss val: 0.04651
[2022-12-06 22:00:40,869] [INFO] [controller] EPOCH 4 loss ppo:  -0.01580, loss val: 0.04669
[2022-12-06 22:00:40,884] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 22:00:41,111] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 22:00:41,112] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 22:00:49,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 22:00:58,356] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 22:01:06,962] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 22:01:14,548] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 22:01:22,188] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 22:01:29,855] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 22:01:37,702] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 22:01:45,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 22:01:53,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 22:02:01,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7102505672234765
[2022-12-06 22:02:01,665] [INFO] [runner_train_mujoco] Average state value: 0.6582086319526037
[2022-12-06 22:02:01,666] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 22:02:01,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.04671
[2022-12-06 22:02:01,850] [INFO] [controller] EPOCH 2 loss ppo:  -0.01350, loss val: 0.04703
[2022-12-06 22:02:01,925] [INFO] [controller] EPOCH 3 loss ppo:  -0.01418, loss val: 0.04580
[2022-12-06 22:02:01,998] [INFO] [controller] EPOCH 4 loss ppo:  -0.01521, loss val: 0.04613
[2022-12-06 22:02:02,014] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 22:02:02,252] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 22:02:02,252] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 22:02:10,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 22:02:19,052] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 22:02:27,110] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 22:02:35,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 22:02:42,674] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 22:02:50,372] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 22:02:58,133] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 22:03:06,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 22:03:14,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:03:22,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6644735993643183
[2022-12-06 23:03:22,573] [INFO] [runner_train_mujoco] Average state value: 0.660551915049553
[2022-12-06 23:03:22,573] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 23:03:22,962] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.04423
[2022-12-06 23:03:23,079] [INFO] [controller] EPOCH 2 loss ppo:  -0.01370, loss val: 0.04416
[2022-12-06 23:03:23,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.01420, loss val: 0.04344
[2022-12-06 23:03:23,620] [INFO] [controller] EPOCH 4 loss ppo:  -0.01482, loss val: 0.04344
[2022-12-06 23:03:23,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:03:23,911] [INFO] [optimize] Finished learning.
