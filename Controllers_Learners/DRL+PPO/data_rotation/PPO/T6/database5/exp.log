[2022-12-07 00:36:34,423] [INFO] [optimize] Starting learning
[2022-12-07 00:36:34,429] [INFO] [optimize] Starting learning process..
[2022-12-07 00:36:34,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:36:34,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:36:42,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:36:48,839] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:36:55,022] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:37:00,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:37:07,367] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:37:13,824] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:37:20,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:37:26,071] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:37:32,524] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:37:38,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14847219664028558
[2022-12-07 00:37:38,696] [INFO] [runner_train_mujoco] Average state value: -0.08141299045830966
[2022-12-07 00:37:38,696] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 00:37:38,770] [INFO] [controller] EPOCH 1 loss ppo:  -0.01602, loss val: 0.49187
[2022-12-07 00:37:38,824] [INFO] [controller] EPOCH 2 loss ppo:  -0.02929, loss val: 0.43861
[2022-12-07 00:37:38,880] [INFO] [controller] EPOCH 3 loss ppo:  -0.03370, loss val: 0.38063
[2022-12-07 00:37:38,932] [INFO] [controller] EPOCH 4 loss ppo:  -0.03682, loss val: 0.34481
[2022-12-07 00:37:38,943] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:37:39,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:37:39,127] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:37:45,540] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:37:52,043] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:37:58,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:38:04,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:38:11,232] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:38:17,240] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:38:23,594] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:38:29,560] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:38:35,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:38:41,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16393117533706958
[2022-12-07 00:38:41,841] [INFO] [runner_train_mujoco] Average state value: 0.09483873372214535
[2022-12-07 00:38:41,841] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 00:38:41,901] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.28798
[2022-12-07 00:38:41,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.02818, loss val: 0.26497
[2022-12-07 00:38:42,020] [INFO] [controller] EPOCH 3 loss ppo:  -0.03213, loss val: 0.21641
[2022-12-07 00:38:42,069] [INFO] [controller] EPOCH 4 loss ppo:  -0.03712, loss val: 0.18766
[2022-12-07 00:38:42,080] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:38:42,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:38:42,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:38:48,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:38:54,736] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:39:01,040] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:39:07,658] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:39:14,107] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:39:20,735] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:39:27,428] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:39:33,303] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:39:39,685] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:39:46,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18591400903409258
[2022-12-07 00:39:46,118] [INFO] [runner_train_mujoco] Average state value: 0.22198909462740027
[2022-12-07 00:39:46,118] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 00:39:46,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.01217, loss val: 0.21705
[2022-12-07 00:39:46,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.02354, loss val: 0.19122
[2022-12-07 00:39:46,328] [INFO] [controller] EPOCH 3 loss ppo:  -0.03164, loss val: 0.16324
[2022-12-07 00:39:46,379] [INFO] [controller] EPOCH 4 loss ppo:  -0.03699, loss val: 0.13811
[2022-12-07 00:39:46,390] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:39:46,579] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:39:46,580] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:39:53,002] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:40:00,033] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:40:07,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:40:13,797] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:40:20,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:40:27,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:40:33,829] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:40:40,256] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:40:46,961] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:40:52,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19204691763337167
[2022-12-07 00:40:52,981] [INFO] [runner_train_mujoco] Average state value: 0.41222359862426916
[2022-12-07 00:40:52,981] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 00:40:53,044] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.12072
[2022-12-07 00:40:53,110] [INFO] [controller] EPOCH 2 loss ppo:  -0.02614, loss val: 0.10827
[2022-12-07 00:40:53,161] [INFO] [controller] EPOCH 3 loss ppo:  -0.03043, loss val: 0.08857
[2022-12-07 00:40:53,217] [INFO] [controller] EPOCH 4 loss ppo:  -0.03433, loss val: 0.07649
[2022-12-07 00:40:53,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:40:53,440] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:40:53,441] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:41:00,475] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:41:07,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:41:13,739] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:41:19,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:41:26,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:41:33,064] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:41:39,549] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:41:46,239] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:41:52,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:41:59,185] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18630294873350742
[2022-12-07 00:41:59,186] [INFO] [runner_train_mujoco] Average state value: 0.5779898528729877
[2022-12-07 00:41:59,186] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 00:41:59,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01052, loss val: 0.07280
[2022-12-07 00:41:59,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.02323, loss val: 0.06451
[2022-12-07 00:41:59,364] [INFO] [controller] EPOCH 3 loss ppo:  -0.02915, loss val: 0.05812
[2022-12-07 00:41:59,414] [INFO] [controller] EPOCH 4 loss ppo:  -0.03658, loss val: 0.05424
[2022-12-07 00:41:59,424] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:41:59,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:41:59,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:42:06,000] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:42:12,700] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:42:19,087] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:42:25,437] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:42:31,507] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:42:37,576] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:42:43,806] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:42:49,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:42:55,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:43:01,298] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2280515602448864
[2022-12-07 00:43:01,298] [INFO] [runner_train_mujoco] Average state value: 0.6833489252229532
[2022-12-07 00:43:01,298] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 00:43:01,442] [INFO] [controller] EPOCH 1 loss ppo:  -0.00820, loss val: 0.06225
[2022-12-07 00:43:01,530] [INFO] [controller] EPOCH 2 loss ppo:  -0.01863, loss val: 0.05882
[2022-12-07 00:43:01,607] [INFO] [controller] EPOCH 3 loss ppo:  -0.02395, loss val: 0.05552
[2022-12-07 00:43:01,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.02906, loss val: 0.05346
[2022-12-07 00:43:01,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:43:01,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:43:01,854] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:43:08,028] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:43:14,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:43:21,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:43:28,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:43:34,557] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:43:40,513] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:43:47,058] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:43:53,287] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:43:59,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:44:05,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17972401418793896
[2022-12-07 00:44:05,111] [INFO] [runner_train_mujoco] Average state value: 0.7534503186345101
[2022-12-07 00:44:05,111] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 00:44:05,183] [INFO] [controller] EPOCH 1 loss ppo:  -0.00526, loss val: 0.04609
[2022-12-07 00:44:05,239] [INFO] [controller] EPOCH 2 loss ppo:  -0.01702, loss val: 0.04516
[2022-12-07 00:44:05,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.02595, loss val: 0.04518
[2022-12-07 00:44:05,344] [INFO] [controller] EPOCH 4 loss ppo:  -0.03030, loss val: 0.04236
[2022-12-07 00:44:05,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:44:05,552] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:44:05,552] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:44:11,743] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:44:18,402] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:44:25,117] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:44:31,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:44:37,716] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:44:43,640] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:44:50,243] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:44:57,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:45:03,296] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:45:09,735] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2101973572024372
[2022-12-07 00:45:09,736] [INFO] [runner_train_mujoco] Average state value: 0.7454271217783293
[2022-12-07 00:45:09,736] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 00:45:09,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.00630, loss val: 0.04316
[2022-12-07 00:45:09,843] [INFO] [controller] EPOCH 2 loss ppo:  -0.01423, loss val: 0.04296
[2022-12-07 00:45:09,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.01852, loss val: 0.04319
[2022-12-07 00:45:09,947] [INFO] [controller] EPOCH 4 loss ppo:  -0.02502, loss val: 0.04263
[2022-12-07 00:45:09,958] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:45:10,138] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:45:10,138] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:45:16,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:45:23,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:45:30,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:45:38,868] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:45:46,238] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:45:53,809] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:46:01,194] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:46:09,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:46:16,587] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:46:23,927] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2557844280838867
[2022-12-07 00:46:23,927] [INFO] [runner_train_mujoco] Average state value: 0.7286108160217604
[2022-12-07 00:46:23,927] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 00:46:24,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.00573, loss val: 0.04453
[2022-12-07 00:46:24,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.01664, loss val: 0.04746
[2022-12-07 00:46:24,277] [INFO] [controller] EPOCH 3 loss ppo:  -0.02063, loss val: 0.04579
[2022-12-07 00:46:24,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.02786, loss val: 0.04377
[2022-12-07 00:46:24,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:46:24,572] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:46:24,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:46:32,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:46:40,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:46:47,623] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:46:54,842] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:47:02,564] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:47:10,344] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:47:17,565] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:47:24,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:47:32,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:47:39,722] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16925900245124437
[2022-12-07 00:47:39,722] [INFO] [runner_train_mujoco] Average state value: 0.7537783727447191
[2022-12-07 00:47:39,723] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 00:47:39,799] [INFO] [controller] EPOCH 1 loss ppo:  -0.00767, loss val: 0.04163
[2022-12-07 00:47:39,857] [INFO] [controller] EPOCH 2 loss ppo:  -0.01799, loss val: 0.04195
[2022-12-07 00:47:39,910] [INFO] [controller] EPOCH 3 loss ppo:  -0.02405, loss val: 0.04231
[2022-12-07 00:47:39,967] [INFO] [controller] EPOCH 4 loss ppo:  -0.02825, loss val: 0.04196
[2022-12-07 00:47:39,979] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:47:40,187] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:47:40,187] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:47:47,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:47:54,216] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:48:01,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:48:08,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:48:15,237] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:48:22,341] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:48:29,402] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:48:36,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:48:43,011] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:48:50,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16898683654709373
[2022-12-07 00:48:50,071] [INFO] [runner_train_mujoco] Average state value: 0.7597870856920879
[2022-12-07 00:48:50,071] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 00:48:50,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.00721, loss val: 0.04364
[2022-12-07 00:48:50,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.01763, loss val: 0.04235
[2022-12-07 00:48:50,275] [INFO] [controller] EPOCH 3 loss ppo:  -0.02107, loss val: 0.04249
[2022-12-07 00:48:50,356] [INFO] [controller] EPOCH 4 loss ppo:  -0.02583, loss val: 0.04193
[2022-12-07 00:48:50,368] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:48:50,605] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:48:50,605] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:48:57,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:49:04,659] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:49:11,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:49:18,493] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:49:25,156] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:49:31,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:49:38,063] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:49:44,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:49:50,864] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:49:57,043] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1898780630983344
[2022-12-07 00:49:57,043] [INFO] [runner_train_mujoco] Average state value: 0.7265827970902126
[2022-12-07 00:49:57,043] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 00:49:57,114] [INFO] [controller] EPOCH 1 loss ppo:  -0.00713, loss val: 0.04419
[2022-12-07 00:49:57,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.01670, loss val: 0.04444
[2022-12-07 00:49:57,246] [INFO] [controller] EPOCH 3 loss ppo:  -0.02267, loss val: 0.04486
[2022-12-07 00:49:57,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.02956, loss val: 0.04445
[2022-12-07 00:49:57,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:49:57,517] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:49:57,517] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:50:04,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:50:10,978] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:50:17,281] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:50:23,435] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:50:29,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:50:35,463] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:50:42,073] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:50:48,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:50:54,312] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:51:00,405] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2224505454477212
[2022-12-07 00:51:00,405] [INFO] [runner_train_mujoco] Average state value: 0.7250291060010593
[2022-12-07 00:51:00,405] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 00:51:00,464] [INFO] [controller] EPOCH 1 loss ppo:  -0.00774, loss val: 0.04930
[2022-12-07 00:51:00,515] [INFO] [controller] EPOCH 2 loss ppo:  -0.01786, loss val: 0.04643
[2022-12-07 00:51:00,570] [INFO] [controller] EPOCH 3 loss ppo:  -0.02318, loss val: 0.04561
[2022-12-07 00:51:00,623] [INFO] [controller] EPOCH 4 loss ppo:  -0.02748, loss val: 0.04348
[2022-12-07 00:51:00,633] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:51:00,819] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:51:00,820] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:51:07,132] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:51:13,576] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:51:19,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:51:26,724] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:51:33,254] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:51:39,352] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:51:45,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:51:51,178] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:51:57,491] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:52:03,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23064171018419258
[2022-12-07 00:52:03,590] [INFO] [runner_train_mujoco] Average state value: 0.7815268217722575
[2022-12-07 00:52:03,590] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 00:52:03,646] [INFO] [controller] EPOCH 1 loss ppo:  -0.00692, loss val: 0.04455
[2022-12-07 00:52:03,707] [INFO] [controller] EPOCH 2 loss ppo:  -0.01861, loss val: 0.04461
[2022-12-07 00:52:03,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.02676, loss val: 0.04536
[2022-12-07 00:52:03,813] [INFO] [controller] EPOCH 4 loss ppo:  -0.02946, loss val: 0.04448
[2022-12-07 00:52:03,823] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:52:04,007] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:52:04,008] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:52:10,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:52:16,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:52:23,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:52:29,352] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:52:35,543] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:52:41,340] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:52:47,231] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:52:52,914] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:52:58,678] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:53:04,310] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24409433864590424
[2022-12-07 00:53:04,310] [INFO] [runner_train_mujoco] Average state value: 0.7895470301707587
[2022-12-07 00:53:04,311] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 00:53:04,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.00769, loss val: 0.04487
[2022-12-07 00:53:04,435] [INFO] [controller] EPOCH 2 loss ppo:  -0.01677, loss val: 0.04394
[2022-12-07 00:53:04,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.01887, loss val: 0.04448
[2022-12-07 00:53:04,568] [INFO] [controller] EPOCH 4 loss ppo:  -0.02241, loss val: 0.04355
[2022-12-07 00:53:04,578] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:53:04,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:53:04,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:53:10,750] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:53:16,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:53:22,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:53:27,971] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:53:33,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:53:39,662] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:53:45,507] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:53:51,617] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:53:57,701] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:54:03,319] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22999211348628065
[2022-12-07 00:54:03,319] [INFO] [runner_train_mujoco] Average state value: 0.755765779097875
[2022-12-07 00:54:03,319] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 00:54:03,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.00762, loss val: 0.04393
[2022-12-07 00:54:03,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.01978, loss val: 0.04403
[2022-12-07 00:54:03,476] [INFO] [controller] EPOCH 3 loss ppo:  -0.02533, loss val: 0.04420
[2022-12-07 00:54:03,529] [INFO] [controller] EPOCH 4 loss ppo:  -0.02585, loss val: 0.04317
[2022-12-07 00:54:03,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:54:03,717] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:54:03,717] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:54:09,582] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:54:15,428] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:54:21,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:54:26,911] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:54:32,850] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:54:38,747] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:54:44,535] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:54:50,525] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:54:55,942] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:55:01,893] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23364849448676434
[2022-12-07 00:55:01,893] [INFO] [runner_train_mujoco] Average state value: 0.7602328442335129
[2022-12-07 00:55:01,894] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 00:55:01,954] [INFO] [controller] EPOCH 1 loss ppo:  -0.00703, loss val: 0.04360
[2022-12-07 00:55:02,002] [INFO] [controller] EPOCH 2 loss ppo:  -0.01793, loss val: 0.04308
[2022-12-07 00:55:02,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.02225, loss val: 0.04331
[2022-12-07 00:55:02,101] [INFO] [controller] EPOCH 4 loss ppo:  -0.02484, loss val: 0.04269
[2022-12-07 00:55:02,111] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:55:02,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:55:02,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:55:08,775] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:55:14,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:55:21,368] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:55:28,012] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:55:34,017] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:55:39,937] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:55:45,858] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:55:52,673] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:55:59,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:56:05,733] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3070027013762654
[2022-12-07 00:56:05,734] [INFO] [runner_train_mujoco] Average state value: 0.7751388409137725
[2022-12-07 00:56:05,734] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 00:56:05,794] [INFO] [controller] EPOCH 1 loss ppo:  -0.00666, loss val: 0.04284
[2022-12-07 00:56:05,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.01938, loss val: 0.04275
[2022-12-07 00:56:05,899] [INFO] [controller] EPOCH 3 loss ppo:  -0.02714, loss val: 0.04243
[2022-12-07 00:56:05,951] [INFO] [controller] EPOCH 4 loss ppo:  -0.03007, loss val: 0.04343
[2022-12-07 00:56:05,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:56:06,150] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:56:06,150] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:56:12,557] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:56:18,670] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:56:24,646] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:56:30,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:56:37,023] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:56:43,388] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:56:49,658] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:56:56,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:57:02,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:57:09,519] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23234731397760044
[2022-12-07 00:57:09,519] [INFO] [runner_train_mujoco] Average state value: 0.7625638650258382
[2022-12-07 00:57:09,519] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 00:57:09,596] [INFO] [controller] EPOCH 1 loss ppo:  -0.00690, loss val: 0.04019
[2022-12-07 00:57:09,650] [INFO] [controller] EPOCH 2 loss ppo:  -0.01496, loss val: 0.04058
[2022-12-07 00:57:09,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.02087, loss val: 0.04003
[2022-12-07 00:57:09,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.02848, loss val: 0.04005
[2022-12-07 00:57:09,773] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:57:09,961] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:57:09,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:57:17,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:57:23,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:57:29,982] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:57:36,348] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:57:42,657] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:57:48,873] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:57:54,841] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:58:01,053] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:58:07,257] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:58:13,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3175329418299283
[2022-12-07 00:58:13,266] [INFO] [runner_train_mujoco] Average state value: 0.7519353624184927
[2022-12-07 00:58:13,266] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 00:58:13,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.00853, loss val: 0.04035
[2022-12-07 00:58:13,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.01652, loss val: 0.04006
[2022-12-07 00:58:13,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.02183, loss val: 0.04024
[2022-12-07 00:58:13,489] [INFO] [controller] EPOCH 4 loss ppo:  -0.02700, loss val: 0.04039
[2022-12-07 00:58:13,500] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:58:13,688] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:58:13,688] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:58:19,955] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:58:26,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:58:32,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:58:38,082] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:58:44,147] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:58:50,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:58:56,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:59:02,343] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:59:08,423] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:59:14,855] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3870770428782142
[2022-12-07 00:59:14,856] [INFO] [runner_train_mujoco] Average state value: 0.7343223660389582
[2022-12-07 00:59:14,856] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 00:59:14,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.00833, loss val: 0.04138
[2022-12-07 00:59:14,992] [INFO] [controller] EPOCH 2 loss ppo:  -0.01901, loss val: 0.04163
[2022-12-07 00:59:15,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.02575, loss val: 0.04221
[2022-12-07 00:59:15,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.02935, loss val: 0.04116
[2022-12-07 00:59:15,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:59:15,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:59:15,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:59:21,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:59:27,217] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:59:33,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:59:40,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:59:46,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:59:52,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:59:58,053] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:00:03,840] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:00:09,718] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:00:15,612] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39743006486004484
[2022-12-07 01:00:15,613] [INFO] [runner_train_mujoco] Average state value: 0.7400410736401877
[2022-12-07 01:00:15,613] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 01:00:15,684] [INFO] [controller] EPOCH 1 loss ppo:  -0.00718, loss val: 0.04072
[2022-12-07 01:00:15,745] [INFO] [controller] EPOCH 2 loss ppo:  -0.01296, loss val: 0.04042
[2022-12-07 01:00:15,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.02004, loss val: 0.03869
[2022-12-07 01:00:15,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.02302, loss val: 0.03848
[2022-12-07 01:00:15,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:00:16,046] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:00:16,046] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:00:21,603] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:00:27,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:00:33,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:00:38,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:00:44,891] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:00:50,611] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:00:56,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:01:02,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:01:07,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:01:13,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3921196233093466
[2022-12-07 01:01:13,292] [INFO] [runner_train_mujoco] Average state value: 0.729957566022873
[2022-12-07 01:01:13,292] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 01:01:13,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.00856, loss val: 0.04221
[2022-12-07 01:01:13,566] [INFO] [controller] EPOCH 2 loss ppo:  -0.02030, loss val: 0.04325
[2022-12-07 01:01:13,626] [INFO] [controller] EPOCH 3 loss ppo:  -0.02664, loss val: 0.04263
[2022-12-07 01:01:13,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.03036, loss val: 0.04228
[2022-12-07 01:01:13,700] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:01:13,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:01:13,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:01:19,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:01:25,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:01:31,176] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:01:36,631] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:01:42,166] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:01:47,333] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:01:52,743] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:01:58,138] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:02:03,614] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:02:08,891] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5725705680642429
[2022-12-07 01:02:08,892] [INFO] [runner_train_mujoco] Average state value: 0.7090478278398513
[2022-12-07 01:02:08,892] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 01:02:08,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.00993, loss val: 0.03911
[2022-12-07 01:02:08,999] [INFO] [controller] EPOCH 2 loss ppo:  -0.02017, loss val: 0.03884
[2022-12-07 01:02:09,045] [INFO] [controller] EPOCH 3 loss ppo:  -0.02585, loss val: 0.03978
[2022-12-07 01:02:09,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.02961, loss val: 0.03783
[2022-12-07 01:02:09,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:02:09,364] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:02:09,364] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:02:15,099] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:02:20,895] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:02:26,606] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:02:32,375] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:02:37,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:02:43,200] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:02:48,723] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:02:54,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:02:59,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:03:04,935] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7450094556503581
[2022-12-07 01:03:04,935] [INFO] [runner_train_mujoco] Average state value: 0.7099784449934959
[2022-12-07 01:03:04,935] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 01:03:05,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01028, loss val: 0.03818
[2022-12-07 01:03:05,052] [INFO] [controller] EPOCH 2 loss ppo:  -0.01717, loss val: 0.03803
[2022-12-07 01:03:05,102] [INFO] [controller] EPOCH 3 loss ppo:  -0.02300, loss val: 0.03668
[2022-12-07 01:03:05,157] [INFO] [controller] EPOCH 4 loss ppo:  -0.02974, loss val: 0.03644
[2022-12-07 01:03:05,167] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:03:05,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:03:05,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:03:10,738] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:03:16,614] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:03:22,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:03:28,024] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:03:33,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:03:39,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:03:44,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:03:50,100] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:03:55,575] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:04:00,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6779534534978809
[2022-12-07 01:04:00,773] [INFO] [runner_train_mujoco] Average state value: 0.7196521021326383
[2022-12-07 01:04:00,773] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 01:04:00,821] [INFO] [controller] EPOCH 1 loss ppo:  -0.01122, loss val: 0.03950
[2022-12-07 01:04:00,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.01833, loss val: 0.04048
[2022-12-07 01:04:00,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.02379, loss val: 0.04038
[2022-12-07 01:04:00,961] [INFO] [controller] EPOCH 4 loss ppo:  -0.03052, loss val: 0.04038
[2022-12-07 01:04:00,971] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:04:01,137] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:04:01,138] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:04:06,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:04:12,074] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:04:17,844] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:04:23,531] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:04:28,917] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:04:34,851] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:04:40,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:04:45,411] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:04:50,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:04:55,688] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7886009848683458
[2022-12-07 01:04:55,689] [INFO] [runner_train_mujoco] Average state value: 0.7288449590603511
[2022-12-07 01:04:55,689] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 01:04:55,753] [INFO] [controller] EPOCH 1 loss ppo:  -0.01046, loss val: 0.03767
[2022-12-07 01:04:55,820] [INFO] [controller] EPOCH 2 loss ppo:  -0.01895, loss val: 0.03709
[2022-12-07 01:04:55,875] [INFO] [controller] EPOCH 3 loss ppo:  -0.02522, loss val: 0.03625
[2022-12-07 01:04:55,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.02957, loss val: 0.03651
[2022-12-07 01:04:55,940] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:04:56,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:04:56,111] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:05:01,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:05:06,884] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:05:12,425] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:05:18,102] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:05:24,334] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:05:29,801] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:05:35,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:05:40,804] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:05:46,478] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:05:51,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8327186655909669
[2022-12-07 01:05:51,544] [INFO] [runner_train_mujoco] Average state value: 0.699238535841306
[2022-12-07 01:05:51,544] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 01:05:51,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.01131, loss val: 0.03715
[2022-12-07 01:05:51,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.02211, loss val: 0.03722
[2022-12-07 01:05:51,737] [INFO] [controller] EPOCH 3 loss ppo:  -0.02956, loss val: 0.03723
[2022-12-07 01:05:51,793] [INFO] [controller] EPOCH 4 loss ppo:  -0.03350, loss val: 0.03760
[2022-12-07 01:05:51,804] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:05:51,983] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:05:51,984] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:05:57,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:06:03,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:06:08,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:06:13,884] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:06:19,271] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:06:24,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:06:30,844] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:06:36,880] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:06:43,194] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:06:49,307] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9828874453187328
[2022-12-07 01:06:49,307] [INFO] [runner_train_mujoco] Average state value: 0.6815717786947887
[2022-12-07 01:06:49,307] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 01:06:49,366] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.03901
[2022-12-07 01:06:49,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.02119, loss val: 0.03756
[2022-12-07 01:06:49,478] [INFO] [controller] EPOCH 3 loss ppo:  -0.02591, loss val: 0.03749
[2022-12-07 01:06:49,527] [INFO] [controller] EPOCH 4 loss ppo:  -0.03300, loss val: 0.03808
[2022-12-07 01:06:49,537] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:06:49,704] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:06:49,704] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:06:56,207] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:07:02,168] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:07:08,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:07:14,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:07:20,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:07:26,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:07:31,964] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:07:37,166] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:07:42,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:07:47,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1343626950812002
[2022-12-07 01:07:47,782] [INFO] [runner_train_mujoco] Average state value: 0.691072515765826
[2022-12-07 01:07:47,782] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 01:07:47,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04218
[2022-12-07 01:07:47,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.01899, loss val: 0.04265
[2022-12-07 01:07:47,934] [INFO] [controller] EPOCH 3 loss ppo:  -0.02183, loss val: 0.04137
[2022-12-07 01:07:47,976] [INFO] [controller] EPOCH 4 loss ppo:  -0.02783, loss val: 0.04122
[2022-12-07 01:07:47,985] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:07:48,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:07:48,148] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:07:52,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:07:58,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:08:02,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:08:08,309] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:08:13,188] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:08:18,480] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:08:23,297] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:08:28,509] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:08:33,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:08:39,622] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1964883616537054
[2022-12-07 01:08:39,622] [INFO] [runner_train_mujoco] Average state value: 0.6950800924499829
[2022-12-07 01:08:39,623] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 01:08:39,686] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.04020
[2022-12-07 01:08:39,736] [INFO] [controller] EPOCH 2 loss ppo:  -0.02327, loss val: 0.04046
[2022-12-07 01:08:39,782] [INFO] [controller] EPOCH 3 loss ppo:  -0.02920, loss val: 0.04046
[2022-12-07 01:08:39,839] [INFO] [controller] EPOCH 4 loss ppo:  -0.03469, loss val: 0.03974
[2022-12-07 01:08:39,849] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:08:40,016] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:08:40,016] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:08:45,351] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:08:50,726] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:08:55,667] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:09:01,305] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:09:06,745] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:09:12,351] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:09:17,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:09:22,899] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:09:27,795] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:09:33,683] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1614173673686252
[2022-12-07 01:09:33,684] [INFO] [runner_train_mujoco] Average state value: 0.6964584939479828
[2022-12-07 01:09:33,684] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 01:09:33,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.03845
[2022-12-07 01:09:33,796] [INFO] [controller] EPOCH 2 loss ppo:  -0.02653, loss val: 0.03873
[2022-12-07 01:09:33,849] [INFO] [controller] EPOCH 3 loss ppo:  -0.02634, loss val: 0.03894
[2022-12-07 01:09:33,898] [INFO] [controller] EPOCH 4 loss ppo:  -0.03220, loss val: 0.04007
[2022-12-07 01:09:33,908] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:09:34,096] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:09:34,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:09:39,604] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:09:45,309] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:09:50,815] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:09:56,130] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:10:01,972] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:10:07,611] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:10:12,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:10:18,063] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:10:23,255] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:10:28,288] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3187348305208593
[2022-12-07 01:10:28,288] [INFO] [runner_train_mujoco] Average state value: 0.6900961207946141
[2022-12-07 01:10:28,289] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 01:10:28,362] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.03960
[2022-12-07 01:10:28,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.01632, loss val: 0.03946
[2022-12-07 01:10:28,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.02675, loss val: 0.03869
[2022-12-07 01:10:28,526] [INFO] [controller] EPOCH 4 loss ppo:  -0.03290, loss val: 0.03975
[2022-12-07 01:10:28,535] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:10:28,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:10:28,711] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:10:34,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:10:39,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:10:45,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:10:50,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:10:55,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:11:01,053] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:11:06,100] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:11:11,546] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:11:17,024] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:11:22,710] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3895231553235763
[2022-12-07 01:11:22,710] [INFO] [runner_train_mujoco] Average state value: 0.6972481529315313
[2022-12-07 01:11:22,710] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 01:11:22,771] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04142
[2022-12-07 01:11:22,817] [INFO] [controller] EPOCH 2 loss ppo:  -0.01999, loss val: 0.04022
[2022-12-07 01:11:22,863] [INFO] [controller] EPOCH 3 loss ppo:  -0.02442, loss val: 0.04079
[2022-12-07 01:11:22,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.02865, loss val: 0.04144
[2022-12-07 01:11:22,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:11:23,090] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:11:23,090] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:11:28,423] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:11:34,400] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:11:39,970] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:11:45,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:11:51,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:11:56,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:12:01,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:12:06,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:12:12,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:12:17,671] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4251979678496627
[2022-12-07 01:12:17,672] [INFO] [runner_train_mujoco] Average state value: 0.6818446415662766
[2022-12-07 01:12:17,672] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 01:12:17,730] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.04107
[2022-12-07 01:12:17,775] [INFO] [controller] EPOCH 2 loss ppo:  -0.02080, loss val: 0.04082
[2022-12-07 01:12:17,820] [INFO] [controller] EPOCH 3 loss ppo:  -0.02669, loss val: 0.04081
[2022-12-07 01:12:17,869] [INFO] [controller] EPOCH 4 loss ppo:  -0.03194, loss val: 0.04148
[2022-12-07 01:12:17,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:12:18,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:12:18,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:12:23,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:12:29,032] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:12:34,147] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:12:39,147] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:12:44,234] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:12:49,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:12:54,951] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:13:00,228] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:13:05,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:13:11,180] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5738080171908566
[2022-12-07 01:13:11,180] [INFO] [runner_train_mujoco] Average state value: 0.6761848341027895
[2022-12-07 01:13:11,180] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 01:13:11,244] [INFO] [controller] EPOCH 1 loss ppo:  -0.01560, loss val: 0.04388
[2022-12-07 01:13:11,295] [INFO] [controller] EPOCH 2 loss ppo:  -0.02421, loss val: 0.04203
[2022-12-07 01:13:11,350] [INFO] [controller] EPOCH 3 loss ppo:  -0.02536, loss val: 0.04209
[2022-12-07 01:13:11,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.03067, loss val: 0.04286
[2022-12-07 01:13:11,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:13:11,579] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:13:11,579] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:13:17,301] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:13:22,849] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:13:28,036] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:13:33,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:13:38,877] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:13:44,258] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:13:49,644] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:13:55,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:14:00,524] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:14:05,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.602609286695816
[2022-12-07 01:14:05,813] [INFO] [runner_train_mujoco] Average state value: 0.6851674706538519
[2022-12-07 01:14:05,813] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 01:14:05,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.03965
[2022-12-07 01:14:05,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.02082, loss val: 0.04096
[2022-12-07 01:14:05,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.02774, loss val: 0.04034
[2022-12-07 01:14:06,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.03422, loss val: 0.04160
[2022-12-07 01:14:06,022] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:14:06,190] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:14:06,190] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:14:11,394] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:14:16,610] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:14:22,153] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:14:27,176] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:14:32,740] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:14:38,145] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:14:43,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:14:48,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:14:54,404] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:14:59,496] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.720272826203442
[2022-12-07 01:14:59,496] [INFO] [runner_train_mujoco] Average state value: 0.6836968418955802
[2022-12-07 01:14:59,496] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 01:14:59,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.04274
[2022-12-07 01:14:59,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.02266, loss val: 0.04286
[2022-12-07 01:14:59,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.02566, loss val: 0.04224
[2022-12-07 01:14:59,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.03292, loss val: 0.04244
[2022-12-07 01:14:59,704] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:14:59,867] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:14:59,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:15:05,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:15:10,564] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:15:15,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:15:20,931] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:15:25,985] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:15:31,328] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:15:37,499] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:15:42,951] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:15:48,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:15:53,007] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7528349308303401
[2022-12-07 01:15:53,007] [INFO] [runner_train_mujoco] Average state value: 0.6846892449855806
[2022-12-07 01:15:53,008] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 01:15:53,069] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04237
[2022-12-07 01:15:53,132] [INFO] [controller] EPOCH 2 loss ppo:  -0.02176, loss val: 0.04226
[2022-12-07 01:15:53,191] [INFO] [controller] EPOCH 3 loss ppo:  -0.03143, loss val: 0.04170
[2022-12-07 01:15:53,245] [INFO] [controller] EPOCH 4 loss ppo:  -0.03430, loss val: 0.04175
[2022-12-07 01:15:53,255] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:15:53,427] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:15:53,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:15:58,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:16:03,935] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:16:09,378] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:16:14,809] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:16:19,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:16:25,229] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:16:30,630] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:16:36,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:16:41,626] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:16:47,025] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.852792597552373
[2022-12-07 01:16:47,026] [INFO] [runner_train_mujoco] Average state value: 0.6793997295300167
[2022-12-07 01:16:47,026] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 01:16:47,090] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.04171
[2022-12-07 01:16:47,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.02352, loss val: 0.04170
[2022-12-07 01:16:47,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.02837, loss val: 0.04310
[2022-12-07 01:16:47,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.03248, loss val: 0.04111
[2022-12-07 01:16:47,279] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:16:47,447] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:16:47,447] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:16:52,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:16:57,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:17:02,900] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:17:08,115] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:17:13,153] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:17:18,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:17:23,885] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:17:28,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:17:33,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:17:39,217] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.877581650678281
[2022-12-07 01:17:39,217] [INFO] [runner_train_mujoco] Average state value: 0.6671843828161558
[2022-12-07 01:17:39,217] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 01:17:39,278] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.03904
[2022-12-07 01:17:39,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.02025, loss val: 0.04006
[2022-12-07 01:17:39,378] [INFO] [controller] EPOCH 3 loss ppo:  -0.02567, loss val: 0.04130
[2022-12-07 01:17:39,425] [INFO] [controller] EPOCH 4 loss ppo:  -0.02917, loss val: 0.03945
[2022-12-07 01:17:39,434] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:17:39,598] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:17:39,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:17:44,821] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:17:50,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:17:55,483] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:18:01,042] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:18:06,218] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:18:11,655] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:18:17,130] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:18:22,528] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:18:27,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:18:32,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.99252102065192
[2022-12-07 01:18:32,837] [INFO] [runner_train_mujoco] Average state value: 0.6678087725241979
[2022-12-07 01:18:32,837] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 01:18:32,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.04318
[2022-12-07 01:18:32,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.02210, loss val: 0.04391
[2022-12-07 01:18:33,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.02449, loss val: 0.04273
[2022-12-07 01:18:33,059] [INFO] [controller] EPOCH 4 loss ppo:  -0.03000, loss val: 0.04166
[2022-12-07 01:18:33,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:18:33,236] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:18:33,237] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:18:38,612] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:18:43,208] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:18:48,175] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:18:52,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:18:57,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:19:02,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:19:07,073] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:19:11,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:19:16,711] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:19:21,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9625933096630928
[2022-12-07 01:19:21,147] [INFO] [runner_train_mujoco] Average state value: 0.682019267519315
[2022-12-07 01:19:21,147] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 01:19:21,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.01538, loss val: 0.03952
[2022-12-07 01:19:21,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.02042, loss val: 0.04029
[2022-12-07 01:19:21,286] [INFO] [controller] EPOCH 3 loss ppo:  -0.02521, loss val: 0.03981
[2022-12-07 01:19:21,329] [INFO] [controller] EPOCH 4 loss ppo:  -0.02923, loss val: 0.03966
[2022-12-07 01:19:21,339] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:19:21,501] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:19:21,502] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:19:26,522] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:19:31,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:19:36,104] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:19:41,061] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:19:45,802] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:19:50,503] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:19:54,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:19:59,306] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:20:03,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:20:08,104] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.942919525123186
[2022-12-07 01:20:08,104] [INFO] [runner_train_mujoco] Average state value: 0.6792976551055908
[2022-12-07 01:20:08,104] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 01:20:08,155] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04152
[2022-12-07 01:20:08,197] [INFO] [controller] EPOCH 2 loss ppo:  -0.02209, loss val: 0.04132
[2022-12-07 01:20:08,240] [INFO] [controller] EPOCH 3 loss ppo:  -0.02430, loss val: 0.04169
[2022-12-07 01:20:08,279] [INFO] [controller] EPOCH 4 loss ppo:  -0.02872, loss val: 0.04337
[2022-12-07 01:20:08,288] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:20:08,436] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:20:08,436] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:20:13,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:20:17,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:20:22,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:20:27,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:20:31,894] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:20:36,459] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:20:41,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:20:45,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:20:50,049] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:20:54,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0303803674173766
[2022-12-07 01:20:54,257] [INFO] [runner_train_mujoco] Average state value: 0.6713390746514002
[2022-12-07 01:20:54,258] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 01:20:54,315] [INFO] [controller] EPOCH 1 loss ppo:  -0.01573, loss val: 0.03986
[2022-12-07 01:20:54,360] [INFO] [controller] EPOCH 2 loss ppo:  -0.02264, loss val: 0.04107
[2022-12-07 01:20:54,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.02434, loss val: 0.03991
[2022-12-07 01:20:54,445] [INFO] [controller] EPOCH 4 loss ppo:  -0.02699, loss val: 0.03989
[2022-12-07 01:20:54,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:20:54,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:20:54,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:20:59,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:21:03,949] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:21:08,969] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:21:13,438] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:21:18,075] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:21:22,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:21:26,970] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:21:31,425] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:21:35,805] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:21:40,267] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0360083525883104
[2022-12-07 01:21:40,267] [INFO] [runner_train_mujoco] Average state value: 0.6676961383024851
[2022-12-07 01:21:40,267] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 01:21:40,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.04029
[2022-12-07 01:21:40,361] [INFO] [controller] EPOCH 2 loss ppo:  -0.02133, loss val: 0.04016
[2022-12-07 01:21:40,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.02524, loss val: 0.04021
[2022-12-07 01:21:40,453] [INFO] [controller] EPOCH 4 loss ppo:  -0.02759, loss val: 0.04009
[2022-12-07 01:21:40,463] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:21:40,628] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:21:40,629] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:21:44,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:21:49,579] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:21:54,996] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:22:01,163] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:22:06,707] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:22:11,517] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:22:16,658] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:22:21,802] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:22:27,276] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:22:32,356] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1573345961990884
[2022-12-07 01:22:32,356] [INFO] [runner_train_mujoco] Average state value: 0.662382980187734
[2022-12-07 01:22:32,356] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 01:22:32,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.03983
[2022-12-07 01:22:32,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.01894, loss val: 0.03975
[2022-12-07 01:22:32,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.02226, loss val: 0.03990
[2022-12-07 01:22:32,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.02547, loss val: 0.04023
[2022-12-07 01:22:32,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:22:32,721] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:22:32,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:22:38,254] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:22:43,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:22:48,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:22:53,835] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:22:58,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:23:03,990] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:23:09,121] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:23:14,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:23:20,153] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:23:25,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.156574279925554
[2022-12-07 01:23:25,427] [INFO] [runner_train_mujoco] Average state value: 0.6525803705453872
[2022-12-07 01:23:25,428] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 01:23:25,492] [INFO] [controller] EPOCH 1 loss ppo:  -0.01512, loss val: 0.03907
[2022-12-07 01:23:25,551] [INFO] [controller] EPOCH 2 loss ppo:  -0.01854, loss val: 0.04031
[2022-12-07 01:23:25,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.02187, loss val: 0.04125
[2022-12-07 01:23:25,676] [INFO] [controller] EPOCH 4 loss ppo:  -0.02513, loss val: 0.04042
[2022-12-07 01:23:25,686] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:23:25,863] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:23:25,863] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:23:31,131] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:23:36,291] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:23:41,875] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:23:47,083] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:23:52,266] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:23:57,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:24:02,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:24:07,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:24:12,974] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:24:18,326] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.27126862656718
[2022-12-07 01:24:18,326] [INFO] [runner_train_mujoco] Average state value: 0.6469469802776973
[2022-12-07 01:24:18,326] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 01:24:18,388] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.04203
[2022-12-07 01:24:18,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.01845, loss val: 0.04249
[2022-12-07 01:24:18,499] [INFO] [controller] EPOCH 3 loss ppo:  -0.02434, loss val: 0.04190
[2022-12-07 01:24:18,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.02838, loss val: 0.04224
[2022-12-07 01:24:18,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:24:18,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:24:18,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:24:24,114] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:24:29,456] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:24:34,848] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:24:39,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:24:44,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:24:49,817] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:24:54,643] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:24:59,888] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:25:05,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:25:10,197] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2396185853936075
[2022-12-07 01:25:10,197] [INFO] [runner_train_mujoco] Average state value: 0.656267367641131
[2022-12-07 01:25:10,197] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 01:25:10,264] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.04241
[2022-12-07 01:25:10,318] [INFO] [controller] EPOCH 2 loss ppo:  -0.01963, loss val: 0.04227
[2022-12-07 01:25:10,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.02478, loss val: 0.04220
[2022-12-07 01:25:10,430] [INFO] [controller] EPOCH 4 loss ppo:  -0.02679, loss val: 0.04186
[2022-12-07 01:25:10,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:25:10,608] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:25:10,609] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:25:15,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:25:20,615] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:25:26,143] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:25:31,048] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:25:36,475] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:25:41,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:25:46,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:25:52,121] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:25:59,316] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:26:04,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.292813036219216
[2022-12-07 01:26:04,635] [INFO] [runner_train_mujoco] Average state value: 0.6671863217751184
[2022-12-07 01:26:04,635] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 01:26:04,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01498, loss val: 0.04016
[2022-12-07 01:26:04,754] [INFO] [controller] EPOCH 2 loss ppo:  -0.01935, loss val: 0.04057
[2022-12-07 01:26:04,805] [INFO] [controller] EPOCH 3 loss ppo:  -0.02549, loss val: 0.04053
[2022-12-07 01:26:04,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.02838, loss val: 0.04007
[2022-12-07 01:26:04,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:26:05,039] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:26:05,040] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:26:09,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:26:14,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:26:19,934] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:26:25,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:26:30,119] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:26:35,357] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:26:41,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:26:46,429] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:26:51,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:26:56,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3295950189966796
[2022-12-07 01:26:56,728] [INFO] [runner_train_mujoco] Average state value: 0.6683770569562912
[2022-12-07 01:26:56,728] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 01:26:56,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.01514, loss val: 0.04384
[2022-12-07 01:26:56,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.01946, loss val: 0.04338
[2022-12-07 01:26:56,876] [INFO] [controller] EPOCH 3 loss ppo:  -0.02599, loss val: 0.04269
[2022-12-07 01:26:56,925] [INFO] [controller] EPOCH 4 loss ppo:  -0.02903, loss val: 0.04262
[2022-12-07 01:26:56,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:26:57,116] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:26:57,116] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:27:02,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:27:07,295] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:27:12,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:27:17,545] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:27:22,493] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:27:27,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:27:32,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:27:37,489] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:27:43,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:27:48,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4264545369357773
[2022-12-07 01:27:48,746] [INFO] [runner_train_mujoco] Average state value: 0.6650503079096476
[2022-12-07 01:27:48,746] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 01:27:48,800] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.04105
[2022-12-07 01:27:48,867] [INFO] [controller] EPOCH 2 loss ppo:  -0.01877, loss val: 0.04160
[2022-12-07 01:27:48,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.02308, loss val: 0.04108
[2022-12-07 01:27:48,974] [INFO] [controller] EPOCH 4 loss ppo:  -0.02452, loss val: 0.04069
[2022-12-07 01:27:48,984] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:27:49,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:27:49,160] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:27:54,008] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:27:59,141] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:28:04,419] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:28:09,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:28:14,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:28:19,627] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:28:24,614] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:28:29,532] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:28:34,789] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:28:39,855] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5236219917543368
[2022-12-07 01:28:39,856] [INFO] [runner_train_mujoco] Average state value: 0.662188835422198
[2022-12-07 01:28:39,856] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 01:28:39,906] [INFO] [controller] EPOCH 1 loss ppo:  -0.01562, loss val: 0.04230
[2022-12-07 01:28:39,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.01903, loss val: 0.04244
[2022-12-07 01:28:39,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.02310, loss val: 0.04318
[2022-12-07 01:28:40,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.02438, loss val: 0.04184
[2022-12-07 01:28:40,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:28:40,219] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:28:40,219] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:28:45,366] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:28:50,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:28:55,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:28:59,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:29:05,148] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:29:10,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:29:15,688] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:29:20,772] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:29:25,705] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:29:30,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4810616678739312
[2022-12-07 01:29:30,769] [INFO] [runner_train_mujoco] Average state value: 0.6539357129732768
[2022-12-07 01:29:30,769] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 01:29:30,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.01535, loss val: 0.04321
[2022-12-07 01:29:30,919] [INFO] [controller] EPOCH 2 loss ppo:  -0.01742, loss val: 0.04203
[2022-12-07 01:29:30,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.02081, loss val: 0.04198
[2022-12-07 01:29:31,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.02400, loss val: 0.04209
[2022-12-07 01:29:31,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:29:31,205] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:29:31,205] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:29:36,388] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:29:41,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:29:46,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:29:51,726] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:29:56,630] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:30:01,742] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:30:06,482] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:30:11,691] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:30:16,690] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:30:22,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.458762785163834
[2022-12-07 01:30:22,109] [INFO] [runner_train_mujoco] Average state value: 0.6501762067874273
[2022-12-07 01:30:22,109] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 01:30:22,169] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04330
[2022-12-07 01:30:22,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.01617, loss val: 0.04234
[2022-12-07 01:30:22,276] [INFO] [controller] EPOCH 3 loss ppo:  -0.01854, loss val: 0.04232
[2022-12-07 01:30:22,323] [INFO] [controller] EPOCH 4 loss ppo:  -0.02085, loss val: 0.04246
[2022-12-07 01:30:22,333] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:30:22,502] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:30:22,502] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:30:27,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:30:32,981] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:30:38,460] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:30:43,202] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:30:48,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:30:53,177] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:30:57,896] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:31:02,798] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:31:07,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:31:12,726] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5510080335933325
[2022-12-07 01:31:12,726] [INFO] [runner_train_mujoco] Average state value: 0.648178207039833
[2022-12-07 01:31:12,726] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 01:31:12,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.04045
[2022-12-07 01:31:12,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.01650, loss val: 0.04026
[2022-12-07 01:31:12,888] [INFO] [controller] EPOCH 3 loss ppo:  -0.01812, loss val: 0.04082
[2022-12-07 01:31:12,934] [INFO] [controller] EPOCH 4 loss ppo:  -0.02005, loss val: 0.04016
[2022-12-07 01:31:12,945] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:31:13,116] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:31:13,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:31:18,002] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:31:22,938] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:31:28,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:31:33,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:31:37,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:31:43,429] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:31:48,136] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:31:53,231] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:31:58,251] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:32:03,046] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5024914768432898
[2022-12-07 01:32:03,047] [INFO] [runner_train_mujoco] Average state value: 0.6451174966891606
[2022-12-07 01:32:03,047] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 01:32:03,114] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.04346
[2022-12-07 01:32:03,157] [INFO] [controller] EPOCH 2 loss ppo:  -0.01618, loss val: 0.04346
[2022-12-07 01:32:03,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.01729, loss val: 0.04344
[2022-12-07 01:32:03,275] [INFO] [controller] EPOCH 4 loss ppo:  -0.01876, loss val: 0.04389
[2022-12-07 01:32:03,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:32:03,419] [INFO] [optimize] Finished learning.
