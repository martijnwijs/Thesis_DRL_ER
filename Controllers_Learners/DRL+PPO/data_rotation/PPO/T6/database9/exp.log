[2022-12-07 08:49:34,615] [INFO] [optimize] Starting learning
[2022-12-07 08:49:34,623] [INFO] [optimize] Starting learning process..
[2022-12-07 08:49:34,687] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:49:34,688] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:49:42,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:49:47,477] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:49:53,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:49:59,148] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:50:05,055] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:50:10,827] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:50:16,331] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:50:22,052] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:50:27,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:50:32,900] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15980950910672995
[2022-12-07 08:50:32,900] [INFO] [runner_train_mujoco] Average state value: 0.2550699687016507
[2022-12-07 08:50:32,900] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:50:32,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.23408
[2022-12-07 08:50:33,038] [INFO] [controller] EPOCH 2 loss ppo:  -0.03251, loss val: 0.20659
[2022-12-07 08:50:33,093] [INFO] [controller] EPOCH 3 loss ppo:  -0.03567, loss val: 0.18198
[2022-12-07 08:50:33,157] [INFO] [controller] EPOCH 4 loss ppo:  -0.03820, loss val: 0.16558
[2022-12-07 08:50:33,167] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:50:33,333] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:50:33,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:50:38,917] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:50:44,550] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:50:50,256] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:50:56,006] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:51:01,641] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:51:07,292] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:51:13,054] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:51:18,751] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:51:24,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:51:30,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15081866417389483
[2022-12-07 08:51:30,524] [INFO] [runner_train_mujoco] Average state value: 0.43295931697761025
[2022-12-07 08:51:30,525] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:51:30,594] [INFO] [controller] EPOCH 1 loss ppo:  -0.01210, loss val: 0.16062
[2022-12-07 08:51:30,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.02296, loss val: 0.14307
[2022-12-07 08:51:30,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.03090, loss val: 0.12497
[2022-12-07 08:51:30,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.03525, loss val: 0.11137
[2022-12-07 08:51:30,773] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:51:30,947] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:51:30,948] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:36,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:51:41,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:51:46,944] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:51:52,562] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:51:58,260] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:52:03,787] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:52:09,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:52:15,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:52:21,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:52:26,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2082316820754766
[2022-12-07 08:52:26,818] [INFO] [runner_train_mujoco] Average state value: 0.5927504389112194
[2022-12-07 08:52:26,818] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:52:26,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.00966, loss val: 0.10850
[2022-12-07 08:52:26,929] [INFO] [controller] EPOCH 2 loss ppo:  -0.01669, loss val: 0.09831
[2022-12-07 08:52:26,977] [INFO] [controller] EPOCH 3 loss ppo:  -0.02343, loss val: 0.08791
[2022-12-07 08:52:27,030] [INFO] [controller] EPOCH 4 loss ppo:  -0.02828, loss val: 0.08180
[2022-12-07 08:52:27,040] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:52:27,217] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:52:27,217] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:52:32,543] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:52:38,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:52:43,725] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:52:49,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:52:54,689] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:00,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:53:06,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:53:11,504] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:53:17,452] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:53:23,032] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15857540502870607
[2022-12-07 08:53:23,033] [INFO] [runner_train_mujoco] Average state value: 0.7120321988413731
[2022-12-07 08:53:23,033] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:53:23,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.00981, loss val: 0.08060
[2022-12-07 08:53:23,129] [INFO] [controller] EPOCH 2 loss ppo:  -0.02051, loss val: 0.07483
[2022-12-07 08:53:23,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.02496, loss val: 0.07103
[2022-12-07 08:53:23,213] [INFO] [controller] EPOCH 4 loss ppo:  -0.03158, loss val: 0.06744
[2022-12-07 08:53:23,222] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:53:23,388] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:53:23,388] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:53:29,320] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:53:35,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:40,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:45,895] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:53:51,704] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:57,112] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:54:02,535] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:54:08,297] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:54:13,819] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:54:19,935] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1881914851997276
[2022-12-07 08:54:19,935] [INFO] [runner_train_mujoco] Average state value: 0.7291792493363222
[2022-12-07 08:54:19,935] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:54:19,994] [INFO] [controller] EPOCH 1 loss ppo:  -0.00988, loss val: 0.06126
[2022-12-07 08:54:20,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.02347, loss val: 0.05799
[2022-12-07 08:54:20,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.02728, loss val: 0.05540
[2022-12-07 08:54:20,138] [INFO] [controller] EPOCH 4 loss ppo:  -0.02822, loss val: 0.05289
[2022-12-07 08:54:20,148] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:54:20,318] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:54:20,319] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:54:26,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:54:32,097] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:54:38,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:54:44,061] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:54:49,585] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:54:55,156] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:00,853] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:55:06,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:55:11,813] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:55:17,716] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19362145976345446
[2022-12-07 08:55:17,716] [INFO] [runner_train_mujoco] Average state value: 0.6870479055245717
[2022-12-07 08:55:17,716] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:55:17,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.00692, loss val: 0.05373
[2022-12-07 08:55:17,832] [INFO] [controller] EPOCH 2 loss ppo:  -0.01811, loss val: 0.05318
[2022-12-07 08:55:17,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.02416, loss val: 0.05204
[2022-12-07 08:55:17,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.02831, loss val: 0.04984
[2022-12-07 08:55:17,952] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:55:18,117] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:55:18,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:55:24,386] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:55:30,138] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:55:36,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:55:41,739] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:55:47,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:55:52,840] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:58,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:56:04,161] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:56:10,019] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:56:15,598] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20644018496463415
[2022-12-07 08:56:15,599] [INFO] [runner_train_mujoco] Average state value: 0.6981606721083324
[2022-12-07 08:56:15,599] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:56:15,665] [INFO] [controller] EPOCH 1 loss ppo:  -0.00846, loss val: 0.05004
[2022-12-07 08:56:15,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.01999, loss val: 0.05006
[2022-12-07 08:56:15,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.03041, loss val: 0.04641
[2022-12-07 08:56:15,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.03224, loss val: 0.04595
[2022-12-07 08:56:15,817] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:56:15,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:56:15,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:56:21,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:56:27,766] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:56:33,481] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:56:39,439] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:56:45,362] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:56:50,912] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:56:56,560] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:57:02,219] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:07,755] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:12,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2273155939268776
[2022-12-07 08:57:12,920] [INFO] [runner_train_mujoco] Average state value: 0.7533572575648626
[2022-12-07 08:57:12,920] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:57:12,974] [INFO] [controller] EPOCH 1 loss ppo:  -0.00810, loss val: 0.04448
[2022-12-07 08:57:13,024] [INFO] [controller] EPOCH 2 loss ppo:  -0.02154, loss val: 0.04437
[2022-12-07 08:57:13,079] [INFO] [controller] EPOCH 3 loss ppo:  -0.02256, loss val: 0.04373
[2022-12-07 08:57:13,119] [INFO] [controller] EPOCH 4 loss ppo:  -0.02755, loss val: 0.04260
[2022-12-07 08:57:13,129] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:13,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:13,305] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:57:18,909] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:57:24,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:57:30,693] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:57:36,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:57:42,259] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:57:48,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:57:54,272] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:00,045] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:58:05,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:58:10,934] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2694373768004389
[2022-12-07 08:58:10,934] [INFO] [runner_train_mujoco] Average state value: 0.7785063403844833
[2022-12-07 08:58:10,935] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:58:10,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.00707, loss val: 0.04693
[2022-12-07 08:58:11,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.01943, loss val: 0.04631
[2022-12-07 08:58:11,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.02455, loss val: 0.04650
[2022-12-07 08:58:11,116] [INFO] [controller] EPOCH 4 loss ppo:  -0.02708, loss val: 0.04625
[2022-12-07 08:58:11,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:58:11,291] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:58:11,291] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:58:17,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:58:22,538] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:58:28,430] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:58:33,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:58:39,420] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:58:45,471] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:58:51,502] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:57,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:59:03,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:59:08,555] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24185335452029816
[2022-12-07 08:59:08,556] [INFO] [runner_train_mujoco] Average state value: 0.7669689109325409
[2022-12-07 08:59:08,556] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 08:59:08,618] [INFO] [controller] EPOCH 1 loss ppo:  -0.00833, loss val: 0.04484
[2022-12-07 08:59:08,677] [INFO] [controller] EPOCH 2 loss ppo:  -0.01980, loss val: 0.04469
[2022-12-07 08:59:08,725] [INFO] [controller] EPOCH 3 loss ppo:  -0.02309, loss val: 0.04451
[2022-12-07 08:59:08,778] [INFO] [controller] EPOCH 4 loss ppo:  -0.02520, loss val: 0.04371
[2022-12-07 08:59:08,788] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:59:08,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:59:08,957] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:59:14,468] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:59:19,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:59:25,728] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:59:30,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:59:36,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:59:42,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:59:48,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:59:53,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:59:59,711] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:00:04,984] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22443514616651639
[2022-12-07 09:00:04,984] [INFO] [runner_train_mujoco] Average state value: 0.7329281252225239
[2022-12-07 09:00:04,984] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 09:00:05,041] [INFO] [controller] EPOCH 1 loss ppo:  -0.00750, loss val: 0.03961
[2022-12-07 09:00:05,084] [INFO] [controller] EPOCH 2 loss ppo:  -0.01948, loss val: 0.03909
[2022-12-07 09:00:05,130] [INFO] [controller] EPOCH 3 loss ppo:  -0.02401, loss val: 0.04135
[2022-12-07 09:00:05,176] [INFO] [controller] EPOCH 4 loss ppo:  -0.02659, loss val: 0.03864
[2022-12-07 09:00:05,185] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:00:05,356] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:00:05,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:00:10,876] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:00:16,507] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:00:21,937] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:00:27,422] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:00:33,162] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:00:38,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:00:44,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:00:50,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:00:55,632] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:01:01,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23041703622415946
[2022-12-07 09:01:01,223] [INFO] [runner_train_mujoco] Average state value: 0.6943096335530281
[2022-12-07 09:01:01,223] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 09:01:01,288] [INFO] [controller] EPOCH 1 loss ppo:  -0.00928, loss val: 0.04605
[2022-12-07 09:01:01,340] [INFO] [controller] EPOCH 2 loss ppo:  -0.02127, loss val: 0.04533
[2022-12-07 09:01:01,386] [INFO] [controller] EPOCH 3 loss ppo:  -0.02522, loss val: 0.04552
[2022-12-07 09:01:01,433] [INFO] [controller] EPOCH 4 loss ppo:  -0.03327, loss val: 0.04379
[2022-12-07 09:01:01,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:01:01,607] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:01:01,608] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:01:07,261] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:01:12,278] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:01:17,869] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:01:23,877] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:01:29,510] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:35,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:41,504] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:01:47,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:01:52,079] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:01:57,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22725456908506012
[2022-12-07 09:01:57,761] [INFO] [runner_train_mujoco] Average state value: 0.7320457832018534
[2022-12-07 09:01:57,761] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 09:01:57,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.00706, loss val: 0.04384
[2022-12-07 09:01:57,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.01573, loss val: 0.04413
[2022-12-07 09:01:57,912] [INFO] [controller] EPOCH 3 loss ppo:  -0.02191, loss val: 0.04474
[2022-12-07 09:01:57,954] [INFO] [controller] EPOCH 4 loss ppo:  -0.03141, loss val: 0.04483
[2022-12-07 09:01:57,964] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:01:58,134] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:01:58,135] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:03,534] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:02:09,189] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:02:15,036] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:02:20,721] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:02:26,407] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:02:32,092] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:02:37,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:02:43,277] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:02:48,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:02:53,982] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.36184972986163466
[2022-12-07 09:02:53,982] [INFO] [runner_train_mujoco] Average state value: 0.745533572892348
[2022-12-07 09:02:53,982] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 09:02:54,033] [INFO] [controller] EPOCH 1 loss ppo:  -0.00891, loss val: 0.04499
[2022-12-07 09:02:54,078] [INFO] [controller] EPOCH 2 loss ppo:  -0.01780, loss val: 0.04548
[2022-12-07 09:02:54,129] [INFO] [controller] EPOCH 3 loss ppo:  -0.02180, loss val: 0.04498
[2022-12-07 09:02:54,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.02826, loss val: 0.04457
[2022-12-07 09:02:54,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:02:54,356] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:02:54,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:59,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:03:05,552] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:03:10,848] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:03:16,576] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:03:22,511] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:03:28,249] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:03:33,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:03:39,738] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:03:45,585] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:51,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.49650678804096815
[2022-12-07 09:03:51,165] [INFO] [runner_train_mujoco] Average state value: 0.7127997186978658
[2022-12-07 09:03:51,165] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 09:03:51,238] [INFO] [controller] EPOCH 1 loss ppo:  -0.00822, loss val: 0.04159
[2022-12-07 09:03:51,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.01726, loss val: 0.04151
[2022-12-07 09:03:51,368] [INFO] [controller] EPOCH 3 loss ppo:  -0.02498, loss val: 0.04154
[2022-12-07 09:03:51,427] [INFO] [controller] EPOCH 4 loss ppo:  -0.02818, loss val: 0.04131
[2022-12-07 09:03:51,437] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:03:51,630] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:03:51,630] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:03:56,909] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:04:02,779] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:04:08,471] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:04:14,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:04:19,280] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:04:25,077] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:04:30,751] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:04:36,185] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:04:41,410] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:04:46,604] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4043134343761793
[2022-12-07 09:04:46,604] [INFO] [runner_train_mujoco] Average state value: 0.6838261858026187
[2022-12-07 09:04:46,604] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 09:04:46,665] [INFO] [controller] EPOCH 1 loss ppo:  -0.00943, loss val: 0.04179
[2022-12-07 09:04:46,711] [INFO] [controller] EPOCH 2 loss ppo:  -0.02473, loss val: 0.04191
[2022-12-07 09:04:46,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.02721, loss val: 0.04399
[2022-12-07 09:04:46,798] [INFO] [controller] EPOCH 4 loss ppo:  -0.03306, loss val: 0.04123
[2022-12-07 09:04:46,807] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:04:46,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:04:46,953] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:04:52,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:04:57,380] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:02,417] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:07,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:05:12,465] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:05:17,442] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:05:22,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:05:27,574] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:05:32,996] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:05:38,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5860522321166297
[2022-12-07 09:05:38,165] [INFO] [runner_train_mujoco] Average state value: 0.7028207603693009
[2022-12-07 09:05:38,165] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 09:05:38,212] [INFO] [controller] EPOCH 1 loss ppo:  -0.00827, loss val: 0.04403
[2022-12-07 09:05:38,253] [INFO] [controller] EPOCH 2 loss ppo:  -0.02111, loss val: 0.04299
[2022-12-07 09:05:38,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.02806, loss val: 0.04226
[2022-12-07 09:05:38,333] [INFO] [controller] EPOCH 4 loss ppo:  -0.03233, loss val: 0.04257
[2022-12-07 09:05:38,342] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:05:38,504] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:05:38,504] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:05:43,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:05:48,237] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:53,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:58,105] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:06:02,417] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:06:07,248] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:06:12,344] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:06:17,335] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:06:22,330] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:06:27,493] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.801015458456894
[2022-12-07 09:06:27,493] [INFO] [runner_train_mujoco] Average state value: 0.7624488477309546
[2022-12-07 09:06:27,493] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 09:06:27,556] [INFO] [controller] EPOCH 1 loss ppo:  -0.01070, loss val: 0.04599
[2022-12-07 09:06:27,603] [INFO] [controller] EPOCH 2 loss ppo:  -0.02114, loss val: 0.04556
[2022-12-07 09:06:27,655] [INFO] [controller] EPOCH 3 loss ppo:  -0.02404, loss val: 0.04570
[2022-12-07 09:06:27,699] [INFO] [controller] EPOCH 4 loss ppo:  -0.02976, loss val: 0.04520
[2022-12-07 09:06:27,709] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:06:27,880] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:06:27,881] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:06:32,973] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:06:37,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:06:42,958] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:06:47,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:06:52,787] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:06:57,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:07:02,469] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:07:08,292] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:07:13,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:07:19,456] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7640669279928723
[2022-12-07 09:07:19,456] [INFO] [runner_train_mujoco] Average state value: 0.7479583308498066
[2022-12-07 09:07:19,456] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 09:07:19,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04315
[2022-12-07 09:07:19,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.02706, loss val: 0.04240
[2022-12-07 09:07:19,615] [INFO] [controller] EPOCH 3 loss ppo:  -0.02825, loss val: 0.04245
[2022-12-07 09:07:19,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.03297, loss val: 0.04269
[2022-12-07 09:07:19,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:07:19,855] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:07:19,856] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:07:25,209] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:07:30,177] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:07:35,118] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:07:40,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:07:45,126] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:07:50,272] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:07:54,924] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:07:59,913] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:08:04,853] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:08:09,929] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8503000915241671
[2022-12-07 09:08:09,929] [INFO] [runner_train_mujoco] Average state value: 0.6953107758959135
[2022-12-07 09:08:09,929] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 09:08:09,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.01056, loss val: 0.03783
[2022-12-07 09:08:10,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.02286, loss val: 0.03818
[2022-12-07 09:08:10,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.02859, loss val: 0.03692
[2022-12-07 09:08:10,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.03569, loss val: 0.03799
[2022-12-07 09:08:10,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:08:10,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:08:10,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:08:14,949] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:08:20,118] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:08:25,230] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:08:30,348] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:08:35,125] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:08:39,931] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:08:44,935] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:08:49,933] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:08:54,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:08:59,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0104586861433105
[2022-12-07 09:08:59,507] [INFO] [runner_train_mujoco] Average state value: 0.6548183749318122
[2022-12-07 09:08:59,508] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 09:08:59,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.00978, loss val: 0.04199
[2022-12-07 09:08:59,590] [INFO] [controller] EPOCH 2 loss ppo:  -0.01967, loss val: 0.04256
[2022-12-07 09:08:59,637] [INFO] [controller] EPOCH 3 loss ppo:  -0.02617, loss val: 0.04018
[2022-12-07 09:08:59,682] [INFO] [controller] EPOCH 4 loss ppo:  -0.03054, loss val: 0.03968
[2022-12-07 09:08:59,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:08:59,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:08:59,843] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:09:04,952] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:09:09,628] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:09:14,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:09:19,489] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:09:23,955] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:09:29,287] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:09:34,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:09:39,619] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:09:44,425] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:09:49,142] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9877960802593255
[2022-12-07 09:09:49,143] [INFO] [runner_train_mujoco] Average state value: 0.6999902755618096
[2022-12-07 09:09:49,143] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 09:09:49,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01077, loss val: 0.04288
[2022-12-07 09:09:49,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.02005, loss val: 0.04386
[2022-12-07 09:09:49,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02703, loss val: 0.04298
[2022-12-07 09:09:49,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.03368, loss val: 0.04445
[2022-12-07 09:09:49,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:09:49,546] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:09:49,546] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:09:54,938] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:09:59,864] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:10:04,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:10:09,375] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:10:14,162] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:10:19,456] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:10:24,938] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:10:30,110] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:10:35,196] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:10:40,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0935538858406086
[2022-12-07 09:10:40,071] [INFO] [runner_train_mujoco] Average state value: 0.7508699430624644
[2022-12-07 09:10:40,071] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 09:10:40,127] [INFO] [controller] EPOCH 1 loss ppo:  -0.01023, loss val: 0.04455
[2022-12-07 09:10:40,237] [INFO] [controller] EPOCH 2 loss ppo:  -0.02100, loss val: 0.04389
[2022-12-07 09:10:40,283] [INFO] [controller] EPOCH 3 loss ppo:  -0.02887, loss val: 0.04349
[2022-12-07 09:10:40,330] [INFO] [controller] EPOCH 4 loss ppo:  -0.03490, loss val: 0.04298
[2022-12-07 09:10:40,339] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:10:40,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:10:40,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:10:45,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:10:49,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:10:54,828] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:10:59,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:11:04,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:11:09,865] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:11:14,563] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:11:19,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:11:24,519] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:11:29,658] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1082426157769834
[2022-12-07 09:11:29,659] [INFO] [runner_train_mujoco] Average state value: 0.7214840413530668
[2022-12-07 09:11:29,659] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 09:11:29,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01143, loss val: 0.04359
[2022-12-07 09:11:29,751] [INFO] [controller] EPOCH 2 loss ppo:  -0.01902, loss val: 0.04451
[2022-12-07 09:11:29,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.02466, loss val: 0.04452
[2022-12-07 09:11:29,904] [INFO] [controller] EPOCH 4 loss ppo:  -0.03454, loss val: 0.04526
[2022-12-07 09:11:29,917] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:11:30,123] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:11:30,123] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:11:34,469] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:11:39,324] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:11:44,758] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:11:49,784] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:11:54,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:11:59,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:12:04,983] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:12:09,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:12:15,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:12:19,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.132955832024795
[2022-12-07 09:12:19,991] [INFO] [runner_train_mujoco] Average state value: 0.7015403847893078
[2022-12-07 09:12:19,991] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 09:12:20,049] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.03966
[2022-12-07 09:12:20,092] [INFO] [controller] EPOCH 2 loss ppo:  -0.02136, loss val: 0.03979
[2022-12-07 09:12:20,133] [INFO] [controller] EPOCH 3 loss ppo:  -0.02328, loss val: 0.03896
[2022-12-07 09:12:20,174] [INFO] [controller] EPOCH 4 loss ppo:  -0.03521, loss val: 0.03850
[2022-12-07 09:12:20,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:12:20,339] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:12:20,339] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:12:25,228] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:12:30,414] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:12:34,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:12:39,778] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:12:44,777] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:12:49,325] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:12:54,277] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:12:59,121] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:13:04,081] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:09,021] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2903960671589954
[2022-12-07 09:13:09,021] [INFO] [runner_train_mujoco] Average state value: 0.6832738116582234
[2022-12-07 09:13:09,021] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 09:13:09,079] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.03946
[2022-12-07 09:13:09,124] [INFO] [controller] EPOCH 2 loss ppo:  -0.02219, loss val: 0.04027
[2022-12-07 09:13:09,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.02552, loss val: 0.04021
[2022-12-07 09:13:09,215] [INFO] [controller] EPOCH 4 loss ppo:  -0.02968, loss val: 0.03901
[2022-12-07 09:13:09,224] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:09,393] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:09,393] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:13:14,310] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:13:19,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:13:24,728] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:13:29,618] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:13:34,423] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:13:39,610] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:13:44,435] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:13:49,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:13:53,963] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:58,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2781508675419113
[2022-12-07 09:13:58,544] [INFO] [runner_train_mujoco] Average state value: 0.6934231287240982
[2022-12-07 09:13:58,544] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 09:13:58,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.01232, loss val: 0.04027
[2022-12-07 09:13:58,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.02433, loss val: 0.04015
[2022-12-07 09:13:58,666] [INFO] [controller] EPOCH 3 loss ppo:  -0.03019, loss val: 0.03993
[2022-12-07 09:13:58,700] [INFO] [controller] EPOCH 4 loss ppo:  -0.03639, loss val: 0.04099
[2022-12-07 09:13:58,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:58,848] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:58,848] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:14:03,751] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:14:08,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:14:13,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:14:18,403] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:14:23,298] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:14:28,458] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:14:33,657] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:14:38,488] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:14:43,136] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:14:48,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3524628174330438
[2022-12-07 09:14:48,111] [INFO] [runner_train_mujoco] Average state value: 0.7031418724656107
[2022-12-07 09:14:48,111] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 09:14:48,160] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.04715
[2022-12-07 09:14:48,199] [INFO] [controller] EPOCH 2 loss ppo:  -0.01904, loss val: 0.04689
[2022-12-07 09:14:48,239] [INFO] [controller] EPOCH 3 loss ppo:  -0.02509, loss val: 0.04656
[2022-12-07 09:14:48,281] [INFO] [controller] EPOCH 4 loss ppo:  -0.03072, loss val: 0.04601
[2022-12-07 09:14:48,291] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:14:48,440] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:14:48,440] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:14:53,430] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:14:58,641] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:15:03,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:08,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:15:13,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:15:18,526] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:15:23,693] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:15:28,489] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:15:33,262] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:15:38,006] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4472498522561665
[2022-12-07 09:15:38,007] [INFO] [runner_train_mujoco] Average state value: 0.7438765726486842
[2022-12-07 09:15:38,007] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 09:15:38,058] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.04135
[2022-12-07 09:15:38,101] [INFO] [controller] EPOCH 2 loss ppo:  -0.02214, loss val: 0.04333
[2022-12-07 09:15:38,146] [INFO] [controller] EPOCH 3 loss ppo:  -0.02877, loss val: 0.04194
[2022-12-07 09:15:38,190] [INFO] [controller] EPOCH 4 loss ppo:  -0.03439, loss val: 0.04061
[2022-12-07 09:15:38,199] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:15:38,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:15:38,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:15:43,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:15:48,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:15:53,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:58,502] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:16:03,252] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:16:07,941] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:16:12,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:16:17,651] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:16:22,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:16:28,093] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4390394034773846
[2022-12-07 09:16:28,094] [INFO] [runner_train_mujoco] Average state value: 0.7136692533890405
[2022-12-07 09:16:28,094] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 09:16:28,141] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.04340
[2022-12-07 09:16:28,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.02178, loss val: 0.04352
[2022-12-07 09:16:28,221] [INFO] [controller] EPOCH 3 loss ppo:  -0.02924, loss val: 0.04317
[2022-12-07 09:16:28,263] [INFO] [controller] EPOCH 4 loss ppo:  -0.03472, loss val: 0.04367
[2022-12-07 09:16:28,274] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:16:28,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:16:28,435] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:16:33,409] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:16:38,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:16:43,452] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:16:48,027] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:16:52,725] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:16:57,365] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:17:02,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:17:07,275] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:17:12,382] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:17:17,345] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4621923102250463
[2022-12-07 09:17:17,345] [INFO] [runner_train_mujoco] Average state value: 0.7007356869777044
[2022-12-07 09:17:17,345] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 09:17:17,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.04107
[2022-12-07 09:17:17,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.02470, loss val: 0.04039
[2022-12-07 09:17:17,474] [INFO] [controller] EPOCH 3 loss ppo:  -0.03079, loss val: 0.04076
[2022-12-07 09:17:17,512] [INFO] [controller] EPOCH 4 loss ppo:  -0.03697, loss val: 0.04055
[2022-12-07 09:17:17,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:17:17,684] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:17:17,684] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:17:23,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:17:27,906] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:17:32,704] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:17:37,586] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:17:42,212] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:17:47,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:17:51,553] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:17:56,475] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:18:01,320] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:18:06,478] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4189166375734183
[2022-12-07 09:18:06,479] [INFO] [runner_train_mujoco] Average state value: 0.6868458572030067
[2022-12-07 09:18:06,479] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 09:18:06,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04375
[2022-12-07 09:18:06,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.02296, loss val: 0.04444
[2022-12-07 09:18:06,642] [INFO] [controller] EPOCH 3 loss ppo:  -0.02739, loss val: 0.04411
[2022-12-07 09:18:06,684] [INFO] [controller] EPOCH 4 loss ppo:  -0.03317, loss val: 0.04444
[2022-12-07 09:18:06,693] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:18:06,849] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:18:06,849] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:18:11,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:18:16,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:18:21,692] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:18:26,214] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:18:31,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:18:36,339] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:40,746] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:18:45,557] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:18:49,972] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:18:54,585] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.511382107392925
[2022-12-07 09:18:54,585] [INFO] [runner_train_mujoco] Average state value: 0.6975679764350254
[2022-12-07 09:18:54,585] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 09:18:54,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04074
[2022-12-07 09:18:54,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.01969, loss val: 0.04103
[2022-12-07 09:18:54,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.02348, loss val: 0.04137
[2022-12-07 09:18:54,827] [INFO] [controller] EPOCH 4 loss ppo:  -0.03372, loss val: 0.04180
[2022-12-07 09:18:54,836] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:18:55,006] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:18:55,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:18:59,632] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:19:04,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:19:09,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:19:14,745] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:19:19,915] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:19:25,411] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:19:30,145] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:19:34,844] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:19:39,692] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:19:44,587] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5697916634077085
[2022-12-07 09:19:44,588] [INFO] [runner_train_mujoco] Average state value: 0.7055573631922403
[2022-12-07 09:19:44,588] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 09:19:44,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.04311
[2022-12-07 09:19:44,681] [INFO] [controller] EPOCH 2 loss ppo:  -0.02311, loss val: 0.04203
[2022-12-07 09:19:44,721] [INFO] [controller] EPOCH 3 loss ppo:  -0.02756, loss val: 0.04205
[2022-12-07 09:19:44,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.03346, loss val: 0.04145
[2022-12-07 09:19:44,774] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:19:44,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:19:44,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:19:49,917] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:19:54,976] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:19:59,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:20:04,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:20:09,633] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:20:14,841] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:20:19,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:20:24,231] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:20:29,009] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:20:33,772] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5928797911273673
[2022-12-07 09:20:33,773] [INFO] [runner_train_mujoco] Average state value: 0.6749899419546127
[2022-12-07 09:20:33,773] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 09:20:33,823] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.04468
[2022-12-07 09:20:33,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.02164, loss val: 0.04431
[2022-12-07 09:20:34,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.02495, loss val: 0.04487
[2022-12-07 09:20:34,191] [INFO] [controller] EPOCH 4 loss ppo:  -0.03016, loss val: 0.04450
[2022-12-07 09:20:34,200] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:20:34,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:20:34,370] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:20:38,686] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:20:43,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:20:48,476] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:20:53,278] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:20:58,216] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:21:02,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:21:07,604] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:21:12,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:21:16,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:21:21,865] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6767747758285947
[2022-12-07 09:21:21,866] [INFO] [runner_train_mujoco] Average state value: 0.6670149506727855
[2022-12-07 09:21:21,866] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 09:21:21,925] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03912
[2022-12-07 09:21:21,970] [INFO] [controller] EPOCH 2 loss ppo:  -0.02468, loss val: 0.03877
[2022-12-07 09:21:22,015] [INFO] [controller] EPOCH 3 loss ppo:  -0.02943, loss val: 0.03960
[2022-12-07 09:21:22,057] [INFO] [controller] EPOCH 4 loss ppo:  -0.03371, loss val: 0.03879
[2022-12-07 09:21:22,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:21:22,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:21:22,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:21:26,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:21:32,003] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:21:36,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:21:41,546] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:21:46,181] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:21:50,668] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:21:55,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:22:00,180] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:22:05,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:22:10,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.724645215794925
[2022-12-07 09:22:10,115] [INFO] [runner_train_mujoco] Average state value: 0.6700353111227353
[2022-12-07 09:22:10,115] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 09:22:10,162] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.04076
[2022-12-07 09:22:10,204] [INFO] [controller] EPOCH 2 loss ppo:  -0.02171, loss val: 0.04077
[2022-12-07 09:22:10,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.02892, loss val: 0.03997
[2022-12-07 09:22:10,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.03343, loss val: 0.03975
[2022-12-07 09:22:10,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:22:10,448] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:22:10,448] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:22:15,080] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:22:19,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:22:24,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:22:29,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:22:34,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:22:39,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:22:44,382] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:22:49,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:22:53,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:22:58,489] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7092162087403266
[2022-12-07 09:22:58,490] [INFO] [runner_train_mujoco] Average state value: 0.6990431974728902
[2022-12-07 09:22:58,490] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 09:22:58,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.04048
[2022-12-07 09:22:58,581] [INFO] [controller] EPOCH 2 loss ppo:  -0.02007, loss val: 0.04183
[2022-12-07 09:22:58,621] [INFO] [controller] EPOCH 3 loss ppo:  -0.02593, loss val: 0.04075
[2022-12-07 09:22:58,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.03206, loss val: 0.04063
[2022-12-07 09:22:58,669] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:22:58,827] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:22:58,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:03,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:23:07,623] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:23:12,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:23:17,496] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:23:22,452] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:23:27,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:23:32,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:23:36,500] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:23:41,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:23:45,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7489911184554807
[2022-12-07 09:23:45,507] [INFO] [runner_train_mujoco] Average state value: 0.7052596002817154
[2022-12-07 09:23:45,507] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 09:23:45,559] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04237
[2022-12-07 09:23:45,610] [INFO] [controller] EPOCH 2 loss ppo:  -0.02178, loss val: 0.04189
[2022-12-07 09:23:45,654] [INFO] [controller] EPOCH 3 loss ppo:  -0.02621, loss val: 0.04224
[2022-12-07 09:23:45,694] [INFO] [controller] EPOCH 4 loss ppo:  -0.03062, loss val: 0.04388
[2022-12-07 09:23:45,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:23:45,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:23:45,862] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:50,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:23:55,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:24:00,913] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:24:05,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:24:10,603] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:24:15,516] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:24:20,038] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:24:24,813] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:24:29,550] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:24:34,248] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8259815645388813
[2022-12-07 09:24:34,248] [INFO] [runner_train_mujoco] Average state value: 0.7013942294120789
[2022-12-07 09:24:34,248] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 09:24:34,300] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04474
[2022-12-07 09:24:34,345] [INFO] [controller] EPOCH 2 loss ppo:  -0.02333, loss val: 0.04360
[2022-12-07 09:24:34,390] [INFO] [controller] EPOCH 3 loss ppo:  -0.02810, loss val: 0.04464
[2022-12-07 09:24:34,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.03374, loss val: 0.04414
[2022-12-07 09:24:34,445] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:24:34,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:24:34,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:24:39,418] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:24:44,412] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:24:49,167] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:24:54,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:24:58,730] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:25:03,431] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:25:08,424] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:25:13,141] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:25:17,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:25:22,732] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8530906860922958
[2022-12-07 09:25:22,732] [INFO] [runner_train_mujoco] Average state value: 0.7043136496941249
[2022-12-07 09:25:22,732] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 09:25:22,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04378
[2022-12-07 09:25:22,827] [INFO] [controller] EPOCH 2 loss ppo:  -0.02385, loss val: 0.04208
[2022-12-07 09:25:22,870] [INFO] [controller] EPOCH 3 loss ppo:  -0.02970, loss val: 0.04331
[2022-12-07 09:25:22,916] [INFO] [controller] EPOCH 4 loss ppo:  -0.03473, loss val: 0.04134
[2022-12-07 09:25:22,923] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:25:23,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:25:23,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:25:27,897] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:25:32,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:25:37,057] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:25:41,726] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:25:46,448] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:25:50,957] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:25:55,753] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:26:00,612] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:26:05,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:10,346] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.949658662459888
[2022-12-07 09:26:10,347] [INFO] [runner_train_mujoco] Average state value: 0.685114320953687
[2022-12-07 09:26:10,347] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 09:26:10,404] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.04631
[2022-12-07 09:26:10,455] [INFO] [controller] EPOCH 2 loss ppo:  -0.01854, loss val: 0.04601
[2022-12-07 09:26:10,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.02299, loss val: 0.04533
[2022-12-07 09:26:10,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.02957, loss val: 0.04522
[2022-12-07 09:26:10,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:10,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:10,720] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:26:15,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:26:20,316] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:26:24,712] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:26:29,104] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:26:33,472] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:26:38,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:26:43,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:26:48,443] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:26:53,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:57,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8587001851455711
[2022-12-07 09:26:57,997] [INFO] [runner_train_mujoco] Average state value: 0.6890668215354283
[2022-12-07 09:26:57,998] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 09:26:58,046] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04471
[2022-12-07 09:26:58,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.01995, loss val: 0.04554
[2022-12-07 09:26:58,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.02923, loss val: 0.04651
[2022-12-07 09:26:58,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.03309, loss val: 0.04446
[2022-12-07 09:26:58,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:58,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:58,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:27:03,216] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:27:07,842] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:12,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:27:17,305] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:27:22,199] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:27:26,292] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:27:31,269] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:27:36,023] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:27:40,291] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:27:45,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8966451369998982
[2022-12-07 09:27:45,272] [INFO] [runner_train_mujoco] Average state value: 0.7005858693917592
[2022-12-07 09:27:45,272] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 09:27:45,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.04231
[2022-12-07 09:27:45,362] [INFO] [controller] EPOCH 2 loss ppo:  -0.02154, loss val: 0.04214
[2022-12-07 09:27:45,401] [INFO] [controller] EPOCH 3 loss ppo:  -0.02341, loss val: 0.04311
[2022-12-07 09:27:45,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.02730, loss val: 0.04310
[2022-12-07 09:27:45,449] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:27:45,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:27:45,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:27:50,288] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:27:54,968] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:59,941] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:28:04,516] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:28:09,052] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:28:13,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:28:18,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:28:22,544] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:28:27,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:28:31,393] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9293393317530776
[2022-12-07 09:28:31,393] [INFO] [runner_train_mujoco] Average state value: 0.712175735314687
[2022-12-07 09:28:31,393] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 09:28:31,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.04209
[2022-12-07 09:28:31,486] [INFO] [controller] EPOCH 2 loss ppo:  -0.02200, loss val: 0.04202
[2022-12-07 09:28:31,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.02498, loss val: 0.04123
[2022-12-07 09:28:31,566] [INFO] [controller] EPOCH 4 loss ppo:  -0.02901, loss val: 0.04048
[2022-12-07 09:28:31,576] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:28:31,755] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:28:31,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:28:36,487] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:28:41,166] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:28:46,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:28:51,208] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:28:56,306] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:29:01,186] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:29:05,928] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:10,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:29:15,296] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:29:19,513] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9118639342580628
[2022-12-07 09:29:19,514] [INFO] [runner_train_mujoco] Average state value: 0.6942836196621258
[2022-12-07 09:29:19,514] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 09:29:19,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.04391
[2022-12-07 09:29:19,604] [INFO] [controller] EPOCH 2 loss ppo:  -0.01930, loss val: 0.04360
[2022-12-07 09:29:19,645] [INFO] [controller] EPOCH 3 loss ppo:  -0.02760, loss val: 0.04351
[2022-12-07 09:29:19,685] [INFO] [controller] EPOCH 4 loss ppo:  -0.02874, loss val: 0.04347
[2022-12-07 09:29:19,694] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:29:19,857] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:29:19,857] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:29:24,612] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:29:29,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:29:33,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:38,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:29:43,204] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:29:48,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:29:52,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:57,079] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:01,616] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:06,176] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0927686598267052
[2022-12-07 09:30:06,176] [INFO] [runner_train_mujoco] Average state value: 0.6714812433719635
[2022-12-07 09:30:06,176] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 09:30:06,232] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04045
[2022-12-07 09:30:06,277] [INFO] [controller] EPOCH 2 loss ppo:  -0.01791, loss val: 0.03980
[2022-12-07 09:30:06,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.02164, loss val: 0.03904
[2022-12-07 09:30:06,371] [INFO] [controller] EPOCH 4 loss ppo:  -0.02477, loss val: 0.03879
[2022-12-07 09:30:06,386] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:06,557] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:06,558] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:11,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:30:16,202] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:30:20,920] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:30:25,456] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:30:29,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:30:34,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:30:38,785] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:30:43,427] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:48,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:53,157] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1182293362976674
[2022-12-07 09:30:53,157] [INFO] [runner_train_mujoco] Average state value: 0.6602670507828394
[2022-12-07 09:30:53,157] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 09:30:53,207] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04223
[2022-12-07 09:30:53,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.02277, loss val: 0.04207
[2022-12-07 09:30:53,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.02412, loss val: 0.04149
[2022-12-07 09:30:53,334] [INFO] [controller] EPOCH 4 loss ppo:  -0.02892, loss val: 0.04200
[2022-12-07 09:30:53,343] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:53,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:53,491] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:58,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:31:02,803] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:31:07,515] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:31:12,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:31:17,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:31:21,747] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:31:26,476] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:31:31,226] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:31:36,386] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:31:41,018] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.156767494505228
[2022-12-07 09:31:41,018] [INFO] [runner_train_mujoco] Average state value: 0.6653827913204828
[2022-12-07 09:31:41,019] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 09:31:41,077] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04430
[2022-12-07 09:31:41,124] [INFO] [controller] EPOCH 2 loss ppo:  -0.01987, loss val: 0.04409
[2022-12-07 09:31:41,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.02251, loss val: 0.04357
[2022-12-07 09:31:41,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.02681, loss val: 0.04346
[2022-12-07 09:31:41,229] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:31:41,386] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:31:41,386] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:31:46,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:31:51,192] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:31:55,902] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:32:00,416] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:32:05,122] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:32:09,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:32:13,852] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:32:18,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:32:22,744] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:32:26,993] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.179515176768286
[2022-12-07 09:32:26,994] [INFO] [runner_train_mujoco] Average state value: 0.6782158497770628
[2022-12-07 09:32:26,994] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 09:32:27,045] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.04301
[2022-12-07 09:32:27,086] [INFO] [controller] EPOCH 2 loss ppo:  -0.02019, loss val: 0.04330
[2022-12-07 09:32:27,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.02209, loss val: 0.04320
[2022-12-07 09:32:27,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.02917, loss val: 0.04258
[2022-12-07 09:32:27,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:32:27,346] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:32:27,346] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:32:32,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:32:37,006] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:32:41,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:32:45,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:32:50,673] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:32:55,611] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:33:00,666] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:33:07,082] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:33:11,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:33:16,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2089233196393514
[2022-12-07 09:33:16,169] [INFO] [runner_train_mujoco] Average state value: 0.685030690352122
[2022-12-07 09:33:16,170] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 09:33:16,223] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04068
[2022-12-07 09:33:16,263] [INFO] [controller] EPOCH 2 loss ppo:  -0.01845, loss val: 0.04040
[2022-12-07 09:33:16,302] [INFO] [controller] EPOCH 3 loss ppo:  -0.01952, loss val: 0.04066
[2022-12-07 09:33:16,344] [INFO] [controller] EPOCH 4 loss ppo:  -0.02425, loss val: 0.04104
[2022-12-07 09:33:16,353] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:33:16,514] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:33:16,515] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:33:21,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:33:25,351] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:33:30,341] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:33:34,703] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:33:39,339] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:33:45,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:33:50,074] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:33:54,258] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:33:58,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:34:02,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2464504333330035
[2022-12-07 09:34:02,832] [INFO] [runner_train_mujoco] Average state value: 0.6741510941584904
[2022-12-07 09:34:02,833] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 09:34:02,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.04702
[2022-12-07 09:34:02,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.01534, loss val: 0.04811
[2022-12-07 09:34:02,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.02106, loss val: 0.04743
[2022-12-07 09:34:03,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.02650, loss val: 0.04703
[2022-12-07 09:34:03,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:34:03,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:34:03,214] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:34:07,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:34:12,233] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:34:16,519] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:34:20,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:34:26,309] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:34:30,989] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:34:35,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:34:39,814] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:34:44,219] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:34:48,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2702182791700203
[2022-12-07 09:34:48,895] [INFO] [runner_train_mujoco] Average state value: 0.6698088924487432
[2022-12-07 09:34:48,895] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 09:34:48,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04291
[2022-12-07 09:34:48,984] [INFO] [controller] EPOCH 2 loss ppo:  -0.01531, loss val: 0.04265
[2022-12-07 09:34:49,031] [INFO] [controller] EPOCH 3 loss ppo:  -0.01674, loss val: 0.04298
[2022-12-07 09:34:49,073] [INFO] [controller] EPOCH 4 loss ppo:  -0.01945, loss val: 0.04257
[2022-12-07 09:34:49,082] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:34:49,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:34:49,245] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:34:53,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:34:58,732] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:35:02,958] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:35:07,430] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:35:11,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:35:15,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:35:19,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:35:24,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:35:28,821] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:35:32,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3044880811192483
[2022-12-07 09:35:32,974] [INFO] [runner_train_mujoco] Average state value: 0.6743158539136251
[2022-12-07 09:35:32,974] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 09:35:33,023] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04338
[2022-12-07 09:35:33,064] [INFO] [controller] EPOCH 2 loss ppo:  -0.01595, loss val: 0.04338
[2022-12-07 09:35:33,107] [INFO] [controller] EPOCH 3 loss ppo:  -0.02065, loss val: 0.04332
[2022-12-07 09:35:33,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.02585, loss val: 0.04347
[2022-12-07 09:35:33,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:35:33,313] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:35:33,313] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:35:37,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:35:42,689] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:35:47,753] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:35:52,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:35:56,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:36:01,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:36:05,606] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:36:10,477] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:36:14,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:36:19,645] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2936540470648583
[2022-12-07 09:36:19,646] [INFO] [runner_train_mujoco] Average state value: 0.6770949103434881
[2022-12-07 09:36:19,646] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 09:36:19,695] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04593
[2022-12-07 09:36:19,738] [INFO] [controller] EPOCH 2 loss ppo:  -0.01601, loss val: 0.04583
[2022-12-07 09:36:19,780] [INFO] [controller] EPOCH 3 loss ppo:  -0.01862, loss val: 0.04611
[2022-12-07 09:36:19,824] [INFO] [controller] EPOCH 4 loss ppo:  -0.02235, loss val: 0.04631
[2022-12-07 09:36:19,834] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:36:20,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:36:20,005] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:36:24,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:36:28,526] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:36:33,107] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:36:37,961] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:36:42,233] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:36:46,514] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:36:50,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:36:55,064] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:36:59,152] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:37:03,956] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.355361033256754
[2022-12-07 09:37:03,957] [INFO] [runner_train_mujoco] Average state value: 0.6821912880738576
[2022-12-07 09:37:03,957] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 09:37:04,005] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04235
[2022-12-07 09:37:04,046] [INFO] [controller] EPOCH 2 loss ppo:  -0.01407, loss val: 0.04262
[2022-12-07 09:37:04,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.01661, loss val: 0.04251
[2022-12-07 09:37:04,133] [INFO] [controller] EPOCH 4 loss ppo:  -0.01938, loss val: 0.04227
[2022-12-07 09:37:04,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:37:04,301] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:37:04,301] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:37:08,516] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:37:13,527] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:37:18,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:37:22,777] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:37:27,019] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:37:31,553] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:37:36,397] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:37:41,072] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:37:45,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:37:49,187] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.356831943606953
[2022-12-07 09:37:49,188] [INFO] [runner_train_mujoco] Average state value: 0.6769681345025699
[2022-12-07 09:37:49,188] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 09:37:49,238] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04297
[2022-12-07 09:37:49,277] [INFO] [controller] EPOCH 2 loss ppo:  -0.01471, loss val: 0.04363
[2022-12-07 09:37:49,309] [INFO] [controller] EPOCH 3 loss ppo:  -0.01626, loss val: 0.04322
[2022-12-07 09:37:49,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.01839, loss val: 0.04391
[2022-12-07 09:37:49,358] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:37:49,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:37:49,550] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:37:54,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:37:58,646] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:38:03,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:38:08,651] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:38:13,167] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:38:17,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:38:21,898] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:38:26,506] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:38:31,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:38:35,955] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3676441873942515
[2022-12-07 09:38:35,955] [INFO] [runner_train_mujoco] Average state value: 0.6770281060139338
[2022-12-07 09:38:35,955] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 09:38:36,010] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.04306
[2022-12-07 09:38:36,051] [INFO] [controller] EPOCH 2 loss ppo:  -0.01430, loss val: 0.04289
[2022-12-07 09:38:36,102] [INFO] [controller] EPOCH 3 loss ppo:  -0.01508, loss val: 0.04339
[2022-12-07 09:38:36,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.01672, loss val: 0.04254
[2022-12-07 09:38:36,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:38:36,282] [INFO] [optimize] Finished learning.
