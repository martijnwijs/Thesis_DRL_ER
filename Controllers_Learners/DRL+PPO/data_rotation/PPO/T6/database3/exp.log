[2022-12-06 18:27:36,929] [INFO] [optimize] Starting learning
[2022-12-06 18:27:36,941] [INFO] [optimize] Starting learning process..
[2022-12-06 18:27:37,004] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:27:37,005] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:27:45,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:27:53,014] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:27:59,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:28:06,894] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:28:13,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:28:20,492] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:28:27,333] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:28:34,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:28:41,784] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:28:48,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18322327218625922
[2022-12-06 18:28:48,824] [INFO] [runner_train_mujoco] Average state value: 0.10710035875439643
[2022-12-06 18:28:48,825] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 18:28:48,915] [INFO] [controller] EPOCH 1 loss ppo:  -0.01346, loss val: 0.37674
[2022-12-06 18:28:48,973] [INFO] [controller] EPOCH 2 loss ppo:  -0.02889, loss val: 0.32683
[2022-12-06 18:28:49,031] [INFO] [controller] EPOCH 3 loss ppo:  -0.03410, loss val: 0.28880
[2022-12-06 18:28:49,135] [INFO] [controller] EPOCH 4 loss ppo:  -0.03541, loss val: 0.24986
[2022-12-06 18:28:49,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:28:49,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:28:49,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:28:55,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:29:03,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:29:10,002] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:29:17,369] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:29:24,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:29:31,417] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:29:38,944] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:29:45,537] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:29:52,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:29:59,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14814947728040587
[2022-12-06 18:29:59,271] [INFO] [runner_train_mujoco] Average state value: 0.29715168352921806
[2022-12-06 18:29:59,271] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 18:29:59,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.17942
[2022-12-06 18:29:59,591] [INFO] [controller] EPOCH 2 loss ppo:  -0.02510, loss val: 0.16179
[2022-12-06 18:29:59,650] [INFO] [controller] EPOCH 3 loss ppo:  -0.03015, loss val: 0.13499
[2022-12-06 18:29:59,715] [INFO] [controller] EPOCH 4 loss ppo:  -0.03316, loss val: 0.11821
[2022-12-06 18:29:59,729] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:29:59,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:29:59,936] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:30:06,854] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:30:13,993] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:30:20,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:30:27,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:30:34,630] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:30:41,794] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:30:48,918] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:30:55,968] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:31:02,515] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:31:09,565] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14968967611932577
[2022-12-06 18:31:09,565] [INFO] [runner_train_mujoco] Average state value: 0.4560067907497287
[2022-12-06 18:31:09,565] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 18:31:09,633] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.13116
[2022-12-06 18:31:09,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.02417, loss val: 0.11605
[2022-12-06 18:31:09,751] [INFO] [controller] EPOCH 3 loss ppo:  -0.02838, loss val: 0.09737
[2022-12-06 18:31:09,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.03373, loss val: 0.08738
[2022-12-06 18:31:09,828] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:31:10,029] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:31:10,029] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:31:16,617] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:31:23,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:31:30,537] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:31:37,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:31:44,119] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:31:50,681] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:31:57,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:32:03,982] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:32:10,482] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:32:17,211] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18872955894934412
[2022-12-06 18:32:17,212] [INFO] [runner_train_mujoco] Average state value: 0.6159149166358013
[2022-12-06 18:32:17,212] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 18:32:17,294] [INFO] [controller] EPOCH 1 loss ppo:  -0.01085, loss val: 0.09450
[2022-12-06 18:32:17,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.02213, loss val: 0.08428
[2022-12-06 18:32:17,436] [INFO] [controller] EPOCH 3 loss ppo:  -0.02772, loss val: 0.07562
[2022-12-06 18:32:17,497] [INFO] [controller] EPOCH 4 loss ppo:  -0.03300, loss val: 0.06881
[2022-12-06 18:32:17,508] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:32:17,714] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:32:17,714] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:32:24,268] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:32:30,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:32:37,386] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:32:43,716] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:32:50,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:32:56,672] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:33:02,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:33:09,093] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:33:15,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:33:21,228] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23649965463519554
[2022-12-06 18:33:21,228] [INFO] [runner_train_mujoco] Average state value: 0.7405041131178538
[2022-12-06 18:33:21,229] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 18:33:21,302] [INFO] [controller] EPOCH 1 loss ppo:  -0.00865, loss val: 0.06775
[2022-12-06 18:33:21,372] [INFO] [controller] EPOCH 2 loss ppo:  -0.02239, loss val: 0.06428
[2022-12-06 18:33:21,422] [INFO] [controller] EPOCH 3 loss ppo:  -0.02677, loss val: 0.06205
[2022-12-06 18:33:21,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.02999, loss val: 0.05919
[2022-12-06 18:33:21,488] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:33:21,680] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:33:21,681] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:33:28,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:33:34,232] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:33:40,455] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:33:46,385] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:33:52,041] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:33:58,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:34:05,133] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:34:11,564] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:34:17,787] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:34:24,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2163521161120688
[2022-12-06 18:34:24,271] [INFO] [runner_train_mujoco] Average state value: 0.7935055082043012
[2022-12-06 18:34:24,272] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 18:34:24,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.00874, loss val: 0.05246
[2022-12-06 18:34:24,422] [INFO] [controller] EPOCH 2 loss ppo:  -0.01900, loss val: 0.04947
[2022-12-06 18:34:24,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.02502, loss val: 0.04669
[2022-12-06 18:34:24,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.03083, loss val: 0.04459
[2022-12-06 18:34:24,677] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:34:24,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:34:24,863] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:34:31,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:34:38,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:34:44,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:34:51,764] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:35:02,048] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:35:08,483] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:35:14,363] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:35:20,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:35:26,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:35:32,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20688918276621124
[2022-12-06 18:35:32,116] [INFO] [runner_train_mujoco] Average state value: 0.7385854834318162
[2022-12-06 18:35:32,117] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 18:35:32,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.00676, loss val: 0.04980
[2022-12-06 18:35:32,232] [INFO] [controller] EPOCH 2 loss ppo:  -0.01770, loss val: 0.04925
[2022-12-06 18:35:32,280] [INFO] [controller] EPOCH 3 loss ppo:  -0.01956, loss val: 0.04878
[2022-12-06 18:35:32,336] [INFO] [controller] EPOCH 4 loss ppo:  -0.02628, loss val: 0.04824
[2022-12-06 18:35:32,347] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:35:32,538] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:35:32,539] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:35:38,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:35:45,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:35:51,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:35:58,920] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:36:05,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:36:11,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:36:18,161] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:36:28,098] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:36:36,770] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:36:46,478] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23314233861555586
[2022-12-06 18:36:46,479] [INFO] [runner_train_mujoco] Average state value: 0.7227572007775306
[2022-12-06 18:36:46,479] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 18:36:46,605] [INFO] [controller] EPOCH 1 loss ppo:  -0.00852, loss val: 0.04298
[2022-12-06 18:36:46,780] [INFO] [controller] EPOCH 2 loss ppo:  -0.02014, loss val: 0.04251
[2022-12-06 18:36:46,904] [INFO] [controller] EPOCH 3 loss ppo:  -0.02452, loss val: 0.04255
[2022-12-06 18:36:47,014] [INFO] [controller] EPOCH 4 loss ppo:  -0.02868, loss val: 0.04153
[2022-12-06 18:36:47,029] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:36:47,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:36:47,298] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:36:58,079] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:37:06,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:37:14,819] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:37:24,101] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:37:33,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:37:41,549] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:37:50,294] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:38:01,579] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:38:11,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:38:19,377] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18298983873465166
[2022-12-06 18:38:19,377] [INFO] [runner_train_mujoco] Average state value: 0.7379977326790491
[2022-12-06 18:38:19,378] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 18:38:19,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.00724, loss val: 0.04435
[2022-12-06 18:38:19,603] [INFO] [controller] EPOCH 2 loss ppo:  -0.01861, loss val: 0.04439
[2022-12-06 18:38:19,694] [INFO] [controller] EPOCH 3 loss ppo:  -0.02277, loss val: 0.04400
[2022-12-06 18:38:19,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.02520, loss val: 0.04377
[2022-12-06 18:38:19,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:38:20,003] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:38:20,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:38:28,271] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:38:37,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:38:46,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:38:56,259] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:39:05,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:39:14,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:39:22,514] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:39:30,971] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:39:39,309] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:39:47,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1832473271854471
[2022-12-06 18:39:47,550] [INFO] [runner_train_mujoco] Average state value: 0.7183820254604022
[2022-12-06 18:39:47,551] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 18:39:47,669] [INFO] [controller] EPOCH 1 loss ppo:  -0.00830, loss val: 0.04267
[2022-12-06 18:39:47,762] [INFO] [controller] EPOCH 2 loss ppo:  -0.02111, loss val: 0.04286
[2022-12-06 18:39:47,853] [INFO] [controller] EPOCH 3 loss ppo:  -0.02374, loss val: 0.04226
[2022-12-06 18:39:47,931] [INFO] [controller] EPOCH 4 loss ppo:  -0.02902, loss val: 0.04378
[2022-12-06 18:39:47,945] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:39:48,185] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:39:48,185] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:39:56,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:40:04,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:40:13,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:40:23,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:40:32,268] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:40:42,517] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:40:57,016] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:41:10,641] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:41:19,240] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:41:26,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1635481021484415
[2022-12-06 18:41:26,778] [INFO] [runner_train_mujoco] Average state value: 0.7235290940006575
[2022-12-06 18:41:26,778] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 18:41:26,858] [INFO] [controller] EPOCH 1 loss ppo:  -0.00556, loss val: 0.04909
[2022-12-06 18:41:26,917] [INFO] [controller] EPOCH 2 loss ppo:  -0.01346, loss val: 0.04719
[2022-12-06 18:41:26,979] [INFO] [controller] EPOCH 3 loss ppo:  -0.01983, loss val: 0.04630
[2022-12-06 18:41:27,040] [INFO] [controller] EPOCH 4 loss ppo:  -0.02796, loss val: 0.04636
[2022-12-06 18:41:27,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:41:27,264] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:41:27,264] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:41:34,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:41:42,469] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:41:50,494] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:41:57,644] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:42:04,858] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:42:12,040] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:42:19,515] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:42:27,004] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:42:35,282] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:42:44,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24261978996046724
[2022-12-06 18:42:44,127] [INFO] [runner_train_mujoco] Average state value: 0.7827858017285665
[2022-12-06 18:42:44,127] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 18:42:44,218] [INFO] [controller] EPOCH 1 loss ppo:  -0.00654, loss val: 0.04475
[2022-12-06 18:42:44,311] [INFO] [controller] EPOCH 2 loss ppo:  -0.01930, loss val: 0.04551
[2022-12-06 18:42:44,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.02284, loss val: 0.04462
[2022-12-06 18:42:44,456] [INFO] [controller] EPOCH 4 loss ppo:  -0.02709, loss val: 0.04279
[2022-12-06 18:42:44,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:42:44,745] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:42:44,747] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:42:54,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:43:02,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:43:11,121] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:43:19,378] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:43:28,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:43:36,498] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:43:44,724] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:43:54,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:44:03,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:44:11,443] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2592907153351311
[2022-12-06 18:44:11,443] [INFO] [runner_train_mujoco] Average state value: 0.7573381853501001
[2022-12-06 18:44:11,443] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 18:44:11,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.00591, loss val: 0.04085
[2022-12-06 18:44:11,659] [INFO] [controller] EPOCH 2 loss ppo:  -0.01653, loss val: 0.04043
[2022-12-06 18:44:11,784] [INFO] [controller] EPOCH 3 loss ppo:  -0.02069, loss val: 0.04071
[2022-12-06 18:44:11,866] [INFO] [controller] EPOCH 4 loss ppo:  -0.02569, loss val: 0.04173
[2022-12-06 18:44:11,880] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:44:12,125] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:44:12,125] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:44:20,503] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:44:28,768] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:44:37,341] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:44:45,509] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:44:53,628] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:45:02,412] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:45:11,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:45:18,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:45:27,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:45:36,010] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40808378593294253
[2022-12-06 18:45:36,010] [INFO] [runner_train_mujoco] Average state value: 0.7146346544424692
[2022-12-06 18:45:36,010] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 18:45:36,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.00932, loss val: 0.04124
[2022-12-06 18:45:36,192] [INFO] [controller] EPOCH 2 loss ppo:  -0.02137, loss val: 0.04118
[2022-12-06 18:45:36,308] [INFO] [controller] EPOCH 3 loss ppo:  -0.02378, loss val: 0.04175
[2022-12-06 18:45:36,408] [INFO] [controller] EPOCH 4 loss ppo:  -0.02798, loss val: 0.04177
[2022-12-06 18:45:36,421] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:45:36,753] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:45:36,754] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:45:45,551] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:45:54,169] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:46:02,101] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:46:11,143] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:46:20,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:46:27,964] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:46:35,921] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:46:44,526] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:46:53,546] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:47:02,079] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3693286301822952
[2022-12-06 18:47:02,080] [INFO] [runner_train_mujoco] Average state value: 0.7170728519956271
[2022-12-06 18:47:02,080] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 18:47:02,168] [INFO] [controller] EPOCH 1 loss ppo:  -0.00712, loss val: 0.04113
[2022-12-06 18:47:02,238] [INFO] [controller] EPOCH 2 loss ppo:  -0.01822, loss val: 0.04085
[2022-12-06 18:47:02,313] [INFO] [controller] EPOCH 3 loss ppo:  -0.02497, loss val: 0.04074
[2022-12-06 18:47:02,396] [INFO] [controller] EPOCH 4 loss ppo:  -0.02857, loss val: 0.04116
[2022-12-06 18:47:02,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:47:02,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:47:02,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:47:11,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:47:19,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:47:28,333] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:47:36,820] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:47:45,156] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:47:53,332] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:48:01,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:48:09,598] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:48:18,042] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:48:26,511] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3865057760161683
[2022-12-06 18:48:26,511] [INFO] [runner_train_mujoco] Average state value: 0.7264755374789237
[2022-12-06 18:48:26,512] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 18:48:26,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.00937, loss val: 0.03926
[2022-12-06 18:48:26,684] [INFO] [controller] EPOCH 2 loss ppo:  -0.02278, loss val: 0.03909
[2022-12-06 18:48:26,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.02671, loss val: 0.03920
[2022-12-06 18:48:26,848] [INFO] [controller] EPOCH 4 loss ppo:  -0.03116, loss val: 0.03898
[2022-12-06 18:48:26,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:48:27,081] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:48:27,081] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:48:35,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:48:43,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:48:51,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:48:59,547] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:49:08,084] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:49:16,146] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:49:24,464] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:49:33,179] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:49:41,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:49:49,624] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4340107179133915
[2022-12-06 18:49:49,624] [INFO] [runner_train_mujoco] Average state value: 0.7339495720465978
[2022-12-06 18:49:49,624] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 18:49:49,711] [INFO] [controller] EPOCH 1 loss ppo:  -0.00751, loss val: 0.04186
[2022-12-06 18:49:49,777] [INFO] [controller] EPOCH 2 loss ppo:  -0.02446, loss val: 0.04208
[2022-12-06 18:49:49,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.02617, loss val: 0.04253
[2022-12-06 18:49:49,909] [INFO] [controller] EPOCH 4 loss ppo:  -0.03181, loss val: 0.04182
[2022-12-06 18:49:49,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:49:50,157] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:49:50,157] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:49:58,086] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:50:06,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:50:14,875] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:50:22,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:50:30,803] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:50:39,442] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:50:48,123] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:50:56,820] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:51:04,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:51:12,439] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5226128063648755
[2022-12-06 18:51:12,440] [INFO] [runner_train_mujoco] Average state value: 0.7294153726498285
[2022-12-06 18:51:12,440] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 18:51:12,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.00874, loss val: 0.03892
[2022-12-06 18:51:12,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.02171, loss val: 0.03855
[2022-12-06 18:51:12,656] [INFO] [controller] EPOCH 3 loss ppo:  -0.02596, loss val: 0.03898
[2022-12-06 18:51:12,719] [INFO] [controller] EPOCH 4 loss ppo:  -0.03057, loss val: 0.03779
[2022-12-06 18:51:12,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:51:12,976] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:51:12,976] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:51:21,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:51:29,589] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:51:37,832] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:51:46,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:51:54,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:52:02,939] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:52:11,449] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:52:19,704] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:52:27,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:52:35,628] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5765913226604826
[2022-12-06 18:52:35,629] [INFO] [runner_train_mujoco] Average state value: 0.7030177082618078
[2022-12-06 18:52:35,629] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 18:52:35,725] [INFO] [controller] EPOCH 1 loss ppo:  -0.00849, loss val: 0.04625
[2022-12-06 18:52:35,792] [INFO] [controller] EPOCH 2 loss ppo:  -0.01847, loss val: 0.04536
[2022-12-06 18:52:35,862] [INFO] [controller] EPOCH 3 loss ppo:  -0.02313, loss val: 0.04425
[2022-12-06 18:52:35,931] [INFO] [controller] EPOCH 4 loss ppo:  -0.02723, loss val: 0.04336
[2022-12-06 18:52:35,943] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:52:36,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:52:36,167] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:52:44,402] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:52:52,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:53:00,885] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:53:09,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:53:17,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:53:25,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:53:33,920] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:53:42,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:53:50,726] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:53:59,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7626536624573177
[2022-12-06 18:53:59,113] [INFO] [runner_train_mujoco] Average state value: 0.714523432135582
[2022-12-06 18:53:59,113] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 18:53:59,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01000, loss val: 0.04161
[2022-12-06 18:53:59,279] [INFO] [controller] EPOCH 2 loss ppo:  -0.02241, loss val: 0.04169
[2022-12-06 18:53:59,353] [INFO] [controller] EPOCH 3 loss ppo:  -0.02545, loss val: 0.04114
[2022-12-06 18:53:59,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.03091, loss val: 0.04099
[2022-12-06 18:53:59,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:53:59,667] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:53:59,667] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:54:08,209] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:54:16,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:54:23,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:54:31,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:54:40,628] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:54:48,989] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:54:57,376] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:55:05,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:55:14,052] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:55:22,267] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7597273715826197
[2022-12-06 18:55:22,267] [INFO] [runner_train_mujoco] Average state value: 0.7116456333001455
[2022-12-06 18:55:22,267] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 18:55:22,357] [INFO] [controller] EPOCH 1 loss ppo:  -0.01093, loss val: 0.04445
[2022-12-06 18:55:22,449] [INFO] [controller] EPOCH 2 loss ppo:  -0.01836, loss val: 0.04506
[2022-12-06 18:55:22,545] [INFO] [controller] EPOCH 3 loss ppo:  -0.02104, loss val: 0.04437
[2022-12-06 18:55:22,651] [INFO] [controller] EPOCH 4 loss ppo:  -0.03007, loss val: 0.04412
[2022-12-06 18:55:22,668] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:55:22,919] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:55:22,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:55:31,379] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:55:39,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:55:47,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:55:55,902] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:56:04,447] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:56:12,672] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:56:20,871] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:56:29,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:56:37,565] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:56:45,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7346602117857046
[2022-12-06 18:56:45,462] [INFO] [runner_train_mujoco] Average state value: 0.7265358528296153
[2022-12-06 18:56:45,462] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 18:56:45,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01134, loss val: 0.04263
[2022-12-06 18:56:45,598] [INFO] [controller] EPOCH 2 loss ppo:  -0.02394, loss val: 0.04296
[2022-12-06 18:56:45,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.02618, loss val: 0.04271
[2022-12-06 18:56:45,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.03317, loss val: 0.04302
[2022-12-06 18:56:45,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:56:45,985] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:56:45,985] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:56:53,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:57:01,148] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:57:08,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:57:16,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:57:22,928] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:57:31,258] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:57:39,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:57:46,706] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:57:55,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:58:03,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8282218265770327
[2022-12-06 18:58:03,564] [INFO] [runner_train_mujoco] Average state value: 0.7419074804782867
[2022-12-06 18:58:03,564] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 18:58:03,680] [INFO] [controller] EPOCH 1 loss ppo:  -0.00905, loss val: 0.04263
[2022-12-06 18:58:03,986] [INFO] [controller] EPOCH 2 loss ppo:  -0.02333, loss val: 0.04185
[2022-12-06 18:58:04,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.02922, loss val: 0.04318
[2022-12-06 18:58:04,282] [INFO] [controller] EPOCH 4 loss ppo:  -0.03671, loss val: 0.04157
[2022-12-06 18:58:04,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:58:04,536] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:58:04,537] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:58:12,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:58:20,880] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:58:29,247] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:58:37,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:58:44,976] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:58:52,913] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:59:01,042] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:59:09,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:59:17,310] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:59:25,019] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8870565663429876
[2022-12-06 18:59:25,020] [INFO] [runner_train_mujoco] Average state value: 0.7151014816562336
[2022-12-06 18:59:25,020] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 18:59:25,126] [INFO] [controller] EPOCH 1 loss ppo:  -0.00900, loss val: 0.03880
[2022-12-06 18:59:25,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.02195, loss val: 0.03961
[2022-12-06 18:59:25,323] [INFO] [controller] EPOCH 3 loss ppo:  -0.02845, loss val: 0.03900
[2022-12-06 18:59:25,489] [INFO] [controller] EPOCH 4 loss ppo:  -0.03341, loss val: 0.03894
[2022-12-06 18:59:25,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:59:25,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:59:25,776] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:59:33,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:59:42,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:59:51,580] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:00:00,304] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:00:11,003] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:00:20,096] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:00:28,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:00:37,672] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:00:46,440] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:00:55,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9653481403420056
[2022-12-06 19:00:55,027] [INFO] [runner_train_mujoco] Average state value: 0.7006435087720553
[2022-12-06 19:00:55,027] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 19:00:55,125] [INFO] [controller] EPOCH 1 loss ppo:  -0.00969, loss val: 0.04358
[2022-12-06 19:00:55,211] [INFO] [controller] EPOCH 2 loss ppo:  -0.01973, loss val: 0.04433
[2022-12-06 19:00:55,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.02394, loss val: 0.04340
[2022-12-06 19:00:55,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.03114, loss val: 0.04340
[2022-12-06 19:00:55,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:00:55,612] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:00:55,612] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:01:04,680] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:01:13,834] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:01:23,026] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:01:31,888] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:01:40,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:01:49,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:01:58,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:02:07,815] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:02:16,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:02:25,866] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9636054274699374
[2022-12-06 19:02:25,866] [INFO] [runner_train_mujoco] Average state value: 0.7144942783117294
[2022-12-06 19:02:25,866] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 19:02:25,964] [INFO] [controller] EPOCH 1 loss ppo:  -0.01002, loss val: 0.03961
[2022-12-06 19:02:26,034] [INFO] [controller] EPOCH 2 loss ppo:  -0.02173, loss val: 0.03882
[2022-12-06 19:02:26,131] [INFO] [controller] EPOCH 3 loss ppo:  -0.02526, loss val: 0.03949
[2022-12-06 19:02:26,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.03111, loss val: 0.03920
[2022-12-06 19:02:26,294] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:02:26,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:02:26,567] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:02:35,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:02:45,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:02:54,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:03:03,129] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:03:12,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:03:21,412] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:03:30,439] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:03:39,406] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:03:48,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:03:57,792] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.069764498455708
[2022-12-06 19:03:57,792] [INFO] [runner_train_mujoco] Average state value: 0.7068461712996166
[2022-12-06 19:03:57,792] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 19:03:57,926] [INFO] [controller] EPOCH 1 loss ppo:  -0.00984, loss val: 0.03733
[2022-12-06 19:03:58,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.02260, loss val: 0.03700
[2022-12-06 19:03:58,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.02871, loss val: 0.03658
[2022-12-06 19:03:58,259] [INFO] [controller] EPOCH 4 loss ppo:  -0.03250, loss val: 0.03621
[2022-12-06 19:03:58,272] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:03:58,521] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:03:58,521] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:04:07,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:04:16,769] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:04:25,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:04:34,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:04:43,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:04:52,805] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:05:01,903] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:05:11,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:05:20,315] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:05:29,620] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1908168307252995
[2022-12-06 19:05:29,621] [INFO] [runner_train_mujoco] Average state value: 0.6746422264774641
[2022-12-06 19:05:29,621] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 19:05:29,730] [INFO] [controller] EPOCH 1 loss ppo:  -0.01117, loss val: 0.03787
[2022-12-06 19:05:29,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.02221, loss val: 0.03983
[2022-12-06 19:05:29,941] [INFO] [controller] EPOCH 3 loss ppo:  -0.03018, loss val: 0.03633
[2022-12-06 19:05:30,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.03313, loss val: 0.03850
[2022-12-06 19:05:30,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:05:30,322] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:05:30,322] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:05:39,383] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:05:48,534] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:05:56,532] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:06:03,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:06:12,002] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:06:19,964] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:06:27,880] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:06:35,619] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:06:43,757] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:06:52,137] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.184254360096175
[2022-12-06 19:06:52,139] [INFO] [runner_train_mujoco] Average state value: 0.6737355213562648
[2022-12-06 19:06:52,140] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 19:06:52,245] [INFO] [controller] EPOCH 1 loss ppo:  -0.01055, loss val: 0.04271
[2022-12-06 19:06:52,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.02032, loss val: 0.04240
[2022-12-06 19:06:52,404] [INFO] [controller] EPOCH 3 loss ppo:  -0.02595, loss val: 0.04259
[2022-12-06 19:06:52,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.03098, loss val: 0.04198
[2022-12-06 19:06:52,530] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:06:52,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:06:52,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:07:01,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:07:13,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:07:22,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:07:32,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:07:41,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:07:50,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:07:59,827] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:08:08,792] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:08:17,865] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:08:27,128] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.199832273224422
[2022-12-06 19:08:27,129] [INFO] [runner_train_mujoco] Average state value: 0.7058291832208633
[2022-12-06 19:08:27,129] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 19:08:27,240] [INFO] [controller] EPOCH 1 loss ppo:  -0.01027, loss val: 0.04213
[2022-12-06 19:08:27,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.01978, loss val: 0.04287
[2022-12-06 19:08:27,505] [INFO] [controller] EPOCH 3 loss ppo:  -0.02499, loss val: 0.04217
[2022-12-06 19:08:27,624] [INFO] [controller] EPOCH 4 loss ppo:  -0.03269, loss val: 0.04215
[2022-12-06 19:08:27,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:08:27,892] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:08:27,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:08:37,035] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:08:46,487] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:08:55,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:09:04,721] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:09:13,724] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:09:22,338] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:09:31,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:09:40,677] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:09:49,620] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:09:58,361] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.363679417443398
[2022-12-06 19:09:58,361] [INFO] [runner_train_mujoco] Average state value: 0.7219467027584712
[2022-12-06 19:09:58,362] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 19:09:58,472] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.04263
[2022-12-06 19:09:58,553] [INFO] [controller] EPOCH 2 loss ppo:  -0.02245, loss val: 0.04248
[2022-12-06 19:09:58,642] [INFO] [controller] EPOCH 3 loss ppo:  -0.02676, loss val: 0.04287
[2022-12-06 19:09:58,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.03245, loss val: 0.04182
[2022-12-06 19:09:58,730] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:09:58,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:09:58,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:10:08,034] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:10:17,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:10:26,217] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:10:35,072] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:10:43,988] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:10:53,286] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:11:02,396] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:11:11,239] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:11:19,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:11:28,430] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.431075367767689
[2022-12-06 19:11:28,431] [INFO] [runner_train_mujoco] Average state value: 0.6994400839805603
[2022-12-06 19:11:28,431] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 19:11:28,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04471
[2022-12-06 19:11:28,620] [INFO] [controller] EPOCH 2 loss ppo:  -0.02050, loss val: 0.04440
[2022-12-06 19:11:28,716] [INFO] [controller] EPOCH 3 loss ppo:  -0.02513, loss val: 0.04391
[2022-12-06 19:11:28,801] [INFO] [controller] EPOCH 4 loss ppo:  -0.02941, loss val: 0.04454
[2022-12-06 19:11:28,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:11:29,049] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:11:29,049] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:11:38,301] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:11:47,396] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:11:56,197] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:12:04,927] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:12:14,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:12:23,248] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:12:32,397] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:12:41,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:12:49,521] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:12:58,241] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4340485430282073
[2022-12-06 19:12:58,241] [INFO] [runner_train_mujoco] Average state value: 0.6912114498019218
[2022-12-06 19:12:58,241] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 19:12:58,361] [INFO] [controller] EPOCH 1 loss ppo:  -0.00934, loss val: 0.03723
[2022-12-06 19:12:58,437] [INFO] [controller] EPOCH 2 loss ppo:  -0.01755, loss val: 0.03695
[2022-12-06 19:12:58,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.02406, loss val: 0.03641
[2022-12-06 19:12:58,620] [INFO] [controller] EPOCH 4 loss ppo:  -0.02690, loss val: 0.03590
[2022-12-06 19:12:58,633] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:12:58,873] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:12:58,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:13:08,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:13:16,844] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:13:25,237] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:13:33,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:13:42,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:13:51,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:14:00,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:14:09,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:14:17,663] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:14:26,089] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5902833900242512
[2022-12-06 19:14:26,090] [INFO] [runner_train_mujoco] Average state value: 0.6584574965238572
[2022-12-06 19:14:26,090] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 19:14:26,204] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04119
[2022-12-06 19:14:26,284] [INFO] [controller] EPOCH 2 loss ppo:  -0.02089, loss val: 0.04203
[2022-12-06 19:14:26,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.02969, loss val: 0.04163
[2022-12-06 19:14:26,546] [INFO] [controller] EPOCH 4 loss ppo:  -0.03734, loss val: 0.04153
[2022-12-06 19:14:26,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:14:26,792] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:14:26,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:14:35,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:14:44,105] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:14:52,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:15:00,743] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:15:09,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:15:18,166] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:15:27,520] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:15:36,922] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:15:45,680] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:15:54,211] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5885986511766563
[2022-12-06 19:15:54,211] [INFO] [runner_train_mujoco] Average state value: 0.6482311787406603
[2022-12-06 19:15:54,211] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 19:15:54,356] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04182
[2022-12-06 19:15:54,429] [INFO] [controller] EPOCH 2 loss ppo:  -0.02592, loss val: 0.04180
[2022-12-06 19:15:54,510] [INFO] [controller] EPOCH 3 loss ppo:  -0.02819, loss val: 0.04197
[2022-12-06 19:15:54,594] [INFO] [controller] EPOCH 4 loss ppo:  -0.03533, loss val: 0.04116
[2022-12-06 19:15:54,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:15:54,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:15:54,837] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:16:03,338] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:16:14,699] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:16:23,199] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:16:31,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:16:40,430] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:16:49,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:16:59,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:17:08,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:17:17,330] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:17:27,194] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.645847835408445
[2022-12-06 19:17:27,195] [INFO] [runner_train_mujoco] Average state value: 0.6723464799920718
[2022-12-06 19:17:27,195] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 19:17:27,522] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.03960
[2022-12-06 19:17:27,983] [INFO] [controller] EPOCH 2 loss ppo:  -0.01829, loss val: 0.03983
[2022-12-06 19:17:28,546] [INFO] [controller] EPOCH 3 loss ppo:  -0.02428, loss val: 0.03937
[2022-12-06 19:17:28,933] [INFO] [controller] EPOCH 4 loss ppo:  -0.02902, loss val: 0.03926
[2022-12-06 19:17:28,946] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:17:29,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:17:29,294] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:17:38,290] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:17:48,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:17:58,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:18:07,527] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:18:16,256] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:18:24,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:18:31,762] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:18:41,660] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:19:06,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:19:22,136] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.666033224773028
[2022-12-06 19:19:22,136] [INFO] [runner_train_mujoco] Average state value: 0.6838087396621704
[2022-12-06 19:19:22,136] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 19:19:25,844] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.03997
[2022-12-06 19:19:26,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.02274, loss val: 0.04075
[2022-12-06 19:19:26,833] [INFO] [controller] EPOCH 3 loss ppo:  -0.02806, loss val: 0.04033
[2022-12-06 19:19:26,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.03527, loss val: 0.03943
[2022-12-06 19:19:26,939] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:19:27,157] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:19:27,157] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:19:36,746] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:19:44,531] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:19:50,870] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:19:57,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:20:02,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:20:08,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:20:14,333] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:20:19,838] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:20:25,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:20:31,048] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7904042092869255
[2022-12-06 19:20:31,048] [INFO] [runner_train_mujoco] Average state value: 0.6807210452953975
[2022-12-06 19:20:31,048] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 19:20:31,132] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.04182
[2022-12-06 19:20:31,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.04175
[2022-12-06 19:20:31,227] [INFO] [controller] EPOCH 3 loss ppo:  -0.02528, loss val: 0.04182
[2022-12-06 19:20:31,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.03256, loss val: 0.04152
[2022-12-06 19:20:31,290] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:20:31,462] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:20:31,462] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:20:37,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:20:42,790] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:20:48,486] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:20:54,184] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:20:59,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:21:05,707] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:21:11,345] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:21:17,252] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:21:22,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:21:28,438] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.746571115849413
[2022-12-06 19:21:28,438] [INFO] [runner_train_mujoco] Average state value: 0.6572222919066747
[2022-12-06 19:21:28,438] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 19:21:28,505] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04081
[2022-12-06 19:21:28,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.02445, loss val: 0.04234
[2022-12-06 19:21:28,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.02869, loss val: 0.04079
[2022-12-06 19:21:28,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.03485, loss val: 0.04073
[2022-12-06 19:21:28,660] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:21:28,829] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:21:28,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:21:34,720] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:21:40,340] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:21:46,056] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:21:51,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:21:57,514] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:22:03,095] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:22:08,887] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:22:14,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:22:20,932] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:22:26,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8517604462453963
[2022-12-06 19:22:26,459] [INFO] [runner_train_mujoco] Average state value: 0.6543288720051448
[2022-12-06 19:22:26,459] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 19:22:26,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.04215
[2022-12-06 19:22:26,589] [INFO] [controller] EPOCH 2 loss ppo:  -0.01848, loss val: 0.04250
[2022-12-06 19:22:26,659] [INFO] [controller] EPOCH 3 loss ppo:  -0.02654, loss val: 0.04157
[2022-12-06 19:22:26,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.02950, loss val: 0.04160
[2022-12-06 19:22:26,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:22:26,900] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:22:26,900] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:22:32,829] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:22:38,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:22:44,836] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:22:50,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:22:56,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:23:01,643] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:23:07,725] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:23:13,488] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:23:19,429] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:23:25,280] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0164144853987134
[2022-12-06 19:23:25,280] [INFO] [runner_train_mujoco] Average state value: 0.664432884812355
[2022-12-06 19:23:25,280] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 19:23:25,412] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.04132
[2022-12-06 19:23:25,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.02161, loss val: 0.04140
[2022-12-06 19:23:25,561] [INFO] [controller] EPOCH 3 loss ppo:  -0.02248, loss val: 0.04102
[2022-12-06 19:23:25,697] [INFO] [controller] EPOCH 4 loss ppo:  -0.02927, loss val: 0.04033
[2022-12-06 19:23:25,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:23:25,899] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:23:25,900] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:23:31,996] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:23:38,364] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:23:44,580] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:23:50,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:23:56,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:24:03,266] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:24:09,859] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:24:15,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:24:22,031] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:24:28,533] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0655729085187495
[2022-12-06 19:24:28,534] [INFO] [runner_train_mujoco] Average state value: 0.6465838117996852
[2022-12-06 19:24:28,534] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 19:24:28,602] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.04337
[2022-12-06 19:24:28,670] [INFO] [controller] EPOCH 2 loss ppo:  -0.01718, loss val: 0.04343
[2022-12-06 19:24:28,723] [INFO] [controller] EPOCH 3 loss ppo:  -0.02394, loss val: 0.04526
[2022-12-06 19:24:28,779] [INFO] [controller] EPOCH 4 loss ppo:  -0.02822, loss val: 0.04445
[2022-12-06 19:24:28,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:24:28,976] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:24:28,977] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:24:35,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:24:42,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:24:48,114] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:24:54,546] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:25:00,641] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:25:06,964] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:25:12,912] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:25:19,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:25:25,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:25:31,517] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0726244255219854
[2022-12-06 19:25:31,517] [INFO] [runner_train_mujoco] Average state value: 0.6453202785253523
[2022-12-06 19:25:31,517] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 19:25:31,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04404
[2022-12-06 19:25:31,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.01871, loss val: 0.04208
[2022-12-06 19:25:31,733] [INFO] [controller] EPOCH 3 loss ppo:  -0.02266, loss val: 0.04270
[2022-12-06 19:25:31,806] [INFO] [controller] EPOCH 4 loss ppo:  -0.02971, loss val: 0.04300
[2022-12-06 19:25:31,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:25:32,028] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:25:32,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:25:38,374] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:25:45,106] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:25:51,944] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:25:58,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:26:05,182] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:26:11,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:26:17,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:26:24,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:26:30,801] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:26:37,355] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0466475661977563
[2022-12-06 19:26:37,356] [INFO] [runner_train_mujoco] Average state value: 0.6466923084060351
[2022-12-06 19:26:37,356] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 19:26:37,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.04220
[2022-12-06 19:26:37,751] [INFO] [controller] EPOCH 2 loss ppo:  -0.01514, loss val: 0.04399
[2022-12-06 19:26:37,818] [INFO] [controller] EPOCH 3 loss ppo:  -0.01719, loss val: 0.04224
[2022-12-06 19:26:37,895] [INFO] [controller] EPOCH 4 loss ppo:  -0.02545, loss val: 0.04245
[2022-12-06 19:26:37,907] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:26:38,135] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:26:38,136] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:26:44,698] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:26:51,157] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:26:57,497] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:27:04,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:27:11,146] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:27:17,867] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:27:25,058] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:27:32,273] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:27:39,106] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:27:46,086] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1672324297473993
[2022-12-06 19:27:46,086] [INFO] [runner_train_mujoco] Average state value: 0.6483864465157191
[2022-12-06 19:27:46,087] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 19:27:46,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.01211, loss val: 0.04088
[2022-12-06 19:27:46,255] [INFO] [controller] EPOCH 2 loss ppo:  -0.01832, loss val: 0.04201
[2022-12-06 19:27:46,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.02177, loss val: 0.04199
[2022-12-06 19:27:46,394] [INFO] [controller] EPOCH 4 loss ppo:  -0.03058, loss val: 0.04081
[2022-12-06 19:27:46,405] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:27:46,622] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:27:46,622] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:27:53,808] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:28:00,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:28:07,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:28:15,007] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:28:22,208] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:28:29,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:28:36,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:28:43,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:28:50,996] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:28:58,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.150564400482979
[2022-12-06 19:28:58,231] [INFO] [runner_train_mujoco] Average state value: 0.6519129530986151
[2022-12-06 19:28:58,231] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 19:28:58,310] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.04008
[2022-12-06 19:28:58,378] [INFO] [controller] EPOCH 2 loss ppo:  -0.01880, loss val: 0.04033
[2022-12-06 19:28:58,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.02353, loss val: 0.03979
[2022-12-06 19:28:58,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.02597, loss val: 0.03973
[2022-12-06 19:28:58,557] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:28:58,774] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:28:58,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:29:06,333] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:29:14,062] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:29:21,356] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:29:28,767] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:29:36,229] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:29:43,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:29:51,327] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:29:59,560] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:30:07,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:30:16,352] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2618541708196886
[2022-12-06 19:30:16,352] [INFO] [runner_train_mujoco] Average state value: 0.655120877802372
[2022-12-06 19:30:16,353] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 19:30:16,516] [INFO] [controller] EPOCH 1 loss ppo:  -0.01585, loss val: 0.03997
[2022-12-06 19:30:16,608] [INFO] [controller] EPOCH 2 loss ppo:  -0.02071, loss val: 0.03997
[2022-12-06 19:30:16,684] [INFO] [controller] EPOCH 3 loss ppo:  -0.02204, loss val: 0.04043
[2022-12-06 19:30:16,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.03009, loss val: 0.04062
[2022-12-06 19:30:16,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:30:17,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:30:17,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:30:25,321] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:30:33,523] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:30:42,023] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:30:49,939] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:30:58,080] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:31:06,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:31:15,509] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:31:24,044] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:31:32,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:31:41,761] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3222225128381124
[2022-12-06 19:31:41,761] [INFO] [runner_train_mujoco] Average state value: 0.6498388532797497
[2022-12-06 19:31:41,762] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 19:31:42,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04140
[2022-12-06 19:31:42,167] [INFO] [controller] EPOCH 2 loss ppo:  -0.01450, loss val: 0.04089
[2022-12-06 19:31:42,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.01827, loss val: 0.04160
[2022-12-06 19:31:42,465] [INFO] [controller] EPOCH 4 loss ppo:  -0.02404, loss val: 0.04280
[2022-12-06 19:31:42,483] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:31:42,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:31:42,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:31:52,441] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:32:02,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:32:11,874] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:32:21,612] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:32:30,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:32:40,480] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:32:50,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:33:00,337] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:33:10,734] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:33:20,985] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.292743596239351
[2022-12-06 19:33:20,985] [INFO] [runner_train_mujoco] Average state value: 0.6472399730682373
[2022-12-06 19:33:20,985] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 19:33:21,097] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.04015
[2022-12-06 19:33:21,187] [INFO] [controller] EPOCH 2 loss ppo:  -0.02242, loss val: 0.03984
[2022-12-06 19:33:21,289] [INFO] [controller] EPOCH 3 loss ppo:  -0.02346, loss val: 0.04082
[2022-12-06 19:33:21,439] [INFO] [controller] EPOCH 4 loss ppo:  -0.02590, loss val: 0.04111
[2022-12-06 19:33:21,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:33:21,802] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:33:21,802] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:33:33,487] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:33:44,670] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:33:55,708] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:34:07,076] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:34:17,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:34:28,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:34:38,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:34:48,639] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:34:58,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:35:07,972] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3711253769610963
[2022-12-06 19:35:07,973] [INFO] [runner_train_mujoco] Average state value: 0.6397112583319347
[2022-12-06 19:35:07,973] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 19:35:08,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04606
[2022-12-06 19:35:08,159] [INFO] [controller] EPOCH 2 loss ppo:  -0.01684, loss val: 0.04705
[2022-12-06 19:35:08,246] [INFO] [controller] EPOCH 3 loss ppo:  -0.02386, loss val: 0.04692
[2022-12-06 19:35:08,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.03026, loss val: 0.04582
[2022-12-06 19:35:08,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:35:08,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:35:08,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:35:18,121] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:35:26,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:35:35,589] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:35:44,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:35:53,277] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:36:02,055] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:36:10,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:36:19,094] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:36:27,687] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:36:35,889] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4759230310982145
[2022-12-06 19:36:35,889] [INFO] [runner_train_mujoco] Average state value: 0.6430469248692195
[2022-12-06 19:36:35,890] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 19:36:35,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04422
[2022-12-06 19:36:36,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.01806, loss val: 0.04403
[2022-12-06 19:36:36,148] [INFO] [controller] EPOCH 3 loss ppo:  -0.01901, loss val: 0.04468
[2022-12-06 19:36:36,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.02230, loss val: 0.04419
[2022-12-06 19:36:36,230] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:36:36,465] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:36:36,466] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:36:45,253] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:36:52,959] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:37:01,010] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:37:09,447] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:37:17,349] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:37:25,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:37:32,903] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:37:39,998] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:37:47,211] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:37:55,020] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4540046932059916
[2022-12-06 19:37:55,020] [INFO] [runner_train_mujoco] Average state value: 0.648091628432274
[2022-12-06 19:37:55,021] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 19:37:55,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.04352
[2022-12-06 19:37:55,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.01619, loss val: 0.04273
[2022-12-06 19:37:55,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.01890, loss val: 0.04366
[2022-12-06 19:37:55,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.02191, loss val: 0.04266
[2022-12-06 19:37:55,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:37:55,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:37:55,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:38:02,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:38:09,931] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:38:17,176] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:38:24,599] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:38:31,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:38:38,787] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:38:45,407] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:38:51,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:38:58,788] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:39:05,731] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.49373145784928
[2022-12-06 19:39:05,732] [INFO] [runner_train_mujoco] Average state value: 0.650600483139356
[2022-12-06 19:39:05,732] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 19:39:05,841] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04230
[2022-12-06 19:39:05,904] [INFO] [controller] EPOCH 2 loss ppo:  -0.02065, loss val: 0.04257
[2022-12-06 19:39:05,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.02543, loss val: 0.04203
[2022-12-06 19:39:06,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.02590, loss val: 0.04227
[2022-12-06 19:39:06,044] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:39:06,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:39:06,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:39:13,668] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:39:20,868] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:39:27,933] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:39:35,340] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:39:42,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:39:50,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:39:57,806] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:40:05,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:40:13,247] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:40:20,810] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.545796171432079
[2022-12-06 19:40:20,811] [INFO] [runner_train_mujoco] Average state value: 0.6514794214566548
[2022-12-06 19:40:20,811] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 19:40:20,910] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.04285
[2022-12-06 19:40:20,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.01613, loss val: 0.04283
[2022-12-06 19:40:21,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.02048, loss val: 0.04271
[2022-12-06 19:40:21,114] [INFO] [controller] EPOCH 4 loss ppo:  -0.02251, loss val: 0.04185
[2022-12-06 19:40:21,127] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:40:21,368] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:40:21,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:40:29,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:40:36,955] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:40:45,097] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:40:53,314] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:41:01,743] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:41:11,999] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:41:20,241] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:41:27,877] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:41:36,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:41:45,299] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5413096566547506
[2022-12-06 19:41:45,299] [INFO] [runner_train_mujoco] Average state value: 0.6460886634588241
[2022-12-06 19:41:45,299] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 19:41:45,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04379
[2022-12-06 19:41:45,498] [INFO] [controller] EPOCH 2 loss ppo:  -0.01608, loss val: 0.04448
[2022-12-06 19:41:45,589] [INFO] [controller] EPOCH 3 loss ppo:  -0.01820, loss val: 0.04325
[2022-12-06 19:41:45,680] [INFO] [controller] EPOCH 4 loss ppo:  -0.02089, loss val: 0.04325
[2022-12-06 19:41:45,697] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:41:45,964] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:41:45,964] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:41:54,909] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:42:03,903] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:42:13,054] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:42:21,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:42:30,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:42:40,203] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:42:49,517] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:42:58,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:43:09,225] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:43:19,027] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6203734676227417
[2022-12-06 19:43:19,027] [INFO] [runner_train_mujoco] Average state value: 0.6449363593657811
[2022-12-06 19:43:19,028] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 19:43:19,218] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.04496
[2022-12-06 19:43:19,340] [INFO] [controller] EPOCH 2 loss ppo:  -0.01447, loss val: 0.04510
[2022-12-06 19:43:19,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.01608, loss val: 0.04530
[2022-12-06 19:43:19,619] [INFO] [controller] EPOCH 4 loss ppo:  -0.01761, loss val: 0.04518
[2022-12-06 19:43:19,640] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:43:20,106] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:43:20,106] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:43:32,497] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:43:42,285] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:43:51,459] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:44:02,367] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:44:10,888] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:44:18,786] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:44:26,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:44:33,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:44:41,011] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:44:48,136] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.626707038596974
[2022-12-06 19:44:48,136] [INFO] [runner_train_mujoco] Average state value: 0.6463518330256145
[2022-12-06 19:44:48,136] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 19:44:48,234] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.04252
[2022-12-06 19:44:48,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.01377, loss val: 0.04139
[2022-12-06 19:44:48,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.01519, loss val: 0.04254
[2022-12-06 19:44:48,436] [INFO] [controller] EPOCH 4 loss ppo:  -0.01783, loss val: 0.04125
[2022-12-06 19:44:48,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:44:48,686] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:44:48,686] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:44:56,445] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:45:03,919] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:45:11,039] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:45:18,564] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:45:26,006] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:45:33,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:45:40,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:45:47,967] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:45:54,686] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:46:02,502] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6558449835481226
[2022-12-06 19:46:02,502] [INFO] [runner_train_mujoco] Average state value: 0.6468932529687883
[2022-12-06 19:46:02,502] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 19:46:02,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04573
[2022-12-06 19:46:02,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.01398, loss val: 0.04464
[2022-12-06 19:46:02,770] [INFO] [controller] EPOCH 3 loss ppo:  -0.01516, loss val: 0.04403
[2022-12-06 19:46:02,847] [INFO] [controller] EPOCH 4 loss ppo:  -0.01654, loss val: 0.04396
[2022-12-06 19:46:02,861] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:46:03,082] [INFO] [optimize] Finished learning.
