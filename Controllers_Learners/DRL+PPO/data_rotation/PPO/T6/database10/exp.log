[2022-12-07 11:01:30,123] [INFO] [optimize] Starting learning
[2022-12-07 11:01:30,134] [INFO] [optimize] Starting learning process..
[2022-12-07 11:01:30,202] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:01:30,204] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:01:39,054] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:01:46,539] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:01:54,330] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:02:01,863] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:02:09,916] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:02:17,018] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:02:24,612] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:02:31,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:02:39,331] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:02:46,305] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15764623925666543
[2022-12-07 11:02:46,306] [INFO] [runner_train_mujoco] Average state value: 0.27353402784839276
[2022-12-07 11:02:46,306] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 11:02:46,418] [INFO] [controller] EPOCH 1 loss ppo:  -0.01700, loss val: 0.23646
[2022-12-07 11:02:46,505] [INFO] [controller] EPOCH 2 loss ppo:  -0.03314, loss val: 0.20101
[2022-12-07 11:02:46,576] [INFO] [controller] EPOCH 3 loss ppo:  -0.03799, loss val: 0.17603
[2022-12-07 11:02:46,645] [INFO] [controller] EPOCH 4 loss ppo:  -0.04142, loss val: 0.16629
[2022-12-07 11:02:46,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:02:46,865] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:02:46,866] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:02:53,946] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:03:01,255] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:03:08,287] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:03:15,781] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:03:23,052] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:03:30,001] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:03:37,585] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:03:44,780] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:03:51,973] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:03:59,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.12844036323709596
[2022-12-07 11:03:59,544] [INFO] [runner_train_mujoco] Average state value: 0.4909332496567318
[2022-12-07 11:03:59,545] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 11:03:59,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.15792
[2022-12-07 11:03:59,686] [INFO] [controller] EPOCH 2 loss ppo:  -0.02399, loss val: 0.14027
[2022-12-07 11:03:59,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.02920, loss val: 0.12675
[2022-12-07 11:03:59,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.03191, loss val: 0.11343
[2022-12-07 11:03:59,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:04:00,001] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:04:00,001] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:04:07,134] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:04:14,232] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:04:20,796] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:04:27,965] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:04:34,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:04:41,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:04:47,896] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:04:54,138] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:05:00,758] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:05:07,286] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22302767599062742
[2022-12-07 11:05:07,287] [INFO] [runner_train_mujoco] Average state value: 0.622322697930038
[2022-12-07 11:05:07,287] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 11:05:07,368] [INFO] [controller] EPOCH 1 loss ppo:  -0.01201, loss val: 0.11102
[2022-12-07 11:05:07,429] [INFO] [controller] EPOCH 2 loss ppo:  -0.02362, loss val: 0.10061
[2022-12-07 11:05:07,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.02615, loss val: 0.09236
[2022-12-07 11:05:07,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.03106, loss val: 0.08743
[2022-12-07 11:05:07,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:05:07,755] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:05:07,756] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:05:13,974] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:05:21,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:05:28,040] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:05:35,269] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:05:41,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:05:48,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:05:54,747] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:06:01,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:06:08,294] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:06:14,805] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17246813472094685
[2022-12-07 11:06:14,805] [INFO] [runner_train_mujoco] Average state value: 0.7358157577216625
[2022-12-07 11:06:14,805] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 11:06:14,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.00953, loss val: 0.08637
[2022-12-07 11:06:14,931] [INFO] [controller] EPOCH 2 loss ppo:  -0.02000, loss val: 0.08118
[2022-12-07 11:06:14,995] [INFO] [controller] EPOCH 3 loss ppo:  -0.02278, loss val: 0.07612
[2022-12-07 11:06:15,059] [INFO] [controller] EPOCH 4 loss ppo:  -0.02738, loss val: 0.07132
[2022-12-07 11:06:15,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:06:15,258] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:06:15,258] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:06:22,094] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:06:29,403] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:06:36,204] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:06:43,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:06:50,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:06:57,053] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:07:04,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:07:14,044] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:07:23,109] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:07:32,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.13473995164564226
[2022-12-07 11:07:32,018] [INFO] [runner_train_mujoco] Average state value: 0.7617714353203773
[2022-12-07 11:07:32,018] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 11:07:32,125] [INFO] [controller] EPOCH 1 loss ppo:  -0.00768, loss val: 0.06485
[2022-12-07 11:07:32,212] [INFO] [controller] EPOCH 2 loss ppo:  -0.01717, loss val: 0.06164
[2022-12-07 11:07:32,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.02260, loss val: 0.05762
[2022-12-07 11:07:32,423] [INFO] [controller] EPOCH 4 loss ppo:  -0.02367, loss val: 0.05428
[2022-12-07 11:07:32,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:07:32,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:07:32,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:07:40,485] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:07:47,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:07:54,309] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:08:01,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:08:08,693] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:08:16,312] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:08:23,869] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:08:31,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:08:38,967] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:08:46,743] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2050578548185841
[2022-12-07 11:08:46,744] [INFO] [runner_train_mujoco] Average state value: 0.7276219672362011
[2022-12-07 11:08:46,744] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 11:08:46,837] [INFO] [controller] EPOCH 1 loss ppo:  -0.00636, loss val: 0.05558
[2022-12-07 11:08:46,893] [INFO] [controller] EPOCH 2 loss ppo:  -0.01307, loss val: 0.05382
[2022-12-07 11:08:46,949] [INFO] [controller] EPOCH 3 loss ppo:  -0.02091, loss val: 0.05239
[2022-12-07 11:08:47,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.02279, loss val: 0.05112
[2022-12-07 11:08:47,025] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:08:47,254] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:08:47,254] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:08:54,779] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:09:02,367] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:09:09,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:09:17,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:09:25,393] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:09:33,827] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:09:41,976] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:09:49,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:09:56,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:10:03,458] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18922291398949545
[2022-12-07 11:10:03,458] [INFO] [runner_train_mujoco] Average state value: 0.6857898033459982
[2022-12-07 11:10:03,458] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 11:10:03,541] [INFO] [controller] EPOCH 1 loss ppo:  -0.00848, loss val: 0.04854
[2022-12-07 11:10:03,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.02189, loss val: 0.04784
[2022-12-07 11:10:03,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.02615, loss val: 0.04633
[2022-12-07 11:10:03,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.03086, loss val: 0.04541
[2022-12-07 11:10:03,775] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:10:03,973] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:10:03,974] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:10:10,660] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:10:17,900] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:10:24,737] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:10:32,072] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:10:39,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:10:45,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:10:52,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:10:59,053] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:11:05,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:11:14,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17247089110063912
[2022-12-07 11:11:14,335] [INFO] [runner_train_mujoco] Average state value: 0.7013015584150949
[2022-12-07 11:11:14,335] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 11:11:14,423] [INFO] [controller] EPOCH 1 loss ppo:  -0.00755, loss val: 0.05074
[2022-12-07 11:11:14,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01921, loss val: 0.04873
[2022-12-07 11:11:14,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.02224, loss val: 0.05039
[2022-12-07 11:11:14,654] [INFO] [controller] EPOCH 4 loss ppo:  -0.02631, loss val: 0.04812
[2022-12-07 11:11:14,670] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:11:14,884] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:11:14,885] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:11:22,152] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:11:29,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:11:35,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:11:42,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:11:49,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:11:56,587] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:12:02,979] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:12:09,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:12:14,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:12:20,714] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1639355398122688
[2022-12-07 11:12:20,715] [INFO] [runner_train_mujoco] Average state value: 0.7528228773673374
[2022-12-07 11:12:20,715] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 11:12:20,771] [INFO] [controller] EPOCH 1 loss ppo:  -0.00632, loss val: 0.04791
[2022-12-07 11:12:20,815] [INFO] [controller] EPOCH 2 loss ppo:  -0.01680, loss val: 0.04753
[2022-12-07 11:12:20,861] [INFO] [controller] EPOCH 3 loss ppo:  -0.01871, loss val: 0.04857
[2022-12-07 11:12:20,906] [INFO] [controller] EPOCH 4 loss ppo:  -0.02749, loss val: 0.04752
[2022-12-07 11:12:20,917] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:12:21,096] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:12:21,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:12:26,433] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:12:31,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:12:37,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:12:42,873] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:12:48,354] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:12:54,390] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:12:59,839] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:13:05,336] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:13:10,509] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:13:15,399] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.13648637208660855
[2022-12-07 11:13:15,399] [INFO] [runner_train_mujoco] Average state value: 0.7671590965986252
[2022-12-07 11:13:15,399] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 11:13:15,456] [INFO] [controller] EPOCH 1 loss ppo:  -0.00620, loss val: 0.04804
[2022-12-07 11:13:15,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.01927, loss val: 0.04643
[2022-12-07 11:13:15,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.02322, loss val: 0.04500
[2022-12-07 11:13:15,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.03007, loss val: 0.04446
[2022-12-07 11:13:15,593] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:13:15,766] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:13:15,767] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:13:21,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:13:26,900] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:13:32,406] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:13:37,542] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:13:42,701] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:13:47,559] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:13:52,480] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:13:57,564] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:14:02,491] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:14:07,985] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19014890819697333
[2022-12-07 11:14:07,985] [INFO] [runner_train_mujoco] Average state value: 0.7187157744566599
[2022-12-07 11:14:07,985] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 11:14:08,071] [INFO] [controller] EPOCH 1 loss ppo:  -0.00637, loss val: 0.04743
[2022-12-07 11:14:08,123] [INFO] [controller] EPOCH 2 loss ppo:  -0.01566, loss val: 0.05015
[2022-12-07 11:14:08,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.02228, loss val: 0.04748
[2022-12-07 11:14:08,243] [INFO] [controller] EPOCH 4 loss ppo:  -0.02212, loss val: 0.04712
[2022-12-07 11:14:08,254] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:14:08,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:14:08,440] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:14:13,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:14:18,928] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:14:24,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:14:30,211] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:14:35,384] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:14:40,624] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:14:45,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:14:50,455] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:14:55,865] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:15:01,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1965876623770493
[2022-12-07 11:15:01,659] [INFO] [runner_train_mujoco] Average state value: 0.7432313905556996
[2022-12-07 11:15:01,659] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 11:15:01,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.00498, loss val: 0.03984
[2022-12-07 11:15:01,768] [INFO] [controller] EPOCH 2 loss ppo:  -0.01448, loss val: 0.04057
[2022-12-07 11:15:01,828] [INFO] [controller] EPOCH 3 loss ppo:  -0.02108, loss val: 0.04096
[2022-12-07 11:15:01,879] [INFO] [controller] EPOCH 4 loss ppo:  -0.02455, loss val: 0.04199
[2022-12-07 11:15:01,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:15:02,073] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:15:02,073] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:15:09,075] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:15:15,839] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:15:20,828] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:15:26,219] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:15:32,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:15:38,456] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:15:44,851] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:15:50,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:15:57,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:16:04,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24984927529486747
[2022-12-07 11:16:04,835] [INFO] [runner_train_mujoco] Average state value: 0.7463665084044139
[2022-12-07 11:16:04,835] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 11:16:04,898] [INFO] [controller] EPOCH 1 loss ppo:  -0.00839, loss val: 0.04501
[2022-12-07 11:16:04,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.01972, loss val: 0.04469
[2022-12-07 11:16:05,008] [INFO] [controller] EPOCH 3 loss ppo:  -0.02398, loss val: 0.04596
[2022-12-07 11:16:05,064] [INFO] [controller] EPOCH 4 loss ppo:  -0.03026, loss val: 0.04489
[2022-12-07 11:16:05,075] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:16:05,258] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:16:05,258] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:16:11,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:16:17,253] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:16:22,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:16:28,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:16:33,622] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:16:38,851] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:16:44,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:16:50,830] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:16:57,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:17:03,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.33806039856203146
[2022-12-07 11:17:03,050] [INFO] [runner_train_mujoco] Average state value: 0.7230096241633097
[2022-12-07 11:17:03,051] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 11:17:03,116] [INFO] [controller] EPOCH 1 loss ppo:  -0.00667, loss val: 0.03994
[2022-12-07 11:17:03,173] [INFO] [controller] EPOCH 2 loss ppo:  -0.01845, loss val: 0.03887
[2022-12-07 11:17:03,227] [INFO] [controller] EPOCH 3 loss ppo:  -0.02336, loss val: 0.03946
[2022-12-07 11:17:03,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.02995, loss val: 0.03909
[2022-12-07 11:17:03,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:17:03,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:17:03,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:17:09,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:17:14,857] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:17:20,106] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:17:25,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:17:31,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:17:38,207] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:17:45,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:17:52,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:17:57,885] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:18:04,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46545887701681943
[2022-12-07 11:18:04,117] [INFO] [runner_train_mujoco] Average state value: 0.6998467363715172
[2022-12-07 11:18:04,117] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 11:18:04,176] [INFO] [controller] EPOCH 1 loss ppo:  -0.00967, loss val: 0.04234
[2022-12-07 11:18:04,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.01957, loss val: 0.04125
[2022-12-07 11:18:04,272] [INFO] [controller] EPOCH 3 loss ppo:  -0.02396, loss val: 0.04190
[2022-12-07 11:18:04,322] [INFO] [controller] EPOCH 4 loss ppo:  -0.02935, loss val: 0.04093
[2022-12-07 11:18:04,333] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:18:04,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:18:04,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:18:10,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:18:16,412] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:18:21,677] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:18:26,971] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:18:32,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:18:37,707] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:18:43,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:18:49,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:18:54,899] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:19:00,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3557926174544948
[2022-12-07 11:19:00,109] [INFO] [runner_train_mujoco] Average state value: 0.7066004284620284
[2022-12-07 11:19:00,110] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 11:19:00,165] [INFO] [controller] EPOCH 1 loss ppo:  -0.00683, loss val: 0.04341
[2022-12-07 11:19:00,223] [INFO] [controller] EPOCH 2 loss ppo:  -0.01913, loss val: 0.04129
[2022-12-07 11:19:00,271] [INFO] [controller] EPOCH 3 loss ppo:  -0.02527, loss val: 0.04119
[2022-12-07 11:19:00,319] [INFO] [controller] EPOCH 4 loss ppo:  -0.02840, loss val: 0.04212
[2022-12-07 11:19:00,331] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:19:00,514] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:19:00,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:19:06,011] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:19:12,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:19:18,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:19:23,984] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:19:29,981] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:19:35,753] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:19:41,615] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:19:47,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:19:54,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:20:00,525] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48864334919374885
[2022-12-07 11:20:00,525] [INFO] [runner_train_mujoco] Average state value: 0.7275264226396879
[2022-12-07 11:20:00,525] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 11:20:00,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.00992, loss val: 0.04011
[2022-12-07 11:20:00,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.02512, loss val: 0.03976
[2022-12-07 11:20:00,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.03196, loss val: 0.03980
[2022-12-07 11:20:00,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.03772, loss val: 0.03970
[2022-12-07 11:20:00,803] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:20:01,003] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:20:01,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:20:06,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:20:12,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:20:17,379] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:20:22,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:20:28,473] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:20:34,596] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:20:40,488] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:20:46,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:20:51,626] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:20:57,494] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5758342629446708
[2022-12-07 11:20:57,495] [INFO] [runner_train_mujoco] Average state value: 0.7358277681668599
[2022-12-07 11:20:57,495] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 11:20:57,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.00972, loss val: 0.04678
[2022-12-07 11:20:57,610] [INFO] [controller] EPOCH 2 loss ppo:  -0.02154, loss val: 0.04597
[2022-12-07 11:20:57,663] [INFO] [controller] EPOCH 3 loss ppo:  -0.02555, loss val: 0.04632
[2022-12-07 11:20:57,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.03059, loss val: 0.04624
[2022-12-07 11:20:57,726] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:20:57,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:20:57,899] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:21:04,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:21:10,434] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:21:17,238] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:21:22,541] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:21:28,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:21:34,566] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:21:40,703] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:21:47,372] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:21:52,314] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:21:57,092] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6010829447815258
[2022-12-07 11:21:57,092] [INFO] [runner_train_mujoco] Average state value: 0.7216059694488844
[2022-12-07 11:21:57,092] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 11:21:57,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.00804, loss val: 0.04129
[2022-12-07 11:21:57,191] [INFO] [controller] EPOCH 2 loss ppo:  -0.02390, loss val: 0.04089
[2022-12-07 11:21:57,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.02993, loss val: 0.04146
[2022-12-07 11:21:57,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.03240, loss val: 0.04093
[2022-12-07 11:21:57,308] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:21:57,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:21:57,472] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:22:02,497] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:22:07,551] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:22:12,799] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:22:18,367] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:22:23,665] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:22:29,434] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:22:34,757] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:22:40,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:22:46,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:22:52,113] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6530600924134615
[2022-12-07 11:22:52,113] [INFO] [runner_train_mujoco] Average state value: 0.6780128303964933
[2022-12-07 11:22:52,113] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 11:22:52,177] [INFO] [controller] EPOCH 1 loss ppo:  -0.00917, loss val: 0.04160
[2022-12-07 11:22:52,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.02112, loss val: 0.04155
[2022-12-07 11:22:52,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.04149
[2022-12-07 11:22:52,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.03147, loss val: 0.04110
[2022-12-07 11:22:52,352] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:22:52,529] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:22:52,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:22:57,664] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:23:02,846] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:23:08,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:23:13,542] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:23:19,345] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:23:25,348] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:23:31,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:23:36,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:23:42,069] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:23:47,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8903717329520342
[2022-12-07 11:23:47,355] [INFO] [runner_train_mujoco] Average state value: 0.7027591821153958
[2022-12-07 11:23:47,355] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 11:23:47,429] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.03863
[2022-12-07 11:23:47,486] [INFO] [controller] EPOCH 2 loss ppo:  -0.02220, loss val: 0.04004
[2022-12-07 11:23:47,537] [INFO] [controller] EPOCH 3 loss ppo:  -0.02743, loss val: 0.03945
[2022-12-07 11:23:47,600] [INFO] [controller] EPOCH 4 loss ppo:  -0.02904, loss val: 0.03759
[2022-12-07 11:23:47,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:23:47,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:23:47,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:23:53,315] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:23:59,197] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:24:05,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:24:11,465] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:24:17,166] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:24:22,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:24:28,132] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:24:33,283] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:24:38,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:24:44,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8250921532847757
[2022-12-07 11:24:44,335] [INFO] [runner_train_mujoco] Average state value: 0.7309616419871647
[2022-12-07 11:24:44,335] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 11:24:44,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.04350
[2022-12-07 11:24:44,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.02234, loss val: 0.04304
[2022-12-07 11:24:44,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.02496, loss val: 0.04252
[2022-12-07 11:24:44,539] [INFO] [controller] EPOCH 4 loss ppo:  -0.03463, loss val: 0.04394
[2022-12-07 11:24:44,551] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:24:44,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:24:44,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:24:50,769] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:24:56,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:25:01,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:25:07,009] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:25:12,265] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:25:17,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:25:22,970] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:25:28,603] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:25:34,160] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:25:40,198] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9689026423361728
[2022-12-07 11:25:40,198] [INFO] [runner_train_mujoco] Average state value: 0.7258175576726595
[2022-12-07 11:25:40,199] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 11:25:40,287] [INFO] [controller] EPOCH 1 loss ppo:  -0.01177, loss val: 0.03902
[2022-12-07 11:25:40,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.02344, loss val: 0.03811
[2022-12-07 11:25:40,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.02732, loss val: 0.03908
[2022-12-07 11:25:40,594] [INFO] [controller] EPOCH 4 loss ppo:  -0.03336, loss val: 0.03785
[2022-12-07 11:25:40,605] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:25:40,830] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:25:40,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:25:46,586] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:25:52,933] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:25:58,436] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:26:04,013] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:26:09,885] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:26:16,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:26:22,187] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:26:27,836] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:26:33,538] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:26:39,046] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0640755814545817
[2022-12-07 11:26:39,047] [INFO] [runner_train_mujoco] Average state value: 0.6949287542899449
[2022-12-07 11:26:39,047] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 11:26:39,116] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.04094
[2022-12-07 11:26:39,168] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.03944
[2022-12-07 11:26:39,221] [INFO] [controller] EPOCH 3 loss ppo:  -0.02423, loss val: 0.03965
[2022-12-07 11:26:39,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.03122, loss val: 0.03928
[2022-12-07 11:26:39,352] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:26:39,533] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:26:39,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:26:45,103] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:26:52,025] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:26:58,199] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:27:03,993] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:27:09,447] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:27:14,559] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:27:20,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:27:25,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:27:31,423] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:27:37,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9670171123893674
[2022-12-07 11:27:37,123] [INFO] [runner_train_mujoco] Average state value: 0.6534151571790378
[2022-12-07 11:27:37,123] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 11:27:37,196] [INFO] [controller] EPOCH 1 loss ppo:  -0.01111, loss val: 0.04051
[2022-12-07 11:27:37,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.04216
[2022-12-07 11:27:37,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.02772, loss val: 0.03848
[2022-12-07 11:27:37,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.03369, loss val: 0.04042
[2022-12-07 11:27:37,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:27:37,655] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:27:37,656] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:27:43,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:27:49,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:27:54,535] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:28:00,200] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:28:05,779] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:28:10,823] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:28:15,822] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:28:20,826] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:28:25,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:28:30,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2011786890823282
[2022-12-07 11:28:30,971] [INFO] [runner_train_mujoco] Average state value: 0.6707324968973796
[2022-12-07 11:28:30,971] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 11:28:31,039] [INFO] [controller] EPOCH 1 loss ppo:  -0.01221, loss val: 0.03870
[2022-12-07 11:28:31,104] [INFO] [controller] EPOCH 2 loss ppo:  -0.02127, loss val: 0.03924
[2022-12-07 11:28:31,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.02658, loss val: 0.03836
[2022-12-07 11:28:31,257] [INFO] [controller] EPOCH 4 loss ppo:  -0.03591, loss val: 0.03960
[2022-12-07 11:28:31,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:28:31,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:28:31,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:28:37,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:28:43,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:28:48,763] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:28:54,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:28:59,698] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:29:05,460] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:29:11,195] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:29:16,492] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:29:21,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:29:27,573] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2216625814246453
[2022-12-07 11:29:27,574] [INFO] [runner_train_mujoco] Average state value: 0.6857015054623286
[2022-12-07 11:29:27,574] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 11:29:27,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04068
[2022-12-07 11:29:27,789] [INFO] [controller] EPOCH 2 loss ppo:  -0.02206, loss val: 0.04015
[2022-12-07 11:29:27,875] [INFO] [controller] EPOCH 3 loss ppo:  -0.02859, loss val: 0.03998
[2022-12-07 11:29:27,962] [INFO] [controller] EPOCH 4 loss ppo:  -0.03390, loss val: 0.03924
[2022-12-07 11:29:27,974] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:29:28,165] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:29:28,166] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:29:33,555] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:29:40,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:29:47,785] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:29:54,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:29:58,956] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:30:04,019] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:30:09,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:30:16,898] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:30:21,961] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:30:26,667] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3022522448252731
[2022-12-07 11:30:26,668] [INFO] [runner_train_mujoco] Average state value: 0.7090603298544884
[2022-12-07 11:30:26,668] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 11:30:26,721] [INFO] [controller] EPOCH 1 loss ppo:  -0.01126, loss val: 0.04431
[2022-12-07 11:30:26,769] [INFO] [controller] EPOCH 2 loss ppo:  -0.02038, loss val: 0.04385
[2022-12-07 11:30:26,814] [INFO] [controller] EPOCH 3 loss ppo:  -0.02991, loss val: 0.04323
[2022-12-07 11:30:26,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.03478, loss val: 0.04292
[2022-12-07 11:30:26,863] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:30:27,036] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:30:27,037] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:30:32,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:30:37,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:30:43,039] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:30:48,077] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:30:53,285] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:30:57,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:31:02,967] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:31:07,906] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:31:12,812] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:31:17,809] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4022790729859214
[2022-12-07 11:31:17,809] [INFO] [runner_train_mujoco] Average state value: 0.7407084513902664
[2022-12-07 11:31:17,809] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 11:31:17,872] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.04313
[2022-12-07 11:31:17,919] [INFO] [controller] EPOCH 2 loss ppo:  -0.02529, loss val: 0.04294
[2022-12-07 11:31:17,963] [INFO] [controller] EPOCH 3 loss ppo:  -0.02809, loss val: 0.04249
[2022-12-07 11:31:18,009] [INFO] [controller] EPOCH 4 loss ppo:  -0.03519, loss val: 0.04117
[2022-12-07 11:31:18,019] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:31:18,193] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:31:18,193] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:31:23,659] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:31:29,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:31:34,402] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:31:39,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:31:45,642] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:31:53,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:32:00,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:32:05,876] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:32:11,436] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:32:17,043] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3075046729324915
[2022-12-07 11:32:17,043] [INFO] [runner_train_mujoco] Average state value: 0.7175798010031381
[2022-12-07 11:32:17,043] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 11:32:17,099] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.04190
[2022-12-07 11:32:17,150] [INFO] [controller] EPOCH 2 loss ppo:  -0.02222, loss val: 0.04040
[2022-12-07 11:32:17,202] [INFO] [controller] EPOCH 3 loss ppo:  -0.02856, loss val: 0.03799
[2022-12-07 11:32:17,249] [INFO] [controller] EPOCH 4 loss ppo:  -0.03039, loss val: 0.03636
[2022-12-07 11:32:17,260] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:32:17,447] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:32:17,447] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:32:23,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:32:28,523] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:32:34,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:32:40,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:32:45,382] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:32:50,737] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:32:58,533] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:33:04,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:33:09,640] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:33:14,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4024090087548817
[2022-12-07 11:33:14,979] [INFO] [runner_train_mujoco] Average state value: 0.6401739254196486
[2022-12-07 11:33:14,980] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 11:33:15,039] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.04815
[2022-12-07 11:33:15,087] [INFO] [controller] EPOCH 2 loss ppo:  -0.02459, loss val: 0.04938
[2022-12-07 11:33:15,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.03168, loss val: 0.04894
[2022-12-07 11:33:15,240] [INFO] [controller] EPOCH 4 loss ppo:  -0.03557, loss val: 0.04774
[2022-12-07 11:33:15,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:33:15,449] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:33:15,449] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:33:21,060] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:33:26,545] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:33:32,189] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:33:37,350] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:33:42,968] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:33:48,456] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:33:55,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:34:04,007] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:34:09,943] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:34:16,209] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5681077346410361
[2022-12-07 11:34:16,209] [INFO] [runner_train_mujoco] Average state value: 0.6548108567198118
[2022-12-07 11:34:16,210] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 11:34:16,273] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04816
[2022-12-07 11:34:16,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.02286, loss val: 0.04646
[2022-12-07 11:34:16,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.02655, loss val: 0.04521
[2022-12-07 11:34:16,430] [INFO] [controller] EPOCH 4 loss ppo:  -0.03187, loss val: 0.04524
[2022-12-07 11:34:16,441] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:34:16,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:34:16,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:34:23,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:34:29,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:34:36,140] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:34:42,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:34:47,704] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:34:53,203] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:34:58,416] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:35:03,858] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:35:09,454] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:35:15,691] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6170489112955244
[2022-12-07 11:35:15,691] [INFO] [runner_train_mujoco] Average state value: 0.7215272301435471
[2022-12-07 11:35:15,691] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 11:35:15,807] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.04545
[2022-12-07 11:35:15,943] [INFO] [controller] EPOCH 2 loss ppo:  -0.02294, loss val: 0.04410
[2022-12-07 11:35:16,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.02683, loss val: 0.04490
[2022-12-07 11:35:16,388] [INFO] [controller] EPOCH 4 loss ppo:  -0.03309, loss val: 0.04497
[2022-12-07 11:35:16,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:35:16,672] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:35:16,672] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:35:27,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:35:35,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:35:41,604] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:35:48,406] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:35:56,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:36:01,785] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:36:07,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:36:13,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:36:21,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:36:30,068] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7336094807829046
[2022-12-07 11:36:30,068] [INFO] [runner_train_mujoco] Average state value: 0.7364016310373943
[2022-12-07 11:36:30,068] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 11:36:30,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.04314
[2022-12-07 11:36:30,390] [INFO] [controller] EPOCH 2 loss ppo:  -0.02287, loss val: 0.04311
[2022-12-07 11:36:30,452] [INFO] [controller] EPOCH 3 loss ppo:  -0.02906, loss val: 0.04209
[2022-12-07 11:36:30,532] [INFO] [controller] EPOCH 4 loss ppo:  -0.03408, loss val: 0.04248
[2022-12-07 11:36:30,543] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:36:30,771] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:36:30,772] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:36:37,779] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:36:44,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:36:51,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:36:57,943] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:37:03,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:37:08,652] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:37:13,815] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:37:18,668] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:37:23,904] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:37:29,513] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7617617457443937
[2022-12-07 11:37:29,514] [INFO] [runner_train_mujoco] Average state value: 0.7156403117974598
[2022-12-07 11:37:29,514] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 11:37:29,581] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.04185
[2022-12-07 11:37:29,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.02474, loss val: 0.04152
[2022-12-07 11:37:29,690] [INFO] [controller] EPOCH 3 loss ppo:  -0.03269, loss val: 0.04152
[2022-12-07 11:37:29,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.03596, loss val: 0.04149
[2022-12-07 11:37:29,749] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:37:29,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:37:29,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:37:35,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:37:40,871] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:37:45,929] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:37:51,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:37:56,914] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:38:03,295] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:38:09,406] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:38:15,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:38:22,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:38:28,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7421708334716364
[2022-12-07 11:38:28,542] [INFO] [runner_train_mujoco] Average state value: 0.6932555573383967
[2022-12-07 11:38:28,542] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 11:38:28,610] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.04121
[2022-12-07 11:38:28,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.01818, loss val: 0.04224
[2022-12-07 11:38:28,723] [INFO] [controller] EPOCH 3 loss ppo:  -0.02433, loss val: 0.04100
[2022-12-07 11:38:28,786] [INFO] [controller] EPOCH 4 loss ppo:  -0.02821, loss val: 0.04096
[2022-12-07 11:38:28,797] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:38:28,993] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:38:28,994] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:38:37,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:38:44,317] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:38:49,714] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:38:55,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:39:00,424] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:39:05,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:39:14,321] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:39:21,517] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:39:27,062] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:39:33,176] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.81906433503595
[2022-12-07 11:39:33,176] [INFO] [runner_train_mujoco] Average state value: 0.6787868607640266
[2022-12-07 11:39:33,177] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 11:39:33,255] [INFO] [controller] EPOCH 1 loss ppo:  -0.01486, loss val: 0.04334
[2022-12-07 11:39:33,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.02782, loss val: 0.04348
[2022-12-07 11:39:33,380] [INFO] [controller] EPOCH 3 loss ppo:  -0.03337, loss val: 0.04378
[2022-12-07 11:39:33,434] [INFO] [controller] EPOCH 4 loss ppo:  -0.03584, loss val: 0.04373
[2022-12-07 11:39:33,447] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:39:33,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:39:33,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:39:39,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:39:46,434] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:39:52,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:39:58,485] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:40:04,929] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:40:11,336] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:40:16,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:40:22,384] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:40:28,099] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:40:34,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7365443218134182
[2022-12-07 11:40:34,527] [INFO] [runner_train_mujoco] Average state value: 0.6846874206066131
[2022-12-07 11:40:34,527] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 11:40:34,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01567, loss val: 0.04520
[2022-12-07 11:40:34,635] [INFO] [controller] EPOCH 2 loss ppo:  -0.02705, loss val: 0.04461
[2022-12-07 11:40:34,693] [INFO] [controller] EPOCH 3 loss ppo:  -0.03059, loss val: 0.04472
[2022-12-07 11:40:34,745] [INFO] [controller] EPOCH 4 loss ppo:  -0.03447, loss val: 0.04458
[2022-12-07 11:40:34,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:40:34,955] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:40:34,955] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:40:40,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:40:46,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:40:51,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:40:57,126] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:41:03,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:41:09,035] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:41:15,308] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:41:20,697] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:41:25,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:41:31,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.874253839965429
[2022-12-07 11:41:31,088] [INFO] [runner_train_mujoco] Average state value: 0.6976039563814799
[2022-12-07 11:41:31,089] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 11:41:31,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.04246
[2022-12-07 11:41:31,204] [INFO] [controller] EPOCH 2 loss ppo:  -0.02239, loss val: 0.04279
[2022-12-07 11:41:31,255] [INFO] [controller] EPOCH 3 loss ppo:  -0.02782, loss val: 0.04472
[2022-12-07 11:41:31,302] [INFO] [controller] EPOCH 4 loss ppo:  -0.03135, loss val: 0.04362
[2022-12-07 11:41:31,316] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:41:31,495] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:41:31,495] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:41:36,340] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:41:42,294] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:41:47,364] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:41:52,386] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:41:57,597] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:42:02,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:42:08,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:42:14,359] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:42:19,352] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:42:24,393] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9682078543873398
[2022-12-07 11:42:24,393] [INFO] [runner_train_mujoco] Average state value: 0.6961829512516657
[2022-12-07 11:42:24,393] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 11:42:24,449] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04525
[2022-12-07 11:42:24,495] [INFO] [controller] EPOCH 2 loss ppo:  -0.02367, loss val: 0.04411
[2022-12-07 11:42:24,548] [INFO] [controller] EPOCH 3 loss ppo:  -0.02698, loss val: 0.04491
[2022-12-07 11:42:24,594] [INFO] [controller] EPOCH 4 loss ppo:  -0.02847, loss val: 0.04404
[2022-12-07 11:42:24,605] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:42:24,783] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:42:24,784] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:42:30,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:42:35,364] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:42:40,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:42:45,817] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:42:50,990] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:42:56,645] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:43:01,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:43:06,667] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:43:11,697] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:43:16,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0216414449755638
[2022-12-07 11:43:16,907] [INFO] [runner_train_mujoco] Average state value: 0.694253320813179
[2022-12-07 11:43:16,907] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 11:43:16,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.04007
[2022-12-07 11:43:17,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.02242, loss val: 0.04161
[2022-12-07 11:43:17,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.03021, loss val: 0.04017
[2022-12-07 11:43:17,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.03600, loss val: 0.03910
[2022-12-07 11:43:17,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:43:17,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:43:17,289] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:43:23,347] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:43:29,503] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:43:34,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:43:39,074] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:43:43,886] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:43:48,602] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:43:53,265] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:43:58,063] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:44:03,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:44:08,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.097955521596643
[2022-12-07 11:44:08,808] [INFO] [runner_train_mujoco] Average state value: 0.6787810952266058
[2022-12-07 11:44:08,808] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 11:44:08,867] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.04588
[2022-12-07 11:44:08,914] [INFO] [controller] EPOCH 2 loss ppo:  -0.02204, loss val: 0.04601
[2022-12-07 11:44:08,970] [INFO] [controller] EPOCH 3 loss ppo:  -0.02776, loss val: 0.04567
[2022-12-07 11:44:09,040] [INFO] [controller] EPOCH 4 loss ppo:  -0.02805, loss val: 0.04585
[2022-12-07 11:44:09,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:44:09,241] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:44:09,241] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:44:14,751] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:44:21,563] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:44:30,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:44:36,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:44:42,373] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:44:47,514] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:44:52,360] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:44:57,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:45:03,258] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:45:08,654] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1774154888611963
[2022-12-07 11:45:08,654] [INFO] [runner_train_mujoco] Average state value: 0.6752452779014906
[2022-12-07 11:45:08,654] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 11:45:08,714] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04261
[2022-12-07 11:45:08,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.01783, loss val: 0.04298
[2022-12-07 11:45:08,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.02411, loss val: 0.04259
[2022-12-07 11:45:08,867] [INFO] [controller] EPOCH 4 loss ppo:  -0.02856, loss val: 0.04559
[2022-12-07 11:45:08,877] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:45:09,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:45:09,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:45:14,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:45:19,326] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:45:24,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:45:29,895] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:45:35,995] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:45:42,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:45:49,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:45:55,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:46:02,998] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:46:10,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.166857478826664
[2022-12-07 11:46:10,027] [INFO] [runner_train_mujoco] Average state value: 0.6739970190127691
[2022-12-07 11:46:10,028] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 11:46:10,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01612, loss val: 0.04708
[2022-12-07 11:46:10,211] [INFO] [controller] EPOCH 2 loss ppo:  -0.02360, loss val: 0.04609
[2022-12-07 11:46:10,283] [INFO] [controller] EPOCH 3 loss ppo:  -0.02637, loss val: 0.04608
[2022-12-07 11:46:10,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.03036, loss val: 0.04715
[2022-12-07 11:46:10,382] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:46:10,590] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:46:10,590] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:46:16,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:46:22,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:46:28,581] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:46:34,300] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:46:39,790] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:46:46,293] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:46:52,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:46:58,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:47:04,358] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:47:10,246] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.203518901965877
[2022-12-07 11:47:10,246] [INFO] [runner_train_mujoco] Average state value: 0.6687698129018148
[2022-12-07 11:47:10,246] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 11:47:10,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01513, loss val: 0.04226
[2022-12-07 11:47:10,360] [INFO] [controller] EPOCH 2 loss ppo:  -0.02149, loss val: 0.04271
[2022-12-07 11:47:10,415] [INFO] [controller] EPOCH 3 loss ppo:  -0.02717, loss val: 0.04238
[2022-12-07 11:47:10,468] [INFO] [controller] EPOCH 4 loss ppo:  -0.02979, loss val: 0.04284
[2022-12-07 11:47:10,479] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:47:10,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:47:10,679] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:47:16,244] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:47:21,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:47:27,365] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:47:32,777] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:47:38,788] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:47:44,122] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:47:49,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:47:55,630] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:48:01,945] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:48:07,980] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2940054069981763
[2022-12-07 11:48:07,981] [INFO] [runner_train_mujoco] Average state value: 0.6694280418554943
[2022-12-07 11:48:07,981] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 11:48:08,047] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04368
[2022-12-07 11:48:08,096] [INFO] [controller] EPOCH 2 loss ppo:  -0.02164, loss val: 0.04446
[2022-12-07 11:48:08,145] [INFO] [controller] EPOCH 3 loss ppo:  -0.02218, loss val: 0.04333
[2022-12-07 11:48:08,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.02553, loss val: 0.04440
[2022-12-07 11:48:08,207] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:48:08,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:48:08,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:48:13,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:48:18,949] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:48:23,893] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:48:29,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:48:34,298] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:48:39,009] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:48:44,301] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:48:49,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:48:54,875] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:49:00,476] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3653069607748094
[2022-12-07 11:49:00,476] [INFO] [runner_train_mujoco] Average state value: 0.6765146803458533
[2022-12-07 11:49:00,476] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 11:49:00,532] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.04129
[2022-12-07 11:49:00,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.01774, loss val: 0.04126
[2022-12-07 11:49:00,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.02193, loss val: 0.04231
[2022-12-07 11:49:00,673] [INFO] [controller] EPOCH 4 loss ppo:  -0.02425, loss val: 0.04168
[2022-12-07 11:49:00,682] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:49:00,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:49:00,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:49:06,698] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:49:12,178] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:49:18,163] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:49:23,264] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:49:28,646] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:49:34,497] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:49:39,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:49:44,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:49:50,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:49:55,248] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4510556107015633
[2022-12-07 11:49:55,249] [INFO] [runner_train_mujoco] Average state value: 0.6818247510393461
[2022-12-07 11:49:55,249] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 11:49:55,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.04255
[2022-12-07 11:49:55,355] [INFO] [controller] EPOCH 2 loss ppo:  -0.01981, loss val: 0.04233
[2022-12-07 11:49:55,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.02491, loss val: 0.04107
[2022-12-07 11:49:55,456] [INFO] [controller] EPOCH 4 loss ppo:  -0.02800, loss val: 0.04339
[2022-12-07 11:49:55,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:49:55,650] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:49:55,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:50:00,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:50:06,322] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:50:11,471] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:50:16,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:50:21,913] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:50:26,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:50:31,224] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:50:36,197] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:50:41,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:50:46,316] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3424136406499962
[2022-12-07 11:50:46,316] [INFO] [runner_train_mujoco] Average state value: 0.6624061641097068
[2022-12-07 11:50:46,316] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 11:50:46,395] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04105
[2022-12-07 11:50:46,450] [INFO] [controller] EPOCH 2 loss ppo:  -0.01862, loss val: 0.04110
[2022-12-07 11:50:46,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.02280, loss val: 0.04046
[2022-12-07 11:50:46,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.02430, loss val: 0.04182
[2022-12-07 11:50:46,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:50:46,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:50:46,736] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:50:51,771] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:50:56,563] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:51:01,814] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:51:06,961] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:51:12,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:51:16,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:51:21,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:51:26,821] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:51:31,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:51:36,226] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4453075131429753
[2022-12-07 11:51:36,226] [INFO] [runner_train_mujoco] Average state value: 0.6487339835564295
[2022-12-07 11:51:36,226] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 11:51:36,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.03989
[2022-12-07 11:51:36,329] [INFO] [controller] EPOCH 2 loss ppo:  -0.01831, loss val: 0.04086
[2022-12-07 11:51:36,373] [INFO] [controller] EPOCH 3 loss ppo:  -0.02397, loss val: 0.04068
[2022-12-07 11:51:36,421] [INFO] [controller] EPOCH 4 loss ppo:  -0.02625, loss val: 0.03944
[2022-12-07 11:51:36,431] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:51:36,604] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:51:36,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:51:41,280] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:51:45,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:51:50,538] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:51:55,470] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:52:00,278] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:52:04,769] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:52:09,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:52:14,717] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:52:19,953] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:52:24,684] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4053987047212835
[2022-12-07 11:52:24,685] [INFO] [runner_train_mujoco] Average state value: 0.641916747490565
[2022-12-07 11:52:24,685] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 11:52:24,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01512, loss val: 0.04267
[2022-12-07 11:52:24,790] [INFO] [controller] EPOCH 2 loss ppo:  -0.01725, loss val: 0.04245
[2022-12-07 11:52:24,840] [INFO] [controller] EPOCH 3 loss ppo:  -0.02199, loss val: 0.04253
[2022-12-07 11:52:24,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.02501, loss val: 0.04235
[2022-12-07 11:52:24,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:52:25,079] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:52:25,079] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:52:30,704] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:52:35,839] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:52:40,967] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:52:45,845] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:52:50,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:52:55,238] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:52:59,889] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:53:04,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:53:09,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:53:14,929] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5042937194835146
[2022-12-07 11:53:14,929] [INFO] [runner_train_mujoco] Average state value: 0.6432581388354301
[2022-12-07 11:53:14,929] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 11:53:14,998] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.04270
[2022-12-07 11:53:15,054] [INFO] [controller] EPOCH 2 loss ppo:  -0.01711, loss val: 0.04370
[2022-12-07 11:53:15,105] [INFO] [controller] EPOCH 3 loss ppo:  -0.02079, loss val: 0.04288
[2022-12-07 11:53:15,156] [INFO] [controller] EPOCH 4 loss ppo:  -0.02390, loss val: 0.04269
[2022-12-07 11:53:15,167] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:53:15,348] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:53:15,349] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:53:20,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:53:25,834] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:53:30,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:53:35,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:53:40,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:53:45,547] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:53:50,295] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:53:54,881] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:54:00,168] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:54:06,466] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.516976699322087
[2022-12-07 11:54:06,466] [INFO] [runner_train_mujoco] Average state value: 0.6412432574629784
[2022-12-07 11:54:06,466] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 11:54:06,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04159
[2022-12-07 11:54:06,653] [INFO] [controller] EPOCH 2 loss ppo:  -0.01588, loss val: 0.04217
[2022-12-07 11:54:06,737] [INFO] [controller] EPOCH 3 loss ppo:  -0.01973, loss val: 0.04113
[2022-12-07 11:54:06,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.02396, loss val: 0.04106
[2022-12-07 11:54:06,832] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:54:07,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:54:07,148] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:54:14,756] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:54:20,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:54:25,881] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:54:32,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:54:40,297] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:54:47,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:54:54,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:55:00,648] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:55:08,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:55:18,398] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4840004781948437
[2022-12-07 11:55:18,399] [INFO] [runner_train_mujoco] Average state value: 0.639658406496048
[2022-12-07 11:55:18,399] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 11:55:18,742] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.04409
[2022-12-07 11:55:19,016] [INFO] [controller] EPOCH 2 loss ppo:  -0.01812, loss val: 0.04535
[2022-12-07 11:55:19,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.02320, loss val: 0.04415
[2022-12-07 11:55:19,527] [INFO] [controller] EPOCH 4 loss ppo:  -0.02570, loss val: 0.04381
[2022-12-07 11:55:19,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:55:19,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:55:19,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:55:26,726] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:55:34,031] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:55:41,137] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:55:46,757] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:55:52,234] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:55:57,599] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:56:03,367] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:56:09,196] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:56:14,563] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:56:19,496] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6817760462764655
[2022-12-07 11:56:19,496] [INFO] [runner_train_mujoco] Average state value: 0.6435522102117539
[2022-12-07 11:56:19,496] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 11:56:19,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.01521, loss val: 0.04289
[2022-12-07 11:56:19,605] [INFO] [controller] EPOCH 2 loss ppo:  -0.01725, loss val: 0.04375
[2022-12-07 11:56:19,655] [INFO] [controller] EPOCH 3 loss ppo:  -0.02096, loss val: 0.04357
[2022-12-07 11:56:19,712] [INFO] [controller] EPOCH 4 loss ppo:  -0.02402, loss val: 0.04258
[2022-12-07 11:56:19,724] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:56:19,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:56:19,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:56:25,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:56:30,151] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:56:35,459] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:56:40,829] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:56:45,998] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:56:51,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:56:56,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:57:02,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:57:08,131] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:57:13,864] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6235924344557615
[2022-12-07 11:57:13,864] [INFO] [runner_train_mujoco] Average state value: 0.6455940323869387
[2022-12-07 11:57:13,864] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 11:57:13,930] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04585
[2022-12-07 11:57:13,978] [INFO] [controller] EPOCH 2 loss ppo:  -0.01606, loss val: 0.04532
[2022-12-07 11:57:14,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.01846, loss val: 0.04534
[2022-12-07 11:57:14,083] [INFO] [controller] EPOCH 4 loss ppo:  -0.02155, loss val: 0.04668
[2022-12-07 11:57:14,095] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:57:14,295] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:57:14,296] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:57:19,343] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:57:24,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:57:30,051] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:57:35,033] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:57:40,347] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:57:45,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:57:51,151] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:57:56,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:58:01,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:58:08,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7962199584737486
[2022-12-07 11:58:08,147] [INFO] [runner_train_mujoco] Average state value: 0.6467568757136662
[2022-12-07 11:58:08,147] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 11:58:08,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.04298
[2022-12-07 11:58:08,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.01464, loss val: 0.04307
[2022-12-07 11:58:08,380] [INFO] [controller] EPOCH 3 loss ppo:  -0.01568, loss val: 0.04228
[2022-12-07 11:58:08,439] [INFO] [controller] EPOCH 4 loss ppo:  -0.01712, loss val: 0.04241
[2022-12-07 11:58:08,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:58:08,647] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:58:08,647] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:58:14,997] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:58:21,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:58:27,240] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:58:32,222] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:58:37,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:58:42,325] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:58:47,136] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:58:52,001] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:58:56,961] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:59:01,942] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7444409629430004
[2022-12-07 11:59:01,942] [INFO] [runner_train_mujoco] Average state value: 0.6485673121809958
[2022-12-07 11:59:01,942] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 11:59:01,999] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.04486
[2022-12-07 11:59:02,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.01548, loss val: 0.04397
[2022-12-07 11:59:02,094] [INFO] [controller] EPOCH 3 loss ppo:  -0.01669, loss val: 0.04408
[2022-12-07 11:59:02,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.01808, loss val: 0.04406
[2022-12-07 11:59:02,154] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:59:02,295] [INFO] [optimize] Finished learning.
