[2022-12-06 16:14:53,674] [INFO] [optimize] Starting learning
[2022-12-06 16:14:53,682] [INFO] [optimize] Starting learning process..
[2022-12-06 16:14:53,749] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:53,750] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:15:03,614] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:15:11,328] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:15:19,003] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:15:26,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:15:33,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:15:41,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:15:49,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:15:57,804] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:16:06,275] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:16:14,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17475817857950302
[2022-12-06 16:16:14,665] [INFO] [runner_train_mujoco] Average state value: -0.2243900427532693
[2022-12-06 16:16:14,665] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 16:16:14,761] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.56744
[2022-12-06 16:16:14,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.03211, loss val: 0.50147
[2022-12-06 16:16:14,885] [INFO] [controller] EPOCH 3 loss ppo:  -0.03705, loss val: 0.42456
[2022-12-06 16:16:14,964] [INFO] [controller] EPOCH 4 loss ppo:  -0.03958, loss val: 0.36911
[2022-12-06 16:16:14,976] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:16:15,176] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:16:15,176] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:16:23,203] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:16:30,900] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:16:39,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:16:46,779] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:16:54,964] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:17:03,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:17:11,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:17:19,848] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:17:28,244] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:17:36,834] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15192629184732354
[2022-12-06 16:17:36,835] [INFO] [runner_train_mujoco] Average state value: -0.052986012457249064
[2022-12-06 16:17:36,835] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 16:17:36,929] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.42623
[2022-12-06 16:17:37,029] [INFO] [controller] EPOCH 2 loss ppo:  -0.02647, loss val: 0.37281
[2022-12-06 16:17:37,114] [INFO] [controller] EPOCH 3 loss ppo:  -0.03482, loss val: 0.30406
[2022-12-06 16:17:37,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.03838, loss val: 0.27103
[2022-12-06 16:17:37,214] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:17:37,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:17:37,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:17:45,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:17:54,198] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:18:03,377] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:18:11,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:18:19,892] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:18:28,001] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:18:35,932] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:18:43,723] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:18:51,742] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:18:59,973] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14588935982393064
[2022-12-06 16:18:59,973] [INFO] [runner_train_mujoco] Average state value: 0.12624208401081463
[2022-12-06 16:18:59,973] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 16:19:00,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01473, loss val: 0.20330
[2022-12-06 16:19:00,164] [INFO] [controller] EPOCH 2 loss ppo:  -0.02990, loss val: 0.16875
[2022-12-06 16:19:00,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.03794, loss val: 0.13883
[2022-12-06 16:19:00,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.04044, loss val: 0.11760
[2022-12-06 16:19:00,290] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:19:00,509] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:19:00,509] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:19:08,691] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:19:16,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:24,378] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:19:32,157] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:19:40,100] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:19:48,229] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:19:55,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:20:03,604] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:20:11,013] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:20:18,896] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16311050413098507
[2022-12-06 16:20:18,896] [INFO] [runner_train_mujoco] Average state value: 0.3002587656751275
[2022-12-06 16:20:18,896] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 16:20:18,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.01068, loss val: 0.16596
[2022-12-06 16:20:19,021] [INFO] [controller] EPOCH 2 loss ppo:  -0.02250, loss val: 0.14395
[2022-12-06 16:20:19,080] [INFO] [controller] EPOCH 3 loss ppo:  -0.02580, loss val: 0.11318
[2022-12-06 16:20:19,144] [INFO] [controller] EPOCH 4 loss ppo:  -0.02886, loss val: 0.08472
[2022-12-06 16:20:19,154] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:20:19,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:20:19,352] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:20:26,894] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:20:35,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:20:42,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:20:49,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:20:56,442] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:03,820] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:21:11,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:21:18,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:21:26,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:21:33,863] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.13996516400448794
[2022-12-06 16:21:33,863] [INFO] [runner_train_mujoco] Average state value: 0.47488359355429804
[2022-12-06 16:21:33,863] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 16:21:33,934] [INFO] [controller] EPOCH 1 loss ppo:  -0.00911, loss val: 0.07159
[2022-12-06 16:21:33,991] [INFO] [controller] EPOCH 2 loss ppo:  -0.01694, loss val: 0.05846
[2022-12-06 16:21:34,049] [INFO] [controller] EPOCH 3 loss ppo:  -0.02214, loss val: 0.04939
[2022-12-06 16:21:34,132] [INFO] [controller] EPOCH 4 loss ppo:  -0.02527, loss val: 0.04125
[2022-12-06 16:21:34,143] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:21:34,339] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:21:34,340] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:21:41,783] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:21:49,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:21:57,668] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:22:05,491] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:22:13,182] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:22:20,647] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:22:28,612] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:22:36,287] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:22:44,037] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:22:51,965] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17012273063842
[2022-12-06 16:22:51,966] [INFO] [runner_train_mujoco] Average state value: 0.6353553035656611
[2022-12-06 16:22:51,966] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 16:22:52,042] [INFO] [controller] EPOCH 1 loss ppo:  -0.00729, loss val: 0.04212
[2022-12-06 16:22:52,120] [INFO] [controller] EPOCH 2 loss ppo:  -0.02285, loss val: 0.04010
[2022-12-06 16:22:52,176] [INFO] [controller] EPOCH 3 loss ppo:  -0.02537, loss val: 0.03753
[2022-12-06 16:22:52,236] [INFO] [controller] EPOCH 4 loss ppo:  -0.03017, loss val: 0.03761
[2022-12-06 16:22:52,248] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:22:52,442] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:22:52,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:23:00,521] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:23:08,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:23:16,462] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:23:24,194] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:23:32,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:23:40,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:23:48,202] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:23:56,130] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:24:04,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:24:12,733] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2020938697367692
[2022-12-06 16:24:12,733] [INFO] [runner_train_mujoco] Average state value: 0.7338407408793768
[2022-12-06 16:24:12,734] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 16:24:12,799] [INFO] [controller] EPOCH 1 loss ppo:  -0.00671, loss val: 0.04341
[2022-12-06 16:24:12,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.01897, loss val: 0.04424
[2022-12-06 16:24:12,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.02302, loss val: 0.04380
[2022-12-06 16:24:12,974] [INFO] [controller] EPOCH 4 loss ppo:  -0.02711, loss val: 0.04286
[2022-12-06 16:24:12,986] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:24:13,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:24:13,208] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:24:21,612] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:24:29,986] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:24:38,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:24:47,179] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:24:55,289] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:25:03,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:25:13,133] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:25:21,911] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:25:30,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:25:37,920] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1812368944797772
[2022-12-06 16:25:37,920] [INFO] [runner_train_mujoco] Average state value: 0.7474356442292531
[2022-12-06 16:25:37,920] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 16:25:38,008] [INFO] [controller] EPOCH 1 loss ppo:  -0.00723, loss val: 0.03945
[2022-12-06 16:25:38,077] [INFO] [controller] EPOCH 2 loss ppo:  -0.01792, loss val: 0.03812
[2022-12-06 16:25:38,210] [INFO] [controller] EPOCH 3 loss ppo:  -0.02218, loss val: 0.03629
[2022-12-06 16:25:38,291] [INFO] [controller] EPOCH 4 loss ppo:  -0.02619, loss val: 0.03592
[2022-12-06 16:25:38,304] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:25:38,502] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:25:38,503] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:25:51,917] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:26:05,584] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:26:17,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:26:29,555] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:26:40,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:26:51,819] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:27:01,116] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:27:11,828] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:27:19,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:27:27,437] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22018723077182928
[2022-12-06 16:27:27,437] [INFO] [runner_train_mujoco] Average state value: 0.7004329290390015
[2022-12-06 16:27:27,437] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 16:27:27,504] [INFO] [controller] EPOCH 1 loss ppo:  -0.00593, loss val: 0.04365
[2022-12-06 16:27:27,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.01820, loss val: 0.04409
[2022-12-06 16:27:27,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.02450, loss val: 0.04511
[2022-12-06 16:27:27,733] [INFO] [controller] EPOCH 4 loss ppo:  -0.02988, loss val: 0.04367
[2022-12-06 16:27:27,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:27:27,961] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:27:27,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:27:37,348] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:27:47,983] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:28:01,028] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:28:10,321] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:28:19,588] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:28:27,803] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:28:36,332] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:28:44,805] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:28:53,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:29:01,082] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2688067328581535
[2022-12-06 16:29:01,083] [INFO] [runner_train_mujoco] Average state value: 0.7027469448248544
[2022-12-06 16:29:01,083] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 16:29:01,163] [INFO] [controller] EPOCH 1 loss ppo:  -0.00611, loss val: 0.04026
[2022-12-06 16:29:01,219] [INFO] [controller] EPOCH 2 loss ppo:  -0.01924, loss val: 0.04077
[2022-12-06 16:29:01,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.02212, loss val: 0.03988
[2022-12-06 16:29:01,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.02706, loss val: 0.04146
[2022-12-06 16:29:01,377] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:29:01,603] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:29:01,603] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:29:09,789] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:29:19,950] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:29:29,546] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:29:38,178] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:29:47,853] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:29:56,108] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:30:03,928] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:30:11,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:30:20,051] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:30:27,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2737803056394633
[2022-12-06 16:30:27,404] [INFO] [runner_train_mujoco] Average state value: 0.7205800096988677
[2022-12-06 16:30:27,405] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 16:30:27,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.00675, loss val: 0.03868
[2022-12-06 16:30:27,549] [INFO] [controller] EPOCH 2 loss ppo:  -0.01659, loss val: 0.03699
[2022-12-06 16:30:27,601] [INFO] [controller] EPOCH 3 loss ppo:  -0.01982, loss val: 0.03704
[2022-12-06 16:30:27,685] [INFO] [controller] EPOCH 4 loss ppo:  -0.02594, loss val: 0.03825
[2022-12-06 16:30:27,697] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:30:27,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:30:27,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:30:36,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:30:44,421] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:30:52,334] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:31:00,060] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:31:07,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:31:16,108] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:31:24,231] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:31:32,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:31:40,324] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:31:47,731] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4371290550890753
[2022-12-06 16:31:47,731] [INFO] [runner_train_mujoco] Average state value: 0.7327967030604681
[2022-12-06 16:31:47,731] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 16:31:47,823] [INFO] [controller] EPOCH 1 loss ppo:  -0.00688, loss val: 0.04067
[2022-12-06 16:31:47,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.02246, loss val: 0.04126
[2022-12-06 16:31:48,012] [INFO] [controller] EPOCH 3 loss ppo:  -0.02445, loss val: 0.03859
[2022-12-06 16:31:48,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.02613, loss val: 0.03776
[2022-12-06 16:31:48,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:31:48,321] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:31:48,321] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:31:56,351] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:32:04,317] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:32:11,837] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:32:19,705] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:32:27,792] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:32:35,361] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:32:43,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:32:51,552] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:32:58,967] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:33:06,479] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46367805556380376
[2022-12-06 16:33:06,479] [INFO] [runner_train_mujoco] Average state value: 0.6873156736095745
[2022-12-06 16:33:06,479] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 16:33:06,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.00840, loss val: 0.03768
[2022-12-06 16:33:06,608] [INFO] [controller] EPOCH 2 loss ppo:  -0.01993, loss val: 0.03877
[2022-12-06 16:33:06,712] [INFO] [controller] EPOCH 3 loss ppo:  -0.02481, loss val: 0.03837
[2022-12-06 16:33:06,821] [INFO] [controller] EPOCH 4 loss ppo:  -0.02582, loss val: 0.03919
[2022-12-06 16:33:06,834] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:33:07,045] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:33:07,045] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:33:14,933] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:33:22,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:33:29,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:33:36,680] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:33:44,054] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:33:51,669] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:33:59,229] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:34:07,350] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:34:15,632] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:34:24,395] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5518973508788011
[2022-12-06 16:34:24,396] [INFO] [runner_train_mujoco] Average state value: 0.6665266362031301
[2022-12-06 16:34:24,396] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 16:34:24,467] [INFO] [controller] EPOCH 1 loss ppo:  -0.00841, loss val: 0.04157
[2022-12-06 16:34:24,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.02154, loss val: 0.04057
[2022-12-06 16:34:24,653] [INFO] [controller] EPOCH 3 loss ppo:  -0.02880, loss val: 0.04004
[2022-12-06 16:34:24,725] [INFO] [controller] EPOCH 4 loss ppo:  -0.03013, loss val: 0.03868
[2022-12-06 16:34:24,738] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:34:24,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:34:24,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:34:34,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:34:43,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:34:52,100] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:35:05,101] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:35:15,314] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:35:23,607] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:35:32,558] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:35:40,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:35:48,751] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:35:56,518] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7777319886031056
[2022-12-06 16:35:56,518] [INFO] [runner_train_mujoco] Average state value: 0.7135920223792394
[2022-12-06 16:35:56,518] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 16:35:56,597] [INFO] [controller] EPOCH 1 loss ppo:  -0.01081, loss val: 0.03840
[2022-12-06 16:35:56,682] [INFO] [controller] EPOCH 2 loss ppo:  -0.02105, loss val: 0.03920
[2022-12-06 16:35:56,738] [INFO] [controller] EPOCH 3 loss ppo:  -0.02168, loss val: 0.03889
[2022-12-06 16:35:56,796] [INFO] [controller] EPOCH 4 loss ppo:  -0.03125, loss val: 0.03794
[2022-12-06 16:35:56,807] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:35:57,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:35:57,011] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:36:04,549] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:36:12,896] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:36:23,367] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:36:33,964] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:36:45,161] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:36:54,161] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:37:03,543] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:37:12,920] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:37:22,039] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:37:31,156] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7646316268854817
[2022-12-06 16:37:31,156] [INFO] [runner_train_mujoco] Average state value: 0.7168674686352412
[2022-12-06 16:37:31,156] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 16:37:31,290] [INFO] [controller] EPOCH 1 loss ppo:  -0.01028, loss val: 0.04073
[2022-12-06 16:37:31,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.02275, loss val: 0.03956
[2022-12-06 16:37:31,423] [INFO] [controller] EPOCH 3 loss ppo:  -0.02760, loss val: 0.03797
[2022-12-06 16:37:31,516] [INFO] [controller] EPOCH 4 loss ppo:  -0.03310, loss val: 0.03795
[2022-12-06 16:37:31,528] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:37:31,725] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:37:31,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:37:40,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:37:48,715] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:37:57,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:38:06,560] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:38:15,421] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:38:26,355] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:38:41,662] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:38:51,968] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:39:01,884] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:39:12,087] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9489627812307594
[2022-12-06 16:39:12,087] [INFO] [runner_train_mujoco] Average state value: 0.674183314661185
[2022-12-06 16:39:12,087] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 16:39:12,189] [INFO] [controller] EPOCH 1 loss ppo:  -0.00916, loss val: 0.03936
[2022-12-06 16:39:12,254] [INFO] [controller] EPOCH 2 loss ppo:  -0.01952, loss val: 0.03670
[2022-12-06 16:39:12,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02579, loss val: 0.03943
[2022-12-06 16:39:12,376] [INFO] [controller] EPOCH 4 loss ppo:  -0.03087, loss val: 0.03907
[2022-12-06 16:39:12,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:39:12,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:39:12,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:39:23,782] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:39:34,492] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:39:44,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:39:53,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:40:03,175] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:40:14,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:40:25,046] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:40:34,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:40:43,309] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:40:52,306] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.02744237592857
[2022-12-06 16:40:52,307] [INFO] [runner_train_mujoco] Average state value: 0.691628932038943
[2022-12-06 16:40:52,307] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 16:40:52,401] [INFO] [controller] EPOCH 1 loss ppo:  -0.00911, loss val: 0.03549
[2022-12-06 16:40:52,480] [INFO] [controller] EPOCH 2 loss ppo:  -0.01800, loss val: 0.03576
[2022-12-06 16:40:52,552] [INFO] [controller] EPOCH 3 loss ppo:  -0.02337, loss val: 0.03569
[2022-12-06 16:40:52,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.02971, loss val: 0.03587
[2022-12-06 16:40:52,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:40:52,867] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:40:52,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:41:01,426] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:41:09,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:41:18,080] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:41:26,669] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:41:35,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:43,268] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:41:51,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:42:00,718] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:42:09,739] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:42:17,610] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0084038259857404
[2022-12-06 16:42:17,610] [INFO] [runner_train_mujoco] Average state value: 0.696811684846878
[2022-12-06 16:42:17,610] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 16:42:17,727] [INFO] [controller] EPOCH 1 loss ppo:  -0.00943, loss val: 0.03952
[2022-12-06 16:42:17,778] [INFO] [controller] EPOCH 2 loss ppo:  -0.01996, loss val: 0.03829
[2022-12-06 16:42:17,839] [INFO] [controller] EPOCH 3 loss ppo:  -0.02695, loss val: 0.03753
[2022-12-06 16:42:17,910] [INFO] [controller] EPOCH 4 loss ppo:  -0.03227, loss val: 0.03674
[2022-12-06 16:42:17,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:42:18,122] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:42:18,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:42:26,637] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:42:34,795] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:42:42,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:42:50,925] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:42:58,975] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:43:07,506] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:43:16,047] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:43:25,359] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:43:33,592] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:43:41,781] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1734020463121952
[2022-12-06 16:43:41,782] [INFO] [runner_train_mujoco] Average state value: 0.7212103524208068
[2022-12-06 16:43:41,782] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 16:43:41,849] [INFO] [controller] EPOCH 1 loss ppo:  -0.01152, loss val: 0.04130
[2022-12-06 16:43:41,902] [INFO] [controller] EPOCH 2 loss ppo:  -0.02346, loss val: 0.04109
[2022-12-06 16:43:41,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.02860, loss val: 0.04133
[2022-12-06 16:43:42,122] [INFO] [controller] EPOCH 4 loss ppo:  -0.03220, loss val: 0.04183
[2022-12-06 16:43:42,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:43:42,354] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:43:42,354] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:43:50,180] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:43:58,112] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:44:06,272] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:44:14,637] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:44:23,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:44:32,281] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:44:40,885] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:44:49,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:44:58,172] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:45:06,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1326034156831006
[2022-12-06 16:45:06,818] [INFO] [runner_train_mujoco] Average state value: 0.7362755042711894
[2022-12-06 16:45:06,818] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 16:45:06,935] [INFO] [controller] EPOCH 1 loss ppo:  -0.00998, loss val: 0.03949
[2022-12-06 16:45:07,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.02183, loss val: 0.03908
[2022-12-06 16:45:07,124] [INFO] [controller] EPOCH 3 loss ppo:  -0.02572, loss val: 0.03766
[2022-12-06 16:45:07,228] [INFO] [controller] EPOCH 4 loss ppo:  -0.02849, loss val: 0.03762
[2022-12-06 16:45:07,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:45:07,463] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:45:07,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:45:15,816] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:45:26,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:45:35,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:45:45,490] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:45:55,369] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:46:04,983] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:46:15,125] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:46:25,300] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:46:34,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:46:44,189] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2460814404259772
[2022-12-06 16:46:44,190] [INFO] [runner_train_mujoco] Average state value: 0.6941077762444814
[2022-12-06 16:46:44,190] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 16:46:44,273] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.03739
[2022-12-06 16:46:44,353] [INFO] [controller] EPOCH 2 loss ppo:  -0.02063, loss val: 0.03789
[2022-12-06 16:46:44,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.02375, loss val: 0.03766
[2022-12-06 16:46:44,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.02803, loss val: 0.03719
[2022-12-06 16:46:44,548] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:46:44,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:46:44,763] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:46:54,840] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:47:04,044] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:47:12,870] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:47:23,303] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:47:32,317] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:47:40,812] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:47:49,720] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:47:58,536] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:48:07,884] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:48:16,000] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3068131380772858
[2022-12-06 16:48:16,000] [INFO] [runner_train_mujoco] Average state value: 0.6822830566565196
[2022-12-06 16:48:16,000] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 16:48:16,098] [INFO] [controller] EPOCH 1 loss ppo:  -0.01213, loss val: 0.03545
[2022-12-06 16:48:16,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.02376, loss val: 0.03428
[2022-12-06 16:48:16,345] [INFO] [controller] EPOCH 3 loss ppo:  -0.03027, loss val: 0.03402
[2022-12-06 16:48:16,427] [INFO] [controller] EPOCH 4 loss ppo:  -0.03561, loss val: 0.03510
[2022-12-06 16:48:16,439] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:48:16,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:48:16,674] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:48:25,829] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:48:36,521] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:48:44,971] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:48:53,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:49:01,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:49:09,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:49:19,324] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:49:28,047] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:49:37,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:49:46,262] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3491805760691036
[2022-12-06 16:49:46,263] [INFO] [runner_train_mujoco] Average state value: 0.6666988157629967
[2022-12-06 16:49:46,263] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 16:49:46,402] [INFO] [controller] EPOCH 1 loss ppo:  -0.01059, loss val: 0.03460
[2022-12-06 16:49:46,515] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.03413
[2022-12-06 16:49:46,584] [INFO] [controller] EPOCH 3 loss ppo:  -0.02779, loss val: 0.03261
[2022-12-06 16:49:46,759] [INFO] [controller] EPOCH 4 loss ppo:  -0.03126, loss val: 0.03554
[2022-12-06 16:49:46,774] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:49:47,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:49:47,021] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:49:55,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:50:03,451] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:50:10,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:50:19,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:50:29,776] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:50:38,667] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:50:47,150] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:50:55,835] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:51:04,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:51:13,964] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5122458284915208
[2022-12-06 16:51:13,964] [INFO] [runner_train_mujoco] Average state value: 0.6262244808276495
[2022-12-06 16:51:13,965] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 16:51:14,154] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04092
[2022-12-06 16:51:14,379] [INFO] [controller] EPOCH 2 loss ppo:  -0.02384, loss val: 0.04140
[2022-12-06 16:51:14,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.03086, loss val: 0.04059
[2022-12-06 16:51:14,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.03542, loss val: 0.04031
[2022-12-06 16:51:14,701] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:51:14,919] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:51:14,919] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:51:24,077] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:51:33,422] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:51:42,973] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:51:50,341] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:51:59,149] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:52:08,261] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:52:16,770] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:52:25,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:52:33,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:52:41,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4597569286294108
[2022-12-06 16:52:41,838] [INFO] [runner_train_mujoco] Average state value: 0.6510722992022833
[2022-12-06 16:52:41,838] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 16:52:41,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04513
[2022-12-06 16:52:41,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.02756, loss val: 0.04324
[2022-12-06 16:52:42,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.03046, loss val: 0.04169
[2022-12-06 16:52:42,149] [INFO] [controller] EPOCH 4 loss ppo:  -0.03540, loss val: 0.04176
[2022-12-06 16:52:42,173] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:52:42,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:52:42,397] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:52:50,559] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:52:58,578] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:53:06,831] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:53:14,752] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:53:22,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:53:30,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:53:38,668] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:53:46,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:53:54,342] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:54:02,383] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.474422543931596
[2022-12-06 16:54:02,383] [INFO] [runner_train_mujoco] Average state value: 0.7184099963903428
[2022-12-06 16:54:02,383] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 16:54:02,537] [INFO] [controller] EPOCH 1 loss ppo:  -0.01191, loss val: 0.04247
[2022-12-06 16:54:02,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.02425, loss val: 0.04262
[2022-12-06 16:54:02,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.03027, loss val: 0.04273
[2022-12-06 16:54:02,723] [INFO] [controller] EPOCH 4 loss ppo:  -0.03370, loss val: 0.04227
[2022-12-06 16:54:02,736] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:54:02,961] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:54:02,962] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:54:10,879] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:54:18,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:54:26,898] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:54:34,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:54:42,296] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:54:49,612] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:54:56,910] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:55:04,449] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:55:11,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:55:19,134] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5795643643955732
[2022-12-06 16:55:19,135] [INFO] [runner_train_mujoco] Average state value: 0.7366450196107228
[2022-12-06 16:55:19,135] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 16:55:19,215] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.04094
[2022-12-06 16:55:19,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.02323, loss val: 0.04080
[2022-12-06 16:55:19,333] [INFO] [controller] EPOCH 3 loss ppo:  -0.02869, loss val: 0.04030
[2022-12-06 16:55:19,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.03576, loss val: 0.03993
[2022-12-06 16:55:19,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:55:19,681] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:55:19,681] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:55:27,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:55:35,413] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:55:42,838] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:55:50,626] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:55:57,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:56:04,947] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:56:12,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:56:19,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:56:27,610] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:56:35,845] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4651102290860059
[2022-12-06 16:56:35,846] [INFO] [runner_train_mujoco] Average state value: 0.7132241917451224
[2022-12-06 16:56:35,846] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 16:56:35,934] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.04156
[2022-12-06 16:56:36,000] [INFO] [controller] EPOCH 2 loss ppo:  -0.01826, loss val: 0.04051
[2022-12-06 16:56:36,072] [INFO] [controller] EPOCH 3 loss ppo:  -0.02123, loss val: 0.04030
[2022-12-06 16:56:36,298] [INFO] [controller] EPOCH 4 loss ppo:  -0.03021, loss val: 0.04051
[2022-12-06 16:56:36,309] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:56:36,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:56:36,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:56:44,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:56:52,297] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:57:00,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:57:08,881] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:57:16,542] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:57:24,063] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:57:32,087] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:57:40,253] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:57:47,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:57:56,383] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.618923325465122
[2022-12-06 16:57:56,384] [INFO] [runner_train_mujoco] Average state value: 0.6788485434452692
[2022-12-06 16:57:56,384] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 16:57:56,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.03890
[2022-12-06 16:57:56,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.02313, loss val: 0.03837
[2022-12-06 16:57:56,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.03017, loss val: 0.03833
[2022-12-06 16:57:56,950] [INFO] [controller] EPOCH 4 loss ppo:  -0.03879, loss val: 0.03843
[2022-12-06 16:57:56,963] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:57:57,251] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:57:57,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:58:05,341] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:58:13,868] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:58:22,325] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:58:30,488] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:58:39,192] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:58:47,452] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:58:56,482] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:59:05,478] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:59:14,803] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:59:23,708] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.654879230051554
[2022-12-06 16:59:23,708] [INFO] [runner_train_mujoco] Average state value: 0.6809509260654449
[2022-12-06 16:59:23,708] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 16:59:23,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04014
[2022-12-06 16:59:23,838] [INFO] [controller] EPOCH 2 loss ppo:  -0.02210, loss val: 0.03934
[2022-12-06 16:59:23,908] [INFO] [controller] EPOCH 3 loss ppo:  -0.02515, loss val: 0.03911
[2022-12-06 16:59:23,976] [INFO] [controller] EPOCH 4 loss ppo:  -0.03164, loss val: 0.03890
[2022-12-06 16:59:23,989] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:59:24,239] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:59:24,239] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:59:32,686] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:59:41,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:59:50,657] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:59:59,671] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:00:08,415] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:00:16,902] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:00:25,261] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:00:33,594] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:00:42,176] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:00:50,693] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6200005044219121
[2022-12-06 17:00:50,694] [INFO] [runner_train_mujoco] Average state value: 0.7000560383001964
[2022-12-06 17:00:50,694] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 17:00:51,646] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.03904
[2022-12-06 17:00:51,710] [INFO] [controller] EPOCH 2 loss ppo:  -0.01908, loss val: 0.03820
[2022-12-06 17:00:51,783] [INFO] [controller] EPOCH 3 loss ppo:  -0.02304, loss val: 0.03833
[2022-12-06 17:00:51,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.03225, loss val: 0.03682
[2022-12-06 17:00:51,882] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:00:52,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:00:52,099] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:01:00,562] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:01:09,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:01:16,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:01:24,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:01:33,003] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:01:41,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:01:50,892] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:01:59,240] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:02:08,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:02:16,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5764258209937885
[2022-12-06 17:02:16,372] [INFO] [runner_train_mujoco] Average state value: 0.711763350625833
[2022-12-06 17:02:16,372] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 17:02:16,457] [INFO] [controller] EPOCH 1 loss ppo:  -0.01072, loss val: 0.03920
[2022-12-06 17:02:16,510] [INFO] [controller] EPOCH 2 loss ppo:  -0.01808, loss val: 0.04019
[2022-12-06 17:02:16,565] [INFO] [controller] EPOCH 3 loss ppo:  -0.02458, loss val: 0.03884
[2022-12-06 17:02:16,625] [INFO] [controller] EPOCH 4 loss ppo:  -0.03259, loss val: 0.03887
[2022-12-06 17:02:16,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:02:16,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:02:16,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:02:25,301] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:02:33,740] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:02:41,753] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:02:49,910] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:02:57,508] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:03:05,547] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:03:13,488] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:03:21,277] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:03:29,230] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:03:36,982] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7487401644595373
[2022-12-06 17:03:36,983] [INFO] [runner_train_mujoco] Average state value: 0.7224736085732778
[2022-12-06 17:03:36,983] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 17:03:37,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.03994
[2022-12-06 17:03:37,202] [INFO] [controller] EPOCH 2 loss ppo:  -0.01999, loss val: 0.03979
[2022-12-06 17:03:37,276] [INFO] [controller] EPOCH 3 loss ppo:  -0.02455, loss val: 0.03931
[2022-12-06 17:03:37,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.03245, loss val: 0.03853
[2022-12-06 17:03:37,432] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:03:37,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:03:37,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:03:45,624] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:03:53,001] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:04:00,543] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:04:08,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:04:15,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:04:23,437] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:04:31,026] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:04:38,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:04:46,631] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:04:54,685] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.658427629793288
[2022-12-06 17:04:54,686] [INFO] [runner_train_mujoco] Average state value: 0.7007813632090887
[2022-12-06 17:04:54,686] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 17:04:54,903] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.04318
[2022-12-06 17:04:55,063] [INFO] [controller] EPOCH 2 loss ppo:  -0.02333, loss val: 0.04374
[2022-12-06 17:04:55,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.02798, loss val: 0.04232
[2022-12-06 17:04:55,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.03154, loss val: 0.04390
[2022-12-06 17:04:55,522] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:04:55,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:04:55,763] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:05:03,863] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:05:10,773] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:05:17,942] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:05:25,493] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:05:33,725] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:05:41,668] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:05:50,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:05:58,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:06:06,861] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:06:15,221] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8285540398006468
[2022-12-06 17:06:15,221] [INFO] [runner_train_mujoco] Average state value: 0.7007546939849852
[2022-12-06 17:06:15,221] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 17:06:15,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01249, loss val: 0.03849
[2022-12-06 17:06:15,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.02313, loss val: 0.03869
[2022-12-06 17:06:15,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.02528, loss val: 0.03863
[2022-12-06 17:06:15,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.03072, loss val: 0.03863
[2022-12-06 17:06:15,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:06:15,874] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:06:15,875] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:06:25,151] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:06:34,198] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:06:41,693] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:06:50,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:06:59,732] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:07:11,274] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:07:20,241] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:07:29,705] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:07:42,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:07:53,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8645006031279725
[2022-12-06 17:07:53,115] [INFO] [runner_train_mujoco] Average state value: 0.7130915666421254
[2022-12-06 17:07:53,115] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 17:07:53,224] [INFO] [controller] EPOCH 1 loss ppo:  -0.01158, loss val: 0.03804
[2022-12-06 17:07:53,333] [INFO] [controller] EPOCH 2 loss ppo:  -0.01858, loss val: 0.03778
[2022-12-06 17:07:53,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.02269, loss val: 0.03754
[2022-12-06 17:07:53,472] [INFO] [controller] EPOCH 4 loss ppo:  -0.02894, loss val: 0.03740
[2022-12-06 17:07:53,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:07:53,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:07:53,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:08:04,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:08:15,015] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:08:26,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:08:35,805] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:08:45,608] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:08:55,340] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:09:06,214] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:09:17,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:09:27,683] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:09:37,390] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8085521062165495
[2022-12-06 17:09:37,390] [INFO] [runner_train_mujoco] Average state value: 0.7013759506940842
[2022-12-06 17:09:37,390] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 17:09:37,558] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.03960
[2022-12-06 17:09:37,738] [INFO] [controller] EPOCH 2 loss ppo:  -0.02167, loss val: 0.03971
[2022-12-06 17:09:37,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.02893, loss val: 0.04027
[2022-12-06 17:09:37,983] [INFO] [controller] EPOCH 4 loss ppo:  -0.03465, loss val: 0.03946
[2022-12-06 17:09:37,999] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:09:38,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:09:38,247] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:09:48,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:09:58,836] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:10:11,578] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:10:22,339] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:10:32,599] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:10:44,980] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:10:56,326] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:11:07,832] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:11:17,812] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:11:29,338] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8454724093534332
[2022-12-06 17:11:29,338] [INFO] [runner_train_mujoco] Average state value: 0.6828278824885686
[2022-12-06 17:11:29,338] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 17:11:29,456] [INFO] [controller] EPOCH 1 loss ppo:  -0.01179, loss val: 0.04180
[2022-12-06 17:11:29,546] [INFO] [controller] EPOCH 2 loss ppo:  -0.01652, loss val: 0.04164
[2022-12-06 17:11:29,702] [INFO] [controller] EPOCH 3 loss ppo:  -0.02213, loss val: 0.04225
[2022-12-06 17:11:29,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.02756, loss val: 0.04001
[2022-12-06 17:11:29,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:11:30,139] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:11:30,140] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:11:43,201] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:11:54,684] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:12:06,110] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:12:17,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:12:27,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:12:37,812] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:12:49,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:13:02,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:13:12,943] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:13:23,637] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8671852783316705
[2022-12-06 17:13:23,638] [INFO] [runner_train_mujoco] Average state value: 0.6951442424058915
[2022-12-06 17:13:23,638] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 17:13:23,734] [INFO] [controller] EPOCH 1 loss ppo:  -0.01258, loss val: 0.04378
[2022-12-06 17:13:23,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.01962, loss val: 0.04413
[2022-12-06 17:13:23,937] [INFO] [controller] EPOCH 3 loss ppo:  -0.02422, loss val: 0.04339
[2022-12-06 17:13:24,069] [INFO] [controller] EPOCH 4 loss ppo:  -0.02964, loss val: 0.04411
[2022-12-06 17:13:24,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:13:24,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:13:24,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:13:35,445] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:13:45,703] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:13:55,543] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:14:04,990] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:14:14,798] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:14:25,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:14:35,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:14:44,140] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:14:52,450] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:15:00,814] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9685158097587607
[2022-12-06 17:15:00,814] [INFO] [runner_train_mujoco] Average state value: 0.7124063441753388
[2022-12-06 17:15:00,814] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 17:15:00,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.03852
[2022-12-06 17:15:01,020] [INFO] [controller] EPOCH 2 loss ppo:  -0.02444, loss val: 0.03831
[2022-12-06 17:15:01,083] [INFO] [controller] EPOCH 3 loss ppo:  -0.02860, loss val: 0.03969
[2022-12-06 17:15:01,156] [INFO] [controller] EPOCH 4 loss ppo:  -0.03369, loss val: 0.03891
[2022-12-06 17:15:01,167] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:15:01,411] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:15:01,412] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:15:13,167] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:15:23,375] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:15:31,018] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:15:38,676] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:15:46,806] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:15:54,789] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:16:03,030] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:16:11,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:16:20,016] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:16:27,664] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.08261469580124
[2022-12-06 17:16:27,664] [INFO] [runner_train_mujoco] Average state value: 0.7069381121794382
[2022-12-06 17:16:27,665] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 17:16:27,769] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.04171
[2022-12-06 17:16:27,840] [INFO] [controller] EPOCH 2 loss ppo:  -0.02367, loss val: 0.04065
[2022-12-06 17:16:27,911] [INFO] [controller] EPOCH 3 loss ppo:  -0.02891, loss val: 0.04128
[2022-12-06 17:16:27,971] [INFO] [controller] EPOCH 4 loss ppo:  -0.03142, loss val: 0.04051
[2022-12-06 17:16:27,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:16:28,191] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:16:28,192] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:16:36,116] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:16:45,111] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:16:53,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:17:01,627] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:17:09,411] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:17:17,294] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:17:25,340] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:17:33,982] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:17:43,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:17:50,488] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0399730381362087
[2022-12-06 17:17:50,488] [INFO] [runner_train_mujoco] Average state value: 0.6896586821476618
[2022-12-06 17:17:50,488] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 17:17:50,675] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.04248
[2022-12-06 17:17:50,747] [INFO] [controller] EPOCH 2 loss ppo:  -0.01908, loss val: 0.04163
[2022-12-06 17:17:50,810] [INFO] [controller] EPOCH 3 loss ppo:  -0.02428, loss val: 0.04135
[2022-12-06 17:17:50,866] [INFO] [controller] EPOCH 4 loss ppo:  -0.02777, loss val: 0.04132
[2022-12-06 17:17:50,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:17:51,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:17:51,100] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:17:58,330] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:18:05,467] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:18:12,284] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:18:19,064] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:18:26,817] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:18:32,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:18:40,245] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:18:47,393] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:18:54,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:19:01,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1164830456620374
[2022-12-06 17:19:01,178] [INFO] [runner_train_mujoco] Average state value: 0.6923604801893233
[2022-12-06 17:19:01,178] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 17:19:01,251] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.04309
[2022-12-06 17:19:01,310] [INFO] [controller] EPOCH 2 loss ppo:  -0.02149, loss val: 0.04299
[2022-12-06 17:19:01,377] [INFO] [controller] EPOCH 3 loss ppo:  -0.02437, loss val: 0.04231
[2022-12-06 17:19:01,436] [INFO] [controller] EPOCH 4 loss ppo:  -0.03049, loss val: 0.04191
[2022-12-06 17:19:01,448] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:19:01,648] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:19:01,648] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:19:09,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:19:15,812] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:19:23,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:19:31,117] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:19:38,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:19:44,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:19:50,667] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:19:57,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:20:05,178] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:20:11,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1433653067429574
[2022-12-06 17:20:11,919] [INFO] [runner_train_mujoco] Average state value: 0.7028356260458628
[2022-12-06 17:20:11,919] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 17:20:11,979] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04067
[2022-12-06 17:20:12,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.01869, loss val: 0.04019
[2022-12-06 17:20:12,075] [INFO] [controller] EPOCH 3 loss ppo:  -0.02364, loss val: 0.04015
[2022-12-06 17:20:12,124] [INFO] [controller] EPOCH 4 loss ppo:  -0.02998, loss val: 0.04063
[2022-12-06 17:20:12,135] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:20:12,320] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:20:12,320] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:20:18,857] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:20:25,677] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:20:34,712] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:20:43,172] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:20:51,339] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:21:00,995] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:21:08,311] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:21:15,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:21:24,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:21:31,848] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.103513413516417
[2022-12-06 17:21:31,848] [INFO] [runner_train_mujoco] Average state value: 0.7113804261684418
[2022-12-06 17:21:31,848] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 17:21:31,910] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.03805
[2022-12-06 17:21:31,960] [INFO] [controller] EPOCH 2 loss ppo:  -0.01696, loss val: 0.03897
[2022-12-06 17:21:32,012] [INFO] [controller] EPOCH 3 loss ppo:  -0.02005, loss val: 0.03882
[2022-12-06 17:21:32,070] [INFO] [controller] EPOCH 4 loss ppo:  -0.02454, loss val: 0.03774
[2022-12-06 17:21:32,082] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:21:32,271] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:21:32,272] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:21:38,733] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:21:45,609] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:21:51,945] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:21:58,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:22:05,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:22:12,459] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:22:19,076] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:22:26,190] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:22:32,613] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:22:39,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1708745869356996
[2022-12-06 17:22:39,375] [INFO] [runner_train_mujoco] Average state value: 0.7058456408182779
[2022-12-06 17:22:39,376] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 17:22:39,448] [INFO] [controller] EPOCH 1 loss ppo:  -0.01283, loss val: 0.03614
[2022-12-06 17:22:39,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01622, loss val: 0.03619
[2022-12-06 17:22:39,575] [INFO] [controller] EPOCH 3 loss ppo:  -0.02232, loss val: 0.03565
[2022-12-06 17:22:39,641] [INFO] [controller] EPOCH 4 loss ppo:  -0.02649, loss val: 0.03615
[2022-12-06 17:22:39,652] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:22:39,869] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:22:39,870] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:22:46,343] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:22:53,494] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:23:00,770] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:23:07,570] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:23:14,417] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:23:21,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:23:28,081] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:23:35,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:23:42,515] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:23:49,540] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1546304516571064
[2022-12-06 17:23:49,541] [INFO] [runner_train_mujoco] Average state value: 0.6838410708506901
[2022-12-06 17:23:49,541] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 17:23:49,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.03877
[2022-12-06 17:23:49,680] [INFO] [controller] EPOCH 2 loss ppo:  -0.01925, loss val: 0.03950
[2022-12-06 17:23:49,730] [INFO] [controller] EPOCH 3 loss ppo:  -0.02677, loss val: 0.03980
[2022-12-06 17:23:49,782] [INFO] [controller] EPOCH 4 loss ppo:  -0.03089, loss val: 0.03916
[2022-12-06 17:23:49,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:23:49,997] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:23:49,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:23:56,558] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:24:03,417] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:24:10,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:24:17,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:24:23,810] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:24:30,255] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:24:36,705] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:24:43,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:24:50,160] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:24:56,957] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2121934807265977
[2022-12-06 17:24:56,957] [INFO] [runner_train_mujoco] Average state value: 0.6781491808096567
[2022-12-06 17:24:56,957] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 17:24:57,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04088
[2022-12-06 17:24:57,092] [INFO] [controller] EPOCH 2 loss ppo:  -0.01699, loss val: 0.04032
[2022-12-06 17:24:57,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.02163, loss val: 0.04090
[2022-12-06 17:24:57,238] [INFO] [controller] EPOCH 4 loss ppo:  -0.02703, loss val: 0.04028
[2022-12-06 17:24:57,250] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:24:57,457] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:24:57,457] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:25:04,210] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:25:11,086] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:25:17,470] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:25:23,702] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:25:30,225] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:25:36,140] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:25:42,171] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:25:48,424] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:25:54,835] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:26:01,457] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2287339894815905
[2022-12-06 17:26:01,457] [INFO] [runner_train_mujoco] Average state value: 0.6835985857844353
[2022-12-06 17:26:01,457] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 17:26:01,521] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04030
[2022-12-06 17:26:01,577] [INFO] [controller] EPOCH 2 loss ppo:  -0.01906, loss val: 0.04032
[2022-12-06 17:26:01,636] [INFO] [controller] EPOCH 3 loss ppo:  -0.02463, loss val: 0.04014
[2022-12-06 17:26:01,685] [INFO] [controller] EPOCH 4 loss ppo:  -0.02886, loss val: 0.04084
[2022-12-06 17:26:01,698] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:26:01,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:26:01,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:26:08,604] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:26:15,641] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:26:22,090] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:26:28,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:26:34,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:26:41,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:26:48,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:26:54,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:27:00,074] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:27:06,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2353718619582135
[2022-12-06 17:27:06,177] [INFO] [runner_train_mujoco] Average state value: 0.685926376303037
[2022-12-06 17:27:06,177] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 17:27:06,234] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.03919
[2022-12-06 17:27:06,287] [INFO] [controller] EPOCH 2 loss ppo:  -0.01791, loss val: 0.03969
[2022-12-06 17:27:06,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.02385, loss val: 0.03917
[2022-12-06 17:27:06,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.02719, loss val: 0.03950
[2022-12-06 17:27:06,387] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:27:06,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:27:06,561] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:27:12,167] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:27:17,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:27:22,941] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:27:27,959] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:27:33,075] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:27:37,923] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:27:43,514] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:27:48,746] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:27:54,458] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:27:59,499] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2743720555511158
[2022-12-06 17:27:59,499] [INFO] [runner_train_mujoco] Average state value: 0.6915019651651382
[2022-12-06 17:27:59,499] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 17:27:59,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.03879
[2022-12-06 17:27:59,592] [INFO] [controller] EPOCH 2 loss ppo:  -0.01686, loss val: 0.03888
[2022-12-06 17:27:59,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.02128, loss val: 0.03911
[2022-12-06 17:27:59,681] [INFO] [controller] EPOCH 4 loss ppo:  -0.02479, loss val: 0.03826
[2022-12-06 17:27:59,691] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:27:59,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:27:59,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:28:06,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:28:16,991] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:28:24,308] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:28:29,390] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:28:34,339] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:28:40,422] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:28:47,115] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:28:55,225] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:29:02,343] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:29:07,301] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1556459529994947
[2022-12-06 17:29:07,301] [INFO] [runner_train_mujoco] Average state value: 0.7000320603847503
[2022-12-06 17:29:07,302] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 17:29:07,353] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.04133
[2022-12-06 17:29:07,393] [INFO] [controller] EPOCH 2 loss ppo:  -0.01527, loss val: 0.04079
[2022-12-06 17:29:07,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.01945, loss val: 0.04067
[2022-12-06 17:29:07,480] [INFO] [controller] EPOCH 4 loss ppo:  -0.02212, loss val: 0.04096
[2022-12-06 17:29:07,490] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:29:07,646] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:29:07,647] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:29:12,721] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:29:18,177] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:29:23,324] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:29:28,736] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:29:33,764] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:29:38,880] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:29:44,186] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:29:49,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:29:54,766] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:30:00,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3159290363355387
[2022-12-06 17:30:00,316] [INFO] [runner_train_mujoco] Average state value: 0.706460454026858
[2022-12-06 17:30:00,316] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 17:30:00,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.03947
[2022-12-06 17:30:00,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.01493, loss val: 0.03942
[2022-12-06 17:30:00,457] [INFO] [controller] EPOCH 3 loss ppo:  -0.02026, loss val: 0.04039
[2022-12-06 17:30:00,500] [INFO] [controller] EPOCH 4 loss ppo:  -0.02418, loss val: 0.04152
[2022-12-06 17:30:00,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:30:00,693] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:30:00,694] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:30:05,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:30:10,794] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:30:16,163] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:30:21,247] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:30:26,143] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:30:31,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:30:36,664] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:30:41,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:30:47,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:30:52,205] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2457514297685233
[2022-12-06 17:30:52,206] [INFO] [runner_train_mujoco] Average state value: 0.7049554951985677
[2022-12-06 17:30:52,206] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 17:30:52,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.04164
[2022-12-06 17:30:52,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.01794, loss val: 0.04159
[2022-12-06 17:30:52,348] [INFO] [controller] EPOCH 3 loss ppo:  -0.02161, loss val: 0.04161
[2022-12-06 17:30:52,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.02300, loss val: 0.04108
[2022-12-06 17:30:52,396] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:30:52,577] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:30:52,578] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:30:58,117] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:31:04,363] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:31:10,015] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:31:15,503] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:31:20,862] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:31:26,184] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:31:31,369] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:31:36,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:31:42,242] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:31:47,557] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2732199070912467
[2022-12-06 17:31:47,558] [INFO] [runner_train_mujoco] Average state value: 0.700276272058487
[2022-12-06 17:31:47,558] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 17:31:47,614] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.03913
[2022-12-06 17:31:47,660] [INFO] [controller] EPOCH 2 loss ppo:  -0.01548, loss val: 0.03923
[2022-12-06 17:31:47,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.01993, loss val: 0.03925
[2022-12-06 17:31:47,756] [INFO] [controller] EPOCH 4 loss ppo:  -0.02351, loss val: 0.03960
[2022-12-06 17:31:47,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:31:47,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:31:47,952] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:31:53,053] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:31:58,996] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:32:04,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:32:09,927] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:32:15,277] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:32:20,471] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:32:25,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:32:31,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:32:37,114] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:32:42,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.364815890060407
[2022-12-06 17:32:42,237] [INFO] [runner_train_mujoco] Average state value: 0.6987271976073582
[2022-12-06 17:32:42,237] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 17:32:42,292] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04368
[2022-12-06 17:32:42,343] [INFO] [controller] EPOCH 2 loss ppo:  -0.01373, loss val: 0.04300
[2022-12-06 17:32:42,390] [INFO] [controller] EPOCH 3 loss ppo:  -0.01578, loss val: 0.04224
[2022-12-06 17:32:42,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.01829, loss val: 0.04189
[2022-12-06 17:32:42,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:32:42,633] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:32:42,633] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:32:47,931] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:32:52,997] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:32:58,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:33:03,656] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:33:09,021] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:33:13,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:33:18,899] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:33:23,687] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:33:28,733] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:33:33,522] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4120475712691984
[2022-12-06 17:33:33,522] [INFO] [runner_train_mujoco] Average state value: 0.6982217812538146
[2022-12-06 17:33:33,522] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 17:33:33,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.03872
[2022-12-06 17:33:33,625] [INFO] [controller] EPOCH 2 loss ppo:  -0.01281, loss val: 0.04039
[2022-12-06 17:33:33,671] [INFO] [controller] EPOCH 3 loss ppo:  -0.01347, loss val: 0.03878
[2022-12-06 17:33:33,710] [INFO] [controller] EPOCH 4 loss ppo:  -0.01437, loss val: 0.03871
[2022-12-06 17:33:33,719] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:33:33,862] [INFO] [optimize] Finished learning.
