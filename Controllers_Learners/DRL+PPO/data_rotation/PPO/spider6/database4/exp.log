[2022-12-06 21:32:49,076] [INFO] [optimize] Starting learning
[2022-12-06 21:32:49,086] [INFO] [optimize] Starting learning process..
[2022-12-06 21:32:49,145] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:32:49,145] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:32:56,882] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:33:04,553] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:33:13,023] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:33:19,949] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:33:27,289] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:33:34,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:33:41,140] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:33:48,019] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:33:55,306] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:34:02,802] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.12559113224116364
[2022-12-06 21:34:02,802] [INFO] [runner_train_mujoco] Average state value: -0.1724444738117357
[2022-12-06 21:34:02,802] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 21:34:02,883] [INFO] [controller] EPOCH 1 loss ppo:  -0.01661, loss val: 0.71539
[2022-12-06 21:34:02,940] [INFO] [controller] EPOCH 2 loss ppo:  -0.03182, loss val: 0.65515
[2022-12-06 21:34:03,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.03776, loss val: 0.57067
[2022-12-06 21:34:03,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.04098, loss val: 0.51557
[2022-12-06 21:34:03,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:34:03,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:34:03,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:34:11,197] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:34:18,705] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:34:26,192] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:34:33,525] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:34:40,903] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:34:48,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:34:55,990] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:35:03,564] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:35:10,919] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:35:18,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16386359333867412
[2022-12-06 21:35:18,524] [INFO] [runner_train_mujoco] Average state value: -0.03220975269936025
[2022-12-06 21:35:18,524] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 21:35:18,584] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.40713
[2022-12-06 21:35:18,635] [INFO] [controller] EPOCH 2 loss ppo:  -0.02746, loss val: 0.35068
[2022-12-06 21:35:18,685] [INFO] [controller] EPOCH 3 loss ppo:  -0.03586, loss val: 0.29551
[2022-12-06 21:35:18,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.03737, loss val: 0.25182
[2022-12-06 21:35:18,756] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:35:18,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:35:18,951] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:35:26,618] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:35:33,687] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:35:41,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:35:48,780] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:35:56,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:36:04,500] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:36:11,786] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:36:19,214] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:36:26,800] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:36:34,461] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17756191322709639
[2022-12-06 21:36:34,461] [INFO] [runner_train_mujoco] Average state value: 0.15289467610791324
[2022-12-06 21:36:34,461] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 21:36:34,532] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.25617
[2022-12-06 21:36:34,590] [INFO] [controller] EPOCH 2 loss ppo:  -0.02724, loss val: 0.24271
[2022-12-06 21:36:34,651] [INFO] [controller] EPOCH 3 loss ppo:  -0.03155, loss val: 0.18866
[2022-12-06 21:36:34,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.03571, loss val: 0.17779
[2022-12-06 21:36:34,718] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:36:34,916] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:36:34,916] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:36:43,056] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:36:50,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:36:58,308] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:37:06,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:37:13,790] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:37:21,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:37:29,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:37:36,901] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:37:44,745] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:37:52,898] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14146316306934448
[2022-12-06 21:37:52,898] [INFO] [runner_train_mujoco] Average state value: 0.3219708545673639
[2022-12-06 21:37:52,898] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 21:37:52,979] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.21613
[2022-12-06 21:37:53,043] [INFO] [controller] EPOCH 2 loss ppo:  -0.02356, loss val: 0.18568
[2022-12-06 21:37:53,104] [INFO] [controller] EPOCH 3 loss ppo:  -0.02776, loss val: 0.15986
[2022-12-06 21:37:53,177] [INFO] [controller] EPOCH 4 loss ppo:  -0.03313, loss val: 0.13625
[2022-12-06 21:37:53,189] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:37:53,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:37:53,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:38:01,684] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:38:09,961] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:38:17,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:38:25,321] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:38:32,667] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:38:40,482] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:38:48,075] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:38:55,871] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:39:03,207] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:39:11,046] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21405774173828193
[2022-12-06 21:39:11,047] [INFO] [runner_train_mujoco] Average state value: 0.48309990245600537
[2022-12-06 21:39:11,047] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 21:39:11,129] [INFO] [controller] EPOCH 1 loss ppo:  -0.01188, loss val: 0.12800
[2022-12-06 21:39:11,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.02791, loss val: 0.10854
[2022-12-06 21:39:11,257] [INFO] [controller] EPOCH 3 loss ppo:  -0.03165, loss val: 0.09238
[2022-12-06 21:39:11,374] [INFO] [controller] EPOCH 4 loss ppo:  -0.03463, loss val: 0.08313
[2022-12-06 21:39:11,385] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:39:11,607] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:39:11,608] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:39:19,083] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:39:26,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:39:33,889] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:39:41,635] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:39:49,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:39:56,450] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:40:03,859] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:40:11,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:40:18,817] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:40:25,900] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22780445237033192
[2022-12-06 21:40:25,901] [INFO] [runner_train_mujoco] Average state value: 0.6393453327417374
[2022-12-06 21:40:25,901] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 21:40:25,980] [INFO] [controller] EPOCH 1 loss ppo:  -0.01019, loss val: 0.07435
[2022-12-06 21:40:26,043] [INFO] [controller] EPOCH 2 loss ppo:  -0.02759, loss val: 0.06732
[2022-12-06 21:40:26,102] [INFO] [controller] EPOCH 3 loss ppo:  -0.03016, loss val: 0.06041
[2022-12-06 21:40:26,163] [INFO] [controller] EPOCH 4 loss ppo:  -0.03211, loss val: 0.05827
[2022-12-06 21:40:26,174] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:40:26,373] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:40:26,374] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:40:33,552] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:40:48,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:42:41,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:42:57,280] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:43:11,386] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:43:22,766] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:43:37,004] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:43:48,381] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:43:58,843] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:44:07,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1549562778200903
[2022-12-06 21:44:07,535] [INFO] [runner_train_mujoco] Average state value: 0.7517594233751297
[2022-12-06 21:44:07,535] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 21:44:07,644] [INFO] [controller] EPOCH 1 loss ppo:  -0.00723, loss val: 0.05508
[2022-12-06 21:44:07,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.01889, loss val: 0.05360
[2022-12-06 21:44:07,808] [INFO] [controller] EPOCH 3 loss ppo:  -0.02305, loss val: 0.05113
[2022-12-06 21:44:07,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.02418, loss val: 0.04908
[2022-12-06 21:44:07,892] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:44:08,121] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:44:08,121] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:44:17,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:44:25,912] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:44:34,819] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:44:44,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:44:54,553] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:45:03,817] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:45:13,276] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:45:22,636] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:45:31,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:45:40,006] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.13505518852412945
[2022-12-06 21:45:40,006] [INFO] [runner_train_mujoco] Average state value: 0.7637698714931807
[2022-12-06 21:45:40,006] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 21:45:40,102] [INFO] [controller] EPOCH 1 loss ppo:  -0.00634, loss val: 0.05049
[2022-12-06 21:45:40,163] [INFO] [controller] EPOCH 2 loss ppo:  -0.02005, loss val: 0.04853
[2022-12-06 21:45:40,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.02468, loss val: 0.04763
[2022-12-06 21:45:40,283] [INFO] [controller] EPOCH 4 loss ppo:  -0.02498, loss val: 0.04692
[2022-12-06 21:45:40,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:45:40,496] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:45:40,496] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:45:49,717] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:45:58,531] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:46:07,240] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:46:15,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:46:24,932] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:46:34,050] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:46:43,344] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:46:52,581] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:47:01,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:47:10,668] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1719053645955068
[2022-12-06 21:47:10,669] [INFO] [runner_train_mujoco] Average state value: 0.7337518447637559
[2022-12-06 21:47:10,669] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 21:47:10,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.00834, loss val: 0.04309
[2022-12-06 21:47:10,845] [INFO] [controller] EPOCH 2 loss ppo:  -0.01817, loss val: 0.04049
[2022-12-06 21:47:10,919] [INFO] [controller] EPOCH 3 loss ppo:  -0.01890, loss val: 0.04316
[2022-12-06 21:47:11,034] [INFO] [controller] EPOCH 4 loss ppo:  -0.02484, loss val: 0.03862
[2022-12-06 21:47:11,051] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:47:11,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:47:11,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:47:20,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:47:28,993] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:47:38,087] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:47:47,330] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:47:56,784] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:48:06,234] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:48:15,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:48:25,380] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:48:34,219] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:48:43,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19952333372498993
[2022-12-06 21:48:43,332] [INFO] [runner_train_mujoco] Average state value: 0.7103419728676478
[2022-12-06 21:48:43,332] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 21:48:43,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.00777, loss val: 0.04260
[2022-12-06 21:48:43,534] [INFO] [controller] EPOCH 2 loss ppo:  -0.02089, loss val: 0.04258
[2022-12-06 21:48:43,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.02484, loss val: 0.04261
[2022-12-06 21:48:43,697] [INFO] [controller] EPOCH 4 loss ppo:  -0.02913, loss val: 0.04249
[2022-12-06 21:48:43,710] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:48:43,934] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:48:43,935] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:48:52,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:49:01,247] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:49:10,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:49:19,495] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:49:28,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:49:38,126] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:49:48,038] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:49:59,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:50:10,440] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:50:22,349] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.11893890206273275
[2022-12-06 21:50:22,349] [INFO] [runner_train_mujoco] Average state value: 0.7027182892163595
[2022-12-06 21:50:22,349] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 21:50:22,451] [INFO] [controller] EPOCH 1 loss ppo:  -0.00658, loss val: 0.03833
[2022-12-06 21:50:22,562] [INFO] [controller] EPOCH 2 loss ppo:  -0.01792, loss val: 0.03830
[2022-12-06 21:50:22,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.02443, loss val: 0.03962
[2022-12-06 21:50:22,747] [INFO] [controller] EPOCH 4 loss ppo:  -0.02619, loss val: 0.03849
[2022-12-06 21:50:22,760] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:50:23,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:50:23,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:50:34,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:50:45,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:50:56,426] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:51:08,486] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:51:19,851] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:51:30,535] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:51:41,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:51:52,800] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:52:04,406] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:52:15,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23993293975746086
[2022-12-06 21:52:15,088] [INFO] [runner_train_mujoco] Average state value: 0.6976376268068949
[2022-12-06 21:52:15,089] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 21:52:15,191] [INFO] [controller] EPOCH 1 loss ppo:  -0.00927, loss val: 0.04741
[2022-12-06 21:52:15,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.02244, loss val: 0.04538
[2022-12-06 21:52:15,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.02708, loss val: 0.04492
[2022-12-06 21:52:15,619] [INFO] [controller] EPOCH 4 loss ppo:  -0.02820, loss val: 0.04463
[2022-12-06 21:52:15,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:52:15,921] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:52:15,921] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:52:27,045] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:52:37,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:52:48,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:52:59,457] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:53:10,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:53:20,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:53:31,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:53:41,241] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:53:50,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:53:59,588] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15816571415950123
[2022-12-06 21:53:59,588] [INFO] [runner_train_mujoco] Average state value: 0.7228110524813335
[2022-12-06 21:53:59,588] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 21:53:59,703] [INFO] [controller] EPOCH 1 loss ppo:  -0.00660, loss val: 0.03885
[2022-12-06 21:53:59,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.01620, loss val: 0.03852
[2022-12-06 21:53:59,866] [INFO] [controller] EPOCH 3 loss ppo:  -0.02406, loss val: 0.03800
[2022-12-06 21:53:59,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.02641, loss val: 0.03842
[2022-12-06 21:53:59,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:54:00,204] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:54:00,204] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:54:09,569] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:54:19,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:54:28,325] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:54:38,033] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:54:46,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:54:55,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:55:05,416] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:55:14,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:55:23,223] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:55:31,554] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1320749922229646
[2022-12-06 21:55:31,554] [INFO] [runner_train_mujoco] Average state value: 0.745907765229543
[2022-12-06 21:55:31,555] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 21:55:31,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.00757, loss val: 0.04299
[2022-12-06 21:55:31,714] [INFO] [controller] EPOCH 2 loss ppo:  -0.02218, loss val: 0.04198
[2022-12-06 21:55:31,790] [INFO] [controller] EPOCH 3 loss ppo:  -0.02637, loss val: 0.04245
[2022-12-06 21:55:31,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.02901, loss val: 0.04195
[2022-12-06 21:55:31,883] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:55:32,101] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:55:32,102] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:55:40,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:55:49,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:55:57,774] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:56:06,096] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:56:14,142] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:56:22,400] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:56:33,919] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:56:46,021] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:56:56,293] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:57:07,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14545461776743798
[2022-12-06 21:57:07,330] [INFO] [runner_train_mujoco] Average state value: 0.7554096077283223
[2022-12-06 21:57:07,331] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 21:57:07,511] [INFO] [controller] EPOCH 1 loss ppo:  -0.00628, loss val: 0.04203
[2022-12-06 21:57:07,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.01636, loss val: 0.04162
[2022-12-06 21:57:07,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.02072, loss val: 0.04141
[2022-12-06 21:57:07,823] [INFO] [controller] EPOCH 4 loss ppo:  -0.02471, loss val: 0.04115
[2022-12-06 21:57:07,836] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:57:08,121] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:57:08,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:57:18,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:57:28,558] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:57:37,888] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:57:47,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:57:57,180] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:58:07,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:58:18,775] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:58:29,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:58:39,374] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:58:49,657] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20816567036880826
[2022-12-06 21:58:49,657] [INFO] [runner_train_mujoco] Average state value: 0.7319205298026403
[2022-12-06 21:58:49,657] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 21:58:49,749] [INFO] [controller] EPOCH 1 loss ppo:  -0.00766, loss val: 0.03783
[2022-12-06 21:58:49,832] [INFO] [controller] EPOCH 2 loss ppo:  -0.02183, loss val: 0.03787
[2022-12-06 21:58:49,901] [INFO] [controller] EPOCH 3 loss ppo:  -0.02561, loss val: 0.03738
[2022-12-06 21:58:49,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.02876, loss val: 0.03682
[2022-12-06 21:58:50,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:58:50,243] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:58:50,243] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:59:00,840] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:59:11,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:59:21,723] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:59:32,037] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:59:42,559] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:59:53,024] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 22:00:03,541] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 22:00:14,140] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 22:00:24,955] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 22:00:35,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14152614204815964
[2022-12-06 22:00:35,091] [INFO] [runner_train_mujoco] Average state value: 0.7072272695302964
[2022-12-06 22:00:35,091] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 22:00:35,180] [INFO] [controller] EPOCH 1 loss ppo:  -0.00652, loss val: 0.04405
[2022-12-06 22:00:35,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.01874, loss val: 0.04391
[2022-12-06 22:00:35,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.02396, loss val: 0.04350
[2022-12-06 22:00:35,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.02516, loss val: 0.04262
[2022-12-06 22:00:35,441] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 22:00:35,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 22:00:35,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 22:00:45,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 22:00:57,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 22:01:07,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 22:01:17,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 22:01:27,524] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 22:01:37,773] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 22:01:48,047] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 22:01:58,087] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 22:02:09,150] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 22:02:19,252] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1883732173423695
[2022-12-06 22:02:19,252] [INFO] [runner_train_mujoco] Average state value: 0.7295006396770477
[2022-12-06 22:02:19,252] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 22:02:19,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.00586, loss val: 0.04163
[2022-12-06 22:02:19,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.01749, loss val: 0.04126
[2022-12-06 22:02:19,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.02686, loss val: 0.04226
[2022-12-06 22:02:19,586] [INFO] [controller] EPOCH 4 loss ppo:  -0.03122, loss val: 0.04125
[2022-12-06 22:02:19,599] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 22:02:19,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 22:02:19,837] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 22:02:29,775] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 22:02:39,301] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 22:02:48,919] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 22:02:58,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 22:03:08,429] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 22:03:18,215] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:03:31,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:03:45,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:03:56,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:04:06,538] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2429041945471484
[2022-12-06 23:04:06,538] [INFO] [runner_train_mujoco] Average state value: 0.7386188003619513
[2022-12-06 23:04:06,538] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 23:04:06,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.00800, loss val: 0.03969
[2022-12-06 23:04:06,804] [INFO] [controller] EPOCH 2 loss ppo:  -0.01829, loss val: 0.03732
[2022-12-06 23:04:07,270] [INFO] [controller] EPOCH 3 loss ppo:  -0.02410, loss val: 0.03668
[2022-12-06 23:04:07,792] [INFO] [controller] EPOCH 4 loss ppo:  -0.02920, loss val: 0.03700
[2022-12-06 23:04:07,806] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:04:08,144] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:04:08,145] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:04:20,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:04:30,032] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:04:40,315] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:04:50,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:05:00,816] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:05:11,047] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:05:20,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:05:31,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:05:41,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:05:51,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.26739899773833886
[2022-12-06 23:05:51,332] [INFO] [runner_train_mujoco] Average state value: 0.6886137222846349
[2022-12-06 23:05:51,332] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 23:05:51,418] [INFO] [controller] EPOCH 1 loss ppo:  -0.00905, loss val: 0.03509
[2022-12-06 23:05:51,491] [INFO] [controller] EPOCH 2 loss ppo:  -0.01888, loss val: 0.03302
[2022-12-06 23:05:51,559] [INFO] [controller] EPOCH 3 loss ppo:  -0.02117, loss val: 0.03311
[2022-12-06 23:05:51,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.02449, loss val: 0.03051
[2022-12-06 23:05:51,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:05:51,896] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:05:51,896] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:06:02,314] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:06:12,319] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:06:21,882] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:06:31,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:06:41,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:06:50,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:07:00,234] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:07:12,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:07:22,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:07:33,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.229815759916782
[2022-12-06 23:07:33,661] [INFO] [runner_train_mujoco] Average state value: 0.6134503322045008
[2022-12-06 23:07:33,661] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 23:07:33,774] [INFO] [controller] EPOCH 1 loss ppo:  -0.00638, loss val: 0.04155
[2022-12-06 23:07:33,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.01570, loss val: 0.04000
[2022-12-06 23:07:33,950] [INFO] [controller] EPOCH 3 loss ppo:  -0.02399, loss val: 0.04008
[2022-12-06 23:07:34,043] [INFO] [controller] EPOCH 4 loss ppo:  -0.02887, loss val: 0.03912
[2022-12-06 23:07:34,056] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:07:34,275] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:07:34,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:07:43,895] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:07:53,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:08:02,752] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:08:12,645] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:08:23,964] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:08:34,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:08:48,297] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:08:58,334] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:09:08,746] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:09:19,577] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4001178206827046
[2022-12-06 23:09:19,578] [INFO] [runner_train_mujoco] Average state value: 0.6254004889726639
[2022-12-06 23:09:19,578] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 23:09:19,673] [INFO] [controller] EPOCH 1 loss ppo:  -0.00806, loss val: 0.03800
[2022-12-06 23:09:19,751] [INFO] [controller] EPOCH 2 loss ppo:  -0.01970, loss val: 0.03744
[2022-12-06 23:09:19,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.02954, loss val: 0.03792
[2022-12-06 23:09:19,916] [INFO] [controller] EPOCH 4 loss ppo:  -0.03265, loss val: 0.03686
[2022-12-06 23:09:19,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:09:20,196] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:09:20,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:09:29,868] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:09:39,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:09:49,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:09:59,666] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:10:09,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:10:18,447] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:10:28,102] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:10:37,611] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:10:47,314] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:10:58,089] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3387283888152192
[2022-12-06 23:10:58,089] [INFO] [runner_train_mujoco] Average state value: 0.6693782236377397
[2022-12-06 23:10:58,090] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 23:10:58,187] [INFO] [controller] EPOCH 1 loss ppo:  -0.00785, loss val: 0.03938
[2022-12-06 23:10:58,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.01718, loss val: 0.03907
[2022-12-06 23:10:58,467] [INFO] [controller] EPOCH 3 loss ppo:  -0.02441, loss val: 0.03875
[2022-12-06 23:10:58,582] [INFO] [controller] EPOCH 4 loss ppo:  -0.02970, loss val: 0.03873
[2022-12-06 23:10:58,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:10:58,830] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:10:58,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:11:08,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:11:18,512] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:11:27,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:11:37,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:11:47,750] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:11:57,225] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:12:06,947] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:12:16,675] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:12:26,242] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:12:36,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.570182866723689
[2022-12-06 23:12:36,401] [INFO] [runner_train_mujoco] Average state value: 0.6964460567235946
[2022-12-06 23:12:36,401] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 23:12:36,496] [INFO] [controller] EPOCH 1 loss ppo:  -0.00938, loss val: 0.03591
[2022-12-06 23:12:36,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.02457, loss val: 0.03642
[2022-12-06 23:12:36,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.03281, loss val: 0.03603
[2022-12-06 23:12:36,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.03678, loss val: 0.03579
[2022-12-06 23:12:36,861] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:12:37,096] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:12:37,097] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:12:47,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:12:56,952] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:13:06,172] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:13:15,826] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:13:25,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:13:35,142] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:13:45,156] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:13:54,130] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:14:02,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:14:12,424] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6478663648827564
[2022-12-06 23:14:12,425] [INFO] [runner_train_mujoco] Average state value: 0.6809536933104197
[2022-12-06 23:14:12,425] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 23:14:12,528] [INFO] [controller] EPOCH 1 loss ppo:  -0.00904, loss val: 0.03602
[2022-12-06 23:14:12,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.01689, loss val: 0.03712
[2022-12-06 23:14:12,689] [INFO] [controller] EPOCH 3 loss ppo:  -0.02089, loss val: 0.03819
[2022-12-06 23:14:12,769] [INFO] [controller] EPOCH 4 loss ppo:  -0.02535, loss val: 0.03635
[2022-12-06 23:14:12,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:14:13,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:14:13,013] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:14:23,283] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:14:32,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:14:42,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:14:51,881] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:15:00,917] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:15:10,646] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:15:20,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:15:29,561] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:15:39,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:15:50,437] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7833814976394142
[2022-12-06 23:15:50,437] [INFO] [runner_train_mujoco] Average state value: 0.6770568239688874
[2022-12-06 23:15:50,437] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 23:15:50,536] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.03736
[2022-12-06 23:15:50,619] [INFO] [controller] EPOCH 2 loss ppo:  -0.02576, loss val: 0.03633
[2022-12-06 23:15:50,716] [INFO] [controller] EPOCH 3 loss ppo:  -0.03037, loss val: 0.03592
[2022-12-06 23:15:50,861] [INFO] [controller] EPOCH 4 loss ppo:  -0.03595, loss val: 0.03624
[2022-12-06 23:15:50,873] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:15:51,114] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:15:51,114] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:16:01,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:16:11,201] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:16:21,297] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:16:31,351] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:16:41,822] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:16:50,849] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:17:00,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:17:09,922] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:17:19,408] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:17:28,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.062006052905498
[2022-12-06 23:17:28,834] [INFO] [runner_train_mujoco] Average state value: 0.6813465627034505
[2022-12-06 23:17:28,834] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 23:17:28,937] [INFO] [controller] EPOCH 1 loss ppo:  -0.00941, loss val: 0.03855
[2022-12-06 23:17:29,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.01716, loss val: 0.03816
[2022-12-06 23:17:29,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.02330, loss val: 0.03775
[2022-12-06 23:17:29,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.02905, loss val: 0.03840
[2022-12-06 23:17:29,412] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:17:29,663] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:17:29,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:17:39,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:17:50,643] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:18:02,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:18:11,083] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:18:18,944] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:18:27,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:18:35,216] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:18:43,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:18:51,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:18:59,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1410991379354791
[2022-12-06 23:18:59,643] [INFO] [runner_train_mujoco] Average state value: 0.6619374668598176
[2022-12-06 23:18:59,643] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 23:18:59,714] [INFO] [controller] EPOCH 1 loss ppo:  -0.01115, loss val: 0.03615
[2022-12-06 23:18:59,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.02537, loss val: 0.03763
[2022-12-06 23:18:59,849] [INFO] [controller] EPOCH 3 loss ppo:  -0.03079, loss val: 0.03660
[2022-12-06 23:18:59,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.03413, loss val: 0.03546
[2022-12-06 23:18:59,923] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:19:00,150] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:19:00,151] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:19:08,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:19:18,210] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:19:29,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:19:38,000] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:19:48,303] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:19:57,303] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:20:06,300] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:20:16,001] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:20:25,857] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:20:35,124] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.301372944547275
[2022-12-06 23:20:35,125] [INFO] [runner_train_mujoco] Average state value: 0.6691428912878037
[2022-12-06 23:20:35,125] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 23:20:35,210] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.03710
[2022-12-06 23:20:35,276] [INFO] [controller] EPOCH 2 loss ppo:  -0.02647, loss val: 0.03778
[2022-12-06 23:20:35,345] [INFO] [controller] EPOCH 3 loss ppo:  -0.03404, loss val: 0.03720
[2022-12-06 23:20:35,442] [INFO] [controller] EPOCH 4 loss ppo:  -0.03636, loss val: 0.03770
[2022-12-06 23:20:35,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:20:35,682] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:20:35,682] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:20:44,883] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:20:54,341] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:21:04,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:21:12,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:21:21,817] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:21:30,389] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:21:39,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:21:48,235] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:21:56,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:22:05,476] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2617240936436356
[2022-12-06 23:22:05,476] [INFO] [runner_train_mujoco] Average state value: 0.6750286781390509
[2022-12-06 23:22:05,476] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 23:22:05,563] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.04817
[2022-12-06 23:22:05,636] [INFO] [controller] EPOCH 2 loss ppo:  -0.02428, loss val: 0.04708
[2022-12-06 23:22:05,736] [INFO] [controller] EPOCH 3 loss ppo:  -0.02919, loss val: 0.04595
[2022-12-06 23:22:05,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.03516, loss val: 0.04620
[2022-12-06 23:22:05,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:22:06,042] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:22:06,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:22:14,750] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:22:23,471] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:22:31,707] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:22:39,835] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:22:47,372] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:22:54,730] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:23:02,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:23:10,502] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:23:18,508] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:23:26,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3609237826145624
[2022-12-06 23:23:26,483] [INFO] [runner_train_mujoco] Average state value: 0.6982636306285858
[2022-12-06 23:23:26,483] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 23:23:26,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01080, loss val: 0.04360
[2022-12-06 23:23:26,644] [INFO] [controller] EPOCH 2 loss ppo:  -0.01952, loss val: 0.04220
[2022-12-06 23:23:26,734] [INFO] [controller] EPOCH 3 loss ppo:  -0.02774, loss val: 0.04186
[2022-12-06 23:23:26,815] [INFO] [controller] EPOCH 4 loss ppo:  -0.03416, loss val: 0.04162
[2022-12-06 23:23:26,823] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:23:27,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:23:27,051] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:23:34,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:23:43,139] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:23:51,090] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:23:58,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:24:06,203] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:24:13,938] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:24:21,641] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:24:29,495] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:24:37,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:24:44,990] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.541223433487383
[2022-12-06 23:24:44,991] [INFO] [runner_train_mujoco] Average state value: 0.6964602727095286
[2022-12-06 23:24:44,991] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 23:24:45,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.03675
[2022-12-06 23:24:45,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.02452, loss val: 0.03710
[2022-12-06 23:24:45,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.02763, loss val: 0.03705
[2022-12-06 23:24:45,309] [INFO] [controller] EPOCH 4 loss ppo:  -0.03465, loss val: 0.03662
[2022-12-06 23:24:45,320] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:24:45,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:24:45,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:24:53,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:25:01,710] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:25:09,525] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:25:17,787] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:25:25,842] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:25:33,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:25:41,256] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:25:49,076] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:25:57,036] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:26:04,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6068173961046424
[2022-12-06 23:26:04,677] [INFO] [runner_train_mujoco] Average state value: 0.6792752340833346
[2022-12-06 23:26:04,677] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 23:26:04,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04328
[2022-12-06 23:26:04,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.02333, loss val: 0.04297
[2022-12-06 23:26:04,922] [INFO] [controller] EPOCH 3 loss ppo:  -0.02749, loss val: 0.04341
[2022-12-06 23:26:04,989] [INFO] [controller] EPOCH 4 loss ppo:  -0.03473, loss val: 0.04233
[2022-12-06 23:26:05,000] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:26:05,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:26:05,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:26:13,000] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:26:20,658] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:26:28,843] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:26:36,920] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:26:45,277] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:26:53,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:27:00,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:27:08,927] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:27:17,175] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:27:24,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6344769179102259
[2022-12-06 23:27:24,915] [INFO] [runner_train_mujoco] Average state value: 0.6986882177988687
[2022-12-06 23:27:24,915] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 23:27:24,999] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.04052
[2022-12-06 23:27:25,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.02275, loss val: 0.03964
[2022-12-06 23:27:25,120] [INFO] [controller] EPOCH 3 loss ppo:  -0.02732, loss val: 0.03916
[2022-12-06 23:27:25,189] [INFO] [controller] EPOCH 4 loss ppo:  -0.03262, loss val: 0.03988
[2022-12-06 23:27:25,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:27:25,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:27:25,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:27:33,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:27:40,930] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:27:48,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:27:56,521] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:28:03,948] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:28:10,065] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:28:16,445] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:28:22,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:28:29,717] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:28:35,965] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7358695879715735
[2022-12-06 23:28:35,965] [INFO] [runner_train_mujoco] Average state value: 0.7115045790274938
[2022-12-06 23:28:35,965] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 23:28:36,029] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.04325
[2022-12-06 23:28:36,087] [INFO] [controller] EPOCH 2 loss ppo:  -0.01813, loss val: 0.04462
[2022-12-06 23:28:36,142] [INFO] [controller] EPOCH 3 loss ppo:  -0.02664, loss val: 0.04322
[2022-12-06 23:28:36,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.03370, loss val: 0.04507
[2022-12-06 23:28:36,213] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:28:36,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:28:36,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:28:42,493] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:28:48,656] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:28:54,942] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:29:00,873] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:29:07,071] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:29:13,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:29:19,279] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:29:25,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:29:31,857] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:29:38,360] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8605783069550061
[2022-12-06 23:29:38,360] [INFO] [runner_train_mujoco] Average state value: 0.7023767618338267
[2022-12-06 23:29:38,360] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 23:29:38,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.03904
[2022-12-06 23:29:38,525] [INFO] [controller] EPOCH 2 loss ppo:  -0.02365, loss val: 0.03983
[2022-12-06 23:29:38,584] [INFO] [controller] EPOCH 3 loss ppo:  -0.02653, loss val: 0.03919
[2022-12-06 23:29:38,634] [INFO] [controller] EPOCH 4 loss ppo:  -0.03071, loss val: 0.03893
[2022-12-06 23:29:38,644] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:29:38,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:29:38,842] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:29:44,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:29:51,302] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:29:57,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:30:04,375] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:30:10,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:30:16,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:30:23,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:30:28,988] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:30:35,012] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:30:41,170] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9152949391979193
[2022-12-06 23:30:41,170] [INFO] [runner_train_mujoco] Average state value: 0.681604584733645
[2022-12-06 23:30:41,171] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 23:30:41,234] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.04107
[2022-12-06 23:30:41,289] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.04082
[2022-12-06 23:30:41,348] [INFO] [controller] EPOCH 3 loss ppo:  -0.02943, loss val: 0.04014
[2022-12-06 23:30:41,401] [INFO] [controller] EPOCH 4 loss ppo:  -0.03528, loss val: 0.04016
[2022-12-06 23:30:41,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:30:41,605] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:30:41,606] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:30:48,244] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:30:55,109] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:31:01,275] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:31:07,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:31:13,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:31:19,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:31:25,481] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:31:31,848] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:31:38,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:31:44,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9839668512472055
[2022-12-06 23:31:44,309] [INFO] [runner_train_mujoco] Average state value: 0.6785149838129679
[2022-12-06 23:31:44,309] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 23:31:44,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01514, loss val: 0.03780
[2022-12-06 23:31:44,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.02277, loss val: 0.03785
[2022-12-06 23:31:44,489] [INFO] [controller] EPOCH 3 loss ppo:  -0.02782, loss val: 0.03905
[2022-12-06 23:31:44,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.03246, loss val: 0.03843
[2022-12-06 23:31:44,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:31:44,739] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:31:44,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:31:50,716] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:31:56,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:32:03,028] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:32:09,255] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:32:15,276] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:32:22,153] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:33:11,459] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:33:24,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:33:31,446] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:33:37,450] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9901490798411217
[2022-12-06 23:33:37,450] [INFO] [runner_train_mujoco] Average state value: 0.677540190378825
[2022-12-06 23:33:37,451] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 23:33:37,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.04206
[2022-12-06 23:33:37,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.02124, loss val: 0.04171
[2022-12-06 23:33:37,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.02836, loss val: 0.04210
[2022-12-06 23:33:37,680] [INFO] [controller] EPOCH 4 loss ppo:  -0.03353, loss val: 0.04070
[2022-12-06 23:33:37,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:33:37,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:33:37,910] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:33:43,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:33:50,074] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:33:56,253] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:34:02,181] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:34:08,575] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:34:14,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:34:21,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:34:27,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:34:33,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:34:40,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0119077050251244
[2022-12-06 23:34:40,505] [INFO] [runner_train_mujoco] Average state value: 0.6993271676301956
[2022-12-06 23:34:40,505] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 23:34:40,584] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.04216
[2022-12-06 23:34:40,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.01930, loss val: 0.04161
[2022-12-06 23:34:40,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.02211, loss val: 0.04177
[2022-12-06 23:34:40,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.02873, loss val: 0.04149
[2022-12-06 23:34:40,765] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:34:40,985] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:34:40,985] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:34:47,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:34:55,622] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:35:02,941] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:35:08,847] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:35:15,187] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:35:21,960] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:35:28,564] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:35:35,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:35:42,284] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:35:48,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.087412410780192
[2022-12-06 23:35:48,447] [INFO] [runner_train_mujoco] Average state value: 0.7002859317064285
[2022-12-06 23:35:48,447] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 23:35:48,511] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.04476
[2022-12-06 23:35:48,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.01766, loss val: 0.04458
[2022-12-06 23:35:48,632] [INFO] [controller] EPOCH 3 loss ppo:  -0.02563, loss val: 0.04458
[2022-12-06 23:35:48,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.02801, loss val: 0.04429
[2022-12-06 23:35:48,701] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:35:48,925] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:35:48,926] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:35:55,539] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:36:02,498] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:36:08,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:36:14,437] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:36:20,974] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:36:27,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:36:33,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:36:40,505] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:36:47,356] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:36:54,827] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0702511462379265
[2022-12-06 23:36:54,827] [INFO] [runner_train_mujoco] Average state value: 0.7026479050318398
[2022-12-06 23:36:54,827] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 23:36:54,898] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.03744
[2022-12-06 23:36:54,953] [INFO] [controller] EPOCH 2 loss ppo:  -0.02505, loss val: 0.03757
[2022-12-06 23:36:55,014] [INFO] [controller] EPOCH 3 loss ppo:  -0.03112, loss val: 0.03648
[2022-12-06 23:36:55,076] [INFO] [controller] EPOCH 4 loss ppo:  -0.03344, loss val: 0.03689
[2022-12-06 23:36:55,085] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:36:55,273] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:36:55,273] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:37:02,547] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:37:09,038] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:37:14,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:37:21,099] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:37:27,264] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:37:32,841] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:37:38,618] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:37:44,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:37:50,313] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:37:56,742] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.182843841676546
[2022-12-06 23:37:56,743] [INFO] [runner_train_mujoco] Average state value: 0.6963980296850204
[2022-12-06 23:37:56,743] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 23:37:56,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04328
[2022-12-06 23:37:56,984] [INFO] [controller] EPOCH 2 loss ppo:  -0.02057, loss val: 0.04289
[2022-12-06 23:37:57,072] [INFO] [controller] EPOCH 3 loss ppo:  -0.02782, loss val: 0.04296
[2022-12-06 23:37:57,162] [INFO] [controller] EPOCH 4 loss ppo:  -0.03083, loss val: 0.04314
[2022-12-06 23:37:57,177] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:37:57,429] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:37:57,429] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:38:07,026] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:38:16,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:38:24,251] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:38:32,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:38:40,420] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:38:48,355] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:38:56,192] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:39:04,208] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:39:12,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:39:20,238] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2706074629992914
[2022-12-06 23:39:20,238] [INFO] [runner_train_mujoco] Average state value: 0.6732502185702324
[2022-12-06 23:39:20,238] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 23:39:20,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.04159
[2022-12-06 23:39:20,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.01939, loss val: 0.04287
[2022-12-06 23:39:20,534] [INFO] [controller] EPOCH 3 loss ppo:  -0.02605, loss val: 0.04206
[2022-12-06 23:39:20,618] [INFO] [controller] EPOCH 4 loss ppo:  -0.03076, loss val: 0.04343
[2022-12-06 23:39:20,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:39:20,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:39:20,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:39:28,616] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:39:36,595] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:39:44,918] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:39:52,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:40:00,285] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:40:08,190] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:40:16,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:40:23,955] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:40:32,065] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:40:39,973] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.31057226581386
[2022-12-06 23:40:39,974] [INFO] [runner_train_mujoco] Average state value: 0.6597454934914906
[2022-12-06 23:40:39,974] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 23:40:40,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.03741
[2022-12-06 23:40:40,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.02189, loss val: 0.03753
[2022-12-06 23:40:40,240] [INFO] [controller] EPOCH 3 loss ppo:  -0.02970, loss val: 0.03852
[2022-12-06 23:40:40,318] [INFO] [controller] EPOCH 4 loss ppo:  -0.03431, loss val: 0.03788
[2022-12-06 23:40:40,334] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:40:40,555] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:40:40,555] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:40:48,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:40:56,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:41:04,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:41:12,960] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:41:21,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:41:28,969] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:41:36,906] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:41:44,812] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:41:52,716] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:42:00,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3619382008532077
[2022-12-06 23:42:00,415] [INFO] [runner_train_mujoco] Average state value: 0.665796780804793
[2022-12-06 23:42:00,415] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 23:42:00,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.04062
[2022-12-06 23:42:00,602] [INFO] [controller] EPOCH 2 loss ppo:  -0.02148, loss val: 0.04056
[2022-12-06 23:42:00,679] [INFO] [controller] EPOCH 3 loss ppo:  -0.02685, loss val: 0.04017
[2022-12-06 23:42:00,767] [INFO] [controller] EPOCH 4 loss ppo:  -0.03318, loss val: 0.04016
[2022-12-06 23:42:00,780] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:42:01,000] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:42:01,000] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:42:08,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:42:16,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:42:24,184] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:42:32,041] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:42:39,689] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:42:47,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:42:56,092] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:43:04,230] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:43:12,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:43:20,714] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4684574880581747
[2022-12-06 23:43:20,714] [INFO] [runner_train_mujoco] Average state value: 0.6651848204930623
[2022-12-06 23:43:20,714] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 23:43:20,811] [INFO] [controller] EPOCH 1 loss ppo:  -0.01540, loss val: 0.04568
[2022-12-06 23:43:20,895] [INFO] [controller] EPOCH 2 loss ppo:  -0.01863, loss val: 0.04608
[2022-12-06 23:43:21,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.02421, loss val: 0.04466
[2022-12-06 23:43:21,223] [INFO] [controller] EPOCH 4 loss ppo:  -0.03139, loss val: 0.04433
[2022-12-06 23:43:21,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:43:21,516] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:43:21,516] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:43:30,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:43:38,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:43:46,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:43:53,677] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:44:01,613] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:44:09,252] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:44:17,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:44:25,036] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:44:32,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:44:40,516] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4025440643784703
[2022-12-06 23:44:40,516] [INFO] [runner_train_mujoco] Average state value: 0.6888373885552088
[2022-12-06 23:44:40,516] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 23:44:40,602] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04178
[2022-12-06 23:44:40,682] [INFO] [controller] EPOCH 2 loss ppo:  -0.01946, loss val: 0.04081
[2022-12-06 23:44:40,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.02803, loss val: 0.04092
[2022-12-06 23:44:40,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.02828, loss val: 0.04167
[2022-12-06 23:44:40,860] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:44:41,106] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:44:41,106] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:44:48,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:44:57,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:45:05,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:45:13,418] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:45:21,346] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:45:29,372] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:45:38,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:45:45,897] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:45:53,910] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:46:01,705] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.558521039532092
[2022-12-06 23:46:01,706] [INFO] [runner_train_mujoco] Average state value: 0.7016707020203272
[2022-12-06 23:46:01,706] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 23:46:01,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04202
[2022-12-06 23:46:01,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.01663, loss val: 0.04199
[2022-12-06 23:46:01,982] [INFO] [controller] EPOCH 3 loss ppo:  -0.02191, loss val: 0.04214
[2022-12-06 23:46:02,067] [INFO] [controller] EPOCH 4 loss ppo:  -0.02733, loss val: 0.04262
[2022-12-06 23:46:02,087] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:46:02,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:46:02,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:46:10,519] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:46:18,382] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:46:26,145] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:46:33,657] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:46:41,721] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:46:49,250] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:46:56,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:47:05,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:47:13,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:47:21,253] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5290614111815275
[2022-12-06 23:47:21,253] [INFO] [runner_train_mujoco] Average state value: 0.7036308025121689
[2022-12-06 23:47:21,253] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 23:47:21,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.04237
[2022-12-06 23:47:21,419] [INFO] [controller] EPOCH 2 loss ppo:  -0.01914, loss val: 0.04234
[2022-12-06 23:47:21,499] [INFO] [controller] EPOCH 3 loss ppo:  -0.02428, loss val: 0.04133
[2022-12-06 23:47:21,581] [INFO] [controller] EPOCH 4 loss ppo:  -0.02767, loss val: 0.04059
[2022-12-06 23:47:21,594] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:47:21,818] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:47:21,818] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:47:30,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:47:38,422] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:47:47,504] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:47:54,258] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:48:00,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:48:06,691] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:48:12,757] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:48:18,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:48:25,648] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:48:33,656] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6734625996216765
[2022-12-06 23:48:33,656] [INFO] [runner_train_mujoco] Average state value: 0.683402357061704
[2022-12-06 23:48:33,656] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 23:48:33,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04204
[2022-12-06 23:48:33,835] [INFO] [controller] EPOCH 2 loss ppo:  -0.01770, loss val: 0.04092
[2022-12-06 23:48:33,903] [INFO] [controller] EPOCH 3 loss ppo:  -0.02254, loss val: 0.04110
[2022-12-06 23:48:34,013] [INFO] [controller] EPOCH 4 loss ppo:  -0.02575, loss val: 0.04228
[2022-12-06 23:48:34,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:48:34,275] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:48:34,276] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:48:40,708] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:48:47,018] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:48:53,058] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:48:59,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:49:06,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:49:12,643] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:49:19,155] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:49:24,761] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:49:31,053] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:49:37,918] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6633746364292787
[2022-12-06 23:49:37,919] [INFO] [runner_train_mujoco] Average state value: 0.667733488380909
[2022-12-06 23:49:37,919] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 23:49:37,981] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.04255
[2022-12-06 23:49:38,036] [INFO] [controller] EPOCH 2 loss ppo:  -0.01903, loss val: 0.04153
[2022-12-06 23:49:38,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.02457, loss val: 0.04276
[2022-12-06 23:49:38,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.02843, loss val: 0.04141
[2022-12-06 23:49:38,155] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:49:38,345] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:49:38,345] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:49:44,242] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:49:50,351] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:49:56,061] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:50:01,887] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:50:09,158] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:50:18,945] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:50:27,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:50:33,663] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:50:40,445] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:50:47,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.704086962118358
[2022-12-06 23:50:47,264] [INFO] [runner_train_mujoco] Average state value: 0.6722044033606847
[2022-12-06 23:50:47,264] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 23:50:47,341] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.04196
[2022-12-06 23:50:47,404] [INFO] [controller] EPOCH 2 loss ppo:  -0.01846, loss val: 0.04205
[2022-12-06 23:50:47,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.02309, loss val: 0.04209
[2022-12-06 23:50:47,525] [INFO] [controller] EPOCH 4 loss ppo:  -0.02536, loss val: 0.04186
[2022-12-06 23:50:47,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:50:47,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:50:47,744] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:50:54,827] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:51:01,561] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:51:07,499] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:51:13,888] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:51:19,843] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:51:26,018] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:51:32,213] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:51:38,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:51:44,749] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:51:50,831] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7978669900664057
[2022-12-06 23:51:50,832] [INFO] [runner_train_mujoco] Average state value: 0.6679026153882346
[2022-12-06 23:51:50,832] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 23:51:50,901] [INFO] [controller] EPOCH 1 loss ppo:  -0.01473, loss val: 0.04420
[2022-12-06 23:51:50,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.01766, loss val: 0.04491
[2022-12-06 23:51:51,009] [INFO] [controller] EPOCH 3 loss ppo:  -0.02229, loss val: 0.04443
[2022-12-06 23:51:51,067] [INFO] [controller] EPOCH 4 loss ppo:  -0.02529, loss val: 0.04325
[2022-12-06 23:51:51,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:51:51,280] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:51:51,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:51:57,331] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:52:03,916] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:52:10,248] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:52:16,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:52:22,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:52:29,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:52:35,600] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:52:42,741] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:52:49,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:52:55,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.721178629769372
[2022-12-06 23:52:55,549] [INFO] [runner_train_mujoco] Average state value: 0.6682449737389883
[2022-12-06 23:52:55,549] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 23:52:55,613] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.03906
[2022-12-06 23:52:55,666] [INFO] [controller] EPOCH 2 loss ppo:  -0.01629, loss val: 0.03964
[2022-12-06 23:52:55,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.01924, loss val: 0.03982
[2022-12-06 23:52:55,769] [INFO] [controller] EPOCH 4 loss ppo:  -0.02281, loss val: 0.03910
[2022-12-06 23:52:55,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:52:55,986] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:52:55,986] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:53:02,141] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:53:08,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:53:15,137] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:53:23,784] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:53:31,787] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:53:39,577] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:53:47,034] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:53:54,906] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:54:02,646] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:54:10,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.775405994451625
[2022-12-06 23:54:10,564] [INFO] [runner_train_mujoco] Average state value: 0.6709936554431916
[2022-12-06 23:54:10,564] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 23:54:10,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04032
[2022-12-06 23:54:10,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.01567, loss val: 0.04057
[2022-12-06 23:54:10,825] [INFO] [controller] EPOCH 3 loss ppo:  -0.01816, loss val: 0.04022
[2022-12-06 23:54:10,904] [INFO] [controller] EPOCH 4 loss ppo:  -0.02103, loss val: 0.04017
[2022-12-06 23:54:10,919] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:54:11,144] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:54:11,144] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:54:19,685] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:54:27,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:54:36,126] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:54:43,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:54:51,267] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:54:58,746] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:55:06,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:55:14,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:55:21,890] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:55:29,732] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8346856708982076
[2022-12-06 23:55:29,733] [INFO] [runner_train_mujoco] Average state value: 0.6684582710266113
[2022-12-06 23:55:29,733] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 23:55:29,821] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04195
[2022-12-06 23:55:29,895] [INFO] [controller] EPOCH 2 loss ppo:  -0.01579, loss val: 0.04063
[2022-12-06 23:55:29,965] [INFO] [controller] EPOCH 3 loss ppo:  -0.01858, loss val: 0.04136
[2022-12-06 23:55:30,032] [INFO] [controller] EPOCH 4 loss ppo:  -0.02157, loss val: 0.04168
[2022-12-06 23:55:30,046] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:55:30,265] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:55:30,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:55:38,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:55:46,722] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:55:54,591] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:56:02,272] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:56:09,906] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:56:17,482] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:56:25,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:56:33,953] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:56:42,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:56:50,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.843839388079063
[2022-12-06 23:56:50,167] [INFO] [runner_train_mujoco] Average state value: 0.6675436021884282
[2022-12-06 23:56:50,168] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 23:56:50,260] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04269
[2022-12-06 23:56:50,354] [INFO] [controller] EPOCH 2 loss ppo:  -0.01478, loss val: 0.04397
[2022-12-06 23:56:50,444] [INFO] [controller] EPOCH 3 loss ppo:  -0.01589, loss val: 0.04280
[2022-12-06 23:56:50,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.01765, loss val: 0.04371
[2022-12-06 23:56:50,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:56:50,745] [INFO] [optimize] Finished learning.
