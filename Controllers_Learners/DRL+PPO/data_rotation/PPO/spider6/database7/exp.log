[2022-12-07 05:41:58,894] [INFO] [optimize] Starting learning
[2022-12-07 05:41:58,903] [INFO] [optimize] Starting learning process..
[2022-12-07 05:41:58,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:41:58,960] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:42:06,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:42:13,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:42:19,280] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:42:24,985] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:42:30,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:42:36,826] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:42:43,035] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:42:48,985] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:42:54,931] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:43:00,495] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16418450606040833
[2022-12-07 05:43:00,495] [INFO] [runner_train_mujoco] Average state value: 0.2598941051835815
[2022-12-07 05:43:00,496] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 05:43:00,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.28758
[2022-12-07 05:43:00,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.03042, loss val: 0.24867
[2022-12-07 05:43:00,625] [INFO] [controller] EPOCH 3 loss ppo:  -0.03378, loss val: 0.21995
[2022-12-07 05:43:00,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.03712, loss val: 0.18877
[2022-12-07 05:43:00,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:43:00,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:43:00,834] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:43:06,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:43:11,946] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:43:17,487] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:43:24,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:43:29,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:43:35,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:43:40,434] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:43:45,998] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:43:51,257] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:43:56,431] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17166359179080176
[2022-12-07 05:43:56,431] [INFO] [runner_train_mujoco] Average state value: 0.42606165796642503
[2022-12-07 05:43:56,431] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 05:43:56,482] [INFO] [controller] EPOCH 1 loss ppo:  -0.01256, loss val: 0.18460
[2022-12-07 05:43:56,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.02622, loss val: 0.15605
[2022-12-07 05:43:56,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.03263, loss val: 0.13428
[2022-12-07 05:43:56,607] [INFO] [controller] EPOCH 4 loss ppo:  -0.03432, loss val: 0.11616
[2022-12-07 05:43:56,617] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:43:56,773] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:43:56,773] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:44:02,197] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:44:07,933] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:44:12,918] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:44:18,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:44:23,117] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:44:27,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:44:32,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:44:37,244] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:44:42,130] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:44:46,976] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17351442677733414
[2022-12-07 05:44:46,977] [INFO] [runner_train_mujoco] Average state value: 0.594549646123002
[2022-12-07 05:44:46,977] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 05:44:47,024] [INFO] [controller] EPOCH 1 loss ppo:  -0.01067, loss val: 0.11924
[2022-12-07 05:44:47,063] [INFO] [controller] EPOCH 2 loss ppo:  -0.02746, loss val: 0.10166
[2022-12-07 05:44:47,103] [INFO] [controller] EPOCH 3 loss ppo:  -0.03569, loss val: 0.09030
[2022-12-07 05:44:47,142] [INFO] [controller] EPOCH 4 loss ppo:  -0.03872, loss val: 0.08260
[2022-12-07 05:44:47,151] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:44:47,306] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:44:47,306] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:44:52,281] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:44:57,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:45:02,621] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:45:07,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:45:12,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:45:16,867] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:45:21,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:45:26,453] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:45:31,130] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:45:35,636] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1453759350466201
[2022-12-07 05:45:35,637] [INFO] [runner_train_mujoco] Average state value: 0.7319792678852876
[2022-12-07 05:45:35,637] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 05:45:35,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.01037, loss val: 0.07614
[2022-12-07 05:45:35,729] [INFO] [controller] EPOCH 2 loss ppo:  -0.02426, loss val: 0.06807
[2022-12-07 05:45:35,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.02778, loss val: 0.06303
[2022-12-07 05:45:35,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.02952, loss val: 0.06262
[2022-12-07 05:45:35,819] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:45:35,962] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:45:35,962] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:45:40,645] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:45:46,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:45:51,535] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:45:56,124] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:46:01,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:46:06,085] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:46:11,069] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:46:16,367] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:46:21,037] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:46:25,967] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16787866415550962
[2022-12-07 05:46:25,967] [INFO] [runner_train_mujoco] Average state value: 0.81078686551253
[2022-12-07 05:46:25,967] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 05:46:26,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.00740, loss val: 0.06310
[2022-12-07 05:46:26,054] [INFO] [controller] EPOCH 2 loss ppo:  -0.01644, loss val: 0.06075
[2022-12-07 05:46:26,096] [INFO] [controller] EPOCH 3 loss ppo:  -0.02273, loss val: 0.05545
[2022-12-07 05:46:26,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.02924, loss val: 0.05217
[2022-12-07 05:46:26,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:46:26,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:46:26,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:46:31,308] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:46:36,458] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:46:41,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:46:46,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:46:50,804] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:46:55,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:47:00,151] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:47:05,225] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:47:09,814] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:47:15,008] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16210171677445923
[2022-12-07 05:47:15,008] [INFO] [runner_train_mujoco] Average state value: 0.7672760939200719
[2022-12-07 05:47:15,008] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 05:47:15,057] [INFO] [controller] EPOCH 1 loss ppo:  -0.00661, loss val: 0.05069
[2022-12-07 05:47:15,100] [INFO] [controller] EPOCH 2 loss ppo:  -0.01981, loss val: 0.04732
[2022-12-07 05:47:15,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.02312, loss val: 0.04515
[2022-12-07 05:47:15,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.02871, loss val: 0.04386
[2022-12-07 05:47:15,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:47:15,335] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:47:15,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:47:20,329] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:47:24,898] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:47:30,025] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:47:35,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:47:39,448] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:47:44,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:47:49,182] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:47:53,815] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:47:58,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:48:03,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15713345336202175
[2022-12-07 05:48:03,721] [INFO] [runner_train_mujoco] Average state value: 0.6832790433764457
[2022-12-07 05:48:03,721] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 05:48:03,770] [INFO] [controller] EPOCH 1 loss ppo:  -0.00691, loss val: 0.04569
[2022-12-07 05:48:03,811] [INFO] [controller] EPOCH 2 loss ppo:  -0.01519, loss val: 0.04436
[2022-12-07 05:48:03,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.02180, loss val: 0.03966
[2022-12-07 05:48:03,897] [INFO] [controller] EPOCH 4 loss ppo:  -0.02629, loss val: 0.04323
[2022-12-07 05:48:03,907] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:48:04,089] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:48:04,089] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:48:08,943] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:48:14,223] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:48:19,609] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:48:24,387] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:48:28,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:48:33,894] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:48:38,463] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:48:43,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:48:48,289] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:48:53,024] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15168245899570237
[2022-12-07 05:48:53,024] [INFO] [runner_train_mujoco] Average state value: 0.6994277226527532
[2022-12-07 05:48:53,024] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 05:48:53,081] [INFO] [controller] EPOCH 1 loss ppo:  -0.00609, loss val: 0.04509
[2022-12-07 05:48:53,125] [INFO] [controller] EPOCH 2 loss ppo:  -0.01221, loss val: 0.04383
[2022-12-07 05:48:53,182] [INFO] [controller] EPOCH 3 loss ppo:  -0.01932, loss val: 0.04404
[2022-12-07 05:48:53,229] [INFO] [controller] EPOCH 4 loss ppo:  -0.02205, loss val: 0.04495
[2022-12-07 05:48:53,238] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:48:53,398] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:48:53,398] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:48:58,696] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:49:03,467] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:49:08,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:49:13,233] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:49:18,337] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:49:23,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:49:28,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:49:32,805] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:49:37,482] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:49:42,323] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15932612616346714
[2022-12-07 05:49:42,323] [INFO] [runner_train_mujoco] Average state value: 0.7506750666896501
[2022-12-07 05:49:42,324] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 05:49:42,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.00686, loss val: 0.04187
[2022-12-07 05:49:42,419] [INFO] [controller] EPOCH 2 loss ppo:  -0.01526, loss val: 0.04134
[2022-12-07 05:49:42,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.01867, loss val: 0.04141
[2022-12-07 05:49:42,505] [INFO] [controller] EPOCH 4 loss ppo:  -0.02681, loss val: 0.04261
[2022-12-07 05:49:42,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:49:42,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:49:42,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:49:47,609] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:49:52,325] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:49:57,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:50:02,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:50:07,701] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:50:12,297] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:50:16,974] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:50:21,427] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:50:26,000] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:50:30,648] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2073648423494968
[2022-12-07 05:50:30,648] [INFO] [runner_train_mujoco] Average state value: 0.7689246447086335
[2022-12-07 05:50:30,648] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 05:50:30,702] [INFO] [controller] EPOCH 1 loss ppo:  -0.00666, loss val: 0.04227
[2022-12-07 05:50:30,743] [INFO] [controller] EPOCH 2 loss ppo:  -0.01535, loss val: 0.04026
[2022-12-07 05:50:30,785] [INFO] [controller] EPOCH 3 loss ppo:  -0.01741, loss val: 0.03858
[2022-12-07 05:50:30,828] [INFO] [controller] EPOCH 4 loss ppo:  -0.02287, loss val: 0.03827
[2022-12-07 05:50:30,836] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:50:30,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:50:30,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:50:36,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:50:41,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:50:46,359] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:50:51,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:50:56,164] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:51:01,333] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:51:06,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:51:11,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:51:15,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:51:20,416] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16036718864283395
[2022-12-07 05:51:20,416] [INFO] [runner_train_mujoco] Average state value: 0.7121754978299141
[2022-12-07 05:51:20,416] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 05:51:20,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.00514, loss val: 0.04463
[2022-12-07 05:51:20,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.01471, loss val: 0.04436
[2022-12-07 05:51:20,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.02190, loss val: 0.04538
[2022-12-07 05:51:20,581] [INFO] [controller] EPOCH 4 loss ppo:  -0.02938, loss val: 0.04474
[2022-12-07 05:51:20,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:51:20,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:51:20,738] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:51:25,507] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:51:30,127] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:51:34,949] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:51:39,933] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:51:44,417] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:51:49,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:51:53,992] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:51:58,768] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:52:03,171] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:52:07,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.10999348494568917
[2022-12-07 05:52:07,913] [INFO] [runner_train_mujoco] Average state value: 0.7064449301958085
[2022-12-07 05:52:07,913] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 05:52:07,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.00662, loss val: 0.04553
[2022-12-07 05:52:08,023] [INFO] [controller] EPOCH 2 loss ppo:  -0.01383, loss val: 0.04532
[2022-12-07 05:52:08,067] [INFO] [controller] EPOCH 3 loss ppo:  -0.01872, loss val: 0.04427
[2022-12-07 05:52:08,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.02771, loss val: 0.04415
[2022-12-07 05:52:08,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:52:08,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:52:08,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:52:13,579] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:52:18,619] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:52:23,687] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:52:28,966] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:52:33,568] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:52:38,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:52:42,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:52:47,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:52:52,706] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:52:57,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1555907504746879
[2022-12-07 05:52:57,341] [INFO] [runner_train_mujoco] Average state value: 0.7647240177790324
[2022-12-07 05:52:57,341] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 05:52:57,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.00709, loss val: 0.04310
[2022-12-07 05:52:57,431] [INFO] [controller] EPOCH 2 loss ppo:  -0.01942, loss val: 0.04213
[2022-12-07 05:52:57,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.02291, loss val: 0.04235
[2022-12-07 05:52:57,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.02431, loss val: 0.04210
[2022-12-07 05:52:57,521] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:52:57,675] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:52:57,676] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:53:02,859] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:53:07,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:53:11,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:53:16,613] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:53:21,279] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:53:26,085] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:53:31,204] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:53:36,163] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:53:41,093] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:53:45,823] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1451312583090319
[2022-12-07 05:53:45,824] [INFO] [runner_train_mujoco] Average state value: 0.7640858563582102
[2022-12-07 05:53:45,824] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 05:53:45,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.00555, loss val: 0.04419
[2022-12-07 05:53:45,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.01596, loss val: 0.04323
[2022-12-07 05:53:45,958] [INFO] [controller] EPOCH 3 loss ppo:  -0.02039, loss val: 0.04436
[2022-12-07 05:53:45,999] [INFO] [controller] EPOCH 4 loss ppo:  -0.02484, loss val: 0.04302
[2022-12-07 05:53:46,008] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:53:46,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:53:46,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:53:51,403] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:53:56,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:54:01,083] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:54:05,928] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:54:10,674] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:54:15,470] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:54:19,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:54:24,618] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:54:29,170] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:54:34,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.26603914467965784
[2022-12-07 05:54:34,327] [INFO] [runner_train_mujoco] Average state value: 0.7347005887428919
[2022-12-07 05:54:34,327] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 05:54:34,373] [INFO] [controller] EPOCH 1 loss ppo:  -0.00719, loss val: 0.03943
[2022-12-07 05:54:34,408] [INFO] [controller] EPOCH 2 loss ppo:  -0.01915, loss val: 0.04120
[2022-12-07 05:54:34,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.02440, loss val: 0.03932
[2022-12-07 05:54:34,488] [INFO] [controller] EPOCH 4 loss ppo:  -0.03063, loss val: 0.03914
[2022-12-07 05:54:34,497] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:54:34,637] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:54:34,637] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:54:39,713] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:54:44,895] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:54:49,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:54:54,562] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:54:59,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:55:03,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:55:08,542] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:55:13,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:55:18,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:55:22,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17755941405107245
[2022-12-07 05:55:22,851] [INFO] [runner_train_mujoco] Average state value: 0.7132888680696488
[2022-12-07 05:55:22,851] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 05:55:22,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.00749, loss val: 0.03942
[2022-12-07 05:55:22,939] [INFO] [controller] EPOCH 2 loss ppo:  -0.01826, loss val: 0.03718
[2022-12-07 05:55:22,980] [INFO] [controller] EPOCH 3 loss ppo:  -0.02379, loss val: 0.03779
[2022-12-07 05:55:23,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.02652, loss val: 0.03563
[2022-12-07 05:55:23,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:55:23,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:55:23,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:55:28,222] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:55:33,425] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:55:38,104] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:55:43,238] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:55:47,976] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:55:52,997] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:55:57,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:56:02,843] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:56:07,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:56:11,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3045677521598874
[2022-12-07 05:56:11,721] [INFO] [runner_train_mujoco] Average state value: 0.6777005161245663
[2022-12-07 05:56:11,721] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 05:56:11,770] [INFO] [controller] EPOCH 1 loss ppo:  -0.00657, loss val: 0.03909
[2022-12-07 05:56:11,811] [INFO] [controller] EPOCH 2 loss ppo:  -0.01551, loss val: 0.03932
[2022-12-07 05:56:11,849] [INFO] [controller] EPOCH 3 loss ppo:  -0.02393, loss val: 0.03940
[2022-12-07 05:56:11,889] [INFO] [controller] EPOCH 4 loss ppo:  -0.02811, loss val: 0.03985
[2022-12-07 05:56:11,898] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:56:12,054] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:56:12,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:56:16,518] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:56:21,301] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:56:26,137] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:56:31,433] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:56:36,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:56:41,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:56:45,762] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:56:50,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:56:56,009] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:57:00,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2644504113554154
[2022-12-07 05:57:00,996] [INFO] [runner_train_mujoco] Average state value: 0.659355723977089
[2022-12-07 05:57:00,997] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 05:57:01,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.00704, loss val: 0.04499
[2022-12-07 05:57:01,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.01603, loss val: 0.04166
[2022-12-07 05:57:01,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.02271, loss val: 0.04105
[2022-12-07 05:57:01,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.02590, loss val: 0.04058
[2022-12-07 05:57:01,269] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:57:01,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:57:01,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:57:06,207] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:57:11,074] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:57:16,021] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:57:20,522] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:57:25,288] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:57:29,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:57:34,789] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:57:39,247] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:57:43,878] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:57:48,434] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5603700227954539
[2022-12-07 05:57:48,434] [INFO] [runner_train_mujoco] Average state value: 0.6971930450598399
[2022-12-07 05:57:48,434] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 05:57:48,480] [INFO] [controller] EPOCH 1 loss ppo:  -0.00776, loss val: 0.03421
[2022-12-07 05:57:48,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.01714, loss val: 0.03439
[2022-12-07 05:57:48,562] [INFO] [controller] EPOCH 3 loss ppo:  -0.02693, loss val: 0.03440
[2022-12-07 05:57:48,599] [INFO] [controller] EPOCH 4 loss ppo:  -0.02922, loss val: 0.03438
[2022-12-07 05:57:48,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:57:48,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:57:48,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:57:53,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:57:58,499] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:58:03,831] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:58:09,398] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:58:14,822] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:58:19,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:58:24,936] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:58:29,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:58:34,365] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:58:39,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5986077253724865
[2022-12-07 05:58:39,026] [INFO] [runner_train_mujoco] Average state value: 0.7165780753691992
[2022-12-07 05:58:39,026] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:58:39,072] [INFO] [controller] EPOCH 1 loss ppo:  -0.00827, loss val: 0.04068
[2022-12-07 05:58:39,113] [INFO] [controller] EPOCH 2 loss ppo:  -0.01924, loss val: 0.03834
[2022-12-07 05:58:39,155] [INFO] [controller] EPOCH 3 loss ppo:  -0.02455, loss val: 0.03841
[2022-12-07 05:58:39,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.02938, loss val: 0.03900
[2022-12-07 05:58:39,203] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:58:39,352] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:58:39,352] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:58:43,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:58:48,781] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:58:53,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:58:58,280] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:59:03,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:59:07,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:59:12,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:59:17,587] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:59:22,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:59:27,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.784424974648595
[2022-12-07 05:59:27,146] [INFO] [runner_train_mujoco] Average state value: 0.7001582979162534
[2022-12-07 05:59:27,146] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 05:59:27,193] [INFO] [controller] EPOCH 1 loss ppo:  -0.01004, loss val: 0.03778
[2022-12-07 05:59:27,238] [INFO] [controller] EPOCH 2 loss ppo:  -0.02181, loss val: 0.03668
[2022-12-07 05:59:27,280] [INFO] [controller] EPOCH 3 loss ppo:  -0.02572, loss val: 0.03481
[2022-12-07 05:59:27,322] [INFO] [controller] EPOCH 4 loss ppo:  -0.02989, loss val: 0.03465
[2022-12-07 05:59:27,331] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:59:27,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:59:27,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:59:32,175] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:59:36,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:59:41,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:59:46,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:59:50,707] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:59:55,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:00:00,296] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:00:05,170] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:00:10,067] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:00:14,762] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8005369859053804
[2022-12-07 06:00:14,762] [INFO] [runner_train_mujoco] Average state value: 0.6446197480360667
[2022-12-07 06:00:14,762] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 06:00:14,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01011, loss val: 0.03812
[2022-12-07 06:00:14,854] [INFO] [controller] EPOCH 2 loss ppo:  -0.02097, loss val: 0.03887
[2022-12-07 06:00:14,896] [INFO] [controller] EPOCH 3 loss ppo:  -0.02273, loss val: 0.03931
[2022-12-07 06:00:14,937] [INFO] [controller] EPOCH 4 loss ppo:  -0.02743, loss val: 0.03930
[2022-12-07 06:00:14,947] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:00:15,104] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:00:15,104] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:00:19,993] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:00:24,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:00:29,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:00:34,284] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:00:39,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:00:43,767] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:00:48,276] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:00:52,766] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:00:57,527] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:01:01,957] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0798284347416913
[2022-12-07 06:01:01,958] [INFO] [runner_train_mujoco] Average state value: 0.6179813254674275
[2022-12-07 06:01:01,958] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 06:01:02,006] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.04545
[2022-12-07 06:01:02,115] [INFO] [controller] EPOCH 2 loss ppo:  -0.02105, loss val: 0.04276
[2022-12-07 06:01:02,148] [INFO] [controller] EPOCH 3 loss ppo:  -0.02491, loss val: 0.04098
[2022-12-07 06:01:02,184] [INFO] [controller] EPOCH 4 loss ppo:  -0.02908, loss val: 0.03781
[2022-12-07 06:01:02,193] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:01:02,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:01:02,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:01:07,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:01:12,021] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:01:17,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:01:22,015] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:01:26,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:01:31,705] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:01:36,154] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:01:41,041] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:01:45,564] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:01:50,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.208565697873059
[2022-12-07 06:01:50,116] [INFO] [runner_train_mujoco] Average state value: 0.6832053428689638
[2022-12-07 06:01:50,116] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 06:01:50,168] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.04082
[2022-12-07 06:01:50,207] [INFO] [controller] EPOCH 2 loss ppo:  -0.02624, loss val: 0.04324
[2022-12-07 06:01:50,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.03325, loss val: 0.04262
[2022-12-07 06:01:50,338] [INFO] [controller] EPOCH 4 loss ppo:  -0.03893, loss val: 0.04353
[2022-12-07 06:01:50,347] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:01:50,501] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:01:50,501] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:01:55,167] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:01:59,647] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:02:05,130] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:02:09,648] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:02:14,287] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:02:18,945] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:02:23,500] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:02:28,047] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:02:32,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:02:37,016] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5222840983671386
[2022-12-07 06:02:37,017] [INFO] [runner_train_mujoco] Average state value: 0.6993802962700525
[2022-12-07 06:02:37,017] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 06:02:37,065] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.04383
[2022-12-07 06:02:37,108] [INFO] [controller] EPOCH 2 loss ppo:  -0.02116, loss val: 0.04289
[2022-12-07 06:02:37,150] [INFO] [controller] EPOCH 3 loss ppo:  -0.02445, loss val: 0.04389
[2022-12-07 06:02:37,189] [INFO] [controller] EPOCH 4 loss ppo:  -0.02986, loss val: 0.04291
[2022-12-07 06:02:37,198] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:02:37,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:02:37,357] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:02:42,047] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:02:46,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:02:51,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:02:56,415] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:03:01,096] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:03:06,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:03:10,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:03:15,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:03:20,244] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:03:24,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4590699510059508
[2022-12-07 06:03:24,659] [INFO] [runner_train_mujoco] Average state value: 0.6827460917433104
[2022-12-07 06:03:24,659] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 06:03:24,710] [INFO] [controller] EPOCH 1 loss ppo:  -0.01194, loss val: 0.03787
[2022-12-07 06:03:24,752] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.03907
[2022-12-07 06:03:24,796] [INFO] [controller] EPOCH 3 loss ppo:  -0.02668, loss val: 0.03800
[2022-12-07 06:03:24,837] [INFO] [controller] EPOCH 4 loss ppo:  -0.03132, loss val: 0.03759
[2022-12-07 06:03:24,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:03:24,990] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:03:24,990] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:03:29,578] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:03:34,081] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:03:39,028] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:03:43,653] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:03:48,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:03:53,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:03:57,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:04:03,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:04:07,785] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:04:12,221] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4994941451823698
[2022-12-07 06:04:12,221] [INFO] [runner_train_mujoco] Average state value: 0.695088456551234
[2022-12-07 06:04:12,221] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 06:04:12,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04264
[2022-12-07 06:04:12,321] [INFO] [controller] EPOCH 2 loss ppo:  -0.02284, loss val: 0.04301
[2022-12-07 06:04:12,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.02992, loss val: 0.04291
[2022-12-07 06:04:12,406] [INFO] [controller] EPOCH 4 loss ppo:  -0.03512, loss val: 0.04286
[2022-12-07 06:04:12,414] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:04:12,569] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:04:12,569] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:04:17,227] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:04:21,989] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:04:26,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:04:30,917] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:04:35,803] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:04:40,088] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:04:44,667] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:04:49,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:04:54,082] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:04:58,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5118551129004572
[2022-12-07 06:04:58,818] [INFO] [runner_train_mujoco] Average state value: 0.6877469194531441
[2022-12-07 06:04:58,818] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 06:04:58,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04190
[2022-12-07 06:04:58,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.02503, loss val: 0.04097
[2022-12-07 06:04:58,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.02809, loss val: 0.03938
[2022-12-07 06:04:59,002] [INFO] [controller] EPOCH 4 loss ppo:  -0.03543, loss val: 0.03865
[2022-12-07 06:04:59,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:04:59,163] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:04:59,164] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:05:04,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:05:08,925] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:05:13,881] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:05:18,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:05:22,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:05:26,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:05:31,246] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:05:35,958] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:05:40,483] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:05:45,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.715684745635627
[2022-12-07 06:05:45,310] [INFO] [runner_train_mujoco] Average state value: 0.641128444035848
[2022-12-07 06:05:45,310] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 06:05:45,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01239, loss val: 0.04094
[2022-12-07 06:05:45,437] [INFO] [controller] EPOCH 2 loss ppo:  -0.02131, loss val: 0.04188
[2022-12-07 06:05:45,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.02427, loss val: 0.04137
[2022-12-07 06:05:45,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.03544, loss val: 0.04163
[2022-12-07 06:05:45,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:05:45,725] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:05:45,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:05:50,304] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:05:55,117] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:05:59,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:06:04,600] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:06:09,206] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:06:13,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:06:18,216] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:06:22,748] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:06:27,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:06:31,448] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.803164945943261
[2022-12-07 06:06:31,448] [INFO] [runner_train_mujoco] Average state value: 0.6227643803159395
[2022-12-07 06:06:31,448] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 06:06:31,498] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.04373
[2022-12-07 06:06:31,536] [INFO] [controller] EPOCH 2 loss ppo:  -0.02465, loss val: 0.04489
[2022-12-07 06:06:31,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.02914, loss val: 0.04254
[2022-12-07 06:06:31,618] [INFO] [controller] EPOCH 4 loss ppo:  -0.03717, loss val: 0.04310
[2022-12-07 06:06:31,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:06:31,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:06:31,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:06:36,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:06:41,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:06:46,067] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:06:50,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:06:55,081] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:06:59,572] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:07:04,948] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:07:09,978] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:07:14,809] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:07:20,078] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9480561525459599
[2022-12-07 06:07:20,079] [INFO] [runner_train_mujoco] Average state value: 0.6458232147097588
[2022-12-07 06:07:20,079] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 06:07:20,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.03815
[2022-12-07 06:07:20,212] [INFO] [controller] EPOCH 2 loss ppo:  -0.02172, loss val: 0.03904
[2022-12-07 06:07:20,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.02493, loss val: 0.03733
[2022-12-07 06:07:20,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.03146, loss val: 0.03679
[2022-12-07 06:07:20,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:07:20,496] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:07:20,496] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:07:24,839] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:07:29,710] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:07:34,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:07:39,395] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:07:43,670] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:07:48,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:07:52,623] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:07:56,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:08:01,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:08:05,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.062935878634124
[2022-12-07 06:08:05,812] [INFO] [runner_train_mujoco] Average state value: 0.6656701322793961
[2022-12-07 06:08:05,812] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 06:08:05,860] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.04094
[2022-12-07 06:08:05,901] [INFO] [controller] EPOCH 2 loss ppo:  -0.02310, loss val: 0.04109
[2022-12-07 06:08:05,943] [INFO] [controller] EPOCH 3 loss ppo:  -0.02741, loss val: 0.04104
[2022-12-07 06:08:05,985] [INFO] [controller] EPOCH 4 loss ppo:  -0.03443, loss val: 0.04074
[2022-12-07 06:08:05,993] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:08:06,152] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:08:06,153] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:08:11,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:08:16,207] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:08:20,759] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:08:24,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:08:29,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:08:34,423] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:08:38,902] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:08:43,751] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:08:48,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:08:52,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.100204165729302
[2022-12-07 06:08:52,980] [INFO] [runner_train_mujoco] Average state value: 0.6658643008669217
[2022-12-07 06:08:52,980] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 06:08:53,026] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.03922
[2022-12-07 06:08:53,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.02342, loss val: 0.03874
[2022-12-07 06:08:53,108] [INFO] [controller] EPOCH 3 loss ppo:  -0.02762, loss val: 0.03880
[2022-12-07 06:08:53,149] [INFO] [controller] EPOCH 4 loss ppo:  -0.03355, loss val: 0.03894
[2022-12-07 06:08:53,157] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:08:53,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:08:53,311] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:08:57,437] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:09:01,997] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:09:06,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:09:10,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:09:15,257] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:09:19,764] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:09:24,068] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:09:28,985] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:09:33,484] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:09:38,288] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1170567405418756
[2022-12-07 06:09:38,288] [INFO] [runner_train_mujoco] Average state value: 0.6634103009502094
[2022-12-07 06:09:38,288] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 06:09:38,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.04276
[2022-12-07 06:09:38,382] [INFO] [controller] EPOCH 2 loss ppo:  -0.02206, loss val: 0.04293
[2022-12-07 06:09:38,425] [INFO] [controller] EPOCH 3 loss ppo:  -0.02530, loss val: 0.04284
[2022-12-07 06:09:38,470] [INFO] [controller] EPOCH 4 loss ppo:  -0.03436, loss val: 0.04271
[2022-12-07 06:09:38,480] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:09:38,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:09:38,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:09:43,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:09:47,791] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:09:52,628] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:09:57,611] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:10:01,817] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:10:06,018] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:10:10,485] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:10:14,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:10:19,152] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:10:23,724] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2450319118037827
[2022-12-07 06:10:23,724] [INFO] [runner_train_mujoco] Average state value: 0.6586259527405103
[2022-12-07 06:10:23,724] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 06:10:23,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01038, loss val: 0.04043
[2022-12-07 06:10:23,826] [INFO] [controller] EPOCH 2 loss ppo:  -0.01580, loss val: 0.03972
[2022-12-07 06:10:23,869] [INFO] [controller] EPOCH 3 loss ppo:  -0.02317, loss val: 0.04067
[2022-12-07 06:10:23,914] [INFO] [controller] EPOCH 4 loss ppo:  -0.03081, loss val: 0.03985
[2022-12-07 06:10:23,923] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:10:24,063] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:10:24,064] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:10:28,655] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:10:33,501] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:10:38,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:10:42,811] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:10:46,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:10:51,633] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:10:55,874] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:11:00,359] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:11:04,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:11:09,155] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4292999503135007
[2022-12-07 06:11:09,155] [INFO] [runner_train_mujoco] Average state value: 0.6331915025313696
[2022-12-07 06:11:09,155] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 06:11:09,206] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.03808
[2022-12-07 06:11:09,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.01939, loss val: 0.04045
[2022-12-07 06:11:09,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.02475, loss val: 0.03929
[2022-12-07 06:11:09,336] [INFO] [controller] EPOCH 4 loss ppo:  -0.03067, loss val: 0.03864
[2022-12-07 06:11:09,342] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:11:09,478] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:11:09,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:11:13,899] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:11:18,521] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:11:22,758] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:11:26,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:11:31,599] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:11:35,803] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:11:40,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:11:46,126] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:11:52,369] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:11:57,788] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4492883762129423
[2022-12-07 06:11:57,788] [INFO] [runner_train_mujoco] Average state value: 0.6279200288852056
[2022-12-07 06:11:57,788] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 06:11:57,856] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.04565
[2022-12-07 06:11:57,907] [INFO] [controller] EPOCH 2 loss ppo:  -0.02234, loss val: 0.04483
[2022-12-07 06:11:57,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.02707, loss val: 0.04486
[2022-12-07 06:11:58,005] [INFO] [controller] EPOCH 4 loss ppo:  -0.03117, loss val: 0.04382
[2022-12-07 06:11:58,014] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:11:58,173] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:11:58,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:12:03,172] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:12:08,611] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:12:13,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:12:19,025] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:12:24,167] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:12:29,659] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:12:34,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:12:39,754] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:12:44,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:12:50,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5584538790700084
[2022-12-07 06:12:50,432] [INFO] [runner_train_mujoco] Average state value: 0.6553053742249808
[2022-12-07 06:12:50,433] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 06:12:50,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.01601, loss val: 0.04167
[2022-12-07 06:12:50,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.01842, loss val: 0.04157
[2022-12-07 06:12:50,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.02040, loss val: 0.04210
[2022-12-07 06:12:50,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.03112, loss val: 0.04181
[2022-12-07 06:12:50,625] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:12:50,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:12:50,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:12:55,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:13:01,253] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:13:06,260] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:13:11,381] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:13:16,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:13:22,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:13:27,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:13:32,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:13:38,275] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:13:42,796] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6241297382908977
[2022-12-07 06:13:42,796] [INFO] [runner_train_mujoco] Average state value: 0.6683828090031942
[2022-12-07 06:13:42,796] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 06:13:42,851] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.03966
[2022-12-07 06:13:42,895] [INFO] [controller] EPOCH 2 loss ppo:  -0.01562, loss val: 0.04142
[2022-12-07 06:13:42,941] [INFO] [controller] EPOCH 3 loss ppo:  -0.02507, loss val: 0.03968
[2022-12-07 06:13:42,988] [INFO] [controller] EPOCH 4 loss ppo:  -0.02735, loss val: 0.04074
[2022-12-07 06:13:42,998] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:13:43,163] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:13:43,164] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:13:48,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:13:53,236] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:13:58,564] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:14:03,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:14:09,117] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:14:14,141] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:14:18,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:14:23,649] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:14:28,616] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:14:33,792] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.660290128088001
[2022-12-07 06:14:33,792] [INFO] [runner_train_mujoco] Average state value: 0.6650697032809256
[2022-12-07 06:14:33,792] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 06:14:33,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.03982
[2022-12-07 06:14:33,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.01935, loss val: 0.03955
[2022-12-07 06:14:34,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.02440, loss val: 0.04056
[2022-12-07 06:14:34,052] [INFO] [controller] EPOCH 4 loss ppo:  -0.03199, loss val: 0.03816
[2022-12-07 06:14:34,062] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:14:34,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:14:34,219] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:14:39,125] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:14:44,476] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:14:49,609] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:14:54,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:14:59,671] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:15:04,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:15:09,830] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:15:14,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:15:19,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:15:24,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6345871919924524
[2022-12-07 06:15:24,508] [INFO] [runner_train_mujoco] Average state value: 0.651545921643575
[2022-12-07 06:15:24,508] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 06:15:24,561] [INFO] [controller] EPOCH 1 loss ppo:  -0.00999, loss val: 0.04256
[2022-12-07 06:15:24,605] [INFO] [controller] EPOCH 2 loss ppo:  -0.01844, loss val: 0.04239
[2022-12-07 06:15:24,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.02365, loss val: 0.04265
[2022-12-07 06:15:24,693] [INFO] [controller] EPOCH 4 loss ppo:  -0.02729, loss val: 0.04304
[2022-12-07 06:15:24,702] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:15:24,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:15:24,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:15:30,234] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:15:35,391] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:15:40,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:15:45,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:15:51,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:15:56,412] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:16:00,857] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:16:06,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:16:11,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:16:16,554] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7424510913073155
[2022-12-07 06:16:16,555] [INFO] [runner_train_mujoco] Average state value: 0.6441979021032651
[2022-12-07 06:16:16,555] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 06:16:16,605] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04298
[2022-12-07 06:16:16,649] [INFO] [controller] EPOCH 2 loss ppo:  -0.01535, loss val: 0.04194
[2022-12-07 06:16:16,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.02131, loss val: 0.04161
[2022-12-07 06:16:16,737] [INFO] [controller] EPOCH 4 loss ppo:  -0.02470, loss val: 0.04171
[2022-12-07 06:16:16,747] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:16:16,918] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:16:16,919] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:16:21,974] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:16:26,828] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:16:32,435] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:16:37,408] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:16:42,886] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:16:48,001] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:16:52,772] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:16:57,657] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:17:02,460] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:17:07,035] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7530713524542882
[2022-12-07 06:17:07,035] [INFO] [runner_train_mujoco] Average state value: 0.6602800903916359
[2022-12-07 06:17:07,035] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 06:17:07,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01275, loss val: 0.03814
[2022-12-07 06:17:07,127] [INFO] [controller] EPOCH 2 loss ppo:  -0.01994, loss val: 0.03836
[2022-12-07 06:17:07,176] [INFO] [controller] EPOCH 3 loss ppo:  -0.02225, loss val: 0.04011
[2022-12-07 06:17:07,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.02846, loss val: 0.03933
[2022-12-07 06:17:07,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:17:07,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:17:07,469] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:17:12,515] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:17:17,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:17:23,028] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:17:28,055] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:17:33,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:17:38,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:17:43,779] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:17:48,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:17:53,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:17:58,976] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9077109288396548
[2022-12-07 06:17:58,976] [INFO] [runner_train_mujoco] Average state value: 0.6590045737822852
[2022-12-07 06:17:58,976] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 06:17:59,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.04101
[2022-12-07 06:17:59,077] [INFO] [controller] EPOCH 2 loss ppo:  -0.01723, loss val: 0.04280
[2022-12-07 06:17:59,130] [INFO] [controller] EPOCH 3 loss ppo:  -0.02171, loss val: 0.04333
[2022-12-07 06:17:59,180] [INFO] [controller] EPOCH 4 loss ppo:  -0.02292, loss val: 0.04254
[2022-12-07 06:17:59,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:17:59,353] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:17:59,353] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:18:04,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:18:09,549] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:18:14,675] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:18:19,859] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:18:24,349] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:18:29,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:18:34,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:18:39,269] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:18:44,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:18:49,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.866411818222244
[2022-12-07 06:18:49,912] [INFO] [runner_train_mujoco] Average state value: 0.6481668351093928
[2022-12-07 06:18:49,912] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 06:18:49,965] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04241
[2022-12-07 06:18:50,014] [INFO] [controller] EPOCH 2 loss ppo:  -0.02217, loss val: 0.04282
[2022-12-07 06:18:50,059] [INFO] [controller] EPOCH 3 loss ppo:  -0.02230, loss val: 0.04266
[2022-12-07 06:18:50,107] [INFO] [controller] EPOCH 4 loss ppo:  -0.02597, loss val: 0.04402
[2022-12-07 06:18:50,115] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:18:50,266] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:18:50,266] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:18:54,939] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:19:00,057] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:19:04,878] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:19:09,982] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:19:14,708] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:19:20,097] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:19:25,126] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:19:30,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:19:36,057] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:19:41,463] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.912863785200394
[2022-12-07 06:19:41,463] [INFO] [runner_train_mujoco] Average state value: 0.6484024756352106
[2022-12-07 06:19:41,464] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 06:19:41,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.04383
[2022-12-07 06:19:41,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.01547, loss val: 0.04285
[2022-12-07 06:19:41,616] [INFO] [controller] EPOCH 3 loss ppo:  -0.01835, loss val: 0.04354
[2022-12-07 06:19:41,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.02051, loss val: 0.04261
[2022-12-07 06:19:41,670] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:19:41,848] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:19:41,849] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:19:47,204] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:19:52,317] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:19:57,067] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:20:01,958] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:20:07,173] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:20:12,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:20:17,602] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:20:22,530] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:20:27,278] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:20:32,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0128958285867546
[2022-12-07 06:20:32,440] [INFO] [runner_train_mujoco] Average state value: 0.6580535848736763
[2022-12-07 06:20:32,441] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 06:20:32,504] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.03958
[2022-12-07 06:20:32,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.01936, loss val: 0.03969
[2022-12-07 06:20:32,592] [INFO] [controller] EPOCH 3 loss ppo:  -0.02163, loss val: 0.04257
[2022-12-07 06:20:32,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.02798, loss val: 0.04049
[2022-12-07 06:20:32,647] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:20:32,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:20:32,823] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:20:37,684] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:20:43,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:20:48,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:20:53,432] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:20:58,675] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:21:03,512] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:21:08,380] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:21:13,212] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:21:18,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:21:23,411] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9907660112067505
[2022-12-07 06:21:23,411] [INFO] [runner_train_mujoco] Average state value: 0.6625459913015366
[2022-12-07 06:21:23,411] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 06:21:23,469] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.04457
[2022-12-07 06:21:23,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01633, loss val: 0.04396
[2022-12-07 06:21:23,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.01850, loss val: 0.04610
[2022-12-07 06:21:23,599] [INFO] [controller] EPOCH 4 loss ppo:  -0.02401, loss val: 0.04690
[2022-12-07 06:21:23,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:21:23,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:21:23,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:21:29,127] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:21:34,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:21:39,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:21:45,362] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:21:50,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:21:55,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:22:00,185] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:22:05,112] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:22:10,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:22:15,532] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2419419865660055
[2022-12-07 06:22:15,532] [INFO] [runner_train_mujoco] Average state value: 0.65330631762743
[2022-12-07 06:22:15,532] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 06:22:15,586] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.04392
[2022-12-07 06:22:15,633] [INFO] [controller] EPOCH 2 loss ppo:  -0.01802, loss val: 0.04552
[2022-12-07 06:22:15,680] [INFO] [controller] EPOCH 3 loss ppo:  -0.01956, loss val: 0.04454
[2022-12-07 06:22:15,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.02161, loss val: 0.04473
[2022-12-07 06:22:15,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:22:15,907] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:22:15,907] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:22:21,253] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:22:26,653] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:22:31,690] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:22:36,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:22:41,652] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:22:46,950] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:22:52,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:22:57,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:23:02,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:23:07,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.124939467035402
[2022-12-07 06:23:07,109] [INFO] [runner_train_mujoco] Average state value: 0.6422272837956746
[2022-12-07 06:23:07,109] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 06:23:07,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04147
[2022-12-07 06:23:07,203] [INFO] [controller] EPOCH 2 loss ppo:  -0.01585, loss val: 0.04135
[2022-12-07 06:23:07,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.01821, loss val: 0.04277
[2022-12-07 06:23:07,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.02010, loss val: 0.04168
[2022-12-07 06:23:07,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:23:07,452] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:23:07,452] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:23:12,488] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:23:17,724] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:23:22,704] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:23:27,647] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:23:32,981] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:23:38,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:23:43,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:23:48,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:23:53,716] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:23:58,899] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.165669246027329
[2022-12-07 06:23:58,900] [INFO] [runner_train_mujoco] Average state value: 0.6344992565115293
[2022-12-07 06:23:58,900] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 06:23:58,952] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.04597
[2022-12-07 06:23:58,993] [INFO] [controller] EPOCH 2 loss ppo:  -0.01652, loss val: 0.04534
[2022-12-07 06:23:59,033] [INFO] [controller] EPOCH 3 loss ppo:  -0.02002, loss val: 0.04507
[2022-12-07 06:23:59,075] [INFO] [controller] EPOCH 4 loss ppo:  -0.02064, loss val: 0.04456
[2022-12-07 06:23:59,084] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:23:59,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:23:59,242] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:24:04,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:24:09,409] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:24:14,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:24:19,851] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:24:24,829] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:24:29,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:24:34,575] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:24:39,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:24:44,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:24:49,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2194097867955414
[2022-12-07 06:24:49,917] [INFO] [runner_train_mujoco] Average state value: 0.6373249848286311
[2022-12-07 06:24:49,917] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 06:24:49,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.04370
[2022-12-07 06:24:50,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.01651, loss val: 0.04391
[2022-12-07 06:24:50,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.02138, loss val: 0.04346
[2022-12-07 06:24:50,095] [INFO] [controller] EPOCH 4 loss ppo:  -0.02289, loss val: 0.04371
[2022-12-07 06:24:50,105] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:24:50,270] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:24:50,271] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:24:55,434] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:25:00,698] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:25:05,977] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:25:11,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:25:15,992] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:25:21,302] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:25:26,307] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:25:31,912] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:25:37,210] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:25:42,298] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.285913011758428
[2022-12-07 06:25:42,298] [INFO] [runner_train_mujoco] Average state value: 0.6496262343525887
[2022-12-07 06:25:42,298] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 06:25:42,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.04192
[2022-12-07 06:25:42,400] [INFO] [controller] EPOCH 2 loss ppo:  -0.01532, loss val: 0.04188
[2022-12-07 06:25:42,451] [INFO] [controller] EPOCH 3 loss ppo:  -0.01664, loss val: 0.04184
[2022-12-07 06:25:42,497] [INFO] [controller] EPOCH 4 loss ppo:  -0.01784, loss val: 0.04195
[2022-12-07 06:25:42,505] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:25:42,670] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:25:42,671] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:25:47,565] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:25:52,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:25:57,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:26:02,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:26:07,995] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:26:12,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:26:18,199] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:26:23,331] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:26:28,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:26:33,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.365235160503494
[2022-12-07 06:26:33,728] [INFO] [runner_train_mujoco] Average state value: 0.6559457739988963
[2022-12-07 06:26:33,728] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 06:26:33,801] [INFO] [controller] EPOCH 1 loss ppo:  -0.01170, loss val: 0.04426
[2022-12-07 06:26:33,851] [INFO] [controller] EPOCH 2 loss ppo:  -0.01352, loss val: 0.04314
[2022-12-07 06:26:33,898] [INFO] [controller] EPOCH 3 loss ppo:  -0.01555, loss val: 0.04323
[2022-12-07 06:26:33,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.01708, loss val: 0.04387
[2022-12-07 06:26:33,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:26:34,117] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:26:34,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:26:39,546] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:26:45,022] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:26:50,449] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:26:55,663] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:27:00,968] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:06,319] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:27:11,242] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:27:16,113] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:27:20,754] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:27:26,089] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3406592301258704
[2022-12-07 06:27:26,090] [INFO] [runner_train_mujoco] Average state value: 0.6573888427019119
[2022-12-07 06:27:26,090] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 06:27:26,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.01260, loss val: 0.04099
[2022-12-07 06:27:26,188] [INFO] [controller] EPOCH 2 loss ppo:  -0.01467, loss val: 0.04121
[2022-12-07 06:27:26,236] [INFO] [controller] EPOCH 3 loss ppo:  -0.01973, loss val: 0.04135
[2022-12-07 06:27:26,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.02420, loss val: 0.04179
[2022-12-07 06:27:26,290] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:27:26,457] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:27:26,458] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:27:31,300] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:27:36,643] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:27:41,762] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:27:46,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:27:51,711] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:57,066] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:28:02,344] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:28:07,301] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:28:12,596] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:28:17,574] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3092954882167804
[2022-12-07 06:28:17,575] [INFO] [runner_train_mujoco] Average state value: 0.6515040864149729
[2022-12-07 06:28:17,575] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 06:28:17,640] [INFO] [controller] EPOCH 1 loss ppo:  -0.01237, loss val: 0.04463
[2022-12-07 06:28:17,697] [INFO] [controller] EPOCH 2 loss ppo:  -0.01283, loss val: 0.04613
[2022-12-07 06:28:17,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.01519, loss val: 0.04444
[2022-12-07 06:28:17,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.01573, loss val: 0.04653
[2022-12-07 06:28:17,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:28:17,981] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:28:17,981] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:28:23,378] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:28:28,224] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:28:33,381] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:28:38,042] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:28:42,860] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:28:47,467] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:28:52,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:28:57,338] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:29:02,697] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:29:07,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3787715586480616
[2022-12-07 06:29:07,887] [INFO] [runner_train_mujoco] Average state value: 0.6511030788818996
[2022-12-07 06:29:07,887] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 06:29:07,941] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.03989
[2022-12-07 06:29:07,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.01341, loss val: 0.03991
[2022-12-07 06:29:08,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.01461, loss val: 0.03946
[2022-12-07 06:29:08,083] [INFO] [controller] EPOCH 4 loss ppo:  -0.01622, loss val: 0.04117
[2022-12-07 06:29:08,093] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:29:08,238] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:29:08,238] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:29:13,258] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:29:18,753] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:29:23,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:29:28,879] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:29:34,191] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:29:39,497] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:29:44,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:29:49,292] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:29:54,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:29:59,238] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4046946833534575
[2022-12-07 06:29:59,239] [INFO] [runner_train_mujoco] Average state value: 0.6500848074754079
[2022-12-07 06:29:59,239] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 06:29:59,300] [INFO] [controller] EPOCH 1 loss ppo:  -0.01258, loss val: 0.04284
[2022-12-07 06:29:59,351] [INFO] [controller] EPOCH 2 loss ppo:  -0.01306, loss val: 0.04237
[2022-12-07 06:29:59,400] [INFO] [controller] EPOCH 3 loss ppo:  -0.01396, loss val: 0.04140
[2022-12-07 06:29:59,449] [INFO] [controller] EPOCH 4 loss ppo:  -0.01526, loss val: 0.04234
[2022-12-07 06:29:59,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:29:59,592] [INFO] [optimize] Finished learning.
