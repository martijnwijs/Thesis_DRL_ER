[2022-12-07 12:27:51,852] [INFO] [optimize] Starting learning
[2022-12-07 12:27:51,857] [INFO] [optimize] Starting learning process..
[2022-12-07 12:27:51,913] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:27:51,913] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:27:58,157] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:28:03,069] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:28:08,316] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:28:13,386] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:28:18,380] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:28:23,146] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:28:27,915] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:28:32,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:28:38,048] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:28:42,871] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.11387534107808446
[2022-12-07 12:28:42,871] [INFO] [runner_train_mujoco] Average state value: 0.2503927147164941
[2022-12-07 12:28:42,871] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 12:28:42,940] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.24899
[2022-12-07 12:28:42,991] [INFO] [controller] EPOCH 2 loss ppo:  -0.02900, loss val: 0.20826
[2022-12-07 12:28:43,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.03186, loss val: 0.17275
[2022-12-07 12:28:43,090] [INFO] [controller] EPOCH 4 loss ppo:  -0.03583, loss val: 0.14704
[2022-12-07 12:28:43,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:28:43,267] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:28:43,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:28:48,197] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:28:53,281] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:28:58,127] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:29:03,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:29:08,088] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:29:12,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:29:17,842] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:29:22,832] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:29:27,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:29:32,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1604139467991239
[2022-12-07 12:29:32,345] [INFO] [runner_train_mujoco] Average state value: 0.4473170146364719
[2022-12-07 12:29:32,345] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 12:29:32,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.13953
[2022-12-07 12:29:32,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.02266, loss val: 0.12192
[2022-12-07 12:29:32,484] [INFO] [controller] EPOCH 3 loss ppo:  -0.02732, loss val: 0.10029
[2022-12-07 12:29:32,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.03342, loss val: 0.08950
[2022-12-07 12:29:32,538] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:29:32,682] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:29:32,682] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:29:37,747] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:29:42,822] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:29:48,257] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:29:53,207] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:29:58,339] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:30:03,303] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:30:08,388] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:30:13,351] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:30:18,468] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:30:23,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16388683454294517
[2022-12-07 12:30:23,273] [INFO] [runner_train_mujoco] Average state value: 0.5921619136376928
[2022-12-07 12:30:23,273] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 12:30:23,323] [INFO] [controller] EPOCH 1 loss ppo:  -0.01038, loss val: 0.07161
[2022-12-07 12:30:23,361] [INFO] [controller] EPOCH 2 loss ppo:  -0.01997, loss val: 0.06443
[2022-12-07 12:30:23,404] [INFO] [controller] EPOCH 3 loss ppo:  -0.02511, loss val: 0.06231
[2022-12-07 12:30:23,445] [INFO] [controller] EPOCH 4 loss ppo:  -0.02724, loss val: 0.05854
[2022-12-07 12:30:23,455] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:30:23,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:30:23,615] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:30:28,563] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:30:34,018] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:30:39,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:30:43,998] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:30:49,482] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:30:54,377] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:30:59,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:31:04,814] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:31:09,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:31:14,453] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.128098633362491
[2022-12-07 12:31:14,453] [INFO] [runner_train_mujoco] Average state value: 0.6882285385628542
[2022-12-07 12:31:14,453] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 12:31:14,504] [INFO] [controller] EPOCH 1 loss ppo:  -0.00835, loss val: 0.06361
[2022-12-07 12:31:14,546] [INFO] [controller] EPOCH 2 loss ppo:  -0.01980, loss val: 0.05888
[2022-12-07 12:31:14,583] [INFO] [controller] EPOCH 3 loss ppo:  -0.02345, loss val: 0.05505
[2022-12-07 12:31:14,626] [INFO] [controller] EPOCH 4 loss ppo:  -0.02723, loss val: 0.05366
[2022-12-07 12:31:14,636] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:31:14,902] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:31:14,902] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:31:19,924] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:31:25,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:31:30,056] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:31:35,024] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:31:40,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:31:46,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:31:51,100] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:31:56,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:32:01,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:32:06,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20359324975948354
[2022-12-07 12:32:06,341] [INFO] [runner_train_mujoco] Average state value: 0.749850260257721
[2022-12-07 12:32:06,341] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 12:32:06,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.00559, loss val: 0.04605
[2022-12-07 12:32:06,477] [INFO] [controller] EPOCH 2 loss ppo:  -0.01606, loss val: 0.04494
[2022-12-07 12:32:06,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.02266, loss val: 0.04435
[2022-12-07 12:32:06,565] [INFO] [controller] EPOCH 4 loss ppo:  -0.02646, loss val: 0.04395
[2022-12-07 12:32:06,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:32:06,735] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:32:06,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:32:12,070] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:32:17,408] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:32:23,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:32:28,281] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:32:33,444] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:32:38,505] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:32:43,604] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:32:49,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:32:54,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:32:59,655] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14023085651454087
[2022-12-07 12:32:59,655] [INFO] [runner_train_mujoco] Average state value: 0.775759483853976
[2022-12-07 12:32:59,655] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 12:32:59,702] [INFO] [controller] EPOCH 1 loss ppo:  -0.00542, loss val: 0.04628
[2022-12-07 12:32:59,742] [INFO] [controller] EPOCH 2 loss ppo:  -0.01679, loss val: 0.04692
[2022-12-07 12:32:59,786] [INFO] [controller] EPOCH 3 loss ppo:  -0.02135, loss val: 0.04551
[2022-12-07 12:32:59,832] [INFO] [controller] EPOCH 4 loss ppo:  -0.02479, loss val: 0.04559
[2022-12-07 12:32:59,842] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:33:00,104] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:33:00,104] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:33:05,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:33:10,802] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:33:15,809] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:33:21,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:33:26,016] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:33:31,245] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:33:36,437] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:33:41,406] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:33:47,049] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:33:52,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.185142830300576
[2022-12-07 12:33:52,109] [INFO] [runner_train_mujoco] Average state value: 0.7658782974481584
[2022-12-07 12:33:52,109] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 12:33:52,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.00592, loss val: 0.04164
[2022-12-07 12:33:52,193] [INFO] [controller] EPOCH 2 loss ppo:  -0.01657, loss val: 0.04139
[2022-12-07 12:33:52,240] [INFO] [controller] EPOCH 3 loss ppo:  -0.02326, loss val: 0.04194
[2022-12-07 12:33:52,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.02597, loss val: 0.04237
[2022-12-07 12:33:52,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:33:52,433] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:33:52,433] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:33:57,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:34:03,189] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:34:08,387] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:34:13,479] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:34:18,363] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:34:23,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:34:28,236] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:34:33,231] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:34:38,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:34:43,625] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2500855587663867
[2022-12-07 12:34:43,625] [INFO] [runner_train_mujoco] Average state value: 0.7739815570116043
[2022-12-07 12:34:43,625] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 12:34:43,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.00497, loss val: 0.04571
[2022-12-07 12:34:43,732] [INFO] [controller] EPOCH 2 loss ppo:  -0.01649, loss val: 0.04443
[2022-12-07 12:34:43,789] [INFO] [controller] EPOCH 3 loss ppo:  -0.02439, loss val: 0.04244
[2022-12-07 12:34:43,851] [INFO] [controller] EPOCH 4 loss ppo:  -0.02518, loss val: 0.04091
[2022-12-07 12:34:43,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:34:44,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:34:44,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:34:49,082] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:34:54,217] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:34:59,144] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:35:04,198] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:35:08,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:35:13,915] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:35:18,666] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:35:23,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:35:28,495] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:35:33,374] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2718478481465459
[2022-12-07 12:35:33,374] [INFO] [runner_train_mujoco] Average state value: 0.7141782040596009
[2022-12-07 12:35:33,374] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 12:35:33,421] [INFO] [controller] EPOCH 1 loss ppo:  -0.00708, loss val: 0.04513
[2022-12-07 12:35:33,455] [INFO] [controller] EPOCH 2 loss ppo:  -0.01880, loss val: 0.04595
[2022-12-07 12:35:33,495] [INFO] [controller] EPOCH 3 loss ppo:  -0.02076, loss val: 0.04522
[2022-12-07 12:35:33,533] [INFO] [controller] EPOCH 4 loss ppo:  -0.02771, loss val: 0.04522
[2022-12-07 12:35:33,542] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:35:33,669] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:35:33,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:35:38,833] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:35:43,931] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:35:48,629] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:35:53,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:35:58,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:36:03,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:36:08,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:36:13,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:36:18,544] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:36:23,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4256974539982675
[2022-12-07 12:36:23,914] [INFO] [runner_train_mujoco] Average state value: 0.6994316553473473
[2022-12-07 12:36:23,914] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 12:36:23,963] [INFO] [controller] EPOCH 1 loss ppo:  -0.00893, loss val: 0.04596
[2022-12-07 12:36:24,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.01738, loss val: 0.04353
[2022-12-07 12:36:24,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.02006, loss val: 0.04227
[2022-12-07 12:36:24,091] [INFO] [controller] EPOCH 4 loss ppo:  -0.02537, loss val: 0.04129
[2022-12-07 12:36:24,100] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:36:24,245] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:36:24,246] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:36:29,654] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:36:35,191] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:36:40,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:36:45,423] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:36:50,408] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:36:55,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:36:59,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:37:05,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:37:10,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:37:15,399] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39315774799746134
[2022-12-07 12:37:15,399] [INFO] [runner_train_mujoco] Average state value: 0.7680133480230966
[2022-12-07 12:37:15,399] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 12:37:15,451] [INFO] [controller] EPOCH 1 loss ppo:  -0.00653, loss val: 0.04530
[2022-12-07 12:37:15,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.01793, loss val: 0.04604
[2022-12-07 12:37:15,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.02324, loss val: 0.04616
[2022-12-07 12:37:15,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.02658, loss val: 0.04496
[2022-12-07 12:37:15,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:37:15,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:37:15,745] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:37:20,626] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:37:25,462] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:37:30,667] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:37:36,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:37:41,134] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:37:46,268] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:37:51,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:37:56,597] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:38:01,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:38:06,877] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.511041243932002
[2022-12-07 12:38:06,877] [INFO] [runner_train_mujoco] Average state value: 0.7647872351805368
[2022-12-07 12:38:06,878] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 12:38:06,927] [INFO] [controller] EPOCH 1 loss ppo:  -0.00801, loss val: 0.04173
[2022-12-07 12:38:06,970] [INFO] [controller] EPOCH 2 loss ppo:  -0.01441, loss val: 0.04200
[2022-12-07 12:38:07,010] [INFO] [controller] EPOCH 3 loss ppo:  -0.01969, loss val: 0.04054
[2022-12-07 12:38:07,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.02786, loss val: 0.04075
[2022-12-07 12:38:07,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:38:07,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:38:07,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:38:12,578] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:38:17,451] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:38:22,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:38:27,829] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:38:33,181] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:38:38,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:38:43,839] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:38:48,910] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:38:54,151] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:38:59,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5093913634239517
[2022-12-07 12:38:59,370] [INFO] [runner_train_mujoco] Average state value: 0.7271859892606735
[2022-12-07 12:38:59,371] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 12:38:59,425] [INFO] [controller] EPOCH 1 loss ppo:  -0.00619, loss val: 0.03733
[2022-12-07 12:38:59,471] [INFO] [controller] EPOCH 2 loss ppo:  -0.02223, loss val: 0.03798
[2022-12-07 12:38:59,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.02838, loss val: 0.03783
[2022-12-07 12:38:59,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.03324, loss val: 0.03874
[2022-12-07 12:38:59,574] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:38:59,758] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:38:59,758] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:39:05,223] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:39:10,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:39:16,116] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:39:21,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:39:26,874] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:39:32,256] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:39:37,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:39:42,680] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:39:47,962] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:39:53,161] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6507621249027302
[2022-12-07 12:39:53,161] [INFO] [runner_train_mujoco] Average state value: 0.691993287007014
[2022-12-07 12:39:53,161] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 12:39:53,212] [INFO] [controller] EPOCH 1 loss ppo:  -0.00910, loss val: 0.04189
[2022-12-07 12:39:53,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.01961, loss val: 0.04237
[2022-12-07 12:39:53,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.02427, loss val: 0.04230
[2022-12-07 12:39:53,334] [INFO] [controller] EPOCH 4 loss ppo:  -0.02910, loss val: 0.04088
[2022-12-07 12:39:53,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:39:53,525] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:39:53,526] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:39:58,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:40:04,087] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:40:09,178] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:40:14,210] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:40:18,903] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:40:23,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:40:28,958] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:40:34,295] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:40:39,044] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:40:44,043] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7670945574870813
[2022-12-07 12:40:44,043] [INFO] [runner_train_mujoco] Average state value: 0.7075323840181034
[2022-12-07 12:40:44,043] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 12:40:44,097] [INFO] [controller] EPOCH 1 loss ppo:  -0.00803, loss val: 0.04434
[2022-12-07 12:40:44,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.01931, loss val: 0.04518
[2022-12-07 12:40:44,185] [INFO] [controller] EPOCH 3 loss ppo:  -0.02264, loss val: 0.04455
[2022-12-07 12:40:44,231] [INFO] [controller] EPOCH 4 loss ppo:  -0.02830, loss val: 0.04589
[2022-12-07 12:40:44,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:40:44,422] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:40:44,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:40:49,667] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:40:55,052] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:41:00,493] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:41:05,843] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:41:11,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:41:16,540] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:41:21,791] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:41:27,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:41:32,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:41:37,423] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6413707084748729
[2022-12-07 12:41:37,423] [INFO] [runner_train_mujoco] Average state value: 0.7397173744837444
[2022-12-07 12:41:37,423] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 12:41:37,500] [INFO] [controller] EPOCH 1 loss ppo:  -0.00862, loss val: 0.04347
[2022-12-07 12:41:37,557] [INFO] [controller] EPOCH 2 loss ppo:  -0.01726, loss val: 0.04383
[2022-12-07 12:41:37,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.02317, loss val: 0.04418
[2022-12-07 12:41:37,679] [INFO] [controller] EPOCH 4 loss ppo:  -0.02760, loss val: 0.04370
[2022-12-07 12:41:37,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:41:37,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:41:37,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:41:43,750] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:41:48,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:41:54,316] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:41:59,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:42:04,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:42:09,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:42:14,766] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:42:20,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:42:25,331] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:42:30,547] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8133288564883948
[2022-12-07 12:42:30,547] [INFO] [runner_train_mujoco] Average state value: 0.7253816977739334
[2022-12-07 12:42:30,547] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 12:42:30,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.00688, loss val: 0.04476
[2022-12-07 12:42:30,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.02001, loss val: 0.04477
[2022-12-07 12:42:30,682] [INFO] [controller] EPOCH 3 loss ppo:  -0.02856, loss val: 0.04420
[2022-12-07 12:42:30,728] [INFO] [controller] EPOCH 4 loss ppo:  -0.03514, loss val: 0.04473
[2022-12-07 12:42:30,735] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:42:30,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:42:30,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:42:36,550] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:42:42,719] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:42:49,494] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:42:56,520] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:43:01,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:43:07,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:43:12,294] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:43:17,514] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:43:24,495] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:43:30,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.977200731293047
[2022-12-07 12:43:30,445] [INFO] [runner_train_mujoco] Average state value: 0.7070062002539634
[2022-12-07 12:43:30,445] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 12:43:30,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01043, loss val: 0.04342
[2022-12-07 12:43:30,540] [INFO] [controller] EPOCH 2 loss ppo:  -0.02194, loss val: 0.04334
[2022-12-07 12:43:30,589] [INFO] [controller] EPOCH 3 loss ppo:  -0.02589, loss val: 0.04395
[2022-12-07 12:43:30,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.03266, loss val: 0.04334
[2022-12-07 12:43:30,655] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:43:30,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:43:30,835] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:43:36,214] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:43:41,719] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:43:47,636] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:43:53,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:43:58,551] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:44:03,723] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:44:09,603] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:44:15,126] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:44:20,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:44:25,766] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1372704740260215
[2022-12-07 12:44:25,766] [INFO] [runner_train_mujoco] Average state value: 0.721428452014923
[2022-12-07 12:44:25,766] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 12:44:25,816] [INFO] [controller] EPOCH 1 loss ppo:  -0.01153, loss val: 0.04406
[2022-12-07 12:44:25,862] [INFO] [controller] EPOCH 2 loss ppo:  -0.02103, loss val: 0.04320
[2022-12-07 12:44:25,905] [INFO] [controller] EPOCH 3 loss ppo:  -0.02797, loss val: 0.04439
[2022-12-07 12:44:25,952] [INFO] [controller] EPOCH 4 loss ppo:  -0.03190, loss val: 0.04295
[2022-12-07 12:44:25,963] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:44:26,139] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:44:26,139] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:44:31,531] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:44:37,062] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:44:42,457] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:44:48,043] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:44:53,389] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:44:59,035] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:45:04,883] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:45:10,980] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:45:16,694] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:45:23,071] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1356601179560786
[2022-12-07 12:45:23,072] [INFO] [runner_train_mujoco] Average state value: 0.7374851119120915
[2022-12-07 12:45:23,072] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 12:45:23,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01001, loss val: 0.04132
[2022-12-07 12:45:23,188] [INFO] [controller] EPOCH 2 loss ppo:  -0.01433, loss val: 0.04135
[2022-12-07 12:45:23,238] [INFO] [controller] EPOCH 3 loss ppo:  -0.02002, loss val: 0.04216
[2022-12-07 12:45:23,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.02805, loss val: 0.04034
[2022-12-07 12:45:23,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:45:23,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:45:23,491] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:45:30,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:45:36,865] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:45:43,471] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:45:49,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:45:56,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:46:04,742] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:46:12,240] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:46:18,728] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:46:25,409] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:46:31,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1451591960113088
[2022-12-07 12:46:31,979] [INFO] [runner_train_mujoco] Average state value: 0.7315571935971578
[2022-12-07 12:46:31,980] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 12:46:32,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.00805, loss val: 0.03900
[2022-12-07 12:46:32,099] [INFO] [controller] EPOCH 2 loss ppo:  -0.01806, loss val: 0.04004
[2022-12-07 12:46:32,151] [INFO] [controller] EPOCH 3 loss ppo:  -0.02233, loss val: 0.03901
[2022-12-07 12:46:32,206] [INFO] [controller] EPOCH 4 loss ppo:  -0.03117, loss val: 0.03906
[2022-12-07 12:46:32,219] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:46:32,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:46:32,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:46:38,943] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:46:46,015] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:46:53,147] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:47:00,330] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:47:07,352] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:47:13,847] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:47:20,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:47:26,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:47:33,536] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:47:39,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1680255473239611
[2022-12-07 12:47:39,272] [INFO] [runner_train_mujoco] Average state value: 0.7310622090498606
[2022-12-07 12:47:39,272] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 12:47:39,332] [INFO] [controller] EPOCH 1 loss ppo:  -0.00947, loss val: 0.04559
[2022-12-07 12:47:39,380] [INFO] [controller] EPOCH 2 loss ppo:  -0.02101, loss val: 0.04567
[2022-12-07 12:47:39,430] [INFO] [controller] EPOCH 3 loss ppo:  -0.02597, loss val: 0.04539
[2022-12-07 12:47:39,480] [INFO] [controller] EPOCH 4 loss ppo:  -0.03260, loss val: 0.04574
[2022-12-07 12:47:39,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:47:39,684] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:47:39,684] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:47:45,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:47:52,635] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:47:58,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:48:04,824] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:48:11,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:48:17,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:48:24,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:48:30,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:48:36,980] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:48:42,844] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3628958407686038
[2022-12-07 12:48:42,844] [INFO] [runner_train_mujoco] Average state value: 0.7171517482995986
[2022-12-07 12:48:42,844] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 12:48:42,898] [INFO] [controller] EPOCH 1 loss ppo:  -0.00875, loss val: 0.04352
[2022-12-07 12:48:43,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.01536, loss val: 0.04381
[2022-12-07 12:48:43,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.02116, loss val: 0.04345
[2022-12-07 12:48:43,114] [INFO] [controller] EPOCH 4 loss ppo:  -0.02648, loss val: 0.04283
[2022-12-07 12:48:43,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:48:43,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:48:43,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:48:49,392] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:48:55,423] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:49:01,127] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:49:07,446] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:49:13,265] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:49:18,686] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:49:24,001] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:49:29,473] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:49:35,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:49:41,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3511131891502122
[2022-12-07 12:49:41,150] [INFO] [runner_train_mujoco] Average state value: 0.7439353408813476
[2022-12-07 12:49:41,150] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 12:49:41,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.04293
[2022-12-07 12:49:41,252] [INFO] [controller] EPOCH 2 loss ppo:  -0.02061, loss val: 0.04318
[2022-12-07 12:49:41,297] [INFO] [controller] EPOCH 3 loss ppo:  -0.02671, loss val: 0.04316
[2022-12-07 12:49:41,399] [INFO] [controller] EPOCH 4 loss ppo:  -0.03061, loss val: 0.04333
[2022-12-07 12:49:41,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:49:41,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:49:41,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:49:47,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:49:53,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:49:58,487] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:50:04,137] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:50:09,645] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:50:15,350] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:50:20,829] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:50:26,263] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:50:31,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:50:37,402] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.322528417044781
[2022-12-07 12:50:37,402] [INFO] [runner_train_mujoco] Average state value: 0.7563794220685958
[2022-12-07 12:50:37,402] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 12:50:37,455] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.04003
[2022-12-07 12:50:37,503] [INFO] [controller] EPOCH 2 loss ppo:  -0.02025, loss val: 0.03960
[2022-12-07 12:50:37,544] [INFO] [controller] EPOCH 3 loss ppo:  -0.02514, loss val: 0.03929
[2022-12-07 12:50:37,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.03189, loss val: 0.03925
[2022-12-07 12:50:37,599] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:50:37,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:50:37,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:50:43,853] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:50:49,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:50:55,509] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:51:01,517] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:51:07,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:51:12,718] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:51:18,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:51:24,073] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:51:29,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:51:34,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3297378854775137
[2022-12-07 12:51:34,530] [INFO] [runner_train_mujoco] Average state value: 0.7406583048105241
[2022-12-07 12:51:34,530] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 12:51:34,587] [INFO] [controller] EPOCH 1 loss ppo:  -0.01077, loss val: 0.04195
[2022-12-07 12:51:34,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.01616, loss val: 0.04189
[2022-12-07 12:51:34,701] [INFO] [controller] EPOCH 3 loss ppo:  -0.01733, loss val: 0.04193
[2022-12-07 12:51:34,751] [INFO] [controller] EPOCH 4 loss ppo:  -0.02277, loss val: 0.04180
[2022-12-07 12:51:34,761] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:51:34,945] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:51:34,945] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:51:40,491] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:51:46,143] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:51:51,555] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:51:56,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:52:02,166] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:52:07,445] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:52:13,082] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:52:18,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:52:23,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:52:28,678] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.253493120238049
[2022-12-07 12:52:28,678] [INFO] [runner_train_mujoco] Average state value: 0.7279583420753479
[2022-12-07 12:52:28,678] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 12:52:28,726] [INFO] [controller] EPOCH 1 loss ppo:  -0.00973, loss val: 0.04083
[2022-12-07 12:52:28,766] [INFO] [controller] EPOCH 2 loss ppo:  -0.01816, loss val: 0.04043
[2022-12-07 12:52:28,815] [INFO] [controller] EPOCH 3 loss ppo:  -0.02314, loss val: 0.03982
[2022-12-07 12:52:28,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.03043, loss val: 0.03987
[2022-12-07 12:52:28,873] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:52:29,034] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:52:29,034] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:52:34,392] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:52:39,943] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:52:45,369] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:52:50,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:52:55,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:53:00,763] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:53:05,729] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:53:10,717] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:53:15,718] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:53:20,360] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4128563216025851
[2022-12-07 12:53:20,361] [INFO] [runner_train_mujoco] Average state value: 0.7171799717744192
[2022-12-07 12:53:20,361] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 12:53:20,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01027, loss val: 0.03997
[2022-12-07 12:53:20,449] [INFO] [controller] EPOCH 2 loss ppo:  -0.01676, loss val: 0.04009
[2022-12-07 12:53:20,491] [INFO] [controller] EPOCH 3 loss ppo:  -0.02208, loss val: 0.04002
[2022-12-07 12:53:20,532] [INFO] [controller] EPOCH 4 loss ppo:  -0.02946, loss val: 0.03986
[2022-12-07 12:53:20,541] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:53:20,697] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:53:20,697] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:53:25,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:53:31,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:53:35,932] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:53:40,902] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:53:45,838] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:53:50,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:53:55,388] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:54:00,494] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:54:05,417] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:54:10,466] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4774928805567138
[2022-12-07 12:54:10,466] [INFO] [runner_train_mujoco] Average state value: 0.7200308338006337
[2022-12-07 12:54:10,466] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 12:54:10,515] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.04052
[2022-12-07 12:54:10,555] [INFO] [controller] EPOCH 2 loss ppo:  -0.02067, loss val: 0.03915
[2022-12-07 12:54:10,596] [INFO] [controller] EPOCH 3 loss ppo:  -0.02492, loss val: 0.03987
[2022-12-07 12:54:10,635] [INFO] [controller] EPOCH 4 loss ppo:  -0.03230, loss val: 0.03862
[2022-12-07 12:54:10,644] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:54:10,797] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:54:10,797] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:54:15,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:54:20,819] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:54:25,610] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:54:30,592] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:54:35,788] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:54:41,015] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:54:45,944] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:54:50,673] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:54:55,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:55:00,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5562430591083056
[2022-12-07 12:55:00,389] [INFO] [runner_train_mujoco] Average state value: 0.711254037896792
[2022-12-07 12:55:00,389] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 12:55:00,441] [INFO] [controller] EPOCH 1 loss ppo:  -0.01215, loss val: 0.04129
[2022-12-07 12:55:00,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.02068, loss val: 0.04186
[2022-12-07 12:55:00,524] [INFO] [controller] EPOCH 3 loss ppo:  -0.02327, loss val: 0.04156
[2022-12-07 12:55:00,565] [INFO] [controller] EPOCH 4 loss ppo:  -0.03004, loss val: 0.04128
[2022-12-07 12:55:00,573] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:55:00,742] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:55:00,742] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:55:05,740] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:55:10,624] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:55:16,037] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:55:20,795] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:55:25,820] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:55:30,700] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:55:36,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:55:41,106] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:55:46,502] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:55:51,296] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.56807933212935
[2022-12-07 12:55:51,296] [INFO] [runner_train_mujoco] Average state value: 0.71947270154953
[2022-12-07 12:55:51,297] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 12:55:51,347] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.04259
[2022-12-07 12:55:51,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.01936, loss val: 0.04296
[2022-12-07 12:55:51,430] [INFO] [controller] EPOCH 3 loss ppo:  -0.02135, loss val: 0.04266
[2022-12-07 12:55:51,477] [INFO] [controller] EPOCH 4 loss ppo:  -0.02903, loss val: 0.04263
[2022-12-07 12:55:51,487] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:55:51,644] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:55:51,645] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:55:56,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:56:01,957] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:56:06,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:56:11,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:56:16,806] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:56:21,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:56:26,480] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:56:31,858] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:56:37,475] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:56:42,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5907523637816752
[2022-12-07 12:56:42,572] [INFO] [runner_train_mujoco] Average state value: 0.7315926480690638
[2022-12-07 12:56:42,572] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 12:56:42,621] [INFO] [controller] EPOCH 1 loss ppo:  -0.01040, loss val: 0.03974
[2022-12-07 12:56:42,660] [INFO] [controller] EPOCH 2 loss ppo:  -0.01986, loss val: 0.03976
[2022-12-07 12:56:42,702] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.04064
[2022-12-07 12:56:42,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.03235, loss val: 0.03998
[2022-12-07 12:56:42,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:56:42,943] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:56:42,943] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:56:48,202] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:56:53,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:56:58,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:57:03,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:57:08,922] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:57:13,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:57:18,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:57:23,970] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:57:28,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:57:34,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7245276307024056
[2022-12-07 12:57:34,275] [INFO] [runner_train_mujoco] Average state value: 0.7279863189458846
[2022-12-07 12:57:34,275] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 12:57:34,327] [INFO] [controller] EPOCH 1 loss ppo:  -0.01079, loss val: 0.04340
[2022-12-07 12:57:34,376] [INFO] [controller] EPOCH 2 loss ppo:  -0.01813, loss val: 0.04331
[2022-12-07 12:57:34,422] [INFO] [controller] EPOCH 3 loss ppo:  -0.02585, loss val: 0.04355
[2022-12-07 12:57:34,473] [INFO] [controller] EPOCH 4 loss ppo:  -0.03209, loss val: 0.04336
[2022-12-07 12:57:34,484] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:57:34,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:57:34,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:57:40,180] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:57:45,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:57:50,569] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:57:55,758] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:58:01,018] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:58:06,293] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:58:11,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:58:17,153] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:58:22,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:58:27,710] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6011705762673203
[2022-12-07 12:58:27,710] [INFO] [runner_train_mujoco] Average state value: 0.736399648586909
[2022-12-07 12:58:27,710] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 12:58:27,762] [INFO] [controller] EPOCH 1 loss ppo:  -0.01117, loss val: 0.03933
[2022-12-07 12:58:27,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.01731, loss val: 0.03876
[2022-12-07 12:58:27,850] [INFO] [controller] EPOCH 3 loss ppo:  -0.02276, loss val: 0.03979
[2022-12-07 12:58:27,894] [INFO] [controller] EPOCH 4 loss ppo:  -0.02754, loss val: 0.03936
[2022-12-07 12:58:27,908] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:58:28,089] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:58:28,090] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:58:33,985] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:58:39,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:58:44,583] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:58:49,620] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:58:54,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:58:59,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:59:04,332] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:59:09,501] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:59:14,567] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:59:19,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6497314225537938
[2022-12-07 12:59:19,619] [INFO] [runner_train_mujoco] Average state value: 0.7367354526122412
[2022-12-07 12:59:19,619] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 12:59:19,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.04292
[2022-12-07 12:59:19,711] [INFO] [controller] EPOCH 2 loss ppo:  -0.02145, loss val: 0.04355
[2022-12-07 12:59:19,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.02427, loss val: 0.04291
[2022-12-07 12:59:19,793] [INFO] [controller] EPOCH 4 loss ppo:  -0.02987, loss val: 0.04307
[2022-12-07 12:59:19,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:59:19,969] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:59:19,969] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:59:25,712] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:59:31,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:59:36,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:59:41,452] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:59:46,232] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:59:51,115] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:59:55,820] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:00:00,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:00:05,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:00:10,582] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7212547648777516
[2022-12-07 13:00:10,582] [INFO] [runner_train_mujoco] Average state value: 0.7330103156169255
[2022-12-07 13:00:10,582] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 13:00:10,632] [INFO] [controller] EPOCH 1 loss ppo:  -0.01065, loss val: 0.04154
[2022-12-07 13:00:10,670] [INFO] [controller] EPOCH 2 loss ppo:  -0.01792, loss val: 0.04187
[2022-12-07 13:00:10,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.02145, loss val: 0.04173
[2022-12-07 13:00:10,751] [INFO] [controller] EPOCH 4 loss ppo:  -0.02932, loss val: 0.04114
[2022-12-07 13:00:10,761] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:00:10,924] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:00:10,925] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:00:15,927] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:00:21,034] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:00:25,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:00:31,012] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:00:36,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:00:41,404] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:00:46,804] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:00:51,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:00:56,551] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:01:01,240] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6989851419550313
[2022-12-07 13:01:01,240] [INFO] [runner_train_mujoco] Average state value: 0.7340312703053157
[2022-12-07 13:01:01,241] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 13:01:01,291] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.04069
[2022-12-07 13:01:01,336] [INFO] [controller] EPOCH 2 loss ppo:  -0.02139, loss val: 0.04094
[2022-12-07 13:01:01,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.02391, loss val: 0.04168
[2022-12-07 13:01:01,422] [INFO] [controller] EPOCH 4 loss ppo:  -0.02813, loss val: 0.04201
[2022-12-07 13:01:01,431] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:01:01,585] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:01:01,586] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:01:06,735] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:01:11,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:01:16,359] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:01:21,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:01:26,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:01:31,339] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:01:36,060] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:01:41,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:01:46,162] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:01:51,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6977484463461767
[2022-12-07 13:01:51,368] [INFO] [runner_train_mujoco] Average state value: 0.7431816938320795
[2022-12-07 13:01:51,368] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 13:01:51,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.04025
[2022-12-07 13:01:51,454] [INFO] [controller] EPOCH 2 loss ppo:  -0.02366, loss val: 0.04033
[2022-12-07 13:01:51,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.02938, loss val: 0.04020
[2022-12-07 13:01:51,536] [INFO] [controller] EPOCH 4 loss ppo:  -0.03093, loss val: 0.03976
[2022-12-07 13:01:51,546] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:01:51,687] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:01:51,687] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:01:56,797] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:02:01,454] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:02:06,940] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:02:11,721] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:02:16,551] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:02:21,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:02:26,524] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:02:31,172] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:02:35,894] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:02:40,559] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.877547187089501
[2022-12-07 13:02:40,559] [INFO] [runner_train_mujoco] Average state value: 0.730680613597234
[2022-12-07 13:02:40,560] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 13:02:40,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04172
[2022-12-07 13:02:40,653] [INFO] [controller] EPOCH 2 loss ppo:  -0.02439, loss val: 0.04092
[2022-12-07 13:02:40,698] [INFO] [controller] EPOCH 3 loss ppo:  -0.02696, loss val: 0.04021
[2022-12-07 13:02:40,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.03160, loss val: 0.04137
[2022-12-07 13:02:40,750] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:02:40,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:02:40,905] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:02:45,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:02:50,857] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:02:55,581] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:03:00,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:03:05,731] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:03:10,877] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:03:15,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:03:21,187] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:03:26,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:03:31,487] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7489987217453689
[2022-12-07 13:03:31,488] [INFO] [runner_train_mujoco] Average state value: 0.7103732165495555
[2022-12-07 13:03:31,488] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 13:03:31,536] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.04230
[2022-12-07 13:03:31,576] [INFO] [controller] EPOCH 2 loss ppo:  -0.01903, loss val: 0.04313
[2022-12-07 13:03:31,611] [INFO] [controller] EPOCH 3 loss ppo:  -0.02193, loss val: 0.04204
[2022-12-07 13:03:31,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.02611, loss val: 0.04216
[2022-12-07 13:03:31,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:03:31,840] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:03:31,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:03:37,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:03:42,078] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:03:46,716] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:03:51,476] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:03:56,327] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:04:01,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:04:05,940] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:04:10,765] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:04:16,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:04:21,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8690522090449189
[2022-12-07 13:04:21,728] [INFO] [runner_train_mujoco] Average state value: 0.7168517207304637
[2022-12-07 13:04:21,728] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 13:04:21,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04214
[2022-12-07 13:04:21,821] [INFO] [controller] EPOCH 2 loss ppo:  -0.01787, loss val: 0.04224
[2022-12-07 13:04:21,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.02581, loss val: 0.04186
[2022-12-07 13:04:21,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.03270, loss val: 0.04260
[2022-12-07 13:04:21,921] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:04:22,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:04:22,109] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:04:27,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:04:32,735] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:04:37,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:04:43,465] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:04:48,573] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:04:53,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:04:58,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:05:03,323] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:05:08,540] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:05:13,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8255739124934998
[2022-12-07 13:05:13,892] [INFO] [runner_train_mujoco] Average state value: 0.7339839587608973
[2022-12-07 13:05:13,892] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 13:05:13,953] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.04267
[2022-12-07 13:05:14,002] [INFO] [controller] EPOCH 2 loss ppo:  -0.01877, loss val: 0.04153
[2022-12-07 13:05:14,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.01937, loss val: 0.04148
[2022-12-07 13:05:14,096] [INFO] [controller] EPOCH 4 loss ppo:  -0.02420, loss val: 0.04061
[2022-12-07 13:05:14,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:05:14,383] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:05:14,383] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:05:19,933] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:05:25,421] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:05:31,121] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:05:36,218] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:05:41,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:05:46,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:05:51,350] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:05:56,615] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:06:02,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:06:07,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8863370549276852
[2022-12-07 13:06:07,550] [INFO] [runner_train_mujoco] Average state value: 0.7303397274812063
[2022-12-07 13:06:07,550] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 13:06:07,608] [INFO] [controller] EPOCH 1 loss ppo:  -0.01134, loss val: 0.04107
[2022-12-07 13:06:07,652] [INFO] [controller] EPOCH 2 loss ppo:  -0.02031, loss val: 0.03960
[2022-12-07 13:06:07,704] [INFO] [controller] EPOCH 3 loss ppo:  -0.03032, loss val: 0.03960
[2022-12-07 13:06:07,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.03357, loss val: 0.03957
[2022-12-07 13:06:07,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:06:07,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:06:07,952] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:06:13,292] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:06:18,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:06:24,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:06:28,902] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:06:33,979] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:06:38,868] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:06:44,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:06:49,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:06:54,574] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:06:59,425] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9675846602328506
[2022-12-07 13:06:59,425] [INFO] [runner_train_mujoco] Average state value: 0.7195863075256347
[2022-12-07 13:06:59,425] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 13:06:59,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04068
[2022-12-07 13:06:59,516] [INFO] [controller] EPOCH 2 loss ppo:  -0.02171, loss val: 0.03973
[2022-12-07 13:06:59,560] [INFO] [controller] EPOCH 3 loss ppo:  -0.02400, loss val: 0.04152
[2022-12-07 13:06:59,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.02599, loss val: 0.04024
[2022-12-07 13:06:59,610] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:06:59,786] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:06:59,786] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:07:05,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:07:12,055] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:07:18,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:07:24,456] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:07:29,504] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:07:34,750] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:07:39,685] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:07:44,625] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:07:49,461] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:07:54,243] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9753533675490567
[2022-12-07 13:07:54,243] [INFO] [runner_train_mujoco] Average state value: 0.716561877687772
[2022-12-07 13:07:54,243] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 13:07:54,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01207, loss val: 0.04489
[2022-12-07 13:07:54,339] [INFO] [controller] EPOCH 2 loss ppo:  -0.01580, loss val: 0.04494
[2022-12-07 13:07:54,385] [INFO] [controller] EPOCH 3 loss ppo:  -0.01948, loss val: 0.04500
[2022-12-07 13:07:54,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.02443, loss val: 0.04501
[2022-12-07 13:07:54,453] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:07:54,627] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:07:54,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:07:59,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:08:05,224] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:08:10,147] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:08:15,351] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:08:20,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:08:25,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:08:29,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:08:34,468] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:08:39,106] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:08:44,249] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0616636246015507
[2022-12-07 13:08:44,249] [INFO] [runner_train_mujoco] Average state value: 0.7244438529809316
[2022-12-07 13:08:44,249] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 13:08:44,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04182
[2022-12-07 13:08:44,340] [INFO] [controller] EPOCH 2 loss ppo:  -0.01800, loss val: 0.04116
[2022-12-07 13:08:44,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.02240, loss val: 0.04130
[2022-12-07 13:08:44,426] [INFO] [controller] EPOCH 4 loss ppo:  -0.02698, loss val: 0.04199
[2022-12-07 13:08:44,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:08:44,602] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:08:44,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:08:49,933] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:08:54,695] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:08:59,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:09:04,206] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:09:09,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:09:14,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:09:19,326] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:09:24,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:09:28,941] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:09:34,003] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0183220620332913
[2022-12-07 13:09:34,003] [INFO] [runner_train_mujoco] Average state value: 0.7354392773310343
[2022-12-07 13:09:34,003] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 13:09:34,055] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.04036
[2022-12-07 13:09:34,101] [INFO] [controller] EPOCH 2 loss ppo:  -0.01996, loss val: 0.04012
[2022-12-07 13:09:34,146] [INFO] [controller] EPOCH 3 loss ppo:  -0.02252, loss val: 0.04046
[2022-12-07 13:09:34,193] [INFO] [controller] EPOCH 4 loss ppo:  -0.02527, loss val: 0.04115
[2022-12-07 13:09:34,204] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:09:34,385] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:09:34,386] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:09:39,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:09:44,198] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:09:48,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:09:53,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:09:58,558] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:10:03,718] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:10:08,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:10:13,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:10:18,418] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:10:23,512] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0276259824637357
[2022-12-07 13:10:23,512] [INFO] [runner_train_mujoco] Average state value: 0.7412673221826555
[2022-12-07 13:10:23,512] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 13:10:23,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01232, loss val: 0.04273
[2022-12-07 13:10:23,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.01596, loss val: 0.04277
[2022-12-07 13:10:23,663] [INFO] [controller] EPOCH 3 loss ppo:  -0.02049, loss val: 0.04331
[2022-12-07 13:10:23,708] [INFO] [controller] EPOCH 4 loss ppo:  -0.02421, loss val: 0.04289
[2022-12-07 13:10:23,719] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:10:23,867] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:10:23,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:10:29,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:10:33,960] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:10:38,985] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:10:43,652] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:10:48,312] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:10:52,966] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:10:57,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:11:03,180] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:11:08,214] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:11:13,436] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9529665215540224
[2022-12-07 13:11:13,436] [INFO] [runner_train_mujoco] Average state value: 0.7390641276439031
[2022-12-07 13:11:13,436] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 13:11:13,511] [INFO] [controller] EPOCH 1 loss ppo:  -0.01131, loss val: 0.04308
[2022-12-07 13:11:13,556] [INFO] [controller] EPOCH 2 loss ppo:  -0.01416, loss val: 0.04307
[2022-12-07 13:11:13,604] [INFO] [controller] EPOCH 3 loss ppo:  -0.02000, loss val: 0.04259
[2022-12-07 13:11:13,659] [INFO] [controller] EPOCH 4 loss ppo:  -0.02562, loss val: 0.04196
[2022-12-07 13:11:13,670] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:11:13,847] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:11:13,847] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:11:19,115] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:11:24,501] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:11:29,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:11:34,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:11:39,993] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:11:44,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:11:49,550] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:11:54,437] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:11:59,955] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:12:05,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0023747946451698
[2022-12-07 13:12:05,191] [INFO] [runner_train_mujoco] Average state value: 0.7240248840252559
[2022-12-07 13:12:05,191] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 13:12:05,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.01239, loss val: 0.04132
[2022-12-07 13:12:05,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.01634, loss val: 0.03967
[2022-12-07 13:12:05,340] [INFO] [controller] EPOCH 3 loss ppo:  -0.02328, loss val: 0.03950
[2022-12-07 13:12:05,390] [INFO] [controller] EPOCH 4 loss ppo:  -0.02720, loss val: 0.04063
[2022-12-07 13:12:05,397] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:12:05,588] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:12:05,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:12:11,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:12:16,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:12:21,249] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:12:26,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:12:32,491] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:12:37,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:12:42,814] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:12:48,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:12:52,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:12:57,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.14261953835312
[2022-12-07 13:12:57,542] [INFO] [runner_train_mujoco] Average state value: 0.698675479054451
[2022-12-07 13:12:57,542] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 13:12:57,587] [INFO] [controller] EPOCH 1 loss ppo:  -0.01217, loss val: 0.04013
[2022-12-07 13:12:57,625] [INFO] [controller] EPOCH 2 loss ppo:  -0.01505, loss val: 0.03969
[2022-12-07 13:12:57,674] [INFO] [controller] EPOCH 3 loss ppo:  -0.01957, loss val: 0.03972
[2022-12-07 13:12:57,716] [INFO] [controller] EPOCH 4 loss ppo:  -0.02360, loss val: 0.04007
[2022-12-07 13:12:57,726] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:12:57,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:12:57,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:13:02,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:13:07,687] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:13:12,443] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:13:17,040] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:13:21,553] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:13:26,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:13:30,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:13:35,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:13:39,957] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:13:44,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.104554394987588
[2022-12-07 13:13:44,392] [INFO] [runner_train_mujoco] Average state value: 0.6979751300414404
[2022-12-07 13:13:44,392] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 13:13:44,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01190, loss val: 0.04648
[2022-12-07 13:13:44,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.01453, loss val: 0.04641
[2022-12-07 13:13:44,535] [INFO] [controller] EPOCH 3 loss ppo:  -0.01794, loss val: 0.04593
[2022-12-07 13:13:44,579] [INFO] [controller] EPOCH 4 loss ppo:  -0.02032, loss val: 0.04517
[2022-12-07 13:13:44,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:13:44,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:13:44,734] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:13:49,387] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:13:54,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:13:59,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:14:03,198] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:14:07,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:14:11,387] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:14:15,392] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:14:19,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:14:23,278] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:14:27,224] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.146550687129387
[2022-12-07 13:14:27,224] [INFO] [runner_train_mujoco] Average state value: 0.717985569079717
[2022-12-07 13:14:27,224] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 13:14:27,273] [INFO] [controller] EPOCH 1 loss ppo:  -0.01217, loss val: 0.04219
[2022-12-07 13:14:27,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.01342, loss val: 0.04184
[2022-12-07 13:14:27,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.01674, loss val: 0.04227
[2022-12-07 13:14:27,402] [INFO] [controller] EPOCH 4 loss ppo:  -0.02106, loss val: 0.04223
[2022-12-07 13:14:27,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:14:27,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:14:27,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:14:31,739] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:14:35,753] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:14:40,064] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:14:43,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:14:47,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:14:51,764] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:14:55,655] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:14:59,443] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:15:03,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:15:07,540] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1859808630756232
[2022-12-07 13:15:07,540] [INFO] [runner_train_mujoco] Average state value: 0.7318185905218124
[2022-12-07 13:15:07,541] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 13:15:07,584] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.03975
[2022-12-07 13:15:07,623] [INFO] [controller] EPOCH 2 loss ppo:  -0.01634, loss val: 0.03974
[2022-12-07 13:15:07,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.02117, loss val: 0.04022
[2022-12-07 13:15:07,703] [INFO] [controller] EPOCH 4 loss ppo:  -0.02335, loss val: 0.03971
[2022-12-07 13:15:07,713] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:15:07,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:15:07,860] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:15:12,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:15:16,037] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:15:19,874] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:15:24,168] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:15:28,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:15:32,014] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:15:35,840] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:15:39,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:15:43,501] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:15:47,232] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.128427269387933
[2022-12-07 13:15:47,232] [INFO] [runner_train_mujoco] Average state value: 0.7361497727632523
[2022-12-07 13:15:47,232] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 13:15:47,271] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.03930
[2022-12-07 13:15:47,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.01351, loss val: 0.03930
[2022-12-07 13:15:47,343] [INFO] [controller] EPOCH 3 loss ppo:  -0.01592, loss val: 0.03957
[2022-12-07 13:15:47,376] [INFO] [controller] EPOCH 4 loss ppo:  -0.01945, loss val: 0.03898
[2022-12-07 13:15:47,382] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:15:47,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:15:47,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:15:51,604] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:15:55,453] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:15:59,424] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:16:03,845] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:16:07,856] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:16:11,803] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:16:15,627] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:16:19,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:16:23,219] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:16:27,078] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1539176733401466
[2022-12-07 13:16:27,078] [INFO] [runner_train_mujoco] Average state value: 0.7363766243457794
[2022-12-07 13:16:27,078] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 13:16:27,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01237, loss val: 0.04124
[2022-12-07 13:16:27,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.01365, loss val: 0.04203
[2022-12-07 13:16:27,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.01554, loss val: 0.04127
[2022-12-07 13:16:27,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.01796, loss val: 0.04122
[2022-12-07 13:16:27,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:16:27,337] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:16:27,337] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:16:31,431] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:16:35,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:16:39,221] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:16:43,110] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:16:46,896] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:16:50,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:16:55,116] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:16:58,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:17:02,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:17:06,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1620056015244193
[2022-12-07 13:17:06,651] [INFO] [runner_train_mujoco] Average state value: 0.7369419438838958
[2022-12-07 13:17:06,651] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 13:17:06,694] [INFO] [controller] EPOCH 1 loss ppo:  -0.01267, loss val: 0.04087
[2022-12-07 13:17:06,729] [INFO] [controller] EPOCH 2 loss ppo:  -0.01387, loss val: 0.04099
[2022-12-07 13:17:06,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.01593, loss val: 0.04081
[2022-12-07 13:17:06,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.01845, loss val: 0.04080
[2022-12-07 13:17:06,812] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:17:06,922] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:17:06,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:17:10,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:17:14,739] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:17:18,685] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:17:22,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:17:26,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:17:30,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:17:33,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:17:38,112] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:17:41,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:17:45,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2305556740654597
[2022-12-07 13:17:45,904] [INFO] [runner_train_mujoco] Average state value: 0.7351217441558837
[2022-12-07 13:17:45,904] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 13:17:45,941] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04372
[2022-12-07 13:17:45,972] [INFO] [controller] EPOCH 2 loss ppo:  -0.01296, loss val: 0.04355
[2022-12-07 13:17:46,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.01362, loss val: 0.04207
[2022-12-07 13:17:46,044] [INFO] [controller] EPOCH 4 loss ppo:  -0.01448, loss val: 0.04233
[2022-12-07 13:17:46,053] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:17:46,170] [INFO] [optimize] Finished learning.
