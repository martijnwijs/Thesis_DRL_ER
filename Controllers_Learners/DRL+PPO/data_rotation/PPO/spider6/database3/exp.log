[2022-12-06 18:59:48,417] [INFO] [optimize] Starting learning
[2022-12-06 18:59:48,424] [INFO] [optimize] Starting learning process..
[2022-12-06 18:59:48,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:59:48,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:59:59,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:00:11,499] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:00:22,053] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:00:31,910] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:00:41,950] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:00:51,694] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:01:02,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:01:12,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:01:23,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:01:33,764] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19196339408198532
[2022-12-06 19:01:33,765] [INFO] [runner_train_mujoco] Average state value: 0.22465269404401383
[2022-12-06 19:01:33,765] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 19:01:33,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.27113
[2022-12-06 19:01:33,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.02611, loss val: 0.24388
[2022-12-06 19:01:34,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.02995, loss val: 0.21579
[2022-12-06 19:01:34,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.03458, loss val: 0.17608
[2022-12-06 19:01:34,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:01:34,322] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:01:34,322] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:01:44,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:01:55,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:02:05,900] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:02:15,695] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:02:26,010] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:02:36,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:02:47,614] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:02:57,749] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:03:07,663] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:03:17,594] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.11267490327458088
[2022-12-06 19:03:17,595] [INFO] [runner_train_mujoco] Average state value: 0.3739595840225617
[2022-12-06 19:03:17,595] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 19:03:17,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.20916
[2022-12-06 19:03:17,804] [INFO] [controller] EPOCH 2 loss ppo:  -0.02587, loss val: 0.17929
[2022-12-06 19:03:17,932] [INFO] [controller] EPOCH 3 loss ppo:  -0.03420, loss val: 0.15246
[2022-12-06 19:03:18,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.03500, loss val: 0.12901
[2022-12-06 19:03:18,031] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:03:18,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:03:18,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:03:28,736] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:03:39,342] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:03:49,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:04:00,736] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:04:11,271] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:04:21,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:04:31,916] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:04:42,206] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:04:52,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:05:03,023] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19529366746820728
[2022-12-06 19:05:03,023] [INFO] [runner_train_mujoco] Average state value: 0.5608219583655397
[2022-12-06 19:05:03,023] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 19:05:03,125] [INFO] [controller] EPOCH 1 loss ppo:  -0.00992, loss val: 0.12349
[2022-12-06 19:05:03,214] [INFO] [controller] EPOCH 2 loss ppo:  -0.02182, loss val: 0.10605
[2022-12-06 19:05:03,385] [INFO] [controller] EPOCH 3 loss ppo:  -0.02829, loss val: 0.09212
[2022-12-06 19:05:03,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.02963, loss val: 0.08197
[2022-12-06 19:05:03,528] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:05:03,773] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:05:03,773] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:05:14,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:05:24,803] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:05:34,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:05:45,630] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:05:55,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:06:04,502] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:06:13,778] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:06:22,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:06:32,311] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:06:41,779] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14583633035600937
[2022-12-06 19:06:41,779] [INFO] [runner_train_mujoco] Average state value: 0.6917943603595097
[2022-12-06 19:06:41,779] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 19:06:41,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.00895, loss val: 0.07675
[2022-12-06 19:06:41,992] [INFO] [controller] EPOCH 2 loss ppo:  -0.01662, loss val: 0.07064
[2022-12-06 19:06:42,069] [INFO] [controller] EPOCH 3 loss ppo:  -0.02050, loss val: 0.06727
[2022-12-06 19:06:42,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.02712, loss val: 0.06453
[2022-12-06 19:06:42,152] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:06:42,373] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:06:42,374] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:06:52,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:07:03,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:07:15,463] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:07:26,794] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:07:38,232] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:07:48,099] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:07:57,984] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:08:08,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:08:18,465] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:08:29,212] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15000497786571737
[2022-12-06 19:08:29,212] [INFO] [runner_train_mujoco] Average state value: 0.7677560931046804
[2022-12-06 19:08:29,213] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 19:08:29,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.00735, loss val: 0.05797
[2022-12-06 19:08:29,447] [INFO] [controller] EPOCH 2 loss ppo:  -0.01961, loss val: 0.05475
[2022-12-06 19:08:29,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.02318, loss val: 0.05268
[2022-12-06 19:08:29,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.02509, loss val: 0.04952
[2022-12-06 19:08:29,624] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:08:29,873] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:08:29,874] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:08:40,807] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:08:50,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:09:01,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:09:12,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:09:22,980] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:09:33,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:09:43,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:09:54,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:10:04,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:10:15,363] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2000993310980841
[2022-12-06 19:10:15,363] [INFO] [runner_train_mujoco] Average state value: 0.7447103635072707
[2022-12-06 19:10:15,364] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 19:10:15,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.00653, loss val: 0.05059
[2022-12-06 19:10:15,637] [INFO] [controller] EPOCH 2 loss ppo:  -0.01515, loss val: 0.04873
[2022-12-06 19:10:15,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.02072, loss val: 0.04741
[2022-12-06 19:10:15,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.02441, loss val: 0.04639
[2022-12-06 19:10:15,957] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:10:16,211] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:10:16,212] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:10:26,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:10:37,272] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:10:47,678] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:10:58,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:11:08,479] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:11:18,469] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:11:28,375] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:11:39,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:11:49,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:11:59,712] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15097191532989213
[2022-12-06 19:11:59,713] [INFO] [runner_train_mujoco] Average state value: 0.7234440687100093
[2022-12-06 19:11:59,713] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 19:11:59,867] [INFO] [controller] EPOCH 1 loss ppo:  -0.00530, loss val: 0.04168
[2022-12-06 19:12:00,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.01315, loss val: 0.04172
[2022-12-06 19:12:00,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.01986, loss val: 0.04141
[2022-12-06 19:12:00,261] [INFO] [controller] EPOCH 4 loss ppo:  -0.02426, loss val: 0.03947
[2022-12-06 19:12:00,277] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:12:00,575] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:12:00,575] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:12:10,617] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:12:21,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:12:32,040] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:12:41,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:12:52,005] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:13:02,045] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:13:12,799] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:13:22,813] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:13:32,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:13:43,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1581779133080664
[2022-12-06 19:13:43,077] [INFO] [runner_train_mujoco] Average state value: 0.706538411974907
[2022-12-06 19:13:43,077] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 19:13:43,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.00555, loss val: 0.03800
[2022-12-06 19:13:43,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.01384, loss val: 0.03901
[2022-12-06 19:13:43,313] [INFO] [controller] EPOCH 3 loss ppo:  -0.02047, loss val: 0.03718
[2022-12-06 19:13:43,455] [INFO] [controller] EPOCH 4 loss ppo:  -0.02614, loss val: 0.03657
[2022-12-06 19:13:43,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:13:43,725] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:13:43,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:13:54,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:14:04,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:14:15,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:14:25,098] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:14:35,262] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:14:45,443] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:14:55,696] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:15:05,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:15:16,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:15:26,907] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21695660807633027
[2022-12-06 19:15:26,907] [INFO] [runner_train_mujoco] Average state value: 0.7182563230395317
[2022-12-06 19:15:26,907] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 19:15:27,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.00723, loss val: 0.04235
[2022-12-06 19:15:27,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.01905, loss val: 0.04243
[2022-12-06 19:15:27,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.02616, loss val: 0.04049
[2022-12-06 19:15:27,470] [INFO] [controller] EPOCH 4 loss ppo:  -0.02913, loss val: 0.04220
[2022-12-06 19:15:27,483] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:15:27,760] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:15:27,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:15:38,237] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:15:48,628] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:15:58,677] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:16:09,910] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:16:21,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:16:31,452] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:16:41,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:16:52,909] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:17:03,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:17:14,492] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20432269127532338
[2022-12-06 19:17:14,493] [INFO] [runner_train_mujoco] Average state value: 0.7350836085279783
[2022-12-06 19:17:14,493] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 19:17:14,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.00600, loss val: 0.04131
[2022-12-06 19:17:14,715] [INFO] [controller] EPOCH 2 loss ppo:  -0.01663, loss val: 0.04155
[2022-12-06 19:17:14,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.02149, loss val: 0.03836
[2022-12-06 19:17:14,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.02397, loss val: 0.03895
[2022-12-06 19:17:14,940] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:17:15,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:17:15,160] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:17:26,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:17:38,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:17:50,219] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:18:01,022] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:18:11,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:18:21,417] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:18:30,446] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:18:41,412] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:19:08,687] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:19:26,608] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2523288551754549
[2022-12-06 19:19:26,609] [INFO] [runner_train_mujoco] Average state value: 0.7307427615324656
[2022-12-06 19:19:26,609] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 19:19:26,777] [INFO] [controller] EPOCH 1 loss ppo:  -0.00748, loss val: 0.04293
[2022-12-06 19:19:26,888] [INFO] [controller] EPOCH 2 loss ppo:  -0.02016, loss val: 0.04288
[2022-12-06 19:19:27,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.02535, loss val: 0.04318
[2022-12-06 19:19:27,953] [INFO] [controller] EPOCH 4 loss ppo:  -0.03052, loss val: 0.04310
[2022-12-06 19:19:27,979] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:19:28,416] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:19:28,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:19:38,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:19:47,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:19:54,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:20:01,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:20:08,907] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:20:15,699] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:20:22,417] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:20:29,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:20:36,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:20:42,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3109373226333383
[2022-12-06 19:20:42,543] [INFO] [runner_train_mujoco] Average state value: 0.7349608321984609
[2022-12-06 19:20:42,543] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 19:20:42,614] [INFO] [controller] EPOCH 1 loss ppo:  -0.00646, loss val: 0.03900
[2022-12-06 19:20:42,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.01694, loss val: 0.03786
[2022-12-06 19:20:42,715] [INFO] [controller] EPOCH 3 loss ppo:  -0.02042, loss val: 0.03733
[2022-12-06 19:20:42,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.02336, loss val: 0.03666
[2022-12-06 19:20:42,778] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:20:42,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:20:42,952] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:20:49,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:20:56,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:21:04,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:21:10,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:21:17,802] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:21:24,362] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:21:30,970] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:21:38,223] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:21:45,149] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:21:51,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3075554095777246
[2022-12-06 19:21:51,904] [INFO] [runner_train_mujoco] Average state value: 0.7076283418536187
[2022-12-06 19:21:51,904] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 19:21:51,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.00739, loss val: 0.03851
[2022-12-06 19:21:52,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.01844, loss val: 0.03881
[2022-12-06 19:21:52,074] [INFO] [controller] EPOCH 3 loss ppo:  -0.02170, loss val: 0.03862
[2022-12-06 19:21:52,141] [INFO] [controller] EPOCH 4 loss ppo:  -0.02677, loss val: 0.03896
[2022-12-06 19:21:52,151] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:21:52,329] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:21:52,329] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:21:59,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:22:06,555] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:22:13,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:22:21,064] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:22:27,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:22:35,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:22:42,940] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:22:49,745] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:22:56,715] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:23:03,968] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.30451352453068564
[2022-12-06 19:23:03,968] [INFO] [runner_train_mujoco] Average state value: 0.7031616936922074
[2022-12-06 19:23:03,969] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 19:23:04,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.00645, loss val: 0.03974
[2022-12-06 19:23:04,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.01573, loss val: 0.03895
[2022-12-06 19:23:04,153] [INFO] [controller] EPOCH 3 loss ppo:  -0.02217, loss val: 0.04002
[2022-12-06 19:23:04,215] [INFO] [controller] EPOCH 4 loss ppo:  -0.02982, loss val: 0.04015
[2022-12-06 19:23:04,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:23:04,406] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:23:04,406] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:23:11,897] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:23:19,734] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:23:26,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:23:34,407] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:23:42,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:23:49,466] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:23:57,005] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:24:04,092] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:24:12,439] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:24:19,639] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3795474670625896
[2022-12-06 19:24:19,639] [INFO] [runner_train_mujoco] Average state value: 0.7184086048603058
[2022-12-06 19:24:19,640] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 19:24:19,705] [INFO] [controller] EPOCH 1 loss ppo:  -0.00768, loss val: 0.03951
[2022-12-06 19:24:19,758] [INFO] [controller] EPOCH 2 loss ppo:  -0.01816, loss val: 0.03988
[2022-12-06 19:24:19,825] [INFO] [controller] EPOCH 3 loss ppo:  -0.02197, loss val: 0.03931
[2022-12-06 19:24:19,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.02351, loss val: 0.03884
[2022-12-06 19:24:19,892] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:24:20,129] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:24:20,130] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:24:27,611] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:24:35,516] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:24:43,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:24:51,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:24:58,570] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:25:06,272] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:25:14,265] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:25:21,742] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:25:29,592] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:25:37,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4303795668324315
[2022-12-06 19:25:37,514] [INFO] [runner_train_mujoco] Average state value: 0.6920149520039558
[2022-12-06 19:25:37,514] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 19:25:37,584] [INFO] [controller] EPOCH 1 loss ppo:  -0.00994, loss val: 0.04131
[2022-12-06 19:25:37,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.02223, loss val: 0.04112
[2022-12-06 19:25:37,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.02426, loss val: 0.04009
[2022-12-06 19:25:37,974] [INFO] [controller] EPOCH 4 loss ppo:  -0.03107, loss val: 0.03982
[2022-12-06 19:25:37,985] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:25:38,199] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:25:38,199] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:25:46,150] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:25:54,585] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:26:02,240] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:26:10,496] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:26:18,195] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:26:25,979] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:26:33,948] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:26:42,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:26:50,693] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:26:59,019] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5365852003892858
[2022-12-06 19:26:59,020] [INFO] [runner_train_mujoco] Average state value: 0.6979662211537361
[2022-12-06 19:26:59,020] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 19:26:59,141] [INFO] [controller] EPOCH 1 loss ppo:  -0.00839, loss val: 0.03925
[2022-12-06 19:26:59,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.01923, loss val: 0.03925
[2022-12-06 19:26:59,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.02521, loss val: 0.03922
[2022-12-06 19:26:59,407] [INFO] [controller] EPOCH 4 loss ppo:  -0.02932, loss val: 0.03824
[2022-12-06 19:26:59,420] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:26:59,624] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:26:59,625] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:27:07,854] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:27:16,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:27:24,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:27:32,993] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:27:41,382] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:27:50,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:27:58,950] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:28:07,966] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:28:16,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:28:25,402] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6658869577747445
[2022-12-06 19:28:25,403] [INFO] [runner_train_mujoco] Average state value: 0.7080261404712995
[2022-12-06 19:28:25,403] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 19:28:25,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.00865, loss val: 0.03840
[2022-12-06 19:28:25,562] [INFO] [controller] EPOCH 2 loss ppo:  -0.01902, loss val: 0.03750
[2022-12-06 19:28:25,629] [INFO] [controller] EPOCH 3 loss ppo:  -0.02359, loss val: 0.03698
[2022-12-06 19:28:25,691] [INFO] [controller] EPOCH 4 loss ppo:  -0.02931, loss val: 0.03873
[2022-12-06 19:28:25,704] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:28:25,904] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:28:25,904] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:28:34,902] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:28:43,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:28:53,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:29:02,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:29:11,542] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:29:20,521] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:29:29,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:29:39,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:29:49,081] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:29:58,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6338586631875616
[2022-12-06 19:29:58,543] [INFO] [runner_train_mujoco] Average state value: 0.6658234507640203
[2022-12-06 19:29:58,544] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 19:29:58,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.00734, loss val: 0.03790
[2022-12-06 19:29:58,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.01731, loss val: 0.03793
[2022-12-06 19:29:58,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.02678, loss val: 0.03793
[2022-12-06 19:29:58,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.03055, loss val: 0.03772
[2022-12-06 19:29:58,904] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:29:59,137] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:29:59,138] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:30:09,299] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:30:19,299] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:30:29,589] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:30:39,550] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:30:49,973] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:31:00,062] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:31:10,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:31:21,045] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:31:31,679] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:31:43,580] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7468430207152666
[2022-12-06 19:31:43,581] [INFO] [runner_train_mujoco] Average state value: 0.6671324152549107
[2022-12-06 19:31:43,581] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 19:31:43,723] [INFO] [controller] EPOCH 1 loss ppo:  -0.01073, loss val: 0.03760
[2022-12-06 19:31:43,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.02457, loss val: 0.03763
[2022-12-06 19:31:43,899] [INFO] [controller] EPOCH 3 loss ppo:  -0.02812, loss val: 0.03756
[2022-12-06 19:31:43,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.03250, loss val: 0.03747
[2022-12-06 19:31:43,998] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:31:44,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:31:44,250] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:31:56,338] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:32:07,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:32:19,997] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:32:31,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:32:44,273] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:32:56,438] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:33:09,274] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:33:22,755] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:33:36,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:33:51,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7435327349018759
[2022-12-06 19:33:51,006] [INFO] [runner_train_mujoco] Average state value: 0.668565623899301
[2022-12-06 19:33:51,006] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 19:33:51,194] [INFO] [controller] EPOCH 1 loss ppo:  -0.01042, loss val: 0.03785
[2022-12-06 19:33:51,508] [INFO] [controller] EPOCH 2 loss ppo:  -0.02187, loss val: 0.03770
[2022-12-06 19:33:51,647] [INFO] [controller] EPOCH 3 loss ppo:  -0.02657, loss val: 0.03736
[2022-12-06 19:33:51,792] [INFO] [controller] EPOCH 4 loss ppo:  -0.03103, loss val: 0.03845
[2022-12-06 19:33:51,811] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:33:52,128] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:33:52,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:34:06,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:34:19,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:34:32,799] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:34:45,869] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:34:57,902] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:35:09,815] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:35:21,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:35:32,207] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:35:43,932] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:35:54,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9609046085902001
[2022-12-06 19:35:54,828] [INFO] [runner_train_mujoco] Average state value: 0.6710960311492284
[2022-12-06 19:35:54,828] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 19:35:54,917] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.03725
[2022-12-06 19:35:54,996] [INFO] [controller] EPOCH 2 loss ppo:  -0.01936, loss val: 0.03713
[2022-12-06 19:35:55,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.01988, loss val: 0.03759
[2022-12-06 19:35:55,185] [INFO] [controller] EPOCH 4 loss ppo:  -0.02543, loss val: 0.03682
[2022-12-06 19:35:55,200] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:35:55,451] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:35:55,451] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:36:06,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:36:17,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:36:27,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:36:37,969] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:36:49,119] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:36:59,005] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:37:08,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:37:18,894] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:37:28,152] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:37:37,449] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.945392083135232
[2022-12-06 19:37:37,449] [INFO] [runner_train_mujoco] Average state value: 0.6890840358535448
[2022-12-06 19:37:37,449] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 19:37:37,528] [INFO] [controller] EPOCH 1 loss ppo:  -0.01028, loss val: 0.03860
[2022-12-06 19:37:37,676] [INFO] [controller] EPOCH 2 loss ppo:  -0.01967, loss val: 0.03889
[2022-12-06 19:37:37,740] [INFO] [controller] EPOCH 3 loss ppo:  -0.02475, loss val: 0.03863
[2022-12-06 19:37:37,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.03072, loss val: 0.03964
[2022-12-06 19:37:37,817] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:37:38,059] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:37:38,060] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:37:47,451] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:37:57,088] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:38:06,165] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:38:14,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:38:24,121] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:38:32,578] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:38:41,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:38:49,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:38:58,261] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:39:07,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1400272196844394
[2022-12-06 19:39:07,050] [INFO] [runner_train_mujoco] Average state value: 0.6900189561247826
[2022-12-06 19:39:07,050] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 19:39:07,163] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.04004
[2022-12-06 19:39:07,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.02270, loss val: 0.03966
[2022-12-06 19:39:07,500] [INFO] [controller] EPOCH 3 loss ppo:  -0.02856, loss val: 0.03857
[2022-12-06 19:39:07,684] [INFO] [controller] EPOCH 4 loss ppo:  -0.03219, loss val: 0.03849
[2022-12-06 19:39:07,698] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:39:07,946] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:39:07,946] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:39:17,168] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:39:25,998] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:39:35,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:39:45,084] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:39:54,413] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:40:03,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:40:13,081] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:40:22,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:40:32,043] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:40:41,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.17877087795786
[2022-12-06 19:40:41,448] [INFO] [runner_train_mujoco] Average state value: 0.6972739503383636
[2022-12-06 19:40:41,448] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 19:40:41,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.01121, loss val: 0.03732
[2022-12-06 19:40:41,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.02155, loss val: 0.03787
[2022-12-06 19:40:41,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.02804, loss val: 0.03736
[2022-12-06 19:40:41,776] [INFO] [controller] EPOCH 4 loss ppo:  -0.03285, loss val: 0.03893
[2022-12-06 19:40:41,791] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:40:42,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:40:42,018] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:40:52,401] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:41:02,751] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:41:15,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:41:25,842] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:41:35,883] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:41:47,067] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:41:58,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:42:09,656] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:42:20,831] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:42:31,848] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2287044944909378
[2022-12-06 19:42:31,848] [INFO] [runner_train_mujoco] Average state value: 0.6994435691833496
[2022-12-06 19:42:31,848] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 19:42:31,957] [INFO] [controller] EPOCH 1 loss ppo:  -0.01138, loss val: 0.03754
[2022-12-06 19:42:32,063] [INFO] [controller] EPOCH 2 loss ppo:  -0.02200, loss val: 0.03724
[2022-12-06 19:42:32,149] [INFO] [controller] EPOCH 3 loss ppo:  -0.02751, loss val: 0.03684
[2022-12-06 19:42:32,244] [INFO] [controller] EPOCH 4 loss ppo:  -0.03201, loss val: 0.03682
[2022-12-06 19:42:32,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:42:32,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:42:32,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:42:43,830] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:42:55,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:43:07,150] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:43:19,823] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:43:34,399] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:43:46,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:43:58,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:44:09,857] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:44:19,273] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:44:28,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4032651563021374
[2022-12-06 19:44:28,112] [INFO] [runner_train_mujoco] Average state value: 0.6648236303925514
[2022-12-06 19:44:28,112] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 19:44:28,194] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.04144
[2022-12-06 19:44:28,267] [INFO] [controller] EPOCH 2 loss ppo:  -0.02461, loss val: 0.04237
[2022-12-06 19:44:28,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.03056, loss val: 0.04151
[2022-12-06 19:44:28,405] [INFO] [controller] EPOCH 4 loss ppo:  -0.03511, loss val: 0.04018
[2022-12-06 19:44:28,419] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:44:28,648] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:44:28,648] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:44:37,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:44:46,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:44:55,512] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:45:05,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:45:13,468] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:45:22,097] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:45:31,668] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:45:40,149] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:45:48,340] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:45:57,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3807743211400276
[2022-12-06 19:45:57,051] [INFO] [runner_train_mujoco] Average state value: 0.6933681251207988
[2022-12-06 19:45:57,051] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 19:45:57,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.01106, loss val: 0.04040
[2022-12-06 19:45:57,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.01960, loss val: 0.04046
[2022-12-06 19:45:57,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.02990, loss val: 0.04049
[2022-12-06 19:45:57,302] [INFO] [controller] EPOCH 4 loss ppo:  -0.03654, loss val: 0.04068
[2022-12-06 19:45:57,314] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:45:57,536] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:45:57,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:46:07,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:46:16,945] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:46:25,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:46:33,081] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:46:41,008] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:46:49,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:46:57,435] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:47:05,410] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:47:14,758] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:47:22,396] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.48707934584924
[2022-12-06 19:47:22,397] [INFO] [runner_train_mujoco] Average state value: 0.7140447267691294
[2022-12-06 19:47:22,397] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 19:47:22,467] [INFO] [controller] EPOCH 1 loss ppo:  -0.01179, loss val: 0.04318
[2022-12-06 19:47:22,527] [INFO] [controller] EPOCH 2 loss ppo:  -0.02182, loss val: 0.04262
[2022-12-06 19:47:22,588] [INFO] [controller] EPOCH 3 loss ppo:  -0.02634, loss val: 0.04205
[2022-12-06 19:47:22,648] [INFO] [controller] EPOCH 4 loss ppo:  -0.02970, loss val: 0.04279
[2022-12-06 19:47:22,660] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:47:22,884] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:47:22,884] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:47:30,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:47:37,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:47:45,478] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:47:52,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:48:01,467] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:48:10,522] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:48:18,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:48:26,496] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:48:33,846] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:48:41,082] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.669667870191336
[2022-12-06 19:48:41,082] [INFO] [runner_train_mujoco] Average state value: 0.6923034988244374
[2022-12-06 19:48:41,083] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 19:48:41,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01318, loss val: 0.03718
[2022-12-06 19:48:41,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.02695, loss val: 0.03631
[2022-12-06 19:48:41,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.03220, loss val: 0.03602
[2022-12-06 19:48:41,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.03766, loss val: 0.03589
[2022-12-06 19:48:41,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:48:41,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:48:41,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:48:49,234] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:48:56,852] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:49:04,930] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:49:12,817] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:49:20,883] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:49:28,855] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:49:36,918] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:49:44,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:49:52,689] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:50:00,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7123599297773804
[2022-12-06 19:50:00,702] [INFO] [runner_train_mujoco] Average state value: 0.6660825066963831
[2022-12-06 19:50:00,702] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 19:50:00,787] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.04234
[2022-12-06 19:50:00,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.01655, loss val: 0.04263
[2022-12-06 19:50:00,904] [INFO] [controller] EPOCH 3 loss ppo:  -0.02401, loss val: 0.04244
[2022-12-06 19:50:00,979] [INFO] [controller] EPOCH 4 loss ppo:  -0.03023, loss val: 0.04191
[2022-12-06 19:50:00,994] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:50:01,196] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:50:01,197] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:50:09,293] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:50:17,525] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:50:25,432] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:50:33,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:50:41,018] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:50:48,348] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:50:55,523] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:51:02,914] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:51:09,710] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:51:16,909] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.871587046257685
[2022-12-06 19:51:16,910] [INFO] [runner_train_mujoco] Average state value: 0.68168139564991
[2022-12-06 19:51:16,910] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 19:51:16,996] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.03955
[2022-12-06 19:51:17,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.02682, loss val: 0.03932
[2022-12-06 19:51:17,113] [INFO] [controller] EPOCH 3 loss ppo:  -0.02759, loss val: 0.03891
[2022-12-06 19:51:17,170] [INFO] [controller] EPOCH 4 loss ppo:  -0.03181, loss val: 0.03913
[2022-12-06 19:51:17,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:51:17,383] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:51:17,383] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:51:24,480] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:51:31,384] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:51:38,400] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:51:45,523] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:51:52,849] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:51:59,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:52:07,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:52:14,894] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:52:21,778] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:52:28,188] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9454297174833077
[2022-12-06 19:52:28,188] [INFO] [runner_train_mujoco] Average state value: 0.7026893165906271
[2022-12-06 19:52:28,188] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 19:52:28,250] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.03841
[2022-12-06 19:52:28,299] [INFO] [controller] EPOCH 2 loss ppo:  -0.02188, loss val: 0.03699
[2022-12-06 19:52:28,350] [INFO] [controller] EPOCH 3 loss ppo:  -0.02681, loss val: 0.03622
[2022-12-06 19:52:28,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.03222, loss val: 0.03638
[2022-12-06 19:52:28,412] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:52:28,611] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:52:28,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:52:35,693] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:52:42,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:52:49,580] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:52:56,423] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:53:03,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:53:10,111] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:53:16,901] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:53:23,373] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:53:29,952] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:53:36,466] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9753038627151962
[2022-12-06 19:53:36,467] [INFO] [runner_train_mujoco] Average state value: 0.686397682070732
[2022-12-06 19:53:36,467] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 19:53:36,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01123, loss val: 0.03813
[2022-12-06 19:53:36,597] [INFO] [controller] EPOCH 2 loss ppo:  -0.01897, loss val: 0.03807
[2022-12-06 19:53:36,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.02761, loss val: 0.03799
[2022-12-06 19:53:36,704] [INFO] [controller] EPOCH 4 loss ppo:  -0.03312, loss val: 0.03754
[2022-12-06 19:53:36,715] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:53:36,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:53:36,906] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:53:43,420] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:53:49,991] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:53:56,505] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:54:02,692] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:54:08,738] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:54:15,643] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:54:22,116] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:54:28,803] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:54:35,109] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:54:41,016] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.952922811892656
[2022-12-06 19:54:41,016] [INFO] [runner_train_mujoco] Average state value: 0.6856477575699489
[2022-12-06 19:54:41,017] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 19:54:41,077] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.04690
[2022-12-06 19:54:41,124] [INFO] [controller] EPOCH 2 loss ppo:  -0.02089, loss val: 0.04613
[2022-12-06 19:54:41,172] [INFO] [controller] EPOCH 3 loss ppo:  -0.02470, loss val: 0.04561
[2022-12-06 19:54:41,218] [INFO] [controller] EPOCH 4 loss ppo:  -0.03518, loss val: 0.04493
[2022-12-06 19:54:41,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:54:41,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:54:41,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:54:47,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:54:53,416] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:54:59,466] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:55:05,323] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:55:11,698] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:55:17,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:55:24,546] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:55:30,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:55:37,051] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:55:43,276] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0054268509001654
[2022-12-06 19:55:43,277] [INFO] [runner_train_mujoco] Average state value: 0.7017927485307058
[2022-12-06 19:55:43,277] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 19:55:43,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.04332
[2022-12-06 19:55:43,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.02330, loss val: 0.04303
[2022-12-06 19:55:43,437] [INFO] [controller] EPOCH 3 loss ppo:  -0.02751, loss val: 0.04318
[2022-12-06 19:55:43,491] [INFO] [controller] EPOCH 4 loss ppo:  -0.03257, loss val: 0.04333
[2022-12-06 19:55:43,501] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:55:43,682] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:55:43,683] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:55:49,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:55:55,304] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:56:01,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:56:07,137] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:56:12,880] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:56:18,816] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:56:24,751] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:56:30,802] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:56:37,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:56:43,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.171939553608067
[2022-12-06 19:56:43,161] [INFO] [runner_train_mujoco] Average state value: 0.7145484300454459
[2022-12-06 19:56:43,161] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 19:56:43,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04272
[2022-12-06 19:56:43,269] [INFO] [controller] EPOCH 2 loss ppo:  -0.02522, loss val: 0.04253
[2022-12-06 19:56:43,336] [INFO] [controller] EPOCH 3 loss ppo:  -0.03032, loss val: 0.04282
[2022-12-06 19:56:43,399] [INFO] [controller] EPOCH 4 loss ppo:  -0.03466, loss val: 0.04280
[2022-12-06 19:56:43,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:56:43,602] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:56:43,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:56:49,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:56:56,516] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:57:02,722] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:57:08,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:57:14,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:57:20,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:57:26,604] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:57:32,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:57:38,445] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:57:43,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3680162607519266
[2022-12-06 19:57:43,549] [INFO] [runner_train_mujoco] Average state value: 0.7233224360148113
[2022-12-06 19:57:43,549] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 19:57:43,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04418
[2022-12-06 19:57:43,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.02194, loss val: 0.04377
[2022-12-06 19:57:43,682] [INFO] [controller] EPOCH 3 loss ppo:  -0.02687, loss val: 0.04435
[2022-12-06 19:57:43,729] [INFO] [controller] EPOCH 4 loss ppo:  -0.03482, loss val: 0.04476
[2022-12-06 19:57:43,738] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:57:43,901] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:57:43,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:57:49,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:57:54,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:58:00,121] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:58:05,395] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:58:10,358] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:58:15,460] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:58:20,498] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:58:25,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:58:30,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:58:34,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.324938781950254
[2022-12-06 19:58:34,851] [INFO] [runner_train_mujoco] Average state value: 0.7118258323669433
[2022-12-06 19:58:34,851] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 19:58:34,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04073
[2022-12-06 19:58:34,942] [INFO] [controller] EPOCH 2 loss ppo:  -0.02138, loss val: 0.04150
[2022-12-06 19:58:34,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.02630, loss val: 0.04023
[2022-12-06 19:58:35,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.02990, loss val: 0.04091
[2022-12-06 19:58:35,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:58:35,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:58:35,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:58:39,906] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:58:44,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:58:49,182] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:58:53,456] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:58:57,886] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:59:02,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:59:06,885] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:59:11,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:59:15,778] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:59:20,189] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3839119952005268
[2022-12-06 19:59:20,189] [INFO] [runner_train_mujoco] Average state value: 0.7020970765749613
[2022-12-06 19:59:20,189] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 19:59:20,234] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04435
[2022-12-06 19:59:20,275] [INFO] [controller] EPOCH 2 loss ppo:  -0.01791, loss val: 0.04466
[2022-12-06 19:59:20,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.02385, loss val: 0.04321
[2022-12-06 19:59:20,360] [INFO] [controller] EPOCH 4 loss ppo:  -0.03221, loss val: 0.04415
[2022-12-06 19:59:20,369] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:59:20,534] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:59:20,534] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:59:25,220] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:59:29,865] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:59:34,593] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:59:39,502] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:59:44,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:59:49,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:59:53,910] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:59:58,230] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:00:02,789] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:00:07,532] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3191405869332558
[2022-12-06 20:00:07,532] [INFO] [runner_train_mujoco] Average state value: 0.6946016235748926
[2022-12-06 20:00:07,532] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 20:00:07,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.03839
[2022-12-06 20:00:07,619] [INFO] [controller] EPOCH 2 loss ppo:  -0.01987, loss val: 0.03833
[2022-12-06 20:00:07,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.02521, loss val: 0.03877
[2022-12-06 20:00:07,697] [INFO] [controller] EPOCH 4 loss ppo:  -0.03027, loss val: 0.03827
[2022-12-06 20:00:07,706] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:00:07,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:00:07,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:00:12,408] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:00:16,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:00:21,650] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:00:26,556] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:00:31,384] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:00:36,697] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:00:41,587] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:00:46,320] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:00:51,019] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:00:55,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4116217257547325
[2022-12-06 20:00:55,892] [INFO] [runner_train_mujoco] Average state value: 0.6895617401997247
[2022-12-06 20:00:55,892] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 20:00:55,942] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04611
[2022-12-06 20:00:55,983] [INFO] [controller] EPOCH 2 loss ppo:  -0.01977, loss val: 0.04535
[2022-12-06 20:00:56,023] [INFO] [controller] EPOCH 3 loss ppo:  -0.02288, loss val: 0.04588
[2022-12-06 20:00:56,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.02882, loss val: 0.04480
[2022-12-06 20:00:56,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:00:56,238] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:00:56,239] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:01:01,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:01:06,051] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:01:11,189] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:01:15,897] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:01:20,510] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:01:25,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:01:30,045] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:01:34,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:01:39,746] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:01:44,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5242982635223457
[2022-12-06 20:01:44,508] [INFO] [runner_train_mujoco] Average state value: 0.6998539599180221
[2022-12-06 20:01:44,509] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 20:01:44,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04017
[2022-12-06 20:01:44,593] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.04024
[2022-12-06 20:01:44,636] [INFO] [controller] EPOCH 3 loss ppo:  -0.02595, loss val: 0.04130
[2022-12-06 20:01:44,678] [INFO] [controller] EPOCH 4 loss ppo:  -0.02957, loss val: 0.03999
[2022-12-06 20:01:44,688] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:01:44,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:01:44,860] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:01:49,996] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:01:54,949] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:02:00,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:02:04,670] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:02:09,891] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:02:14,899] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:02:20,077] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:02:25,347] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:02:30,254] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:02:35,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.390112602829282
[2022-12-06 20:02:35,266] [INFO] [runner_train_mujoco] Average state value: 0.6909999303420384
[2022-12-06 20:02:35,266] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 20:02:35,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04148
[2022-12-06 20:02:35,363] [INFO] [controller] EPOCH 2 loss ppo:  -0.01750, loss val: 0.04168
[2022-12-06 20:02:35,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.02144, loss val: 0.04088
[2022-12-06 20:02:35,451] [INFO] [controller] EPOCH 4 loss ppo:  -0.02669, loss val: 0.03961
[2022-12-06 20:02:35,461] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:02:35,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:02:35,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:02:40,668] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:02:45,709] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:02:50,552] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:02:55,478] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:03:00,330] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:03:05,352] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:03:10,252] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:03:15,111] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:03:20,123] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:03:25,015] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.435884446383263
[2022-12-06 20:03:25,016] [INFO] [runner_train_mujoco] Average state value: 0.6872980078458786
[2022-12-06 20:03:25,016] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 20:03:25,061] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.04311
[2022-12-06 20:03:25,103] [INFO] [controller] EPOCH 2 loss ppo:  -0.01733, loss val: 0.04163
[2022-12-06 20:03:25,147] [INFO] [controller] EPOCH 3 loss ppo:  -0.02081, loss val: 0.04176
[2022-12-06 20:03:25,186] [INFO] [controller] EPOCH 4 loss ppo:  -0.02523, loss val: 0.04340
[2022-12-06 20:03:25,195] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:03:25,368] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:03:25,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:03:30,529] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:03:35,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:03:40,385] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:03:45,430] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:03:50,035] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:03:54,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:03:59,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:04:04,057] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:04:08,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:04:13,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.524767606147972
[2022-12-06 20:04:13,620] [INFO] [runner_train_mujoco] Average state value: 0.6876759203672409
[2022-12-06 20:04:13,620] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 20:04:13,672] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04131
[2022-12-06 20:04:13,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.02032, loss val: 0.04122
[2022-12-06 20:04:13,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.02210, loss val: 0.04130
[2022-12-06 20:04:13,799] [INFO] [controller] EPOCH 4 loss ppo:  -0.02626, loss val: 0.04123
[2022-12-06 20:04:13,809] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:04:13,963] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:04:13,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:04:19,067] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:04:23,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:04:28,783] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:04:33,460] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:04:38,330] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:04:43,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:04:47,880] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:04:52,636] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:04:57,959] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:05:02,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5202213459404934
[2022-12-06 20:05:02,892] [INFO] [runner_train_mujoco] Average state value: 0.6837654709418615
[2022-12-06 20:05:02,892] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 20:05:02,938] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04024
[2022-12-06 20:05:02,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.01803, loss val: 0.04088
[2022-12-06 20:05:03,023] [INFO] [controller] EPOCH 3 loss ppo:  -0.01986, loss val: 0.03988
[2022-12-06 20:05:03,065] [INFO] [controller] EPOCH 4 loss ppo:  -0.02438, loss val: 0.04040
[2022-12-06 20:05:03,074] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:05:03,217] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:05:03,218] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:05:07,977] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:05:12,995] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:05:17,526] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:05:22,100] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:05:26,639] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:05:31,548] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:05:36,317] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:05:40,875] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:05:45,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:05:49,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6341311792609328
[2022-12-06 20:05:49,838] [INFO] [runner_train_mujoco] Average state value: 0.6760266211032867
[2022-12-06 20:05:49,838] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 20:05:49,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.03971
[2022-12-06 20:05:49,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.01753, loss val: 0.04054
[2022-12-06 20:05:49,966] [INFO] [controller] EPOCH 3 loss ppo:  -0.02205, loss val: 0.03973
[2022-12-06 20:05:50,000] [INFO] [controller] EPOCH 4 loss ppo:  -0.02636, loss val: 0.03969
[2022-12-06 20:05:50,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:05:50,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:05:50,169] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:05:54,665] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:05:59,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:06:04,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:06:08,642] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:06:13,511] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:06:18,060] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:06:22,683] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:06:27,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:06:31,642] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:06:36,012] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5968785129607954
[2022-12-06 20:06:36,013] [INFO] [runner_train_mujoco] Average state value: 0.6739016352494558
[2022-12-06 20:06:36,013] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 20:06:36,058] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.04041
[2022-12-06 20:06:36,100] [INFO] [controller] EPOCH 2 loss ppo:  -0.01601, loss val: 0.03911
[2022-12-06 20:06:36,142] [INFO] [controller] EPOCH 3 loss ppo:  -0.01822, loss val: 0.03984
[2022-12-06 20:06:36,182] [INFO] [controller] EPOCH 4 loss ppo:  -0.02082, loss val: 0.03845
[2022-12-06 20:06:36,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:06:36,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:06:36,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:06:41,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:06:45,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:06:50,385] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:06:55,168] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:06:59,757] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:07:05,270] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:07:10,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:07:15,628] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:07:20,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:07:25,089] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.678031003334236
[2022-12-06 20:07:25,089] [INFO] [runner_train_mujoco] Average state value: 0.6793076623678207
[2022-12-06 20:07:25,090] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 20:07:25,140] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04251
[2022-12-06 20:07:25,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.02050, loss val: 0.04191
[2022-12-06 20:07:25,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.02330, loss val: 0.04208
[2022-12-06 20:07:25,259] [INFO] [controller] EPOCH 4 loss ppo:  -0.02615, loss val: 0.04171
[2022-12-06 20:07:25,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:07:25,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:07:25,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:07:30,228] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:07:35,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:07:39,912] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:07:44,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:07:48,866] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:07:53,786] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:07:58,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:08:03,405] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:08:08,231] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:08:12,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6757159762313854
[2022-12-06 20:08:12,819] [INFO] [runner_train_mujoco] Average state value: 0.6833917907873789
[2022-12-06 20:08:12,819] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 20:08:12,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04197
[2022-12-06 20:08:12,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.01681, loss val: 0.04343
[2022-12-06 20:08:12,953] [INFO] [controller] EPOCH 3 loss ppo:  -0.02150, loss val: 0.04206
[2022-12-06 20:08:12,990] [INFO] [controller] EPOCH 4 loss ppo:  -0.02335, loss val: 0.04223
[2022-12-06 20:08:13,001] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:08:13,168] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:08:13,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:08:17,713] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:08:22,241] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:08:27,014] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:08:31,488] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:08:36,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:08:40,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:08:45,659] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:08:50,479] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:08:55,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:08:59,752] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6346757649163566
[2022-12-06 20:08:59,753] [INFO] [runner_train_mujoco] Average state value: 0.684315712292989
[2022-12-06 20:08:59,753] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 20:08:59,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.04108
[2022-12-06 20:08:59,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.01696, loss val: 0.04003
[2022-12-06 20:08:59,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.02107, loss val: 0.04262
[2022-12-06 20:08:59,936] [INFO] [controller] EPOCH 4 loss ppo:  -0.02398, loss val: 0.03975
[2022-12-06 20:08:59,944] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:09:00,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:09:00,109] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:09:04,823] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:09:09,836] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:09:14,430] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:09:19,167] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:09:23,926] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:09:28,679] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:09:33,369] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:09:38,159] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:09:43,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:09:47,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7865216853547894
[2022-12-06 20:09:47,832] [INFO] [runner_train_mujoco] Average state value: 0.6769965890645981
[2022-12-06 20:09:47,832] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 20:09:47,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04690
[2022-12-06 20:09:47,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.01603, loss val: 0.04702
[2022-12-06 20:09:48,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.02184, loss val: 0.04705
[2022-12-06 20:09:48,049] [INFO] [controller] EPOCH 4 loss ppo:  -0.02513, loss val: 0.04681
[2022-12-06 20:09:48,059] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:09:48,206] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:09:48,206] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:09:53,013] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:09:58,032] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:10:02,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:10:07,702] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:10:12,601] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:10:17,327] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:10:22,301] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:10:26,990] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:10:31,892] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:10:37,032] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.762394198900724
[2022-12-06 20:10:37,032] [INFO] [runner_train_mujoco] Average state value: 0.6782039564450582
[2022-12-06 20:10:37,032] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 20:10:37,085] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04040
[2022-12-06 20:10:37,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.01699, loss val: 0.04154
[2022-12-06 20:10:37,164] [INFO] [controller] EPOCH 3 loss ppo:  -0.01902, loss val: 0.04044
[2022-12-06 20:10:37,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.01992, loss val: 0.04046
[2022-12-06 20:10:37,219] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:10:37,395] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:10:37,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:10:42,338] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:10:47,326] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:10:52,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:10:57,387] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:11:02,562] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:11:07,513] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:11:12,553] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:11:17,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:11:22,459] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:11:27,421] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9288582523961346
[2022-12-06 20:11:27,421] [INFO] [runner_train_mujoco] Average state value: 0.6799363418817519
[2022-12-06 20:11:27,421] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 20:11:27,475] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.04192
[2022-12-06 20:11:27,522] [INFO] [controller] EPOCH 2 loss ppo:  -0.01505, loss val: 0.04149
[2022-12-06 20:11:27,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.01754, loss val: 0.04219
[2022-12-06 20:11:27,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.02031, loss val: 0.04139
[2022-12-06 20:11:27,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:11:27,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:11:27,788] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:11:32,852] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:11:38,260] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:11:44,167] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:11:49,133] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:11:53,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:11:58,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:12:03,267] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:12:08,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:12:13,187] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:12:18,030] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8638135221619083
[2022-12-06 20:12:18,030] [INFO] [runner_train_mujoco] Average state value: 0.6816408241589864
[2022-12-06 20:12:18,031] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 20:12:18,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.04296
[2022-12-06 20:12:18,134] [INFO] [controller] EPOCH 2 loss ppo:  -0.01651, loss val: 0.04299
[2022-12-06 20:12:18,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.02062, loss val: 0.04278
[2022-12-06 20:12:18,225] [INFO] [controller] EPOCH 4 loss ppo:  -0.02377, loss val: 0.04303
[2022-12-06 20:12:18,235] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:12:18,410] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:12:18,410] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:12:23,239] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:12:28,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:12:33,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:12:38,274] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:12:42,872] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:12:47,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:12:52,023] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:12:56,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:13:01,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:13:06,445] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.846490253833596
[2022-12-06 20:13:06,445] [INFO] [runner_train_mujoco] Average state value: 0.6807702342271804
[2022-12-06 20:13:06,445] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 20:13:06,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.04432
[2022-12-06 20:13:06,543] [INFO] [controller] EPOCH 2 loss ppo:  -0.01498, loss val: 0.04397
[2022-12-06 20:13:06,590] [INFO] [controller] EPOCH 3 loss ppo:  -0.01716, loss val: 0.04391
[2022-12-06 20:13:06,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.01914, loss val: 0.04492
[2022-12-06 20:13:06,648] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:13:06,822] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:13:06,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:13:11,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:13:16,192] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:13:20,769] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:13:25,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:13:30,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:13:35,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:13:39,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:13:44,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:13:48,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:13:53,552] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.966432567598628
[2022-12-06 20:13:53,552] [INFO] [runner_train_mujoco] Average state value: 0.6825406809647878
[2022-12-06 20:13:53,552] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 20:13:53,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.03867
[2022-12-06 20:13:53,647] [INFO] [controller] EPOCH 2 loss ppo:  -0.01329, loss val: 0.03991
[2022-12-06 20:13:53,689] [INFO] [controller] EPOCH 3 loss ppo:  -0.01388, loss val: 0.03872
[2022-12-06 20:13:53,729] [INFO] [controller] EPOCH 4 loss ppo:  -0.01460, loss val: 0.03871
[2022-12-06 20:13:53,738] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:13:53,842] [INFO] [optimize] Finished learning.
