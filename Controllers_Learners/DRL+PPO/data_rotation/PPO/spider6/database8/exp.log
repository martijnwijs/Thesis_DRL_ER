[2022-12-07 07:49:05,889] [INFO] [optimize] Starting learning
[2022-12-07 07:49:05,898] [INFO] [optimize] Starting learning process..
[2022-12-07 07:49:05,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:49:05,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:49:11,618] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:49:16,877] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:49:22,423] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:49:27,211] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:49:31,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:49:36,696] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:49:41,569] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:49:46,270] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:49:51,180] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:49:56,376] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17795150293304768
[2022-12-07 07:49:56,376] [INFO] [runner_train_mujoco] Average state value: -0.22705367386713626
[2022-12-07 07:49:56,376] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 07:49:56,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01700, loss val: 0.73534
[2022-12-07 07:49:56,474] [INFO] [controller] EPOCH 2 loss ppo:  -0.02991, loss val: 0.67329
[2022-12-07 07:49:56,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.03783, loss val: 0.58945
[2022-12-07 07:49:56,561] [INFO] [controller] EPOCH 4 loss ppo:  -0.03868, loss val: 0.54093
[2022-12-07 07:49:56,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:49:56,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:49:56,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:50:01,503] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:50:06,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:50:11,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:50:16,550] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:50:21,512] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:50:26,112] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:50:31,055] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:50:36,299] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:50:41,034] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:50:45,926] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17153193358393654
[2022-12-07 07:50:45,926] [INFO] [runner_train_mujoco] Average state value: -0.04531688800485184
[2022-12-07 07:50:45,926] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 07:50:45,973] [INFO] [controller] EPOCH 1 loss ppo:  -0.01515, loss val: 0.51896
[2022-12-07 07:50:46,014] [INFO] [controller] EPOCH 2 loss ppo:  -0.02499, loss val: 0.45728
[2022-12-07 07:50:46,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.03110, loss val: 0.40479
[2022-12-07 07:50:46,096] [INFO] [controller] EPOCH 4 loss ppo:  -0.03582, loss val: 0.35232
[2022-12-07 07:50:46,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:50:46,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:50:46,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:50:51,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:50:56,050] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:51:01,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:51:06,048] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:51:10,877] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:51:15,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:51:20,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:51:25,493] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:51:30,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:51:35,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16225064625276336
[2022-12-07 07:51:35,627] [INFO] [runner_train_mujoco] Average state value: 0.13039702514310675
[2022-12-07 07:51:35,627] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 07:51:35,676] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.24717
[2022-12-07 07:51:35,717] [INFO] [controller] EPOCH 2 loss ppo:  -0.02622, loss val: 0.20814
[2022-12-07 07:51:35,763] [INFO] [controller] EPOCH 3 loss ppo:  -0.03037, loss val: 0.17792
[2022-12-07 07:51:35,809] [INFO] [controller] EPOCH 4 loss ppo:  -0.03474, loss val: 0.15175
[2022-12-07 07:51:35,819] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:51:35,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:51:35,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:51:41,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:51:46,070] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:51:50,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:51:55,535] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:52:00,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:52:05,188] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:52:10,296] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:52:15,072] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:52:19,937] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:52:24,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1800033159727897
[2022-12-07 07:52:24,806] [INFO] [runner_train_mujoco] Average state value: 0.2836856254115701
[2022-12-07 07:52:24,806] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 07:52:24,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.17344
[2022-12-07 07:52:24,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.02388, loss val: 0.14555
[2022-12-07 07:52:24,967] [INFO] [controller] EPOCH 3 loss ppo:  -0.03280, loss val: 0.11229
[2022-12-07 07:52:25,010] [INFO] [controller] EPOCH 4 loss ppo:  -0.03435, loss val: 0.10019
[2022-12-07 07:52:25,019] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:52:25,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:52:25,167] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:52:29,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:52:34,418] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:52:39,731] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:52:44,437] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:52:49,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:52:54,542] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:52:59,615] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:53:04,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:53:09,506] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:53:14,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18840103934085223
[2022-12-07 07:53:14,106] [INFO] [runner_train_mujoco] Average state value: 0.44549294047554333
[2022-12-07 07:53:14,106] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 07:53:14,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.11439
[2022-12-07 07:53:14,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.02283, loss val: 0.10191
[2022-12-07 07:53:14,240] [INFO] [controller] EPOCH 3 loss ppo:  -0.02912, loss val: 0.07728
[2022-12-07 07:53:14,283] [INFO] [controller] EPOCH 4 loss ppo:  -0.03391, loss val: 0.06348
[2022-12-07 07:53:14,289] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:53:14,441] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:53:14,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:53:19,521] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:53:24,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:53:29,497] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:53:34,233] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:53:38,796] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:53:43,378] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:53:48,133] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:53:53,361] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:53:58,309] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:54:03,512] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.11715027153932281
[2022-12-07 07:54:03,512] [INFO] [runner_train_mujoco] Average state value: 0.6163787200053533
[2022-12-07 07:54:03,512] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 07:54:03,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.00747, loss val: 0.06222
[2022-12-07 07:54:03,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.02144, loss val: 0.05448
[2022-12-07 07:54:03,641] [INFO] [controller] EPOCH 3 loss ppo:  -0.02326, loss val: 0.05062
[2022-12-07 07:54:03,683] [INFO] [controller] EPOCH 4 loss ppo:  -0.02682, loss val: 0.04735
[2022-12-07 07:54:03,693] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:54:03,844] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:54:03,845] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:54:08,962] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:54:13,991] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:54:18,851] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:54:23,399] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:54:28,026] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:54:32,470] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:54:37,343] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:54:42,057] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:54:46,975] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:54:51,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22759420646773543
[2022-12-07 07:54:51,828] [INFO] [runner_train_mujoco] Average state value: 0.7392845019300779
[2022-12-07 07:54:51,828] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 07:54:51,877] [INFO] [controller] EPOCH 1 loss ppo:  -0.00719, loss val: 0.04524
[2022-12-07 07:54:51,919] [INFO] [controller] EPOCH 2 loss ppo:  -0.01611, loss val: 0.04319
[2022-12-07 07:54:51,963] [INFO] [controller] EPOCH 3 loss ppo:  -0.01937, loss val: 0.04198
[2022-12-07 07:54:52,006] [INFO] [controller] EPOCH 4 loss ppo:  -0.02326, loss val: 0.04252
[2022-12-07 07:54:52,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:54:52,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:54:52,169] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:54:56,590] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:55:01,787] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:55:06,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:55:11,912] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:55:16,546] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:55:21,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:55:26,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:55:30,556] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:55:34,861] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:55:39,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3108708370104079
[2022-12-07 07:55:39,468] [INFO] [runner_train_mujoco] Average state value: 0.7811823201179504
[2022-12-07 07:55:39,468] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 07:55:39,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.00796, loss val: 0.04395
[2022-12-07 07:55:39,565] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.04330
[2022-12-07 07:55:39,607] [INFO] [controller] EPOCH 3 loss ppo:  -0.02238, loss val: 0.04271
[2022-12-07 07:55:39,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.02503, loss val: 0.04139
[2022-12-07 07:55:39,659] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:55:39,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:55:39,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:55:44,699] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:55:49,918] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:55:54,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:55:59,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:56:04,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:56:08,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:56:13,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:56:18,593] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:56:23,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:56:28,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.257147187088709
[2022-12-07 07:56:28,195] [INFO] [runner_train_mujoco] Average state value: 0.7475548421144487
[2022-12-07 07:56:28,195] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 07:56:28,253] [INFO] [controller] EPOCH 1 loss ppo:  -0.00716, loss val: 0.04067
[2022-12-07 07:56:28,292] [INFO] [controller] EPOCH 2 loss ppo:  -0.01764, loss val: 0.03904
[2022-12-07 07:56:28,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.02241, loss val: 0.04074
[2022-12-07 07:56:28,373] [INFO] [controller] EPOCH 4 loss ppo:  -0.02415, loss val: 0.04040
[2022-12-07 07:56:28,382] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:56:28,546] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:56:28,546] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:56:33,214] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:56:37,882] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:56:42,925] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:56:47,458] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:56:52,554] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:56:57,452] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:57:02,422] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:57:07,283] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:57:12,037] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:57:16,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23246938245082802
[2022-12-07 07:57:16,701] [INFO] [runner_train_mujoco] Average state value: 0.7111663505832354
[2022-12-07 07:57:16,701] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 07:57:16,751] [INFO] [controller] EPOCH 1 loss ppo:  -0.00795, loss val: 0.03883
[2022-12-07 07:57:16,792] [INFO] [controller] EPOCH 2 loss ppo:  -0.01987, loss val: 0.03889
[2022-12-07 07:57:16,838] [INFO] [controller] EPOCH 3 loss ppo:  -0.02319, loss val: 0.03792
[2022-12-07 07:57:16,879] [INFO] [controller] EPOCH 4 loss ppo:  -0.02724, loss val: 0.03830
[2022-12-07 07:57:16,888] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:57:17,022] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:57:17,022] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:57:22,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:57:26,867] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:57:31,735] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:57:36,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:57:41,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:57:45,774] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:57:50,779] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:57:55,646] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:58:00,076] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:58:04,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.31175617919573345
[2022-12-07 07:58:04,568] [INFO] [runner_train_mujoco] Average state value: 0.7144014353156088
[2022-12-07 07:58:04,568] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 07:58:04,627] [INFO] [controller] EPOCH 1 loss ppo:  -0.00805, loss val: 0.04096
[2022-12-07 07:58:04,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.02006, loss val: 0.03974
[2022-12-07 07:58:04,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.02690, loss val: 0.03883
[2022-12-07 07:58:04,764] [INFO] [controller] EPOCH 4 loss ppo:  -0.02899, loss val: 0.03905
[2022-12-07 07:58:04,773] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:58:04,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:58:04,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:58:09,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:58:14,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:58:19,369] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:58:24,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:58:29,097] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:58:34,113] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:58:38,944] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:58:43,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:58:48,459] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:58:53,289] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4029605400468303
[2022-12-07 07:58:53,289] [INFO] [runner_train_mujoco] Average state value: 0.7479069029092789
[2022-12-07 07:58:53,289] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 07:58:53,345] [INFO] [controller] EPOCH 1 loss ppo:  -0.00743, loss val: 0.03818
[2022-12-07 07:58:53,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.01978, loss val: 0.03822
[2022-12-07 07:58:53,436] [INFO] [controller] EPOCH 3 loss ppo:  -0.02366, loss val: 0.03756
[2022-12-07 07:58:53,480] [INFO] [controller] EPOCH 4 loss ppo:  -0.02480, loss val: 0.03710
[2022-12-07 07:58:53,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:58:53,636] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:58:53,636] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:58:58,389] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:59:02,856] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:59:07,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:59:12,589] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:59:17,093] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:59:21,936] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:59:26,480] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:59:31,203] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:59:35,879] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:59:40,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40896634839221
[2022-12-07 07:59:40,996] [INFO] [runner_train_mujoco] Average state value: 0.7220903377930322
[2022-12-07 07:59:40,996] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 07:59:41,064] [INFO] [controller] EPOCH 1 loss ppo:  -0.00877, loss val: 0.03884
[2022-12-07 07:59:41,117] [INFO] [controller] EPOCH 2 loss ppo:  -0.02169, loss val: 0.03860
[2022-12-07 07:59:41,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.02701, loss val: 0.03882
[2022-12-07 07:59:41,234] [INFO] [controller] EPOCH 4 loss ppo:  -0.03061, loss val: 0.03924
[2022-12-07 07:59:41,244] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:59:41,406] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:59:41,406] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:59:46,195] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:59:51,125] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:59:55,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:00:00,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:00:05,554] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:00:10,678] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:00:15,418] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:00:20,186] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:00:24,744] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:00:29,390] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.529538418704554
[2022-12-07 08:00:29,390] [INFO] [runner_train_mujoco] Average state value: 0.7006989358266195
[2022-12-07 08:00:29,391] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 08:00:29,443] [INFO] [controller] EPOCH 1 loss ppo:  -0.00794, loss val: 0.03929
[2022-12-07 08:00:29,489] [INFO] [controller] EPOCH 2 loss ppo:  -0.01993, loss val: 0.04021
[2022-12-07 08:00:29,534] [INFO] [controller] EPOCH 3 loss ppo:  -0.02526, loss val: 0.03980
[2022-12-07 08:00:29,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.03202, loss val: 0.03932
[2022-12-07 08:00:29,594] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:00:29,760] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:00:29,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:00:34,730] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:00:39,278] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:00:44,433] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:00:48,947] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:00:53,777] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:00:58,575] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:01:03,393] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:01:07,887] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:01:12,450] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:01:17,029] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5337479350908817
[2022-12-07 08:01:17,029] [INFO] [runner_train_mujoco] Average state value: 0.6931184861262639
[2022-12-07 08:01:17,029] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 08:01:17,080] [INFO] [controller] EPOCH 1 loss ppo:  -0.00821, loss val: 0.03995
[2022-12-07 08:01:17,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.01910, loss val: 0.03851
[2022-12-07 08:01:17,157] [INFO] [controller] EPOCH 3 loss ppo:  -0.02499, loss val: 0.03899
[2022-12-07 08:01:17,201] [INFO] [controller] EPOCH 4 loss ppo:  -0.03340, loss val: 0.03838
[2022-12-07 08:01:17,209] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:01:17,366] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:01:17,366] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:01:22,439] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:01:27,088] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:01:31,915] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:01:36,222] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:01:41,303] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:01:46,060] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:01:50,602] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:01:55,288] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:02:00,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:02:04,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6784147626125385
[2022-12-07 08:02:04,991] [INFO] [runner_train_mujoco] Average state value: 0.700547304391861
[2022-12-07 08:02:04,992] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 08:02:05,041] [INFO] [controller] EPOCH 1 loss ppo:  -0.00850, loss val: 0.04388
[2022-12-07 08:02:05,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.01899, loss val: 0.04295
[2022-12-07 08:02:05,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.02624, loss val: 0.04396
[2022-12-07 08:02:05,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.02881, loss val: 0.04288
[2022-12-07 08:02:05,168] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:02:05,330] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:02:05,330] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:02:09,992] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:02:14,959] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:02:19,582] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:02:23,995] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:02:28,960] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:02:33,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:02:38,688] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:02:43,307] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:02:47,653] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:02:52,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7340324762229674
[2022-12-07 08:02:52,469] [INFO] [runner_train_mujoco] Average state value: 0.7225992281834284
[2022-12-07 08:02:52,469] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 08:02:52,519] [INFO] [controller] EPOCH 1 loss ppo:  -0.00959, loss val: 0.03908
[2022-12-07 08:02:52,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.02320, loss val: 0.04013
[2022-12-07 08:02:52,595] [INFO] [controller] EPOCH 3 loss ppo:  -0.02581, loss val: 0.03834
[2022-12-07 08:02:52,633] [INFO] [controller] EPOCH 4 loss ppo:  -0.02776, loss val: 0.03792
[2022-12-07 08:02:52,643] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:02:52,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:02:52,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:02:57,232] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:03:01,971] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:03:06,849] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:03:11,113] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:03:16,139] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:03:20,523] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:03:25,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:03:30,158] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:03:34,969] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:03:39,613] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8874031622415579
[2022-12-07 08:03:39,613] [INFO] [runner_train_mujoco] Average state value: 0.7153763106266658
[2022-12-07 08:03:39,613] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 08:03:39,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.01006, loss val: 0.04065
[2022-12-07 08:03:39,702] [INFO] [controller] EPOCH 2 loss ppo:  -0.02021, loss val: 0.04142
[2022-12-07 08:03:39,743] [INFO] [controller] EPOCH 3 loss ppo:  -0.02530, loss val: 0.04071
[2022-12-07 08:03:39,788] [INFO] [controller] EPOCH 4 loss ppo:  -0.03101, loss val: 0.04063
[2022-12-07 08:03:39,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:03:39,959] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:03:39,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:03:44,644] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:03:49,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:03:54,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:03:58,776] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:04:03,365] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:04:07,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:04:12,580] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:04:17,168] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:04:22,234] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:04:27,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9596638099649878
[2022-12-07 08:04:27,201] [INFO] [runner_train_mujoco] Average state value: 0.7192515088121098
[2022-12-07 08:04:27,201] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 08:04:27,264] [INFO] [controller] EPOCH 1 loss ppo:  -0.00821, loss val: 0.04191
[2022-12-07 08:04:27,310] [INFO] [controller] EPOCH 2 loss ppo:  -0.01955, loss val: 0.04319
[2022-12-07 08:04:27,363] [INFO] [controller] EPOCH 3 loss ppo:  -0.02418, loss val: 0.04199
[2022-12-07 08:04:27,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.02979, loss val: 0.04243
[2022-12-07 08:04:27,425] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:04:27,593] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:04:27,593] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:04:32,471] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:04:37,107] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:04:41,561] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:04:46,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:04:50,864] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:04:55,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:04:59,583] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:05:04,167] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:05:08,492] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:05:13,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1453388828500737
[2022-12-07 08:05:13,415] [INFO] [runner_train_mujoco] Average state value: 0.6998561075528463
[2022-12-07 08:05:13,415] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 08:05:13,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.01112, loss val: 0.04200
[2022-12-07 08:05:13,498] [INFO] [controller] EPOCH 2 loss ppo:  -0.02042, loss val: 0.04173
[2022-12-07 08:05:13,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.02587, loss val: 0.04130
[2022-12-07 08:05:13,581] [INFO] [controller] EPOCH 4 loss ppo:  -0.02961, loss val: 0.04279
[2022-12-07 08:05:13,589] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:05:13,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:05:13,738] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:05:18,318] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:05:23,086] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:05:27,693] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:05:32,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:05:36,584] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:05:41,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:05:45,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:05:50,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:05:55,289] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:06:00,043] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0664632658241129
[2022-12-07 08:06:00,043] [INFO] [runner_train_mujoco] Average state value: 0.7136148584286373
[2022-12-07 08:06:00,043] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 08:06:00,096] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.04181
[2022-12-07 08:06:00,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.02278, loss val: 0.04242
[2022-12-07 08:06:00,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.02504, loss val: 0.04149
[2022-12-07 08:06:00,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.03297, loss val: 0.04276
[2022-12-07 08:06:00,240] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:06:00,389] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:06:00,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:06:04,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:06:09,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:06:14,596] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:06:19,097] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:06:23,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:06:28,455] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:06:32,883] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:06:37,632] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:06:42,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:06:46,852] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.124724622623811
[2022-12-07 08:06:46,852] [INFO] [runner_train_mujoco] Average state value: 0.7006604121923448
[2022-12-07 08:06:46,852] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 08:06:46,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04039
[2022-12-07 08:06:46,940] [INFO] [controller] EPOCH 2 loss ppo:  -0.02177, loss val: 0.03977
[2022-12-07 08:06:46,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.02584, loss val: 0.03942
[2022-12-07 08:06:47,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.03223, loss val: 0.04043
[2022-12-07 08:06:47,046] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:06:47,202] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:06:47,203] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:06:52,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:06:56,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:07:01,723] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:07:07,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:07:12,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:07:18,037] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:07:23,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:07:28,121] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:07:32,387] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:07:37,030] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2873857420937764
[2022-12-07 08:07:37,030] [INFO] [runner_train_mujoco] Average state value: 0.6648589477936426
[2022-12-07 08:07:37,031] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 08:07:37,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.03680
[2022-12-07 08:07:37,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.02395, loss val: 0.03804
[2022-12-07 08:07:37,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.02860, loss val: 0.03740
[2022-12-07 08:07:37,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.03291, loss val: 0.03556
[2022-12-07 08:07:37,300] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:07:37,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:07:37,456] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:07:41,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:07:46,510] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:07:51,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:07:55,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:08:00,026] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:08:04,780] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:08:09,802] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:08:16,105] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:08:21,429] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:08:26,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2604500692611091
[2022-12-07 08:08:26,814] [INFO] [runner_train_mujoco] Average state value: 0.6775049504240355
[2022-12-07 08:08:26,814] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 08:08:26,864] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.03796
[2022-12-07 08:08:26,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.02375, loss val: 0.03903
[2022-12-07 08:08:26,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.02734, loss val: 0.03846
[2022-12-07 08:08:27,057] [INFO] [controller] EPOCH 4 loss ppo:  -0.03320, loss val: 0.03843
[2022-12-07 08:08:27,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:08:27,227] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:08:27,227] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:08:32,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:08:37,890] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:08:43,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:08:48,257] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:08:53,358] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:08:58,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:09:04,397] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:09:09,613] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:09:15,296] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:09:21,161] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2966023906592636
[2022-12-07 08:09:21,161] [INFO] [runner_train_mujoco] Average state value: 0.6864054780006408
[2022-12-07 08:09:21,162] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 08:09:21,218] [INFO] [controller] EPOCH 1 loss ppo:  -0.01194, loss val: 0.03792
[2022-12-07 08:09:21,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.02219, loss val: 0.03977
[2022-12-07 08:09:21,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02493, loss val: 0.03742
[2022-12-07 08:09:21,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.02991, loss val: 0.03979
[2022-12-07 08:09:21,373] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:09:21,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:09:21,535] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:09:27,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:09:32,417] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:09:37,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:09:42,440] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:09:47,483] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:09:52,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:09:57,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:02,783] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:10:07,778] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:10:12,673] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4016251364273102
[2022-12-07 08:10:12,674] [INFO] [runner_train_mujoco] Average state value: 0.7047198535998662
[2022-12-07 08:10:12,674] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 08:10:12,726] [INFO] [controller] EPOCH 1 loss ppo:  -0.01220, loss val: 0.04369
[2022-12-07 08:10:12,770] [INFO] [controller] EPOCH 2 loss ppo:  -0.02437, loss val: 0.04316
[2022-12-07 08:10:12,818] [INFO] [controller] EPOCH 3 loss ppo:  -0.02861, loss val: 0.04368
[2022-12-07 08:10:12,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.03254, loss val: 0.04480
[2022-12-07 08:10:12,874] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:10:13,024] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:10:13,024] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:10:18,642] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:10:24,249] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:10:29,859] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:10:34,916] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:10:39,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:10:45,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:10:50,052] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:54,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:11:00,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:11:05,319] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4861426579328751
[2022-12-07 08:11:05,320] [INFO] [runner_train_mujoco] Average state value: 0.7337359335025152
[2022-12-07 08:11:05,320] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 08:11:05,384] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.03988
[2022-12-07 08:11:05,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.02526, loss val: 0.04230
[2022-12-07 08:11:05,481] [INFO] [controller] EPOCH 3 loss ppo:  -0.02779, loss val: 0.03904
[2022-12-07 08:11:05,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.03182, loss val: 0.04124
[2022-12-07 08:11:05,538] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:05,704] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:05,704] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:11:11,321] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:11:17,267] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:11:22,759] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:11:28,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:11:33,234] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:11:38,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:11:43,580] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:11:48,568] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:11:53,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:11:58,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5286520027034023
[2022-12-07 08:11:58,930] [INFO] [runner_train_mujoco] Average state value: 0.7174588392774264
[2022-12-07 08:11:58,930] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 08:11:58,980] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.04095
[2022-12-07 08:11:59,023] [INFO] [controller] EPOCH 2 loss ppo:  -0.02166, loss val: 0.04138
[2022-12-07 08:11:59,067] [INFO] [controller] EPOCH 3 loss ppo:  -0.02460, loss val: 0.03945
[2022-12-07 08:11:59,110] [INFO] [controller] EPOCH 4 loss ppo:  -0.03148, loss val: 0.04193
[2022-12-07 08:11:59,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:59,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:59,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:12:04,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:12:09,390] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:12:14,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:12:19,850] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:12:25,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:12:30,380] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:12:35,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:12:40,656] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:12:45,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:12:50,947] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5082446981705142
[2022-12-07 08:12:50,947] [INFO] [runner_train_mujoco] Average state value: 0.6977388751109441
[2022-12-07 08:12:50,947] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 08:12:51,003] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.04476
[2022-12-07 08:12:51,047] [INFO] [controller] EPOCH 2 loss ppo:  -0.02592, loss val: 0.04504
[2022-12-07 08:12:51,092] [INFO] [controller] EPOCH 3 loss ppo:  -0.02959, loss val: 0.04453
[2022-12-07 08:12:51,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.03406, loss val: 0.04527
[2022-12-07 08:12:51,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:12:51,303] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:12:51,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:12:56,141] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:13:01,161] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:13:06,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:13:12,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:13:17,860] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:13:23,627] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:13:28,927] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:13:33,785] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:13:38,837] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:13:43,888] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.635919239807582
[2022-12-07 08:13:43,889] [INFO] [runner_train_mujoco] Average state value: 0.708907438437144
[2022-12-07 08:13:43,889] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 08:13:43,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04302
[2022-12-07 08:13:44,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.02284, loss val: 0.04358
[2022-12-07 08:13:44,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.02889, loss val: 0.04366
[2022-12-07 08:13:44,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.03389, loss val: 0.04415
[2022-12-07 08:13:44,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:13:44,256] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:13:44,256] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:13:49,509] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:13:54,912] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:14:00,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:05,447] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:14:10,466] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:14:15,372] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:14:20,387] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:14:25,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:14:31,055] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:14:36,142] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.697143164856104
[2022-12-07 08:14:36,142] [INFO] [runner_train_mujoco] Average state value: 0.724449051340421
[2022-12-07 08:14:36,142] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 08:14:36,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.03893
[2022-12-07 08:14:36,247] [INFO] [controller] EPOCH 2 loss ppo:  -0.02290, loss val: 0.03874
[2022-12-07 08:14:36,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.02344, loss val: 0.03868
[2022-12-07 08:14:36,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.03012, loss val: 0.03871
[2022-12-07 08:14:36,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:14:36,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:14:36,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:14:41,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:14:47,173] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:14:52,266] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:57,126] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:15:02,121] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:15:07,356] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:15:12,591] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:15:18,063] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:15:23,410] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:15:28,687] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6524022282908848
[2022-12-07 08:15:28,687] [INFO] [runner_train_mujoco] Average state value: 0.7195661667585372
[2022-12-07 08:15:28,687] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 08:15:28,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04057
[2022-12-07 08:15:28,787] [INFO] [controller] EPOCH 2 loss ppo:  -0.01941, loss val: 0.03983
[2022-12-07 08:15:28,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.02799, loss val: 0.03993
[2022-12-07 08:15:28,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.03404, loss val: 0.03916
[2022-12-07 08:15:28,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:15:29,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:15:29,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:15:33,816] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:15:38,509] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:15:43,810] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:15:49,557] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:15:55,370] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:00,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:05,967] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:16:10,752] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:16:15,631] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:16:20,903] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.750204628542954
[2022-12-07 08:16:20,904] [INFO] [runner_train_mujoco] Average state value: 0.6934002173542977
[2022-12-07 08:16:20,904] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 08:16:20,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04691
[2022-12-07 08:16:21,020] [INFO] [controller] EPOCH 2 loss ppo:  -0.02613, loss val: 0.04681
[2022-12-07 08:16:21,070] [INFO] [controller] EPOCH 3 loss ppo:  -0.03183, loss val: 0.04683
[2022-12-07 08:16:21,131] [INFO] [controller] EPOCH 4 loss ppo:  -0.03378, loss val: 0.04678
[2022-12-07 08:16:21,141] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:16:21,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:16:21,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:16:26,589] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:16:31,795] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:16:37,350] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:16:42,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:16:48,056] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:53,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:57,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:17:03,482] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:17:08,437] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:17:13,749] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7644520946625595
[2022-12-07 08:17:13,749] [INFO] [runner_train_mujoco] Average state value: 0.6993720386823019
[2022-12-07 08:17:13,749] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 08:17:13,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04056
[2022-12-07 08:17:13,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.02770, loss val: 0.04028
[2022-12-07 08:17:13,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.03202, loss val: 0.03896
[2022-12-07 08:17:13,937] [INFO] [controller] EPOCH 4 loss ppo:  -0.03585, loss val: 0.03850
[2022-12-07 08:17:13,947] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:17:14,124] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:17:14,124] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:17:19,454] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:17:24,930] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:17:29,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:17:34,980] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:17:40,157] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:17:45,106] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:17:50,541] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:17:55,433] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:18:01,129] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:18:06,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8433581819467069
[2022-12-07 08:18:06,884] [INFO] [runner_train_mujoco] Average state value: 0.7306864699522655
[2022-12-07 08:18:06,884] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 08:18:06,941] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.03921
[2022-12-07 08:18:06,991] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.03882
[2022-12-07 08:18:07,036] [INFO] [controller] EPOCH 3 loss ppo:  -0.02628, loss val: 0.03880
[2022-12-07 08:18:07,083] [INFO] [controller] EPOCH 4 loss ppo:  -0.03327, loss val: 0.03891
[2022-12-07 08:18:07,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:18:07,264] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:18:07,264] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:18:12,435] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:18:18,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:18:23,806] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:18:29,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:18:34,897] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:18:40,392] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:18:45,246] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:18:50,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:18:55,014] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:00,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8516475835768922
[2022-12-07 08:19:00,111] [INFO] [runner_train_mujoco] Average state value: 0.7279915190140406
[2022-12-07 08:19:00,111] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 08:19:00,164] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04148
[2022-12-07 08:19:00,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.02005, loss val: 0.04082
[2022-12-07 08:19:00,259] [INFO] [controller] EPOCH 3 loss ppo:  -0.02258, loss val: 0.04088
[2022-12-07 08:19:00,304] [INFO] [controller] EPOCH 4 loss ppo:  -0.03089, loss val: 0.04075
[2022-12-07 08:19:00,313] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:00,457] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:00,457] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:05,374] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:19:10,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:19:16,021] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:19:21,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:19:27,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:19:32,385] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:19:37,401] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:19:42,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:19:48,171] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:53,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.829510441604263
[2022-12-07 08:19:53,432] [INFO] [runner_train_mujoco] Average state value: 0.7084794655243556
[2022-12-07 08:19:53,432] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 08:19:53,490] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.04501
[2022-12-07 08:19:53,530] [INFO] [controller] EPOCH 2 loss ppo:  -0.01838, loss val: 0.04536
[2022-12-07 08:19:53,571] [INFO] [controller] EPOCH 3 loss ppo:  -0.02369, loss val: 0.04518
[2022-12-07 08:19:53,612] [INFO] [controller] EPOCH 4 loss ppo:  -0.03071, loss val: 0.04482
[2022-12-07 08:19:53,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:53,791] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:53,792] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:58,844] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:20:04,337] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:20:09,504] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:20:14,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:20:19,671] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:20:24,776] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:20:29,977] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:20:34,711] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:20:39,800] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:20:45,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9373882666732634
[2022-12-07 08:20:45,126] [INFO] [runner_train_mujoco] Average state value: 0.7098857751290002
[2022-12-07 08:20:45,126] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 08:20:45,177] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.03814
[2022-12-07 08:20:45,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.02103, loss val: 0.03799
[2022-12-07 08:20:45,264] [INFO] [controller] EPOCH 3 loss ppo:  -0.02633, loss val: 0.03804
[2022-12-07 08:20:45,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.03074, loss val: 0.03764
[2022-12-07 08:20:45,317] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:20:45,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:20:45,480] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:20:50,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:20:56,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:02,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:07,549] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:21:12,552] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:21:17,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:21:22,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:21:27,774] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:21:32,917] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:21:38,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.91463416264613
[2022-12-07 08:21:38,099] [INFO] [runner_train_mujoco] Average state value: 0.7006807905038198
[2022-12-07 08:21:38,099] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 08:21:38,180] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.04013
[2022-12-07 08:21:38,239] [INFO] [controller] EPOCH 2 loss ppo:  -0.02046, loss val: 0.04075
[2022-12-07 08:21:38,292] [INFO] [controller] EPOCH 3 loss ppo:  -0.02492, loss val: 0.04089
[2022-12-07 08:21:38,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.03127, loss val: 0.04024
[2022-12-07 08:21:38,356] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:21:38,541] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:21:38,542] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:21:43,868] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:21:49,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:54,585] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:59,376] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:04,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:22:09,474] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:22:14,708] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:22:20,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:22:25,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:22:31,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9700410941380972
[2022-12-07 08:22:31,166] [INFO] [runner_train_mujoco] Average state value: 0.7001043114264806
[2022-12-07 08:22:31,166] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 08:22:31,222] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.03520
[2022-12-07 08:22:31,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.02108, loss val: 0.03520
[2022-12-07 08:22:31,313] [INFO] [controller] EPOCH 3 loss ppo:  -0.02451, loss val: 0.03782
[2022-12-07 08:22:31,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.03072, loss val: 0.03730
[2022-12-07 08:22:31,367] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:22:31,531] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:22:31,531] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:22:36,966] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:22:42,244] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:22:47,532] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:22:52,384] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:57,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:23:02,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:23:07,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:23:12,223] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:23:17,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:23:22,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.990987992314317
[2022-12-07 08:23:22,271] [INFO] [runner_train_mujoco] Average state value: 0.6922488423983256
[2022-12-07 08:23:22,271] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 08:23:22,345] [INFO] [controller] EPOCH 1 loss ppo:  -0.01497, loss val: 0.04207
[2022-12-07 08:23:22,398] [INFO] [controller] EPOCH 2 loss ppo:  -0.02573, loss val: 0.04206
[2022-12-07 08:23:22,451] [INFO] [controller] EPOCH 3 loss ppo:  -0.02840, loss val: 0.04277
[2022-12-07 08:23:22,501] [INFO] [controller] EPOCH 4 loss ppo:  -0.03331, loss val: 0.04439
[2022-12-07 08:23:22,511] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:23:22,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:23:22,674] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:23:27,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:23:33,760] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:23:38,897] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:23:44,177] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:23:49,559] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:23:54,739] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:23:59,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:05,321] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:24:10,448] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:24:15,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9738228062342096
[2022-12-07 08:24:15,704] [INFO] [runner_train_mujoco] Average state value: 0.6887191132307053
[2022-12-07 08:24:15,704] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 08:24:15,754] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.04085
[2022-12-07 08:24:15,798] [INFO] [controller] EPOCH 2 loss ppo:  -0.01873, loss val: 0.03927
[2022-12-07 08:24:15,840] [INFO] [controller] EPOCH 3 loss ppo:  -0.02676, loss val: 0.03993
[2022-12-07 08:24:15,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.03077, loss val: 0.04029
[2022-12-07 08:24:15,888] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:24:16,049] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:24:16,049] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:24:21,168] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:24:26,147] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:24:31,919] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:24:36,762] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:24:42,046] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:24:46,806] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:24:52,162] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:57,443] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:25:02,779] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:25:07,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0261269894797964
[2022-12-07 08:25:07,983] [INFO] [runner_train_mujoco] Average state value: 0.6869113277991613
[2022-12-07 08:25:07,983] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 08:25:08,032] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.04275
[2022-12-07 08:25:08,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.01744, loss val: 0.04231
[2022-12-07 08:25:08,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.02450, loss val: 0.04109
[2022-12-07 08:25:08,169] [INFO] [controller] EPOCH 4 loss ppo:  -0.02923, loss val: 0.04064
[2022-12-07 08:25:08,179] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:25:08,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:25:08,341] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:25:13,374] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:25:18,337] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:25:23,750] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:25:28,816] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:25:34,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:39,193] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:25:44,206] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:25:49,499] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:25:54,258] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:25:58,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0127351299592227
[2022-12-07 08:25:58,996] [INFO] [runner_train_mujoco] Average state value: 0.7028013520240785
[2022-12-07 08:25:58,996] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 08:25:59,053] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.04209
[2022-12-07 08:25:59,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.01807, loss val: 0.04296
[2022-12-07 08:25:59,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.02172, loss val: 0.04266
[2022-12-07 08:25:59,181] [INFO] [controller] EPOCH 4 loss ppo:  -0.02573, loss val: 0.04220
[2022-12-07 08:25:59,189] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:25:59,328] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:25:59,328] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:04,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:26:09,801] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:26:14,824] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:26:19,960] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:26:25,475] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:26:30,166] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:26:35,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:26:40,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:26:45,653] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:26:50,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0365140599829563
[2022-12-07 08:26:50,894] [INFO] [runner_train_mujoco] Average state value: 0.713161871989568
[2022-12-07 08:26:50,894] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 08:26:50,952] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04101
[2022-12-07 08:26:50,998] [INFO] [controller] EPOCH 2 loss ppo:  -0.01919, loss val: 0.04096
[2022-12-07 08:26:51,045] [INFO] [controller] EPOCH 3 loss ppo:  -0.02500, loss val: 0.04149
[2022-12-07 08:26:51,092] [INFO] [controller] EPOCH 4 loss ppo:  -0.02887, loss val: 0.04143
[2022-12-07 08:26:51,099] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:26:51,263] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:26:51,264] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:56,604] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:27:01,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:27:06,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:27:11,918] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:27:16,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:27:21,950] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:27:27,561] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:27:32,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:27:38,125] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:27:43,601] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1289584439984104
[2022-12-07 08:27:43,601] [INFO] [runner_train_mujoco] Average state value: 0.7108096196651459
[2022-12-07 08:27:43,601] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 08:27:43,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.03998
[2022-12-07 08:27:43,706] [INFO] [controller] EPOCH 2 loss ppo:  -0.01797, loss val: 0.03858
[2022-12-07 08:27:43,754] [INFO] [controller] EPOCH 3 loss ppo:  -0.02663, loss val: 0.03943
[2022-12-07 08:27:43,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.03077, loss val: 0.03851
[2022-12-07 08:27:43,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:27:43,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:27:43,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:27:48,674] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:27:53,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:27:59,158] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:28:04,282] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:28:09,331] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:28:14,492] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:28:19,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:28:24,443] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:28:29,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:28:34,787] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1486346036387727
[2022-12-07 08:28:34,787] [INFO] [runner_train_mujoco] Average state value: 0.7051622028350829
[2022-12-07 08:28:34,788] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 08:28:34,849] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04156
[2022-12-07 08:28:34,891] [INFO] [controller] EPOCH 2 loss ppo:  -0.01918, loss val: 0.04121
[2022-12-07 08:28:34,936] [INFO] [controller] EPOCH 3 loss ppo:  -0.02390, loss val: 0.04158
[2022-12-07 08:28:34,976] [INFO] [controller] EPOCH 4 loss ppo:  -0.02750, loss val: 0.04143
[2022-12-07 08:28:34,986] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:28:35,151] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:28:35,151] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:28:40,293] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:28:45,371] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:28:51,001] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:28:56,351] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:29:01,155] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:06,362] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:29:11,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:29:16,476] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:29:21,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:29:26,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9871799648934132
[2022-12-07 08:29:26,769] [INFO] [runner_train_mujoco] Average state value: 0.7063177518844604
[2022-12-07 08:29:26,769] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 08:29:26,823] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04041
[2022-12-07 08:29:26,869] [INFO] [controller] EPOCH 2 loss ppo:  -0.01741, loss val: 0.04045
[2022-12-07 08:29:26,912] [INFO] [controller] EPOCH 3 loss ppo:  -0.02424, loss val: 0.04175
[2022-12-07 08:29:26,958] [INFO] [controller] EPOCH 4 loss ppo:  -0.02696, loss val: 0.04101
[2022-12-07 08:29:26,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:29:27,126] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:29:27,127] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:29:32,396] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:29:37,561] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:29:42,904] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:29:48,084] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:29:53,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:58,498] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:30:03,852] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:30:09,283] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:30:14,266] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:30:19,581] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.08232965667466
[2022-12-07 08:30:19,581] [INFO] [runner_train_mujoco] Average state value: 0.7058488543828327
[2022-12-07 08:30:19,581] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 08:30:19,640] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.04072
[2022-12-07 08:30:19,685] [INFO] [controller] EPOCH 2 loss ppo:  -0.01883, loss val: 0.04068
[2022-12-07 08:30:19,732] [INFO] [controller] EPOCH 3 loss ppo:  -0.02475, loss val: 0.04001
[2022-12-07 08:30:19,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.02645, loss val: 0.04005
[2022-12-07 08:30:19,793] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:30:19,962] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:30:19,962] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:30:24,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:30:29,785] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:30:35,256] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:30:40,587] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:30:45,712] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:30:50,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:30:55,883] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:31:00,934] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:06,239] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:11,348] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1453351161212746
[2022-12-07 08:31:11,349] [INFO] [runner_train_mujoco] Average state value: 0.706332368294398
[2022-12-07 08:31:11,349] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 08:31:11,419] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.04126
[2022-12-07 08:31:11,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.01770, loss val: 0.04136
[2022-12-07 08:31:11,516] [INFO] [controller] EPOCH 3 loss ppo:  -0.02438, loss val: 0.04021
[2022-12-07 08:31:11,562] [INFO] [controller] EPOCH 4 loss ppo:  -0.02782, loss val: 0.04059
[2022-12-07 08:31:11,571] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:11,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:11,741] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:31:17,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:31:22,719] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:31:28,245] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:31:33,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:31:38,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:31:43,563] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:31:49,051] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:31:54,218] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:59,185] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:32:04,122] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.157138713226752
[2022-12-07 08:32:04,122] [INFO] [runner_train_mujoco] Average state value: 0.7088784516652425
[2022-12-07 08:32:04,122] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 08:32:04,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.04208
[2022-12-07 08:32:04,232] [INFO] [controller] EPOCH 2 loss ppo:  -0.01660, loss val: 0.04346
[2022-12-07 08:32:04,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.02202, loss val: 0.04198
[2022-12-07 08:32:04,324] [INFO] [controller] EPOCH 4 loss ppo:  -0.02686, loss val: 0.04313
[2022-12-07 08:32:04,330] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:32:04,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:32:04,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:32:09,699] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:32:14,563] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:32:19,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:32:24,824] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:32:30,030] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:32:35,203] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:32:40,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:32:45,199] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:32:50,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:32:55,941] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1288103072861206
[2022-12-07 08:32:55,941] [INFO] [runner_train_mujoco] Average state value: 0.7166373827060064
[2022-12-07 08:32:55,941] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 08:32:55,992] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04086
[2022-12-07 08:32:56,037] [INFO] [controller] EPOCH 2 loss ppo:  -0.01651, loss val: 0.04092
[2022-12-07 08:32:56,083] [INFO] [controller] EPOCH 3 loss ppo:  -0.02181, loss val: 0.04133
[2022-12-07 08:32:56,128] [INFO] [controller] EPOCH 4 loss ppo:  -0.02494, loss val: 0.04095
[2022-12-07 08:32:56,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:32:56,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:32:56,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:01,537] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:33:07,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:33:12,396] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:33:17,459] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:33:22,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:33:27,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:33:32,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:33:38,048] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:33:43,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:33:48,811] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.197562877450655
[2022-12-07 08:33:48,812] [INFO] [runner_train_mujoco] Average state value: 0.7171746640602747
[2022-12-07 08:33:48,812] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 08:33:48,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.03937
[2022-12-07 08:33:48,921] [INFO] [controller] EPOCH 2 loss ppo:  -0.01606, loss val: 0.03956
[2022-12-07 08:33:48,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.02200, loss val: 0.03943
[2022-12-07 08:33:49,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.02562, loss val: 0.03927
[2022-12-07 08:33:49,042] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:33:49,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:33:49,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:54,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:00,065] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:34:05,079] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:34:10,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:34:15,278] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:34:20,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:34:26,165] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:34:31,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:34:36,319] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:34:41,538] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1858308810773126
[2022-12-07 08:34:41,539] [INFO] [runner_train_mujoco] Average state value: 0.7146695349216461
[2022-12-07 08:34:41,539] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 08:34:41,591] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04177
[2022-12-07 08:34:41,637] [INFO] [controller] EPOCH 2 loss ppo:  -0.01485, loss val: 0.04233
[2022-12-07 08:34:41,683] [INFO] [controller] EPOCH 3 loss ppo:  -0.01835, loss val: 0.04139
[2022-12-07 08:34:41,733] [INFO] [controller] EPOCH 4 loss ppo:  -0.02202, loss val: 0.04134
[2022-12-07 08:34:41,742] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:34:41,903] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:34:41,903] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:34:47,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:52,785] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:34:58,369] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:03,877] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:35:08,839] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:35:14,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:35:19,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:35:24,885] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:35:30,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:35:35,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.157200839889956
[2022-12-07 08:35:35,264] [INFO] [runner_train_mujoco] Average state value: 0.7137317542235057
[2022-12-07 08:35:35,264] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 08:35:35,322] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04064
[2022-12-07 08:35:35,361] [INFO] [controller] EPOCH 2 loss ppo:  -0.01446, loss val: 0.04046
[2022-12-07 08:35:35,399] [INFO] [controller] EPOCH 3 loss ppo:  -0.01731, loss val: 0.04022
[2022-12-07 08:35:35,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.02106, loss val: 0.04020
[2022-12-07 08:35:35,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:35:35,604] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:35:35,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:35:40,992] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:35:46,291] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:35:52,035] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:57,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:02,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:36:07,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:36:13,018] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:36:18,205] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:36:23,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:36:28,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2100671881793823
[2022-12-07 08:36:28,256] [INFO] [runner_train_mujoco] Average state value: 0.7137605804204941
[2022-12-07 08:36:28,256] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 08:36:28,314] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.04306
[2022-12-07 08:36:28,358] [INFO] [controller] EPOCH 2 loss ppo:  -0.01409, loss val: 0.04279
[2022-12-07 08:36:28,403] [INFO] [controller] EPOCH 3 loss ppo:  -0.01663, loss val: 0.04260
[2022-12-07 08:36:28,449] [INFO] [controller] EPOCH 4 loss ppo:  -0.01984, loss val: 0.04282
[2022-12-07 08:36:28,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:36:28,628] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:36:28,629] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:36:33,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:36:39,168] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:36:44,406] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:36:49,720] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:55,262] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:37:00,519] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:37:05,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:37:10,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:37:15,616] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:37:20,638] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2051935717341626
[2022-12-07 08:37:20,638] [INFO] [runner_train_mujoco] Average state value: 0.7135349642833073
[2022-12-07 08:37:20,638] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 08:37:20,694] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.04281
[2022-12-07 08:37:20,745] [INFO] [controller] EPOCH 2 loss ppo:  -0.01427, loss val: 0.04243
[2022-12-07 08:37:20,796] [INFO] [controller] EPOCH 3 loss ppo:  -0.01680, loss val: 0.04157
[2022-12-07 08:37:20,845] [INFO] [controller] EPOCH 4 loss ppo:  -0.01961, loss val: 0.04234
[2022-12-07 08:37:20,856] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:37:21,046] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:37:21,046] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:37:26,585] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:37:32,158] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:37:37,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:37:42,489] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:37:47,951] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:37:54,217] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:38:00,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:38:06,224] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:38:11,404] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:38:16,733] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2421501351463506
[2022-12-07 08:38:16,733] [INFO] [runner_train_mujoco] Average state value: 0.7132378858327866
[2022-12-07 08:38:16,733] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 08:38:16,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04210
[2022-12-07 08:38:16,827] [INFO] [controller] EPOCH 2 loss ppo:  -0.01403, loss val: 0.04095
[2022-12-07 08:38:16,869] [INFO] [controller] EPOCH 3 loss ppo:  -0.01516, loss val: 0.04201
[2022-12-07 08:38:16,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.01639, loss val: 0.04206
[2022-12-07 08:38:16,920] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:38:17,064] [INFO] [optimize] Finished learning.
