[2022-12-07 01:21:54,182] [INFO] [optimize] Starting learning
[2022-12-07 01:21:54,188] [INFO] [optimize] Starting learning process..
[2022-12-07 01:21:54,248] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:21:54,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:22:01,771] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:22:08,231] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:22:14,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:22:20,412] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:22:27,122] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:22:33,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:22:40,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:22:46,369] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:22:52,914] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:22:59,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.212615306192328
[2022-12-07 01:22:59,111] [INFO] [runner_train_mujoco] Average state value: 0.688311422166725
[2022-12-07 01:22:59,112] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 01:22:59,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.16053
[2022-12-07 01:22:59,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.02750, loss val: 0.14644
[2022-12-07 01:22:59,276] [INFO] [controller] EPOCH 3 loss ppo:  -0.03208, loss val: 0.13448
[2022-12-07 01:22:59,323] [INFO] [controller] EPOCH 4 loss ppo:  -0.03538, loss val: 0.12394
[2022-12-07 01:22:59,333] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:22:59,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:22:59,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:23:05,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:23:12,563] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:23:18,991] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:23:26,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:23:32,407] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:23:38,815] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:23:45,546] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:23:51,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:23:58,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:24:04,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1446925708397761
[2022-12-07 01:24:04,738] [INFO] [runner_train_mujoco] Average state value: 0.7561408711479356
[2022-12-07 01:24:04,738] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 01:24:04,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.01034, loss val: 0.11028
[2022-12-07 01:24:04,843] [INFO] [controller] EPOCH 2 loss ppo:  -0.01768, loss val: 0.10218
[2022-12-07 01:24:04,890] [INFO] [controller] EPOCH 3 loss ppo:  -0.02618, loss val: 0.09313
[2022-12-07 01:24:04,940] [INFO] [controller] EPOCH 4 loss ppo:  -0.03142, loss val: 0.08590
[2022-12-07 01:24:04,950] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:24:05,116] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:24:05,116] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:24:10,511] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:24:17,131] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:24:23,820] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:24:30,346] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:24:36,837] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:24:43,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:24:49,061] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:24:54,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:25:00,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:25:07,189] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18940643545057473
[2022-12-07 01:25:07,189] [INFO] [runner_train_mujoco] Average state value: 0.7279582645595074
[2022-12-07 01:25:07,190] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 01:25:07,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01045, loss val: 0.08179
[2022-12-07 01:25:07,311] [INFO] [controller] EPOCH 2 loss ppo:  -0.02478, loss val: 0.07755
[2022-12-07 01:25:07,368] [INFO] [controller] EPOCH 3 loss ppo:  -0.03011, loss val: 0.07263
[2022-12-07 01:25:07,426] [INFO] [controller] EPOCH 4 loss ppo:  -0.03408, loss val: 0.06630
[2022-12-07 01:25:07,438] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:25:07,601] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:25:07,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:25:14,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:25:20,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:25:27,055] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:25:32,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:25:39,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:25:45,745] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:25:52,091] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:26:00,334] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:26:07,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:26:13,094] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.12984049857381033
[2022-12-07 01:26:13,094] [INFO] [runner_train_mujoco] Average state value: 0.7497657969196638
[2022-12-07 01:26:13,094] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 01:26:13,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.00855, loss val: 0.06974
[2022-12-07 01:26:13,209] [INFO] [controller] EPOCH 2 loss ppo:  -0.01854, loss val: 0.06534
[2022-12-07 01:26:13,255] [INFO] [controller] EPOCH 3 loss ppo:  -0.02544, loss val: 0.06146
[2022-12-07 01:26:13,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.02741, loss val: 0.05876
[2022-12-07 01:26:13,315] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:26:13,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:26:13,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:26:20,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:26:26,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:26:32,827] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:26:39,657] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:26:45,965] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:26:52,152] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:26:58,881] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:27:05,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:27:11,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:27:17,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18921536580260848
[2022-12-07 01:27:17,741] [INFO] [runner_train_mujoco] Average state value: 0.7800209501783054
[2022-12-07 01:27:17,742] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 01:27:17,819] [INFO] [controller] EPOCH 1 loss ppo:  -0.00730, loss val: 0.05801
[2022-12-07 01:27:17,870] [INFO] [controller] EPOCH 2 loss ppo:  -0.01667, loss val: 0.05355
[2022-12-07 01:27:18,024] [INFO] [controller] EPOCH 3 loss ppo:  -0.02071, loss val: 0.04855
[2022-12-07 01:27:18,077] [INFO] [controller] EPOCH 4 loss ppo:  -0.02513, loss val: 0.04561
[2022-12-07 01:27:18,089] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:27:18,258] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:27:18,258] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:27:24,335] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:27:30,667] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:27:36,399] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:27:42,972] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:27:49,701] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:27:55,689] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:28:02,135] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:28:08,462] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:28:14,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:28:20,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1835242759731776
[2022-12-07 01:28:20,770] [INFO] [runner_train_mujoco] Average state value: 0.6749080088734626
[2022-12-07 01:28:20,770] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 01:28:20,834] [INFO] [controller] EPOCH 1 loss ppo:  -0.00690, loss val: 0.04938
[2022-12-07 01:28:20,883] [INFO] [controller] EPOCH 2 loss ppo:  -0.01903, loss val: 0.04976
[2022-12-07 01:28:20,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.02446, loss val: 0.04755
[2022-12-07 01:28:20,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.02680, loss val: 0.04564
[2022-12-07 01:28:21,005] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:28:21,181] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:28:21,181] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:28:27,268] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:28:33,595] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:28:39,727] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:28:46,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:28:52,273] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:28:58,748] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:29:05,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:29:11,145] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:29:17,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:29:23,649] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24346401539477042
[2022-12-07 01:29:23,649] [INFO] [runner_train_mujoco] Average state value: 0.7078756004373233
[2022-12-07 01:29:23,649] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 01:29:23,710] [INFO] [controller] EPOCH 1 loss ppo:  -0.00609, loss val: 0.04067
[2022-12-07 01:29:23,750] [INFO] [controller] EPOCH 2 loss ppo:  -0.01865, loss val: 0.03821
[2022-12-07 01:29:23,798] [INFO] [controller] EPOCH 3 loss ppo:  -0.02562, loss val: 0.04025
[2022-12-07 01:29:23,840] [INFO] [controller] EPOCH 4 loss ppo:  -0.03008, loss val: 0.03806
[2022-12-07 01:29:23,850] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:29:24,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:29:24,021] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:29:29,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:29:36,764] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:29:42,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:29:49,176] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:29:55,261] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:30:01,307] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:30:07,023] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:30:13,668] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:30:20,223] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:30:26,628] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.34270624968716257
[2022-12-07 01:30:26,629] [INFO] [runner_train_mujoco] Average state value: 0.7634234018723169
[2022-12-07 01:30:26,629] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 01:30:26,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.00684, loss val: 0.04358
[2022-12-07 01:30:26,746] [INFO] [controller] EPOCH 2 loss ppo:  -0.01990, loss val: 0.04336
[2022-12-07 01:30:26,793] [INFO] [controller] EPOCH 3 loss ppo:  -0.02361, loss val: 0.04410
[2022-12-07 01:30:26,843] [INFO] [controller] EPOCH 4 loss ppo:  -0.02662, loss val: 0.04307
[2022-12-07 01:30:26,853] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:30:27,023] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:30:27,024] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:30:33,497] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:30:40,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:30:46,239] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:30:52,480] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:30:58,150] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:31:04,165] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:31:10,465] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:31:16,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:31:22,839] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:31:29,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2813644924415964
[2022-12-07 01:31:29,273] [INFO] [runner_train_mujoco] Average state value: 0.765877135892709
[2022-12-07 01:31:29,273] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 01:31:29,333] [INFO] [controller] EPOCH 1 loss ppo:  -0.00667, loss val: 0.04896
[2022-12-07 01:31:29,378] [INFO] [controller] EPOCH 2 loss ppo:  -0.01806, loss val: 0.04590
[2022-12-07 01:31:29,426] [INFO] [controller] EPOCH 3 loss ppo:  -0.02442, loss val: 0.04167
[2022-12-07 01:31:29,472] [INFO] [controller] EPOCH 4 loss ppo:  -0.02516, loss val: 0.03958
[2022-12-07 01:31:29,482] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:31:29,648] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:31:29,648] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:31:35,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:31:42,482] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:31:48,579] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:31:55,254] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:32:01,439] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:32:07,680] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:32:14,722] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:32:21,653] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:32:27,624] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:32:33,691] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4550864331696104
[2022-12-07 01:32:33,691] [INFO] [runner_train_mujoco] Average state value: 0.6695881335735321
[2022-12-07 01:32:33,692] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 01:32:33,762] [INFO] [controller] EPOCH 1 loss ppo:  -0.00908, loss val: 0.03948
[2022-12-07 01:32:33,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.02169, loss val: 0.04116
[2022-12-07 01:32:33,856] [INFO] [controller] EPOCH 3 loss ppo:  -0.02731, loss val: 0.04179
[2022-12-07 01:32:33,903] [INFO] [controller] EPOCH 4 loss ppo:  -0.03066, loss val: 0.04152
[2022-12-07 01:32:33,913] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:32:34,078] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:32:34,079] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:32:40,414] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:32:46,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:32:52,865] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:32:58,858] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:33:05,375] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:33:11,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:33:17,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:33:23,959] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:33:29,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:33:35,929] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5264460763845953
[2022-12-07 01:33:35,930] [INFO] [runner_train_mujoco] Average state value: 0.6369110935926438
[2022-12-07 01:33:35,930] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 01:33:36,014] [INFO] [controller] EPOCH 1 loss ppo:  -0.00976, loss val: 0.04164
[2022-12-07 01:33:36,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.02000, loss val: 0.04127
[2022-12-07 01:33:36,122] [INFO] [controller] EPOCH 3 loss ppo:  -0.02364, loss val: 0.03894
[2022-12-07 01:33:36,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.02981, loss val: 0.04063
[2022-12-07 01:33:36,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:33:36,346] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:33:36,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:33:42,432] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:33:48,915] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:33:55,542] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:34:01,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:34:08,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:34:14,081] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:34:20,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:34:26,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:34:32,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:34:38,735] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5800254227084997
[2022-12-07 01:34:38,735] [INFO] [runner_train_mujoco] Average state value: 0.7014548200567563
[2022-12-07 01:34:38,736] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 01:34:38,797] [INFO] [controller] EPOCH 1 loss ppo:  -0.00938, loss val: 0.04163
[2022-12-07 01:34:38,842] [INFO] [controller] EPOCH 2 loss ppo:  -0.02000, loss val: 0.04105
[2022-12-07 01:34:38,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.02187, loss val: 0.04286
[2022-12-07 01:34:39,034] [INFO] [controller] EPOCH 4 loss ppo:  -0.02482, loss val: 0.04232
[2022-12-07 01:34:39,044] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:34:39,222] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:34:39,222] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:34:45,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:34:52,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:34:58,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:35:04,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:35:11,536] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:35:18,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:35:24,358] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:35:30,729] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:35:36,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:35:43,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7666268638119743
[2022-12-07 01:35:43,447] [INFO] [runner_train_mujoco] Average state value: 0.7311352102359135
[2022-12-07 01:35:43,447] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 01:35:43,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.01070, loss val: 0.03908
[2022-12-07 01:35:43,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.02271, loss val: 0.03887
[2022-12-07 01:35:43,611] [INFO] [controller] EPOCH 3 loss ppo:  -0.02858, loss val: 0.03874
[2022-12-07 01:35:43,657] [INFO] [controller] EPOCH 4 loss ppo:  -0.03296, loss val: 0.03933
[2022-12-07 01:35:43,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:35:43,831] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:35:43,831] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:35:49,636] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:35:56,182] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:36:02,635] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:36:08,626] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:36:14,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:36:20,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:36:26,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:36:33,144] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:36:39,995] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:36:46,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8125901498527837
[2022-12-07 01:36:46,148] [INFO] [runner_train_mujoco] Average state value: 0.7115399646957715
[2022-12-07 01:36:46,148] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 01:36:46,221] [INFO] [controller] EPOCH 1 loss ppo:  -0.00844, loss val: 0.03930
[2022-12-07 01:36:46,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.02287, loss val: 0.03812
[2022-12-07 01:36:46,323] [INFO] [controller] EPOCH 3 loss ppo:  -0.02572, loss val: 0.03705
[2022-12-07 01:36:46,374] [INFO] [controller] EPOCH 4 loss ppo:  -0.03006, loss val: 0.03720
[2022-12-07 01:36:46,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:36:46,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:36:46,552] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:36:52,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:36:59,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:37:05,259] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:37:11,638] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:37:17,797] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:37:23,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:37:30,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:37:37,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:37:43,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:37:49,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9372997192177535
[2022-12-07 01:37:49,886] [INFO] [runner_train_mujoco] Average state value: 0.6536111443638802
[2022-12-07 01:37:49,886] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 01:37:49,974] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.03299
[2022-12-07 01:37:50,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.02222, loss val: 0.03284
[2022-12-07 01:37:50,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.02771, loss val: 0.03188
[2022-12-07 01:37:50,139] [INFO] [controller] EPOCH 4 loss ppo:  -0.03521, loss val: 0.03270
[2022-12-07 01:37:50,148] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:37:50,319] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:37:50,319] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:37:56,399] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:38:02,921] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:38:08,841] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:38:15,489] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:38:21,805] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:38:27,939] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:38:34,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:38:40,758] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:38:47,183] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:38:53,501] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.133753724034753
[2022-12-07 01:38:53,501] [INFO] [runner_train_mujoco] Average state value: 0.5907378592292468
[2022-12-07 01:38:53,501] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 01:38:53,611] [INFO] [controller] EPOCH 1 loss ppo:  -0.01147, loss val: 0.04520
[2022-12-07 01:38:53,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.04425
[2022-12-07 01:38:53,732] [INFO] [controller] EPOCH 3 loss ppo:  -0.02504, loss val: 0.04054
[2022-12-07 01:38:53,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.03088, loss val: 0.03880
[2022-12-07 01:38:53,790] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:38:53,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:38:53,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:39:00,463] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:39:06,423] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:39:12,552] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:39:18,578] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:39:24,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:39:31,239] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:39:37,875] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:39:44,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:39:50,490] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:39:57,143] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.163164554982064
[2022-12-07 01:39:57,143] [INFO] [runner_train_mujoco] Average state value: 0.6630475487112999
[2022-12-07 01:39:57,143] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 01:39:57,194] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.03556
[2022-12-07 01:39:57,241] [INFO] [controller] EPOCH 2 loss ppo:  -0.02201, loss val: 0.03669
[2022-12-07 01:39:57,286] [INFO] [controller] EPOCH 3 loss ppo:  -0.02719, loss val: 0.03781
[2022-12-07 01:39:57,330] [INFO] [controller] EPOCH 4 loss ppo:  -0.02969, loss val: 0.03869
[2022-12-07 01:39:57,339] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:39:57,504] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:39:57,505] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:40:03,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:40:09,631] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:40:16,118] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:40:22,063] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:40:28,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:40:34,021] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:40:40,287] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:40:45,388] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:40:51,203] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:40:56,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2452582338197802
[2022-12-07 01:40:56,913] [INFO] [runner_train_mujoco] Average state value: 0.7087631851434708
[2022-12-07 01:40:56,913] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 01:40:56,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.00934, loss val: 0.04526
[2022-12-07 01:40:57,022] [INFO] [controller] EPOCH 2 loss ppo:  -0.01824, loss val: 0.04556
[2022-12-07 01:40:57,073] [INFO] [controller] EPOCH 3 loss ppo:  -0.02460, loss val: 0.04482
[2022-12-07 01:40:57,128] [INFO] [controller] EPOCH 4 loss ppo:  -0.03024, loss val: 0.04457
[2022-12-07 01:40:57,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:40:57,316] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:40:57,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:41:03,421] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:41:09,109] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:41:14,890] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:41:20,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:41:25,470] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:41:30,654] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:41:36,000] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:41:41,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:41:47,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:41:52,516] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3540615450892062
[2022-12-07 01:41:52,516] [INFO] [runner_train_mujoco] Average state value: 0.6866245793104172
[2022-12-07 01:41:52,516] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 01:41:52,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.03968
[2022-12-07 01:41:52,614] [INFO] [controller] EPOCH 2 loss ppo:  -0.02071, loss val: 0.04047
[2022-12-07 01:41:52,656] [INFO] [controller] EPOCH 3 loss ppo:  -0.03177, loss val: 0.04017
[2022-12-07 01:41:52,697] [INFO] [controller] EPOCH 4 loss ppo:  -0.03643, loss val: 0.03956
[2022-12-07 01:41:52,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:41:52,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:41:52,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:41:58,366] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:42:03,235] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:42:08,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:42:13,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:42:18,528] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:42:23,199] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:42:28,358] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:42:33,153] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:42:38,074] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:42:43,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4779989944598944
[2022-12-07 01:42:43,054] [INFO] [runner_train_mujoco] Average state value: 0.6821804583072663
[2022-12-07 01:42:43,054] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 01:42:43,103] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.03931
[2022-12-07 01:42:43,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.02343, loss val: 0.03925
[2022-12-07 01:42:43,178] [INFO] [controller] EPOCH 3 loss ppo:  -0.03050, loss val: 0.03920
[2022-12-07 01:42:43,218] [INFO] [controller] EPOCH 4 loss ppo:  -0.03588, loss val: 0.03998
[2022-12-07 01:42:43,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:42:43,373] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:42:43,373] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:42:48,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:42:52,650] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:42:57,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:43:02,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:43:06,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:43:11,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:43:16,410] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:43:21,844] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:43:27,088] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:43:32,083] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5907974744874867
[2022-12-07 01:43:32,083] [INFO] [runner_train_mujoco] Average state value: 0.6934100599686304
[2022-12-07 01:43:32,083] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 01:43:32,132] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04224
[2022-12-07 01:43:32,173] [INFO] [controller] EPOCH 2 loss ppo:  -0.02580, loss val: 0.04253
[2022-12-07 01:43:32,213] [INFO] [controller] EPOCH 3 loss ppo:  -0.02572, loss val: 0.04163
[2022-12-07 01:43:32,254] [INFO] [controller] EPOCH 4 loss ppo:  -0.03269, loss val: 0.04232
[2022-12-07 01:43:32,262] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:43:32,425] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:43:32,426] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:43:37,310] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:43:42,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:43:47,001] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:43:51,764] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:43:56,876] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:44:01,654] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:44:06,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:44:11,177] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:44:15,980] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:44:20,490] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5344991560476542
[2022-12-07 01:44:20,490] [INFO] [runner_train_mujoco] Average state value: 0.7175869867801666
[2022-12-07 01:44:20,490] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 01:44:20,537] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.04062
[2022-12-07 01:44:20,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.01949, loss val: 0.03985
[2022-12-07 01:44:20,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.02569, loss val: 0.04066
[2022-12-07 01:44:20,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.03212, loss val: 0.04022
[2022-12-07 01:44:20,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:44:20,799] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:44:20,800] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:44:25,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:44:30,366] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:44:35,081] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:44:40,388] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:44:45,456] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:44:50,257] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:44:55,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:45:00,439] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:45:05,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:45:10,663] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6279311665482858
[2022-12-07 01:45:10,664] [INFO] [runner_train_mujoco] Average state value: 0.6997933809558551
[2022-12-07 01:45:10,664] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 01:45:10,712] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.04311
[2022-12-07 01:45:10,813] [INFO] [controller] EPOCH 2 loss ppo:  -0.02573, loss val: 0.04295
[2022-12-07 01:45:10,851] [INFO] [controller] EPOCH 3 loss ppo:  -0.02538, loss val: 0.04396
[2022-12-07 01:45:10,892] [INFO] [controller] EPOCH 4 loss ppo:  -0.03462, loss val: 0.04411
[2022-12-07 01:45:10,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:45:11,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:45:11,057] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:45:15,739] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:45:20,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:45:25,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:45:29,840] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:45:34,665] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:45:39,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:45:44,680] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:45:49,759] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:45:54,427] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:45:59,502] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7681627535665463
[2022-12-07 01:45:59,502] [INFO] [runner_train_mujoco] Average state value: 0.6926407312552134
[2022-12-07 01:45:59,502] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 01:45:59,572] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.03898
[2022-12-07 01:45:59,621] [INFO] [controller] EPOCH 2 loss ppo:  -0.02320, loss val: 0.03899
[2022-12-07 01:45:59,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.03079, loss val: 0.03892
[2022-12-07 01:45:59,783] [INFO] [controller] EPOCH 4 loss ppo:  -0.03943, loss val: 0.03932
[2022-12-07 01:45:59,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:45:59,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:45:59,965] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:46:04,859] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:46:09,885] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:46:14,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:46:19,599] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:46:24,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:46:28,720] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:46:33,506] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:46:38,181] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:46:43,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:46:47,848] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8904351043366425
[2022-12-07 01:46:47,849] [INFO] [runner_train_mujoco] Average state value: 0.6871734789212545
[2022-12-07 01:46:47,849] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 01:46:47,896] [INFO] [controller] EPOCH 1 loss ppo:  -0.01262, loss val: 0.04152
[2022-12-07 01:46:47,948] [INFO] [controller] EPOCH 2 loss ppo:  -0.02089, loss val: 0.04306
[2022-12-07 01:46:47,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.03191, loss val: 0.04218
[2022-12-07 01:46:48,050] [INFO] [controller] EPOCH 4 loss ppo:  -0.03823, loss val: 0.04251
[2022-12-07 01:46:48,060] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:46:48,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:46:48,217] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:46:53,278] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:46:58,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:47:03,150] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:47:08,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:47:12,810] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:47:17,908] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:47:22,739] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:47:27,935] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:47:32,651] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:47:37,662] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8392487982166912
[2022-12-07 01:47:37,662] [INFO] [runner_train_mujoco] Average state value: 0.680461641430855
[2022-12-07 01:47:37,662] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 01:47:37,714] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.04032
[2022-12-07 01:47:37,756] [INFO] [controller] EPOCH 2 loss ppo:  -0.02516, loss val: 0.04141
[2022-12-07 01:47:37,802] [INFO] [controller] EPOCH 3 loss ppo:  -0.02894, loss val: 0.04008
[2022-12-07 01:47:37,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.03340, loss val: 0.04036
[2022-12-07 01:47:37,857] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:47:38,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:47:38,010] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:47:42,822] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:47:47,795] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:47:52,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:47:57,421] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:48:02,257] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:48:07,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:48:11,795] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:48:16,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:48:21,588] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:48:26,536] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7932231487946997
[2022-12-07 01:48:26,537] [INFO] [runner_train_mujoco] Average state value: 0.7002625924746195
[2022-12-07 01:48:26,537] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 01:48:26,599] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.03813
[2022-12-07 01:48:26,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.02066, loss val: 0.03837
[2022-12-07 01:48:26,680] [INFO] [controller] EPOCH 3 loss ppo:  -0.02652, loss val: 0.03860
[2022-12-07 01:48:26,720] [INFO] [controller] EPOCH 4 loss ppo:  -0.03608, loss val: 0.03718
[2022-12-07 01:48:26,728] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:48:26,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:48:26,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:48:31,716] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:48:36,684] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:48:41,785] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:48:46,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:48:51,442] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:48:56,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:49:00,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:49:05,528] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:49:10,275] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:49:14,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9320841169653833
[2022-12-07 01:49:14,979] [INFO] [runner_train_mujoco] Average state value: 0.6745793303648631
[2022-12-07 01:49:14,979] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 01:49:15,038] [INFO] [controller] EPOCH 1 loss ppo:  -0.01318, loss val: 0.03952
[2022-12-07 01:49:15,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.02239, loss val: 0.03960
[2022-12-07 01:49:15,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.03081, loss val: 0.03857
[2022-12-07 01:49:15,159] [INFO] [controller] EPOCH 4 loss ppo:  -0.03716, loss val: 0.03879
[2022-12-07 01:49:15,168] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:49:15,322] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:49:15,322] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:49:19,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:49:24,850] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:49:30,119] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:49:35,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:49:39,763] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:49:44,888] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:49:49,265] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:49:54,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:49:59,106] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:50:03,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9614860236035228
[2022-12-07 01:50:03,837] [INFO] [runner_train_mujoco] Average state value: 0.6359568654894829
[2022-12-07 01:50:03,837] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 01:50:03,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.03973
[2022-12-07 01:50:03,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.02264, loss val: 0.04129
[2022-12-07 01:50:03,961] [INFO] [controller] EPOCH 3 loss ppo:  -0.02635, loss val: 0.04121
[2022-12-07 01:50:04,001] [INFO] [controller] EPOCH 4 loss ppo:  -0.03162, loss val: 0.04037
[2022-12-07 01:50:04,010] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:50:04,165] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:50:04,165] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:50:08,631] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:50:13,250] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:50:18,005] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:50:22,901] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:50:27,230] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:50:32,302] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:50:36,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:50:41,689] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:50:46,207] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:50:50,744] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.104034154116111
[2022-12-07 01:50:50,744] [INFO] [runner_train_mujoco] Average state value: 0.6511471757491429
[2022-12-07 01:50:50,745] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 01:50:50,794] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.04414
[2022-12-07 01:50:50,832] [INFO] [controller] EPOCH 2 loss ppo:  -0.02046, loss val: 0.04380
[2022-12-07 01:50:50,870] [INFO] [controller] EPOCH 3 loss ppo:  -0.02585, loss val: 0.04314
[2022-12-07 01:50:50,909] [INFO] [controller] EPOCH 4 loss ppo:  -0.03126, loss val: 0.04440
[2022-12-07 01:50:50,918] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:50:51,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:50:51,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:50:55,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:51:00,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:51:05,497] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:51:10,406] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:51:15,226] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:51:19,712] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:51:24,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:51:29,086] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:51:33,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:51:37,939] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.038836802808018
[2022-12-07 01:51:37,939] [INFO] [runner_train_mujoco] Average state value: 0.6948981674512228
[2022-12-07 01:51:37,939] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 01:51:37,984] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.04208
[2022-12-07 01:51:38,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.02100, loss val: 0.04066
[2022-12-07 01:51:38,067] [INFO] [controller] EPOCH 3 loss ppo:  -0.02627, loss val: 0.04108
[2022-12-07 01:51:38,117] [INFO] [controller] EPOCH 4 loss ppo:  -0.03344, loss val: 0.04043
[2022-12-07 01:51:38,126] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:51:38,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:51:38,289] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:51:43,174] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:51:47,798] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:51:52,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:51:57,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:52:01,880] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:52:06,655] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:52:12,031] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:52:16,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:52:21,842] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:52:26,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.047931485040258
[2022-12-07 01:52:26,747] [INFO] [runner_train_mujoco] Average state value: 0.7200026095310846
[2022-12-07 01:52:26,747] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 01:52:26,794] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.04232
[2022-12-07 01:52:26,834] [INFO] [controller] EPOCH 2 loss ppo:  -0.02122, loss val: 0.04226
[2022-12-07 01:52:26,876] [INFO] [controller] EPOCH 3 loss ppo:  -0.02488, loss val: 0.04203
[2022-12-07 01:52:26,920] [INFO] [controller] EPOCH 4 loss ppo:  -0.03359, loss val: 0.04206
[2022-12-07 01:52:26,928] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:52:27,082] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:52:27,083] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:52:31,756] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:52:36,520] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:52:41,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:52:46,236] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:52:50,858] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:52:55,758] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:53:00,156] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:53:04,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:53:09,931] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:53:14,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1725317548881318
[2022-12-07 01:53:14,515] [INFO] [runner_train_mujoco] Average state value: 0.7091764427423477
[2022-12-07 01:53:14,515] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 01:53:14,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01198, loss val: 0.03952
[2022-12-07 01:53:14,606] [INFO] [controller] EPOCH 2 loss ppo:  -0.01764, loss val: 0.03852
[2022-12-07 01:53:14,645] [INFO] [controller] EPOCH 3 loss ppo:  -0.02441, loss val: 0.03724
[2022-12-07 01:53:14,688] [INFO] [controller] EPOCH 4 loss ppo:  -0.02771, loss val: 0.03661
[2022-12-07 01:53:14,697] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:53:14,856] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:53:14,856] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:53:19,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:53:24,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:53:29,581] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:53:34,523] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:53:39,171] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:53:44,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:53:48,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:53:53,079] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:53:57,885] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:54:02,593] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.256274808109687
[2022-12-07 01:54:02,593] [INFO] [runner_train_mujoco] Average state value: 0.6558925700982411
[2022-12-07 01:54:02,593] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 01:54:02,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.03946
[2022-12-07 01:54:02,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.02209, loss val: 0.03937
[2022-12-07 01:54:02,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.02762, loss val: 0.03960
[2022-12-07 01:54:02,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.03214, loss val: 0.04245
[2022-12-07 01:54:02,772] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:54:02,939] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:54:02,940] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:54:07,712] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:54:12,954] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:54:17,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:54:22,157] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:54:26,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:54:31,254] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:54:36,073] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:54:40,750] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:54:45,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:54:50,650] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2557940037886235
[2022-12-07 01:54:50,650] [INFO] [runner_train_mujoco] Average state value: 0.6453659765521685
[2022-12-07 01:54:50,650] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 01:54:50,696] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.04378
[2022-12-07 01:54:50,732] [INFO] [controller] EPOCH 2 loss ppo:  -0.01976, loss val: 0.04200
[2022-12-07 01:54:50,773] [INFO] [controller] EPOCH 3 loss ppo:  -0.02454, loss val: 0.04161
[2022-12-07 01:54:50,812] [INFO] [controller] EPOCH 4 loss ppo:  -0.03372, loss val: 0.04178
[2022-12-07 01:54:50,821] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:54:50,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:54:50,958] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:54:55,374] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:55:00,121] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:55:04,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:55:09,876] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:55:14,534] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:55:19,321] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:55:23,883] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:55:28,449] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:55:33,043] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:55:37,466] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.31855667369013
[2022-12-07 01:55:37,466] [INFO] [runner_train_mujoco] Average state value: 0.6872279845476151
[2022-12-07 01:55:37,466] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 01:55:37,521] [INFO] [controller] EPOCH 1 loss ppo:  -0.01566, loss val: 0.03955
[2022-12-07 01:55:37,562] [INFO] [controller] EPOCH 2 loss ppo:  -0.01705, loss val: 0.03997
[2022-12-07 01:55:37,603] [INFO] [controller] EPOCH 3 loss ppo:  -0.01714, loss val: 0.03998
[2022-12-07 01:55:37,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.02657, loss val: 0.03990
[2022-12-07 01:55:37,654] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:55:37,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:55:37,806] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:55:42,350] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:55:47,278] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:55:52,406] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:55:57,343] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:56:02,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:56:06,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:56:11,520] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:56:16,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:56:20,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:56:25,153] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2893962773895913
[2022-12-07 01:56:25,153] [INFO] [runner_train_mujoco] Average state value: 0.7067508533795676
[2022-12-07 01:56:25,154] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 01:56:25,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.04404
[2022-12-07 01:56:25,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.01730, loss val: 0.04438
[2022-12-07 01:56:25,281] [INFO] [controller] EPOCH 3 loss ppo:  -0.02265, loss val: 0.04475
[2022-12-07 01:56:25,320] [INFO] [controller] EPOCH 4 loss ppo:  -0.02786, loss val: 0.04452
[2022-12-07 01:56:25,329] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:56:25,461] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:56:25,461] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:56:30,304] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:56:34,894] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:56:40,089] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:56:44,600] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:56:49,535] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:56:54,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:56:58,994] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:57:03,556] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:57:08,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:57:13,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2865708722987454
[2022-12-07 01:57:13,342] [INFO] [runner_train_mujoco] Average state value: 0.7106258335113526
[2022-12-07 01:57:13,342] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 01:57:13,487] [INFO] [controller] EPOCH 1 loss ppo:  -0.01495, loss val: 0.04232
[2022-12-07 01:57:13,557] [INFO] [controller] EPOCH 2 loss ppo:  -0.02313, loss val: 0.04276
[2022-12-07 01:57:13,653] [INFO] [controller] EPOCH 3 loss ppo:  -0.02565, loss val: 0.04320
[2022-12-07 01:57:13,721] [INFO] [controller] EPOCH 4 loss ppo:  -0.03174, loss val: 0.04189
[2022-12-07 01:57:13,730] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:57:13,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:57:13,910] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:57:18,712] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:57:23,306] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:57:28,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:57:33,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:57:37,995] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:57:42,889] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:57:47,392] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:57:52,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:57:57,026] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:58:01,800] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3463706333472314
[2022-12-07 01:58:01,800] [INFO] [runner_train_mujoco] Average state value: 0.7021283727884293
[2022-12-07 01:58:01,800] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 01:58:01,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.04030
[2022-12-07 01:58:01,886] [INFO] [controller] EPOCH 2 loss ppo:  -0.01907, loss val: 0.04013
[2022-12-07 01:58:01,926] [INFO] [controller] EPOCH 3 loss ppo:  -0.02470, loss val: 0.03992
[2022-12-07 01:58:01,966] [INFO] [controller] EPOCH 4 loss ppo:  -0.03064, loss val: 0.04004
[2022-12-07 01:58:01,975] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:58:02,118] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:58:02,119] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:58:06,694] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:58:11,447] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:58:16,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:58:21,402] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:58:25,943] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:58:30,509] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:58:35,267] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:58:39,909] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:58:44,293] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:58:49,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4854751434360183
[2022-12-07 01:58:49,017] [INFO] [runner_train_mujoco] Average state value: 0.6839168909390767
[2022-12-07 01:58:49,017] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 01:58:49,072] [INFO] [controller] EPOCH 1 loss ppo:  -0.01156, loss val: 0.04124
[2022-12-07 01:58:49,112] [INFO] [controller] EPOCH 2 loss ppo:  -0.01591, loss val: 0.04025
[2022-12-07 01:58:49,160] [INFO] [controller] EPOCH 3 loss ppo:  -0.01869, loss val: 0.04080
[2022-12-07 01:58:49,195] [INFO] [controller] EPOCH 4 loss ppo:  -0.02539, loss val: 0.04046
[2022-12-07 01:58:49,204] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:58:49,366] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:58:49,367] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:58:53,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:58:58,428] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:59:03,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:59:08,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:59:12,617] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:59:17,121] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:59:21,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:59:26,322] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:59:31,075] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:59:35,763] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4888176604036447
[2022-12-07 01:59:35,764] [INFO] [runner_train_mujoco] Average state value: 0.6769695826768876
[2022-12-07 01:59:35,764] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 01:59:35,814] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.04245
[2022-12-07 01:59:35,853] [INFO] [controller] EPOCH 2 loss ppo:  -0.01710, loss val: 0.04216
[2022-12-07 01:59:35,897] [INFO] [controller] EPOCH 3 loss ppo:  -0.01947, loss val: 0.04206
[2022-12-07 01:59:35,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.02817, loss val: 0.04190
[2022-12-07 01:59:35,947] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:59:36,086] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:59:36,086] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:59:40,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:59:45,648] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:59:50,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:59:55,246] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:59:59,826] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:00:04,397] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:00:09,091] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:00:13,555] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:00:17,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:00:22,366] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.478098552139859
[2022-12-07 02:00:22,366] [INFO] [runner_train_mujoco] Average state value: 0.6904254777034124
[2022-12-07 02:00:22,366] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 02:00:22,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04311
[2022-12-07 02:00:22,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.01994, loss val: 0.04370
[2022-12-07 02:00:22,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.02514, loss val: 0.04359
[2022-12-07 02:00:22,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.02941, loss val: 0.04385
[2022-12-07 02:00:22,563] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:00:22,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:00:22,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:00:27,372] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:00:31,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:00:36,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:00:41,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:00:46,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:00:51,017] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:00:55,480] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:01:00,210] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:01:04,567] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:01:09,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6203859315477778
[2022-12-07 02:01:09,040] [INFO] [runner_train_mujoco] Average state value: 0.6978744460344314
[2022-12-07 02:01:09,041] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 02:01:09,095] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.04215
[2022-12-07 02:01:09,129] [INFO] [controller] EPOCH 2 loss ppo:  -0.01782, loss val: 0.04247
[2022-12-07 02:01:09,167] [INFO] [controller] EPOCH 3 loss ppo:  -0.02015, loss val: 0.04161
[2022-12-07 02:01:09,208] [INFO] [controller] EPOCH 4 loss ppo:  -0.02457, loss val: 0.04159
[2022-12-07 02:01:09,217] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:01:09,366] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:01:09,366] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:01:14,150] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:01:18,881] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:01:24,029] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:01:28,681] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:01:33,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:01:38,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:01:42,486] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:01:46,905] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:01:51,830] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:01:56,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5766807297888894
[2022-12-07 02:01:56,284] [INFO] [runner_train_mujoco] Average state value: 0.7017472923994065
[2022-12-07 02:01:56,284] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 02:01:56,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.04401
[2022-12-07 02:01:56,394] [INFO] [controller] EPOCH 2 loss ppo:  -0.01673, loss val: 0.04367
[2022-12-07 02:01:56,435] [INFO] [controller] EPOCH 3 loss ppo:  -0.01924, loss val: 0.04471
[2022-12-07 02:01:56,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.02411, loss val: 0.04492
[2022-12-07 02:01:56,483] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:01:56,653] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:01:56,653] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:02:01,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:02:06,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:02:11,326] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:02:16,220] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:02:21,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:02:25,954] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:02:30,325] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:02:34,840] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:02:39,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:02:43,945] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.53803843672991
[2022-12-07 02:02:43,946] [INFO] [runner_train_mujoco] Average state value: 0.7013808019161225
[2022-12-07 02:02:43,946] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 02:02:43,992] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.04076
[2022-12-07 02:02:44,035] [INFO] [controller] EPOCH 2 loss ppo:  -0.01653, loss val: 0.04074
[2022-12-07 02:02:44,077] [INFO] [controller] EPOCH 3 loss ppo:  -0.01873, loss val: 0.04051
[2022-12-07 02:02:44,119] [INFO] [controller] EPOCH 4 loss ppo:  -0.02559, loss val: 0.04113
[2022-12-07 02:02:44,127] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:02:44,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:02:44,279] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:02:48,877] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:02:53,603] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:02:58,300] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:03:02,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:03:07,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:03:12,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:03:16,947] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:03:21,694] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:03:26,711] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:03:31,118] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.589385302040852
[2022-12-07 02:03:31,118] [INFO] [runner_train_mujoco] Average state value: 0.6954304843346278
[2022-12-07 02:03:31,118] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 02:03:31,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.04212
[2022-12-07 02:03:31,215] [INFO] [controller] EPOCH 2 loss ppo:  -0.02224, loss val: 0.04333
[2022-12-07 02:03:31,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.02215, loss val: 0.04320
[2022-12-07 02:03:31,300] [INFO] [controller] EPOCH 4 loss ppo:  -0.02619, loss val: 0.04190
[2022-12-07 02:03:31,310] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:03:31,473] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:03:31,474] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:03:36,158] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:03:40,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:03:45,099] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:03:50,042] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:03:54,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:03:59,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:04:03,956] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:04:09,456] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:04:14,992] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:04:20,206] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5685816810218856
[2022-12-07 02:04:20,206] [INFO] [runner_train_mujoco] Average state value: 0.6844763746658961
[2022-12-07 02:04:20,206] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 02:04:20,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04182
[2022-12-07 02:04:20,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.01769, loss val: 0.04181
[2022-12-07 02:04:20,369] [INFO] [controller] EPOCH 3 loss ppo:  -0.02098, loss val: 0.04157
[2022-12-07 02:04:20,413] [INFO] [controller] EPOCH 4 loss ppo:  -0.02268, loss val: 0.04158
[2022-12-07 02:04:20,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:04:20,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:04:20,587] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:04:25,791] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:04:31,081] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:04:36,232] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:04:40,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:04:45,285] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:04:50,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:04:55,132] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:04:59,557] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:05:04,258] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:05:08,829] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.675016822769517
[2022-12-07 02:05:08,829] [INFO] [runner_train_mujoco] Average state value: 0.6793260915676752
[2022-12-07 02:05:08,829] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 02:05:08,872] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.04242
[2022-12-07 02:05:08,907] [INFO] [controller] EPOCH 2 loss ppo:  -0.02244, loss val: 0.04256
[2022-12-07 02:05:08,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.02338, loss val: 0.04193
[2022-12-07 02:05:08,990] [INFO] [controller] EPOCH 4 loss ppo:  -0.02668, loss val: 0.04143
[2022-12-07 02:05:08,999] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:05:09,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:05:09,148] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:05:13,743] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:05:18,206] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:05:22,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:05:27,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:05:31,466] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:05:36,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:05:40,403] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:05:44,697] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:05:49,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:05:54,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7300422193859855
[2022-12-07 02:05:54,420] [INFO] [runner_train_mujoco] Average state value: 0.6805575825770697
[2022-12-07 02:05:54,420] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 02:05:54,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01081, loss val: 0.04128
[2022-12-07 02:05:54,519] [INFO] [controller] EPOCH 2 loss ppo:  -0.01320, loss val: 0.04059
[2022-12-07 02:05:54,561] [INFO] [controller] EPOCH 3 loss ppo:  -0.01750, loss val: 0.04035
[2022-12-07 02:05:54,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.02304, loss val: 0.04009
[2022-12-07 02:05:54,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:05:54,764] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:05:54,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:06:00,280] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:06:05,305] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:06:09,969] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:06:14,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:06:18,896] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:06:23,290] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:06:27,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:06:32,010] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:06:36,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:06:41,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7318177706512277
[2022-12-07 02:06:41,195] [INFO] [runner_train_mujoco] Average state value: 0.6859607700904211
[2022-12-07 02:06:41,195] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 02:06:41,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.04091
[2022-12-07 02:06:41,288] [INFO] [controller] EPOCH 2 loss ppo:  -0.01339, loss val: 0.04069
[2022-12-07 02:06:41,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.01586, loss val: 0.04195
[2022-12-07 02:06:41,371] [INFO] [controller] EPOCH 4 loss ppo:  -0.01939, loss val: 0.04140
[2022-12-07 02:06:41,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:06:41,530] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:06:41,530] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:06:46,014] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:06:50,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:06:55,449] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:07:00,227] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:07:06,227] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:07:11,808] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:07:17,031] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:07:22,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:07:26,583] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:07:30,994] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7320370027085645
[2022-12-07 02:07:30,994] [INFO] [runner_train_mujoco] Average state value: 0.6915283537705739
[2022-12-07 02:07:30,994] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 02:07:31,044] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.04386
[2022-12-07 02:07:31,080] [INFO] [controller] EPOCH 2 loss ppo:  -0.01645, loss val: 0.04444
[2022-12-07 02:07:31,128] [INFO] [controller] EPOCH 3 loss ppo:  -0.02204, loss val: 0.04380
[2022-12-07 02:07:31,162] [INFO] [controller] EPOCH 4 loss ppo:  -0.02356, loss val: 0.04367
[2022-12-07 02:07:31,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:07:31,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:07:31,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:07:35,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:07:40,484] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:07:45,315] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:07:49,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:07:54,331] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:07:58,783] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:08:03,435] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:08:07,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:08:12,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:08:16,921] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7003249024643083
[2022-12-07 02:08:16,921] [INFO] [runner_train_mujoco] Average state value: 0.6994589610894522
[2022-12-07 02:08:16,921] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 02:08:16,969] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.04258
[2022-12-07 02:08:17,010] [INFO] [controller] EPOCH 2 loss ppo:  -0.01622, loss val: 0.04292
[2022-12-07 02:08:17,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.02103, loss val: 0.04266
[2022-12-07 02:08:17,091] [INFO] [controller] EPOCH 4 loss ppo:  -0.02418, loss val: 0.04242
[2022-12-07 02:08:17,100] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:08:17,259] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:08:17,260] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:08:22,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:08:26,675] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:08:31,381] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:08:36,375] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:08:40,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:08:45,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:08:49,873] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:08:54,461] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:08:59,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:09:03,455] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7231177717855
[2022-12-07 02:09:03,455] [INFO] [runner_train_mujoco] Average state value: 0.7021530969142915
[2022-12-07 02:09:03,455] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 02:09:03,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.04183
[2022-12-07 02:09:03,550] [INFO] [controller] EPOCH 2 loss ppo:  -0.01669, loss val: 0.04221
[2022-12-07 02:09:03,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.02088, loss val: 0.04175
[2022-12-07 02:09:03,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.02377, loss val: 0.04230
[2022-12-07 02:09:03,640] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:09:03,796] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:09:03,797] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:09:08,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:09:12,855] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:09:17,551] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:09:22,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:09:26,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:09:31,025] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:09:35,936] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:09:40,683] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:09:45,648] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:09:50,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7128588014851536
[2022-12-07 02:09:50,651] [INFO] [runner_train_mujoco] Average state value: 0.6998362714449564
[2022-12-07 02:09:50,651] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 02:09:50,701] [INFO] [controller] EPOCH 1 loss ppo:  -0.01239, loss val: 0.04377
[2022-12-07 02:09:50,744] [INFO] [controller] EPOCH 2 loss ppo:  -0.01367, loss val: 0.04412
[2022-12-07 02:09:50,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.01728, loss val: 0.04356
[2022-12-07 02:09:50,837] [INFO] [controller] EPOCH 4 loss ppo:  -0.02101, loss val: 0.04468
[2022-12-07 02:09:50,845] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:09:51,009] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:09:51,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:09:55,879] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:10:00,482] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:10:05,065] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:10:09,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:10:14,224] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:10:18,679] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:10:23,291] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:10:27,787] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:10:32,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:10:36,533] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.685032802375838
[2022-12-07 02:10:36,534] [INFO] [runner_train_mujoco] Average state value: 0.6963294863303504
[2022-12-07 02:10:36,534] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 02:10:36,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04537
[2022-12-07 02:10:36,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.01425, loss val: 0.04527
[2022-12-07 02:10:36,671] [INFO] [controller] EPOCH 3 loss ppo:  -0.01676, loss val: 0.04534
[2022-12-07 02:10:36,712] [INFO] [controller] EPOCH 4 loss ppo:  -0.01970, loss val: 0.04647
[2022-12-07 02:10:36,722] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:10:36,885] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:10:36,885] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:10:41,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:10:46,661] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:10:51,977] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:10:56,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:11:01,878] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:11:06,475] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:11:10,914] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:11:15,355] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:11:19,653] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:11:24,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7296786675729843
[2022-12-07 02:11:24,105] [INFO] [runner_train_mujoco] Average state value: 0.6993260544538499
[2022-12-07 02:11:24,105] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 02:11:24,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.04515
[2022-12-07 02:11:24,193] [INFO] [controller] EPOCH 2 loss ppo:  -0.01425, loss val: 0.04553
[2022-12-07 02:11:24,236] [INFO] [controller] EPOCH 3 loss ppo:  -0.01690, loss val: 0.04421
[2022-12-07 02:11:24,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.02006, loss val: 0.04463
[2022-12-07 02:11:24,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:11:24,438] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:11:24,438] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:11:28,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:11:33,652] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:11:38,663] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:11:43,161] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:11:47,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:11:52,426] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:11:57,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:12:02,423] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:12:07,050] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:12:11,753] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.777862287892828
[2022-12-07 02:12:11,753] [INFO] [runner_train_mujoco] Average state value: 0.7006579602559406
[2022-12-07 02:12:11,753] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 02:12:11,803] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.04280
[2022-12-07 02:12:11,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.01367, loss val: 0.04345
[2022-12-07 02:12:11,904] [INFO] [controller] EPOCH 3 loss ppo:  -0.01511, loss val: 0.04275
[2022-12-07 02:12:11,961] [INFO] [controller] EPOCH 4 loss ppo:  -0.01717, loss val: 0.04296
[2022-12-07 02:12:11,971] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:12:12,129] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:12:12,130] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:12:17,029] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:12:21,631] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:12:26,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:12:31,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:12:35,940] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:12:40,255] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:12:44,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:12:49,394] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:12:54,035] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:12:58,405] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8088794179219705
[2022-12-07 02:12:58,405] [INFO] [runner_train_mujoco] Average state value: 0.701442282239596
[2022-12-07 02:12:58,405] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 02:12:58,453] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.04334
[2022-12-07 02:12:58,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.01366, loss val: 0.04322
[2022-12-07 02:12:58,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.01478, loss val: 0.04324
[2022-12-07 02:12:58,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.01628, loss val: 0.04478
[2022-12-07 02:12:58,587] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:12:58,698] [INFO] [optimize] Finished learning.
