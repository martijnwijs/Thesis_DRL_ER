[2022-12-07 03:33:26,416] [INFO] [optimize] Starting learning
[2022-12-07 03:33:26,425] [INFO] [optimize] Starting learning process..
[2022-12-07 03:33:26,490] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:33:26,491] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:33:34,268] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:33:40,737] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:33:47,326] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:33:53,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:33:59,262] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:34:05,642] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:34:11,907] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:34:17,927] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:34:24,581] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:34:31,064] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2384007751920944
[2022-12-07 03:34:31,064] [INFO] [runner_train_mujoco] Average state value: -0.1844567348112663
[2022-12-07 03:34:31,064] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 03:34:31,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.01129, loss val: 0.54767
[2022-12-07 03:34:31,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.02696, loss val: 0.47485
[2022-12-07 03:34:31,227] [INFO] [controller] EPOCH 3 loss ppo:  -0.03572, loss val: 0.42572
[2022-12-07 03:34:31,274] [INFO] [controller] EPOCH 4 loss ppo:  -0.03651, loss val: 0.34661
[2022-12-07 03:34:31,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:34:31,459] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:34:31,459] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:34:38,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:34:44,514] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:34:51,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:34:57,812] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:35:03,916] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:35:10,160] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:35:16,343] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:35:22,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:35:28,748] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:35:35,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1252629421170562
[2022-12-07 03:35:35,090] [INFO] [runner_train_mujoco] Average state value: 0.00459556213207543
[2022-12-07 03:35:35,090] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 03:35:35,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01638, loss val: 0.31984
[2022-12-07 03:35:35,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03015, loss val: 0.26217
[2022-12-07 03:35:35,247] [INFO] [controller] EPOCH 3 loss ppo:  -0.03604, loss val: 0.23115
[2022-12-07 03:35:35,295] [INFO] [controller] EPOCH 4 loss ppo:  -0.03850, loss val: 0.20103
[2022-12-07 03:35:35,304] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:35:35,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:35:35,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:35:41,316] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:35:47,976] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:35:54,424] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:36:00,739] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:36:07,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:36:12,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:36:19,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:36:24,993] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:36:31,234] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:36:37,588] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.11906129586042971
[2022-12-07 03:36:37,588] [INFO] [runner_train_mujoco] Average state value: 0.19624122462483745
[2022-12-07 03:36:37,588] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 03:36:37,666] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.18411
[2022-12-07 03:36:37,722] [INFO] [controller] EPOCH 2 loss ppo:  -0.02534, loss val: 0.15800
[2022-12-07 03:36:37,779] [INFO] [controller] EPOCH 3 loss ppo:  -0.02879, loss val: 0.12952
[2022-12-07 03:36:37,837] [INFO] [controller] EPOCH 4 loss ppo:  -0.03159, loss val: 0.09699
[2022-12-07 03:36:37,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:36:38,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:36:38,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:36:44,208] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:36:50,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:36:56,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:37:03,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:37:09,021] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:37:14,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:37:21,090] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:37:27,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:37:33,419] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:37:39,649] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.12590769033040522
[2022-12-07 03:37:39,650] [INFO] [runner_train_mujoco] Average state value: 0.37875152125892547
[2022-12-07 03:37:39,650] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 03:37:39,704] [INFO] [controller] EPOCH 1 loss ppo:  -0.01049, loss val: 0.09234
[2022-12-07 03:37:39,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.02078, loss val: 0.07855
[2022-12-07 03:37:39,807] [INFO] [controller] EPOCH 3 loss ppo:  -0.02413, loss val: 0.06465
[2022-12-07 03:37:39,856] [INFO] [controller] EPOCH 4 loss ppo:  -0.02784, loss val: 0.04936
[2022-12-07 03:37:39,867] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:37:40,033] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:37:40,033] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:37:46,465] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:37:52,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:37:59,327] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:38:05,176] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:38:11,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:38:17,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:38:23,847] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:38:30,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:38:36,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:38:42,051] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20630837868174884
[2022-12-07 03:38:42,051] [INFO] [runner_train_mujoco] Average state value: 0.5302694761455059
[2022-12-07 03:38:42,051] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 03:38:42,105] [INFO] [controller] EPOCH 1 loss ppo:  -0.00804, loss val: 0.07132
[2022-12-07 03:38:42,150] [INFO] [controller] EPOCH 2 loss ppo:  -0.01915, loss val: 0.05664
[2022-12-07 03:38:42,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.02667, loss val: 0.04732
[2022-12-07 03:38:42,239] [INFO] [controller] EPOCH 4 loss ppo:  -0.03059, loss val: 0.04168
[2022-12-07 03:38:42,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:38:42,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:38:42,435] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:38:48,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:38:54,936] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:39:01,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:39:07,334] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:39:13,774] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:39:19,832] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:39:25,970] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:39:32,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:39:38,378] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:39:44,278] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1587092597981248
[2022-12-07 03:39:44,278] [INFO] [runner_train_mujoco] Average state value: 0.6892879592776298
[2022-12-07 03:39:44,278] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 03:39:44,345] [INFO] [controller] EPOCH 1 loss ppo:  -0.00563, loss val: 0.04045
[2022-12-07 03:39:44,395] [INFO] [controller] EPOCH 2 loss ppo:  -0.01895, loss val: 0.04029
[2022-12-07 03:39:44,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.02455, loss val: 0.03885
[2022-12-07 03:39:44,512] [INFO] [controller] EPOCH 4 loss ppo:  -0.02813, loss val: 0.03968
[2022-12-07 03:39:44,522] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:39:44,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:39:44,722] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:39:51,128] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:39:57,575] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:40:03,753] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:40:09,838] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:40:15,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:40:21,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:40:27,745] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:40:33,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:40:39,759] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:40:45,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1212674813614663
[2022-12-07 03:40:45,888] [INFO] [runner_train_mujoco] Average state value: 0.7743236130475998
[2022-12-07 03:40:45,888] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 03:40:45,947] [INFO] [controller] EPOCH 1 loss ppo:  -0.00497, loss val: 0.04306
[2022-12-07 03:40:46,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.01433, loss val: 0.04326
[2022-12-07 03:40:46,075] [INFO] [controller] EPOCH 3 loss ppo:  -0.02043, loss val: 0.04323
[2022-12-07 03:40:46,128] [INFO] [controller] EPOCH 4 loss ppo:  -0.02455, loss val: 0.04290
[2022-12-07 03:40:46,140] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:40:46,328] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:40:46,328] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:40:52,463] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:40:58,884] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:41:04,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:41:10,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:41:16,686] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:41:22,843] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:41:28,896] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:41:35,003] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:41:41,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:41:47,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1888845173461857
[2022-12-07 03:41:47,285] [INFO] [runner_train_mujoco] Average state value: 0.7712799458901087
[2022-12-07 03:41:47,285] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 03:41:47,338] [INFO] [controller] EPOCH 1 loss ppo:  -0.00584, loss val: 0.04455
[2022-12-07 03:41:47,382] [INFO] [controller] EPOCH 2 loss ppo:  -0.01734, loss val: 0.04402
[2022-12-07 03:41:47,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.01889, loss val: 0.04388
[2022-12-07 03:41:47,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.02264, loss val: 0.04498
[2022-12-07 03:41:47,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:41:47,655] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:41:47,655] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:41:53,899] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:42:00,058] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:42:06,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:42:12,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:42:18,402] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:42:24,359] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:42:30,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:42:35,995] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:42:41,993] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:42:47,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22593411016996492
[2022-12-07 03:42:47,378] [INFO] [runner_train_mujoco] Average state value: 0.7300432781775792
[2022-12-07 03:42:47,379] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 03:42:47,428] [INFO] [controller] EPOCH 1 loss ppo:  -0.00707, loss val: 0.04112
[2022-12-07 03:42:47,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.01602, loss val: 0.04203
[2022-12-07 03:42:47,511] [INFO] [controller] EPOCH 3 loss ppo:  -0.02071, loss val: 0.04101
[2022-12-07 03:42:47,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.02550, loss val: 0.04259
[2022-12-07 03:42:47,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:42:47,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:42:47,733] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:42:53,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:42:59,095] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:43:05,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:43:10,557] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:43:16,140] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:43:22,494] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:43:28,217] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:43:33,528] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:43:38,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:43:44,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37736629238292163
[2022-12-07 03:43:44,034] [INFO] [runner_train_mujoco] Average state value: 0.7061216738621393
[2022-12-07 03:43:44,034] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 03:43:44,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.00755, loss val: 0.03834
[2022-12-07 03:43:44,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.01745, loss val: 0.03815
[2022-12-07 03:43:44,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.02252, loss val: 0.03793
[2022-12-07 03:43:44,205] [INFO] [controller] EPOCH 4 loss ppo:  -0.02673, loss val: 0.03779
[2022-12-07 03:43:44,215] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:43:44,372] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:43:44,372] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:43:49,592] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:43:55,096] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:44:00,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:44:06,905] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:44:13,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:44:19,090] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:44:24,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:44:29,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:44:34,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:44:40,049] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46688151011504414
[2022-12-07 03:44:40,049] [INFO] [runner_train_mujoco] Average state value: 0.7119160187641779
[2022-12-07 03:44:40,049] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 03:44:40,099] [INFO] [controller] EPOCH 1 loss ppo:  -0.00705, loss val: 0.03855
[2022-12-07 03:44:40,138] [INFO] [controller] EPOCH 2 loss ppo:  -0.01538, loss val: 0.03792
[2022-12-07 03:44:40,176] [INFO] [controller] EPOCH 3 loss ppo:  -0.02178, loss val: 0.03847
[2022-12-07 03:44:40,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.02712, loss val: 0.03838
[2022-12-07 03:44:40,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:44:40,382] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:44:40,382] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:44:45,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:44:51,333] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:44:56,825] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:45:01,974] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:45:06,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:45:11,620] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:45:16,380] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:45:21,247] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:45:26,402] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:45:31,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44172138481742584
[2022-12-07 03:45:31,273] [INFO] [runner_train_mujoco] Average state value: 0.7025701961119969
[2022-12-07 03:45:31,273] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 03:45:31,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.00887, loss val: 0.03212
[2022-12-07 03:45:31,366] [INFO] [controller] EPOCH 2 loss ppo:  -0.02217, loss val: 0.03192
[2022-12-07 03:45:31,410] [INFO] [controller] EPOCH 3 loss ppo:  -0.02678, loss val: 0.03090
[2022-12-07 03:45:31,450] [INFO] [controller] EPOCH 4 loss ppo:  -0.02868, loss val: 0.03259
[2022-12-07 03:45:31,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:45:31,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:45:31,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:45:36,401] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:45:41,646] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:45:46,666] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:45:51,206] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:45:56,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:46:00,823] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:46:05,923] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:46:10,815] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:46:15,596] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:46:20,368] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.43615438752570973
[2022-12-07 03:46:20,369] [INFO] [runner_train_mujoco] Average state value: 0.6889167097210883
[2022-12-07 03:46:20,369] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 03:46:20,418] [INFO] [controller] EPOCH 1 loss ppo:  -0.00754, loss val: 0.03780
[2022-12-07 03:46:20,456] [INFO] [controller] EPOCH 2 loss ppo:  -0.02393, loss val: 0.03847
[2022-12-07 03:46:20,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.02783, loss val: 0.03864
[2022-12-07 03:46:20,538] [INFO] [controller] EPOCH 4 loss ppo:  -0.03339, loss val: 0.03688
[2022-12-07 03:46:20,547] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:46:20,699] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:46:20,699] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:46:25,407] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:46:30,610] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:46:35,156] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:46:40,550] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:46:46,404] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:46:52,301] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:46:57,360] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:47:02,472] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:47:07,325] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:47:12,293] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6281523200870146
[2022-12-07 03:47:12,293] [INFO] [runner_train_mujoco] Average state value: 0.6839926833311717
[2022-12-07 03:47:12,293] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 03:47:12,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.00889, loss val: 0.03815
[2022-12-07 03:47:12,377] [INFO] [controller] EPOCH 2 loss ppo:  -0.02380, loss val: 0.03755
[2022-12-07 03:47:12,421] [INFO] [controller] EPOCH 3 loss ppo:  -0.02979, loss val: 0.03774
[2022-12-07 03:47:12,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.03153, loss val: 0.03742
[2022-12-07 03:47:12,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:47:12,620] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:47:12,620] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:47:17,652] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:47:22,269] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:47:27,010] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:47:31,632] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:47:36,376] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:47:41,169] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:47:46,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:47:51,849] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:47:56,662] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:48:01,538] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7251082410264689
[2022-12-07 03:48:01,538] [INFO] [runner_train_mujoco] Average state value: 0.6942578357855479
[2022-12-07 03:48:01,538] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 03:48:01,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.00841, loss val: 0.04105
[2022-12-07 03:48:01,633] [INFO] [controller] EPOCH 2 loss ppo:  -0.02336, loss val: 0.04074
[2022-12-07 03:48:01,675] [INFO] [controller] EPOCH 3 loss ppo:  -0.02721, loss val: 0.04066
[2022-12-07 03:48:01,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.02724, loss val: 0.04093
[2022-12-07 03:48:01,728] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:48:01,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:48:01,899] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:48:07,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:48:11,879] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:48:16,427] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:48:21,290] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:48:26,180] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:48:30,735] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:48:35,323] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:48:40,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:48:44,975] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:48:49,551] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8576277675398462
[2022-12-07 03:48:49,551] [INFO] [runner_train_mujoco] Average state value: 0.7273383613824844
[2022-12-07 03:48:49,551] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 03:48:49,611] [INFO] [controller] EPOCH 1 loss ppo:  -0.01111, loss val: 0.03928
[2022-12-07 03:48:49,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.02492, loss val: 0.03935
[2022-12-07 03:48:49,728] [INFO] [controller] EPOCH 3 loss ppo:  -0.02907, loss val: 0.03915
[2022-12-07 03:48:49,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.03296, loss val: 0.03994
[2022-12-07 03:48:49,780] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:48:49,942] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:48:49,942] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:48:55,132] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:48:59,973] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:49:05,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:49:10,068] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:49:14,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:49:19,317] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:49:24,078] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:49:28,915] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:49:33,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:49:38,647] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0710848671649251
[2022-12-07 03:49:38,647] [INFO] [runner_train_mujoco] Average state value: 0.719804914077123
[2022-12-07 03:49:38,647] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 03:49:38,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.03638
[2022-12-07 03:49:38,739] [INFO] [controller] EPOCH 2 loss ppo:  -0.02496, loss val: 0.03533
[2022-12-07 03:49:38,779] [INFO] [controller] EPOCH 3 loss ppo:  -0.02912, loss val: 0.03477
[2022-12-07 03:49:38,819] [INFO] [controller] EPOCH 4 loss ppo:  -0.03354, loss val: 0.03453
[2022-12-07 03:49:38,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:49:38,979] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:49:38,980] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:49:43,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:49:48,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:49:53,495] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:49:58,121] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:50:02,662] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:50:07,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:50:12,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:50:17,134] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:50:21,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:50:26,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1035768216884092
[2022-12-07 03:50:26,779] [INFO] [runner_train_mujoco] Average state value: 0.66933869745334
[2022-12-07 03:50:26,779] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 03:50:26,831] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.04230
[2022-12-07 03:50:26,873] [INFO] [controller] EPOCH 2 loss ppo:  -0.02432, loss val: 0.04425
[2022-12-07 03:50:26,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.03070, loss val: 0.04195
[2022-12-07 03:50:26,954] [INFO] [controller] EPOCH 4 loss ppo:  -0.03391, loss val: 0.04071
[2022-12-07 03:50:26,962] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:50:27,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:50:27,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:50:31,758] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:50:37,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:50:41,957] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:50:46,894] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:50:51,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:50:56,354] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:51:00,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:51:05,505] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:51:10,164] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:51:14,941] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0331958594782644
[2022-12-07 03:51:14,941] [INFO] [runner_train_mujoco] Average state value: 0.7056960908969243
[2022-12-07 03:51:14,941] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 03:51:14,986] [INFO] [controller] EPOCH 1 loss ppo:  -0.01088, loss val: 0.03435
[2022-12-07 03:51:15,025] [INFO] [controller] EPOCH 2 loss ppo:  -0.02342, loss val: 0.03572
[2022-12-07 03:51:15,064] [INFO] [controller] EPOCH 3 loss ppo:  -0.02812, loss val: 0.03647
[2022-12-07 03:51:15,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.03419, loss val: 0.03512
[2022-12-07 03:51:15,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:51:15,261] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:51:15,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:51:20,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:51:25,118] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:51:30,258] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:51:35,180] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:51:40,298] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:51:45,216] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:51:50,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:51:54,983] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:51:59,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:52:04,624] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.020440394678927
[2022-12-07 03:52:04,625] [INFO] [runner_train_mujoco] Average state value: 0.7211607093811035
[2022-12-07 03:52:04,625] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 03:52:04,674] [INFO] [controller] EPOCH 1 loss ppo:  -0.00897, loss val: 0.04018
[2022-12-07 03:52:04,707] [INFO] [controller] EPOCH 2 loss ppo:  -0.02060, loss val: 0.03999
[2022-12-07 03:52:04,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.02790, loss val: 0.03868
[2022-12-07 03:52:04,783] [INFO] [controller] EPOCH 4 loss ppo:  -0.03360, loss val: 0.03926
[2022-12-07 03:52:04,793] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:52:04,954] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:52:04,954] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:52:09,708] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:52:14,607] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:52:19,312] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:52:23,963] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:52:28,930] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:52:33,818] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:52:39,075] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:52:43,877] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:52:48,365] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:52:53,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0642440285314727
[2022-12-07 03:52:53,257] [INFO] [runner_train_mujoco] Average state value: 0.6905496213436126
[2022-12-07 03:52:53,257] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 03:52:53,306] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.04046
[2022-12-07 03:52:53,343] [INFO] [controller] EPOCH 2 loss ppo:  -0.02388, loss val: 0.04149
[2022-12-07 03:52:53,388] [INFO] [controller] EPOCH 3 loss ppo:  -0.02677, loss val: 0.04137
[2022-12-07 03:52:53,433] [INFO] [controller] EPOCH 4 loss ppo:  -0.03541, loss val: 0.04104
[2022-12-07 03:52:53,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:52:53,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:52:53,597] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:52:58,582] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:53:03,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:53:08,435] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:53:12,682] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:53:17,064] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:53:21,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:53:26,491] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:53:31,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:53:35,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:53:40,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3331995158387828
[2022-12-07 03:53:40,640] [INFO] [runner_train_mujoco] Average state value: 0.6799246396422386
[2022-12-07 03:53:40,640] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 03:53:40,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.01020, loss val: 0.03606
[2022-12-07 03:53:40,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.01993, loss val: 0.03601
[2022-12-07 03:53:40,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.02466, loss val: 0.03610
[2022-12-07 03:53:40,798] [INFO] [controller] EPOCH 4 loss ppo:  -0.02880, loss val: 0.03654
[2022-12-07 03:53:40,807] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:53:40,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:53:40,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:53:45,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:53:50,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:53:55,548] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:54:00,196] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:54:05,149] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:54:09,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:54:14,243] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:54:19,012] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:54:23,579] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:54:28,428] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4432634840953371
[2022-12-07 03:54:28,428] [INFO] [runner_train_mujoco] Average state value: 0.6897029118537904
[2022-12-07 03:54:28,428] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 03:54:28,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.03827
[2022-12-07 03:54:28,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.02284, loss val: 0.03813
[2022-12-07 03:54:28,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.03072, loss val: 0.03746
[2022-12-07 03:54:28,658] [INFO] [controller] EPOCH 4 loss ppo:  -0.03765, loss val: 0.03730
[2022-12-07 03:54:28,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:54:28,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:54:28,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:54:33,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:54:38,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:54:42,845] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:54:47,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:54:51,853] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:54:56,415] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:55:01,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:55:05,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:55:10,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:55:15,489] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4407072264203262
[2022-12-07 03:55:15,489] [INFO] [runner_train_mujoco] Average state value: 0.677034064968427
[2022-12-07 03:55:15,489] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 03:55:15,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04138
[2022-12-07 03:55:15,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.02262, loss val: 0.04033
[2022-12-07 03:55:15,625] [INFO] [controller] EPOCH 3 loss ppo:  -0.02602, loss val: 0.04297
[2022-12-07 03:55:15,733] [INFO] [controller] EPOCH 4 loss ppo:  -0.03460, loss val: 0.04012
[2022-12-07 03:55:15,742] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:55:15,913] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:55:15,913] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:55:20,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:55:25,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:55:30,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:55:35,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:55:40,107] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:55:44,692] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:55:49,281] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:55:53,867] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:55:58,498] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:56:03,410] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5075579613520953
[2022-12-07 03:56:03,411] [INFO] [runner_train_mujoco] Average state value: 0.6774571306308109
[2022-12-07 03:56:03,411] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 03:56:03,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.03919
[2022-12-07 03:56:03,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.02487, loss val: 0.03765
[2022-12-07 03:56:03,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.03062, loss val: 0.03838
[2022-12-07 03:56:03,572] [INFO] [controller] EPOCH 4 loss ppo:  -0.03575, loss val: 0.03784
[2022-12-07 03:56:03,581] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:56:03,727] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:56:03,727] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:56:08,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:56:13,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:56:18,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:56:23,187] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:56:28,010] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:56:32,927] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:56:37,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:56:42,306] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:56:46,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:56:51,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5646422982109707
[2022-12-07 03:56:51,218] [INFO] [runner_train_mujoco] Average state value: 0.6884675497611364
[2022-12-07 03:56:51,219] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 03:56:51,264] [INFO] [controller] EPOCH 1 loss ppo:  -0.01176, loss val: 0.03988
[2022-12-07 03:56:51,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.02538, loss val: 0.03920
[2022-12-07 03:56:51,339] [INFO] [controller] EPOCH 3 loss ppo:  -0.03323, loss val: 0.03912
[2022-12-07 03:56:51,378] [INFO] [controller] EPOCH 4 loss ppo:  -0.03576, loss val: 0.03867
[2022-12-07 03:56:51,387] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:56:51,531] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:56:51,532] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:56:56,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:57:01,007] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:57:05,425] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:57:09,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:57:14,548] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:57:19,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:57:23,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:57:28,259] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:57:32,679] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:57:37,781] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8566006596059477
[2022-12-07 03:57:37,781] [INFO] [runner_train_mujoco] Average state value: 0.699482928554217
[2022-12-07 03:57:37,781] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 03:57:37,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.04124
[2022-12-07 03:57:37,885] [INFO] [controller] EPOCH 2 loss ppo:  -0.02185, loss val: 0.04159
[2022-12-07 03:57:37,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.02302, loss val: 0.04159
[2022-12-07 03:57:37,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.03285, loss val: 0.04163
[2022-12-07 03:57:37,977] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:57:38,124] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:57:38,124] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:57:42,878] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:57:48,593] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:57:53,125] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:57:57,739] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:58:02,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:58:06,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:58:10,983] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:58:15,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:58:19,970] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:58:24,712] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9007779539938503
[2022-12-07 03:58:24,712] [INFO] [runner_train_mujoco] Average state value: 0.7060348109006883
[2022-12-07 03:58:24,712] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 03:58:24,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.03933
[2022-12-07 03:58:24,799] [INFO] [controller] EPOCH 2 loss ppo:  -0.02054, loss val: 0.03873
[2022-12-07 03:58:24,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.02538, loss val: 0.04036
[2022-12-07 03:58:24,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.03467, loss val: 0.03901
[2022-12-07 03:58:24,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:58:25,046] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:58:25,047] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:58:29,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:58:34,181] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:58:39,258] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:58:43,621] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:58:48,256] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:58:53,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:58:57,900] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:59:02,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:59:07,396] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:59:11,849] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.038326615257595
[2022-12-07 03:59:11,850] [INFO] [runner_train_mujoco] Average state value: 0.6957669219970704
[2022-12-07 03:59:11,850] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 03:59:11,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04399
[2022-12-07 03:59:11,951] [INFO] [controller] EPOCH 2 loss ppo:  -0.02024, loss val: 0.04372
[2022-12-07 03:59:11,993] [INFO] [controller] EPOCH 3 loss ppo:  -0.02580, loss val: 0.04361
[2022-12-07 03:59:12,033] [INFO] [controller] EPOCH 4 loss ppo:  -0.03469, loss val: 0.04351
[2022-12-07 03:59:12,041] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:59:12,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:59:12,184] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:59:16,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:59:21,389] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:59:25,845] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:59:29,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:59:34,362] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:59:39,239] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:59:44,130] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:59:49,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:59:53,294] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:59:58,268] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0632926790073776
[2022-12-07 03:59:58,268] [INFO] [runner_train_mujoco] Average state value: 0.6771795506079992
[2022-12-07 03:59:58,268] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 03:59:58,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.04543
[2022-12-07 03:59:58,352] [INFO] [controller] EPOCH 2 loss ppo:  -0.02390, loss val: 0.04595
[2022-12-07 03:59:58,393] [INFO] [controller] EPOCH 3 loss ppo:  -0.02594, loss val: 0.04582
[2022-12-07 03:59:58,431] [INFO] [controller] EPOCH 4 loss ppo:  -0.03500, loss val: 0.04570
[2022-12-07 03:59:58,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:59:58,586] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:59:58,587] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:00:03,401] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:00:08,364] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:00:13,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:00:18,210] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:00:22,574] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:00:26,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:00:31,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:00:35,680] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:00:40,434] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:00:44,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1505059248635536
[2022-12-07 04:00:44,894] [INFO] [runner_train_mujoco] Average state value: 0.6840860572258631
[2022-12-07 04:00:44,894] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 04:00:44,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04192
[2022-12-07 04:00:44,983] [INFO] [controller] EPOCH 2 loss ppo:  -0.01545, loss val: 0.04165
[2022-12-07 04:00:45,023] [INFO] [controller] EPOCH 3 loss ppo:  -0.02482, loss val: 0.04173
[2022-12-07 04:00:45,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.03187, loss val: 0.04109
[2022-12-07 04:00:45,072] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:00:45,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:00:45,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:00:50,069] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:00:54,370] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:00:59,274] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:01:03,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:01:08,315] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:01:12,941] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:01:17,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:01:22,339] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:01:26,941] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:01:31,226] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4134484764495348
[2022-12-07 04:01:31,227] [INFO] [runner_train_mujoco] Average state value: 0.7013972481091818
[2022-12-07 04:01:31,227] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 04:01:31,274] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.03893
[2022-12-07 04:01:31,314] [INFO] [controller] EPOCH 2 loss ppo:  -0.02284, loss val: 0.03920
[2022-12-07 04:01:31,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.02707, loss val: 0.03905
[2022-12-07 04:01:31,394] [INFO] [controller] EPOCH 4 loss ppo:  -0.03322, loss val: 0.03995
[2022-12-07 04:01:31,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:01:31,543] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:01:31,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:01:36,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:01:41,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:01:45,814] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:01:50,186] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:01:54,527] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:01:59,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:02:03,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:02:08,014] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:02:12,545] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:02:17,172] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.37823060037231
[2022-12-07 04:02:17,172] [INFO] [runner_train_mujoco] Average state value: 0.702740548491478
[2022-12-07 04:02:17,172] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 04:02:17,231] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04034
[2022-12-07 04:02:17,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.01983, loss val: 0.04052
[2022-12-07 04:02:17,311] [INFO] [controller] EPOCH 3 loss ppo:  -0.02746, loss val: 0.04166
[2022-12-07 04:02:17,353] [INFO] [controller] EPOCH 4 loss ppo:  -0.03333, loss val: 0.04046
[2022-12-07 04:02:17,363] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:02:17,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:02:17,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:02:21,768] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:02:26,289] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:02:31,260] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:02:35,907] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:02:40,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:02:45,071] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:02:49,317] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:02:53,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:02:58,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:03:02,504] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4684645401473166
[2022-12-07 04:03:02,504] [INFO] [runner_train_mujoco] Average state value: 0.6892580099503199
[2022-12-07 04:03:02,504] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 04:03:02,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.03937
[2022-12-07 04:03:02,583] [INFO] [controller] EPOCH 2 loss ppo:  -0.02168, loss val: 0.03989
[2022-12-07 04:03:02,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.02438, loss val: 0.03998
[2022-12-07 04:03:02,662] [INFO] [controller] EPOCH 4 loss ppo:  -0.03185, loss val: 0.03918
[2022-12-07 04:03:02,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:03:02,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:03:02,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:03:07,257] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:03:12,239] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:03:16,710] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:03:21,355] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:03:25,842] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:03:30,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:03:35,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:03:39,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:03:44,600] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:03:49,350] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.449558535957544
[2022-12-07 04:03:49,350] [INFO] [runner_train_mujoco] Average state value: 0.6628913318713505
[2022-12-07 04:03:49,350] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 04:03:49,397] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04320
[2022-12-07 04:03:49,431] [INFO] [controller] EPOCH 2 loss ppo:  -0.02045, loss val: 0.04360
[2022-12-07 04:03:49,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.02402, loss val: 0.04340
[2022-12-07 04:03:49,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.03179, loss val: 0.04317
[2022-12-07 04:03:49,522] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:03:49,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:03:49,679] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:03:54,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:03:58,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:04:03,269] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:04:07,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:04:12,015] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:04:16,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:04:21,391] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:04:25,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:04:30,452] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:04:35,018] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.497645937326697
[2022-12-07 04:04:35,018] [INFO] [runner_train_mujoco] Average state value: 0.6598955239057542
[2022-12-07 04:04:35,018] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 04:04:35,067] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.03951
[2022-12-07 04:04:35,108] [INFO] [controller] EPOCH 2 loss ppo:  -0.01943, loss val: 0.03900
[2022-12-07 04:04:35,149] [INFO] [controller] EPOCH 3 loss ppo:  -0.02473, loss val: 0.04028
[2022-12-07 04:04:35,186] [INFO] [controller] EPOCH 4 loss ppo:  -0.03171, loss val: 0.03847
[2022-12-07 04:04:35,195] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:04:35,353] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:04:35,353] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:04:39,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:04:44,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:04:49,205] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:04:53,657] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:04:58,253] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:05:02,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:05:07,276] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:05:11,711] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:05:16,023] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:05:20,392] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.615190117015937
[2022-12-07 04:05:20,392] [INFO] [runner_train_mujoco] Average state value: 0.6556981912851334
[2022-12-07 04:05:20,392] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 04:05:20,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.03926
[2022-12-07 04:05:20,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.02332, loss val: 0.03954
[2022-12-07 04:05:20,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.02484, loss val: 0.03867
[2022-12-07 04:05:20,571] [INFO] [controller] EPOCH 4 loss ppo:  -0.02875, loss val: 0.03905
[2022-12-07 04:05:20,580] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:05:20,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:05:20,726] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:05:25,028] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:05:29,550] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:05:34,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:05:38,869] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:05:43,658] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:05:48,067] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:05:52,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:05:57,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:06:01,522] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:06:06,035] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6142500998304294
[2022-12-07 04:06:06,036] [INFO] [runner_train_mujoco] Average state value: 0.6566333098808924
[2022-12-07 04:06:06,036] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 04:06:06,083] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.03825
[2022-12-07 04:06:06,119] [INFO] [controller] EPOCH 2 loss ppo:  -0.01787, loss val: 0.04113
[2022-12-07 04:06:06,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.02268, loss val: 0.03841
[2022-12-07 04:06:06,201] [INFO] [controller] EPOCH 4 loss ppo:  -0.02976, loss val: 0.03815
[2022-12-07 04:06:06,210] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:06:06,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:06:06,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:06:11,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:06:15,649] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:06:20,352] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:06:24,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:06:28,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:06:33,245] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:06:37,738] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:06:42,420] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:06:46,676] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:06:51,087] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.709811302770466
[2022-12-07 04:06:51,087] [INFO] [runner_train_mujoco] Average state value: 0.665431145588557
[2022-12-07 04:06:51,087] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 04:06:51,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04359
[2022-12-07 04:06:51,181] [INFO] [controller] EPOCH 2 loss ppo:  -0.02016, loss val: 0.04355
[2022-12-07 04:06:51,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.02285, loss val: 0.04403
[2022-12-07 04:06:51,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.03093, loss val: 0.04354
[2022-12-07 04:06:51,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:06:51,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:06:51,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:06:56,276] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:07:01,004] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:07:07,399] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:07:12,552] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:07:17,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:07:22,262] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:07:26,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:07:31,170] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:07:35,686] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:07:40,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.770361507994456
[2022-12-07 04:07:40,045] [INFO] [runner_train_mujoco] Average state value: 0.6749338369369506
[2022-12-07 04:07:40,046] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 04:07:40,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.03891
[2022-12-07 04:07:40,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.02030, loss val: 0.04031
[2022-12-07 04:07:40,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.02269, loss val: 0.03922
[2022-12-07 04:07:40,210] [INFO] [controller] EPOCH 4 loss ppo:  -0.02618, loss val: 0.03923
[2022-12-07 04:07:40,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:07:40,362] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:07:40,362] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:07:44,565] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:07:48,969] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:07:53,499] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:07:57,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:08:02,528] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:08:07,289] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:08:11,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:08:16,141] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:08:20,614] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:08:24,911] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8021739214015424
[2022-12-07 04:08:24,911] [INFO] [runner_train_mujoco] Average state value: 0.6731941732565561
[2022-12-07 04:08:24,912] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 04:08:24,963] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04057
[2022-12-07 04:08:25,004] [INFO] [controller] EPOCH 2 loss ppo:  -0.01719, loss val: 0.03959
[2022-12-07 04:08:25,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.01759, loss val: 0.03883
[2022-12-07 04:08:25,087] [INFO] [controller] EPOCH 4 loss ppo:  -0.02370, loss val: 0.03914
[2022-12-07 04:08:25,095] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:08:25,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:08:25,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:08:29,473] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:08:33,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:08:38,416] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:08:42,777] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:08:47,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:08:51,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:08:56,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:09:00,888] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:09:05,357] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:09:10,061] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8206549819293993
[2022-12-07 04:09:10,062] [INFO] [runner_train_mujoco] Average state value: 0.6570965167681375
[2022-12-07 04:09:10,062] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 04:09:10,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.03776
[2022-12-07 04:09:10,145] [INFO] [controller] EPOCH 2 loss ppo:  -0.01758, loss val: 0.03841
[2022-12-07 04:09:10,183] [INFO] [controller] EPOCH 3 loss ppo:  -0.01913, loss val: 0.03769
[2022-12-07 04:09:10,221] [INFO] [controller] EPOCH 4 loss ppo:  -0.02553, loss val: 0.03823
[2022-12-07 04:09:10,229] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:09:10,378] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:09:10,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:09:14,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:09:19,744] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:09:23,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:09:28,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:09:32,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:09:37,112] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:09:41,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:09:45,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:09:51,055] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:09:55,234] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8686352246820186
[2022-12-07 04:09:55,234] [INFO] [runner_train_mujoco] Average state value: 0.6419062137206395
[2022-12-07 04:09:55,234] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 04:09:55,289] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.03966
[2022-12-07 04:09:55,329] [INFO] [controller] EPOCH 2 loss ppo:  -0.02208, loss val: 0.03886
[2022-12-07 04:09:55,370] [INFO] [controller] EPOCH 3 loss ppo:  -0.02321, loss val: 0.03883
[2022-12-07 04:09:55,406] [INFO] [controller] EPOCH 4 loss ppo:  -0.02532, loss val: 0.03959
[2022-12-07 04:09:55,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:09:55,560] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:09:55,561] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:10:00,356] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:10:04,965] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:10:09,114] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:10:13,510] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:10:17,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:10:22,158] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:10:26,749] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:10:31,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:10:36,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:10:40,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9176019914539597
[2022-12-07 04:10:40,738] [INFO] [runner_train_mujoco] Average state value: 0.6420988394419352
[2022-12-07 04:10:40,738] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 04:10:40,787] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.04122
[2022-12-07 04:10:40,829] [INFO] [controller] EPOCH 2 loss ppo:  -0.01728, loss val: 0.04055
[2022-12-07 04:10:40,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.01818, loss val: 0.03940
[2022-12-07 04:10:40,916] [INFO] [controller] EPOCH 4 loss ppo:  -0.02364, loss val: 0.03865
[2022-12-07 04:10:40,925] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:10:41,075] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:10:41,075] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:10:45,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:10:49,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:10:54,267] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:10:58,518] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:11:03,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:11:07,340] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:11:11,787] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:11:15,876] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:11:20,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:11:24,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.853768621201943
[2022-12-07 04:11:24,484] [INFO] [runner_train_mujoco] Average state value: 0.6672450131177903
[2022-12-07 04:11:24,484] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 04:11:24,541] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.04411
[2022-12-07 04:11:24,589] [INFO] [controller] EPOCH 2 loss ppo:  -0.01865, loss val: 0.04324
[2022-12-07 04:11:24,640] [INFO] [controller] EPOCH 3 loss ppo:  -0.01958, loss val: 0.04381
[2022-12-07 04:11:24,687] [INFO] [controller] EPOCH 4 loss ppo:  -0.02529, loss val: 0.04472
[2022-12-07 04:11:24,697] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:11:24,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:11:24,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:11:29,199] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:11:33,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:11:38,818] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:11:43,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:11:47,812] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:11:52,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:11:56,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:12:00,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:12:05,117] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:12:09,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8543665640031444
[2022-12-07 04:12:09,257] [INFO] [runner_train_mujoco] Average state value: 0.6737187081972759
[2022-12-07 04:12:09,257] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 04:12:09,298] [INFO] [controller] EPOCH 1 loss ppo:  -0.01091, loss val: 0.03751
[2022-12-07 04:12:09,336] [INFO] [controller] EPOCH 2 loss ppo:  -0.01198, loss val: 0.03889
[2022-12-07 04:12:09,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.01679, loss val: 0.03849
[2022-12-07 04:12:09,418] [INFO] [controller] EPOCH 4 loss ppo:  -0.02472, loss val: 0.03818
[2022-12-07 04:12:09,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:12:09,572] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:12:09,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:12:13,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:12:18,819] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:12:23,206] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:12:27,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:12:32,129] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:12:36,299] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:12:40,618] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:12:45,160] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:12:49,676] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:12:54,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.999816622416403
[2022-12-07 04:12:54,160] [INFO] [runner_train_mujoco] Average state value: 0.6632949498494467
[2022-12-07 04:12:54,160] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 04:12:54,210] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.04303
[2022-12-07 04:12:54,255] [INFO] [controller] EPOCH 2 loss ppo:  -0.01800, loss val: 0.04302
[2022-12-07 04:12:54,300] [INFO] [controller] EPOCH 3 loss ppo:  -0.02157, loss val: 0.04437
[2022-12-07 04:12:54,344] [INFO] [controller] EPOCH 4 loss ppo:  -0.02543, loss val: 0.04310
[2022-12-07 04:12:54,353] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:12:54,510] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:12:54,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:12:58,839] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:13:03,398] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:13:07,765] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:13:12,097] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:13:16,597] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:13:21,170] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:13:25,339] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:13:29,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:13:34,025] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:13:38,412] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9762317578885353
[2022-12-07 04:13:38,412] [INFO] [runner_train_mujoco] Average state value: 0.6578721475601197
[2022-12-07 04:13:38,412] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 04:13:38,459] [INFO] [controller] EPOCH 1 loss ppo:  -0.01197, loss val: 0.04082
[2022-12-07 04:13:38,498] [INFO] [controller] EPOCH 2 loss ppo:  -0.01637, loss val: 0.04049
[2022-12-07 04:13:38,540] [INFO] [controller] EPOCH 3 loss ppo:  -0.02354, loss val: 0.04085
[2022-12-07 04:13:38,581] [INFO] [controller] EPOCH 4 loss ppo:  -0.02486, loss val: 0.04043
[2022-12-07 04:13:38,590] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:13:38,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:13:38,736] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:13:42,960] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:13:47,437] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:13:51,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:13:56,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:14:00,774] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:14:05,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:14:09,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:14:14,334] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:14:18,476] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:14:22,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0205365558246293
[2022-12-07 04:14:22,634] [INFO] [runner_train_mujoco] Average state value: 0.6598565077781678
[2022-12-07 04:14:22,634] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 04:14:22,682] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04417
[2022-12-07 04:14:22,724] [INFO] [controller] EPOCH 2 loss ppo:  -0.01436, loss val: 0.04337
[2022-12-07 04:14:22,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.01821, loss val: 0.04336
[2022-12-07 04:14:22,807] [INFO] [controller] EPOCH 4 loss ppo:  -0.02145, loss val: 0.04351
[2022-12-07 04:14:22,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:14:22,970] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:14:22,970] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:14:27,272] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:14:31,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:14:35,683] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:14:39,972] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:14:44,445] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:14:48,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:14:53,189] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:14:57,712] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:15:02,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:15:07,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0101386896701485
[2022-12-07 04:15:07,098] [INFO] [runner_train_mujoco] Average state value: 0.6628608330488206
[2022-12-07 04:15:07,098] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 04:15:07,147] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.04579
[2022-12-07 04:15:07,190] [INFO] [controller] EPOCH 2 loss ppo:  -0.01497, loss val: 0.04618
[2022-12-07 04:15:07,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.01947, loss val: 0.04559
[2022-12-07 04:15:07,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.02339, loss val: 0.04541
[2022-12-07 04:15:07,288] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:15:07,444] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:15:07,444] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:15:12,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:15:16,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:15:21,262] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:15:25,392] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:15:29,633] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:15:33,685] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:15:37,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:15:42,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:15:46,914] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:15:51,362] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.983130070829507
[2022-12-07 04:15:51,362] [INFO] [runner_train_mujoco] Average state value: 0.6755401801268259
[2022-12-07 04:15:51,362] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 04:15:51,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.04049
[2022-12-07 04:15:51,457] [INFO] [controller] EPOCH 2 loss ppo:  -0.01639, loss val: 0.03990
[2022-12-07 04:15:51,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.01897, loss val: 0.04019
[2022-12-07 04:15:51,538] [INFO] [controller] EPOCH 4 loss ppo:  -0.01925, loss val: 0.03923
[2022-12-07 04:15:51,547] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:15:51,702] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:15:51,703] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:15:57,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:16:03,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:16:08,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:16:13,776] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:16:18,956] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:16:24,213] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:16:29,506] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:16:34,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:16:39,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:16:44,684] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.043172513879955
[2022-12-07 04:16:44,685] [INFO] [runner_train_mujoco] Average state value: 0.6862885806163151
[2022-12-07 04:16:44,685] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 04:16:44,742] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.04356
[2022-12-07 04:16:44,795] [INFO] [controller] EPOCH 2 loss ppo:  -0.01460, loss val: 0.04326
[2022-12-07 04:16:44,841] [INFO] [controller] EPOCH 3 loss ppo:  -0.01852, loss val: 0.04335
[2022-12-07 04:16:44,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.02159, loss val: 0.04318
[2022-12-07 04:16:44,903] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:16:45,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:16:45,075] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:16:50,119] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:16:55,320] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:17:00,312] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:17:05,630] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:17:10,794] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:17:15,650] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:17:20,680] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:17:25,615] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:17:30,818] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:17:35,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1316153315035185
[2022-12-07 04:17:35,893] [INFO] [runner_train_mujoco] Average state value: 0.68007111064593
[2022-12-07 04:17:35,893] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 04:17:35,958] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.04293
[2022-12-07 04:17:36,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.01541, loss val: 0.04291
[2022-12-07 04:17:36,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.02045, loss val: 0.04349
[2022-12-07 04:17:36,103] [INFO] [controller] EPOCH 4 loss ppo:  -0.02249, loss val: 0.04349
[2022-12-07 04:17:36,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:17:36,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:17:36,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:17:41,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:17:46,648] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:17:51,908] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:17:57,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:18:02,300] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:18:07,633] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:18:13,077] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:18:17,886] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:18:22,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:18:27,526] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1005207487796613
[2022-12-07 04:18:27,527] [INFO] [runner_train_mujoco] Average state value: 0.674114779472351
[2022-12-07 04:18:27,527] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 04:18:27,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01233, loss val: 0.03992
[2022-12-07 04:18:27,623] [INFO] [controller] EPOCH 2 loss ppo:  -0.01535, loss val: 0.03992
[2022-12-07 04:18:27,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.01974, loss val: 0.04075
[2022-12-07 04:18:27,712] [INFO] [controller] EPOCH 4 loss ppo:  -0.02117, loss val: 0.04025
[2022-12-07 04:18:27,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:18:27,884] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:18:27,884] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:18:32,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:18:37,278] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:18:42,629] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:18:47,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:18:52,462] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:18:58,382] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:19:03,833] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:19:09,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:19:14,310] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:19:19,265] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.080991490408705
[2022-12-07 04:19:19,265] [INFO] [runner_train_mujoco] Average state value: 0.6699951112270355
[2022-12-07 04:19:19,265] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 04:19:19,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.04286
[2022-12-07 04:19:19,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.01429, loss val: 0.04376
[2022-12-07 04:19:19,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.01760, loss val: 0.04321
[2022-12-07 04:19:19,457] [INFO] [controller] EPOCH 4 loss ppo:  -0.02085, loss val: 0.04207
[2022-12-07 04:19:19,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:19:19,629] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:19:19,630] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:19:25,120] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:19:30,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:19:35,390] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:19:40,563] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:19:45,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:19:50,274] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:19:55,408] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:20:00,354] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:20:05,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:20:10,754] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0516853580155043
[2022-12-07 04:20:10,754] [INFO] [runner_train_mujoco] Average state value: 0.6616378101507823
[2022-12-07 04:20:10,754] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 04:20:10,804] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.04262
[2022-12-07 04:20:10,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.01388, loss val: 0.04267
[2022-12-07 04:20:10,890] [INFO] [controller] EPOCH 3 loss ppo:  -0.01631, loss val: 0.04239
[2022-12-07 04:20:10,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.01867, loss val: 0.04237
[2022-12-07 04:20:10,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:20:11,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:20:11,100] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:20:16,421] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:20:21,698] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:20:26,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:20:31,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:20:36,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:20:41,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:20:46,640] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:20:51,538] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:20:56,738] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:21:01,890] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1951522868330935
[2022-12-07 04:21:01,890] [INFO] [runner_train_mujoco] Average state value: 0.6579349297285081
[2022-12-07 04:21:01,891] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 04:21:01,939] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04169
[2022-12-07 04:21:01,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.01364, loss val: 0.04338
[2022-12-07 04:21:02,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.01587, loss val: 0.04132
[2022-12-07 04:21:02,072] [INFO] [controller] EPOCH 4 loss ppo:  -0.01874, loss val: 0.04163
[2022-12-07 04:21:02,082] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:21:02,241] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:21:02,241] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:21:07,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:21:12,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:21:17,435] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:21:22,419] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:21:27,322] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:21:32,515] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:21:37,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:21:42,844] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:21:48,211] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:21:53,390] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1229617150624227
[2022-12-07 04:21:53,390] [INFO] [runner_train_mujoco] Average state value: 0.6568631023963293
[2022-12-07 04:21:53,390] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 04:21:53,442] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.04199
[2022-12-07 04:21:53,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.01308, loss val: 0.04190
[2022-12-07 04:21:53,529] [INFO] [controller] EPOCH 3 loss ppo:  -0.01445, loss val: 0.04189
[2022-12-07 04:21:53,575] [INFO] [controller] EPOCH 4 loss ppo:  -0.01611, loss val: 0.04217
[2022-12-07 04:21:53,584] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:21:53,718] [INFO] [optimize] Finished learning.
