[2022-12-06 21:57:09,605] [INFO] [optimize] Starting learning
[2022-12-06 21:57:09,631] [INFO] [optimize] Starting learning process..
[2022-12-06 21:57:09,849] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:57:09,850] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:57:24,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:57:38,654] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:57:52,421] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:58:07,095] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:58:23,278] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:58:38,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:58:52,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:59:08,172] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:59:23,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:59:37,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5136806542304149
[2022-12-06 21:59:37,996] [INFO] [runner_train_mujoco] Average state value: 0.043498540199051305
[2022-12-06 21:59:37,997] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 21:59:38,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.32539
[2022-12-06 21:59:38,207] [INFO] [controller] EPOCH 2 loss ppo:  -0.05492, loss val: 0.27891
[2022-12-06 21:59:38,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.07101, loss val: 0.25187
[2022-12-06 21:59:38,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.08076, loss val: 0.21957
[2022-12-06 21:59:38,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:59:38,718] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:59:38,718] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:59:53,409] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 22:00:08,611] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 22:00:25,017] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 22:00:39,469] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 22:00:54,988] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 22:01:10,007] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 22:01:24,051] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 22:01:38,568] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 22:01:52,562] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 22:02:07,445] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5100880401460735
[2022-12-06 22:02:07,456] [INFO] [runner_train_mujoco] Average state value: 0.22732947822846472
[2022-12-06 22:02:07,457] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 22:02:07,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01267, loss val: 0.24834
[2022-12-06 22:02:07,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.04602, loss val: 0.21350
[2022-12-06 22:02:07,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.06716, loss val: 0.19794
[2022-12-06 22:02:07,788] [INFO] [controller] EPOCH 4 loss ppo:  -0.08038, loss val: 0.17371
[2022-12-06 22:02:07,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 22:02:08,104] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 22:02:08,104] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 22:02:22,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 22:02:36,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 22:02:50,537] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 22:03:05,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 22:03:18,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:03:38,989] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:03:57,829] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:04:15,618] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:04:29,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:04:43,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5536741714158396
[2022-12-06 23:04:43,991] [INFO] [runner_train_mujoco] Average state value: 0.37840544925443825
[2022-12-06 23:04:43,991] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 23:04:44,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.14391
[2022-12-06 23:04:44,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.05110, loss val: 0.12944
[2022-12-06 23:04:44,246] [INFO] [controller] EPOCH 3 loss ppo:  -0.07116, loss val: 0.11738
[2022-12-06 23:04:44,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.08411, loss val: 0.10801
[2022-12-06 23:04:44,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:04:44,653] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:04:44,654] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:04:59,789] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:05:14,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:05:28,121] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:05:43,130] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:05:57,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:06:12,605] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:06:26,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:06:40,914] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:06:54,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:07:10,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6334067274105953
[2022-12-06 23:07:10,778] [INFO] [runner_train_mujoco] Average state value: 0.49544389745344725
[2022-12-06 23:07:10,779] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 23:07:10,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.01061, loss val: 0.11663
[2022-12-06 23:07:11,012] [INFO] [controller] EPOCH 2 loss ppo:  -0.04056, loss val: 0.11473
[2022-12-06 23:07:11,105] [INFO] [controller] EPOCH 3 loss ppo:  -0.05557, loss val: 0.10962
[2022-12-06 23:07:11,239] [INFO] [controller] EPOCH 4 loss ppo:  -0.06579, loss val: 0.10343
[2022-12-06 23:07:11,264] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:07:11,581] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:07:11,581] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:07:27,525] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:07:42,210] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:07:56,171] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:08:10,161] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:08:25,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:08:41,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:08:58,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:09:13,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:09:28,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:09:42,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6953626853302879
[2022-12-06 23:09:42,515] [INFO] [runner_train_mujoco] Average state value: 0.5008059024810791
[2022-12-06 23:09:42,515] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 23:09:42,613] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.08104
[2022-12-06 23:09:42,691] [INFO] [controller] EPOCH 2 loss ppo:  -0.04821, loss val: 0.07798
[2022-12-06 23:09:42,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.06512, loss val: 0.07389
[2022-12-06 23:09:42,939] [INFO] [controller] EPOCH 4 loss ppo:  -0.07650, loss val: 0.07049
[2022-12-06 23:09:42,953] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:09:43,256] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:09:43,256] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:09:57,586] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:10:11,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:10:26,050] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:10:39,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:10:54,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:11:09,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:11:24,076] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:11:38,263] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:11:52,303] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:12:06,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6566402406730006
[2022-12-06 23:12:06,332] [INFO] [runner_train_mujoco] Average state value: 0.5083768458999693
[2022-12-06 23:12:06,333] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 23:12:06,465] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.06299
[2022-12-06 23:12:06,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.04395, loss val: 0.06002
[2022-12-06 23:12:06,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.06028, loss val: 0.05775
[2022-12-06 23:12:06,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.07153, loss val: 0.05663
[2022-12-06 23:12:06,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:12:07,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:12:07,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:12:21,812] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:12:36,446] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:12:51,292] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:13:05,706] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:13:19,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:13:34,309] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:13:48,484] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:14:02,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:14:16,960] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:14:31,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.30160984155492065
[2022-12-06 23:14:31,550] [INFO] [runner_train_mujoco] Average state value: 0.5334296328530956
[2022-12-06 23:14:31,550] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 23:14:31,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.00985, loss val: 0.06209
[2022-12-06 23:14:31,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.04607, loss val: 0.05976
[2022-12-06 23:14:31,811] [INFO] [controller] EPOCH 3 loss ppo:  -0.06524, loss val: 0.05871
[2022-12-06 23:14:31,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.07490, loss val: 0.05662
[2022-12-06 23:14:31,926] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:14:32,235] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:14:32,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:14:46,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:15:01,033] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:15:14,952] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:15:28,937] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:15:44,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:15:59,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:16:14,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:16:29,141] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:16:44,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:16:57,893] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.376151811609328
[2022-12-06 23:16:57,894] [INFO] [runner_train_mujoco] Average state value: 0.5435107600192228
[2022-12-06 23:16:57,894] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 23:16:58,006] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.04641
[2022-12-06 23:16:58,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.04426, loss val: 0.04484
[2022-12-06 23:16:58,248] [INFO] [controller] EPOCH 3 loss ppo:  -0.06268, loss val: 0.04475
[2022-12-06 23:16:58,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.07579, loss val: 0.04182
[2022-12-06 23:16:58,375] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:16:58,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:16:58,643] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:17:12,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:17:26,611] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:17:41,035] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:17:58,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:18:12,490] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:18:24,860] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:18:38,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:18:50,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:19:02,358] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:19:15,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4185025592228107
[2022-12-06 23:19:15,459] [INFO] [runner_train_mujoco] Average state value: 0.5661517210230231
[2022-12-06 23:19:15,459] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 23:19:15,644] [INFO] [controller] EPOCH 1 loss ppo:  -0.00901, loss val: 0.05093
[2022-12-06 23:19:15,831] [INFO] [controller] EPOCH 2 loss ppo:  -0.03372, loss val: 0.04820
[2022-12-06 23:19:15,949] [INFO] [controller] EPOCH 3 loss ppo:  -0.05250, loss val: 0.04847
[2022-12-06 23:19:16,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.06672, loss val: 0.04549
[2022-12-06 23:19:16,129] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:19:16,533] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:19:16,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:19:32,700] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:19:46,800] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:20:00,349] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:20:14,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:20:28,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:20:42,802] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:20:57,429] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:21:10,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:21:24,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:21:36,921] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6018932757045493
[2022-12-06 23:21:36,922] [INFO] [runner_train_mujoco] Average state value: 0.5958718783160051
[2022-12-06 23:21:36,922] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 23:21:37,034] [INFO] [controller] EPOCH 1 loss ppo:  -0.00998, loss val: 0.04738
[2022-12-06 23:21:37,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.04079, loss val: 0.04662
[2022-12-06 23:21:37,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.05856, loss val: 0.04738
[2022-12-06 23:21:37,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.06864, loss val: 0.04493
[2022-12-06 23:21:37,304] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:21:37,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:21:37,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:21:50,986] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:22:03,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:22:17,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:22:30,549] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:22:42,756] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:22:54,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:23:05,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:23:17,970] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:23:30,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:23:42,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.49795150667270816
[2022-12-06 23:23:42,838] [INFO] [runner_train_mujoco] Average state value: 0.5753287142316502
[2022-12-06 23:23:42,839] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 23:23:42,921] [INFO] [controller] EPOCH 1 loss ppo:  -0.00969, loss val: 0.04647
[2022-12-06 23:23:42,988] [INFO] [controller] EPOCH 2 loss ppo:  -0.04214, loss val: 0.04631
[2022-12-06 23:23:43,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.05927, loss val: 0.04703
[2022-12-06 23:23:43,128] [INFO] [controller] EPOCH 4 loss ppo:  -0.07114, loss val: 0.04648
[2022-12-06 23:23:43,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:23:43,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:23:43,419] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:23:55,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:24:07,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:24:19,493] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:24:31,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:24:44,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:24:57,138] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:25:09,327] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:25:21,396] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:25:33,427] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:25:45,299] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4902741678227042
[2022-12-06 23:25:45,300] [INFO] [runner_train_mujoco] Average state value: 0.5482566528320312
[2022-12-06 23:25:45,305] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 23:25:45,382] [INFO] [controller] EPOCH 1 loss ppo:  -0.01165, loss val: 0.04003
[2022-12-06 23:25:45,451] [INFO] [controller] EPOCH 2 loss ppo:  -0.04712, loss val: 0.04138
[2022-12-06 23:25:45,517] [INFO] [controller] EPOCH 3 loss ppo:  -0.06422, loss val: 0.04103
[2022-12-06 23:25:45,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.07370, loss val: 0.03915
[2022-12-06 23:25:45,589] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:25:45,874] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:25:45,874] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:25:57,819] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:26:09,574] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:26:21,200] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:26:33,370] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:26:45,761] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:26:57,874] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:27:09,974] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:27:22,054] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:27:34,123] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:27:46,058] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4228970526401879
[2022-12-06 23:27:46,058] [INFO] [runner_train_mujoco] Average state value: 0.553032186259826
[2022-12-06 23:27:46,058] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 23:27:46,145] [INFO] [controller] EPOCH 1 loss ppo:  -0.01085, loss val: 0.03519
[2022-12-06 23:27:46,209] [INFO] [controller] EPOCH 2 loss ppo:  -0.04050, loss val: 0.03671
[2022-12-06 23:27:46,282] [INFO] [controller] EPOCH 3 loss ppo:  -0.05779, loss val: 0.03441
[2022-12-06 23:27:46,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.07103, loss val: 0.03389
[2022-12-06 23:27:46,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:27:46,640] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:27:46,640] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:27:58,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:28:08,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:28:18,468] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:28:28,602] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:28:38,510] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:28:48,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:28:57,269] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:29:06,800] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:29:16,082] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:29:25,269] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7142746539696668
[2022-12-06 23:29:25,270] [INFO] [runner_train_mujoco] Average state value: 0.5344870249927044
[2022-12-06 23:29:25,270] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 23:29:25,347] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.03037
[2022-12-06 23:29:25,396] [INFO] [controller] EPOCH 2 loss ppo:  -0.03908, loss val: 0.03024
[2022-12-06 23:29:25,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.05416, loss val: 0.03068
[2022-12-06 23:29:25,587] [INFO] [controller] EPOCH 4 loss ppo:  -0.06919, loss val: 0.02989
[2022-12-06 23:29:25,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:29:25,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:29:25,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:29:35,814] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:29:45,664] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:29:55,295] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:30:05,119] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:30:14,265] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:30:23,497] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:30:32,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:30:42,122] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:30:52,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:31:01,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4956091156892968
[2022-12-06 23:31:01,974] [INFO] [runner_train_mujoco] Average state value: 0.5305747928520044
[2022-12-06 23:31:01,974] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 23:31:02,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.00937, loss val: 0.04210
[2022-12-06 23:31:02,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.03404, loss val: 0.04139
[2022-12-06 23:31:02,155] [INFO] [controller] EPOCH 3 loss ppo:  -0.05625, loss val: 0.04023
[2022-12-06 23:31:02,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.07143, loss val: 0.04234
[2022-12-06 23:31:02,222] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:31:02,453] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:31:02,453] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:31:12,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:31:21,520] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:31:31,196] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:31:40,789] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:31:50,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:32:00,013] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:32:10,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:32:19,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:33:14,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:33:29,308] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6814443332406668
[2022-12-06 23:33:29,308] [INFO] [runner_train_mujoco] Average state value: 0.49205372936526937
[2022-12-06 23:33:29,308] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 23:33:29,388] [INFO] [controller] EPOCH 1 loss ppo:  -0.01176, loss val: 0.04145
[2022-12-06 23:33:29,444] [INFO] [controller] EPOCH 2 loss ppo:  -0.03907, loss val: 0.04204
[2022-12-06 23:33:29,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.05558, loss val: 0.04243
[2022-12-06 23:33:29,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.07003, loss val: 0.04017
[2022-12-06 23:33:29,587] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:33:29,833] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:33:29,833] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:33:39,677] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:33:48,741] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:33:58,165] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:34:07,998] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:34:17,582] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:34:27,284] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:34:36,546] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:34:47,883] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:34:59,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:35:09,788] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5196548841557759
[2022-12-06 23:35:09,789] [INFO] [runner_train_mujoco] Average state value: 0.4994347054859002
[2022-12-06 23:35:09,789] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 23:35:09,861] [INFO] [controller] EPOCH 1 loss ppo:  -0.01137, loss val: 0.03551
[2022-12-06 23:35:09,916] [INFO] [controller] EPOCH 2 loss ppo:  -0.03940, loss val: 0.02889
[2022-12-06 23:35:09,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.06184, loss val: 0.03736
[2022-12-06 23:35:10,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.07830, loss val: 0.02797
[2022-12-06 23:35:10,044] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:35:10,317] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:35:10,317] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:35:20,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:35:30,820] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:35:41,931] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:35:52,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:36:02,563] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:36:11,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:36:22,166] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:36:31,622] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:36:42,146] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:36:53,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5123540845543395
[2022-12-06 23:36:53,404] [INFO] [runner_train_mujoco] Average state value: 0.5205609609882036
[2022-12-06 23:36:53,404] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 23:36:53,468] [INFO] [controller] EPOCH 1 loss ppo:  -0.01159, loss val: 0.04220
[2022-12-06 23:36:53,518] [INFO] [controller] EPOCH 2 loss ppo:  -0.04213, loss val: 0.04469
[2022-12-06 23:36:53,576] [INFO] [controller] EPOCH 3 loss ppo:  -0.06167, loss val: 0.04034
[2022-12-06 23:36:53,634] [INFO] [controller] EPOCH 4 loss ppo:  -0.07460, loss val: 0.03903
[2022-12-06 23:36:53,645] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:36:53,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:36:53,911] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:37:05,142] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:37:14,428] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:37:23,784] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:37:32,751] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:37:41,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:37:50,765] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:38:02,951] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:38:17,075] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:38:29,691] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:38:42,106] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.33795339869805485
[2022-12-06 23:38:42,106] [INFO] [runner_train_mujoco] Average state value: 0.48690008103847504
[2022-12-06 23:38:42,107] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 23:38:42,207] [INFO] [controller] EPOCH 1 loss ppo:  -0.00859, loss val: 0.04477
[2022-12-06 23:38:42,280] [INFO] [controller] EPOCH 2 loss ppo:  -0.03768, loss val: 0.04538
[2022-12-06 23:38:42,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.05785, loss val: 0.04483
[2022-12-06 23:38:42,434] [INFO] [controller] EPOCH 4 loss ppo:  -0.07252, loss val: 0.04689
[2022-12-06 23:38:42,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:38:42,774] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:38:42,774] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:38:55,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:39:06,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:39:19,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:39:31,563] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:39:44,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:39:56,375] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:40:08,446] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:40:20,530] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:40:32,677] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:40:45,138] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4874860836455029
[2022-12-06 23:40:45,139] [INFO] [runner_train_mujoco] Average state value: 0.5008370280961196
[2022-12-06 23:40:45,139] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 23:40:45,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.01001, loss val: 0.03338
[2022-12-06 23:40:45,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.03648, loss val: 0.03399
[2022-12-06 23:40:45,420] [INFO] [controller] EPOCH 3 loss ppo:  -0.05399, loss val: 0.03338
[2022-12-06 23:40:45,499] [INFO] [controller] EPOCH 4 loss ppo:  -0.06990, loss val: 0.03293
[2022-12-06 23:40:45,512] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:40:45,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:40:45,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:40:58,441] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:41:11,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:41:24,016] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:41:36,127] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:41:48,294] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:42:00,706] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:42:13,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:42:25,025] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:42:37,040] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:42:49,455] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7123007375179194
[2022-12-06 23:42:49,455] [INFO] [runner_train_mujoco] Average state value: 0.4836305462817351
[2022-12-06 23:42:49,455] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 23:42:49,541] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.03753
[2022-12-06 23:42:49,615] [INFO] [controller] EPOCH 2 loss ppo:  -0.04204, loss val: 0.03833
[2022-12-06 23:42:49,732] [INFO] [controller] EPOCH 3 loss ppo:  -0.06466, loss val: 0.03893
[2022-12-06 23:42:49,813] [INFO] [controller] EPOCH 4 loss ppo:  -0.07722, loss val: 0.04033
[2022-12-06 23:42:49,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:42:50,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:42:50,161] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:43:02,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:43:15,871] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:43:29,812] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:43:41,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:43:53,594] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:44:05,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:44:17,932] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:44:30,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:44:42,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:44:55,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7227496042541298
[2022-12-06 23:44:55,085] [INFO] [runner_train_mujoco] Average state value: 0.4615236625870069
[2022-12-06 23:44:55,085] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 23:44:55,206] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.03762
[2022-12-06 23:44:55,305] [INFO] [controller] EPOCH 2 loss ppo:  -0.03962, loss val: 0.04023
[2022-12-06 23:44:55,389] [INFO] [controller] EPOCH 3 loss ppo:  -0.05743, loss val: 0.03783
[2022-12-06 23:44:55,463] [INFO] [controller] EPOCH 4 loss ppo:  -0.07133, loss val: 0.03861
[2022-12-06 23:44:55,481] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:44:55,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:44:55,772] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:45:08,522] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:45:20,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:45:34,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:45:46,529] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:45:58,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:46:11,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:46:23,452] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:46:35,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:46:48,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:47:00,377] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6946270037243178
[2022-12-06 23:47:00,377] [INFO] [runner_train_mujoco] Average state value: 0.4602401114106178
[2022-12-06 23:47:00,377] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 23:47:00,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.02566
[2022-12-06 23:47:00,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.04072, loss val: 0.02454
[2022-12-06 23:47:00,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.05579, loss val: 0.02766
[2022-12-06 23:47:00,715] [INFO] [controller] EPOCH 4 loss ppo:  -0.07053, loss val: 0.02593
[2022-12-06 23:47:00,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:47:01,029] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:47:01,029] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:47:13,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:47:26,251] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:47:39,275] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:47:52,408] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:48:01,904] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:48:11,630] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:48:21,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:48:33,343] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:48:43,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:48:54,397] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7657075846298085
[2022-12-06 23:48:54,398] [INFO] [runner_train_mujoco] Average state value: 0.46856552356481557
[2022-12-06 23:48:54,398] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 23:48:54,464] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.03365
[2022-12-06 23:48:54,514] [INFO] [controller] EPOCH 2 loss ppo:  -0.03981, loss val: 0.03510
[2022-12-06 23:48:54,566] [INFO] [controller] EPOCH 3 loss ppo:  -0.05885, loss val: 0.03364
[2022-12-06 23:48:54,616] [INFO] [controller] EPOCH 4 loss ppo:  -0.07320, loss val: 0.03368
[2022-12-06 23:48:54,636] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:48:54,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:48:54,912] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:49:05,172] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:49:15,569] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:49:24,967] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:49:35,213] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:49:44,944] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:49:54,100] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:50:03,555] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:50:16,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:50:29,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:50:39,712] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5905631808776957
[2022-12-06 23:50:39,712] [INFO] [runner_train_mujoco] Average state value: 0.47079412432511647
[2022-12-06 23:50:39,713] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 23:50:39,783] [INFO] [controller] EPOCH 1 loss ppo:  -0.01051, loss val: 0.04331
[2022-12-06 23:50:39,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.03617, loss val: 0.04349
[2022-12-06 23:50:39,901] [INFO] [controller] EPOCH 3 loss ppo:  -0.05570, loss val: 0.04318
[2022-12-06 23:50:39,959] [INFO] [controller] EPOCH 4 loss ppo:  -0.07233, loss val: 0.04189
[2022-12-06 23:50:39,971] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:50:40,258] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:50:40,258] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:50:51,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:51:01,995] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:51:11,509] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:51:20,968] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:51:30,826] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:51:40,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:51:50,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:52:00,613] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:52:10,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:52:20,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.894391379149386
[2022-12-06 23:52:20,118] [INFO] [runner_train_mujoco] Average state value: 0.47484337040781976
[2022-12-06 23:52:20,118] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 23:52:20,180] [INFO] [controller] EPOCH 1 loss ppo:  -0.01160, loss val: 0.05007
[2022-12-06 23:52:20,237] [INFO] [controller] EPOCH 2 loss ppo:  -0.03571, loss val: 0.04749
[2022-12-06 23:52:20,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.05195, loss val: 0.04438
[2022-12-06 23:52:20,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.06432, loss val: 0.04126
[2022-12-06 23:52:20,365] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:52:20,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:52:20,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:52:30,936] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:52:41,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:52:51,956] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:53:01,435] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:53:11,546] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:53:23,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:53:36,352] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:53:48,226] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:54:00,033] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:54:12,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9014136601115872
[2022-12-06 23:54:12,465] [INFO] [runner_train_mujoco] Average state value: 0.5292463608682155
[2022-12-06 23:54:12,465] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 23:54:12,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.05286
[2022-12-06 23:54:12,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.04082, loss val: 0.05882
[2022-12-06 23:54:12,756] [INFO] [controller] EPOCH 3 loss ppo:  -0.05925, loss val: 0.05578
[2022-12-06 23:54:12,861] [INFO] [controller] EPOCH 4 loss ppo:  -0.06934, loss val: 0.05345
[2022-12-06 23:54:12,879] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:54:13,205] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:54:13,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:54:26,330] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:54:38,974] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:54:50,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:55:04,661] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:55:16,415] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:55:28,146] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:55:41,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:55:53,508] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:56:05,276] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:56:16,956] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1347629731801363
[2022-12-06 23:56:16,957] [INFO] [runner_train_mujoco] Average state value: 0.5307794275085131
[2022-12-06 23:56:16,957] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 23:56:17,051] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.03577
[2022-12-06 23:56:17,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.04522, loss val: 0.03504
[2022-12-06 23:56:17,214] [INFO] [controller] EPOCH 3 loss ppo:  -0.06185, loss val: 0.03265
[2022-12-06 23:56:17,312] [INFO] [controller] EPOCH 4 loss ppo:  -0.07296, loss val: 0.03200
[2022-12-06 23:56:17,329] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:56:17,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:56:17,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:56:30,206] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:56:43,079] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:56:56,357] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:57:11,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:57:23,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:57:36,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:57:48,005] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 23:58:00,082] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 23:58:12,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 23:58:25,355] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.813350720679498
[2022-12-06 23:58:25,355] [INFO] [runner_train_mujoco] Average state value: 0.47743459478020667
[2022-12-06 23:58:25,356] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 23:58:25,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01520, loss val: 0.03721
[2022-12-06 23:58:25,701] [INFO] [controller] EPOCH 2 loss ppo:  -0.04596, loss val: 0.03915
[2022-12-06 23:58:25,810] [INFO] [controller] EPOCH 3 loss ppo:  -0.06707, loss val: 0.03720
[2022-12-06 23:58:25,888] [INFO] [controller] EPOCH 4 loss ppo:  -0.08005, loss val: 0.03836
[2022-12-06 23:58:25,928] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 23:58:26,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 23:58:26,227] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 23:58:41,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 23:58:54,366] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 23:59:06,712] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 23:59:20,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 23:59:32,591] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 23:59:45,719] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 23:59:57,609] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:00:07,544] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:00:19,492] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:00:29,936] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1557634084443764
[2022-12-07 00:00:29,936] [INFO] [runner_train_mujoco] Average state value: 0.44293601195017496
[2022-12-07 00:00:29,936] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 00:00:30,006] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03693
[2022-12-07 00:00:30,072] [INFO] [controller] EPOCH 2 loss ppo:  -0.03529, loss val: 0.03648
[2022-12-07 00:00:30,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.05409, loss val: 0.03718
[2022-12-07 00:00:30,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.06910, loss val: 0.03527
[2022-12-07 00:00:30,302] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:00:30,691] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:00:30,692] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:00:42,782] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:00:52,856] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:01:04,175] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:01:14,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:01:23,482] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:01:32,496] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:01:41,936] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:01:52,597] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:01:59,406] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:02:05,972] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7533641772286734
[2022-12-07 00:02:05,972] [INFO] [runner_train_mujoco] Average state value: 0.4616692518591881
[2022-12-07 00:02:05,973] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 00:02:06,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01653, loss val: 0.03744
[2022-12-07 00:02:06,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.04582, loss val: 0.03684
[2022-12-07 00:02:06,157] [INFO] [controller] EPOCH 3 loss ppo:  -0.06226, loss val: 0.03877
[2022-12-07 00:02:06,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.07453, loss val: 0.03794
[2022-12-07 00:02:06,204] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:02:06,410] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:02:06,411] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:02:13,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:02:20,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:02:28,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:02:36,458] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:02:43,584] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:02:50,523] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:02:57,162] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:03:04,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:03:11,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:03:18,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1216593071617083
[2022-12-07 00:03:18,045] [INFO] [runner_train_mujoco] Average state value: 0.47709351253509524
[2022-12-07 00:03:18,045] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 00:03:18,093] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.03802
[2022-12-07 00:03:18,135] [INFO] [controller] EPOCH 2 loss ppo:  -0.03979, loss val: 0.03687
[2022-12-07 00:03:18,176] [INFO] [controller] EPOCH 3 loss ppo:  -0.05762, loss val: 0.03758
[2022-12-07 00:03:18,218] [INFO] [controller] EPOCH 4 loss ppo:  -0.07009, loss val: 0.03784
[2022-12-07 00:03:18,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:03:18,450] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:03:18,452] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:03:25,512] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:03:32,749] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:03:40,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:03:47,388] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:03:54,355] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:04:01,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:04:07,899] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:04:14,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:04:21,434] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:04:28,251] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1509030660145654
[2022-12-07 00:04:28,251] [INFO] [runner_train_mujoco] Average state value: 0.46778937515616426
[2022-12-07 00:04:28,251] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 00:04:28,305] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.04394
[2022-12-07 00:04:28,348] [INFO] [controller] EPOCH 2 loss ppo:  -0.04020, loss val: 0.04161
[2022-12-07 00:04:28,391] [INFO] [controller] EPOCH 3 loss ppo:  -0.05950, loss val: 0.03988
[2022-12-07 00:04:28,433] [INFO] [controller] EPOCH 4 loss ppo:  -0.07555, loss val: 0.03939
[2022-12-07 00:04:28,442] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:04:28,653] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:04:28,654] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:04:35,866] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:04:43,306] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:04:50,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:04:57,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:05:04,341] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:05:11,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:05:18,036] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:05:24,833] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:05:32,027] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:05:39,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.72444207862428
[2022-12-07 00:05:39,254] [INFO] [runner_train_mujoco] Average state value: 0.4125544798970222
[2022-12-07 00:05:39,254] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 00:05:39,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01611, loss val: 0.04086
[2022-12-07 00:05:39,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.03897, loss val: 0.04377
[2022-12-07 00:05:39,392] [INFO] [controller] EPOCH 3 loss ppo:  -0.05509, loss val: 0.04102
[2022-12-07 00:05:39,434] [INFO] [controller] EPOCH 4 loss ppo:  -0.06953, loss val: 0.04096
[2022-12-07 00:05:39,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:05:39,651] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:05:39,651] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:05:46,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:05:53,476] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:06:00,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:06:07,305] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:06:14,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:06:20,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:06:26,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:06:32,589] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:06:39,016] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:06:45,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7713631095584765
[2022-12-07 00:06:45,468] [INFO] [runner_train_mujoco] Average state value: 0.39582649675011633
[2022-12-07 00:06:45,468] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 00:06:45,519] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.03761
[2022-12-07 00:06:45,562] [INFO] [controller] EPOCH 2 loss ppo:  -0.03892, loss val: 0.03948
[2022-12-07 00:06:45,602] [INFO] [controller] EPOCH 3 loss ppo:  -0.05927, loss val: 0.03715
[2022-12-07 00:06:45,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.07251, loss val: 0.03852
[2022-12-07 00:06:45,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:06:45,848] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:06:45,848] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:06:52,076] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:06:58,524] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:07:05,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:07:12,935] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:07:20,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:07:26,169] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:07:32,229] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:07:38,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:07:44,969] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:07:51,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.563671822539524
[2022-12-07 00:07:51,166] [INFO] [runner_train_mujoco] Average state value: 0.41240764663616813
[2022-12-07 00:07:51,167] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 00:07:51,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.04183
[2022-12-07 00:07:51,251] [INFO] [controller] EPOCH 2 loss ppo:  -0.04080, loss val: 0.04408
[2022-12-07 00:07:51,296] [INFO] [controller] EPOCH 3 loss ppo:  -0.06261, loss val: 0.04344
[2022-12-07 00:07:51,338] [INFO] [controller] EPOCH 4 loss ppo:  -0.07596, loss val: 0.04279
[2022-12-07 00:07:51,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:07:51,549] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:07:51,550] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:07:58,071] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:08:04,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:08:10,670] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:08:16,981] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:08:23,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:08:30,007] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:08:36,478] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:08:42,832] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:08:49,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:08:55,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.893511292763853
[2022-12-07 00:08:55,837] [INFO] [runner_train_mujoco] Average state value: 0.43667208695411686
[2022-12-07 00:08:55,837] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 00:08:55,945] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.03877
[2022-12-07 00:08:55,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.03312, loss val: 0.03950
[2022-12-07 00:08:56,022] [INFO] [controller] EPOCH 3 loss ppo:  -0.05167, loss val: 0.03820
[2022-12-07 00:08:56,065] [INFO] [controller] EPOCH 4 loss ppo:  -0.06617, loss val: 0.03971
[2022-12-07 00:08:56,075] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:08:56,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:08:56,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:09:03,325] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:09:09,539] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:09:15,657] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:09:22,353] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:09:28,702] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:09:37,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:09:43,367] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:09:50,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:09:56,519] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:10:02,961] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.635586301600449
[2022-12-07 00:10:02,961] [INFO] [runner_train_mujoco] Average state value: 0.45563069673379264
[2022-12-07 00:10:02,962] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 00:10:03,013] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.04531
[2022-12-07 00:10:03,056] [INFO] [controller] EPOCH 2 loss ppo:  -0.03217, loss val: 0.04425
[2022-12-07 00:10:03,102] [INFO] [controller] EPOCH 3 loss ppo:  -0.05155, loss val: 0.04369
[2022-12-07 00:10:03,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.06675, loss val: 0.04265
[2022-12-07 00:10:03,152] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:10:03,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:10:03,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:10:10,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:10:16,644] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:10:22,932] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:10:29,140] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:10:35,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:10:42,874] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:10:49,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:10:56,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:11:03,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:11:10,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5627432386250035
[2022-12-07 00:11:10,315] [INFO] [runner_train_mujoco] Average state value: 0.4793915805617968
[2022-12-07 00:11:10,315] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 00:11:10,362] [INFO] [controller] EPOCH 1 loss ppo:  -0.01631, loss val: 0.04794
[2022-12-07 00:11:10,401] [INFO] [controller] EPOCH 2 loss ppo:  -0.03670, loss val: 0.04774
[2022-12-07 00:11:10,440] [INFO] [controller] EPOCH 3 loss ppo:  -0.04742, loss val: 0.04764
[2022-12-07 00:11:10,479] [INFO] [controller] EPOCH 4 loss ppo:  -0.06033, loss val: 0.04636
[2022-12-07 00:11:10,488] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:11:10,683] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:11:10,683] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:11:17,325] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:11:23,821] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:11:29,929] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:11:36,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:11:42,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:11:49,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:11:56,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:12:02,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:12:09,546] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:12:16,006] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.718869822743594
[2022-12-07 00:12:16,006] [INFO] [runner_train_mujoco] Average state value: 0.47880352421601613
[2022-12-07 00:12:16,006] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 00:12:16,054] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04719
[2022-12-07 00:12:16,097] [INFO] [controller] EPOCH 2 loss ppo:  -0.03589, loss val: 0.04447
[2022-12-07 00:12:16,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.05778, loss val: 0.04417
[2022-12-07 00:12:16,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.07169, loss val: 0.04463
[2022-12-07 00:12:16,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:12:16,381] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:12:16,381] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:12:22,658] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:12:28,950] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:12:35,086] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:12:42,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:12:49,176] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:12:55,452] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:13:02,084] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:13:08,787] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:13:15,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:13:21,736] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4425381230337475
[2022-12-07 00:13:21,736] [INFO] [runner_train_mujoco] Average state value: 0.45525339021285377
[2022-12-07 00:13:21,736] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 00:13:21,783] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.03995
[2022-12-07 00:13:21,821] [INFO] [controller] EPOCH 2 loss ppo:  -0.03420, loss val: 0.04587
[2022-12-07 00:13:21,862] [INFO] [controller] EPOCH 3 loss ppo:  -0.04931, loss val: 0.03973
[2022-12-07 00:13:21,904] [INFO] [controller] EPOCH 4 loss ppo:  -0.06422, loss val: 0.04107
[2022-12-07 00:13:21,913] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:13:22,117] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:13:22,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:13:28,402] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:13:34,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:13:40,947] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:13:47,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:13:53,433] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:14:00,121] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:14:06,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:14:13,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:14:19,566] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:14:25,842] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.26858406940885
[2022-12-07 00:14:25,842] [INFO] [runner_train_mujoco] Average state value: 0.44444988756378495
[2022-12-07 00:14:25,842] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 00:14:25,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04229
[2022-12-07 00:14:25,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.03149, loss val: 0.04117
[2022-12-07 00:14:25,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.04962, loss val: 0.04111
[2022-12-07 00:14:26,003] [INFO] [controller] EPOCH 4 loss ppo:  -0.06172, loss val: 0.04116
[2022-12-07 00:14:26,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:14:26,201] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:14:26,201] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:14:32,606] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:14:38,976] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:14:45,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:14:51,777] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:14:57,913] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:15:04,265] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:15:10,726] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:15:17,530] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:15:24,449] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:15:30,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.144006266213586
[2022-12-07 00:15:30,906] [INFO] [runner_train_mujoco] Average state value: 0.44156156272689506
[2022-12-07 00:15:30,906] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 00:15:30,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.03386
[2022-12-07 00:15:30,991] [INFO] [controller] EPOCH 2 loss ppo:  -0.03209, loss val: 0.03382
[2022-12-07 00:15:31,031] [INFO] [controller] EPOCH 3 loss ppo:  -0.05169, loss val: 0.03379
[2022-12-07 00:15:31,066] [INFO] [controller] EPOCH 4 loss ppo:  -0.06272, loss val: 0.03396
[2022-12-07 00:15:31,076] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:15:31,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:15:31,287] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:15:38,595] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:15:45,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:15:51,515] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:15:57,831] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:16:04,332] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:16:10,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:16:17,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:16:24,270] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:16:31,029] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:16:37,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.259442854233295
[2022-12-07 00:16:37,507] [INFO] [runner_train_mujoco] Average state value: 0.4342537379860878
[2022-12-07 00:16:37,507] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 00:16:37,557] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.05326
[2022-12-07 00:16:37,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.02912, loss val: 0.05252
[2022-12-07 00:16:37,644] [INFO] [controller] EPOCH 3 loss ppo:  -0.04634, loss val: 0.05245
[2022-12-07 00:16:37,691] [INFO] [controller] EPOCH 4 loss ppo:  -0.06063, loss val: 0.05188
[2022-12-07 00:16:37,701] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:16:37,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:16:37,888] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:16:44,310] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:16:50,857] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:16:57,189] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:17:03,360] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:17:09,652] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:17:15,744] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:17:22,008] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:17:28,416] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:17:37,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:17:45,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.954983086839775
[2022-12-07 00:17:45,561] [INFO] [runner_train_mujoco] Average state value: 0.44836150064195196
[2022-12-07 00:17:45,562] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 00:17:45,618] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04676
[2022-12-07 00:17:45,662] [INFO] [controller] EPOCH 2 loss ppo:  -0.02908, loss val: 0.04519
[2022-12-07 00:17:45,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.04220, loss val: 0.04377
[2022-12-07 00:17:45,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.05260, loss val: 0.04254
[2022-12-07 00:17:45,755] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:17:45,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:17:45,993] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:17:53,130] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:18:00,427] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:18:07,372] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:18:14,460] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:18:22,115] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:18:29,502] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:18:36,386] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:18:43,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:18:51,573] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:18:58,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.737530319516769
[2022-12-07 00:18:58,799] [INFO] [runner_train_mujoco] Average state value: 0.494360180079937
[2022-12-07 00:18:58,799] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 00:18:58,855] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.03957
[2022-12-07 00:18:58,896] [INFO] [controller] EPOCH 2 loss ppo:  -0.02925, loss val: 0.04176
[2022-12-07 00:18:58,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.04569, loss val: 0.03989
[2022-12-07 00:18:58,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.05764, loss val: 0.04015
[2022-12-07 00:18:59,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:18:59,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:18:59,218] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:19:07,366] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:19:14,797] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:19:22,541] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:19:30,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:19:37,988] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:19:45,354] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:19:52,708] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:19:59,966] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:20:07,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:20:14,715] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.860834176294487
[2022-12-07 00:20:14,715] [INFO] [runner_train_mujoco] Average state value: 0.4922929978470008
[2022-12-07 00:20:14,715] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 00:20:14,764] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.07291
[2022-12-07 00:20:14,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.02388, loss val: 0.07233
[2022-12-07 00:20:14,855] [INFO] [controller] EPOCH 3 loss ppo:  -0.03916, loss val: 0.07121
[2022-12-07 00:20:14,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.04991, loss val: 0.06930
[2022-12-07 00:20:14,911] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:20:15,117] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:20:15,118] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:20:23,570] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:20:31,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:20:38,697] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:20:46,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:20:53,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:21:01,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:21:08,833] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:21:16,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:21:24,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:21:32,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.710217520019168
[2022-12-07 00:21:32,567] [INFO] [runner_train_mujoco] Average state value: 0.5353833302954831
[2022-12-07 00:21:32,567] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 00:21:32,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.04314
[2022-12-07 00:21:32,681] [INFO] [controller] EPOCH 2 loss ppo:  -0.02904, loss val: 0.04975
[2022-12-07 00:21:32,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.04393, loss val: 0.04448
[2022-12-07 00:21:32,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.05578, loss val: 0.04370
[2022-12-07 00:21:32,853] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:21:33,083] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:21:33,083] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:21:40,987] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:21:49,484] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:21:56,913] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:22:04,102] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:22:14,031] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:22:21,624] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:22:29,262] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:22:36,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:22:44,093] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:22:51,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.736597478863539
[2022-12-07 00:22:51,633] [INFO] [runner_train_mujoco] Average state value: 0.5102571584532659
[2022-12-07 00:22:51,633] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 00:22:51,685] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.06118
[2022-12-07 00:22:51,723] [INFO] [controller] EPOCH 2 loss ppo:  -0.02700, loss val: 0.06080
[2022-12-07 00:22:51,768] [INFO] [controller] EPOCH 3 loss ppo:  -0.04315, loss val: 0.06053
[2022-12-07 00:22:51,814] [INFO] [controller] EPOCH 4 loss ppo:  -0.05627, loss val: 0.06004
[2022-12-07 00:22:51,824] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:22:52,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:22:52,041] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:23:00,698] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:23:08,465] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:23:15,525] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:23:23,033] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:23:30,058] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:23:37,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:23:44,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:23:51,775] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:23:58,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:24:06,186] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.009173285018109
[2022-12-07 00:24:06,186] [INFO] [runner_train_mujoco] Average state value: 0.5255252148509026
[2022-12-07 00:24:06,186] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 00:24:06,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.04267
[2022-12-07 00:24:06,286] [INFO] [controller] EPOCH 2 loss ppo:  -0.02603, loss val: 0.04013
[2022-12-07 00:24:06,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.03847, loss val: 0.03927
[2022-12-07 00:24:06,378] [INFO] [controller] EPOCH 4 loss ppo:  -0.04858, loss val: 0.03884
[2022-12-07 00:24:06,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:24:06,635] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:24:06,636] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:24:14,722] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:24:22,829] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:24:29,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:24:37,017] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:24:44,191] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:24:51,593] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:24:59,038] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:25:07,840] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:25:15,291] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:25:22,251] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.141251203437986
[2022-12-07 00:25:22,251] [INFO] [runner_train_mujoco] Average state value: 0.507873413403829
[2022-12-07 00:25:22,251] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 00:25:22,306] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04147
[2022-12-07 00:25:22,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.02289, loss val: 0.04101
[2022-12-07 00:25:22,394] [INFO] [controller] EPOCH 3 loss ppo:  -0.03535, loss val: 0.04161
[2022-12-07 00:25:22,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.04692, loss val: 0.03981
[2022-12-07 00:25:22,445] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:25:22,666] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:25:22,667] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:25:31,026] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:25:38,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:25:46,253] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:25:53,702] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:26:00,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:26:08,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:26:16,621] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:26:24,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:26:31,535] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:26:39,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.328794927476989
[2022-12-07 00:26:39,052] [INFO] [runner_train_mujoco] Average state value: 0.491630969842275
[2022-12-07 00:26:39,053] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 00:26:39,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.03399
[2022-12-07 00:26:39,173] [INFO] [controller] EPOCH 2 loss ppo:  -0.02177, loss val: 0.03649
[2022-12-07 00:26:39,228] [INFO] [controller] EPOCH 3 loss ppo:  -0.03219, loss val: 0.03664
[2022-12-07 00:26:39,282] [INFO] [controller] EPOCH 4 loss ppo:  -0.04409, loss val: 0.03532
[2022-12-07 00:26:39,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:26:39,533] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:26:39,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:26:47,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:26:56,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:27:04,525] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:27:11,806] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:27:19,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:27:27,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:27:35,110] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:27:43,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:27:51,076] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:27:58,243] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.037970575232561
[2022-12-07 00:27:58,243] [INFO] [runner_train_mujoco] Average state value: 0.4856983222067356
[2022-12-07 00:27:58,243] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 00:27:58,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.03835
[2022-12-07 00:27:58,342] [INFO] [controller] EPOCH 2 loss ppo:  -0.02424, loss val: 0.03840
[2022-12-07 00:27:58,388] [INFO] [controller] EPOCH 3 loss ppo:  -0.03590, loss val: 0.03883
[2022-12-07 00:27:58,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.04695, loss val: 0.03811
[2022-12-07 00:27:58,444] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:27:58,651] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:27:58,652] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:28:06,522] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:28:14,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:28:22,541] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:28:29,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:28:37,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:28:45,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:28:53,557] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:29:02,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:29:09,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:29:17,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.417740322155851
[2022-12-07 00:29:17,065] [INFO] [runner_train_mujoco] Average state value: 0.4815663584272067
[2022-12-07 00:29:17,066] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 00:29:17,119] [INFO] [controller] EPOCH 1 loss ppo:  -0.01486, loss val: 0.03645
[2022-12-07 00:29:17,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.02209, loss val: 0.03732
[2022-12-07 00:29:17,205] [INFO] [controller] EPOCH 3 loss ppo:  -0.03250, loss val: 0.03694
[2022-12-07 00:29:17,253] [INFO] [controller] EPOCH 4 loss ppo:  -0.04283, loss val: 0.03625
[2022-12-07 00:29:17,263] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:29:17,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:29:17,480] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:29:25,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:29:32,534] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:29:40,424] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:29:47,762] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:29:55,145] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:30:02,546] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:30:10,067] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:30:16,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:30:23,955] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:30:30,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.432220898666711
[2022-12-07 00:30:30,727] [INFO] [runner_train_mujoco] Average state value: 0.4595768870574733
[2022-12-07 00:30:30,727] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 00:30:30,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.05619
[2022-12-07 00:30:30,829] [INFO] [controller] EPOCH 2 loss ppo:  -0.01862, loss val: 0.05437
[2022-12-07 00:30:30,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.02603, loss val: 0.05612
[2022-12-07 00:30:30,914] [INFO] [controller] EPOCH 4 loss ppo:  -0.03370, loss val: 0.05543
[2022-12-07 00:30:30,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:30:31,128] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:30:31,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:30:38,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:30:46,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:30:53,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:31:00,871] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:31:07,914] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:31:15,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:31:22,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:31:31,403] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:31:38,350] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:31:45,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.303759805898602
[2022-12-07 00:31:45,367] [INFO] [runner_train_mujoco] Average state value: 0.4858874318102996
[2022-12-07 00:31:45,367] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 00:31:45,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.04722
[2022-12-07 00:31:45,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.01904, loss val: 0.04701
[2022-12-07 00:31:45,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.02610, loss val: 0.04716
[2022-12-07 00:31:45,546] [INFO] [controller] EPOCH 4 loss ppo:  -0.03404, loss val: 0.04707
[2022-12-07 00:31:45,556] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:31:45,760] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:31:45,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:31:53,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:32:01,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:32:09,236] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:32:16,523] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:32:23,629] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:32:31,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:32:39,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:32:46,501] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:32:53,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:33:00,982] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.6623559155477015
[2022-12-07 00:33:00,982] [INFO] [runner_train_mujoco] Average state value: 0.48560410018761946
[2022-12-07 00:33:00,982] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 00:33:01,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04019
[2022-12-07 00:33:01,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.01689, loss val: 0.04062
[2022-12-07 00:33:01,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.02129, loss val: 0.04035
[2022-12-07 00:33:01,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.02725, loss val: 0.03992
[2022-12-07 00:33:01,219] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:33:01,432] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:33:01,432] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:33:09,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:33:16,624] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:33:24,532] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:33:31,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:33:39,703] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:33:47,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:33:55,468] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:34:04,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:34:12,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:34:22,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.221044954595787
[2022-12-07 00:34:22,106] [INFO] [runner_train_mujoco] Average state value: 0.4808971091508865
[2022-12-07 00:34:22,106] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 00:34:22,163] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04355
[2022-12-07 00:34:22,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.01543, loss val: 0.04370
[2022-12-07 00:34:22,262] [INFO] [controller] EPOCH 3 loss ppo:  -0.01749, loss val: 0.04695
[2022-12-07 00:34:22,311] [INFO] [controller] EPOCH 4 loss ppo:  -0.02012, loss val: 0.04329
[2022-12-07 00:34:22,321] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:34:22,457] [INFO] [optimize] Finished learning.
