[2022-12-07 03:29:36,509] [INFO] [optimize] Starting learning
[2022-12-07 03:29:36,528] [INFO] [optimize] Starting learning process..
[2022-12-07 03:29:36,647] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:29:36,648] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:29:46,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:29:54,449] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:30:02,232] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:30:10,171] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:30:18,252] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:30:26,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:30:34,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:30:42,611] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:30:51,634] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:30:59,889] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44618199152736615
[2022-12-07 03:30:59,889] [INFO] [runner_train_mujoco] Average state value: -0.10357390278577802
[2022-12-07 03:30:59,889] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 03:30:59,945] [INFO] [controller] EPOCH 1 loss ppo:  -0.01191, loss val: 0.43867
[2022-12-07 03:30:59,989] [INFO] [controller] EPOCH 2 loss ppo:  -0.04828, loss val: 0.38993
[2022-12-07 03:31:00,050] [INFO] [controller] EPOCH 3 loss ppo:  -0.06592, loss val: 0.33725
[2022-12-07 03:31:00,091] [INFO] [controller] EPOCH 4 loss ppo:  -0.07904, loss val: 0.29424
[2022-12-07 03:31:00,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:31:00,319] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:31:00,320] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:31:08,152] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:31:16,297] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:31:24,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:31:32,385] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:31:40,460] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:31:48,507] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:31:56,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:32:04,422] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:32:12,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:32:20,777] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6139706560190309
[2022-12-07 03:32:20,777] [INFO] [runner_train_mujoco] Average state value: 0.08935218190867453
[2022-12-07 03:32:20,777] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 03:32:20,832] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.30422
[2022-12-07 03:32:20,884] [INFO] [controller] EPOCH 2 loss ppo:  -0.04856, loss val: 0.27755
[2022-12-07 03:32:20,931] [INFO] [controller] EPOCH 3 loss ppo:  -0.06646, loss val: 0.23231
[2022-12-07 03:32:20,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.07883, loss val: 0.22772
[2022-12-07 03:32:20,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:32:21,212] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:32:21,213] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:32:29,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:32:37,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:32:46,239] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:32:53,839] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:33:01,706] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:33:09,338] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:33:17,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:33:27,605] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:33:38,276] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:33:47,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6499191246789296
[2022-12-07 03:33:47,548] [INFO] [runner_train_mujoco] Average state value: 0.26443848938619097
[2022-12-07 03:33:47,548] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 03:33:47,615] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.14109
[2022-12-07 03:33:47,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.04952, loss val: 0.11171
[2022-12-07 03:33:47,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.07384, loss val: 0.10003
[2022-12-07 03:33:47,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.08396, loss val: 0.10174
[2022-12-07 03:33:47,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:33:48,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:33:48,033] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:33:56,735] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:34:05,574] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:34:14,489] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:34:23,529] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:34:32,266] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:34:41,763] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:34:51,274] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:35:00,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:35:09,684] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:35:18,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5206897826820309
[2022-12-07 03:35:18,590] [INFO] [runner_train_mujoco] Average state value: 0.36697570522874595
[2022-12-07 03:35:18,590] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 03:35:18,644] [INFO] [controller] EPOCH 1 loss ppo:  -0.01172, loss val: 0.11338
[2022-12-07 03:35:18,691] [INFO] [controller] EPOCH 2 loss ppo:  -0.04835, loss val: 0.09677
[2022-12-07 03:35:18,736] [INFO] [controller] EPOCH 3 loss ppo:  -0.06620, loss val: 0.09377
[2022-12-07 03:35:18,782] [INFO] [controller] EPOCH 4 loss ppo:  -0.07770, loss val: 0.08269
[2022-12-07 03:35:18,792] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:35:19,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:35:19,005] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:35:27,703] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:35:36,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:35:45,408] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:35:54,456] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:36:03,167] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:36:11,707] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:36:20,482] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:36:29,416] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:36:38,147] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:36:47,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5199399995627176
[2022-12-07 03:36:47,304] [INFO] [runner_train_mujoco] Average state value: 0.48354875723583
[2022-12-07 03:36:47,305] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 03:36:47,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01121, loss val: 0.06864
[2022-12-07 03:36:47,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.04043, loss val: 0.06530
[2022-12-07 03:36:47,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.05876, loss val: 0.06213
[2022-12-07 03:36:47,550] [INFO] [controller] EPOCH 4 loss ppo:  -0.06677, loss val: 0.06074
[2022-12-07 03:36:47,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:36:47,787] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:36:47,788] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:36:56,495] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:37:05,661] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:37:14,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:37:22,855] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:37:31,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:37:40,255] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:37:48,951] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:37:58,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:38:07,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:38:15,950] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.488445992531003
[2022-12-07 03:38:15,950] [INFO] [runner_train_mujoco] Average state value: 0.4994415126467744
[2022-12-07 03:38:15,951] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 03:38:16,009] [INFO] [controller] EPOCH 1 loss ppo:  -0.01074, loss val: 0.07400
[2022-12-07 03:38:16,055] [INFO] [controller] EPOCH 2 loss ppo:  -0.04259, loss val: 0.06976
[2022-12-07 03:38:16,105] [INFO] [controller] EPOCH 3 loss ppo:  -0.06209, loss val: 0.06772
[2022-12-07 03:38:16,149] [INFO] [controller] EPOCH 4 loss ppo:  -0.07470, loss val: 0.06336
[2022-12-07 03:38:16,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:38:16,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:38:16,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:38:25,635] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:38:34,651] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:38:43,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:38:52,200] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:39:00,805] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:39:09,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:39:17,992] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:39:26,954] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:39:35,895] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:39:44,879] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.63731296635759
[2022-12-07 03:39:44,879] [INFO] [runner_train_mujoco] Average state value: 0.5373786337996522
[2022-12-07 03:39:44,879] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 03:39:44,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01175, loss val: 0.06356
[2022-12-07 03:39:45,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.03991, loss val: 0.06385
[2022-12-07 03:39:45,061] [INFO] [controller] EPOCH 3 loss ppo:  -0.05523, loss val: 0.06373
[2022-12-07 03:39:45,123] [INFO] [controller] EPOCH 4 loss ppo:  -0.06663, loss val: 0.05660
[2022-12-07 03:39:45,132] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:39:45,348] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:39:45,348] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:39:54,330] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:40:03,367] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:40:12,266] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:40:20,518] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:40:29,058] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:40:37,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:40:46,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:40:55,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:41:04,295] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:41:13,094] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5229645710753811
[2022-12-07 03:41:13,095] [INFO] [runner_train_mujoco] Average state value: 0.5251420956527194
[2022-12-07 03:41:13,095] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 03:41:13,172] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.04826
[2022-12-07 03:41:13,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.04863, loss val: 0.04831
[2022-12-07 03:41:13,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.06574, loss val: 0.04658
[2022-12-07 03:41:13,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.07615, loss val: 0.04635
[2022-12-07 03:41:13,312] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:41:13,527] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:41:13,528] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:41:22,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:41:31,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:41:40,028] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:41:49,330] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:41:58,163] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:42:07,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:42:15,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:42:24,790] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:42:32,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:42:41,044] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6668864363897951
[2022-12-07 03:42:41,044] [INFO] [runner_train_mujoco] Average state value: 0.48560551579358674
[2022-12-07 03:42:41,044] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 03:42:41,104] [INFO] [controller] EPOCH 1 loss ppo:  -0.01090, loss val: 0.04311
[2022-12-07 03:42:41,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.04468, loss val: 0.04144
[2022-12-07 03:42:41,187] [INFO] [controller] EPOCH 3 loss ppo:  -0.05992, loss val: 0.04073
[2022-12-07 03:42:41,238] [INFO] [controller] EPOCH 4 loss ppo:  -0.07052, loss val: 0.03971
[2022-12-07 03:42:41,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:42:41,453] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:42:41,453] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:42:49,821] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:42:57,950] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:43:06,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:43:14,226] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:43:22,694] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:43:30,607] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:43:38,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:43:45,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:43:53,689] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:44:01,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4803832602722194
[2022-12-07 03:44:01,509] [INFO] [runner_train_mujoco] Average state value: 0.494484352534016
[2022-12-07 03:44:01,509] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 03:44:01,558] [INFO] [controller] EPOCH 1 loss ppo:  -0.01170, loss val: 0.04754
[2022-12-07 03:44:01,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.04351, loss val: 0.04662
[2022-12-07 03:44:01,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.06088, loss val: 0.04402
[2022-12-07 03:44:01,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.06906, loss val: 0.04423
[2022-12-07 03:44:01,706] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:44:01,907] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:44:01,908] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:44:10,432] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:44:18,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:44:26,047] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:44:33,258] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:44:40,852] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:44:48,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:44:56,590] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:45:03,779] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:45:10,556] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:45:17,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5626626452093657
[2022-12-07 03:45:17,298] [INFO] [runner_train_mujoco] Average state value: 0.5216366431713105
[2022-12-07 03:45:17,298] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 03:45:17,345] [INFO] [controller] EPOCH 1 loss ppo:  -0.01051, loss val: 0.04452
[2022-12-07 03:45:17,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.04345, loss val: 0.03953
[2022-12-07 03:45:17,426] [INFO] [controller] EPOCH 3 loss ppo:  -0.06346, loss val: 0.03726
[2022-12-07 03:45:17,466] [INFO] [controller] EPOCH 4 loss ppo:  -0.07648, loss val: 0.03595
[2022-12-07 03:45:17,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:45:17,678] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:45:17,678] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:45:24,652] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:45:31,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:45:38,614] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:45:46,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:45:53,155] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:46:00,395] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:46:07,459] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:46:14,271] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:46:21,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:46:28,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7499092196695728
[2022-12-07 03:46:28,098] [INFO] [runner_train_mujoco] Average state value: 0.5491239721874395
[2022-12-07 03:46:28,099] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 03:46:28,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.04661
[2022-12-07 03:46:28,192] [INFO] [controller] EPOCH 2 loss ppo:  -0.04218, loss val: 0.04658
[2022-12-07 03:46:28,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.05978, loss val: 0.04545
[2022-12-07 03:46:28,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.07136, loss val: 0.04533
[2022-12-07 03:46:28,285] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:46:28,493] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:46:28,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:46:35,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:46:43,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:46:51,898] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:46:59,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:47:06,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:47:13,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:47:20,596] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:47:27,611] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:47:34,168] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:47:40,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.530700790271074
[2022-12-07 03:47:40,914] [INFO] [runner_train_mujoco] Average state value: 0.5681518145700296
[2022-12-07 03:47:40,915] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 03:47:40,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.04745
[2022-12-07 03:47:41,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.04244, loss val: 0.04612
[2022-12-07 03:47:41,055] [INFO] [controller] EPOCH 3 loss ppo:  -0.05967, loss val: 0.04400
[2022-12-07 03:47:41,101] [INFO] [controller] EPOCH 4 loss ppo:  -0.07136, loss val: 0.03980
[2022-12-07 03:47:41,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:47:41,338] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:47:41,339] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:47:48,275] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:47:55,852] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:48:03,253] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:48:10,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:48:17,444] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:48:24,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:48:31,334] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:48:38,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:48:45,213] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:48:52,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9003655945938467
[2022-12-07 03:48:52,421] [INFO] [runner_train_mujoco] Average state value: 0.522285220950842
[2022-12-07 03:48:52,421] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 03:48:52,471] [INFO] [controller] EPOCH 1 loss ppo:  -0.01172, loss val: 0.03654
[2022-12-07 03:48:52,514] [INFO] [controller] EPOCH 2 loss ppo:  -0.04267, loss val: 0.03421
[2022-12-07 03:48:52,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.06222, loss val: 0.03146
[2022-12-07 03:48:52,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.07880, loss val: 0.03091
[2022-12-07 03:48:52,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:48:52,863] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:48:52,863] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:48:59,717] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:49:07,205] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:49:14,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:49:21,272] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:49:28,229] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:49:35,190] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:49:42,435] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:49:49,430] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:49:56,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:50:03,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0731037717652587
[2022-12-07 03:50:03,300] [INFO] [runner_train_mujoco] Average state value: 0.4410551589628061
[2022-12-07 03:50:03,300] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 03:50:03,352] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.02979
[2022-12-07 03:50:03,394] [INFO] [controller] EPOCH 2 loss ppo:  -0.04521, loss val: 0.02944
[2022-12-07 03:50:03,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.06513, loss val: 0.03042
[2022-12-07 03:50:03,472] [INFO] [controller] EPOCH 4 loss ppo:  -0.07903, loss val: 0.02846
[2022-12-07 03:50:03,480] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:50:03,678] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:50:03,678] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:50:10,489] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:50:17,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:50:24,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:50:31,443] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:50:38,644] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:50:45,950] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:50:53,384] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:51:00,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:51:06,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:51:13,669] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3473191617503395
[2022-12-07 03:51:13,669] [INFO] [runner_train_mujoco] Average state value: 0.3854260859216253
[2022-12-07 03:51:13,669] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 03:51:13,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.03038
[2022-12-07 03:51:13,762] [INFO] [controller] EPOCH 2 loss ppo:  -0.04282, loss val: 0.02929
[2022-12-07 03:51:13,798] [INFO] [controller] EPOCH 3 loss ppo:  -0.06016, loss val: 0.02805
[2022-12-07 03:51:13,839] [INFO] [controller] EPOCH 4 loss ppo:  -0.07340, loss val: 0.02747
[2022-12-07 03:51:13,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:51:14,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:51:14,052] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:51:21,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:51:28,212] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:51:35,400] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:51:42,956] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:51:49,976] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:51:57,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:52:03,963] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:52:10,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:52:18,037] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:52:24,809] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0121862834614586
[2022-12-07 03:52:24,809] [INFO] [runner_train_mujoco] Average state value: 0.3932596022697787
[2022-12-07 03:52:24,809] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 03:52:24,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.03483
[2022-12-07 03:52:24,898] [INFO] [controller] EPOCH 2 loss ppo:  -0.04494, loss val: 0.03485
[2022-12-07 03:52:24,935] [INFO] [controller] EPOCH 3 loss ppo:  -0.06517, loss val: 0.03350
[2022-12-07 03:52:24,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.07759, loss val: 0.03325
[2022-12-07 03:52:24,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:52:25,166] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:52:25,166] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:52:32,615] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:52:39,856] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:52:46,789] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:52:54,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:53:01,534] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:53:08,865] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:53:15,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:53:22,819] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:53:29,492] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:53:36,231] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0228554571320596
[2022-12-07 03:53:36,231] [INFO] [runner_train_mujoco] Average state value: 0.4224950568278631
[2022-12-07 03:53:36,231] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 03:53:36,287] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.05394
[2022-12-07 03:53:36,327] [INFO] [controller] EPOCH 2 loss ppo:  -0.03914, loss val: 0.04782
[2022-12-07 03:53:36,363] [INFO] [controller] EPOCH 3 loss ppo:  -0.05207, loss val: 0.04405
[2022-12-07 03:53:36,402] [INFO] [controller] EPOCH 4 loss ppo:  -0.06767, loss val: 0.03977
[2022-12-07 03:53:36,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:53:36,620] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:53:36,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:53:43,973] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:53:51,004] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:53:58,185] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:54:05,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:54:12,041] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:54:19,272] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:54:26,149] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:54:32,998] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:54:40,056] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:54:46,860] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.296691204988288
[2022-12-07 03:54:46,860] [INFO] [runner_train_mujoco] Average state value: 0.49845801507433257
[2022-12-07 03:54:46,860] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 03:54:46,906] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.03754
[2022-12-07 03:54:46,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.04281, loss val: 0.03756
[2022-12-07 03:54:46,985] [INFO] [controller] EPOCH 3 loss ppo:  -0.06362, loss val: 0.03792
[2022-12-07 03:54:47,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.07600, loss val: 0.03771
[2022-12-07 03:54:47,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:54:47,235] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:54:47,235] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:54:54,048] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:55:00,968] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:55:10,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:55:18,190] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:55:25,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:55:32,770] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:55:39,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:55:46,322] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:55:52,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:55:59,768] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9145292050520526
[2022-12-07 03:55:59,768] [INFO] [runner_train_mujoco] Average state value: 0.5594059503674507
[2022-12-07 03:55:59,768] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 03:55:59,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01566, loss val: 0.05352
[2022-12-07 03:55:59,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.04431, loss val: 0.05474
[2022-12-07 03:55:59,896] [INFO] [controller] EPOCH 3 loss ppo:  -0.06049, loss val: 0.05243
[2022-12-07 03:55:59,939] [INFO] [controller] EPOCH 4 loss ppo:  -0.07737, loss val: 0.05228
[2022-12-07 03:55:59,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:56:00,152] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:56:00,153] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:56:07,332] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:56:15,980] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:56:22,939] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:56:30,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:56:36,993] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:56:44,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:56:50,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:56:58,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:57:06,715] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:57:13,831] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.127225398839238
[2022-12-07 03:57:13,831] [INFO] [runner_train_mujoco] Average state value: 0.5376132118304571
[2022-12-07 03:57:13,831] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 03:57:13,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04305
[2022-12-07 03:57:13,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.04137, loss val: 0.04050
[2022-12-07 03:57:13,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.05747, loss val: 0.03988
[2022-12-07 03:57:13,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.07434, loss val: 0.03628
[2022-12-07 03:57:14,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:57:14,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:57:14,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:57:21,255] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:57:27,978] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:57:35,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:57:42,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:57:50,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:57:57,968] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:58:04,923] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:58:11,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:58:18,946] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:58:25,897] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.457078827727609
[2022-12-07 03:58:25,897] [INFO] [runner_train_mujoco] Average state value: 0.47614869838953017
[2022-12-07 03:58:25,897] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 03:58:25,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.04009
[2022-12-07 03:58:25,996] [INFO] [controller] EPOCH 2 loss ppo:  -0.04333, loss val: 0.04093
[2022-12-07 03:58:26,035] [INFO] [controller] EPOCH 3 loss ppo:  -0.06286, loss val: 0.03929
[2022-12-07 03:58:26,072] [INFO] [controller] EPOCH 4 loss ppo:  -0.07726, loss val: 0.03946
[2022-12-07 03:58:26,081] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:58:26,273] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:58:26,273] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:58:33,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:58:40,270] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:58:47,150] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:58:54,579] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:59:01,655] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:59:08,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:59:15,563] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:59:22,455] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:59:29,214] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:59:35,755] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.101510620969614
[2022-12-07 03:59:35,755] [INFO] [runner_train_mujoco] Average state value: 0.45769653933246934
[2022-12-07 03:59:35,755] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 03:59:35,802] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04895
[2022-12-07 03:59:35,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.04272, loss val: 0.04926
[2022-12-07 03:59:35,884] [INFO] [controller] EPOCH 3 loss ppo:  -0.05801, loss val: 0.04821
[2022-12-07 03:59:35,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.07590, loss val: 0.04778
[2022-12-07 03:59:35,931] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:59:36,117] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:59:36,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:59:42,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:59:50,055] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:59:57,183] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:00:04,301] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:00:11,611] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:00:18,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:00:25,594] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:00:32,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:00:38,990] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:00:45,977] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.434580227444211
[2022-12-07 04:00:45,977] [INFO] [runner_train_mujoco] Average state value: 0.4861997368435064
[2022-12-07 04:00:45,977] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 04:00:46,025] [INFO] [controller] EPOCH 1 loss ppo:  -0.01574, loss val: 0.05209
[2022-12-07 04:00:46,063] [INFO] [controller] EPOCH 2 loss ppo:  -0.04058, loss val: 0.05068
[2022-12-07 04:00:46,112] [INFO] [controller] EPOCH 3 loss ppo:  -0.05701, loss val: 0.04986
[2022-12-07 04:00:46,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.07278, loss val: 0.05081
[2022-12-07 04:00:46,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:00:46,371] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:00:46,371] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:00:53,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:01:01,746] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:01:08,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:01:15,531] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:01:22,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:01:29,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:01:36,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:01:44,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:01:54,105] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:02:01,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.101310302933271
[2022-12-07 04:02:01,014] [INFO] [runner_train_mujoco] Average state value: 0.47780141708254814
[2022-12-07 04:02:01,015] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 04:02:01,065] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.04538
[2022-12-07 04:02:01,105] [INFO] [controller] EPOCH 2 loss ppo:  -0.04032, loss val: 0.04616
[2022-12-07 04:02:01,140] [INFO] [controller] EPOCH 3 loss ppo:  -0.06030, loss val: 0.04593
[2022-12-07 04:02:01,180] [INFO] [controller] EPOCH 4 loss ppo:  -0.07915, loss val: 0.05147
[2022-12-07 04:02:01,189] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:02:01,395] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:02:01,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:02:08,111] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:02:14,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:02:21,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:02:29,123] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:02:36,002] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:02:43,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:02:49,738] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:02:56,288] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:03:03,235] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:03:09,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.726078468785973
[2022-12-07 04:03:09,923] [INFO] [runner_train_mujoco] Average state value: 0.4446556747953097
[2022-12-07 04:03:09,923] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 04:03:09,982] [INFO] [controller] EPOCH 1 loss ppo:  -0.01722, loss val: 0.03959
[2022-12-07 04:03:10,030] [INFO] [controller] EPOCH 2 loss ppo:  -0.03890, loss val: 0.04056
[2022-12-07 04:03:10,086] [INFO] [controller] EPOCH 3 loss ppo:  -0.05375, loss val: 0.04069
[2022-12-07 04:03:10,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.07375, loss val: 0.03943
[2022-12-07 04:03:10,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:03:10,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:03:10,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:03:17,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:03:24,494] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:03:31,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:03:38,447] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:03:45,479] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:03:52,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:03:59,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:04:06,256] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:04:12,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:04:20,022] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.313721917150471
[2022-12-07 04:04:20,022] [INFO] [runner_train_mujoco] Average state value: 0.42602499928077064
[2022-12-07 04:04:20,022] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 04:04:20,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04961
[2022-12-07 04:04:20,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.03193, loss val: 0.04847
[2022-12-07 04:04:20,159] [INFO] [controller] EPOCH 3 loss ppo:  -0.05224, loss val: 0.04734
[2022-12-07 04:04:20,204] [INFO] [controller] EPOCH 4 loss ppo:  -0.06725, loss val: 0.04701
[2022-12-07 04:04:20,213] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:04:20,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:04:20,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:04:27,650] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:04:34,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:04:41,832] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:04:49,149] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:04:56,089] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:05:03,210] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:05:10,079] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:05:16,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:05:23,610] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:05:30,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4629029947553125
[2022-12-07 04:05:30,371] [INFO] [runner_train_mujoco] Average state value: 0.43279858760039014
[2022-12-07 04:05:30,372] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 04:05:30,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.03791
[2022-12-07 04:05:30,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.03670, loss val: 0.03845
[2022-12-07 04:05:30,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.05525, loss val: 0.03820
[2022-12-07 04:05:30,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.07243, loss val: 0.04103
[2022-12-07 04:05:30,563] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:05:30,758] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:05:30,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:05:37,405] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:05:44,752] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:05:51,797] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:06:00,245] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:06:07,273] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:06:14,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:06:21,293] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:06:27,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:06:34,304] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:06:41,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.760909257948247
[2022-12-07 04:06:41,112] [INFO] [runner_train_mujoco] Average state value: 0.4365505495580534
[2022-12-07 04:06:41,112] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 04:06:41,165] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.05868
[2022-12-07 04:06:41,209] [INFO] [controller] EPOCH 2 loss ppo:  -0.03612, loss val: 0.05683
[2022-12-07 04:06:41,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.05120, loss val: 0.05546
[2022-12-07 04:06:41,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.06579, loss val: 0.04930
[2022-12-07 04:06:41,300] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:06:41,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:06:41,480] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:06:48,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:06:56,935] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:07:05,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:07:14,379] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:07:21,689] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:07:28,630] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:07:35,379] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:07:42,119] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:07:48,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:07:56,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.721697033520993
[2022-12-07 04:07:56,110] [INFO] [runner_train_mujoco] Average state value: 0.45991225651651624
[2022-12-07 04:07:56,110] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 04:07:56,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.05483
[2022-12-07 04:07:56,195] [INFO] [controller] EPOCH 2 loss ppo:  -0.04287, loss val: 0.05303
[2022-12-07 04:07:56,237] [INFO] [controller] EPOCH 3 loss ppo:  -0.06243, loss val: 0.05193
[2022-12-07 04:07:56,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.07674, loss val: 0.05150
[2022-12-07 04:07:56,285] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:07:56,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:07:56,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:08:03,843] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:08:10,900] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:08:17,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:08:25,254] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:08:31,985] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:08:38,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:08:46,197] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:08:52,868] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:09:01,872] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:09:08,490] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.8846643149760895
[2022-12-07 04:09:08,490] [INFO] [runner_train_mujoco] Average state value: 0.5432733621696633
[2022-12-07 04:09:08,490] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 04:09:08,537] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.06110
[2022-12-07 04:09:08,577] [INFO] [controller] EPOCH 2 loss ppo:  -0.03362, loss val: 0.05950
[2022-12-07 04:09:08,677] [INFO] [controller] EPOCH 3 loss ppo:  -0.05152, loss val: 0.05922
[2022-12-07 04:09:08,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.06468, loss val: 0.05798
[2022-12-07 04:09:08,727] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:09:08,915] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:09:08,915] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:09:15,720] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:09:23,033] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:09:29,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:09:36,776] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:09:43,726] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:09:50,743] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:09:57,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:10:04,737] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:10:11,225] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:10:17,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4147581536055815
[2022-12-07 04:10:17,834] [INFO] [runner_train_mujoco] Average state value: 0.5111883559934796
[2022-12-07 04:10:17,834] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 04:10:17,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.05923
[2022-12-07 04:10:17,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.03929, loss val: 0.05842
[2022-12-07 04:10:17,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.05370, loss val: 0.05759
[2022-12-07 04:10:18,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.07170, loss val: 0.05716
[2022-12-07 04:10:18,024] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:10:18,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:10:18,220] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:10:25,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:10:32,958] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:10:39,957] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:10:46,994] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:10:53,902] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:11:01,943] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:11:08,504] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:11:15,260] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:11:21,772] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:11:28,491] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.126573021187592
[2022-12-07 04:11:28,491] [INFO] [runner_train_mujoco] Average state value: 0.5091365908384323
[2022-12-07 04:11:28,491] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 04:11:28,539] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04681
[2022-12-07 04:11:28,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.03680, loss val: 0.04438
[2022-12-07 04:11:28,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.05710, loss val: 0.04391
[2022-12-07 04:11:28,667] [INFO] [controller] EPOCH 4 loss ppo:  -0.07132, loss val: 0.04438
[2022-12-07 04:11:28,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:11:28,850] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:11:28,851] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:11:36,173] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:11:43,596] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:11:50,316] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:11:56,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:12:04,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:12:12,257] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:12:19,462] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:12:27,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:12:33,928] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:12:40,688] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.830396032278603
[2022-12-07 04:12:40,688] [INFO] [runner_train_mujoco] Average state value: 0.4878522004584472
[2022-12-07 04:12:40,689] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 04:12:40,738] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.04626
[2022-12-07 04:12:40,775] [INFO] [controller] EPOCH 2 loss ppo:  -0.03719, loss val: 0.04659
[2022-12-07 04:12:40,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.05454, loss val: 0.04585
[2022-12-07 04:12:40,857] [INFO] [controller] EPOCH 4 loss ppo:  -0.06906, loss val: 0.04841
[2022-12-07 04:12:40,865] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:12:41,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:12:41,051] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:12:47,965] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:12:54,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:13:01,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:13:08,429] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:13:15,395] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:13:22,536] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:13:29,707] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:13:37,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:13:43,941] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:13:50,506] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.301371900947133
[2022-12-07 04:13:50,506] [INFO] [runner_train_mujoco] Average state value: 0.5082264468769233
[2022-12-07 04:13:50,506] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 04:13:50,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04514
[2022-12-07 04:13:50,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.03406, loss val: 0.04490
[2022-12-07 04:13:50,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.04750, loss val: 0.04353
[2022-12-07 04:13:50,680] [INFO] [controller] EPOCH 4 loss ppo:  -0.06650, loss val: 0.04559
[2022-12-07 04:13:50,689] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:13:50,889] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:13:50,889] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:13:57,753] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:14:05,202] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:14:11,828] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:14:18,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:14:25,190] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:14:32,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:14:39,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:14:46,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:14:53,201] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:15:00,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.4141561658322725
[2022-12-07 04:15:00,070] [INFO] [runner_train_mujoco] Average state value: 0.5273735094567139
[2022-12-07 04:15:00,070] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 04:15:00,136] [INFO] [controller] EPOCH 1 loss ppo:  -0.01512, loss val: 0.03625
[2022-12-07 04:15:00,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03457, loss val: 0.03644
[2022-12-07 04:15:00,271] [INFO] [controller] EPOCH 3 loss ppo:  -0.05135, loss val: 0.03693
[2022-12-07 04:15:00,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.06773, loss val: 0.03609
[2022-12-07 04:15:00,322] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:15:00,517] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:15:00,518] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:15:07,998] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:15:15,200] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:15:22,082] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:15:28,398] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:15:34,711] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:15:41,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:15:48,166] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:15:57,429] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:16:06,343] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:16:14,094] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.60446046942706
[2022-12-07 04:16:14,095] [INFO] [runner_train_mujoco] Average state value: 0.5214684581061204
[2022-12-07 04:16:14,095] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 04:16:14,146] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.06575
[2022-12-07 04:16:14,192] [INFO] [controller] EPOCH 2 loss ppo:  -0.02972, loss val: 0.06431
[2022-12-07 04:16:14,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.04232, loss val: 0.06203
[2022-12-07 04:16:14,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.05648, loss val: 0.05862
[2022-12-07 04:16:14,289] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:16:14,498] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:16:14,498] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:16:22,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:16:30,986] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:16:38,254] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:16:46,145] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:16:54,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:17:02,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:17:10,883] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:17:18,012] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:17:25,490] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:17:33,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.208703668489562
[2022-12-07 04:17:33,444] [INFO] [runner_train_mujoco] Average state value: 0.4803349573214849
[2022-12-07 04:17:33,444] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 04:17:33,495] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.03591
[2022-12-07 04:17:33,536] [INFO] [controller] EPOCH 2 loss ppo:  -0.02970, loss val: 0.03447
[2022-12-07 04:17:33,583] [INFO] [controller] EPOCH 3 loss ppo:  -0.04309, loss val: 0.03443
[2022-12-07 04:17:33,629] [INFO] [controller] EPOCH 4 loss ppo:  -0.05810, loss val: 0.03378
[2022-12-07 04:17:33,636] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:17:33,844] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:17:33,844] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:17:41,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:17:49,872] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:18:00,191] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:18:08,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:18:16,018] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:18:24,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:18:32,160] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:18:40,075] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:18:47,854] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:18:56,069] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.489494067127977
[2022-12-07 04:18:56,070] [INFO] [runner_train_mujoco] Average state value: 0.4208182128270467
[2022-12-07 04:18:56,070] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 04:18:56,140] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.06687
[2022-12-07 04:18:56,185] [INFO] [controller] EPOCH 2 loss ppo:  -0.02814, loss val: 0.06835
[2022-12-07 04:18:56,238] [INFO] [controller] EPOCH 3 loss ppo:  -0.04730, loss val: 0.06746
[2022-12-07 04:18:56,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.06156, loss val: 0.06629
[2022-12-07 04:18:56,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:18:56,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:18:56,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:19:04,831] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:19:12,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:19:20,443] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:19:29,379] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:19:37,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:19:44,835] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:19:54,069] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:20:01,844] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:20:10,122] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:20:18,189] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.047870442936544
[2022-12-07 04:20:18,189] [INFO] [runner_train_mujoco] Average state value: 0.42546419212346276
[2022-12-07 04:20:18,189] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 04:20:18,245] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.08168
[2022-12-07 04:20:18,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.02735, loss val: 0.07687
[2022-12-07 04:20:18,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.04087, loss val: 0.07538
[2022-12-07 04:20:18,379] [INFO] [controller] EPOCH 4 loss ppo:  -0.05279, loss val: 0.07062
[2022-12-07 04:20:18,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:20:18,595] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:20:18,596] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:20:26,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:20:34,595] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:20:41,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:20:49,645] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:20:57,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:21:05,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:21:13,976] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:21:21,427] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:21:28,963] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:21:37,787] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.815918917807343
[2022-12-07 04:21:37,788] [INFO] [runner_train_mujoco] Average state value: 0.48049526518086594
[2022-12-07 04:21:37,788] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 04:21:37,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04036
[2022-12-07 04:21:37,890] [INFO] [controller] EPOCH 2 loss ppo:  -0.03117, loss val: 0.03895
[2022-12-07 04:21:37,947] [INFO] [controller] EPOCH 3 loss ppo:  -0.04583, loss val: 0.03845
[2022-12-07 04:21:38,007] [INFO] [controller] EPOCH 4 loss ppo:  -0.06147, loss val: 0.03839
[2022-12-07 04:21:38,019] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:21:38,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:21:38,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:21:46,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:21:54,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:22:03,902] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:22:12,521] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:22:20,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:22:28,625] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:22:35,689] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:22:43,351] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:22:51,222] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:22:59,589] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.840995402445159
[2022-12-07 04:22:59,589] [INFO] [runner_train_mujoco] Average state value: 0.5262740093568962
[2022-12-07 04:22:59,589] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 04:22:59,641] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04152
[2022-12-07 04:22:59,692] [INFO] [controller] EPOCH 2 loss ppo:  -0.03020, loss val: 0.04013
[2022-12-07 04:22:59,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.04434, loss val: 0.03974
[2022-12-07 04:22:59,800] [INFO] [controller] EPOCH 4 loss ppo:  -0.05900, loss val: 0.03986
[2022-12-07 04:22:59,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:23:00,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:23:00,033] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:23:09,712] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:23:17,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:23:24,942] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:23:33,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:23:40,671] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:23:48,993] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:23:56,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:24:04,537] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:24:12,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:24:20,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.372108991272951
[2022-12-07 04:24:20,117] [INFO] [runner_train_mujoco] Average state value: 0.5456939138236144
[2022-12-07 04:24:20,117] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 04:24:20,170] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04248
[2022-12-07 04:24:20,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.03062, loss val: 0.04172
[2022-12-07 04:24:20,267] [INFO] [controller] EPOCH 3 loss ppo:  -0.04552, loss val: 0.04203
[2022-12-07 04:24:20,320] [INFO] [controller] EPOCH 4 loss ppo:  -0.05904, loss val: 0.04208
[2022-12-07 04:24:20,330] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:24:20,534] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:24:20,535] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:24:28,635] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:24:38,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:24:46,937] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:24:54,891] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:25:03,457] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:25:11,174] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:25:18,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:25:26,359] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:25:34,051] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:25:44,187] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.552512999446018
[2022-12-07 04:25:44,187] [INFO] [runner_train_mujoco] Average state value: 0.5678895696401596
[2022-12-07 04:25:44,188] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 04:25:44,244] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.05294
[2022-12-07 04:25:44,293] [INFO] [controller] EPOCH 2 loss ppo:  -0.02814, loss val: 0.04763
[2022-12-07 04:25:44,343] [INFO] [controller] EPOCH 3 loss ppo:  -0.04041, loss val: 0.05159
[2022-12-07 04:25:44,395] [INFO] [controller] EPOCH 4 loss ppo:  -0.05024, loss val: 0.04546
[2022-12-07 04:25:44,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:25:44,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:25:44,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:25:52,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:26:00,216] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:26:08,099] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:26:16,102] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:26:24,918] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:26:32,774] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:26:41,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:26:48,893] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:26:56,249] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:27:04,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.7759816896447
[2022-12-07 04:27:04,381] [INFO] [runner_train_mujoco] Average state value: 0.5201449865599473
[2022-12-07 04:27:04,381] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 04:27:04,437] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.05216
[2022-12-07 04:27:04,483] [INFO] [controller] EPOCH 2 loss ppo:  -0.02708, loss val: 0.05393
[2022-12-07 04:27:04,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.04186, loss val: 0.05212
[2022-12-07 04:27:04,611] [INFO] [controller] EPOCH 4 loss ppo:  -0.05605, loss val: 0.05218
[2022-12-07 04:27:04,622] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:27:04,828] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:27:04,828] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:27:12,578] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:27:20,385] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:27:27,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:27:35,765] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:27:43,269] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:27:51,976] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:27:59,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:28:07,064] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:28:15,568] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:28:23,373] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.193497969804038
[2022-12-07 04:28:23,373] [INFO] [runner_train_mujoco] Average state value: 0.5354923445781072
[2022-12-07 04:28:23,373] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 04:28:23,424] [INFO] [controller] EPOCH 1 loss ppo:  -0.01244, loss val: 0.04225
[2022-12-07 04:28:23,543] [INFO] [controller] EPOCH 2 loss ppo:  -0.02477, loss val: 0.04234
[2022-12-07 04:28:23,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.03666, loss val: 0.04135
[2022-12-07 04:28:23,640] [INFO] [controller] EPOCH 4 loss ppo:  -0.05043, loss val: 0.04155
[2022-12-07 04:28:23,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:28:23,858] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:28:23,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:28:31,600] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:28:39,447] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:28:47,704] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:28:55,339] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:29:03,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:29:10,826] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:29:18,481] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:29:26,033] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:29:33,561] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:29:41,551] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.403414075866086
[2022-12-07 04:29:41,551] [INFO] [runner_train_mujoco] Average state value: 0.5373698905110358
[2022-12-07 04:29:41,551] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 04:29:41,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.01275, loss val: 0.04458
[2022-12-07 04:29:41,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.02469, loss val: 0.04693
[2022-12-07 04:29:41,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.03609, loss val: 0.04536
[2022-12-07 04:29:41,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.04895, loss val: 0.04470
[2022-12-07 04:29:41,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:29:41,964] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:29:41,964] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:29:49,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:29:57,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:30:05,407] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:30:12,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:30:20,058] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:30:27,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:30:33,771] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:30:41,155] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:30:48,484] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:30:55,114] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.372787660449177
[2022-12-07 04:30:55,114] [INFO] [runner_train_mujoco] Average state value: 0.5647157461444536
[2022-12-07 04:30:55,114] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 04:30:55,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.05822
[2022-12-07 04:30:55,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.02423, loss val: 0.05096
[2022-12-07 04:30:55,300] [INFO] [controller] EPOCH 3 loss ppo:  -0.03624, loss val: 0.05448
[2022-12-07 04:30:55,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.04859, loss val: 0.04962
[2022-12-07 04:30:55,346] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:30:55,538] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:30:55,539] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:31:02,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:31:11,079] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:31:19,099] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:31:26,128] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:31:33,707] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:31:40,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:31:47,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:31:55,241] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:32:02,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:32:09,243] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.647325199665914
[2022-12-07 04:32:09,243] [INFO] [runner_train_mujoco] Average state value: 0.5499586412707965
[2022-12-07 04:32:09,243] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 04:32:09,292] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.03840
[2022-12-07 04:32:09,331] [INFO] [controller] EPOCH 2 loss ppo:  -0.02649, loss val: 0.03775
[2022-12-07 04:32:09,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.04046, loss val: 0.03810
[2022-12-07 04:32:09,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.05206, loss val: 0.03832
[2022-12-07 04:32:09,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:32:09,601] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:32:09,601] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:32:17,612] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:32:26,741] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:32:33,481] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:32:40,308] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:32:47,491] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:32:56,054] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:33:03,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:33:10,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:33:17,780] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:33:25,425] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.28167919794231
[2022-12-07 04:33:25,425] [INFO] [runner_train_mujoco] Average state value: 0.4798952819767098
[2022-12-07 04:33:25,425] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 04:33:25,474] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.07403
[2022-12-07 04:33:25,515] [INFO] [controller] EPOCH 2 loss ppo:  -0.02393, loss val: 0.07420
[2022-12-07 04:33:25,558] [INFO] [controller] EPOCH 3 loss ppo:  -0.03499, loss val: 0.07348
[2022-12-07 04:33:25,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.04506, loss val: 0.07293
[2022-12-07 04:33:25,610] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:33:25,816] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:33:25,816] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:33:35,122] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:33:41,636] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:33:48,674] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:33:55,965] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:34:02,872] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:34:09,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:34:17,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:34:24,905] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:34:31,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:34:38,399] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.540443991023641
[2022-12-07 04:34:38,399] [INFO] [runner_train_mujoco] Average state value: 0.5276391573051612
[2022-12-07 04:34:38,399] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 04:34:38,448] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04623
[2022-12-07 04:34:38,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.02091, loss val: 0.04609
[2022-12-07 04:34:38,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.03541, loss val: 0.04601
[2022-12-07 04:34:38,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.04700, loss val: 0.04539
[2022-12-07 04:34:38,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:34:38,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:34:38,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:34:45,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:34:52,760] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:34:59,705] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:35:06,823] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:35:13,442] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:35:20,607] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:35:27,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:35:34,680] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:35:42,959] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:35:50,067] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.295534550623657
[2022-12-07 04:35:50,067] [INFO] [runner_train_mujoco] Average state value: 0.5182259116570155
[2022-12-07 04:35:50,067] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 04:35:50,115] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.05238
[2022-12-07 04:35:50,158] [INFO] [controller] EPOCH 2 loss ppo:  -0.01971, loss val: 0.05210
[2022-12-07 04:35:50,199] [INFO] [controller] EPOCH 3 loss ppo:  -0.03092, loss val: 0.05152
[2022-12-07 04:35:50,238] [INFO] [controller] EPOCH 4 loss ppo:  -0.04319, loss val: 0.05114
[2022-12-07 04:35:50,247] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:35:50,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:35:50,446] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:35:57,441] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:36:04,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:36:11,582] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:36:18,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:36:25,361] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:36:32,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:36:40,782] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:36:47,938] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:36:54,628] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:37:01,411] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.950485401892732
[2022-12-07 04:37:01,412] [INFO] [runner_train_mujoco] Average state value: 0.5026873936156432
[2022-12-07 04:37:01,412] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 04:37:01,461] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.03534
[2022-12-07 04:37:01,502] [INFO] [controller] EPOCH 2 loss ppo:  -0.02054, loss val: 0.03536
[2022-12-07 04:37:01,544] [INFO] [controller] EPOCH 3 loss ppo:  -0.03156, loss val: 0.03540
[2022-12-07 04:37:01,582] [INFO] [controller] EPOCH 4 loss ppo:  -0.04079, loss val: 0.03854
[2022-12-07 04:37:01,592] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:37:01,787] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:37:01,787] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:37:08,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:37:15,712] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:37:23,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:37:31,215] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:37:38,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:37:46,277] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:37:53,950] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:38:01,157] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:38:07,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:38:14,969] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.345426002848636
[2022-12-07 04:38:14,969] [INFO] [runner_train_mujoco] Average state value: 0.49709635223944987
[2022-12-07 04:38:14,970] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 04:38:15,057] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.03313
[2022-12-07 04:38:15,134] [INFO] [controller] EPOCH 2 loss ppo:  -0.02021, loss val: 0.03345
[2022-12-07 04:38:15,185] [INFO] [controller] EPOCH 3 loss ppo:  -0.03085, loss val: 0.03536
[2022-12-07 04:38:15,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.04052, loss val: 0.03361
[2022-12-07 04:38:15,244] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:38:15,450] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:38:15,450] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:38:23,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:38:30,302] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:38:36,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:38:44,171] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:38:51,337] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:38:57,947] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:39:06,273] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:39:12,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:39:19,514] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:39:26,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.257206074244188
[2022-12-07 04:39:26,342] [INFO] [runner_train_mujoco] Average state value: 0.49876802207032844
[2022-12-07 04:39:26,342] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 04:39:26,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04419
[2022-12-07 04:39:26,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.01868, loss val: 0.04349
[2022-12-07 04:39:26,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.02814, loss val: 0.04408
[2022-12-07 04:39:26,509] [INFO] [controller] EPOCH 4 loss ppo:  -0.03843, loss val: 0.04349
[2022-12-07 04:39:26,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:39:26,702] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:39:26,702] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:39:33,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:39:40,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:39:47,431] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:39:54,116] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:40:01,664] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:40:08,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:40:16,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:40:23,078] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:40:31,618] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:40:40,168] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.912677871074257
[2022-12-07 04:40:40,169] [INFO] [runner_train_mujoco] Average state value: 0.47532820350925126
[2022-12-07 04:40:40,169] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 04:40:40,218] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.05636
[2022-12-07 04:40:40,263] [INFO] [controller] EPOCH 2 loss ppo:  -0.01524, loss val: 0.05710
[2022-12-07 04:40:40,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.02131, loss val: 0.05664
[2022-12-07 04:40:40,355] [INFO] [controller] EPOCH 4 loss ppo:  -0.03003, loss val: 0.05667
[2022-12-07 04:40:40,364] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:40:40,549] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:40:40,550] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:40:48,918] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:40:55,786] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:41:03,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:41:09,958] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:41:17,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:41:24,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:41:31,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:41:38,508] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:41:46,690] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:41:54,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.35049960528368
[2022-12-07 04:41:54,375] [INFO] [runner_train_mujoco] Average state value: 0.47254661842932305
[2022-12-07 04:41:54,375] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 04:41:54,422] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04761
[2022-12-07 04:41:54,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.01608, loss val: 0.04786
[2022-12-07 04:41:54,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.02063, loss val: 0.04730
[2022-12-07 04:41:54,546] [INFO] [controller] EPOCH 4 loss ppo:  -0.02622, loss val: 0.04795
[2022-12-07 04:41:54,555] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:41:54,757] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:41:54,757] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:42:01,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:42:08,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:42:16,201] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:42:23,541] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:42:30,909] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:42:37,968] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:42:44,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:42:51,751] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:42:58,435] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:43:05,984] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.476674455591481
[2022-12-07 04:43:05,985] [INFO] [runner_train_mujoco] Average state value: 0.49728358221054075
[2022-12-07 04:43:05,985] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 04:43:06,032] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04063
[2022-12-07 04:43:06,073] [INFO] [controller] EPOCH 2 loss ppo:  -0.01423, loss val: 0.04231
[2022-12-07 04:43:06,115] [INFO] [controller] EPOCH 3 loss ppo:  -0.01612, loss val: 0.04147
[2022-12-07 04:43:06,153] [INFO] [controller] EPOCH 4 loss ppo:  -0.01894, loss val: 0.04324
[2022-12-07 04:43:06,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:43:06,275] [INFO] [optimize] Finished learning.
