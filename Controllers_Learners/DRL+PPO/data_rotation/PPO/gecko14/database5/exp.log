[2022-12-07 01:25:54,509] [INFO] [optimize] Starting learning
[2022-12-07 01:25:54,525] [INFO] [optimize] Starting learning process..
[2022-12-07 01:25:54,637] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:25:54,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:26:05,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:26:14,740] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:26:24,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:26:32,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:26:42,615] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:26:51,419] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:27:00,776] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:27:10,013] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:27:19,127] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:27:27,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5254255046568378
[2022-12-07 01:27:27,836] [INFO] [runner_train_mujoco] Average state value: 0.3050786845025917
[2022-12-07 01:27:27,837] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 01:27:27,899] [INFO] [controller] EPOCH 1 loss ppo:  -0.00850, loss val: 0.20849
[2022-12-07 01:27:27,956] [INFO] [controller] EPOCH 2 loss ppo:  -0.05228, loss val: 0.18109
[2022-12-07 01:27:28,005] [INFO] [controller] EPOCH 3 loss ppo:  -0.07048, loss val: 0.16095
[2022-12-07 01:27:28,054] [INFO] [controller] EPOCH 4 loss ppo:  -0.07902, loss val: 0.14356
[2022-12-07 01:27:28,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:27:28,291] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:27:28,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:27:37,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:27:50,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:27:58,774] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:28:08,224] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:28:17,210] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:28:25,877] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:28:35,066] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:28:43,902] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:28:52,443] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:29:01,408] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4813969897377035
[2022-12-07 01:29:01,408] [INFO] [runner_train_mujoco] Average state value: 0.44974194578143456
[2022-12-07 01:29:01,408] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 01:29:01,463] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.11734
[2022-12-07 01:29:01,510] [INFO] [controller] EPOCH 2 loss ppo:  -0.05031, loss val: 0.11056
[2022-12-07 01:29:01,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.06743, loss val: 0.10429
[2022-12-07 01:29:01,604] [INFO] [controller] EPOCH 4 loss ppo:  -0.07509, loss val: 0.09893
[2022-12-07 01:29:01,614] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:29:01,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:29:01,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:29:11,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:29:20,291] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:29:29,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:29:38,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:29:47,399] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:29:56,096] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:30:04,922] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:30:14,173] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:30:23,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:30:32,683] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4548361901631212
[2022-12-07 01:30:32,683] [INFO] [runner_train_mujoco] Average state value: 0.5296762023673702
[2022-12-07 01:30:32,683] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 01:30:32,749] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.10068
[2022-12-07 01:30:32,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.04200, loss val: 0.09555
[2022-12-07 01:30:32,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.05972, loss val: 0.08780
[2022-12-07 01:30:32,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.06840, loss val: 0.07722
[2022-12-07 01:30:32,937] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:30:33,153] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:30:33,153] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:30:42,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:30:51,310] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:30:59,940] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:31:08,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:31:17,717] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:31:26,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:31:35,783] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:31:45,014] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:31:53,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:32:03,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46609189289578057
[2022-12-07 01:32:03,550] [INFO] [runner_train_mujoco] Average state value: 0.49207198407687247
[2022-12-07 01:32:03,551] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 01:32:03,627] [INFO] [controller] EPOCH 1 loss ppo:  -0.01151, loss val: 0.09100
[2022-12-07 01:32:03,673] [INFO] [controller] EPOCH 2 loss ppo:  -0.04047, loss val: 0.08963
[2022-12-07 01:32:03,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.05595, loss val: 0.08608
[2022-12-07 01:32:03,778] [INFO] [controller] EPOCH 4 loss ppo:  -0.06793, loss val: 0.08127
[2022-12-07 01:32:03,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:32:04,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:32:04,002] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:32:14,111] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:32:23,848] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:32:33,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:32:42,209] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:32:51,580] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:33:00,495] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:33:09,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:33:18,342] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:33:27,306] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:33:36,233] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5530161161981979
[2022-12-07 01:33:36,233] [INFO] [runner_train_mujoco] Average state value: 0.4868627276197076
[2022-12-07 01:33:36,233] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 01:33:36,300] [INFO] [controller] EPOCH 1 loss ppo:  -0.01210, loss val: 0.06329
[2022-12-07 01:33:36,357] [INFO] [controller] EPOCH 2 loss ppo:  -0.04850, loss val: 0.06145
[2022-12-07 01:33:36,418] [INFO] [controller] EPOCH 3 loss ppo:  -0.06634, loss val: 0.05854
[2022-12-07 01:33:36,466] [INFO] [controller] EPOCH 4 loss ppo:  -0.07790, loss val: 0.05734
[2022-12-07 01:33:36,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:33:36,727] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:33:36,727] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:33:45,352] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:33:54,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:34:03,699] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:34:12,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:34:20,896] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:34:30,648] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:34:39,685] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:34:49,111] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:34:58,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:35:07,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48434091727598344
[2022-12-07 01:35:07,814] [INFO] [runner_train_mujoco] Average state value: 0.5489892343195775
[2022-12-07 01:35:07,814] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 01:35:07,871] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.06448
[2022-12-07 01:35:07,926] [INFO] [controller] EPOCH 2 loss ppo:  -0.04169, loss val: 0.06186
[2022-12-07 01:35:07,982] [INFO] [controller] EPOCH 3 loss ppo:  -0.06166, loss val: 0.06179
[2022-12-07 01:35:08,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.07041, loss val: 0.06099
[2022-12-07 01:35:08,038] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:35:08,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:35:08,250] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:35:17,351] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:35:26,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:35:35,112] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:35:44,076] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:35:52,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:36:01,662] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:36:10,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:36:19,183] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:36:28,136] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:36:37,829] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5228374108129775
[2022-12-07 01:36:37,829] [INFO] [runner_train_mujoco] Average state value: 0.5539728728135427
[2022-12-07 01:36:37,829] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 01:36:37,905] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.05518
[2022-12-07 01:36:37,964] [INFO] [controller] EPOCH 2 loss ppo:  -0.04326, loss val: 0.05543
[2022-12-07 01:36:38,039] [INFO] [controller] EPOCH 3 loss ppo:  -0.05999, loss val: 0.05215
[2022-12-07 01:36:38,112] [INFO] [controller] EPOCH 4 loss ppo:  -0.07267, loss val: 0.05132
[2022-12-07 01:36:38,124] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:36:38,352] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:36:38,352] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:36:47,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:36:56,856] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:37:05,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:37:14,157] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:37:23,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:37:32,412] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:37:41,924] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:37:51,089] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:38:00,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:38:09,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5925341085991229
[2022-12-07 01:38:09,364] [INFO] [runner_train_mujoco] Average state value: 0.530123715331157
[2022-12-07 01:38:09,364] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 01:38:09,435] [INFO] [controller] EPOCH 1 loss ppo:  -0.01084, loss val: 0.05017
[2022-12-07 01:38:09,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.04154, loss val: 0.04513
[2022-12-07 01:38:09,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.05972, loss val: 0.04367
[2022-12-07 01:38:09,590] [INFO] [controller] EPOCH 4 loss ppo:  -0.07034, loss val: 0.04444
[2022-12-07 01:38:09,602] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:38:09,832] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:38:09,832] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:38:19,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:38:27,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:38:36,642] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:38:45,923] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:38:54,951] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:39:03,849] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:39:12,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:39:21,951] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:39:30,475] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:39:39,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46773072050763115
[2022-12-07 01:39:39,718] [INFO] [runner_train_mujoco] Average state value: 0.47437707091743747
[2022-12-07 01:39:39,718] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 01:39:39,790] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04760
[2022-12-07 01:39:39,845] [INFO] [controller] EPOCH 2 loss ppo:  -0.04218, loss val: 0.04687
[2022-12-07 01:39:39,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.06054, loss val: 0.04791
[2022-12-07 01:39:39,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.06923, loss val: 0.04623
[2022-12-07 01:39:39,953] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:39:40,176] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:39:40,176] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:39:49,026] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:39:58,073] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:40:06,970] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:40:16,076] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:40:24,429] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:40:32,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:40:41,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:40:49,571] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:40:58,058] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:41:06,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6364056778358542
[2022-12-07 01:41:06,284] [INFO] [runner_train_mujoco] Average state value: 0.44367712738613285
[2022-12-07 01:41:06,285] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 01:41:06,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01105, loss val: 0.04978
[2022-12-07 01:41:06,394] [INFO] [controller] EPOCH 2 loss ppo:  -0.03938, loss val: 0.04636
[2022-12-07 01:41:06,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.05708, loss val: 0.04605
[2022-12-07 01:41:06,491] [INFO] [controller] EPOCH 4 loss ppo:  -0.06919, loss val: 0.04503
[2022-12-07 01:41:06,501] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:41:06,714] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:41:06,714] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:41:15,170] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:41:23,285] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:41:30,837] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:41:38,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:41:46,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:41:54,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:42:02,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:42:09,603] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:42:17,237] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:42:24,156] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6392838448286429
[2022-12-07 01:42:24,156] [INFO] [runner_train_mujoco] Average state value: 0.4528356366753578
[2022-12-07 01:42:24,156] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 01:42:24,208] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.05633
[2022-12-07 01:42:24,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.03801, loss val: 0.05162
[2022-12-07 01:42:24,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.05398, loss val: 0.04804
[2022-12-07 01:42:24,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.06764, loss val: 0.04827
[2022-12-07 01:42:24,345] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:42:24,554] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:42:24,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:42:31,955] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:42:39,040] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:42:46,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:42:53,438] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:43:00,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:43:07,343] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:43:14,503] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:43:21,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:43:29,635] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:43:36,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8704657812290779
[2022-12-07 01:43:36,906] [INFO] [runner_train_mujoco] Average state value: 0.5156385897944371
[2022-12-07 01:43:36,906] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 01:43:36,958] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.04202
[2022-12-07 01:43:37,010] [INFO] [controller] EPOCH 2 loss ppo:  -0.04565, loss val: 0.04312
[2022-12-07 01:43:37,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.05981, loss val: 0.04348
[2022-12-07 01:43:37,097] [INFO] [controller] EPOCH 4 loss ppo:  -0.07264, loss val: 0.04187
[2022-12-07 01:43:37,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:43:37,308] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:43:37,309] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:43:44,520] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:43:51,561] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:43:58,741] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:44:06,095] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:44:12,891] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:44:19,643] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:44:26,606] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:44:33,495] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:44:40,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:44:48,174] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0418270660482665
[2022-12-07 01:44:48,175] [INFO] [runner_train_mujoco] Average state value: 0.5209951112369696
[2022-12-07 01:44:48,175] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 01:44:48,233] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04162
[2022-12-07 01:44:48,281] [INFO] [controller] EPOCH 2 loss ppo:  -0.04290, loss val: 0.04561
[2022-12-07 01:44:48,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.06163, loss val: 0.04520
[2022-12-07 01:44:48,381] [INFO] [controller] EPOCH 4 loss ppo:  -0.07491, loss val: 0.04073
[2022-12-07 01:44:48,391] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:44:48,615] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:44:48,616] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:44:56,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:45:03,707] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:45:10,650] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:45:18,082] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:45:25,079] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:45:32,233] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:45:39,874] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:45:47,403] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:45:54,743] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:46:02,368] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0134770544938654
[2022-12-07 01:46:02,368] [INFO] [runner_train_mujoco] Average state value: 0.5215197082658609
[2022-12-07 01:46:02,368] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 01:46:02,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.03893
[2022-12-07 01:46:02,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.04557, loss val: 0.03850
[2022-12-07 01:46:02,564] [INFO] [controller] EPOCH 3 loss ppo:  -0.06308, loss val: 0.04004
[2022-12-07 01:46:02,604] [INFO] [controller] EPOCH 4 loss ppo:  -0.07732, loss val: 0.03818
[2022-12-07 01:46:02,614] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:46:02,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:46:02,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:46:10,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:46:17,464] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:46:24,211] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:46:30,818] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:46:37,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:46:44,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:46:52,159] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:46:59,152] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:47:06,182] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:47:13,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2836655970915882
[2022-12-07 01:47:13,521] [INFO] [runner_train_mujoco] Average state value: 0.5298935723602771
[2022-12-07 01:47:13,522] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 01:47:13,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.03783
[2022-12-07 01:47:13,612] [INFO] [controller] EPOCH 2 loss ppo:  -0.04316, loss val: 0.03777
[2022-12-07 01:47:13,652] [INFO] [controller] EPOCH 3 loss ppo:  -0.06274, loss val: 0.03889
[2022-12-07 01:47:13,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.07434, loss val: 0.03738
[2022-12-07 01:47:13,699] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:47:13,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:47:13,911] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:47:21,050] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:47:28,374] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:47:35,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:47:42,754] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:47:49,951] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:47:57,008] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:48:04,017] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:48:11,161] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:48:18,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:48:25,067] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1840313793364714
[2022-12-07 01:48:25,067] [INFO] [runner_train_mujoco] Average state value: 0.537090352753798
[2022-12-07 01:48:25,067] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 01:48:25,116] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.04577
[2022-12-07 01:48:25,156] [INFO] [controller] EPOCH 2 loss ppo:  -0.04212, loss val: 0.04374
[2022-12-07 01:48:25,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.06048, loss val: 0.04182
[2022-12-07 01:48:25,234] [INFO] [controller] EPOCH 4 loss ppo:  -0.07441, loss val: 0.04031
[2022-12-07 01:48:25,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:48:25,444] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:48:25,444] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:48:33,128] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:48:40,693] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:48:48,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:48:54,816] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:49:02,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:49:09,169] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:49:16,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:49:26,589] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:49:33,721] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:49:41,270] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.448236110521158
[2022-12-07 01:49:41,270] [INFO] [runner_train_mujoco] Average state value: 0.4850247996747494
[2022-12-07 01:49:41,270] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 01:49:41,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.03520
[2022-12-07 01:49:41,355] [INFO] [controller] EPOCH 2 loss ppo:  -0.04209, loss val: 0.03470
[2022-12-07 01:49:41,395] [INFO] [controller] EPOCH 3 loss ppo:  -0.06250, loss val: 0.03493
[2022-12-07 01:49:41,436] [INFO] [controller] EPOCH 4 loss ppo:  -0.07162, loss val: 0.03665
[2022-12-07 01:49:41,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:49:41,653] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:49:41,653] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:49:48,544] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:49:55,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:50:02,786] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:50:09,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:50:16,913] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:50:25,536] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:50:32,998] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:50:40,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:50:47,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:50:54,695] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9051864140086436
[2022-12-07 01:50:54,695] [INFO] [runner_train_mujoco] Average state value: 0.4265773728812735
[2022-12-07 01:50:54,695] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 01:50:54,757] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.05595
[2022-12-07 01:50:54,819] [INFO] [controller] EPOCH 2 loss ppo:  -0.03850, loss val: 0.05545
[2022-12-07 01:50:54,873] [INFO] [controller] EPOCH 3 loss ppo:  -0.05559, loss val: 0.05412
[2022-12-07 01:50:54,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.07227, loss val: 0.05128
[2022-12-07 01:50:54,938] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:50:55,162] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:50:55,163] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:51:02,248] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:51:09,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:51:16,754] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:51:23,883] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:51:30,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:51:37,406] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:51:44,669] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:51:51,842] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:51:59,006] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:52:05,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9436080909800109
[2022-12-07 01:52:05,828] [INFO] [runner_train_mujoco] Average state value: 0.4732417500416438
[2022-12-07 01:52:05,828] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 01:52:05,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.03270
[2022-12-07 01:52:05,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.04545, loss val: 0.03212
[2022-12-07 01:52:05,958] [INFO] [controller] EPOCH 3 loss ppo:  -0.06314, loss val: 0.03178
[2022-12-07 01:52:06,005] [INFO] [controller] EPOCH 4 loss ppo:  -0.07749, loss val: 0.03174
[2022-12-07 01:52:06,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:52:06,206] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:52:06,206] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:52:13,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:52:21,615] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:52:29,031] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:52:36,332] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:52:43,783] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:52:50,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:52:58,590] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:53:05,709] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:53:13,005] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:53:20,433] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.303753525803992
[2022-12-07 01:53:20,433] [INFO] [runner_train_mujoco] Average state value: 0.5333073575894037
[2022-12-07 01:53:20,433] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 01:53:20,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.03947
[2022-12-07 01:53:20,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.04270, loss val: 0.04398
[2022-12-07 01:53:20,560] [INFO] [controller] EPOCH 3 loss ppo:  -0.06067, loss val: 0.04070
[2022-12-07 01:53:20,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.07542, loss val: 0.04064
[2022-12-07 01:53:20,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:53:20,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:53:20,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:53:28,268] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:53:35,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:53:42,540] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:53:49,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:53:56,089] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:54:03,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:54:10,477] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:54:18,025] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:54:24,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:54:31,815] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.229120270198586
[2022-12-07 01:54:31,815] [INFO] [runner_train_mujoco] Average state value: 0.5423001750806967
[2022-12-07 01:54:31,815] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 01:54:31,863] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.03965
[2022-12-07 01:54:31,904] [INFO] [controller] EPOCH 2 loss ppo:  -0.04103, loss val: 0.03843
[2022-12-07 01:54:31,945] [INFO] [controller] EPOCH 3 loss ppo:  -0.06020, loss val: 0.03855
[2022-12-07 01:54:31,985] [INFO] [controller] EPOCH 4 loss ppo:  -0.07408, loss val: 0.04077
[2022-12-07 01:54:31,994] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:54:32,189] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:54:32,189] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:54:39,430] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:54:46,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:54:53,707] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:55:00,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:55:07,973] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:55:14,847] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:55:22,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:55:30,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:55:37,206] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:55:44,205] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.686629910724705
[2022-12-07 01:55:44,205] [INFO] [runner_train_mujoco] Average state value: 0.5497293441096942
[2022-12-07 01:55:44,205] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 01:55:44,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.05123
[2022-12-07 01:55:44,289] [INFO] [controller] EPOCH 2 loss ppo:  -0.03772, loss val: 0.05000
[2022-12-07 01:55:44,327] [INFO] [controller] EPOCH 3 loss ppo:  -0.05495, loss val: 0.04994
[2022-12-07 01:55:44,366] [INFO] [controller] EPOCH 4 loss ppo:  -0.07094, loss val: 0.05042
[2022-12-07 01:55:44,376] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:55:44,563] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:55:44,563] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:55:52,433] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:56:00,304] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:56:07,648] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:56:14,713] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:56:21,784] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:56:29,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:56:36,030] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:56:43,388] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:56:50,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:56:57,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9500581675658504
[2022-12-07 01:56:57,572] [INFO] [runner_train_mujoco] Average state value: 0.560380974650383
[2022-12-07 01:56:57,572] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 01:56:57,621] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.03539
[2022-12-07 01:56:57,659] [INFO] [controller] EPOCH 2 loss ppo:  -0.03965, loss val: 0.03492
[2022-12-07 01:56:57,700] [INFO] [controller] EPOCH 3 loss ppo:  -0.05561, loss val: 0.03435
[2022-12-07 01:56:57,744] [INFO] [controller] EPOCH 4 loss ppo:  -0.07142, loss val: 0.03330
[2022-12-07 01:56:57,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:56:57,954] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:56:57,955] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:57:06,099] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:57:13,577] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:57:22,382] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:57:30,256] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:57:37,137] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:57:44,222] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:57:51,243] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:57:58,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:58:05,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:58:12,503] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1161010828434064
[2022-12-07 01:58:12,503] [INFO] [runner_train_mujoco] Average state value: 0.532418499737978
[2022-12-07 01:58:12,503] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 01:58:12,553] [INFO] [controller] EPOCH 1 loss ppo:  -0.01529, loss val: 0.03927
[2022-12-07 01:58:12,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.04178, loss val: 0.03776
[2022-12-07 01:58:12,636] [INFO] [controller] EPOCH 3 loss ppo:  -0.06003, loss val: 0.03519
[2022-12-07 01:58:12,676] [INFO] [controller] EPOCH 4 loss ppo:  -0.07395, loss val: 0.03572
[2022-12-07 01:58:12,685] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:58:12,881] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:58:12,881] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:58:20,590] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:58:27,635] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:58:35,051] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:58:41,773] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:58:48,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:58:56,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:59:03,110] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:59:10,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:59:17,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:59:24,679] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.330394343870272
[2022-12-07 01:59:24,679] [INFO] [runner_train_mujoco] Average state value: 0.46820723770062134
[2022-12-07 01:59:24,679] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 01:59:24,734] [INFO] [controller] EPOCH 1 loss ppo:  -0.01605, loss val: 0.03733
[2022-12-07 01:59:24,776] [INFO] [controller] EPOCH 2 loss ppo:  -0.03759, loss val: 0.03518
[2022-12-07 01:59:24,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.05425, loss val: 0.03508
[2022-12-07 01:59:24,855] [INFO] [controller] EPOCH 4 loss ppo:  -0.06867, loss val: 0.03663
[2022-12-07 01:59:24,863] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:59:25,061] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:59:25,061] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:59:32,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:59:40,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:59:48,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:59:55,384] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:00:02,394] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:00:09,558] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:00:16,419] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:00:23,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:00:30,585] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:00:37,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5555293500548935
[2022-12-07 02:00:37,603] [INFO] [runner_train_mujoco] Average state value: 0.4225936336020628
[2022-12-07 02:00:37,603] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 02:00:37,660] [INFO] [controller] EPOCH 1 loss ppo:  -0.01722, loss val: 0.04702
[2022-12-07 02:00:37,704] [INFO] [controller] EPOCH 2 loss ppo:  -0.04051, loss val: 0.04659
[2022-12-07 02:00:37,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.05717, loss val: 0.04435
[2022-12-07 02:00:37,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.07200, loss val: 0.03827
[2022-12-07 02:00:37,795] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:00:37,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:00:37,978] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:00:45,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:00:52,261] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:00:59,236] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:01:06,236] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:01:13,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:01:20,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:01:28,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:01:36,617] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:01:43,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:01:50,518] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1940244766010775
[2022-12-07 02:01:50,518] [INFO] [runner_train_mujoco] Average state value: 0.46726029244065287
[2022-12-07 02:01:50,518] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 02:01:50,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.05588
[2022-12-07 02:01:50,612] [INFO] [controller] EPOCH 2 loss ppo:  -0.03849, loss val: 0.04942
[2022-12-07 02:01:50,654] [INFO] [controller] EPOCH 3 loss ppo:  -0.05860, loss val: 0.04426
[2022-12-07 02:01:50,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.07314, loss val: 0.04054
[2022-12-07 02:01:50,698] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:01:50,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:01:50,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:01:58,653] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:02:06,506] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:02:13,783] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:02:20,820] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:02:28,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:02:36,410] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:02:43,232] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:02:50,214] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:03:01,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:03:09,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9876191565778023
[2022-12-07 02:03:09,090] [INFO] [runner_train_mujoco] Average state value: 0.5666908272703489
[2022-12-07 02:03:09,090] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 02:03:09,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.05588
[2022-12-07 02:03:09,203] [INFO] [controller] EPOCH 2 loss ppo:  -0.03478, loss val: 0.05943
[2022-12-07 02:03:09,245] [INFO] [controller] EPOCH 3 loss ppo:  -0.04913, loss val: 0.06085
[2022-12-07 02:03:09,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.06456, loss val: 0.05707
[2022-12-07 02:03:09,294] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:03:09,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:03:09,491] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:03:16,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:03:25,927] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:03:33,101] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:03:39,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:03:46,926] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:03:54,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:04:02,066] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:04:10,178] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:04:19,396] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:04:31,376] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9383691262633618
[2022-12-07 02:04:31,376] [INFO] [runner_train_mujoco] Average state value: 0.5708197268744309
[2022-12-07 02:04:31,376] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 02:04:31,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01619, loss val: 0.06301
[2022-12-07 02:04:31,502] [INFO] [controller] EPOCH 2 loss ppo:  -0.03853, loss val: 0.05803
[2022-12-07 02:04:31,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.05591, loss val: 0.05335
[2022-12-07 02:04:31,596] [INFO] [controller] EPOCH 4 loss ppo:  -0.07190, loss val: 0.04943
[2022-12-07 02:04:31,606] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:04:31,826] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:04:31,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:04:40,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:04:47,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:04:54,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:05:02,525] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:05:09,729] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:05:16,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:05:24,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:05:31,264] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:05:38,101] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:05:44,821] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7536561525976984
[2022-12-07 02:05:44,821] [INFO] [runner_train_mujoco] Average state value: 0.4868314771751563
[2022-12-07 02:05:44,821] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 02:05:44,866] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.03963
[2022-12-07 02:05:44,908] [INFO] [controller] EPOCH 2 loss ppo:  -0.03835, loss val: 0.04184
[2022-12-07 02:05:44,944] [INFO] [controller] EPOCH 3 loss ppo:  -0.05823, loss val: 0.04207
[2022-12-07 02:05:44,987] [INFO] [controller] EPOCH 4 loss ppo:  -0.07241, loss val: 0.04130
[2022-12-07 02:05:44,996] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:05:45,189] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:05:45,189] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:05:54,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:06:02,551] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:06:09,864] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:06:16,680] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:06:23,936] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:06:30,682] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:06:37,931] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:06:45,726] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:06:52,716] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:07:00,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7537578175226294
[2022-12-07 02:07:00,642] [INFO] [runner_train_mujoco] Average state value: 0.42039820029462377
[2022-12-07 02:07:00,642] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 02:07:00,701] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.07694
[2022-12-07 02:07:00,738] [INFO] [controller] EPOCH 2 loss ppo:  -0.03893, loss val: 0.07653
[2022-12-07 02:07:00,851] [INFO] [controller] EPOCH 3 loss ppo:  -0.05686, loss val: 0.07602
[2022-12-07 02:07:00,895] [INFO] [controller] EPOCH 4 loss ppo:  -0.07476, loss val: 0.07583
[2022-12-07 02:07:00,904] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:07:01,103] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:07:01,104] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:07:10,136] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:07:20,968] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:07:27,877] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:07:34,915] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:07:42,197] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:07:49,137] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:07:56,293] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:08:04,116] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:08:10,966] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:08:18,081] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.714858920679442
[2022-12-07 02:08:18,081] [INFO] [runner_train_mujoco] Average state value: 0.44805394217123595
[2022-12-07 02:08:18,081] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 02:08:18,166] [INFO] [controller] EPOCH 1 loss ppo:  -0.01549, loss val: 0.08652
[2022-12-07 02:08:18,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.03343, loss val: 0.08326
[2022-12-07 02:08:18,278] [INFO] [controller] EPOCH 3 loss ppo:  -0.04561, loss val: 0.07932
[2022-12-07 02:08:18,334] [INFO] [controller] EPOCH 4 loss ppo:  -0.05849, loss val: 0.07405
[2022-12-07 02:08:18,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:08:18,573] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:08:18,574] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:08:25,783] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:08:33,203] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:08:40,376] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:08:47,816] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:08:55,020] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:09:02,679] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:09:09,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:09:16,720] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:09:23,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:09:30,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.876464600122784
[2022-12-07 02:09:30,167] [INFO] [runner_train_mujoco] Average state value: 0.5252132843186458
[2022-12-07 02:09:30,167] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 02:09:30,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.04219
[2022-12-07 02:09:30,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.03930, loss val: 0.04019
[2022-12-07 02:09:30,286] [INFO] [controller] EPOCH 3 loss ppo:  -0.05766, loss val: 0.03850
[2022-12-07 02:09:30,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.07257, loss val: 0.03788
[2022-12-07 02:09:30,336] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:09:30,541] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:09:30,541] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:09:37,944] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:09:45,263] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:09:53,694] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:10:00,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:10:07,821] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:10:14,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:10:23,905] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:10:30,923] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:10:37,982] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:10:45,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.302467889395417
[2022-12-07 02:10:45,371] [INFO] [runner_train_mujoco] Average state value: 0.5930632566213608
[2022-12-07 02:10:45,371] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 02:10:45,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.04332
[2022-12-07 02:10:45,479] [INFO] [controller] EPOCH 2 loss ppo:  -0.03723, loss val: 0.04432
[2022-12-07 02:10:45,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.05026, loss val: 0.04371
[2022-12-07 02:10:45,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.06580, loss val: 0.04434
[2022-12-07 02:10:45,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:10:45,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:10:45,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:10:53,789] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:11:01,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:11:08,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:11:15,195] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:11:22,700] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:11:29,527] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:11:36,550] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:11:43,978] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:11:51,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:11:58,712] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.514206664872072
[2022-12-07 02:11:58,712] [INFO] [runner_train_mujoco] Average state value: 0.5988120929511884
[2022-12-07 02:11:58,712] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 02:11:58,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.07751
[2022-12-07 02:11:58,796] [INFO] [controller] EPOCH 2 loss ppo:  -0.03027, loss val: 0.07349
[2022-12-07 02:11:58,839] [INFO] [controller] EPOCH 3 loss ppo:  -0.04457, loss val: 0.06807
[2022-12-07 02:11:58,879] [INFO] [controller] EPOCH 4 loss ppo:  -0.05624, loss val: 0.06320
[2022-12-07 02:11:58,888] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:11:59,080] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:11:59,080] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:12:06,713] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:12:14,036] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:12:22,223] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:12:29,343] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:12:36,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:12:43,539] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:12:50,620] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:12:57,524] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:13:06,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:13:14,102] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.743367340654833
[2022-12-07 02:13:14,102] [INFO] [runner_train_mujoco] Average state value: 0.5370037059187889
[2022-12-07 02:13:14,103] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 02:13:14,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.03788
[2022-12-07 02:13:14,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03638, loss val: 0.03876
[2022-12-07 02:13:14,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.05177, loss val: 0.03996
[2022-12-07 02:13:14,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.06701, loss val: 0.04033
[2022-12-07 02:13:14,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:13:14,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:13:14,485] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:13:21,924] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:13:29,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:13:36,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:13:43,161] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:13:49,881] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:13:57,344] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:14:04,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:14:11,080] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:14:18,766] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:14:26,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.941494924976011
[2022-12-07 02:14:26,113] [INFO] [runner_train_mujoco] Average state value: 0.507487071633339
[2022-12-07 02:14:26,113] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 02:14:26,168] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.05162
[2022-12-07 02:14:26,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.04057, loss val: 0.04952
[2022-12-07 02:14:26,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.05483, loss val: 0.04799
[2022-12-07 02:14:26,299] [INFO] [controller] EPOCH 4 loss ppo:  -0.06815, loss val: 0.04837
[2022-12-07 02:14:26,308] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:14:26,511] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:14:26,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:14:36,633] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:14:43,814] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:14:50,802] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:14:57,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:15:04,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:15:11,205] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:15:18,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:15:25,256] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:15:32,288] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:15:39,961] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.347648266770856
[2022-12-07 02:15:39,961] [INFO] [runner_train_mujoco] Average state value: 0.5288792184193929
[2022-12-07 02:15:39,961] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 02:15:40,011] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.06100
[2022-12-07 02:15:40,053] [INFO] [controller] EPOCH 2 loss ppo:  -0.03404, loss val: 0.06078
[2022-12-07 02:15:40,098] [INFO] [controller] EPOCH 3 loss ppo:  -0.04742, loss val: 0.06061
[2022-12-07 02:15:40,135] [INFO] [controller] EPOCH 4 loss ppo:  -0.06316, loss val: 0.05939
[2022-12-07 02:15:40,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:15:40,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:15:40,341] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:15:47,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:15:54,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:16:01,838] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:16:08,627] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:16:16,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:16:23,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:16:30,564] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:16:37,809] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:16:45,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:16:52,885] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.573111673816801
[2022-12-07 02:16:52,885] [INFO] [runner_train_mujoco] Average state value: 0.512833359549443
[2022-12-07 02:16:52,885] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 02:16:52,937] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.04787
[2022-12-07 02:16:52,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.03481, loss val: 0.04857
[2022-12-07 02:16:53,024] [INFO] [controller] EPOCH 3 loss ppo:  -0.04984, loss val: 0.04724
[2022-12-07 02:16:53,071] [INFO] [controller] EPOCH 4 loss ppo:  -0.06428, loss val: 0.04701
[2022-12-07 02:16:53,077] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:16:53,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:16:53,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:17:00,962] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:17:08,555] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:17:15,935] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:17:22,827] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:17:29,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:17:37,126] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:17:44,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:17:51,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:17:58,449] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:18:05,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.005313750666787
[2022-12-07 02:18:05,799] [INFO] [runner_train_mujoco] Average state value: 0.48059238743782046
[2022-12-07 02:18:05,799] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 02:18:05,851] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04989
[2022-12-07 02:18:05,893] [INFO] [controller] EPOCH 2 loss ppo:  -0.02938, loss val: 0.04966
[2022-12-07 02:18:05,936] [INFO] [controller] EPOCH 3 loss ppo:  -0.04888, loss val: 0.05002
[2022-12-07 02:18:05,979] [INFO] [controller] EPOCH 4 loss ppo:  -0.06373, loss val: 0.04883
[2022-12-07 02:18:05,986] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:18:06,165] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:18:06,165] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:18:13,557] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:18:20,771] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:18:29,732] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:18:38,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:18:44,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:18:52,406] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:19:00,567] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:19:07,717] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:19:15,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:19:22,622] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.351529649459429
[2022-12-07 02:19:22,622] [INFO] [runner_train_mujoco] Average state value: 0.4660465354124706
[2022-12-07 02:19:22,622] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 02:19:22,676] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.03593
[2022-12-07 02:19:22,718] [INFO] [controller] EPOCH 2 loss ppo:  -0.03216, loss val: 0.03560
[2022-12-07 02:19:22,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.04807, loss val: 0.03602
[2022-12-07 02:19:22,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.06158, loss val: 0.03705
[2022-12-07 02:19:22,812] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:19:23,025] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:19:23,025] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:19:31,776] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:19:40,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:19:50,173] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:19:58,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:20:06,188] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:20:14,422] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:20:21,966] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:20:29,301] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:20:36,373] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:20:44,159] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.340272461211012
[2022-12-07 02:20:44,159] [INFO] [runner_train_mujoco] Average state value: 0.4622835399707159
[2022-12-07 02:20:44,159] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 02:20:44,211] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04995
[2022-12-07 02:20:44,245] [INFO] [controller] EPOCH 2 loss ppo:  -0.03355, loss val: 0.05127
[2022-12-07 02:20:44,284] [INFO] [controller] EPOCH 3 loss ppo:  -0.04710, loss val: 0.04721
[2022-12-07 02:20:44,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.06047, loss val: 0.04869
[2022-12-07 02:20:44,331] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:20:44,527] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:20:44,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:20:51,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:20:59,841] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:21:06,599] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:21:13,756] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:21:21,039] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:21:29,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:21:37,663] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:21:45,174] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:21:53,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:22:00,775] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5293104879049695
[2022-12-07 02:22:00,775] [INFO] [runner_train_mujoco] Average state value: 0.4472866102854411
[2022-12-07 02:22:00,775] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 02:22:00,825] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.03576
[2022-12-07 02:22:00,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.03066, loss val: 0.03470
[2022-12-07 02:22:00,911] [INFO] [controller] EPOCH 3 loss ppo:  -0.04561, loss val: 0.03473
[2022-12-07 02:22:00,954] [INFO] [controller] EPOCH 4 loss ppo:  -0.05652, loss val: 0.03453
[2022-12-07 02:22:00,963] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:22:01,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:22:01,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:22:09,872] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:22:18,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:22:27,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:22:35,424] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:22:42,839] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:22:50,755] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:22:58,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:23:05,728] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:23:13,190] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:23:20,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.704919480490949
[2022-12-07 02:23:20,549] [INFO] [runner_train_mujoco] Average state value: 0.4497466635505359
[2022-12-07 02:23:20,549] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 02:23:20,609] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.05071
[2022-12-07 02:23:20,654] [INFO] [controller] EPOCH 2 loss ppo:  -0.02756, loss val: 0.05035
[2022-12-07 02:23:20,702] [INFO] [controller] EPOCH 3 loss ppo:  -0.04510, loss val: 0.05127
[2022-12-07 02:23:20,758] [INFO] [controller] EPOCH 4 loss ppo:  -0.05833, loss val: 0.05067
[2022-12-07 02:23:20,768] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:23:20,974] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:23:20,975] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:23:29,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:23:38,273] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:23:46,405] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:23:53,687] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:24:01,151] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:24:07,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:24:16,426] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:24:24,959] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:24:31,488] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:24:38,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.805772807214582
[2022-12-07 02:24:38,634] [INFO] [runner_train_mujoco] Average state value: 0.47071742137273154
[2022-12-07 02:24:38,634] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 02:24:38,678] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.03771
[2022-12-07 02:24:38,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.03235, loss val: 0.03757
[2022-12-07 02:24:38,764] [INFO] [controller] EPOCH 3 loss ppo:  -0.04463, loss val: 0.03837
[2022-12-07 02:24:38,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.05704, loss val: 0.04047
[2022-12-07 02:24:38,817] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:24:39,000] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:24:39,000] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:24:45,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:24:53,526] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:25:00,815] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:25:07,583] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:25:14,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:25:22,463] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:25:29,452] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:25:36,294] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:25:43,683] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:25:50,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.743459045560902
[2022-12-07 02:25:50,912] [INFO] [runner_train_mujoco] Average state value: 0.4858413114349047
[2022-12-07 02:25:50,912] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 02:25:50,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.04274
[2022-12-07 02:25:51,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.02792, loss val: 0.04093
[2022-12-07 02:25:51,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.04537, loss val: 0.04088
[2022-12-07 02:25:51,091] [INFO] [controller] EPOCH 4 loss ppo:  -0.05973, loss val: 0.03901
[2022-12-07 02:25:51,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:25:51,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:25:51,302] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:25:58,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:26:06,472] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:26:15,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:26:22,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:26:29,097] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:26:36,248] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:26:43,754] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:26:50,923] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:26:58,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:27:06,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.858542199851154
[2022-12-07 02:27:06,004] [INFO] [runner_train_mujoco] Average state value: 0.4779449006517729
[2022-12-07 02:27:06,004] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 02:27:06,055] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.05491
[2022-12-07 02:27:06,097] [INFO] [controller] EPOCH 2 loss ppo:  -0.02105, loss val: 0.05462
[2022-12-07 02:27:06,140] [INFO] [controller] EPOCH 3 loss ppo:  -0.03670, loss val: 0.05307
[2022-12-07 02:27:06,182] [INFO] [controller] EPOCH 4 loss ppo:  -0.05175, loss val: 0.05374
[2022-12-07 02:27:06,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:27:06,389] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:27:06,389] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:27:14,467] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:27:21,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:27:32,500] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:27:39,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:27:47,002] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:27:54,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:28:01,064] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:28:08,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:28:15,625] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:28:23,911] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.726253521635176
[2022-12-07 02:28:23,911] [INFO] [runner_train_mujoco] Average state value: 0.4005812110329668
[2022-12-07 02:28:23,911] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 02:28:23,986] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.11514
[2022-12-07 02:28:24,045] [INFO] [controller] EPOCH 2 loss ppo:  -0.02710, loss val: 0.11312
[2022-12-07 02:28:24,168] [INFO] [controller] EPOCH 3 loss ppo:  -0.03952, loss val: 0.11419
[2022-12-07 02:28:24,221] [INFO] [controller] EPOCH 4 loss ppo:  -0.04947, loss val: 0.11112
[2022-12-07 02:28:24,231] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:28:24,460] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:28:24,460] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:28:31,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:28:38,984] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:28:45,691] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:28:53,463] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:29:00,126] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:29:07,709] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:29:15,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:29:23,816] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:29:30,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:29:37,873] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.866289426118824
[2022-12-07 02:29:37,873] [INFO] [runner_train_mujoco] Average state value: 0.42743072568873564
[2022-12-07 02:29:37,873] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 02:29:37,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.05926
[2022-12-07 02:29:37,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.02606, loss val: 0.05908
[2022-12-07 02:29:38,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.03967, loss val: 0.05876
[2022-12-07 02:29:38,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.04911, loss val: 0.05901
[2022-12-07 02:29:38,065] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:29:38,260] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:29:38,261] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:29:45,746] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:29:53,147] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:30:00,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:30:09,098] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:30:16,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:30:24,396] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:30:32,199] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:30:40,249] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:30:49,551] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:30:57,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.558021890759472
[2022-12-07 02:30:57,328] [INFO] [runner_train_mujoco] Average state value: 0.4301875287449608
[2022-12-07 02:30:57,328] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 02:30:57,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.07776
[2022-12-07 02:30:57,421] [INFO] [controller] EPOCH 2 loss ppo:  -0.02211, loss val: 0.07576
[2022-12-07 02:30:57,463] [INFO] [controller] EPOCH 3 loss ppo:  -0.03412, loss val: 0.07549
[2022-12-07 02:30:57,505] [INFO] [controller] EPOCH 4 loss ppo:  -0.04447, loss val: 0.07442
[2022-12-07 02:30:57,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:30:57,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:30:57,729] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:31:07,758] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:31:15,322] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:31:22,374] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:31:29,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:31:37,084] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:31:43,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:31:51,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:31:58,871] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:32:06,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:32:15,387] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.058687971573233
[2022-12-07 02:32:15,388] [INFO] [runner_train_mujoco] Average state value: 0.4726347853044669
[2022-12-07 02:32:15,388] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 02:32:15,438] [INFO] [controller] EPOCH 1 loss ppo:  -0.01346, loss val: 0.04829
[2022-12-07 02:32:15,481] [INFO] [controller] EPOCH 2 loss ppo:  -0.02218, loss val: 0.04826
[2022-12-07 02:32:15,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.03729, loss val: 0.04861
[2022-12-07 02:32:15,571] [INFO] [controller] EPOCH 4 loss ppo:  -0.04861, loss val: 0.04824
[2022-12-07 02:32:15,581] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:32:15,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:32:15,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:32:22,538] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:32:30,161] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:32:40,674] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:32:48,470] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:32:56,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:33:05,328] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:33:13,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:33:20,699] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:33:27,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:33:34,317] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.7868021158151155
[2022-12-07 02:33:34,318] [INFO] [runner_train_mujoco] Average state value: 0.4618452794738114
[2022-12-07 02:33:34,318] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 02:33:34,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04423
[2022-12-07 02:33:34,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.02533, loss val: 0.04365
[2022-12-07 02:33:34,471] [INFO] [controller] EPOCH 3 loss ppo:  -0.03868, loss val: 0.04457
[2022-12-07 02:33:34,518] [INFO] [controller] EPOCH 4 loss ppo:  -0.04690, loss val: 0.04319
[2022-12-07 02:33:34,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:33:34,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:33:34,727] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:33:42,227] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:33:51,525] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:33:58,416] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:34:05,495] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:34:12,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:34:20,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:34:27,498] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:34:35,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:34:42,447] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:34:50,216] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.484875201978515
[2022-12-07 02:34:50,216] [INFO] [runner_train_mujoco] Average state value: 0.475538673043251
[2022-12-07 02:34:50,216] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 02:34:50,263] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.05633
[2022-12-07 02:34:50,303] [INFO] [controller] EPOCH 2 loss ppo:  -0.02192, loss val: 0.05907
[2022-12-07 02:34:50,348] [INFO] [controller] EPOCH 3 loss ppo:  -0.03279, loss val: 0.05639
[2022-12-07 02:34:50,390] [INFO] [controller] EPOCH 4 loss ppo:  -0.04197, loss val: 0.05635
[2022-12-07 02:34:50,398] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:34:50,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:34:50,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:34:57,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:35:04,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:35:12,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:35:19,865] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:35:27,352] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:35:35,621] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:35:43,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:35:50,048] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:35:57,000] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:36:05,234] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.232211187674903
[2022-12-07 02:36:05,234] [INFO] [runner_train_mujoco] Average state value: 0.4684012324611346
[2022-12-07 02:36:05,234] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 02:36:05,297] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04663
[2022-12-07 02:36:05,339] [INFO] [controller] EPOCH 2 loss ppo:  -0.02064, loss val: 0.04632
[2022-12-07 02:36:05,384] [INFO] [controller] EPOCH 3 loss ppo:  -0.03078, loss val: 0.04821
[2022-12-07 02:36:05,430] [INFO] [controller] EPOCH 4 loss ppo:  -0.04023, loss val: 0.04609
[2022-12-07 02:36:05,441] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:36:05,638] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:36:05,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:36:12,604] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:36:20,628] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:36:27,799] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:36:35,006] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:36:42,365] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:36:49,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:36:56,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:37:03,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:37:10,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:37:18,874] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.175498411323018
[2022-12-07 02:37:18,875] [INFO] [runner_train_mujoco] Average state value: 0.43699126101781927
[2022-12-07 02:37:18,875] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 02:37:18,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.07504
[2022-12-07 02:37:18,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.01743, loss val: 0.07318
[2022-12-07 02:37:19,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.02418, loss val: 0.07340
[2022-12-07 02:37:19,041] [INFO] [controller] EPOCH 4 loss ppo:  -0.03235, loss val: 0.07526
[2022-12-07 02:37:19,050] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:37:19,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:37:19,250] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:37:26,418] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:37:33,307] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:37:40,430] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:37:47,457] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:37:54,743] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:38:02,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:38:08,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:38:16,472] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:38:24,012] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:38:31,489] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.044304720821925
[2022-12-07 02:38:31,489] [INFO] [runner_train_mujoco] Average state value: 0.4642578391333421
[2022-12-07 02:38:31,489] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 02:38:31,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01385, loss val: 0.03401
[2022-12-07 02:38:31,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.01796, loss val: 0.03495
[2022-12-07 02:38:31,632] [INFO] [controller] EPOCH 3 loss ppo:  -0.02557, loss val: 0.03377
[2022-12-07 02:38:31,669] [INFO] [controller] EPOCH 4 loss ppo:  -0.03409, loss val: 0.03448
[2022-12-07 02:38:31,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:38:31,874] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:38:31,874] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:38:40,069] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:38:47,201] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:38:55,486] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:39:03,443] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:39:11,094] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:39:18,338] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:39:25,387] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:39:33,105] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:39:40,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:39:47,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.0489514001314095
[2022-12-07 02:39:47,237] [INFO] [runner_train_mujoco] Average state value: 0.4573406128436327
[2022-12-07 02:39:47,237] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 02:39:47,284] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.05246
[2022-12-07 02:39:47,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.01647, loss val: 0.05170
[2022-12-07 02:39:47,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.02122, loss val: 0.05183
[2022-12-07 02:39:47,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.02737, loss val: 0.05285
[2022-12-07 02:39:47,412] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:39:47,616] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:39:47,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:39:54,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:40:02,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:40:11,268] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:40:18,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:40:26,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:40:34,156] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:40:41,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:40:48,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:40:56,456] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:41:03,202] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.387357249369148
[2022-12-07 02:41:03,202] [INFO] [runner_train_mujoco] Average state value: 0.4606486763283611
[2022-12-07 02:41:03,202] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 02:41:03,252] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.05526
[2022-12-07 02:41:03,293] [INFO] [controller] EPOCH 2 loss ppo:  -0.01454, loss val: 0.05515
[2022-12-07 02:41:03,331] [INFO] [controller] EPOCH 3 loss ppo:  -0.01695, loss val: 0.05765
[2022-12-07 02:41:03,375] [INFO] [controller] EPOCH 4 loss ppo:  -0.01999, loss val: 0.05509
[2022-12-07 02:41:03,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:41:03,495] [INFO] [optimize] Finished learning.
