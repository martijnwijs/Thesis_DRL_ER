[2022-12-07 07:31:34,936] [INFO] [optimize] Starting learning
[2022-12-07 07:31:34,947] [INFO] [optimize] Starting learning process..
[2022-12-07 07:31:35,054] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:31:35,055] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:31:45,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:31:53,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:32:01,288] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:32:09,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:32:16,891] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:32:24,436] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:32:32,164] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:32:39,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:32:47,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:32:55,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41184578962597024
[2022-12-07 07:32:55,983] [INFO] [runner_train_mujoco] Average state value: 0.22678557041659952
[2022-12-07 07:32:55,984] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 07:32:56,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.00979, loss val: 0.24951
[2022-12-07 07:32:56,085] [INFO] [controller] EPOCH 2 loss ppo:  -0.05190, loss val: 0.22662
[2022-12-07 07:32:56,127] [INFO] [controller] EPOCH 3 loss ppo:  -0.06857, loss val: 0.20149
[2022-12-07 07:32:56,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.07953, loss val: 0.18606
[2022-12-07 07:32:56,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:32:56,388] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:32:56,388] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:33:05,970] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:33:13,580] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:33:21,792] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:33:30,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:33:38,081] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:33:45,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:33:53,416] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:34:01,012] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:34:08,588] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:34:16,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.538786511616482
[2022-12-07 07:34:16,230] [INFO] [runner_train_mujoco] Average state value: 0.37907012606939927
[2022-12-07 07:34:16,230] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 07:34:16,282] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.18302
[2022-12-07 07:34:16,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.04729, loss val: 0.16605
[2022-12-07 07:34:16,370] [INFO] [controller] EPOCH 3 loss ppo:  -0.06601, loss val: 0.15598
[2022-12-07 07:34:16,413] [INFO] [controller] EPOCH 4 loss ppo:  -0.07697, loss val: 0.14371
[2022-12-07 07:34:16,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:34:16,631] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:34:16,631] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:34:25,247] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:34:33,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:34:41,755] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:34:49,369] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:34:56,840] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:35:04,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:35:12,307] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:35:19,866] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:35:27,327] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:35:35,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42419309517863335
[2022-12-07 07:35:35,475] [INFO] [runner_train_mujoco] Average state value: 0.4881610809589426
[2022-12-07 07:35:35,475] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 07:35:35,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01010, loss val: 0.13519
[2022-12-07 07:35:35,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.04203, loss val: 0.12499
[2022-12-07 07:35:35,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.05793, loss val: 0.11573
[2022-12-07 07:35:35,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.07197, loss val: 0.10756
[2022-12-07 07:35:35,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:35:35,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:35:35,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:35:43,929] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:35:51,634] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:36:00,129] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:36:08,073] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:36:15,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:36:23,811] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:36:31,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:36:39,268] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:36:46,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:36:54,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5967465676101689
[2022-12-07 07:36:54,304] [INFO] [runner_train_mujoco] Average state value: 0.5677271918617188
[2022-12-07 07:36:54,305] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 07:36:54,372] [INFO] [controller] EPOCH 1 loss ppo:  -0.01550, loss val: 0.10126
[2022-12-07 07:36:54,425] [INFO] [controller] EPOCH 2 loss ppo:  -0.05291, loss val: 0.10114
[2022-12-07 07:36:54,474] [INFO] [controller] EPOCH 3 loss ppo:  -0.06799, loss val: 0.09556
[2022-12-07 07:36:54,522] [INFO] [controller] EPOCH 4 loss ppo:  -0.07705, loss val: 0.08828
[2022-12-07 07:36:54,533] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:36:54,743] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:36:54,743] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:37:02,856] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:37:11,266] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:37:21,039] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:37:30,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:37:37,840] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:37:45,195] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:37:52,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:38:00,842] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:38:08,577] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:38:16,281] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4089378289208952
[2022-12-07 07:38:16,281] [INFO] [runner_train_mujoco] Average state value: 0.5819604404332737
[2022-12-07 07:38:16,281] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 07:38:16,334] [INFO] [controller] EPOCH 1 loss ppo:  -0.01045, loss val: 0.08608
[2022-12-07 07:38:16,379] [INFO] [controller] EPOCH 2 loss ppo:  -0.04171, loss val: 0.08276
[2022-12-07 07:38:16,424] [INFO] [controller] EPOCH 3 loss ppo:  -0.05929, loss val: 0.07741
[2022-12-07 07:38:16,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.06935, loss val: 0.07502
[2022-12-07 07:38:16,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:38:16,689] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:38:16,690] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:38:24,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:38:32,346] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:38:40,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:38:48,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:38:56,996] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:39:05,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:39:12,932] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:39:20,467] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:39:27,965] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:39:35,417] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5707162198580278
[2022-12-07 07:39:35,417] [INFO] [runner_train_mujoco] Average state value: 0.5476900141860048
[2022-12-07 07:39:35,417] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 07:39:35,474] [INFO] [controller] EPOCH 1 loss ppo:  -0.01090, loss val: 0.07081
[2022-12-07 07:39:35,517] [INFO] [controller] EPOCH 2 loss ppo:  -0.04035, loss val: 0.06308
[2022-12-07 07:39:35,559] [INFO] [controller] EPOCH 3 loss ppo:  -0.06127, loss val: 0.06174
[2022-12-07 07:39:35,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.07462, loss val: 0.06066
[2022-12-07 07:39:35,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:39:35,818] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:39:35,818] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:39:44,055] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:39:52,780] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:40:01,140] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:40:08,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:40:16,472] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:40:24,074] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:40:31,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:40:39,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:40:47,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:40:55,009] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.43014866661080314
[2022-12-07 07:40:55,009] [INFO] [runner_train_mujoco] Average state value: 0.49983752986292035
[2022-12-07 07:40:55,009] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 07:40:55,060] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.07498
[2022-12-07 07:40:55,104] [INFO] [controller] EPOCH 2 loss ppo:  -0.04129, loss val: 0.07435
[2022-12-07 07:40:55,147] [INFO] [controller] EPOCH 3 loss ppo:  -0.05873, loss val: 0.07136
[2022-12-07 07:40:55,188] [INFO] [controller] EPOCH 4 loss ppo:  -0.07047, loss val: 0.07212
[2022-12-07 07:40:55,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:40:55,400] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:40:55,400] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:41:03,391] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:41:11,376] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:41:18,983] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:41:27,001] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:41:34,952] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:41:43,195] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:41:51,251] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:41:59,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:42:06,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:42:14,245] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4259118119982809
[2022-12-07 07:42:14,245] [INFO] [runner_train_mujoco] Average state value: 0.5154909848098954
[2022-12-07 07:42:14,245] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 07:42:14,301] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.05981
[2022-12-07 07:42:14,352] [INFO] [controller] EPOCH 2 loss ppo:  -0.04616, loss val: 0.05551
[2022-12-07 07:42:14,398] [INFO] [controller] EPOCH 3 loss ppo:  -0.06159, loss val: 0.05187
[2022-12-07 07:42:14,447] [INFO] [controller] EPOCH 4 loss ppo:  -0.07359, loss val: 0.05336
[2022-12-07 07:42:14,457] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:42:14,667] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:42:14,667] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:42:22,956] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:42:31,270] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:42:39,399] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:42:47,399] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:42:55,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:43:03,005] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:43:10,481] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:43:18,066] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:43:27,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:43:34,523] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3864531408067187
[2022-12-07 07:43:34,524] [INFO] [runner_train_mujoco] Average state value: 0.5625658136208853
[2022-12-07 07:43:34,524] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 07:43:34,574] [INFO] [controller] EPOCH 1 loss ppo:  -0.00971, loss val: 0.05408
[2022-12-07 07:43:34,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.03860, loss val: 0.05374
[2022-12-07 07:43:34,663] [INFO] [controller] EPOCH 3 loss ppo:  -0.05695, loss val: 0.05230
[2022-12-07 07:43:34,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.06808, loss val: 0.05195
[2022-12-07 07:43:34,716] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:43:34,921] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:43:34,921] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:43:42,528] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:43:49,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:43:56,947] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:44:04,270] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:44:11,680] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:44:18,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:44:25,613] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:44:32,241] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:44:38,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:44:45,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5557242112732438
[2022-12-07 07:44:45,515] [INFO] [runner_train_mujoco] Average state value: 0.5546582076847553
[2022-12-07 07:44:45,515] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 07:44:45,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01070, loss val: 0.05386
[2022-12-07 07:44:45,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.03424, loss val: 0.04930
[2022-12-07 07:44:45,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.05074, loss val: 0.04275
[2022-12-07 07:44:45,678] [INFO] [controller] EPOCH 4 loss ppo:  -0.06535, loss val: 0.03932
[2022-12-07 07:44:45,684] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:44:45,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:44:45,870] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:44:53,231] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:45:00,019] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:45:06,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:45:13,022] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:45:19,350] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:45:26,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:45:32,189] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:45:38,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:45:44,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:45:51,408] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.576761782566383
[2022-12-07 07:45:51,409] [INFO] [runner_train_mujoco] Average state value: 0.4457696892023086
[2022-12-07 07:45:51,409] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 07:45:51,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.04300
[2022-12-07 07:45:51,489] [INFO] [controller] EPOCH 2 loss ppo:  -0.04670, loss val: 0.04414
[2022-12-07 07:45:51,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.06525, loss val: 0.04457
[2022-12-07 07:45:51,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.07421, loss val: 0.04484
[2022-12-07 07:45:51,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:45:51,750] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:45:51,750] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:45:58,332] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:46:05,149] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:46:11,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:46:17,545] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:46:24,110] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:46:30,464] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:46:36,626] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:46:42,966] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:46:49,131] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:46:55,436] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5059392698548162
[2022-12-07 07:46:55,436] [INFO] [runner_train_mujoco] Average state value: 0.40575278339783355
[2022-12-07 07:46:55,436] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 07:46:55,480] [INFO] [controller] EPOCH 1 loss ppo:  -0.01033, loss val: 0.06563
[2022-12-07 07:46:55,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.03823, loss val: 0.06049
[2022-12-07 07:46:55,558] [INFO] [controller] EPOCH 3 loss ppo:  -0.05739, loss val: 0.05807
[2022-12-07 07:46:55,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.06882, loss val: 0.05177
[2022-12-07 07:46:55,610] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:46:55,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:46:55,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:47:02,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:47:09,346] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:47:15,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:47:21,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:47:27,988] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:47:34,176] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:47:40,669] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:47:46,723] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:47:54,359] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:48:01,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5987676947037089
[2022-12-07 07:48:01,043] [INFO] [runner_train_mujoco] Average state value: 0.4845896334946156
[2022-12-07 07:48:01,043] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 07:48:01,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01165, loss val: 0.05359
[2022-12-07 07:48:01,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.04129, loss val: 0.05351
[2022-12-07 07:48:01,164] [INFO] [controller] EPOCH 3 loss ppo:  -0.05806, loss val: 0.05474
[2022-12-07 07:48:01,204] [INFO] [controller] EPOCH 4 loss ppo:  -0.07061, loss val: 0.05496
[2022-12-07 07:48:01,210] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:48:01,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:48:01,391] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:48:07,901] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:48:14,391] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:48:20,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:48:27,004] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:48:33,457] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:48:39,690] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:48:45,898] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:48:52,087] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:48:58,691] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:49:05,551] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6794903534313421
[2022-12-07 07:49:05,551] [INFO] [runner_train_mujoco] Average state value: 0.5519738195240498
[2022-12-07 07:49:05,551] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 07:49:05,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01110, loss val: 0.04452
[2022-12-07 07:49:05,653] [INFO] [controller] EPOCH 2 loss ppo:  -0.03907, loss val: 0.04374
[2022-12-07 07:49:05,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.05798, loss val: 0.04253
[2022-12-07 07:49:05,827] [INFO] [controller] EPOCH 4 loss ppo:  -0.07337, loss val: 0.04214
[2022-12-07 07:49:05,835] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:49:06,071] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:49:06,072] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:49:15,207] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:49:22,896] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:49:29,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:49:36,612] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:49:43,670] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:49:50,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:49:57,568] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:50:04,727] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:50:11,574] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:50:18,756] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.49241389939142727
[2022-12-07 07:50:18,757] [INFO] [runner_train_mujoco] Average state value: 0.5084920541147391
[2022-12-07 07:50:18,757] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 07:50:18,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01088, loss val: 0.03620
[2022-12-07 07:50:18,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.03937, loss val: 0.04010
[2022-12-07 07:50:18,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.06048, loss val: 0.03640
[2022-12-07 07:50:18,928] [INFO] [controller] EPOCH 4 loss ppo:  -0.07073, loss val: 0.03954
[2022-12-07 07:50:18,938] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:50:19,134] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:50:19,135] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:50:25,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:50:33,171] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:50:40,330] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:50:47,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:50:54,639] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:51:02,270] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:51:09,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:51:16,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:51:23,453] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:51:30,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6757007562347286
[2022-12-07 07:51:30,391] [INFO] [runner_train_mujoco] Average state value: 0.4882843438684941
[2022-12-07 07:51:30,391] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 07:51:30,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.04318
[2022-12-07 07:51:30,502] [INFO] [controller] EPOCH 2 loss ppo:  -0.03965, loss val: 0.04387
[2022-12-07 07:51:30,546] [INFO] [controller] EPOCH 3 loss ppo:  -0.05568, loss val: 0.04155
[2022-12-07 07:51:30,591] [INFO] [controller] EPOCH 4 loss ppo:  -0.06616, loss val: 0.04057
[2022-12-07 07:51:30,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:51:30,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:51:30,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:51:38,165] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:51:45,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:51:53,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:52:02,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:52:09,996] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:52:16,778] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:52:24,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:52:31,033] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:52:38,423] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:52:45,565] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6438646816526333
[2022-12-07 07:52:45,566] [INFO] [runner_train_mujoco] Average state value: 0.5282044952511786
[2022-12-07 07:52:45,566] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 07:52:45,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01016, loss val: 0.04624
[2022-12-07 07:52:45,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.04219, loss val: 0.04471
[2022-12-07 07:52:45,715] [INFO] [controller] EPOCH 3 loss ppo:  -0.06344, loss val: 0.04385
[2022-12-07 07:52:45,759] [INFO] [controller] EPOCH 4 loss ppo:  -0.07446, loss val: 0.04526
[2022-12-07 07:52:45,768] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:52:45,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:52:45,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:52:52,931] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:53:00,289] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:53:07,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:53:14,668] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:53:21,719] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:53:29,161] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:53:36,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:53:43,210] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:53:50,761] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:53:58,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7195023480550689
[2022-12-07 07:53:58,195] [INFO] [runner_train_mujoco] Average state value: 0.5487810201843579
[2022-12-07 07:53:58,195] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 07:53:58,251] [INFO] [controller] EPOCH 1 loss ppo:  -0.01095, loss val: 0.05008
[2022-12-07 07:53:58,298] [INFO] [controller] EPOCH 2 loss ppo:  -0.04271, loss val: 0.04683
[2022-12-07 07:53:58,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.06032, loss val: 0.04878
[2022-12-07 07:53:58,393] [INFO] [controller] EPOCH 4 loss ppo:  -0.07113, loss val: 0.04589
[2022-12-07 07:53:58,403] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:53:58,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:53:58,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:54:06,370] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:54:14,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:54:21,213] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:54:28,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:54:34,791] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:54:41,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:54:49,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:54:55,941] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:55:03,481] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:55:10,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7549926497860595
[2022-12-07 07:55:10,887] [INFO] [runner_train_mujoco] Average state value: 0.5820382153689861
[2022-12-07 07:55:10,887] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 07:55:10,930] [INFO] [controller] EPOCH 1 loss ppo:  -0.01264, loss val: 0.03897
[2022-12-07 07:55:10,971] [INFO] [controller] EPOCH 2 loss ppo:  -0.04471, loss val: 0.03887
[2022-12-07 07:55:11,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.06223, loss val: 0.03862
[2022-12-07 07:55:11,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.07102, loss val: 0.03869
[2022-12-07 07:55:11,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:55:11,225] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:55:11,225] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:55:18,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:55:25,291] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:55:32,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:55:39,048] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:55:46,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:55:53,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:56:01,155] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:56:08,134] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:56:15,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:56:22,037] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8347521354092331
[2022-12-07 07:56:22,037] [INFO] [runner_train_mujoco] Average state value: 0.5990218496719997
[2022-12-07 07:56:22,037] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 07:56:22,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.03827
[2022-12-07 07:56:22,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.04012, loss val: 0.04839
[2022-12-07 07:56:22,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.05492, loss val: 0.03838
[2022-12-07 07:56:22,206] [INFO] [controller] EPOCH 4 loss ppo:  -0.06983, loss val: 0.03874
[2022-12-07 07:56:22,215] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:56:22,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:56:22,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:56:29,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:56:37,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:56:44,771] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:56:51,883] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:56:58,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:57:06,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:57:13,149] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:57:21,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:57:28,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:57:35,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0249450366356592
[2022-12-07 07:57:35,548] [INFO] [runner_train_mujoco] Average state value: 0.5572763516108195
[2022-12-07 07:57:35,548] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 07:57:35,605] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.04369
[2022-12-07 07:57:35,647] [INFO] [controller] EPOCH 2 loss ppo:  -0.04179, loss val: 0.04489
[2022-12-07 07:57:35,690] [INFO] [controller] EPOCH 3 loss ppo:  -0.06052, loss val: 0.04021
[2022-12-07 07:57:35,732] [INFO] [controller] EPOCH 4 loss ppo:  -0.07410, loss val: 0.04368
[2022-12-07 07:57:35,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:57:35,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:57:35,938] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:57:43,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:57:50,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:57:57,321] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:58:04,095] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:58:11,362] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:58:18,346] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:58:25,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:58:32,955] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:58:40,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:58:47,143] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0999234414898071
[2022-12-07 07:58:47,143] [INFO] [runner_train_mujoco] Average state value: 0.48901651291052495
[2022-12-07 07:58:47,143] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 07:58:47,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04077
[2022-12-07 07:58:47,231] [INFO] [controller] EPOCH 2 loss ppo:  -0.04160, loss val: 0.03743
[2022-12-07 07:58:47,271] [INFO] [controller] EPOCH 3 loss ppo:  -0.05799, loss val: 0.03863
[2022-12-07 07:58:47,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.07229, loss val: 0.03732
[2022-12-07 07:58:47,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:58:47,502] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:58:47,503] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:58:54,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:59:01,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:59:09,324] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:59:16,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:59:23,025] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:59:30,086] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:59:37,046] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:59:44,754] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:59:52,780] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:59:59,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1565758515531297
[2022-12-07 07:59:59,904] [INFO] [runner_train_mujoco] Average state value: 0.43678783216079076
[2022-12-07 07:59:59,904] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 07:59:59,960] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04470
[2022-12-07 08:00:00,003] [INFO] [controller] EPOCH 2 loss ppo:  -0.04271, loss val: 0.04535
[2022-12-07 08:00:00,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.05827, loss val: 0.04170
[2022-12-07 08:00:00,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.06911, loss val: 0.03945
[2022-12-07 08:00:00,146] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:00:00,350] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:00:00,350] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:00:07,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:00:14,695] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:00:21,664] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:00:28,642] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:00:36,009] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:00:43,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:00:50,842] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:00:58,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:01:05,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:01:12,495] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2184050231392116
[2022-12-07 08:01:12,495] [INFO] [runner_train_mujoco] Average state value: 0.4691059616009395
[2022-12-07 08:01:12,495] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 08:01:12,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01581, loss val: 0.04866
[2022-12-07 08:01:12,593] [INFO] [controller] EPOCH 2 loss ppo:  -0.04068, loss val: 0.04748
[2022-12-07 08:01:12,640] [INFO] [controller] EPOCH 3 loss ppo:  -0.05468, loss val: 0.04472
[2022-12-07 08:01:12,683] [INFO] [controller] EPOCH 4 loss ppo:  -0.07037, loss val: 0.04328
[2022-12-07 08:01:12,691] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:01:12,874] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:01:12,874] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:01:19,880] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:01:26,877] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:01:34,382] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:01:41,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:01:48,940] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:01:55,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:02:02,994] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:02:10,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:02:17,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:02:24,614] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4011445319975588
[2022-12-07 08:02:24,614] [INFO] [runner_train_mujoco] Average state value: 0.5305470554133257
[2022-12-07 08:02:24,615] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 08:02:24,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04451
[2022-12-07 08:02:24,704] [INFO] [controller] EPOCH 2 loss ppo:  -0.04134, loss val: 0.04296
[2022-12-07 08:02:24,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.06174, loss val: 0.04516
[2022-12-07 08:02:24,788] [INFO] [controller] EPOCH 4 loss ppo:  -0.07637, loss val: 0.04495
[2022-12-07 08:02:24,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:02:24,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:02:24,978] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:02:32,147] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:02:39,604] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:02:46,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:02:53,240] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:02:59,981] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:03:07,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:03:14,492] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:03:21,333] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:03:28,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:03:35,810] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9437055672246455
[2022-12-07 08:03:35,811] [INFO] [runner_train_mujoco] Average state value: 0.5668922292888166
[2022-12-07 08:03:35,811] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 08:03:35,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04031
[2022-12-07 08:03:35,918] [INFO] [controller] EPOCH 2 loss ppo:  -0.04468, loss val: 0.04052
[2022-12-07 08:03:35,965] [INFO] [controller] EPOCH 3 loss ppo:  -0.06138, loss val: 0.03992
[2022-12-07 08:03:36,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.07413, loss val: 0.03950
[2022-12-07 08:03:36,021] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:03:36,233] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:03:36,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:03:43,384] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:03:50,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:03:57,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:04:04,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:04:11,152] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:04:18,091] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:04:25,818] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:04:33,305] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:04:40,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:04:47,196] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1936791672364704
[2022-12-07 08:04:47,196] [INFO] [runner_train_mujoco] Average state value: 0.5550452900727588
[2022-12-07 08:04:47,196] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 08:04:47,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.03666
[2022-12-07 08:04:47,281] [INFO] [controller] EPOCH 2 loss ppo:  -0.04075, loss val: 0.03364
[2022-12-07 08:04:47,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.05961, loss val: 0.03191
[2022-12-07 08:04:47,362] [INFO] [controller] EPOCH 4 loss ppo:  -0.07458, loss val: 0.03151
[2022-12-07 08:04:47,371] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:04:47,566] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:04:47,566] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:04:54,368] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:05:01,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:05:08,156] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:05:15,587] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:05:22,617] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:05:29,687] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:05:37,187] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:05:44,647] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:05:51,959] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:05:58,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.133639749173999
[2022-12-07 08:05:58,632] [INFO] [runner_train_mujoco] Average state value: 0.5380544569691021
[2022-12-07 08:05:58,632] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 08:05:58,683] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.04201
[2022-12-07 08:05:58,728] [INFO] [controller] EPOCH 2 loss ppo:  -0.04064, loss val: 0.04119
[2022-12-07 08:05:58,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.05662, loss val: 0.03926
[2022-12-07 08:05:58,822] [INFO] [controller] EPOCH 4 loss ppo:  -0.06974, loss val: 0.03660
[2022-12-07 08:05:58,831] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:05:59,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:05:59,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:06:06,145] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:06:13,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:06:21,037] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:06:27,904] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:06:34,475] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:06:41,492] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:06:48,617] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:06:56,043] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:07:03,878] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:07:11,786] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.646378770428627
[2022-12-07 08:07:11,786] [INFO] [runner_train_mujoco] Average state value: 0.5790741406480471
[2022-12-07 08:07:11,786] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 08:07:11,841] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.04985
[2022-12-07 08:07:11,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.04166, loss val: 0.04868
[2022-12-07 08:07:11,931] [INFO] [controller] EPOCH 3 loss ppo:  -0.05944, loss val: 0.04906
[2022-12-07 08:07:11,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.07225, loss val: 0.04749
[2022-12-07 08:07:11,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:07:12,189] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:07:12,190] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:07:20,439] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:07:27,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:07:34,609] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:07:41,843] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:07:49,315] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:07:56,258] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:08:03,061] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:08:10,818] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:08:19,933] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:08:28,279] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8944911494495376
[2022-12-07 08:08:28,279] [INFO] [runner_train_mujoco] Average state value: 0.5821150089303652
[2022-12-07 08:08:28,279] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 08:08:28,329] [INFO] [controller] EPOCH 1 loss ppo:  -0.01544, loss val: 0.05764
[2022-12-07 08:08:28,369] [INFO] [controller] EPOCH 2 loss ppo:  -0.04250, loss val: 0.05537
[2022-12-07 08:08:28,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.06041, loss val: 0.05281
[2022-12-07 08:08:28,457] [INFO] [controller] EPOCH 4 loss ppo:  -0.07367, loss val: 0.05046
[2022-12-07 08:08:28,467] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:08:28,640] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:08:28,640] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:08:36,791] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:08:46,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:08:54,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:09:02,439] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:09:10,430] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:09:19,466] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:09:28,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:09:35,887] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:09:43,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:09:51,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5614254677108224
[2022-12-07 08:09:51,334] [INFO] [runner_train_mujoco] Average state value: 0.5275255405704181
[2022-12-07 08:09:51,334] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 08:09:51,387] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.05279
[2022-12-07 08:09:51,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.03712, loss val: 0.05022
[2022-12-07 08:09:51,545] [INFO] [controller] EPOCH 3 loss ppo:  -0.05081, loss val: 0.04823
[2022-12-07 08:09:51,591] [INFO] [controller] EPOCH 4 loss ppo:  -0.06627, loss val: 0.04687
[2022-12-07 08:09:51,601] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:09:51,808] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:09:51,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:10:00,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:10:08,206] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:10:16,459] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:10:24,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:10:32,577] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:10:40,472] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:10:48,156] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:55,638] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:11:03,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:11:12,231] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0071738291473844
[2022-12-07 08:11:12,232] [INFO] [runner_train_mujoco] Average state value: 0.4539413763582706
[2022-12-07 08:11:12,232] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 08:11:12,306] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.03432
[2022-12-07 08:11:12,355] [INFO] [controller] EPOCH 2 loss ppo:  -0.03638, loss val: 0.03374
[2022-12-07 08:11:12,403] [INFO] [controller] EPOCH 3 loss ppo:  -0.05294, loss val: 0.03328
[2022-12-07 08:11:12,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.06878, loss val: 0.03465
[2022-12-07 08:11:12,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:12,683] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:12,683] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:11:21,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:11:29,406] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:11:36,818] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:11:44,495] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:11:52,508] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:12:00,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:12:08,581] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:12:16,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:12:24,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:12:32,510] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3738898294669233
[2022-12-07 08:12:32,510] [INFO] [runner_train_mujoco] Average state value: 0.4244772059222062
[2022-12-07 08:12:32,510] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 08:12:32,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.04271
[2022-12-07 08:12:32,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.04001, loss val: 0.04329
[2022-12-07 08:12:32,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.05275, loss val: 0.04183
[2022-12-07 08:12:32,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.06701, loss val: 0.04293
[2022-12-07 08:12:32,722] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:12:32,932] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:12:32,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:12:40,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:12:48,545] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:12:56,157] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:13:04,117] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:13:11,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:13:20,443] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:13:28,710] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:13:36,345] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:13:44,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:13:52,019] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.922796190654868
[2022-12-07 08:13:52,019] [INFO] [runner_train_mujoco] Average state value: 0.41829076848427454
[2022-12-07 08:13:52,020] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 08:13:52,075] [INFO] [controller] EPOCH 1 loss ppo:  -0.01702, loss val: 0.02312
[2022-12-07 08:13:52,145] [INFO] [controller] EPOCH 2 loss ppo:  -0.04127, loss val: 0.02612
[2022-12-07 08:13:52,201] [INFO] [controller] EPOCH 3 loss ppo:  -0.05687, loss val: 0.02303
[2022-12-07 08:13:52,257] [INFO] [controller] EPOCH 4 loss ppo:  -0.07154, loss val: 0.03075
[2022-12-07 08:13:52,267] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:13:52,475] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:13:52,476] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:14:00,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:14:08,889] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:14:16,996] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:25,133] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:14:33,860] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:14:41,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:14:49,949] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:14:57,709] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:15:05,498] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:15:13,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.149774347672825
[2022-12-07 08:15:13,462] [INFO] [runner_train_mujoco] Average state value: 0.416551272585988
[2022-12-07 08:15:13,463] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 08:15:13,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04659
[2022-12-07 08:15:13,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.03168, loss val: 0.04557
[2022-12-07 08:15:13,603] [INFO] [controller] EPOCH 3 loss ppo:  -0.04702, loss val: 0.04403
[2022-12-07 08:15:13,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.06191, loss val: 0.04185
[2022-12-07 08:15:13,660] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:15:13,867] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:15:13,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:15:21,770] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:15:30,000] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:15:37,318] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:15:45,947] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:15:54,611] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:02,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:10,151] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:16:17,780] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:16:26,519] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:16:34,895] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.245466223357712
[2022-12-07 08:16:34,895] [INFO] [runner_train_mujoco] Average state value: 0.4480515925884247
[2022-12-07 08:16:34,895] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 08:16:34,957] [INFO] [controller] EPOCH 1 loss ppo:  -0.01589, loss val: 0.03809
[2022-12-07 08:16:35,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.03719, loss val: 0.03855
[2022-12-07 08:16:35,055] [INFO] [controller] EPOCH 3 loss ppo:  -0.05365, loss val: 0.03775
[2022-12-07 08:16:35,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.06920, loss val: 0.03850
[2022-12-07 08:16:35,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:16:35,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:16:35,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:16:44,153] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:16:51,799] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:16:59,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:17:09,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:17:16,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:17:25,445] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:17:33,393] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:17:42,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:17:50,314] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:17:58,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.392679924447646
[2022-12-07 08:17:58,485] [INFO] [runner_train_mujoco] Average state value: 0.4613311983744303
[2022-12-07 08:17:58,485] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 08:17:58,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01513, loss val: 0.04328
[2022-12-07 08:17:58,586] [INFO] [controller] EPOCH 2 loss ppo:  -0.03511, loss val: 0.04351
[2022-12-07 08:17:58,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.05259, loss val: 0.04096
[2022-12-07 08:17:58,679] [INFO] [controller] EPOCH 4 loss ppo:  -0.06708, loss val: 0.04172
[2022-12-07 08:17:58,688] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:17:58,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:17:58,898] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:18:07,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:18:16,403] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:18:24,733] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:18:33,140] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:18:41,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:18:49,351] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:18:56,550] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:19:04,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:19:12,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:20,269] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.846963797211833
[2022-12-07 08:19:20,269] [INFO] [runner_train_mujoco] Average state value: 0.4379452271163463
[2022-12-07 08:19:20,269] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 08:19:20,334] [INFO] [controller] EPOCH 1 loss ppo:  -0.01703, loss val: 0.05028
[2022-12-07 08:19:20,397] [INFO] [controller] EPOCH 2 loss ppo:  -0.03955, loss val: 0.04932
[2022-12-07 08:19:20,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.05077, loss val: 0.04973
[2022-12-07 08:19:20,516] [INFO] [controller] EPOCH 4 loss ppo:  -0.06108, loss val: 0.04760
[2022-12-07 08:19:20,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:20,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:20,734] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:29,200] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:19:36,967] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:19:44,773] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:19:53,275] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:20:01,535] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:20:09,475] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:20:17,159] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:20:24,789] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:20:32,435] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:20:40,704] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.165995777846239
[2022-12-07 08:20:40,704] [INFO] [runner_train_mujoco] Average state value: 0.44849842580159505
[2022-12-07 08:20:40,705] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 08:20:40,757] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.04212
[2022-12-07 08:20:40,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.03410, loss val: 0.04411
[2022-12-07 08:20:40,843] [INFO] [controller] EPOCH 3 loss ppo:  -0.04783, loss val: 0.04158
[2022-12-07 08:20:40,888] [INFO] [controller] EPOCH 4 loss ppo:  -0.06560, loss val: 0.04174
[2022-12-07 08:20:40,896] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:20:41,105] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:20:41,106] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:20:49,250] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:20:57,390] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:05,725] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:13,294] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:21:20,986] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:21:28,445] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:21:38,235] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:21:46,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:21:56,374] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:22:03,669] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.328409047652636
[2022-12-07 08:22:03,669] [INFO] [runner_train_mujoco] Average state value: 0.4708804078747829
[2022-12-07 08:22:03,669] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 08:22:03,726] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.05233
[2022-12-07 08:22:03,772] [INFO] [controller] EPOCH 2 loss ppo:  -0.03362, loss val: 0.05307
[2022-12-07 08:22:03,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.04935, loss val: 0.05114
[2022-12-07 08:22:03,864] [INFO] [controller] EPOCH 4 loss ppo:  -0.06278, loss val: 0.05055
[2022-12-07 08:22:03,875] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:22:04,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:22:04,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:22:11,816] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:22:20,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:22:29,153] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:22:37,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:45,553] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:22:53,160] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:23:00,565] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:23:08,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:23:15,945] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:23:24,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.851152125956751
[2022-12-07 08:23:24,372] [INFO] [runner_train_mujoco] Average state value: 0.46010352860391135
[2022-12-07 08:23:24,372] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 08:23:24,424] [INFO] [controller] EPOCH 1 loss ppo:  -0.01264, loss val: 0.04577
[2022-12-07 08:23:24,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.02791, loss val: 0.04426
[2022-12-07 08:23:24,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.04523, loss val: 0.04431
[2022-12-07 08:23:24,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.05711, loss val: 0.04618
[2022-12-07 08:23:24,586] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:23:24,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:23:24,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:23:33,296] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:23:43,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:23:51,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:24:00,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:24:09,756] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:24:17,361] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:24:25,073] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:34,439] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:24:42,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:24:49,969] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.638102018838915
[2022-12-07 08:24:49,970] [INFO] [runner_train_mujoco] Average state value: 0.4548446249961852
[2022-12-07 08:24:49,970] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 08:24:50,028] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.05055
[2022-12-07 08:24:50,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.03156, loss val: 0.05004
[2022-12-07 08:24:50,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.04330, loss val: 0.04992
[2022-12-07 08:24:50,175] [INFO] [controller] EPOCH 4 loss ppo:  -0.05702, loss val: 0.05035
[2022-12-07 08:24:50,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:24:50,409] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:24:50,409] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:24:58,108] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:25:08,384] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:25:15,517] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:25:23,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:25:33,043] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:40,648] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:25:48,554] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:25:55,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:26:03,379] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:26:12,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.343778317221297
[2022-12-07 08:26:12,389] [INFO] [runner_train_mujoco] Average state value: 0.44791406326989336
[2022-12-07 08:26:12,389] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 08:26:12,447] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.04236
[2022-12-07 08:26:12,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.03162, loss val: 0.04394
[2022-12-07 08:26:12,540] [INFO] [controller] EPOCH 3 loss ppo:  -0.04483, loss val: 0.04205
[2022-12-07 08:26:12,590] [INFO] [controller] EPOCH 4 loss ppo:  -0.06134, loss val: 0.04196
[2022-12-07 08:26:12,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:26:12,817] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:26:12,818] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:20,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:26:28,762] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:26:36,527] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:26:44,262] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:26:52,260] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:27:00,299] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:27:08,231] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:27:15,842] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:27:24,187] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:27:31,926] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.751327607803143
[2022-12-07 08:27:31,927] [INFO] [runner_train_mujoco] Average state value: 0.4428257517218589
[2022-12-07 08:27:31,927] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 08:27:31,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04605
[2022-12-07 08:27:32,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.02528, loss val: 0.04491
[2022-12-07 08:27:32,064] [INFO] [controller] EPOCH 3 loss ppo:  -0.03842, loss val: 0.04508
[2022-12-07 08:27:32,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.05286, loss val: 0.04491
[2022-12-07 08:27:32,109] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:27:32,318] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:27:32,318] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:27:40,662] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:27:49,301] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:27:57,025] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:28:06,497] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:28:14,309] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:28:22,111] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:28:30,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:28:38,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:28:46,508] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:28:55,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.8921821435146455
[2022-12-07 08:28:55,088] [INFO] [runner_train_mujoco] Average state value: 0.44705095300575104
[2022-12-07 08:28:55,089] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 08:28:55,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01194, loss val: 0.04455
[2022-12-07 08:28:55,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.02238, loss val: 0.04366
[2022-12-07 08:28:55,233] [INFO] [controller] EPOCH 3 loss ppo:  -0.03585, loss val: 0.04385
[2022-12-07 08:28:55,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.05141, loss val: 0.04225
[2022-12-07 08:28:55,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:28:55,509] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:28:55,509] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:29:03,863] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:29:12,029] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:29:19,776] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:29:28,455] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:29:38,877] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:46,764] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:29:54,879] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:30:03,757] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:30:14,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:30:22,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.819234228568471
[2022-12-07 08:30:22,742] [INFO] [runner_train_mujoco] Average state value: 0.47187175145745275
[2022-12-07 08:30:22,742] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 08:30:22,800] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04133
[2022-12-07 08:30:22,846] [INFO] [controller] EPOCH 2 loss ppo:  -0.02412, loss val: 0.04119
[2022-12-07 08:30:22,890] [INFO] [controller] EPOCH 3 loss ppo:  -0.03851, loss val: 0.04039
[2022-12-07 08:30:22,935] [INFO] [controller] EPOCH 4 loss ppo:  -0.05333, loss val: 0.04050
[2022-12-07 08:30:22,945] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:30:23,157] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:30:23,157] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:30:30,889] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:30:39,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:30:46,674] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:30:54,416] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:31:01,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:31:09,652] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:31:17,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:31:25,587] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:34,518] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:42,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.0455560645735185
[2022-12-07 08:31:42,847] [INFO] [runner_train_mujoco] Average state value: 0.49063061392307283
[2022-12-07 08:31:42,847] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 08:31:42,896] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.03859
[2022-12-07 08:31:42,936] [INFO] [controller] EPOCH 2 loss ppo:  -0.02601, loss val: 0.03902
[2022-12-07 08:31:42,980] [INFO] [controller] EPOCH 3 loss ppo:  -0.03538, loss val: 0.03858
[2022-12-07 08:31:43,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.04952, loss val: 0.03933
[2022-12-07 08:31:43,041] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:43,252] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:43,253] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:31:51,114] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:31:58,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:32:07,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:32:14,703] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:32:23,171] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:32:32,383] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:32:40,060] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:32:49,829] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:32:58,094] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:33:06,099] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.6138505164504915
[2022-12-07 08:33:06,099] [INFO] [runner_train_mujoco] Average state value: 0.49925004529953004
[2022-12-07 08:33:06,100] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 08:33:06,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.05152
[2022-12-07 08:33:06,208] [INFO] [controller] EPOCH 2 loss ppo:  -0.02272, loss val: 0.05136
[2022-12-07 08:33:06,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.03455, loss val: 0.05184
[2022-12-07 08:33:06,399] [INFO] [controller] EPOCH 4 loss ppo:  -0.04929, loss val: 0.05061
[2022-12-07 08:33:06,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:33:06,632] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:33:06,633] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:14,464] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:33:22,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:33:29,956] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:33:37,770] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:33:45,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:33:55,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:34:04,141] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:34:11,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:34:19,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:34:28,379] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.9310893751724265
[2022-12-07 08:34:28,379] [INFO] [runner_train_mujoco] Average state value: 0.4967334436972936
[2022-12-07 08:34:28,379] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 08:34:28,441] [INFO] [controller] EPOCH 1 loss ppo:  -0.01576, loss val: 0.05301
[2022-12-07 08:34:28,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.02812, loss val: 0.05198
[2022-12-07 08:34:28,544] [INFO] [controller] EPOCH 3 loss ppo:  -0.03434, loss val: 0.04857
[2022-12-07 08:34:28,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.04308, loss val: 0.04809
[2022-12-07 08:34:28,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:34:28,821] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:34:28,821] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:34:37,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:46,446] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:34:54,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:02,660] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:35:10,006] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:35:19,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:35:27,751] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:35:35,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:35:44,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:35:53,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.064553604970663
[2022-12-07 08:35:53,632] [INFO] [runner_train_mujoco] Average state value: 0.4731873153590908
[2022-12-07 08:35:53,632] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 08:35:53,685] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04811
[2022-12-07 08:35:53,733] [INFO] [controller] EPOCH 2 loss ppo:  -0.02505, loss val: 0.04831
[2022-12-07 08:35:53,781] [INFO] [controller] EPOCH 3 loss ppo:  -0.03661, loss val: 0.04856
[2022-12-07 08:35:53,828] [INFO] [controller] EPOCH 4 loss ppo:  -0.04665, loss val: 0.04854
[2022-12-07 08:35:53,835] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:35:54,044] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:35:54,044] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:36:01,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:36:10,346] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:36:19,871] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:36:31,702] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:39,623] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:36:47,917] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:36:58,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:37:06,500] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:37:14,072] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:37:21,982] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.061801073454267
[2022-12-07 08:37:21,982] [INFO] [runner_train_mujoco] Average state value: 0.4661125973959764
[2022-12-07 08:37:21,983] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 08:37:22,047] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.03603
[2022-12-07 08:37:22,107] [INFO] [controller] EPOCH 2 loss ppo:  -0.02435, loss val: 0.03492
[2022-12-07 08:37:22,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.03344, loss val: 0.03643
[2022-12-07 08:37:22,210] [INFO] [controller] EPOCH 4 loss ppo:  -0.04215, loss val: 0.03626
[2022-12-07 08:37:22,219] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:37:22,428] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:37:22,429] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:37:30,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:37:38,504] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:37:46,957] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:37:56,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:38:05,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:38:13,009] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:38:21,463] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:38:30,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:38:40,009] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:38:47,460] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.193220423738304
[2022-12-07 08:38:47,460] [INFO] [runner_train_mujoco] Average state value: 0.42614660581822195
[2022-12-07 08:38:47,460] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 08:38:47,512] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.07023
[2022-12-07 08:38:47,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.01955, loss val: 0.06903
[2022-12-07 08:38:47,606] [INFO] [controller] EPOCH 3 loss ppo:  -0.03003, loss val: 0.06877
[2022-12-07 08:38:47,651] [INFO] [controller] EPOCH 4 loss ppo:  -0.04004, loss val: 0.06930
[2022-12-07 08:38:47,659] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:38:47,863] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:38:47,864] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:38:57,184] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:39:05,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:39:14,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:39:23,674] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:39:32,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:39:41,406] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:39:49,244] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:39:58,185] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:40:06,158] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:40:13,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.905264611348378
[2022-12-07 08:40:13,837] [INFO] [runner_train_mujoco] Average state value: 0.4658196776211262
[2022-12-07 08:40:13,837] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 08:40:13,885] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.03257
[2022-12-07 08:40:13,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.02235, loss val: 0.03322
[2022-12-07 08:40:13,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.03259, loss val: 0.03294
[2022-12-07 08:40:14,030] [INFO] [controller] EPOCH 4 loss ppo:  -0.03935, loss val: 0.03308
[2022-12-07 08:40:14,042] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:40:14,264] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:40:14,264] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:40:23,517] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:40:31,625] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:40:39,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:40:48,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:57,620] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:41:05,019] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:41:13,092] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:41:21,967] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:41:31,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:41:41,198] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.8807537330998265
[2022-12-07 08:41:41,198] [INFO] [runner_train_mujoco] Average state value: 0.4488807427485784
[2022-12-07 08:41:41,198] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 08:41:41,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.06508
[2022-12-07 08:41:41,289] [INFO] [controller] EPOCH 2 loss ppo:  -0.01752, loss val: 0.06242
[2022-12-07 08:41:41,335] [INFO] [controller] EPOCH 3 loss ppo:  -0.02499, loss val: 0.06171
[2022-12-07 08:41:41,383] [INFO] [controller] EPOCH 4 loss ppo:  -0.03190, loss val: 0.06417
[2022-12-07 08:41:41,395] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:41:41,603] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:41:41,603] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:41:49,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:41:58,800] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:42:07,418] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:42:15,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:42:23,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:42:32,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:42:39,984] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:42:49,799] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:42:59,292] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:43:07,680] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.923769786296708
[2022-12-07 08:43:07,680] [INFO] [runner_train_mujoco] Average state value: 0.45380852576096853
[2022-12-07 08:43:07,680] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 08:43:07,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.06733
[2022-12-07 08:43:07,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.01761, loss val: 0.06725
[2022-12-07 08:43:07,840] [INFO] [controller] EPOCH 3 loss ppo:  -0.02592, loss val: 0.06715
[2022-12-07 08:43:07,885] [INFO] [controller] EPOCH 4 loss ppo:  -0.03337, loss val: 0.06643
[2022-12-07 08:43:07,896] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:43:08,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:43:08,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:43:16,709] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:43:25,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:43:34,700] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:43:42,159] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:43:50,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:43:59,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:44:08,389] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:44:16,767] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:44:24,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:44:33,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.179910424283552
[2022-12-07 08:44:33,651] [INFO] [runner_train_mujoco] Average state value: 0.477759922216336
[2022-12-07 08:44:33,651] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 08:44:33,701] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04616
[2022-12-07 08:44:33,742] [INFO] [controller] EPOCH 2 loss ppo:  -0.01650, loss val: 0.04901
[2022-12-07 08:44:33,784] [INFO] [controller] EPOCH 3 loss ppo:  -0.02198, loss val: 0.04694
[2022-12-07 08:44:33,828] [INFO] [controller] EPOCH 4 loss ppo:  -0.02751, loss val: 0.04541
[2022-12-07 08:44:33,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:44:34,076] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:44:34,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:44:42,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:44:50,572] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:44:58,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:45:07,667] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:45:16,295] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:45:25,402] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:45:36,140] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:45:44,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:45:54,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:46:04,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.205216976848021
[2022-12-07 08:46:04,166] [INFO] [runner_train_mujoco] Average state value: 0.4863701277573903
[2022-12-07 08:46:04,166] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 08:46:04,227] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04910
[2022-12-07 08:46:04,276] [INFO] [controller] EPOCH 2 loss ppo:  -0.01601, loss val: 0.04824
[2022-12-07 08:46:04,335] [INFO] [controller] EPOCH 3 loss ppo:  -0.02027, loss val: 0.05019
[2022-12-07 08:46:04,383] [INFO] [controller] EPOCH 4 loss ppo:  -0.02560, loss val: 0.04799
[2022-12-07 08:46:04,394] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:46:04,622] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:46:04,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:46:14,530] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:46:24,420] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:46:33,857] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:46:42,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:46:51,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:46:59,980] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:47:10,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:47:20,800] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:47:30,020] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:47:37,434] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.01393197442158
[2022-12-07 08:47:37,434] [INFO] [runner_train_mujoco] Average state value: 0.48884664872785405
[2022-12-07 08:47:37,434] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 08:47:37,482] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04514
[2022-12-07 08:47:37,526] [INFO] [controller] EPOCH 2 loss ppo:  -0.01437, loss val: 0.04559
[2022-12-07 08:47:37,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.01634, loss val: 0.04493
[2022-12-07 08:47:37,606] [INFO] [controller] EPOCH 4 loss ppo:  -0.01917, loss val: 0.04550
[2022-12-07 08:47:37,614] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:47:37,741] [INFO] [optimize] Finished learning.
