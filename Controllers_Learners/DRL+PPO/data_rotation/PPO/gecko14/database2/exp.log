[2022-12-06 17:07:33,201] [INFO] [optimize] Starting learning
[2022-12-06 17:07:33,251] [INFO] [optimize] Starting learning process..
[2022-12-06 17:07:33,493] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:07:33,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:07:51,590] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:08:07,144] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:08:23,205] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:08:38,362] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:08:52,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:09:08,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:09:25,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:09:39,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:09:54,706] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:10:12,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4160014714933357
[2022-12-06 17:10:12,475] [INFO] [runner_train_mujoco] Average state value: 0.027472635633001723
[2022-12-06 17:10:12,475] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 17:10:12,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01221, loss val: 0.35538
[2022-12-06 17:10:12,692] [INFO] [controller] EPOCH 2 loss ppo:  -0.05473, loss val: 0.31757
[2022-12-06 17:10:12,782] [INFO] [controller] EPOCH 3 loss ppo:  -0.07299, loss val: 0.27679
[2022-12-06 17:10:12,872] [INFO] [controller] EPOCH 4 loss ppo:  -0.08283, loss val: 0.23246
[2022-12-06 17:10:12,887] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:10:13,201] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:10:13,202] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:10:29,149] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:10:46,412] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:11:03,637] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:11:19,492] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:11:37,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:11:54,820] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:12:11,715] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:12:27,739] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:12:43,799] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:13:03,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5139185826876946
[2022-12-06 17:13:03,300] [INFO] [runner_train_mujoco] Average state value: 0.21214136909320952
[2022-12-06 17:13:03,300] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 17:13:03,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.15383
[2022-12-06 17:13:03,708] [INFO] [controller] EPOCH 2 loss ppo:  -0.04872, loss val: 0.13082
[2022-12-06 17:13:04,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.06817, loss val: 0.11753
[2022-12-06 17:13:04,148] [INFO] [controller] EPOCH 4 loss ppo:  -0.07650, loss val: 0.10188
[2022-12-06 17:13:04,163] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:13:04,541] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:13:04,542] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:13:21,771] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:13:37,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:13:51,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:14:06,824] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:14:21,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:14:36,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:14:49,026] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:15:01,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:15:18,164] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:15:30,874] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5211135092071639
[2022-12-06 17:15:30,874] [INFO] [runner_train_mujoco] Average state value: 0.3605787799820925
[2022-12-06 17:15:30,874] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 17:15:31,010] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.12010
[2022-12-06 17:15:31,090] [INFO] [controller] EPOCH 2 loss ppo:  -0.04624, loss val: 0.10940
[2022-12-06 17:15:31,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.06395, loss val: 0.09666
[2022-12-06 17:15:31,242] [INFO] [controller] EPOCH 4 loss ppo:  -0.07626, loss val: 0.09083
[2022-12-06 17:15:31,255] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:15:31,509] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:15:31,510] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:15:43,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:15:55,837] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:16:08,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:16:21,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:16:32,579] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:16:45,437] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:16:58,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:17:10,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:17:22,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:17:35,662] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3676463043401371
[2022-12-06 17:17:35,663] [INFO] [runner_train_mujoco] Average state value: 0.4950909589839478
[2022-12-06 17:17:35,663] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 17:17:35,845] [INFO] [controller] EPOCH 1 loss ppo:  -0.00949, loss val: 0.07829
[2022-12-06 17:17:36,022] [INFO] [controller] EPOCH 2 loss ppo:  -0.04241, loss val: 0.07435
[2022-12-06 17:17:36,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.06393, loss val: 0.07017
[2022-12-06 17:17:36,274] [INFO] [controller] EPOCH 4 loss ppo:  -0.07577, loss val: 0.06763
[2022-12-06 17:17:36,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:17:36,632] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:17:36,637] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:17:49,202] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:18:00,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:18:11,310] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:18:22,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:18:32,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:18:43,434] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:18:53,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:19:04,866] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:19:15,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:19:26,756] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6245819571692413
[2022-12-06 17:19:26,756] [INFO] [runner_train_mujoco] Average state value: 0.5620777453134458
[2022-12-06 17:19:26,757] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 17:19:26,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.00997, loss val: 0.06596
[2022-12-06 17:19:26,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.04256, loss val: 0.06212
[2022-12-06 17:19:26,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.06174, loss val: 0.05874
[2022-12-06 17:19:27,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.07279, loss val: 0.05646
[2022-12-06 17:19:27,024] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:19:27,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:19:27,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:19:37,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:19:47,842] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:19:58,530] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:20:09,743] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:20:19,885] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:20:31,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:20:45,354] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:20:59,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:21:10,458] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:21:22,197] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5057439184491919
[2022-12-06 17:21:22,198] [INFO] [runner_train_mujoco] Average state value: 0.5994199469089507
[2022-12-06 17:21:22,198] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 17:21:22,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.00856, loss val: 0.05627
[2022-12-06 17:21:22,332] [INFO] [controller] EPOCH 2 loss ppo:  -0.03857, loss val: 0.05421
[2022-12-06 17:21:22,401] [INFO] [controller] EPOCH 3 loss ppo:  -0.05751, loss val: 0.05268
[2022-12-06 17:21:22,461] [INFO] [controller] EPOCH 4 loss ppo:  -0.07065, loss val: 0.05030
[2022-12-06 17:21:22,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:21:22,750] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:21:22,751] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:21:33,855] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:21:43,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:21:53,552] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:22:03,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:22:14,283] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:22:24,904] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:22:35,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:22:45,465] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:22:56,094] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:23:07,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41968847610364424
[2022-12-06 17:23:07,053] [INFO] [runner_train_mujoco] Average state value: 0.5791769832173983
[2022-12-06 17:23:07,053] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 17:23:07,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.00934, loss val: 0.05174
[2022-12-06 17:23:07,174] [INFO] [controller] EPOCH 2 loss ppo:  -0.04192, loss val: 0.04949
[2022-12-06 17:23:07,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.05814, loss val: 0.04793
[2022-12-06 17:23:07,294] [INFO] [controller] EPOCH 4 loss ppo:  -0.06935, loss val: 0.04693
[2022-12-06 17:23:07,307] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:23:07,570] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:23:07,571] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:23:18,622] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:23:29,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:23:40,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:23:51,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:24:02,549] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:24:13,447] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:24:23,990] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:24:34,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:24:44,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:24:55,350] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6419246296514116
[2022-12-06 17:24:55,351] [INFO] [runner_train_mujoco] Average state value: 0.5395183620154856
[2022-12-06 17:24:55,351] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 17:24:55,436] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.05169
[2022-12-06 17:24:55,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.04307, loss val: 0.04689
[2022-12-06 17:24:55,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.06027, loss val: 0.04977
[2022-12-06 17:24:55,636] [INFO] [controller] EPOCH 4 loss ppo:  -0.07092, loss val: 0.04511
[2022-12-06 17:24:55,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:24:55,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:24:55,898] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:25:06,290] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:25:16,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:25:26,345] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:25:36,149] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:25:45,734] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:25:55,272] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:26:05,673] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:26:15,992] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:26:26,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:26:35,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5082044550346321
[2022-12-06 17:26:35,384] [INFO] [runner_train_mujoco] Average state value: 0.5439942823747794
[2022-12-06 17:26:35,384] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 17:26:35,445] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.04944
[2022-12-06 17:26:35,499] [INFO] [controller] EPOCH 2 loss ppo:  -0.03965, loss val: 0.05240
[2022-12-06 17:26:35,552] [INFO] [controller] EPOCH 3 loss ppo:  -0.05571, loss val: 0.04870
[2022-12-06 17:26:35,609] [INFO] [controller] EPOCH 4 loss ppo:  -0.06645, loss val: 0.04718
[2022-12-06 17:26:35,620] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:26:35,877] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:26:35,877] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:26:45,786] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:26:55,011] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:27:04,389] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:27:14,061] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:27:22,643] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:27:30,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:27:38,396] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:27:46,683] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:27:55,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:28:03,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7347331477639987
[2022-12-06 17:28:03,697] [INFO] [runner_train_mujoco] Average state value: 0.5324195521672567
[2022-12-06 17:28:03,697] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 17:28:03,745] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.04324
[2022-12-06 17:28:03,785] [INFO] [controller] EPOCH 2 loss ppo:  -0.04723, loss val: 0.04110
[2022-12-06 17:28:03,837] [INFO] [controller] EPOCH 3 loss ppo:  -0.06702, loss val: 0.03943
[2022-12-06 17:28:03,885] [INFO] [controller] EPOCH 4 loss ppo:  -0.08058, loss val: 0.04456
[2022-12-06 17:28:03,895] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:28:04,108] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:28:04,108] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:28:18,679] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:28:27,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:28:36,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:28:45,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:28:57,223] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:29:06,458] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:29:14,179] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:29:22,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:29:30,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:29:38,409] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7282914592424303
[2022-12-06 17:29:38,409] [INFO] [runner_train_mujoco] Average state value: 0.4954796431859334
[2022-12-06 17:29:38,409] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 17:29:38,462] [INFO] [controller] EPOCH 1 loss ppo:  -0.01105, loss val: 0.04397
[2022-12-06 17:29:38,506] [INFO] [controller] EPOCH 2 loss ppo:  -0.03553, loss val: 0.04146
[2022-12-06 17:29:38,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.05177, loss val: 0.03996
[2022-12-06 17:29:38,587] [INFO] [controller] EPOCH 4 loss ppo:  -0.06454, loss val: 0.03825
[2022-12-06 17:29:38,597] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:29:38,797] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:29:38,798] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:29:47,219] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:29:55,071] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:30:03,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:30:11,618] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:30:19,575] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:30:27,379] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:30:35,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:30:43,440] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:30:51,285] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:30:59,764] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.237816050254412
[2022-12-06 17:30:59,764] [INFO] [runner_train_mujoco] Average state value: 0.44490551416079205
[2022-12-06 17:30:59,764] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 17:30:59,831] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.03573
[2022-12-06 17:30:59,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.04613, loss val: 0.03671
[2022-12-06 17:30:59,935] [INFO] [controller] EPOCH 3 loss ppo:  -0.06551, loss val: 0.03744
[2022-12-06 17:30:59,983] [INFO] [controller] EPOCH 4 loss ppo:  -0.07854, loss val: 0.03485
[2022-12-06 17:30:59,993] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:31:00,221] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:31:00,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:31:09,247] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:31:17,732] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:31:25,833] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:31:34,002] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:31:42,915] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:31:51,063] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:31:59,876] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:32:08,191] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:32:16,376] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:32:24,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6301587644943359
[2022-12-06 17:32:24,264] [INFO] [runner_train_mujoco] Average state value: 0.40158841895063724
[2022-12-06 17:32:24,264] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 17:32:24,319] [INFO] [controller] EPOCH 1 loss ppo:  -0.01166, loss val: 0.04164
[2022-12-06 17:32:24,362] [INFO] [controller] EPOCH 2 loss ppo:  -0.04392, loss val: 0.04122
[2022-12-06 17:32:24,409] [INFO] [controller] EPOCH 3 loss ppo:  -0.06523, loss val: 0.04277
[2022-12-06 17:32:24,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.07707, loss val: 0.04030
[2022-12-06 17:32:24,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:32:24,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:32:24,708] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:32:33,013] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:32:41,363] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:32:49,660] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:32:57,768] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:33:06,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:33:13,644] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:33:21,905] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:33:29,750] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:33:37,450] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:33:46,767] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3172989664072592
[2022-12-06 17:33:46,767] [INFO] [runner_train_mujoco] Average state value: 0.42311149442195883
[2022-12-06 17:33:46,767] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 17:33:46,829] [INFO] [controller] EPOCH 1 loss ppo:  -0.01553, loss val: 0.04010
[2022-12-06 17:33:46,874] [INFO] [controller] EPOCH 2 loss ppo:  -0.05100, loss val: 0.04007
[2022-12-06 17:33:46,991] [INFO] [controller] EPOCH 3 loss ppo:  -0.06520, loss val: 0.03982
[2022-12-06 17:33:47,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.07616, loss val: 0.03940
[2022-12-06 17:33:47,046] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:33:47,261] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:33:47,261] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:33:55,052] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:34:03,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:34:11,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:34:19,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:34:27,611] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:34:35,054] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:34:42,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:34:50,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:34:59,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:35:07,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2475301456144137
[2022-12-06 17:35:07,297] [INFO] [runner_train_mujoco] Average state value: 0.45849458023905754
[2022-12-06 17:35:07,298] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 17:35:07,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.04629
[2022-12-06 17:35:07,393] [INFO] [controller] EPOCH 2 loss ppo:  -0.04273, loss val: 0.04524
[2022-12-06 17:35:07,437] [INFO] [controller] EPOCH 3 loss ppo:  -0.05783, loss val: 0.04318
[2022-12-06 17:35:07,480] [INFO] [controller] EPOCH 4 loss ppo:  -0.07148, loss val: 0.04074
[2022-12-06 17:35:07,490] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:35:07,707] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:35:07,707] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:35:15,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:35:23,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:35:30,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:35:38,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:35:45,738] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:35:53,899] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:36:01,891] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:36:11,750] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:36:19,577] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:36:27,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3785967919639173
[2022-12-06 17:36:27,481] [INFO] [runner_train_mujoco] Average state value: 0.4097206050008535
[2022-12-06 17:36:27,481] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 17:36:27,531] [INFO] [controller] EPOCH 1 loss ppo:  -0.01550, loss val: 0.04348
[2022-12-06 17:36:27,576] [INFO] [controller] EPOCH 2 loss ppo:  -0.04426, loss val: 0.04555
[2022-12-06 17:36:27,622] [INFO] [controller] EPOCH 3 loss ppo:  -0.05927, loss val: 0.04537
[2022-12-06 17:36:27,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.07223, loss val: 0.04399
[2022-12-06 17:36:27,677] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:36:27,921] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:36:27,922] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:36:35,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:36:44,236] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:36:52,595] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:37:00,940] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:37:10,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:37:18,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:37:26,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:37:34,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:37:42,442] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:37:50,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9610956832731916
[2022-12-06 17:37:50,315] [INFO] [runner_train_mujoco] Average state value: 0.41522746097296476
[2022-12-06 17:37:50,315] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 17:37:50,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01611, loss val: 0.05432
[2022-12-06 17:37:50,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.04126, loss val: 0.04681
[2022-12-06 17:37:50,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.06428, loss val: 0.03609
[2022-12-06 17:37:50,509] [INFO] [controller] EPOCH 4 loss ppo:  -0.07577, loss val: 0.03329
[2022-12-06 17:37:50,521] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:37:50,755] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:37:50,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:37:58,997] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:38:07,498] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:38:15,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:38:23,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:38:31,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:38:39,198] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:38:46,782] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:38:54,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:39:02,082] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:39:10,407] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3498579469146774
[2022-12-06 17:39:10,407] [INFO] [runner_train_mujoco] Average state value: 0.4951358569661776
[2022-12-06 17:39:10,407] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 17:39:10,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04737
[2022-12-06 17:39:10,504] [INFO] [controller] EPOCH 2 loss ppo:  -0.04355, loss val: 0.05100
[2022-12-06 17:39:10,549] [INFO] [controller] EPOCH 3 loss ppo:  -0.06216, loss val: 0.05029
[2022-12-06 17:39:10,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.07648, loss val: 0.04969
[2022-12-06 17:39:10,597] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:39:10,814] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:39:10,814] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:39:18,313] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:39:26,174] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:39:33,652] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:39:41,060] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:39:48,763] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:39:55,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:40:02,131] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:40:09,162] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:40:15,942] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:40:22,801] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5327177616460177
[2022-12-06 17:40:22,801] [INFO] [runner_train_mujoco] Average state value: 0.502700324907899
[2022-12-06 17:40:22,801] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 17:40:22,848] [INFO] [controller] EPOCH 1 loss ppo:  -0.01586, loss val: 0.04472
[2022-12-06 17:40:22,890] [INFO] [controller] EPOCH 2 loss ppo:  -0.04630, loss val: 0.04277
[2022-12-06 17:40:22,931] [INFO] [controller] EPOCH 3 loss ppo:  -0.06498, loss val: 0.04197
[2022-12-06 17:40:22,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.07708, loss val: 0.04060
[2022-12-06 17:40:22,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:40:23,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:40:23,169] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:40:30,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:40:36,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:40:43,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:40:49,915] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:40:57,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:41:04,685] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:41:11,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:41:18,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:41:24,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:41:31,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5777925578791
[2022-12-06 17:41:31,460] [INFO] [runner_train_mujoco] Average state value: 0.4414886941065391
[2022-12-06 17:41:31,460] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 17:41:31,510] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.04202
[2022-12-06 17:41:31,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.04018, loss val: 0.04197
[2022-12-06 17:41:31,596] [INFO] [controller] EPOCH 3 loss ppo:  -0.06146, loss val: 0.04265
[2022-12-06 17:41:31,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.07376, loss val: 0.04246
[2022-12-06 17:41:31,650] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:41:31,855] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:41:31,856] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:41:39,140] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:41:45,895] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:41:52,693] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:41:59,825] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:42:06,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:42:13,397] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:42:20,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:42:26,797] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:42:33,906] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:42:40,793] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.612908459575634
[2022-12-06 17:42:40,793] [INFO] [runner_train_mujoco] Average state value: 0.40821907326579093
[2022-12-06 17:42:40,793] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 17:42:40,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03966
[2022-12-06 17:42:40,881] [INFO] [controller] EPOCH 2 loss ppo:  -0.03940, loss val: 0.03949
[2022-12-06 17:42:40,923] [INFO] [controller] EPOCH 3 loss ppo:  -0.05710, loss val: 0.04329
[2022-12-06 17:42:40,963] [INFO] [controller] EPOCH 4 loss ppo:  -0.07190, loss val: 0.04057
[2022-12-06 17:42:40,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:42:41,184] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:42:41,185] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:42:48,112] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:42:55,434] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:43:02,387] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:43:09,878] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:43:17,902] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:43:26,369] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:43:33,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:43:40,056] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:43:46,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:43:53,684] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8400080267399757
[2022-12-06 17:43:53,684] [INFO] [runner_train_mujoco] Average state value: 0.4205157182365656
[2022-12-06 17:43:53,684] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 17:43:53,740] [INFO] [controller] EPOCH 1 loss ppo:  -0.01676, loss val: 0.04676
[2022-12-06 17:43:53,788] [INFO] [controller] EPOCH 2 loss ppo:  -0.04380, loss val: 0.04803
[2022-12-06 17:43:53,834] [INFO] [controller] EPOCH 3 loss ppo:  -0.06357, loss val: 0.04645
[2022-12-06 17:43:53,879] [INFO] [controller] EPOCH 4 loss ppo:  -0.07593, loss val: 0.04990
[2022-12-06 17:43:53,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:43:54,078] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:43:54,079] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:44:01,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:44:09,207] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:44:16,343] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:44:23,834] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:44:30,985] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:44:37,923] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:44:45,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:44:51,842] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:44:58,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:45:05,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.258046514558201
[2022-12-06 17:45:05,370] [INFO] [runner_train_mujoco] Average state value: 0.4451591196159521
[2022-12-06 17:45:05,371] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 17:45:05,421] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.03500
[2022-12-06 17:45:05,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.03883, loss val: 0.03468
[2022-12-06 17:45:05,503] [INFO] [controller] EPOCH 3 loss ppo:  -0.06306, loss val: 0.03605
[2022-12-06 17:45:05,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.07387, loss val: 0.03445
[2022-12-06 17:45:05,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:45:05,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:45:05,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:45:13,186] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:45:20,381] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:45:27,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:45:34,681] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:45:41,466] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:45:48,223] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:45:54,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:46:01,589] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:46:09,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:46:16,058] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.3546552704811905
[2022-12-06 17:46:16,058] [INFO] [runner_train_mujoco] Average state value: 0.46680757411321006
[2022-12-06 17:46:16,058] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 17:46:16,104] [INFO] [controller] EPOCH 1 loss ppo:  -0.01593, loss val: 0.04648
[2022-12-06 17:46:16,139] [INFO] [controller] EPOCH 2 loss ppo:  -0.03768, loss val: 0.04651
[2022-12-06 17:46:16,177] [INFO] [controller] EPOCH 3 loss ppo:  -0.05398, loss val: 0.04616
[2022-12-06 17:46:16,221] [INFO] [controller] EPOCH 4 loss ppo:  -0.06951, loss val: 0.04445
[2022-12-06 17:46:16,230] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:46:16,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:46:16,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:46:23,329] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:46:30,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:46:36,922] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:46:43,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:46:50,304] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:46:56,877] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:47:03,164] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:47:12,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:47:18,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:47:25,130] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.504087115975783
[2022-12-06 17:47:25,130] [INFO] [runner_train_mujoco] Average state value: 0.44638952850302055
[2022-12-06 17:47:25,131] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 17:47:25,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01555, loss val: 0.04176
[2022-12-06 17:47:25,215] [INFO] [controller] EPOCH 2 loss ppo:  -0.04129, loss val: 0.04601
[2022-12-06 17:47:25,252] [INFO] [controller] EPOCH 3 loss ppo:  -0.06142, loss val: 0.03979
[2022-12-06 17:47:25,294] [INFO] [controller] EPOCH 4 loss ppo:  -0.07331, loss val: 0.03996
[2022-12-06 17:47:25,300] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:47:25,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:47:25,491] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:47:32,320] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:47:40,779] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:47:47,339] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:47:54,248] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:48:00,956] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:48:07,672] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:48:14,351] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:48:20,880] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:48:27,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:48:34,318] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.567423003267708
[2022-12-06 17:48:34,318] [INFO] [runner_train_mujoco] Average state value: 0.40816972949107483
[2022-12-06 17:48:34,318] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 17:48:34,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.04413
[2022-12-06 17:48:34,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.03886, loss val: 0.04240
[2022-12-06 17:48:34,457] [INFO] [controller] EPOCH 3 loss ppo:  -0.05921, loss val: 0.04372
[2022-12-06 17:48:34,504] [INFO] [controller] EPOCH 4 loss ppo:  -0.07502, loss val: 0.04308
[2022-12-06 17:48:34,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:48:34,715] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:48:34,716] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:48:41,659] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:48:48,933] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:48:55,701] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:49:02,525] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:49:09,448] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:49:16,310] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:49:22,940] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:49:29,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:49:36,729] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:49:43,474] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.629986479495464
[2022-12-06 17:49:43,474] [INFO] [runner_train_mujoco] Average state value: 0.4148819835881392
[2022-12-06 17:49:43,475] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 17:49:43,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.01592, loss val: 0.04102
[2022-12-06 17:49:43,566] [INFO] [controller] EPOCH 2 loss ppo:  -0.04002, loss val: 0.03941
[2022-12-06 17:49:43,600] [INFO] [controller] EPOCH 3 loss ppo:  -0.06217, loss val: 0.03887
[2022-12-06 17:49:43,641] [INFO] [controller] EPOCH 4 loss ppo:  -0.07533, loss val: 0.03932
[2022-12-06 17:49:43,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:49:43,830] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:49:43,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:49:50,679] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:49:57,988] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:50:04,988] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:50:11,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:50:19,210] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:50:26,239] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:50:33,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:50:40,309] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:50:47,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:50:54,092] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.97481173860928
[2022-12-06 17:50:54,092] [INFO] [runner_train_mujoco] Average state value: 0.41275418068965275
[2022-12-06 17:50:54,092] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 17:50:54,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01614, loss val: 0.03127
[2022-12-06 17:50:54,186] [INFO] [controller] EPOCH 2 loss ppo:  -0.04337, loss val: 0.03117
[2022-12-06 17:50:54,231] [INFO] [controller] EPOCH 3 loss ppo:  -0.06073, loss val: 0.02925
[2022-12-06 17:50:54,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.07661, loss val: 0.02929
[2022-12-06 17:50:54,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:50:54,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:50:54,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:51:01,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:51:08,732] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:51:15,803] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:51:22,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:51:29,490] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:51:36,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:51:43,178] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:51:49,932] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:51:56,560] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:52:03,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.303848274436187
[2022-12-06 17:52:03,066] [INFO] [runner_train_mujoco] Average state value: 0.3841003688077132
[2022-12-06 17:52:03,066] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 17:52:03,122] [INFO] [controller] EPOCH 1 loss ppo:  -0.01676, loss val: 0.03573
[2022-12-06 17:52:03,169] [INFO] [controller] EPOCH 2 loss ppo:  -0.04019, loss val: 0.03339
[2022-12-06 17:52:03,213] [INFO] [controller] EPOCH 3 loss ppo:  -0.05866, loss val: 0.03713
[2022-12-06 17:52:03,257] [INFO] [controller] EPOCH 4 loss ppo:  -0.07307, loss val: 0.04531
[2022-12-06 17:52:03,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:52:03,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:52:03,472] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:52:10,216] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:52:17,321] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:52:24,135] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:52:30,830] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:52:37,148] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:52:43,901] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:52:51,067] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:52:57,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:53:04,027] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:53:10,581] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.913279756447148
[2022-12-06 17:53:10,582] [INFO] [runner_train_mujoco] Average state value: 0.3838959640264511
[2022-12-06 17:53:10,582] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 17:53:10,635] [INFO] [controller] EPOCH 1 loss ppo:  -0.01689, loss val: 0.03822
[2022-12-06 17:53:10,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.04074, loss val: 0.03680
[2022-12-06 17:53:10,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.05826, loss val: 0.03547
[2022-12-06 17:53:10,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.07380, loss val: 0.03406
[2022-12-06 17:53:10,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:53:10,974] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:53:10,974] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:53:17,585] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:53:24,303] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:53:31,465] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:53:37,974] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:53:44,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:53:50,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:53:57,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:54:04,050] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:54:10,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:54:17,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.510967790909878
[2022-12-06 17:54:17,050] [INFO] [runner_train_mujoco] Average state value: 0.4148486642738184
[2022-12-06 17:54:17,050] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 17:54:17,092] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.05296
[2022-12-06 17:54:17,134] [INFO] [controller] EPOCH 2 loss ppo:  -0.03896, loss val: 0.04848
[2022-12-06 17:54:17,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.05767, loss val: 0.04894
[2022-12-06 17:54:17,274] [INFO] [controller] EPOCH 4 loss ppo:  -0.07247, loss val: 0.04612
[2022-12-06 17:54:17,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:54:17,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:54:17,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:54:24,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:54:31,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:54:39,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:54:45,845] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:54:52,380] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:54:58,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:55:05,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:55:12,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:55:19,221] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:55:25,879] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.747751872644659
[2022-12-06 17:55:25,879] [INFO] [runner_train_mujoco] Average state value: 0.4888510236938794
[2022-12-06 17:55:25,879] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 17:55:25,929] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.03337
[2022-12-06 17:55:25,971] [INFO] [controller] EPOCH 2 loss ppo:  -0.03997, loss val: 0.04330
[2022-12-06 17:55:26,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.05551, loss val: 0.03375
[2022-12-06 17:55:26,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.07140, loss val: 0.03233
[2022-12-06 17:55:26,065] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:55:26,266] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:55:26,266] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:55:32,902] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:55:39,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:55:46,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:55:53,439] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:56:00,241] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:56:06,911] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:56:13,827] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:56:20,678] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:56:27,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:56:34,463] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.244282681277429
[2022-12-06 17:56:34,463] [INFO] [runner_train_mujoco] Average state value: 0.5198499076192578
[2022-12-06 17:56:34,463] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 17:56:34,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.03951
[2022-12-06 17:56:34,566] [INFO] [controller] EPOCH 2 loss ppo:  -0.03936, loss val: 0.03857
[2022-12-06 17:56:34,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.05534, loss val: 0.03949
[2022-12-06 17:56:34,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.07028, loss val: 0.03967
[2022-12-06 17:56:34,665] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:56:34,855] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:56:34,856] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:56:42,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:56:49,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:56:56,365] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:57:03,317] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:57:10,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:57:16,843] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:57:23,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:57:30,466] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:57:37,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:57:44,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.613535332238641
[2022-12-06 17:57:44,334] [INFO] [runner_train_mujoco] Average state value: 0.5549324521621068
[2022-12-06 17:57:44,334] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 17:57:44,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.01580, loss val: 0.06129
[2022-12-06 17:57:44,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.03622, loss val: 0.05931
[2022-12-06 17:57:44,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.04566, loss val: 0.05793
[2022-12-06 17:57:44,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.06097, loss val: 0.05706
[2022-12-06 17:57:44,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:57:44,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:57:44,744] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:57:51,634] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:57:58,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:58:05,687] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:58:12,259] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:58:19,176] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:58:25,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:58:32,434] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:58:38,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:58:45,835] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:58:52,547] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.145749876758985
[2022-12-06 17:58:52,547] [INFO] [runner_train_mujoco] Average state value: 0.5178866209685802
[2022-12-06 17:58:52,547] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 17:58:52,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.04747
[2022-12-06 17:58:52,637] [INFO] [controller] EPOCH 2 loss ppo:  -0.02849, loss val: 0.04372
[2022-12-06 17:58:52,679] [INFO] [controller] EPOCH 3 loss ppo:  -0.04604, loss val: 0.04104
[2022-12-06 17:58:52,722] [INFO] [controller] EPOCH 4 loss ppo:  -0.05839, loss val: 0.03674
[2022-12-06 17:58:52,732] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:58:52,934] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:58:52,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:58:59,399] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:59:06,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:59:13,323] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:59:19,947] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:59:26,757] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:59:33,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:59:39,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:59:46,310] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:59:52,843] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:59:59,614] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.699999170160889
[2022-12-06 17:59:59,614] [INFO] [runner_train_mujoco] Average state value: 0.4490408311486244
[2022-12-06 17:59:59,614] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 17:59:59,667] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.03522
[2022-12-06 17:59:59,710] [INFO] [controller] EPOCH 2 loss ppo:  -0.03740, loss val: 0.03538
[2022-12-06 17:59:59,754] [INFO] [controller] EPOCH 3 loss ppo:  -0.05373, loss val: 0.03582
[2022-12-06 17:59:59,790] [INFO] [controller] EPOCH 4 loss ppo:  -0.07063, loss val: 0.03604
[2022-12-06 17:59:59,800] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:59:59,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:59:59,969] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:00:07,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:00:13,540] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:00:20,020] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:00:26,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:00:32,567] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:00:39,223] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:00:45,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:00:51,965] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:00:58,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:01:05,356] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.514260093469645
[2022-12-06 18:01:05,356] [INFO] [runner_train_mujoco] Average state value: 0.40793253503243126
[2022-12-06 18:01:05,356] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 18:01:05,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.04104
[2022-12-06 18:01:05,461] [INFO] [controller] EPOCH 2 loss ppo:  -0.03286, loss val: 0.04277
[2022-12-06 18:01:05,503] [INFO] [controller] EPOCH 3 loss ppo:  -0.05345, loss val: 0.04221
[2022-12-06 18:01:05,548] [INFO] [controller] EPOCH 4 loss ppo:  -0.06888, loss val: 0.04256
[2022-12-06 18:01:05,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:01:05,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:01:05,739] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:01:12,785] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:01:19,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:01:25,794] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:01:32,143] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:01:38,382] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:01:46,342] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:01:53,446] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:02:00,013] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:02:06,376] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:02:13,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.796630690961086
[2022-12-06 18:02:13,375] [INFO] [runner_train_mujoco] Average state value: 0.3926252017517885
[2022-12-06 18:02:13,375] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 18:02:13,425] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04430
[2022-12-06 18:02:13,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.03251, loss val: 0.04282
[2022-12-06 18:02:13,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.04868, loss val: 0.04260
[2022-12-06 18:02:13,555] [INFO] [controller] EPOCH 4 loss ppo:  -0.06387, loss val: 0.04234
[2022-12-06 18:02:13,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:02:13,742] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:02:13,742] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:02:20,770] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:02:27,544] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:02:34,402] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:02:40,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:02:47,248] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:02:53,891] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:03:00,577] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:03:07,305] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:03:13,779] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:03:20,698] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.785298508657729
[2022-12-06 18:03:20,698] [INFO] [runner_train_mujoco] Average state value: 0.4014768800760309
[2022-12-06 18:03:20,698] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 18:03:20,749] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03715
[2022-12-06 18:03:20,790] [INFO] [controller] EPOCH 2 loss ppo:  -0.03061, loss val: 0.03850
[2022-12-06 18:03:20,835] [INFO] [controller] EPOCH 3 loss ppo:  -0.04594, loss val: 0.03659
[2022-12-06 18:03:20,880] [INFO] [controller] EPOCH 4 loss ppo:  -0.05872, loss val: 0.03662
[2022-12-06 18:03:20,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:03:21,090] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:03:21,090] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:03:28,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:03:35,044] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:03:41,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:03:48,367] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:03:54,975] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:04:01,711] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:04:08,764] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:04:15,483] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:04:22,440] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:04:30,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.542708501387994
[2022-12-06 18:04:30,066] [INFO] [runner_train_mujoco] Average state value: 0.41990651650230093
[2022-12-06 18:04:30,066] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 18:04:30,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.03643
[2022-12-06 18:04:30,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.03098, loss val: 0.03566
[2022-12-06 18:04:30,187] [INFO] [controller] EPOCH 3 loss ppo:  -0.04758, loss val: 0.03597
[2022-12-06 18:04:30,230] [INFO] [controller] EPOCH 4 loss ppo:  -0.05861, loss val: 0.03486
[2022-12-06 18:04:30,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:04:30,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:04:30,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:04:37,768] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:04:45,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:04:52,027] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:04:59,066] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:05:05,944] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:05:12,479] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:05:19,452] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:05:26,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:05:33,199] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:05:39,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.128978124216751
[2022-12-06 18:05:39,835] [INFO] [runner_train_mujoco] Average state value: 0.45240492879350985
[2022-12-06 18:05:39,835] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 18:05:39,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.04829
[2022-12-06 18:05:39,928] [INFO] [controller] EPOCH 2 loss ppo:  -0.02986, loss val: 0.04613
[2022-12-06 18:05:39,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.04601, loss val: 0.04406
[2022-12-06 18:05:40,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.05666, loss val: 0.04266
[2022-12-06 18:05:40,029] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:05:40,228] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:05:40,229] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:05:47,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:05:54,603] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:06:01,327] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:06:07,828] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:06:14,389] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:06:21,337] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:06:27,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:06:34,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:06:41,184] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:06:47,526] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.480931060929744
[2022-12-06 18:06:47,526] [INFO] [runner_train_mujoco] Average state value: 0.5033243616223335
[2022-12-06 18:06:47,526] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 18:06:47,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.06230
[2022-12-06 18:06:47,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.03113, loss val: 0.06393
[2022-12-06 18:06:47,659] [INFO] [controller] EPOCH 3 loss ppo:  -0.04298, loss val: 0.06427
[2022-12-06 18:06:47,699] [INFO] [controller] EPOCH 4 loss ppo:  -0.05630, loss val: 0.06613
[2022-12-06 18:06:47,709] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:06:47,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:06:47,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:06:54,716] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:07:01,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:07:13,077] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:07:21,713] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:07:28,427] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:07:35,574] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:07:41,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:07:48,485] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:07:55,113] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:08:01,482] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.041318916897512
[2022-12-06 18:08:01,482] [INFO] [runner_train_mujoco] Average state value: 0.5000119728843371
[2022-12-06 18:08:01,482] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 18:08:01,533] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.03114
[2022-12-06 18:08:01,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.03173, loss val: 0.03083
[2022-12-06 18:08:01,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.04730, loss val: 0.03078
[2022-12-06 18:08:01,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.05835, loss val: 0.03376
[2022-12-06 18:08:01,665] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:08:01,847] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:08:01,847] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:08:09,466] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:08:16,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:08:22,997] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:08:29,357] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:08:35,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:08:42,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:08:48,501] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:08:55,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:09:01,641] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:09:08,382] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.897925701531397
[2022-12-06 18:09:08,382] [INFO] [runner_train_mujoco] Average state value: 0.4768979440828165
[2022-12-06 18:09:08,382] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 18:09:08,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.03956
[2022-12-06 18:09:08,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.03122, loss val: 0.03957
[2022-12-06 18:09:08,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.04784, loss val: 0.04001
[2022-12-06 18:09:08,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.05932, loss val: 0.03772
[2022-12-06 18:09:08,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:09:08,766] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:09:08,766] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:09:15,550] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:09:23,195] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:09:29,941] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:09:36,408] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:09:42,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:09:49,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:09:55,774] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:10:03,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:10:09,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:10:16,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.326950540729499
[2022-12-06 18:10:16,912] [INFO] [runner_train_mujoco] Average state value: 0.466237142076095
[2022-12-06 18:10:16,912] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 18:10:16,962] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04926
[2022-12-06 18:10:17,001] [INFO] [controller] EPOCH 2 loss ppo:  -0.02934, loss val: 0.04828
[2022-12-06 18:10:17,040] [INFO] [controller] EPOCH 3 loss ppo:  -0.04569, loss val: 0.04765
[2022-12-06 18:10:17,078] [INFO] [controller] EPOCH 4 loss ppo:  -0.05730, loss val: 0.04759
[2022-12-06 18:10:17,087] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:10:17,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:10:17,299] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:10:24,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:10:31,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:10:38,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:10:45,752] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:10:52,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:10:58,990] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:11:05,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:11:12,289] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:11:19,085] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:11:26,499] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.587630790057325
[2022-12-06 18:11:26,499] [INFO] [runner_train_mujoco] Average state value: 0.4517748710314433
[2022-12-06 18:11:26,499] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 18:11:26,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.04558
[2022-12-06 18:11:26,587] [INFO] [controller] EPOCH 2 loss ppo:  -0.02996, loss val: 0.04462
[2022-12-06 18:11:26,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.04379, loss val: 0.04429
[2022-12-06 18:11:26,667] [INFO] [controller] EPOCH 4 loss ppo:  -0.05626, loss val: 0.04382
[2022-12-06 18:11:26,673] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:11:26,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:11:26,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:11:33,656] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:11:40,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:11:47,286] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:11:53,969] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:12:00,341] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:12:08,889] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:12:15,272] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:12:22,120] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:12:29,809] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:12:36,502] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.011645099252175
[2022-12-06 18:12:36,503] [INFO] [runner_train_mujoco] Average state value: 0.43793326236804325
[2022-12-06 18:12:36,503] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 18:12:36,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.03680
[2022-12-06 18:12:36,594] [INFO] [controller] EPOCH 2 loss ppo:  -0.02859, loss val: 0.03596
[2022-12-06 18:12:36,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.04229, loss val: 0.03696
[2022-12-06 18:12:36,682] [INFO] [controller] EPOCH 4 loss ppo:  -0.05226, loss val: 0.03790
[2022-12-06 18:12:36,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:12:36,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:12:36,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:12:44,576] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:12:51,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:12:57,481] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:13:04,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:13:10,512] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:13:16,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:13:23,368] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:13:29,739] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:13:36,187] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:13:42,719] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.945032917802766
[2022-12-06 18:13:42,719] [INFO] [runner_train_mujoco] Average state value: 0.40861763781557486
[2022-12-06 18:13:42,719] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 18:13:42,769] [INFO] [controller] EPOCH 1 loss ppo:  -0.01510, loss val: 0.07357
[2022-12-06 18:13:42,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.03020, loss val: 0.07302
[2022-12-06 18:13:42,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.04312, loss val: 0.07315
[2022-12-06 18:13:42,945] [INFO] [controller] EPOCH 4 loss ppo:  -0.05411, loss val: 0.07217
[2022-12-06 18:13:42,951] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:13:43,100] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:13:43,100] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:13:49,717] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:13:56,320] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:14:03,361] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:14:10,065] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:14:16,482] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:14:22,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:14:29,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:14:38,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:14:45,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:14:53,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.3093568941295946
[2022-12-06 18:14:53,092] [INFO] [runner_train_mujoco] Average state value: 0.4514789888262749
[2022-12-06 18:14:53,092] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 18:14:53,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04391
[2022-12-06 18:14:53,188] [INFO] [controller] EPOCH 2 loss ppo:  -0.02348, loss val: 0.04295
[2022-12-06 18:14:53,229] [INFO] [controller] EPOCH 3 loss ppo:  -0.03520, loss val: 0.04535
[2022-12-06 18:14:53,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.04642, loss val: 0.04309
[2022-12-06 18:14:53,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:14:53,436] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:14:53,436] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:15:00,208] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:15:07,010] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:15:13,494] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:15:20,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:15:30,170] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:15:36,616] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:15:43,236] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:15:49,978] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:15:56,925] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:16:03,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.6660542823949545
[2022-12-06 18:16:03,634] [INFO] [runner_train_mujoco] Average state value: 0.4585879257917404
[2022-12-06 18:16:03,635] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 18:16:03,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.03745
[2022-12-06 18:16:03,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.02654, loss val: 0.03729
[2022-12-06 18:16:03,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.04091, loss val: 0.03754
[2022-12-06 18:16:03,821] [INFO] [controller] EPOCH 4 loss ppo:  -0.05210, loss val: 0.03727
[2022-12-06 18:16:03,831] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:16:04,041] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:16:04,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:16:12,571] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:16:19,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:16:26,108] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:16:33,196] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:16:40,620] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:16:47,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:16:54,357] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:17:02,222] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:17:08,970] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:17:15,474] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.33988441946628
[2022-12-06 18:17:15,475] [INFO] [runner_train_mujoco] Average state value: 0.4353910019447406
[2022-12-06 18:17:15,475] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 18:17:15,526] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.05219
[2022-12-06 18:17:15,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.02278, loss val: 0.05174
[2022-12-06 18:17:15,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.03578, loss val: 0.05161
[2022-12-06 18:17:15,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.04645, loss val: 0.05107
[2022-12-06 18:17:15,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:17:15,856] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:17:15,857] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:17:22,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:17:29,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:17:36,476] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:17:43,502] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:17:52,987] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:18:00,273] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:18:07,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:18:16,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:18:24,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:18:31,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.385029256066844
[2022-12-06 18:18:31,846] [INFO] [runner_train_mujoco] Average state value: 0.4438331661472718
[2022-12-06 18:18:31,846] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 18:18:31,899] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04626
[2022-12-06 18:18:31,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.02090, loss val: 0.04265
[2022-12-06 18:18:31,992] [INFO] [controller] EPOCH 3 loss ppo:  -0.03193, loss val: 0.04235
[2022-12-06 18:18:32,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.04459, loss val: 0.04201
[2022-12-06 18:18:32,049] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:18:32,260] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:18:32,260] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:18:40,449] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:18:48,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:18:56,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:19:03,652] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:19:11,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:19:17,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:19:25,786] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:19:33,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:19:40,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:19:47,911] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.535937899680198
[2022-12-06 18:19:47,911] [INFO] [runner_train_mujoco] Average state value: 0.47051529808839165
[2022-12-06 18:19:47,912] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 18:19:47,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04093
[2022-12-06 18:19:48,011] [INFO] [controller] EPOCH 2 loss ppo:  -0.01924, loss val: 0.04041
[2022-12-06 18:19:48,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.02992, loss val: 0.03966
[2022-12-06 18:19:48,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.03973, loss val: 0.04226
[2022-12-06 18:19:48,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:19:48,316] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:19:48,317] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:19:55,564] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:20:03,249] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:20:10,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:20:17,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:20:24,801] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:20:32,321] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:20:39,979] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:20:47,287] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:20:54,491] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:21:01,821] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.693570421104205
[2022-12-06 18:21:01,821] [INFO] [runner_train_mujoco] Average state value: 0.47434210621317224
[2022-12-06 18:21:01,821] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 18:21:01,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04474
[2022-12-06 18:21:01,923] [INFO] [controller] EPOCH 2 loss ppo:  -0.01922, loss val: 0.04283
[2022-12-06 18:21:01,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.02750, loss val: 0.04375
[2022-12-06 18:21:02,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.03493, loss val: 0.04233
[2022-12-06 18:21:02,029] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:21:02,252] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:21:02,252] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:21:09,869] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:21:17,684] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:21:26,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:21:33,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:21:41,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:21:49,289] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:21:57,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:22:05,091] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:22:12,957] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:22:20,657] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.892219922921548
[2022-12-06 18:22:20,657] [INFO] [runner_train_mujoco] Average state value: 0.4682049596905708
[2022-12-06 18:22:20,657] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 18:22:20,715] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.03779
[2022-12-06 18:22:20,768] [INFO] [controller] EPOCH 2 loss ppo:  -0.01818, loss val: 0.03907
[2022-12-06 18:22:20,818] [INFO] [controller] EPOCH 3 loss ppo:  -0.02581, loss val: 0.04054
[2022-12-06 18:22:20,868] [INFO] [controller] EPOCH 4 loss ppo:  -0.03552, loss val: 0.03767
[2022-12-06 18:22:20,876] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:22:21,084] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:22:21,085] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:22:29,006] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:22:38,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:22:46,723] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:22:54,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:23:05,114] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:23:15,497] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:23:24,827] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:23:35,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:23:44,383] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:23:52,467] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.04008076115034
[2022-12-06 18:23:52,467] [INFO] [runner_train_mujoco] Average state value: 0.4649772339264552
[2022-12-06 18:23:52,468] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 18:23:52,522] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.03607
[2022-12-06 18:23:52,573] [INFO] [controller] EPOCH 2 loss ppo:  -0.01824, loss val: 0.03534
[2022-12-06 18:23:52,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.02573, loss val: 0.03768
[2022-12-06 18:23:52,676] [INFO] [controller] EPOCH 4 loss ppo:  -0.03374, loss val: 0.03825
[2022-12-06 18:23:52,687] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:23:52,922] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:23:52,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:24:01,528] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:24:09,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:24:19,956] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:24:28,350] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:24:36,352] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:24:43,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:24:52,650] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:25:00,437] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:25:08,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:25:16,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.099600953794218
[2022-12-06 18:25:16,116] [INFO] [runner_train_mujoco] Average state value: 0.4160729270242155
[2022-12-06 18:25:16,116] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 18:25:16,185] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.07203
[2022-12-06 18:25:16,239] [INFO] [controller] EPOCH 2 loss ppo:  -0.01733, loss val: 0.07214
[2022-12-06 18:25:16,292] [INFO] [controller] EPOCH 3 loss ppo:  -0.02242, loss val: 0.07206
[2022-12-06 18:25:16,360] [INFO] [controller] EPOCH 4 loss ppo:  -0.02882, loss val: 0.07188
[2022-12-06 18:25:16,368] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:25:16,611] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:25:16,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:25:25,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:25:33,349] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:25:41,232] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:25:48,984] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:25:56,537] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:26:04,044] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:26:11,751] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:26:19,799] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:26:27,897] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:26:35,293] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.707239225487271
[2022-12-06 18:26:35,293] [INFO] [runner_train_mujoco] Average state value: 0.4390750823915005
[2022-12-06 18:26:35,294] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 18:26:35,362] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.05428
[2022-12-06 18:26:35,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.01547, loss val: 0.05342
[2022-12-06 18:26:35,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.01789, loss val: 0.05205
[2022-12-06 18:26:35,555] [INFO] [controller] EPOCH 4 loss ppo:  -0.02106, loss val: 0.05191
[2022-12-06 18:26:35,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:26:35,698] [INFO] [optimize] Finished learning.
