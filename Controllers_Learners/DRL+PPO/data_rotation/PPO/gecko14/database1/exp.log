[2022-12-06 14:36:15,806] [INFO] [optimize] Starting learning
[2022-12-06 14:36:15,842] [INFO] [optimize] Starting learning process..
[2022-12-06 14:36:16,037] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:36:16,038] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:36:30,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:36:42,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:36:53,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:37:05,257] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:37:17,813] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:37:29,352] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:37:40,425] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:37:52,381] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:38:03,890] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:38:18,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5802032987338607
[2022-12-06 14:38:18,478] [INFO] [runner_train_mujoco] Average state value: 0.22056950471550224
[2022-12-06 14:38:18,478] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 14:38:18,604] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.26089
[2022-12-06 14:38:18,695] [INFO] [controller] EPOCH 2 loss ppo:  -0.04985, loss val: 0.23974
[2022-12-06 14:38:18,780] [INFO] [controller] EPOCH 3 loss ppo:  -0.06835, loss val: 0.21280
[2022-12-06 14:38:18,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.07836, loss val: 0.19347
[2022-12-06 14:38:18,872] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:38:19,116] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:38:19,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:38:31,524] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:38:43,619] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:38:54,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:39:05,854] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:39:18,199] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:39:30,781] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:39:43,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:39:55,857] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:40:08,481] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:40:21,162] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6589735594829333
[2022-12-06 14:40:21,162] [INFO] [runner_train_mujoco] Average state value: 0.38323965257778764
[2022-12-06 14:40:21,162] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 14:40:21,252] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.20349
[2022-12-06 14:40:21,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.04709, loss val: 0.18315
[2022-12-06 14:40:21,400] [INFO] [controller] EPOCH 3 loss ppo:  -0.06485, loss val: 0.16274
[2022-12-06 14:40:21,459] [INFO] [controller] EPOCH 4 loss ppo:  -0.07867, loss val: 0.15223
[2022-12-06 14:40:21,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:40:21,801] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:40:21,802] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:40:34,480] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:40:47,515] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:41:01,536] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:41:15,553] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:41:27,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:41:40,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:41:52,486] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:42:05,060] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:42:17,578] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:42:30,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4869245575197745
[2022-12-06 14:42:30,238] [INFO] [runner_train_mujoco] Average state value: 0.5173444119362781
[2022-12-06 14:42:30,238] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 14:42:30,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01109, loss val: 0.13824
[2022-12-06 14:42:30,658] [INFO] [controller] EPOCH 2 loss ppo:  -0.04270, loss val: 0.12967
[2022-12-06 14:42:30,740] [INFO] [controller] EPOCH 3 loss ppo:  -0.06076, loss val: 0.12296
[2022-12-06 14:42:30,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.07235, loss val: 0.11823
[2022-12-06 14:42:30,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:42:31,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:42:31,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:42:43,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:42:56,481] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:43:09,407] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:43:24,018] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:43:35,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:43:46,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:43:58,999] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:44:10,514] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:44:21,481] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:44:32,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5580042262404287
[2022-12-06 14:44:32,782] [INFO] [runner_train_mujoco] Average state value: 0.5759181880323838
[2022-12-06 14:44:32,782] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 14:44:32,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01217, loss val: 0.12025
[2022-12-06 14:44:32,946] [INFO] [controller] EPOCH 2 loss ppo:  -0.03998, loss val: 0.11064
[2022-12-06 14:44:33,024] [INFO] [controller] EPOCH 3 loss ppo:  -0.06410, loss val: 0.10336
[2022-12-06 14:44:33,095] [INFO] [controller] EPOCH 4 loss ppo:  -0.07698, loss val: 0.09672
[2022-12-06 14:44:33,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:44:33,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:44:33,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:44:45,379] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:44:57,208] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:45:09,990] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:45:23,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:45:35,730] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:45:47,319] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:45:59,705] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:46:12,478] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:46:24,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:46:37,761] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41037967814566406
[2022-12-06 14:46:37,761] [INFO] [runner_train_mujoco] Average state value: 0.5225118634216488
[2022-12-06 14:46:37,762] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 14:46:37,838] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.09757
[2022-12-06 14:46:37,904] [INFO] [controller] EPOCH 2 loss ppo:  -0.04825, loss val: 0.09448
[2022-12-06 14:46:37,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.06581, loss val: 0.09065
[2022-12-06 14:46:38,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.07651, loss val: 0.08587
[2022-12-06 14:46:38,060] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:46:38,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:46:38,362] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:46:50,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:47:03,907] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:47:16,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:47:30,030] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:47:42,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:47:55,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:48:08,352] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:48:20,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:48:32,654] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:48:44,347] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6304501048942625
[2022-12-06 14:48:44,347] [INFO] [runner_train_mujoco] Average state value: 0.5368402286594113
[2022-12-06 14:48:44,347] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 14:48:44,431] [INFO] [controller] EPOCH 1 loss ppo:  -0.01157, loss val: 0.09301
[2022-12-06 14:48:44,486] [INFO] [controller] EPOCH 2 loss ppo:  -0.04589, loss val: 0.08985
[2022-12-06 14:48:44,554] [INFO] [controller] EPOCH 3 loss ppo:  -0.06304, loss val: 0.08610
[2022-12-06 14:48:44,609] [INFO] [controller] EPOCH 4 loss ppo:  -0.07363, loss val: 0.08461
[2022-12-06 14:48:44,625] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:48:44,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:48:44,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:48:57,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:49:09,053] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:49:21,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:49:34,146] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:49:45,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:49:56,767] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:50:07,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:50:18,951] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:50:30,020] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:50:41,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6320256832403115
[2022-12-06 14:50:41,072] [INFO] [runner_train_mujoco] Average state value: 0.5744998688399792
[2022-12-06 14:50:41,072] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 14:50:41,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.07582
[2022-12-06 14:50:41,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.04187, loss val: 0.07159
[2022-12-06 14:50:41,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.05833, loss val: 0.06964
[2022-12-06 14:50:41,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.07034, loss val: 0.06727
[2022-12-06 14:50:41,464] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:50:41,743] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:50:41,744] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:50:53,993] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:51:05,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:51:17,222] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:51:28,752] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:51:39,703] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:51:50,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:52:02,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:52:14,498] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:52:25,583] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:52:37,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.584586238642878
[2022-12-06 14:52:37,718] [INFO] [runner_train_mujoco] Average state value: 0.5810534136587133
[2022-12-06 14:52:37,718] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 14:52:37,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.00971, loss val: 0.07082
[2022-12-06 14:52:37,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.03643, loss val: 0.06857
[2022-12-06 14:52:37,926] [INFO] [controller] EPOCH 3 loss ppo:  -0.05625, loss val: 0.06571
[2022-12-06 14:52:37,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.06888, loss val: 0.06434
[2022-12-06 14:52:38,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:52:38,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:52:38,287] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:52:50,058] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:53:01,679] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:53:13,821] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:53:28,548] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:53:41,213] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:53:53,029] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:54:05,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:54:16,962] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:54:30,628] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:54:43,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5919358334052264
[2022-12-06 14:54:43,055] [INFO] [runner_train_mujoco] Average state value: 0.5329236309627692
[2022-12-06 14:54:43,056] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 14:54:43,264] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.06124
[2022-12-06 14:54:43,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.04063, loss val: 0.05897
[2022-12-06 14:54:43,384] [INFO] [controller] EPOCH 3 loss ppo:  -0.06006, loss val: 0.05824
[2022-12-06 14:54:43,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.07405, loss val: 0.05124
[2022-12-06 14:54:43,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:54:43,715] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:54:43,716] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:54:56,401] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:55:08,837] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:55:21,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:55:32,296] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:55:42,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:55:51,687] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:56:01,121] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:56:11,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:56:20,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:56:30,487] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7167844897207982
[2022-12-06 14:56:30,487] [INFO] [runner_train_mujoco] Average state value: 0.4897827297734717
[2022-12-06 14:56:30,487] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 14:56:30,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01140, loss val: 0.06178
[2022-12-06 14:56:30,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.04239, loss val: 0.05969
[2022-12-06 14:56:30,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.05878, loss val: 0.05869
[2022-12-06 14:56:30,712] [INFO] [controller] EPOCH 4 loss ppo:  -0.07125, loss val: 0.05773
[2022-12-06 14:56:30,724] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:56:30,962] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:56:30,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:56:40,649] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:56:50,519] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:56:59,831] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:57:09,639] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:57:19,632] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:57:28,245] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:57:36,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:57:44,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:57:51,951] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:57:59,407] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7664767068269425
[2022-12-06 14:57:59,407] [INFO] [runner_train_mujoco] Average state value: 0.4854764174794157
[2022-12-06 14:57:59,408] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 14:57:59,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.05544
[2022-12-06 14:57:59,503] [INFO] [controller] EPOCH 2 loss ppo:  -0.04358, loss val: 0.05243
[2022-12-06 14:57:59,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.06104, loss val: 0.05204
[2022-12-06 14:57:59,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.07382, loss val: 0.04931
[2022-12-06 14:57:59,598] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:57:59,812] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:57:59,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:58:07,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:58:16,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:58:24,504] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:58:32,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:58:40,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:58:48,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:58:56,640] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:59:04,697] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:59:12,711] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:59:20,940] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8276758558140707
[2022-12-06 14:59:20,940] [INFO] [runner_train_mujoco] Average state value: 0.525269942075014
[2022-12-06 14:59:20,940] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 14:59:20,995] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.05914
[2022-12-06 14:59:21,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.03912, loss val: 0.05479
[2022-12-06 14:59:21,093] [INFO] [controller] EPOCH 3 loss ppo:  -0.05744, loss val: 0.05153
[2022-12-06 14:59:21,141] [INFO] [controller] EPOCH 4 loss ppo:  -0.07119, loss val: 0.04909
[2022-12-06 14:59:21,152] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:59:21,378] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:59:21,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:59:29,716] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:59:38,180] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:59:46,579] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:59:56,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:00:04,739] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:00:12,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:00:21,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:00:28,769] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:00:36,557] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:00:44,845] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.721157311247784
[2022-12-06 15:00:44,845] [INFO] [runner_train_mujoco] Average state value: 0.6209715684652329
[2022-12-06 15:00:44,845] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 15:00:44,898] [INFO] [controller] EPOCH 1 loss ppo:  -0.01130, loss val: 0.08473
[2022-12-06 15:00:44,948] [INFO] [controller] EPOCH 2 loss ppo:  -0.02901, loss val: 0.09029
[2022-12-06 15:00:44,998] [INFO] [controller] EPOCH 3 loss ppo:  -0.04317, loss val: 0.07834
[2022-12-06 15:00:45,043] [INFO] [controller] EPOCH 4 loss ppo:  -0.05813, loss val: 0.07919
[2022-12-06 15:00:45,053] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:00:45,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:00:45,242] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:00:52,997] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:01:02,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:01:12,016] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:01:23,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:01:31,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:01:38,763] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:01:46,407] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:01:53,621] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:02:02,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:02:15,202] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8185057731893769
[2022-12-06 15:02:15,202] [INFO] [runner_train_mujoco] Average state value: 0.6011517483790716
[2022-12-06 15:02:15,202] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 15:02:15,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.05896
[2022-12-06 15:02:15,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.04007, loss val: 0.05079
[2022-12-06 15:02:15,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.05903, loss val: 0.04512
[2022-12-06 15:02:15,525] [INFO] [controller] EPOCH 4 loss ppo:  -0.07404, loss val: 0.04180
[2022-12-06 15:02:15,537] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:02:15,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:02:15,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:02:24,209] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:02:32,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:02:41,043] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:02:49,091] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:02:57,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:03:05,137] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:03:12,900] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:03:20,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:03:28,227] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:03:35,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0863284027184443
[2022-12-06 15:03:35,660] [INFO] [runner_train_mujoco] Average state value: 0.48916747938593225
[2022-12-06 15:03:35,660] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 15:03:35,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.04996
[2022-12-06 15:03:35,762] [INFO] [controller] EPOCH 2 loss ppo:  -0.04996, loss val: 0.04800
[2022-12-06 15:03:35,805] [INFO] [controller] EPOCH 3 loss ppo:  -0.07012, loss val: 0.04924
[2022-12-06 15:03:35,853] [INFO] [controller] EPOCH 4 loss ppo:  -0.08131, loss val: 0.04883
[2022-12-06 15:03:35,863] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:03:36,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:03:36,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:03:44,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:03:52,785] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:04:01,086] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:04:09,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:04:19,633] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:04:27,082] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:04:34,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:04:40,955] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:04:49,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:04:58,129] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2960971167473088
[2022-12-06 15:04:58,129] [INFO] [runner_train_mujoco] Average state value: 0.41421245465924345
[2022-12-06 15:04:58,130] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 15:04:58,261] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.07395
[2022-12-06 15:04:58,360] [INFO] [controller] EPOCH 2 loss ppo:  -0.03324, loss val: 0.07715
[2022-12-06 15:04:58,426] [INFO] [controller] EPOCH 3 loss ppo:  -0.04756, loss val: 0.06700
[2022-12-06 15:04:58,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.05941, loss val: 0.06398
[2022-12-06 15:04:58,498] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:04:58,770] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:04:58,771] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:05:07,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:05:16,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:05:23,461] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:05:30,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:05:38,197] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:05:45,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:05:54,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:06:03,427] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:06:10,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:06:18,086] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5269449915723967
[2022-12-06 15:06:18,086] [INFO] [runner_train_mujoco] Average state value: 0.4564554079969724
[2022-12-06 15:06:18,087] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 15:06:18,148] [INFO] [controller] EPOCH 1 loss ppo:  -0.01452, loss val: 0.05870
[2022-12-06 15:06:18,192] [INFO] [controller] EPOCH 2 loss ppo:  -0.04028, loss val: 0.04763
[2022-12-06 15:06:18,229] [INFO] [controller] EPOCH 3 loss ppo:  -0.05955, loss val: 0.04912
[2022-12-06 15:06:18,274] [INFO] [controller] EPOCH 4 loss ppo:  -0.07456, loss val: 0.04771
[2022-12-06 15:06:18,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:06:18,499] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:06:18,499] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:06:25,905] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:06:34,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:06:42,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:06:51,214] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:06:58,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:07:06,852] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:07:14,197] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:07:21,411] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:07:28,295] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:07:35,322] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.646296669006621
[2022-12-06 15:07:35,322] [INFO] [runner_train_mujoco] Average state value: 0.5524667657812437
[2022-12-06 15:07:35,322] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 15:07:35,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04332
[2022-12-06 15:07:35,423] [INFO] [controller] EPOCH 2 loss ppo:  -0.04256, loss val: 0.04454
[2022-12-06 15:07:35,471] [INFO] [controller] EPOCH 3 loss ppo:  -0.05908, loss val: 0.04538
[2022-12-06 15:07:35,519] [INFO] [controller] EPOCH 4 loss ppo:  -0.07145, loss val: 0.05011
[2022-12-06 15:07:35,526] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:07:35,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:07:35,726] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:07:42,609] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:07:49,757] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:07:56,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:08:03,712] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:08:10,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:08:18,088] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:08:25,893] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:08:33,194] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:08:40,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:08:48,113] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.456491608951141
[2022-12-06 15:08:48,113] [INFO] [runner_train_mujoco] Average state value: 0.5747721857726574
[2022-12-06 15:08:48,113] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 15:08:48,171] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04177
[2022-12-06 15:08:48,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.04074, loss val: 0.04053
[2022-12-06 15:08:48,257] [INFO] [controller] EPOCH 3 loss ppo:  -0.05806, loss val: 0.04088
[2022-12-06 15:08:48,305] [INFO] [controller] EPOCH 4 loss ppo:  -0.07043, loss val: 0.04052
[2022-12-06 15:08:48,316] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:08:48,533] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:08:48,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:08:55,580] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:09:04,165] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:09:11,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:09:18,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:09:26,055] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:09:33,165] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:09:40,078] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:09:46,891] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:09:55,578] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:10:05,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1900011321222026
[2022-12-06 15:10:05,404] [INFO] [runner_train_mujoco] Average state value: 0.5732883424262207
[2022-12-06 15:10:05,405] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 15:10:05,465] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.04534
[2022-12-06 15:10:05,521] [INFO] [controller] EPOCH 2 loss ppo:  -0.04213, loss val: 0.04481
[2022-12-06 15:10:05,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.05808, loss val: 0.04425
[2022-12-06 15:10:05,639] [INFO] [controller] EPOCH 4 loss ppo:  -0.07043, loss val: 0.04429
[2022-12-06 15:10:05,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:10:05,878] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:10:05,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:10:12,999] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:10:22,165] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:10:29,762] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:10:37,496] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:10:45,007] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:10:52,437] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:10:59,942] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:11:07,470] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:11:14,751] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:11:22,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4104548719143946
[2022-12-06 15:11:22,381] [INFO] [runner_train_mujoco] Average state value: 0.572808089474837
[2022-12-06 15:11:22,381] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 15:11:22,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.05486
[2022-12-06 15:11:22,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.04300, loss val: 0.05393
[2022-12-06 15:11:22,511] [INFO] [controller] EPOCH 3 loss ppo:  -0.06104, loss val: 0.05210
[2022-12-06 15:11:22,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.07590, loss val: 0.05014
[2022-12-06 15:11:22,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:11:22,786] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:11:22,787] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:11:33,296] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:11:41,476] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:11:48,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:11:56,124] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:12:03,549] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:12:13,015] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:12:22,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:12:31,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:12:40,691] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:12:49,959] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.666169357175767
[2022-12-06 15:12:49,959] [INFO] [runner_train_mujoco] Average state value: 0.5393439533909163
[2022-12-06 15:12:49,959] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 15:12:50,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.01607, loss val: 0.04679
[2022-12-06 15:12:50,060] [INFO] [controller] EPOCH 2 loss ppo:  -0.04219, loss val: 0.04603
[2022-12-06 15:12:50,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.06207, loss val: 0.04400
[2022-12-06 15:12:50,162] [INFO] [controller] EPOCH 4 loss ppo:  -0.07525, loss val: 0.04472
[2022-12-06 15:12:50,174] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:12:50,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:12:50,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:12:58,769] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:13:06,781] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:13:15,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:13:23,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:13:31,381] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:13:39,086] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:13:46,629] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:13:54,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:14:02,088] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:14:09,863] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9290716359140236
[2022-12-06 15:14:09,864] [INFO] [runner_train_mujoco] Average state value: 0.47350517863035196
[2022-12-06 15:14:09,864] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 15:14:09,917] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.05234
[2022-12-06 15:14:09,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.03770, loss val: 0.05372
[2022-12-06 15:14:10,000] [INFO] [controller] EPOCH 3 loss ppo:  -0.05581, loss val: 0.05414
[2022-12-06 15:14:10,035] [INFO] [controller] EPOCH 4 loss ppo:  -0.07470, loss val: 0.05297
[2022-12-06 15:14:10,042] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:14:10,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:14:10,247] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:14:18,414] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:14:26,392] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:14:34,284] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:14:43,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:14:51,705] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:15:00,905] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:15:09,641] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:15:19,849] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:15:30,591] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:15:38,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.952241440936329
[2022-12-06 15:15:38,367] [INFO] [runner_train_mujoco] Average state value: 0.4551638439297676
[2022-12-06 15:15:38,367] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 15:15:38,417] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.05296
[2022-12-06 15:15:38,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.03566, loss val: 0.05247
[2022-12-06 15:15:38,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.05373, loss val: 0.05268
[2022-12-06 15:15:38,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.07152, loss val: 0.05227
[2022-12-06 15:15:38,563] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:15:38,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:15:38,772] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:15:46,999] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:15:55,039] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:16:03,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:16:11,245] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:16:18,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:16:29,257] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:16:41,875] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:16:50,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:16:57,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:17:05,015] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.294057643459574
[2022-12-06 15:17:05,015] [INFO] [runner_train_mujoco] Average state value: 0.4616013648410638
[2022-12-06 15:17:05,015] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 15:17:05,068] [INFO] [controller] EPOCH 1 loss ppo:  -0.01608, loss val: 0.03507
[2022-12-06 15:17:05,113] [INFO] [controller] EPOCH 2 loss ppo:  -0.04417, loss val: 0.03663
[2022-12-06 15:17:05,161] [INFO] [controller] EPOCH 3 loss ppo:  -0.05646, loss val: 0.03448
[2022-12-06 15:17:05,208] [INFO] [controller] EPOCH 4 loss ppo:  -0.07146, loss val: 0.03612
[2022-12-06 15:17:05,218] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:17:05,485] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:17:05,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:17:13,244] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:17:20,412] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:17:28,147] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:17:35,412] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:17:42,369] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:17:49,319] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:17:56,947] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:18:04,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:18:11,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:18:18,662] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.530500182917213
[2022-12-06 15:18:18,662] [INFO] [runner_train_mujoco] Average state value: 0.46198881040016804
[2022-12-06 15:18:18,662] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 15:18:18,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.05191
[2022-12-06 15:18:18,751] [INFO] [controller] EPOCH 2 loss ppo:  -0.04248, loss val: 0.05067
[2022-12-06 15:18:18,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.06106, loss val: 0.05153
[2022-12-06 15:18:18,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.07546, loss val: 0.05126
[2022-12-06 15:18:18,852] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:18:19,043] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:18:19,043] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:18:26,055] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:18:32,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:18:40,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:18:47,904] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:18:56,090] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:19:03,514] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:19:11,208] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:19:18,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:19:25,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:19:32,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2817438483367596
[2022-12-06 15:19:32,110] [INFO] [runner_train_mujoco] Average state value: 0.4729236195087433
[2022-12-06 15:19:32,110] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 15:19:32,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.04708
[2022-12-06 15:19:32,204] [INFO] [controller] EPOCH 2 loss ppo:  -0.03752, loss val: 0.04753
[2022-12-06 15:19:32,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.05157, loss val: 0.04907
[2022-12-06 15:19:32,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.07140, loss val: 0.04808
[2022-12-06 15:19:32,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:19:32,501] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:19:32,501] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:19:39,098] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:19:46,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:19:53,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:20:00,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:20:08,913] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:20:16,340] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:20:22,907] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:20:30,000] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:20:36,412] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:20:42,928] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0182575266117055
[2022-12-06 15:20:42,928] [INFO] [runner_train_mujoco] Average state value: 0.46714863028128945
[2022-12-06 15:20:42,928] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 15:20:42,976] [INFO] [controller] EPOCH 1 loss ppo:  -0.01656, loss val: 0.04191
[2022-12-06 15:20:43,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.03836, loss val: 0.04090
[2022-12-06 15:20:43,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.05353, loss val: 0.03921
[2022-12-06 15:20:43,090] [INFO] [controller] EPOCH 4 loss ppo:  -0.06958, loss val: 0.03785
[2022-12-06 15:20:43,097] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:20:43,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:20:43,287] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:20:52,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:20:58,709] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:21:05,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:21:13,431] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:21:20,025] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:21:27,090] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:21:33,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:21:41,249] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:21:47,750] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:21:54,357] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.017535006614157
[2022-12-06 15:21:54,358] [INFO] [runner_train_mujoco] Average state value: 0.4127523938516776
[2022-12-06 15:21:54,358] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 15:21:54,402] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.05867
[2022-12-06 15:21:54,440] [INFO] [controller] EPOCH 2 loss ppo:  -0.03372, loss val: 0.05928
[2022-12-06 15:21:54,481] [INFO] [controller] EPOCH 3 loss ppo:  -0.04877, loss val: 0.05890
[2022-12-06 15:21:54,519] [INFO] [controller] EPOCH 4 loss ppo:  -0.06454, loss val: 0.05955
[2022-12-06 15:21:54,525] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:21:54,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:21:54,731] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:22:03,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:22:11,221] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:22:19,857] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:22:27,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:22:34,422] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:22:42,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:22:51,620] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:22:58,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:23:05,291] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:23:11,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.055495814142274
[2022-12-06 15:23:11,996] [INFO] [runner_train_mujoco] Average state value: 0.40882396910587937
[2022-12-06 15:23:11,997] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 15:23:12,045] [INFO] [controller] EPOCH 1 loss ppo:  -0.01594, loss val: 0.04567
[2022-12-06 15:23:12,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.03801, loss val: 0.04625
[2022-12-06 15:23:12,132] [INFO] [controller] EPOCH 3 loss ppo:  -0.05879, loss val: 0.04503
[2022-12-06 15:23:12,174] [INFO] [controller] EPOCH 4 loss ppo:  -0.07408, loss val: 0.04449
[2022-12-06 15:23:12,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:23:12,366] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:23:12,366] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:23:19,116] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:23:26,050] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:23:36,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:23:43,148] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:23:50,048] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:23:56,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:24:03,867] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:24:11,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:24:18,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:24:26,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.331425671357358
[2022-12-06 15:24:26,971] [INFO] [runner_train_mujoco] Average state value: 0.44383128211895634
[2022-12-06 15:24:26,971] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 15:24:27,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01574, loss val: 0.05198
[2022-12-06 15:24:27,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.04046, loss val: 0.05048
[2022-12-06 15:24:27,191] [INFO] [controller] EPOCH 3 loss ppo:  -0.05221, loss val: 0.05043
[2022-12-06 15:24:27,246] [INFO] [controller] EPOCH 4 loss ppo:  -0.06612, loss val: 0.04986
[2022-12-06 15:24:27,257] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:24:27,489] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:24:27,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:24:35,319] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:24:42,609] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:24:49,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:24:59,038] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:25:07,117] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:25:14,472] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:25:22,184] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:25:29,433] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:25:36,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:25:45,036] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.047059041909963
[2022-12-06 15:25:45,036] [INFO] [runner_train_mujoco] Average state value: 0.4701417276859283
[2022-12-06 15:25:45,036] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 15:25:45,087] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.05061
[2022-12-06 15:25:45,133] [INFO] [controller] EPOCH 2 loss ppo:  -0.03430, loss val: 0.05061
[2022-12-06 15:25:45,177] [INFO] [controller] EPOCH 3 loss ppo:  -0.04959, loss val: 0.05047
[2022-12-06 15:25:45,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.06564, loss val: 0.05019
[2022-12-06 15:25:45,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:25:45,436] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:25:45,436] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:25:52,584] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:25:59,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:26:07,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:26:14,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:26:22,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:26:30,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:26:38,503] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:26:45,971] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:26:53,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:27:01,199] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.413929564664957
[2022-12-06 15:27:01,199] [INFO] [runner_train_mujoco] Average state value: 0.48833283519744874
[2022-12-06 15:27:01,199] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 15:27:01,264] [INFO] [controller] EPOCH 1 loss ppo:  -0.01682, loss val: 0.04200
[2022-12-06 15:27:01,316] [INFO] [controller] EPOCH 2 loss ppo:  -0.03694, loss val: 0.04260
[2022-12-06 15:27:01,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.05143, loss val: 0.04261
[2022-12-06 15:27:01,429] [INFO] [controller] EPOCH 4 loss ppo:  -0.06335, loss val: 0.04228
[2022-12-06 15:27:01,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:27:01,669] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:27:01,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:27:08,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:27:16,055] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:27:23,308] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:27:30,190] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:27:38,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:27:46,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:27:53,639] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:28:00,901] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:28:07,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:28:14,788] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5418519450808255
[2022-12-06 15:28:14,789] [INFO] [runner_train_mujoco] Average state value: 0.5114071734944979
[2022-12-06 15:28:14,789] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 15:28:14,834] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.05381
[2022-12-06 15:28:14,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.03337, loss val: 0.05191
[2022-12-06 15:28:14,920] [INFO] [controller] EPOCH 3 loss ppo:  -0.04754, loss val: 0.05280
[2022-12-06 15:28:14,963] [INFO] [controller] EPOCH 4 loss ppo:  -0.06350, loss val: 0.05201
[2022-12-06 15:28:14,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:28:15,181] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:28:15,181] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:28:22,597] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:28:29,663] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:28:37,571] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:28:44,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:28:51,965] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:28:58,674] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:29:05,502] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:29:12,083] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:29:19,262] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:29:27,891] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.881008853504619
[2022-12-06 15:29:27,891] [INFO] [runner_train_mujoco] Average state value: 0.4983023796776931
[2022-12-06 15:29:27,891] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 15:29:27,982] [INFO] [controller] EPOCH 1 loss ppo:  -0.01582, loss val: 0.03990
[2022-12-06 15:29:28,050] [INFO] [controller] EPOCH 2 loss ppo:  -0.03126, loss val: 0.03974
[2022-12-06 15:29:28,112] [INFO] [controller] EPOCH 3 loss ppo:  -0.04419, loss val: 0.04083
[2022-12-06 15:29:28,177] [INFO] [controller] EPOCH 4 loss ppo:  -0.06063, loss val: 0.04049
[2022-12-06 15:29:28,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:29:28,437] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:29:28,437] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:29:35,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:29:46,164] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:29:54,416] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:30:01,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:30:11,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:30:22,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:30:29,155] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:30:37,225] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:30:44,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:30:51,636] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.181914676436201
[2022-12-06 15:30:51,636] [INFO] [runner_train_mujoco] Average state value: 0.4797746072808902
[2022-12-06 15:30:51,636] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 15:30:51,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04420
[2022-12-06 15:30:51,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.03058, loss val: 0.04681
[2022-12-06 15:30:51,759] [INFO] [controller] EPOCH 3 loss ppo:  -0.04616, loss val: 0.04413
[2022-12-06 15:30:51,796] [INFO] [controller] EPOCH 4 loss ppo:  -0.06093, loss val: 0.04732
[2022-12-06 15:30:51,803] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:30:52,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:30:52,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:31:00,080] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:31:07,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:31:14,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:31:21,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:31:31,719] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:31:40,784] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:31:48,442] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:31:57,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:32:05,893] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:32:15,709] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.779652574656209
[2022-12-06 15:32:15,709] [INFO] [runner_train_mujoco] Average state value: 0.472633657236894
[2022-12-06 15:32:15,709] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 15:32:15,777] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.05287
[2022-12-06 15:32:15,825] [INFO] [controller] EPOCH 2 loss ppo:  -0.03439, loss val: 0.05350
[2022-12-06 15:32:15,896] [INFO] [controller] EPOCH 3 loss ppo:  -0.04853, loss val: 0.05265
[2022-12-06 15:32:15,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.05969, loss val: 0.05203
[2022-12-06 15:32:15,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:32:16,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:32:16,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:32:27,514] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:32:34,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:32:42,429] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:32:50,121] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:32:58,368] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:33:07,565] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:33:16,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:33:24,621] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:33:33,854] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:33:42,645] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5938859261904055
[2022-12-06 15:33:42,645] [INFO] [runner_train_mujoco] Average state value: 0.45855787038803103
[2022-12-06 15:33:42,645] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 15:33:42,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04357
[2022-12-06 15:33:42,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.03390, loss val: 0.04475
[2022-12-06 15:33:42,833] [INFO] [controller] EPOCH 3 loss ppo:  -0.04995, loss val: 0.04470
[2022-12-06 15:33:42,886] [INFO] [controller] EPOCH 4 loss ppo:  -0.06669, loss val: 0.04452
[2022-12-06 15:33:42,897] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:33:43,143] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:33:43,143] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:33:59,797] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:34:07,748] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:34:17,166] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:34:26,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:34:35,031] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:34:46,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:34:57,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:35:04,838] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:35:15,031] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:35:26,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.055002025785933
[2022-12-06 15:35:26,640] [INFO] [runner_train_mujoco] Average state value: 0.462173163463672
[2022-12-06 15:35:26,640] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 15:35:26,711] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04705
[2022-12-06 15:35:26,784] [INFO] [controller] EPOCH 2 loss ppo:  -0.03037, loss val: 0.04767
[2022-12-06 15:35:26,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.04614, loss val: 0.04740
[2022-12-06 15:35:26,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.05981, loss val: 0.04656
[2022-12-06 15:35:26,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:35:27,254] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:35:27,254] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:35:37,447] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:35:49,032] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:35:59,032] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:36:07,830] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:36:16,782] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:36:26,446] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:36:35,488] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:36:45,337] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:36:54,926] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:37:03,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.701512684614351
[2022-12-06 15:37:03,545] [INFO] [runner_train_mujoco] Average state value: 0.4541815222303073
[2022-12-06 15:37:03,545] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 15:37:03,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.01647, loss val: 0.04177
[2022-12-06 15:37:03,662] [INFO] [controller] EPOCH 2 loss ppo:  -0.03725, loss val: 0.03911
[2022-12-06 15:37:03,736] [INFO] [controller] EPOCH 3 loss ppo:  -0.04708, loss val: 0.03936
[2022-12-06 15:37:03,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.06120, loss val: 0.04033
[2022-12-06 15:37:03,824] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:37:04,063] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:37:04,064] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:37:12,841] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:37:21,352] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:37:29,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:37:38,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:37:46,585] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:37:55,432] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:38:05,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:38:14,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:38:22,240] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:38:32,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.800136134316736
[2022-12-06 15:38:32,072] [INFO] [runner_train_mujoco] Average state value: 0.4469726950128873
[2022-12-06 15:38:32,073] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 15:38:32,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.04205
[2022-12-06 15:38:32,190] [INFO] [controller] EPOCH 2 loss ppo:  -0.03112, loss val: 0.03960
[2022-12-06 15:38:32,246] [INFO] [controller] EPOCH 3 loss ppo:  -0.04702, loss val: 0.03990
[2022-12-06 15:38:32,295] [INFO] [controller] EPOCH 4 loss ppo:  -0.06035, loss val: 0.03951
[2022-12-06 15:38:32,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:38:32,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:38:32,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:38:41,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:38:49,681] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:38:56,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:39:05,058] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:39:12,760] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:39:20,340] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:39:28,554] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:39:37,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:39:47,614] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:39:55,935] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.393526939282485
[2022-12-06 15:39:55,935] [INFO] [runner_train_mujoco] Average state value: 0.4441963404119014
[2022-12-06 15:39:55,935] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 15:39:55,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.05303
[2022-12-06 15:39:56,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.02813, loss val: 0.05201
[2022-12-06 15:39:56,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.04202, loss val: 0.05266
[2022-12-06 15:39:56,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.05467, loss val: 0.05263
[2022-12-06 15:39:56,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:39:56,345] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:39:56,345] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:40:04,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:40:12,267] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:40:19,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:40:27,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:40:35,171] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:40:42,515] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:40:49,290] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:40:58,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:41:06,022] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:41:13,470] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.582314691212858
[2022-12-06 15:41:13,471] [INFO] [runner_train_mujoco] Average state value: 0.4322280815641085
[2022-12-06 15:41:13,471] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 15:41:13,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.01494, loss val: 0.05262
[2022-12-06 15:41:13,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.02904, loss val: 0.05411
[2022-12-06 15:41:13,602] [INFO] [controller] EPOCH 3 loss ppo:  -0.04334, loss val: 0.05258
[2022-12-06 15:41:13,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.05651, loss val: 0.05398
[2022-12-06 15:41:13,654] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:41:13,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:41:13,862] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:41:29,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:41:37,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:41:47,206] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:41:56,405] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:42:04,963] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:42:12,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:42:20,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:42:28,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:42:36,065] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:42:44,368] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.594306582653701
[2022-12-06 15:42:44,368] [INFO] [runner_train_mujoco] Average state value: 0.4233632131367922
[2022-12-06 15:42:44,368] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 15:42:44,423] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.05327
[2022-12-06 15:42:44,473] [INFO] [controller] EPOCH 2 loss ppo:  -0.02970, loss val: 0.05175
[2022-12-06 15:42:44,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.04449, loss val: 0.05298
[2022-12-06 15:42:44,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.05641, loss val: 0.05155
[2022-12-06 15:42:44,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:42:44,818] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:42:44,818] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:42:53,418] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:43:02,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:43:11,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:43:21,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:43:29,690] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:43:38,146] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:43:47,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:43:55,899] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:44:06,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:44:16,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.321533851697017
[2022-12-06 15:44:16,275] [INFO] [runner_train_mujoco] Average state value: 0.42157518126567206
[2022-12-06 15:44:16,276] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 15:44:16,334] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04612
[2022-12-06 15:44:16,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.03076, loss val: 0.04640
[2022-12-06 15:44:16,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.04811, loss val: 0.04647
[2022-12-06 15:44:16,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.05985, loss val: 0.04608
[2022-12-06 15:44:16,515] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:44:16,734] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:44:16,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:44:26,110] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:44:35,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:44:44,309] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:44:53,106] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:45:03,181] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:45:12,027] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:45:21,581] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:45:28,863] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:45:36,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:45:44,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.622447487397434
[2022-12-06 15:45:44,117] [INFO] [runner_train_mujoco] Average state value: 0.4307350291808446
[2022-12-06 15:45:44,117] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 15:45:44,171] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.05054
[2022-12-06 15:45:44,215] [INFO] [controller] EPOCH 2 loss ppo:  -0.02628, loss val: 0.04677
[2022-12-06 15:45:44,260] [INFO] [controller] EPOCH 3 loss ppo:  -0.03736, loss val: 0.04432
[2022-12-06 15:45:44,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.04703, loss val: 0.04538
[2022-12-06 15:45:44,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:45:44,518] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:45:44,519] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:45:51,857] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:45:59,827] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:46:07,920] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:46:16,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:46:24,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:46:32,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:46:41,828] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:46:49,416] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:46:56,573] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:47:04,732] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.94616505275838
[2022-12-06 15:47:04,733] [INFO] [runner_train_mujoco] Average state value: 0.44543927469849587
[2022-12-06 15:47:04,733] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 15:47:04,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.04142
[2022-12-06 15:47:04,819] [INFO] [controller] EPOCH 2 loss ppo:  -0.02939, loss val: 0.03977
[2022-12-06 15:47:04,863] [INFO] [controller] EPOCH 3 loss ppo:  -0.03998, loss val: 0.04200
[2022-12-06 15:47:04,906] [INFO] [controller] EPOCH 4 loss ppo:  -0.04787, loss val: 0.03735
[2022-12-06 15:47:04,917] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:47:05,122] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:47:05,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:47:12,478] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:47:19,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:47:27,054] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:47:35,030] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:47:42,745] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:47:49,944] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:47:57,454] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:48:04,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:48:14,311] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:48:21,611] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.100209976474423
[2022-12-06 15:48:21,611] [INFO] [runner_train_mujoco] Average state value: 0.47305928405125935
[2022-12-06 15:48:21,611] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 15:48:21,659] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.04691
[2022-12-06 15:48:21,693] [INFO] [controller] EPOCH 2 loss ppo:  -0.02658, loss val: 0.04601
[2022-12-06 15:48:21,783] [INFO] [controller] EPOCH 3 loss ppo:  -0.04112, loss val: 0.04598
[2022-12-06 15:48:21,821] [INFO] [controller] EPOCH 4 loss ppo:  -0.05318, loss val: 0.04806
[2022-12-06 15:48:21,831] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:48:21,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:48:21,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:48:29,146] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:48:35,914] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:48:43,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:48:50,844] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:48:59,040] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:49:07,736] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:49:14,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:49:22,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:49:29,014] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:49:36,087] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.839351578649541
[2022-12-06 15:49:36,087] [INFO] [runner_train_mujoco] Average state value: 0.46505097605784734
[2022-12-06 15:49:36,087] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 15:49:36,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.07211
[2022-12-06 15:49:36,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.02466, loss val: 0.07259
[2022-12-06 15:49:36,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.03630, loss val: 0.07239
[2022-12-06 15:49:36,255] [INFO] [controller] EPOCH 4 loss ppo:  -0.04371, loss val: 0.06903
[2022-12-06 15:49:36,265] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:49:36,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:49:36,456] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:49:43,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:49:50,322] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:49:57,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:50:05,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:50:15,867] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:50:24,777] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:50:32,555] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:50:39,193] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:50:45,988] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:50:52,694] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.0848080705717384
[2022-12-06 15:50:52,694] [INFO] [runner_train_mujoco] Average state value: 0.5133701823353768
[2022-12-06 15:50:52,695] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 15:50:52,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04091
[2022-12-06 15:50:52,781] [INFO] [controller] EPOCH 2 loss ppo:  -0.02546, loss val: 0.04169
[2022-12-06 15:50:52,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.03838, loss val: 0.04199
[2022-12-06 15:50:52,858] [INFO] [controller] EPOCH 4 loss ppo:  -0.04543, loss val: 0.04183
[2022-12-06 15:50:52,866] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:50:53,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:50:53,060] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:51:00,219] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:51:07,591] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:51:13,908] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:51:21,191] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:51:28,216] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:51:35,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:51:43,612] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:51:50,550] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:51:59,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:52:07,558] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.829795224460238
[2022-12-06 15:52:07,558] [INFO] [runner_train_mujoco] Average state value: 0.4983467129642765
[2022-12-06 15:52:07,558] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 15:52:07,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.04640
[2022-12-06 15:52:07,642] [INFO] [controller] EPOCH 2 loss ppo:  -0.02395, loss val: 0.04631
[2022-12-06 15:52:07,687] [INFO] [controller] EPOCH 3 loss ppo:  -0.03711, loss val: 0.04627
[2022-12-06 15:52:07,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.04635, loss val: 0.04751
[2022-12-06 15:52:07,739] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:52:07,916] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:52:07,917] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:52:15,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:52:22,857] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:52:29,968] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:52:37,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:52:45,320] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:52:53,316] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:53:00,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:53:07,842] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:53:16,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:53:24,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.167135203387928
[2022-12-06 15:53:24,784] [INFO] [runner_train_mujoco] Average state value: 0.5228877866913876
[2022-12-06 15:53:24,784] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 15:53:24,834] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.06393
[2022-12-06 15:53:24,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.01957, loss val: 0.06380
[2022-12-06 15:53:24,924] [INFO] [controller] EPOCH 3 loss ppo:  -0.03035, loss val: 0.06567
[2022-12-06 15:53:24,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.04282, loss val: 0.06512
[2022-12-06 15:53:24,978] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:53:25,175] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:53:25,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:53:34,734] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:53:42,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:53:50,045] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:53:57,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:54:06,368] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:54:13,770] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:54:23,011] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:54:32,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:54:41,845] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:54:49,469] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.712011309778106
[2022-12-06 15:54:49,469] [INFO] [runner_train_mujoco] Average state value: 0.4813281631966431
[2022-12-06 15:54:49,469] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 15:54:49,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.06772
[2022-12-06 15:54:49,568] [INFO] [controller] EPOCH 2 loss ppo:  -0.02000, loss val: 0.06773
[2022-12-06 15:54:49,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.02999, loss val: 0.06675
[2022-12-06 15:54:49,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.03799, loss val: 0.06640
[2022-12-06 15:54:49,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:54:49,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:54:49,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:55:00,043] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:55:08,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:55:17,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:55:26,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:55:40,262] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:55:51,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:56:02,590] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:56:10,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:56:18,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:56:27,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.960840048738133
[2022-12-06 15:56:27,808] [INFO] [runner_train_mujoco] Average state value: 0.47948896555602555
[2022-12-06 15:56:27,809] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 15:56:27,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.04488
[2022-12-06 15:56:27,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.02009, loss val: 0.04487
[2022-12-06 15:56:27,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.02939, loss val: 0.04592
[2022-12-06 15:56:27,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.03788, loss val: 0.04545
[2022-12-06 15:56:28,007] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:56:28,248] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:56:28,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:56:36,637] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:56:45,824] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:56:59,558] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:57:11,579] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:57:21,722] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:57:31,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:57:39,164] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:57:47,453] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:57:55,938] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:58:04,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5385607029417505
[2022-12-06 15:58:04,364] [INFO] [runner_train_mujoco] Average state value: 0.4329308193226655
[2022-12-06 15:58:04,364] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 15:58:04,421] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.08642
[2022-12-06 15:58:04,466] [INFO] [controller] EPOCH 2 loss ppo:  -0.02063, loss val: 0.08434
[2022-12-06 15:58:04,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.02908, loss val: 0.08471
[2022-12-06 15:58:04,558] [INFO] [controller] EPOCH 4 loss ppo:  -0.03343, loss val: 0.08499
[2022-12-06 15:58:04,567] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:58:04,794] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:58:04,794] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:58:12,697] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:58:21,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:58:29,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:58:37,553] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:58:45,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:58:56,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:59:05,888] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:59:14,330] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:59:23,008] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:59:32,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.438078602700254
[2022-12-06 15:59:32,747] [INFO] [runner_train_mujoco] Average state value: 0.4810239721139272
[2022-12-06 15:59:32,747] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 15:59:32,799] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04145
[2022-12-06 15:59:32,842] [INFO] [controller] EPOCH 2 loss ppo:  -0.01732, loss val: 0.04392
[2022-12-06 15:59:32,881] [INFO] [controller] EPOCH 3 loss ppo:  -0.02293, loss val: 0.04138
[2022-12-06 15:59:32,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.03008, loss val: 0.04111
[2022-12-06 15:59:32,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:59:33,140] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:59:33,141] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:59:41,696] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:59:49,984] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:00:00,783] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:00:08,410] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:00:15,314] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:00:22,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:00:30,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:00:37,742] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:00:45,385] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:00:53,456] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.172548281459613
[2022-12-06 16:00:53,456] [INFO] [runner_train_mujoco] Average state value: 0.4853792817393939
[2022-12-06 16:00:53,456] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 16:00:53,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.04430
[2022-12-06 16:00:53,543] [INFO] [controller] EPOCH 2 loss ppo:  -0.01688, loss val: 0.04619
[2022-12-06 16:00:53,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.02098, loss val: 0.04423
[2022-12-06 16:00:53,625] [INFO] [controller] EPOCH 4 loss ppo:  -0.02617, loss val: 0.04516
[2022-12-06 16:00:53,635] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:00:53,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:00:53,837] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:01:04,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:01:13,336] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:01:21,680] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:01:29,874] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:01:39,078] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:01:46,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:01:56,478] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:02:05,488] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:02:13,217] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:02:21,517] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.785459773183957
[2022-12-06 16:02:21,517] [INFO] [runner_train_mujoco] Average state value: 0.4297230675357084
[2022-12-06 16:02:21,518] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 16:02:21,576] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.07446
[2022-12-06 16:02:21,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.01496, loss val: 0.07244
[2022-12-06 16:02:21,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.01700, loss val: 0.07316
[2022-12-06 16:02:21,719] [INFO] [controller] EPOCH 4 loss ppo:  -0.01967, loss val: 0.07237
[2022-12-06 16:02:21,772] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:02:21,949] [INFO] [optimize] Finished learning.
