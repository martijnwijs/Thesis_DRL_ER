[2022-12-07 05:29:53,511] [INFO] [optimize] Starting learning
[2022-12-07 05:29:53,524] [INFO] [optimize] Starting learning process..
[2022-12-07 05:29:53,636] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:29:53,637] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:30:03,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:30:11,584] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:30:20,119] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:30:28,219] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:30:36,585] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:30:43,894] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:30:51,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:30:59,650] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:31:07,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:31:15,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4755439887297891
[2022-12-07 05:31:15,983] [INFO] [runner_train_mujoco] Average state value: 0.04738623317455251
[2022-12-07 05:31:15,983] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 05:31:16,053] [INFO] [controller] EPOCH 1 loss ppo:  -0.01141, loss val: 0.37334
[2022-12-07 05:31:16,106] [INFO] [controller] EPOCH 2 loss ppo:  -0.05652, loss val: 0.34156
[2022-12-07 05:31:16,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.07083, loss val: 0.28208
[2022-12-07 05:31:16,205] [INFO] [controller] EPOCH 4 loss ppo:  -0.08199, loss val: 0.24789
[2022-12-07 05:31:16,215] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:31:16,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:31:16,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:31:24,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:31:32,138] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:31:39,668] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:31:47,647] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:31:55,527] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:32:02,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:32:11,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:32:18,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:32:25,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:32:33,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4942471927363715
[2022-12-07 05:32:33,291] [INFO] [runner_train_mujoco] Average state value: 0.18739820661054302
[2022-12-07 05:32:33,292] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 05:32:33,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.23085
[2022-12-07 05:32:33,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.05157, loss val: 0.19979
[2022-12-07 05:32:33,425] [INFO] [controller] EPOCH 3 loss ppo:  -0.06935, loss val: 0.17505
[2022-12-07 05:32:33,470] [INFO] [controller] EPOCH 4 loss ppo:  -0.07939, loss val: 0.15528
[2022-12-07 05:32:33,480] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:32:33,696] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:32:33,696] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:32:41,815] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:32:50,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:32:58,825] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:33:06,767] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:33:14,213] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:33:21,968] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:33:29,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:33:37,066] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:33:44,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:33:52,764] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4229000093923275
[2022-12-07 05:33:52,764] [INFO] [runner_train_mujoco] Average state value: 0.3633615045112868
[2022-12-07 05:33:52,764] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 05:33:52,817] [INFO] [controller] EPOCH 1 loss ppo:  -0.01262, loss val: 0.12426
[2022-12-07 05:33:52,862] [INFO] [controller] EPOCH 2 loss ppo:  -0.05353, loss val: 0.10680
[2022-12-07 05:33:52,906] [INFO] [controller] EPOCH 3 loss ppo:  -0.07159, loss val: 0.10509
[2022-12-07 05:33:52,955] [INFO] [controller] EPOCH 4 loss ppo:  -0.08151, loss val: 0.09462
[2022-12-07 05:33:52,965] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:33:53,170] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:33:53,171] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:34:01,419] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:34:08,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:34:17,408] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:34:25,545] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:34:32,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:34:40,601] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:34:49,904] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:34:58,327] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:35:05,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:35:13,228] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.607711847545158
[2022-12-07 05:35:13,228] [INFO] [runner_train_mujoco] Average state value: 0.4778447083427261
[2022-12-07 05:35:13,228] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 05:35:13,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01033, loss val: 0.09135
[2022-12-07 05:35:13,316] [INFO] [controller] EPOCH 2 loss ppo:  -0.04272, loss val: 0.08467
[2022-12-07 05:35:13,354] [INFO] [controller] EPOCH 3 loss ppo:  -0.06100, loss val: 0.07844
[2022-12-07 05:35:13,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.07292, loss val: 0.07349
[2022-12-07 05:35:13,406] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:35:13,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:35:13,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:35:21,347] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:35:29,202] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:35:37,593] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:35:46,882] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:35:54,574] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:36:02,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:36:09,770] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:36:17,337] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:36:24,647] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:36:32,457] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5988109732621586
[2022-12-07 05:36:32,457] [INFO] [runner_train_mujoco] Average state value: 0.5404365079936881
[2022-12-07 05:36:32,457] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 05:36:32,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.07340
[2022-12-07 05:36:32,563] [INFO] [controller] EPOCH 2 loss ppo:  -0.03898, loss val: 0.07088
[2022-12-07 05:36:32,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.05429, loss val: 0.06811
[2022-12-07 05:36:32,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.06676, loss val: 0.06226
[2022-12-07 05:36:32,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:36:32,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:36:32,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:36:41,242] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:36:49,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:36:57,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:37:05,202] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:37:12,449] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:37:19,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:37:27,978] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:37:36,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:37:44,006] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:37:51,442] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6496825011363215
[2022-12-07 05:37:51,442] [INFO] [runner_train_mujoco] Average state value: 0.5205942084901035
[2022-12-07 05:37:51,442] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 05:37:51,495] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.06660
[2022-12-07 05:37:51,542] [INFO] [controller] EPOCH 2 loss ppo:  -0.04422, loss val: 0.06193
[2022-12-07 05:37:51,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.06023, loss val: 0.05774
[2022-12-07 05:37:51,627] [INFO] [controller] EPOCH 4 loss ppo:  -0.07075, loss val: 0.05543
[2022-12-07 05:37:51,637] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:37:51,841] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:37:51,841] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:37:59,284] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:38:07,456] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:38:15,003] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:38:22,520] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:38:30,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:38:38,335] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:38:46,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:38:54,486] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:39:01,793] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:39:09,320] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40824473255014804
[2022-12-07 05:39:09,320] [INFO] [runner_train_mujoco] Average state value: 0.4521637569218873
[2022-12-07 05:39:09,320] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 05:39:09,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01160, loss val: 0.04946
[2022-12-07 05:39:09,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.04535, loss val: 0.04709
[2022-12-07 05:39:09,463] [INFO] [controller] EPOCH 3 loss ppo:  -0.06126, loss val: 0.04470
[2022-12-07 05:39:09,505] [INFO] [controller] EPOCH 4 loss ppo:  -0.07207, loss val: 0.04427
[2022-12-07 05:39:09,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:39:09,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:39:09,720] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:39:17,338] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:39:25,525] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:39:33,818] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:39:41,629] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:39:49,257] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:39:56,578] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:40:04,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:40:12,101] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:40:20,342] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:40:28,075] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6143202314515466
[2022-12-07 05:40:28,075] [INFO] [runner_train_mujoco] Average state value: 0.3945836412503073
[2022-12-07 05:40:28,075] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 05:40:28,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.05059
[2022-12-07 05:40:28,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.04410, loss val: 0.05333
[2022-12-07 05:40:28,209] [INFO] [controller] EPOCH 3 loss ppo:  -0.05945, loss val: 0.05130
[2022-12-07 05:40:28,247] [INFO] [controller] EPOCH 4 loss ppo:  -0.07221, loss val: 0.04631
[2022-12-07 05:40:28,257] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:40:28,462] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:40:28,462] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:40:35,831] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:40:43,752] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:40:51,469] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:40:59,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:41:06,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:41:15,028] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:41:22,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:41:30,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:41:37,557] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:41:44,843] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6885172894693714
[2022-12-07 05:41:44,844] [INFO] [runner_train_mujoco] Average state value: 0.42010205088804164
[2022-12-07 05:41:44,844] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 05:41:44,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01210, loss val: 0.05002
[2022-12-07 05:41:44,956] [INFO] [controller] EPOCH 2 loss ppo:  -0.03848, loss val: 0.04437
[2022-12-07 05:41:45,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.06013, loss val: 0.04441
[2022-12-07 05:41:45,061] [INFO] [controller] EPOCH 4 loss ppo:  -0.07378, loss val: 0.04023
[2022-12-07 05:41:45,072] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:41:45,295] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:41:45,296] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:41:53,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:42:03,302] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:42:12,723] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:42:21,809] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:42:30,313] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:42:39,242] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:42:48,042] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:42:56,779] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:43:04,745] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:43:12,792] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6707005669743393
[2022-12-07 05:43:12,792] [INFO] [runner_train_mujoco] Average state value: 0.48228067538142205
[2022-12-07 05:43:12,793] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 05:43:12,853] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.05053
[2022-12-07 05:43:12,899] [INFO] [controller] EPOCH 2 loss ppo:  -0.04097, loss val: 0.04639
[2022-12-07 05:43:12,945] [INFO] [controller] EPOCH 3 loss ppo:  -0.06195, loss val: 0.04566
[2022-12-07 05:43:12,992] [INFO] [controller] EPOCH 4 loss ppo:  -0.07419, loss val: 0.04623
[2022-12-07 05:43:13,001] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:43:13,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:43:13,215] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:43:22,239] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:43:30,448] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:43:38,355] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:43:46,052] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:43:53,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:44:01,338] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:44:09,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:44:16,593] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:44:23,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:44:30,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47754740899686965
[2022-12-07 05:44:30,375] [INFO] [runner_train_mujoco] Average state value: 0.5577883197069168
[2022-12-07 05:44:30,375] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 05:44:30,428] [INFO] [controller] EPOCH 1 loss ppo:  -0.01160, loss val: 0.04222
[2022-12-07 05:44:30,467] [INFO] [controller] EPOCH 2 loss ppo:  -0.04227, loss val: 0.03960
[2022-12-07 05:44:30,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.05731, loss val: 0.03960
[2022-12-07 05:44:30,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.06765, loss val: 0.04006
[2022-12-07 05:44:30,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:44:30,766] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:44:30,767] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:44:37,688] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:44:44,532] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:44:51,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:44:58,972] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:45:05,981] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:45:13,035] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:45:20,211] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:45:27,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:45:33,582] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:45:40,320] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7797848050221281
[2022-12-07 05:45:40,320] [INFO] [runner_train_mujoco] Average state value: 0.6034516261617343
[2022-12-07 05:45:40,320] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 05:45:40,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.05687
[2022-12-07 05:45:40,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.04085, loss val: 0.05560
[2022-12-07 05:45:40,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.05767, loss val: 0.05438
[2022-12-07 05:45:40,491] [INFO] [controller] EPOCH 4 loss ppo:  -0.07158, loss val: 0.05017
[2022-12-07 05:45:40,500] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:45:40,702] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:45:40,703] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:45:48,396] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:45:55,458] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:46:02,270] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:46:09,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:46:17,035] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:46:23,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:46:31,065] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:46:38,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:46:45,590] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:46:52,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.075451115029106
[2022-12-07 05:46:52,384] [INFO] [runner_train_mujoco] Average state value: 0.5648703389565151
[2022-12-07 05:46:52,385] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 05:46:52,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01146, loss val: 0.05029
[2022-12-07 05:46:52,477] [INFO] [controller] EPOCH 2 loss ppo:  -0.04004, loss val: 0.04726
[2022-12-07 05:46:52,524] [INFO] [controller] EPOCH 3 loss ppo:  -0.06174, loss val: 0.04557
[2022-12-07 05:46:52,565] [INFO] [controller] EPOCH 4 loss ppo:  -0.07451, loss val: 0.04751
[2022-12-07 05:46:52,573] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:46:52,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:46:52,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:46:59,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:47:06,766] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:47:13,791] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:47:20,964] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:47:27,773] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:47:35,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:47:42,271] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:47:49,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:47:56,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:48:03,865] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8284917633102589
[2022-12-07 05:48:03,865] [INFO] [runner_train_mujoco] Average state value: 0.48745494259397193
[2022-12-07 05:48:03,865] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 05:48:03,934] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.04349
[2022-12-07 05:48:03,983] [INFO] [controller] EPOCH 2 loss ppo:  -0.04700, loss val: 0.04338
[2022-12-07 05:48:04,099] [INFO] [controller] EPOCH 3 loss ppo:  -0.06130, loss val: 0.04072
[2022-12-07 05:48:04,144] [INFO] [controller] EPOCH 4 loss ppo:  -0.07333, loss val: 0.04696
[2022-12-07 05:48:04,154] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:48:04,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:48:04,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:48:11,340] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:48:18,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:48:25,767] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:48:32,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:48:39,904] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:48:47,265] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:48:54,320] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:49:01,799] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:49:09,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:49:16,044] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9562939895579744
[2022-12-07 05:49:16,044] [INFO] [runner_train_mujoco] Average state value: 0.4740269722739856
[2022-12-07 05:49:16,044] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 05:49:16,114] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.02927
[2022-12-07 05:49:16,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.04514, loss val: 0.03097
[2022-12-07 05:49:16,209] [INFO] [controller] EPOCH 3 loss ppo:  -0.06529, loss val: 0.03172
[2022-12-07 05:49:16,257] [INFO] [controller] EPOCH 4 loss ppo:  -0.08010, loss val: 0.03096
[2022-12-07 05:49:16,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:49:16,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:49:16,472] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:49:23,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:49:30,455] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:49:37,335] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:49:44,291] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:49:51,389] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:49:59,270] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:50:06,943] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:50:13,579] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:50:20,185] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:50:26,994] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9571386236099315
[2022-12-07 05:50:26,994] [INFO] [runner_train_mujoco] Average state value: 0.5076855811278025
[2022-12-07 05:50:26,994] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 05:50:27,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.01188, loss val: 0.04520
[2022-12-07 05:50:27,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.04023, loss val: 0.04396
[2022-12-07 05:50:27,123] [INFO] [controller] EPOCH 3 loss ppo:  -0.05976, loss val: 0.03938
[2022-12-07 05:50:27,171] [INFO] [controller] EPOCH 4 loss ppo:  -0.07079, loss val: 0.03712
[2022-12-07 05:50:27,181] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:50:27,392] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:50:27,392] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:50:34,422] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:50:41,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:50:48,799] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:50:55,636] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:51:02,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:51:09,815] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:51:16,974] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:51:23,838] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:51:30,405] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:51:37,227] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.148611414953947
[2022-12-07 05:51:37,227] [INFO] [runner_train_mujoco] Average state value: 0.5858436858753364
[2022-12-07 05:51:37,227] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 05:51:37,304] [INFO] [controller] EPOCH 1 loss ppo:  -0.01167, loss val: 0.02736
[2022-12-07 05:51:37,354] [INFO] [controller] EPOCH 2 loss ppo:  -0.04398, loss val: 0.02911
[2022-12-07 05:51:37,399] [INFO] [controller] EPOCH 3 loss ppo:  -0.06245, loss val: 0.02899
[2022-12-07 05:51:37,444] [INFO] [controller] EPOCH 4 loss ppo:  -0.07706, loss val: 0.02921
[2022-12-07 05:51:37,453] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:51:37,659] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:51:37,660] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:51:44,589] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:51:51,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:51:58,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:52:05,457] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:52:12,743] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:52:20,087] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:52:27,744] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:52:34,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:52:41,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:52:48,487] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3920412818579948
[2022-12-07 05:52:48,487] [INFO] [runner_train_mujoco] Average state value: 0.6057749678095181
[2022-12-07 05:52:48,487] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 05:52:48,533] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.04973
[2022-12-07 05:52:48,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.03492, loss val: 0.04680
[2022-12-07 05:52:48,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.05292, loss val: 0.04215
[2022-12-07 05:52:48,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.06722, loss val: 0.03764
[2022-12-07 05:52:48,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:52:48,849] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:52:48,849] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:52:55,832] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:53:02,995] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:53:09,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:53:16,366] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:53:23,415] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:53:30,719] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:53:37,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:53:44,666] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:53:51,972] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:53:58,870] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4729788662696042
[2022-12-07 05:53:58,871] [INFO] [runner_train_mujoco] Average state value: 0.5358756802976131
[2022-12-07 05:53:58,871] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 05:53:58,921] [INFO] [controller] EPOCH 1 loss ppo:  -0.01496, loss val: 0.04580
[2022-12-07 05:53:58,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.04157, loss val: 0.05070
[2022-12-07 05:53:59,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.05998, loss val: 0.04980
[2022-12-07 05:53:59,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.07236, loss val: 0.04966
[2022-12-07 05:53:59,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:53:59,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:53:59,287] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:54:06,445] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:54:13,252] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:54:19,978] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:54:27,310] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:54:34,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:54:42,198] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:54:50,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:54:56,752] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:55:03,532] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:55:10,192] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3259502603044482
[2022-12-07 05:55:10,193] [INFO] [runner_train_mujoco] Average state value: 0.531468975196282
[2022-12-07 05:55:10,193] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:55:10,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.04263
[2022-12-07 05:55:10,278] [INFO] [controller] EPOCH 2 loss ppo:  -0.04669, loss val: 0.04412
[2022-12-07 05:55:10,318] [INFO] [controller] EPOCH 3 loss ppo:  -0.06670, loss val: 0.04414
[2022-12-07 05:55:10,357] [INFO] [controller] EPOCH 4 loss ppo:  -0.08425, loss val: 0.04536
[2022-12-07 05:55:10,366] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:55:10,554] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:55:10,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:55:17,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:55:24,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:55:31,905] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:55:38,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:55:46,035] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:55:53,299] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:56:00,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:56:06,962] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:56:14,479] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:56:21,277] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5044036455867196
[2022-12-07 05:56:21,277] [INFO] [runner_train_mujoco] Average state value: 0.5514516829848289
[2022-12-07 05:56:21,277] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 05:56:21,328] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.02506
[2022-12-07 05:56:21,373] [INFO] [controller] EPOCH 2 loss ppo:  -0.04524, loss val: 0.02331
[2022-12-07 05:56:21,416] [INFO] [controller] EPOCH 3 loss ppo:  -0.06723, loss val: 0.02628
[2022-12-07 05:56:21,459] [INFO] [controller] EPOCH 4 loss ppo:  -0.07662, loss val: 0.02512
[2022-12-07 05:56:21,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:56:21,666] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:56:21,666] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:56:29,392] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:56:36,998] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:56:43,786] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:56:51,324] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:56:58,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:57:05,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:57:13,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:57:19,891] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:57:26,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:57:33,490] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.023555574114776
[2022-12-07 05:57:33,491] [INFO] [runner_train_mujoco] Average state value: 0.5230955635110537
[2022-12-07 05:57:33,491] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 05:57:33,548] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.04354
[2022-12-07 05:57:33,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.04524, loss val: 0.04336
[2022-12-07 05:57:33,636] [INFO] [controller] EPOCH 3 loss ppo:  -0.06770, loss val: 0.04323
[2022-12-07 05:57:33,681] [INFO] [controller] EPOCH 4 loss ppo:  -0.08033, loss val: 0.04337
[2022-12-07 05:57:33,690] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:57:33,892] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:57:33,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:57:41,075] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:57:48,133] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:57:54,797] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:58:02,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:58:11,336] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:58:18,640] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:58:26,577] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:58:33,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:58:40,591] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:58:47,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0851244933608672
[2022-12-07 05:58:47,634] [INFO] [runner_train_mujoco] Average state value: 0.5092843927045663
[2022-12-07 05:58:47,634] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 05:58:47,684] [INFO] [controller] EPOCH 1 loss ppo:  -0.01623, loss val: 0.03533
[2022-12-07 05:58:47,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.04689, loss val: 0.03527
[2022-12-07 05:58:47,768] [INFO] [controller] EPOCH 3 loss ppo:  -0.06433, loss val: 0.03422
[2022-12-07 05:58:47,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.07941, loss val: 0.03509
[2022-12-07 05:58:47,817] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:58:48,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:58:48,008] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:58:55,076] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:59:02,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:59:09,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:59:17,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:59:24,054] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:59:31,305] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:59:37,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:59:45,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:59:51,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:00:00,011] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.319919811621397
[2022-12-07 06:00:00,011] [INFO] [runner_train_mujoco] Average state value: 0.4865348707139492
[2022-12-07 06:00:00,012] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 06:00:00,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01657, loss val: 0.03543
[2022-12-07 06:00:00,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.04559, loss val: 0.03489
[2022-12-07 06:00:00,177] [INFO] [controller] EPOCH 3 loss ppo:  -0.06280, loss val: 0.03480
[2022-12-07 06:00:00,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.07793, loss val: 0.03810
[2022-12-07 06:00:00,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:00:00,429] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:00:00,430] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:00:07,306] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:00:14,854] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:00:22,405] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:00:29,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:00:37,004] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:00:45,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:00:51,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:00:58,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:01:05,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:01:12,809] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4939317556522216
[2022-12-07 06:01:12,809] [INFO] [runner_train_mujoco] Average state value: 0.47862068151434267
[2022-12-07 06:01:12,809] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 06:01:12,858] [INFO] [controller] EPOCH 1 loss ppo:  -0.01615, loss val: 0.04206
[2022-12-07 06:01:12,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.04421, loss val: 0.04165
[2022-12-07 06:01:12,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.05970, loss val: 0.04305
[2022-12-07 06:01:12,996] [INFO] [controller] EPOCH 4 loss ppo:  -0.07584, loss val: 0.04325
[2022-12-07 06:01:13,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:01:13,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:01:13,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:01:20,504] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:01:27,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:01:34,154] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:01:41,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:01:47,625] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:01:54,823] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:02:02,128] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:02:09,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:02:16,227] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:02:22,753] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.713455639708103
[2022-12-07 06:02:22,753] [INFO] [runner_train_mujoco] Average state value: 0.4843028869827589
[2022-12-07 06:02:22,753] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 06:02:22,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.04077
[2022-12-07 06:02:22,838] [INFO] [controller] EPOCH 2 loss ppo:  -0.03801, loss val: 0.03997
[2022-12-07 06:02:22,877] [INFO] [controller] EPOCH 3 loss ppo:  -0.05779, loss val: 0.03943
[2022-12-07 06:02:22,913] [INFO] [controller] EPOCH 4 loss ppo:  -0.07504, loss val: 0.03881
[2022-12-07 06:02:22,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:02:23,124] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:02:23,124] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:02:29,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:02:37,204] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:02:44,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:02:52,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:02:59,153] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:03:07,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:03:14,477] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:03:21,702] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:03:29,373] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:03:35,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7697390061317573
[2022-12-07 06:03:35,980] [INFO] [runner_train_mujoco] Average state value: 0.4596873891353607
[2022-12-07 06:03:35,980] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 06:03:36,029] [INFO] [controller] EPOCH 1 loss ppo:  -0.01574, loss val: 0.03579
[2022-12-07 06:03:36,070] [INFO] [controller] EPOCH 2 loss ppo:  -0.04275, loss val: 0.03480
[2022-12-07 06:03:36,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.05958, loss val: 0.03391
[2022-12-07 06:03:36,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.07075, loss val: 0.03400
[2022-12-07 06:03:36,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:03:36,380] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:03:36,381] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:03:44,391] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:03:51,829] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:03:58,904] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:04:06,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:04:13,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:04:19,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:04:28,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:04:35,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:04:42,188] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:04:48,872] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9950885830753182
[2022-12-07 06:04:48,872] [INFO] [runner_train_mujoco] Average state value: 0.4442861211995284
[2022-12-07 06:04:48,873] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 06:04:48,922] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.03392
[2022-12-07 06:04:48,964] [INFO] [controller] EPOCH 2 loss ppo:  -0.04121, loss val: 0.03203
[2022-12-07 06:04:49,008] [INFO] [controller] EPOCH 3 loss ppo:  -0.05889, loss val: 0.03282
[2022-12-07 06:04:49,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.07534, loss val: 0.03186
[2022-12-07 06:04:49,058] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:04:49,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:04:49,263] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:04:55,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:05:03,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:05:11,028] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:05:18,831] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:05:25,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:05:32,301] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:05:39,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:05:46,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:05:53,756] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:06:01,182] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3901309890143763
[2022-12-07 06:06:01,183] [INFO] [runner_train_mujoco] Average state value: 0.4402521147330602
[2022-12-07 06:06:01,183] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 06:06:01,232] [INFO] [controller] EPOCH 1 loss ppo:  -0.01504, loss val: 0.05102
[2022-12-07 06:06:01,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.04183, loss val: 0.05104
[2022-12-07 06:06:01,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.05909, loss val: 0.05531
[2022-12-07 06:06:01,357] [INFO] [controller] EPOCH 4 loss ppo:  -0.07594, loss val: 0.05434
[2022-12-07 06:06:01,366] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:06:01,574] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:06:01,574] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:06:08,868] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:06:15,872] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:06:22,733] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:06:30,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:06:40,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:06:48,505] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:06:56,434] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:07:04,469] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:07:12,113] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:07:19,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1333572800470075
[2022-12-07 06:07:19,958] [INFO] [runner_train_mujoco] Average state value: 0.42247035191704835
[2022-12-07 06:07:19,958] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 06:07:20,024] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.05737
[2022-12-07 06:07:20,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.03869, loss val: 0.05957
[2022-12-07 06:07:20,125] [INFO] [controller] EPOCH 3 loss ppo:  -0.05892, loss val: 0.05715
[2022-12-07 06:07:20,190] [INFO] [controller] EPOCH 4 loss ppo:  -0.07014, loss val: 0.05722
[2022-12-07 06:07:20,201] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:07:20,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:07:20,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:07:27,405] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:07:35,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:07:42,333] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:07:49,910] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:07:56,441] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:08:03,530] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:08:11,009] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:08:18,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:08:25,155] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:08:32,361] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.759438580784631
[2022-12-07 06:08:32,362] [INFO] [runner_train_mujoco] Average state value: 0.4444398767749469
[2022-12-07 06:08:32,362] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 06:08:32,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.04124
[2022-12-07 06:08:32,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.03982, loss val: 0.04191
[2022-12-07 06:08:32,576] [INFO] [controller] EPOCH 3 loss ppo:  -0.05618, loss val: 0.04173
[2022-12-07 06:08:32,624] [INFO] [controller] EPOCH 4 loss ppo:  -0.06939, loss val: 0.03908
[2022-12-07 06:08:32,634] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:08:32,847] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:08:32,848] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:08:40,023] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:08:47,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:08:54,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:09:01,186] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:09:08,289] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:09:16,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:09:22,886] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:09:30,083] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:09:37,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:09:46,400] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.868158842541317
[2022-12-07 06:09:46,400] [INFO] [runner_train_mujoco] Average state value: 0.46417405958970387
[2022-12-07 06:09:46,400] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 06:09:46,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01763, loss val: 0.04352
[2022-12-07 06:09:46,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.04215, loss val: 0.04388
[2022-12-07 06:09:46,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.05744, loss val: 0.04371
[2022-12-07 06:09:46,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.07115, loss val: 0.04467
[2022-12-07 06:09:46,576] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:09:46,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:09:46,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:09:55,821] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:10:02,525] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:10:10,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:10:16,838] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:10:23,749] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:10:30,815] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:10:39,131] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:10:46,303] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:10:53,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:11:01,939] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.147887936363417
[2022-12-07 06:11:01,940] [INFO] [runner_train_mujoco] Average state value: 0.46118540349602694
[2022-12-07 06:11:01,940] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 06:11:01,993] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04997
[2022-12-07 06:11:02,035] [INFO] [controller] EPOCH 2 loss ppo:  -0.03661, loss val: 0.04877
[2022-12-07 06:11:02,076] [INFO] [controller] EPOCH 3 loss ppo:  -0.05664, loss val: 0.04792
[2022-12-07 06:11:02,114] [INFO] [controller] EPOCH 4 loss ppo:  -0.06889, loss val: 0.04760
[2022-12-07 06:11:02,122] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:11:02,310] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:11:02,310] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:11:08,996] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:11:16,112] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:11:23,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:11:31,596] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:11:38,761] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:11:47,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:11:58,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:12:06,120] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:12:13,888] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:12:21,899] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.235422962097658
[2022-12-07 06:12:21,900] [INFO] [runner_train_mujoco] Average state value: 0.42379134557147824
[2022-12-07 06:12:21,900] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 06:12:22,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.03881
[2022-12-07 06:12:22,054] [INFO] [controller] EPOCH 2 loss ppo:  -0.03934, loss val: 0.03894
[2022-12-07 06:12:22,098] [INFO] [controller] EPOCH 3 loss ppo:  -0.05441, loss val: 0.04135
[2022-12-07 06:12:22,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.06762, loss val: 0.03953
[2022-12-07 06:12:22,154] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:12:22,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:12:22,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:12:30,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:12:38,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:12:47,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:12:55,309] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:13:03,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:13:11,849] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:13:20,941] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:13:29,162] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:13:37,510] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:13:45,685] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.826501892072162
[2022-12-07 06:13:45,685] [INFO] [runner_train_mujoco] Average state value: 0.4158854636152586
[2022-12-07 06:13:45,685] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 06:13:45,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.04099
[2022-12-07 06:13:45,784] [INFO] [controller] EPOCH 2 loss ppo:  -0.03729, loss val: 0.04044
[2022-12-07 06:13:45,834] [INFO] [controller] EPOCH 3 loss ppo:  -0.05561, loss val: 0.03942
[2022-12-07 06:13:45,879] [INFO] [controller] EPOCH 4 loss ppo:  -0.07131, loss val: 0.03883
[2022-12-07 06:13:45,888] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:13:46,096] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:13:46,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:13:53,600] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:14:02,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:14:10,461] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:14:18,710] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:14:26,746] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:14:34,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:14:43,701] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:14:51,665] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:15:00,425] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:15:07,975] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.560311394422799
[2022-12-07 06:15:07,975] [INFO] [runner_train_mujoco] Average state value: 0.4419293236831824
[2022-12-07 06:15:07,975] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 06:15:08,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04120
[2022-12-07 06:15:08,073] [INFO] [controller] EPOCH 2 loss ppo:  -0.02957, loss val: 0.04320
[2022-12-07 06:15:08,120] [INFO] [controller] EPOCH 3 loss ppo:  -0.04679, loss val: 0.04148
[2022-12-07 06:15:08,167] [INFO] [controller] EPOCH 4 loss ppo:  -0.05847, loss val: 0.04264
[2022-12-07 06:15:08,177] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:15:08,386] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:15:08,387] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:15:16,075] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:15:26,580] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:15:35,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:15:43,518] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:15:51,844] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:16:00,079] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:16:07,901] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:16:15,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:16:23,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:16:31,357] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.728526489692107
[2022-12-07 06:16:31,357] [INFO] [runner_train_mujoco] Average state value: 0.4360544502834479
[2022-12-07 06:16:31,357] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 06:16:31,440] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.03020
[2022-12-07 06:16:31,492] [INFO] [controller] EPOCH 2 loss ppo:  -0.03113, loss val: 0.02975
[2022-12-07 06:16:31,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.04817, loss val: 0.03149
[2022-12-07 06:16:31,598] [INFO] [controller] EPOCH 4 loss ppo:  -0.06236, loss val: 0.03142
[2022-12-07 06:16:31,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:16:31,818] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:16:31,819] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:16:40,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:16:49,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:16:56,425] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:17:04,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:17:12,277] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:17:20,515] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:17:29,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:17:38,630] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:17:50,072] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:17:58,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.474814229131248
[2022-12-07 06:17:58,218] [INFO] [runner_train_mujoco] Average state value: 0.42292535495261346
[2022-12-07 06:17:58,218] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 06:17:58,270] [INFO] [controller] EPOCH 1 loss ppo:  -0.01593, loss val: 0.03928
[2022-12-07 06:17:58,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.03639, loss val: 0.03884
[2022-12-07 06:17:58,357] [INFO] [controller] EPOCH 3 loss ppo:  -0.04818, loss val: 0.03790
[2022-12-07 06:17:58,399] [INFO] [controller] EPOCH 4 loss ppo:  -0.06247, loss val: 0.03720
[2022-12-07 06:17:58,407] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:17:58,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:17:58,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:18:07,468] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:18:15,574] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:18:23,185] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:18:31,012] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:18:38,423] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:18:46,624] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:18:55,064] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:19:03,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:19:11,110] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:19:19,280] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.05443604105077
[2022-12-07 06:19:19,280] [INFO] [runner_train_mujoco] Average state value: 0.39603125334282707
[2022-12-07 06:19:19,280] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 06:19:19,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04641
[2022-12-07 06:19:19,398] [INFO] [controller] EPOCH 2 loss ppo:  -0.03192, loss val: 0.04753
[2022-12-07 06:19:19,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.05021, loss val: 0.04692
[2022-12-07 06:19:19,504] [INFO] [controller] EPOCH 4 loss ppo:  -0.06308, loss val: 0.04824
[2022-12-07 06:19:19,513] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:19:19,741] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:19:19,741] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:19:27,795] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:19:35,990] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:19:45,589] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:19:53,379] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:20:02,649] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:20:10,757] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:20:18,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:20:26,078] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:20:35,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:20:43,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.731660546888278
[2022-12-07 06:20:43,997] [INFO] [runner_train_mujoco] Average state value: 0.38101980933050317
[2022-12-07 06:20:43,997] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 06:20:44,071] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.05977
[2022-12-07 06:20:44,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.02857, loss val: 0.05364
[2022-12-07 06:20:44,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.04549, loss val: 0.05412
[2022-12-07 06:20:44,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.05567, loss val: 0.04873
[2022-12-07 06:20:44,262] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:20:44,461] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:20:44,461] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:20:52,474] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:21:00,360] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:21:07,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:21:15,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:21:24,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:21:33,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:21:41,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:21:49,291] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:21:57,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:22:05,168] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.177415511488657
[2022-12-07 06:22:05,169] [INFO] [runner_train_mujoco] Average state value: 0.4017994266450405
[2022-12-07 06:22:05,169] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 06:22:05,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.04230
[2022-12-07 06:22:05,263] [INFO] [controller] EPOCH 2 loss ppo:  -0.03301, loss val: 0.04191
[2022-12-07 06:22:05,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.04797, loss val: 0.04120
[2022-12-07 06:22:05,348] [INFO] [controller] EPOCH 4 loss ppo:  -0.06134, loss val: 0.04108
[2022-12-07 06:22:05,358] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:22:05,566] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:22:05,567] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:22:13,478] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:22:23,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:22:32,351] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:22:41,989] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:22:50,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:22:58,564] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:23:06,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:23:14,181] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:23:22,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:23:30,858] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.388418232758979
[2022-12-07 06:23:30,859] [INFO] [runner_train_mujoco] Average state value: 0.43387720834215476
[2022-12-07 06:23:30,859] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 06:23:30,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04348
[2022-12-07 06:23:30,960] [INFO] [controller] EPOCH 2 loss ppo:  -0.03275, loss val: 0.04413
[2022-12-07 06:23:31,010] [INFO] [controller] EPOCH 3 loss ppo:  -0.04807, loss val: 0.04358
[2022-12-07 06:23:31,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.05983, loss val: 0.04352
[2022-12-07 06:23:31,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:23:31,285] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:23:31,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:23:39,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:23:48,570] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:23:57,007] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:24:04,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:24:13,146] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:24:23,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:24:31,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:24:39,226] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:24:46,805] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:24:54,993] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.292022488271627
[2022-12-07 06:24:54,993] [INFO] [runner_train_mujoco] Average state value: 0.4515543151497841
[2022-12-07 06:24:54,993] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 06:24:55,046] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04496
[2022-12-07 06:24:55,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.03098, loss val: 0.04510
[2022-12-07 06:24:55,133] [INFO] [controller] EPOCH 3 loss ppo:  -0.04325, loss val: 0.04440
[2022-12-07 06:24:55,174] [INFO] [controller] EPOCH 4 loss ppo:  -0.05800, loss val: 0.04361
[2022-12-07 06:24:55,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:24:55,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:24:55,397] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:25:03,635] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:25:11,643] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:25:20,033] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:25:28,238] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:25:36,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:25:45,027] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:25:52,808] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:26:00,561] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:26:11,182] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:26:18,845] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4546948142182625
[2022-12-07 06:26:18,845] [INFO] [runner_train_mujoco] Average state value: 0.4350178350905577
[2022-12-07 06:26:18,845] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 06:26:18,899] [INFO] [controller] EPOCH 1 loss ppo:  -0.01616, loss val: 0.04723
[2022-12-07 06:26:18,946] [INFO] [controller] EPOCH 2 loss ppo:  -0.02864, loss val: 0.04753
[2022-12-07 06:26:18,989] [INFO] [controller] EPOCH 3 loss ppo:  -0.04096, loss val: 0.04682
[2022-12-07 06:26:19,030] [INFO] [controller] EPOCH 4 loss ppo:  -0.05590, loss val: 0.04581
[2022-12-07 06:26:19,043] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:26:19,255] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:26:19,255] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:26:28,677] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:26:37,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:26:45,636] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:26:53,984] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:27:03,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:11,605] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:27:19,191] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:27:27,380] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:27:35,395] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:27:43,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.554406018635384
[2022-12-07 06:27:43,932] [INFO] [runner_train_mujoco] Average state value: 0.4133385762075584
[2022-12-07 06:27:43,932] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 06:27:43,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04611
[2022-12-07 06:27:44,026] [INFO] [controller] EPOCH 2 loss ppo:  -0.03032, loss val: 0.04668
[2022-12-07 06:27:44,070] [INFO] [controller] EPOCH 3 loss ppo:  -0.04586, loss val: 0.04820
[2022-12-07 06:27:44,113] [INFO] [controller] EPOCH 4 loss ppo:  -0.05907, loss val: 0.04647
[2022-12-07 06:27:44,124] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:27:44,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:27:44,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:27:52,136] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:28:00,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:28:08,812] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:28:16,840] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:28:25,061] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:28:34,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:28:41,990] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:28:49,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:28:57,476] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:29:06,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.535822427187241
[2022-12-07 06:29:06,782] [INFO] [runner_train_mujoco] Average state value: 0.4071008607049783
[2022-12-07 06:29:06,782] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 06:29:06,838] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.04528
[2022-12-07 06:29:06,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.02973, loss val: 0.04165
[2022-12-07 06:29:06,953] [INFO] [controller] EPOCH 3 loss ppo:  -0.04030, loss val: 0.04335
[2022-12-07 06:29:06,999] [INFO] [controller] EPOCH 4 loss ppo:  -0.05329, loss val: 0.04058
[2022-12-07 06:29:07,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:29:07,221] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:29:07,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:29:15,232] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:29:23,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:29:32,718] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:29:42,048] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:29:51,023] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:29:58,683] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:30:08,382] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:30:16,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:30:24,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:30:32,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.782841937884537
[2022-12-07 06:30:32,718] [INFO] [runner_train_mujoco] Average state value: 0.4149987788498402
[2022-12-07 06:30:32,719] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 06:30:32,772] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.03591
[2022-12-07 06:30:32,821] [INFO] [controller] EPOCH 2 loss ppo:  -0.02783, loss val: 0.03572
[2022-12-07 06:30:32,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.04312, loss val: 0.03694
[2022-12-07 06:30:32,937] [INFO] [controller] EPOCH 4 loss ppo:  -0.05477, loss val: 0.03651
[2022-12-07 06:30:32,947] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:30:33,187] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:30:33,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:30:41,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:30:51,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:31:01,821] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:31:10,023] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:31:18,973] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:31:26,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:31:34,641] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:31:42,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:31:50,310] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:31:58,821] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.17281065654244
[2022-12-07 06:31:58,821] [INFO] [runner_train_mujoco] Average state value: 0.427852239002784
[2022-12-07 06:31:58,821] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 06:31:58,883] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.03731
[2022-12-07 06:31:58,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.02679, loss val: 0.03776
[2022-12-07 06:31:59,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.03739, loss val: 0.03747
[2022-12-07 06:31:59,080] [INFO] [controller] EPOCH 4 loss ppo:  -0.04598, loss val: 0.03737
[2022-12-07 06:31:59,090] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:31:59,297] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:31:59,297] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:32:06,906] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:32:16,420] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:32:24,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:32:32,441] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:32:39,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:32:47,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:32:56,089] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:33:04,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:33:12,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:33:20,761] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.908724314242213
[2022-12-07 06:33:20,761] [INFO] [runner_train_mujoco] Average state value: 0.43076286297043165
[2022-12-07 06:33:20,761] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 06:33:20,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.05012
[2022-12-07 06:33:20,899] [INFO] [controller] EPOCH 2 loss ppo:  -0.02910, loss val: 0.04663
[2022-12-07 06:33:20,966] [INFO] [controller] EPOCH 3 loss ppo:  -0.04069, loss val: 0.04711
[2022-12-07 06:33:21,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.05038, loss val: 0.04686
[2022-12-07 06:33:21,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:33:21,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:33:21,245] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:33:29,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:33:37,538] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:33:45,277] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:33:53,479] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:34:00,536] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:34:08,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:34:16,451] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:34:26,082] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:34:34,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:34:41,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.0608169091275546
[2022-12-07 06:34:41,459] [INFO] [runner_train_mujoco] Average state value: 0.4140673596759637
[2022-12-07 06:34:41,459] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 06:34:41,512] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.04442
[2022-12-07 06:34:41,556] [INFO] [controller] EPOCH 2 loss ppo:  -0.02770, loss val: 0.04434
[2022-12-07 06:34:41,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.03902, loss val: 0.04498
[2022-12-07 06:34:41,657] [INFO] [controller] EPOCH 4 loss ppo:  -0.04929, loss val: 0.04439
[2022-12-07 06:34:41,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:34:41,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:34:41,870] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:34:50,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:34:58,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:35:05,557] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:35:13,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:35:22,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:35:30,058] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:35:38,696] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:35:46,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:35:54,235] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:36:03,286] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.632296517168737
[2022-12-07 06:36:03,286] [INFO] [runner_train_mujoco] Average state value: 0.41973553498586025
[2022-12-07 06:36:03,286] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 06:36:03,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04158
[2022-12-07 06:36:03,397] [INFO] [controller] EPOCH 2 loss ppo:  -0.02516, loss val: 0.04354
[2022-12-07 06:36:03,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.03680, loss val: 0.04148
[2022-12-07 06:36:03,493] [INFO] [controller] EPOCH 4 loss ppo:  -0.04425, loss val: 0.04018
[2022-12-07 06:36:03,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:36:03,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:36:03,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:36:11,878] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:36:20,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:36:27,441] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:36:34,819] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:36:42,256] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:36:49,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:36:59,022] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:37:07,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:37:15,279] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:37:23,295] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.299390986782556
[2022-12-07 06:37:23,296] [INFO] [runner_train_mujoco] Average state value: 0.42202254684766133
[2022-12-07 06:37:23,296] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 06:37:23,352] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04261
[2022-12-07 06:37:23,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.02310, loss val: 0.04260
[2022-12-07 06:37:23,471] [INFO] [controller] EPOCH 3 loss ppo:  -0.03276, loss val: 0.04152
[2022-12-07 06:37:23,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.04327, loss val: 0.04211
[2022-12-07 06:37:23,525] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:37:23,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:37:23,737] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:37:31,607] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:37:39,139] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:37:46,680] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:37:54,319] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:38:01,952] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:38:09,844] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:38:18,023] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:38:26,162] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:38:35,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:38:45,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.810326175906322
[2022-12-07 06:38:45,271] [INFO] [runner_train_mujoco] Average state value: 0.3932185571591059
[2022-12-07 06:38:45,271] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 06:38:45,327] [INFO] [controller] EPOCH 1 loss ppo:  -0.01346, loss val: 0.07858
[2022-12-07 06:38:45,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.01740, loss val: 0.07545
[2022-12-07 06:38:45,415] [INFO] [controller] EPOCH 3 loss ppo:  -0.02477, loss val: 0.07562
[2022-12-07 06:38:45,456] [INFO] [controller] EPOCH 4 loss ppo:  -0.03533, loss val: 0.07544
[2022-12-07 06:38:45,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:38:45,671] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:38:45,672] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:38:54,443] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:39:02,335] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:39:09,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:39:16,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:39:24,480] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:39:33,160] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:39:40,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:39:47,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:39:54,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:40:02,035] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.479660871158228
[2022-12-07 06:40:02,036] [INFO] [runner_train_mujoco] Average state value: 0.43264964291453356
[2022-12-07 06:40:02,036] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 06:40:02,082] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04064
[2022-12-07 06:40:02,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.02174, loss val: 0.04094
[2022-12-07 06:40:02,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.03146, loss val: 0.04087
[2022-12-07 06:40:02,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.03832, loss val: 0.04171
[2022-12-07 06:40:02,209] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:40:02,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:40:02,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:40:09,408] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:40:16,140] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:40:24,599] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:40:31,648] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:40:38,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:40:45,575] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:40:52,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:40:59,278] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:41:06,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:41:14,203] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.736410539503659
[2022-12-07 06:41:14,203] [INFO] [runner_train_mujoco] Average state value: 0.4389000331858794
[2022-12-07 06:41:14,203] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 06:41:14,251] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.03939
[2022-12-07 06:41:14,290] [INFO] [controller] EPOCH 2 loss ppo:  -0.01915, loss val: 0.04076
[2022-12-07 06:41:14,326] [INFO] [controller] EPOCH 3 loss ppo:  -0.02975, loss val: 0.03933
[2022-12-07 06:41:14,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.03833, loss val: 0.03882
[2022-12-07 06:41:14,377] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:41:14,574] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:41:14,574] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:41:21,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:41:29,871] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:41:36,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:41:44,912] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:41:51,665] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:41:58,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:42:05,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:42:13,498] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:42:20,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:42:28,814] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.227657356743263
[2022-12-07 06:42:28,815] [INFO] [runner_train_mujoco] Average state value: 0.44051081151763594
[2022-12-07 06:42:28,815] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 06:42:28,860] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.05199
[2022-12-07 06:42:28,903] [INFO] [controller] EPOCH 2 loss ppo:  -0.01832, loss val: 0.05186
[2022-12-07 06:42:28,941] [INFO] [controller] EPOCH 3 loss ppo:  -0.02508, loss val: 0.05180
[2022-12-07 06:42:28,977] [INFO] [controller] EPOCH 4 loss ppo:  -0.03306, loss val: 0.05157
[2022-12-07 06:42:28,987] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:42:29,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:42:29,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:42:37,590] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:42:45,247] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:42:52,158] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:42:58,687] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:43:06,907] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:43:17,261] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:43:26,459] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:43:33,260] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:43:40,016] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:43:46,911] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.474970768402765
[2022-12-07 06:43:46,911] [INFO] [runner_train_mujoco] Average state value: 0.44517168611288066
[2022-12-07 06:43:46,912] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 06:43:46,965] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.04515
[2022-12-07 06:43:47,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.01627, loss val: 0.04413
[2022-12-07 06:43:47,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.02092, loss val: 0.04458
[2022-12-07 06:43:47,097] [INFO] [controller] EPOCH 4 loss ppo:  -0.02699, loss val: 0.04465
[2022-12-07 06:43:47,107] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:43:47,317] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:43:47,317] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:43:54,125] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:44:03,098] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:44:09,938] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:44:17,362] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:44:24,758] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:44:31,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:44:40,321] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:44:49,532] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:44:56,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:45:04,076] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.4898697500102696
[2022-12-07 06:45:04,076] [INFO] [runner_train_mujoco] Average state value: 0.44779884103933976
[2022-12-07 06:45:04,076] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 06:45:04,136] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.03433
[2022-12-07 06:45:04,180] [INFO] [controller] EPOCH 2 loss ppo:  -0.01528, loss val: 0.03431
[2022-12-07 06:45:04,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.01740, loss val: 0.03529
[2022-12-07 06:45:04,274] [INFO] [controller] EPOCH 4 loss ppo:  -0.02083, loss val: 0.03452
[2022-12-07 06:45:04,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:45:04,405] [INFO] [optimize] Finished learning.
