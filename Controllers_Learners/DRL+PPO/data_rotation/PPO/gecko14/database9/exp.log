[2022-12-07 09:33:02,253] [INFO] [optimize] Starting learning
[2022-12-07 09:33:02,266] [INFO] [optimize] Starting learning process..
[2022-12-07 09:33:02,393] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:33:02,394] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:33:12,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:33:20,389] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:33:28,656] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:33:36,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:33:46,229] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:33:53,825] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:34:01,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:34:08,986] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:34:16,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:34:24,496] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4980771946303985
[2022-12-07 09:34:24,496] [INFO] [runner_train_mujoco] Average state value: -0.10518466649949551
[2022-12-07 09:34:24,496] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 09:34:24,572] [INFO] [controller] EPOCH 1 loss ppo:  -0.01015, loss val: 0.54656
[2022-12-07 09:34:24,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.05242, loss val: 0.49201
[2022-12-07 09:34:24,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.06810, loss val: 0.45851
[2022-12-07 09:34:24,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.08075, loss val: 0.40924
[2022-12-07 09:34:24,723] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:34:24,923] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:34:24,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:34:32,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:34:40,588] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:34:48,449] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:34:56,704] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:35:04,490] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:35:12,618] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:35:20,192] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:35:27,976] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:35:35,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:35:43,950] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44668462851938545
[2022-12-07 09:35:43,950] [INFO] [runner_train_mujoco] Average state value: 0.0890844892890503
[2022-12-07 09:35:43,950] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 09:35:44,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.35057
[2022-12-07 09:35:44,045] [INFO] [controller] EPOCH 2 loss ppo:  -0.04888, loss val: 0.30614
[2022-12-07 09:35:44,084] [INFO] [controller] EPOCH 3 loss ppo:  -0.06508, loss val: 0.26573
[2022-12-07 09:35:44,132] [INFO] [controller] EPOCH 4 loss ppo:  -0.07523, loss val: 0.23479
[2022-12-07 09:35:44,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:35:44,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:35:44,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:35:52,432] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:36:00,299] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:36:07,941] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:36:15,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:36:23,870] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:36:31,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:36:39,502] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:36:46,948] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:36:54,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:37:01,774] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.45280482850550624
[2022-12-07 09:37:01,774] [INFO] [runner_train_mujoco] Average state value: 0.23281332252919676
[2022-12-07 09:37:01,774] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 09:37:01,960] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.18524
[2022-12-07 09:37:02,002] [INFO] [controller] EPOCH 2 loss ppo:  -0.05086, loss val: 0.16105
[2022-12-07 09:37:02,045] [INFO] [controller] EPOCH 3 loss ppo:  -0.06887, loss val: 0.13849
[2022-12-07 09:37:02,087] [INFO] [controller] EPOCH 4 loss ppo:  -0.08032, loss val: 0.12329
[2022-12-07 09:37:02,097] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:37:02,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:37:02,311] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:37:10,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:37:18,820] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:37:26,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:37:34,642] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:37:42,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:37:49,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:37:57,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:38:05,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:38:13,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:38:21,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6025124034619748
[2022-12-07 09:38:21,570] [INFO] [runner_train_mujoco] Average state value: 0.3977607462393741
[2022-12-07 09:38:21,570] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 09:38:21,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.11233
[2022-12-07 09:38:21,657] [INFO] [controller] EPOCH 2 loss ppo:  -0.04481, loss val: 0.09268
[2022-12-07 09:38:21,698] [INFO] [controller] EPOCH 3 loss ppo:  -0.06384, loss val: 0.08594
[2022-12-07 09:38:21,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.07628, loss val: 0.07772
[2022-12-07 09:38:21,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:38:21,970] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:38:21,971] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:38:30,208] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:38:38,487] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:38:47,654] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:38:55,840] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:39:04,052] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:39:12,188] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:39:19,941] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:39:27,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:39:35,195] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:39:42,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4968937244831923
[2022-12-07 09:39:42,405] [INFO] [runner_train_mujoco] Average state value: 0.5248629352394492
[2022-12-07 09:39:42,405] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 09:39:42,456] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.08861
[2022-12-07 09:39:42,493] [INFO] [controller] EPOCH 2 loss ppo:  -0.04180, loss val: 0.08770
[2022-12-07 09:39:42,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.05577, loss val: 0.08490
[2022-12-07 09:39:42,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.06787, loss val: 0.08237
[2022-12-07 09:39:42,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:39:42,796] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:39:42,796] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:39:50,970] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:39:59,225] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:40:07,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:40:15,721] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:40:24,082] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:40:32,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:40:40,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:40:56,271] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:41:10,005] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:41:19,029] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.384400842046656
[2022-12-07 09:41:19,029] [INFO] [runner_train_mujoco] Average state value: 0.5305221743093183
[2022-12-07 09:41:19,029] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 09:41:19,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01174, loss val: 0.05955
[2022-12-07 09:41:19,133] [INFO] [controller] EPOCH 2 loss ppo:  -0.04796, loss val: 0.05705
[2022-12-07 09:41:19,178] [INFO] [controller] EPOCH 3 loss ppo:  -0.06628, loss val: 0.05830
[2022-12-07 09:41:19,224] [INFO] [controller] EPOCH 4 loss ppo:  -0.07702, loss val: 0.05087
[2022-12-07 09:41:19,235] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:41:19,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:41:19,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:41:28,521] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:41:38,197] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:41:48,792] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:41:57,388] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:42:06,515] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:42:14,350] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:42:24,198] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:42:33,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:42:42,002] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:42:55,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5540363031551527
[2022-12-07 09:42:55,202] [INFO] [runner_train_mujoco] Average state value: 0.537585341523091
[2022-12-07 09:42:55,202] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 09:42:55,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01106, loss val: 0.06326
[2022-12-07 09:42:55,374] [INFO] [controller] EPOCH 2 loss ppo:  -0.04280, loss val: 0.06224
[2022-12-07 09:42:55,435] [INFO] [controller] EPOCH 3 loss ppo:  -0.06006, loss val: 0.06007
[2022-12-07 09:42:55,520] [INFO] [controller] EPOCH 4 loss ppo:  -0.07248, loss val: 0.05735
[2022-12-07 09:42:55,531] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:42:55,792] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:42:55,792] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:43:06,483] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:43:16,631] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:43:28,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:43:42,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:43:54,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:44:12,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:44:24,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:44:33,263] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:44:42,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:44:51,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6693277571297528
[2022-12-07 09:44:51,505] [INFO] [runner_train_mujoco] Average state value: 0.5313363948861759
[2022-12-07 09:44:51,506] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 09:44:51,564] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.05088
[2022-12-07 09:44:51,610] [INFO] [controller] EPOCH 2 loss ppo:  -0.04590, loss val: 0.04988
[2022-12-07 09:44:51,662] [INFO] [controller] EPOCH 3 loss ppo:  -0.06020, loss val: 0.04913
[2022-12-07 09:44:51,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.06875, loss val: 0.04835
[2022-12-07 09:44:51,751] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:44:51,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:44:51,979] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:45:02,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:45:11,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:45:21,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:45:33,722] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:45:43,402] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:45:53,172] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:46:02,024] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:46:10,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:46:20,026] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:46:30,037] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7159805096342919
[2022-12-07 09:46:30,037] [INFO] [runner_train_mujoco] Average state value: 0.5065702632864316
[2022-12-07 09:46:30,037] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 09:46:30,097] [INFO] [controller] EPOCH 1 loss ppo:  -0.00967, loss val: 0.03382
[2022-12-07 09:46:30,164] [INFO] [controller] EPOCH 2 loss ppo:  -0.04875, loss val: 0.03315
[2022-12-07 09:46:30,216] [INFO] [controller] EPOCH 3 loss ppo:  -0.06607, loss val: 0.03384
[2022-12-07 09:46:30,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.07516, loss val: 0.03140
[2022-12-07 09:46:30,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:46:30,543] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:46:30,543] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:46:41,265] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:46:50,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:46:58,849] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:47:07,324] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:47:15,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:47:24,068] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:47:33,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:47:41,190] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:47:49,427] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:47:58,208] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5230843075478369
[2022-12-07 09:47:58,208] [INFO] [runner_train_mujoco] Average state value: 0.504064289033413
[2022-12-07 09:47:58,209] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 09:47:58,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.04641
[2022-12-07 09:47:58,318] [INFO] [controller] EPOCH 2 loss ppo:  -0.04674, loss val: 0.04706
[2022-12-07 09:47:58,377] [INFO] [controller] EPOCH 3 loss ppo:  -0.06549, loss val: 0.04570
[2022-12-07 09:47:58,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.07475, loss val: 0.04717
[2022-12-07 09:47:58,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:47:58,685] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:47:58,686] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:48:07,334] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:48:16,131] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:48:24,192] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:48:32,702] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:48:40,434] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:48:47,783] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:48:55,441] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:49:03,103] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:49:11,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:49:18,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48946102298630845
[2022-12-07 09:49:18,531] [INFO] [runner_train_mujoco] Average state value: 0.5048721136947473
[2022-12-07 09:49:18,531] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 09:49:18,572] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.04467
[2022-12-07 09:49:18,606] [INFO] [controller] EPOCH 2 loss ppo:  -0.04848, loss val: 0.04232
[2022-12-07 09:49:18,641] [INFO] [controller] EPOCH 3 loss ppo:  -0.06704, loss val: 0.04241
[2022-12-07 09:49:18,680] [INFO] [controller] EPOCH 4 loss ppo:  -0.07611, loss val: 0.04018
[2022-12-07 09:49:18,689] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:49:18,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:49:18,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:49:26,070] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:49:34,056] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:49:41,304] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:49:47,844] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:49:54,439] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:50:00,960] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:50:07,649] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:50:14,973] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:50:22,162] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:50:28,412] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6527095032792177
[2022-12-07 09:50:28,412] [INFO] [runner_train_mujoco] Average state value: 0.5619662013848623
[2022-12-07 09:50:28,412] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 09:50:28,457] [INFO] [controller] EPOCH 1 loss ppo:  -0.01041, loss val: 0.03544
[2022-12-07 09:50:28,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.04692, loss val: 0.03566
[2022-12-07 09:50:28,532] [INFO] [controller] EPOCH 3 loss ppo:  -0.06383, loss val: 0.03536
[2022-12-07 09:50:28,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.07444, loss val: 0.03576
[2022-12-07 09:50:28,584] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:50:28,791] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:50:28,791] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:50:35,896] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:50:43,219] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:50:50,117] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:50:56,837] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:51:03,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:51:10,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:51:17,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:51:23,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:51:30,516] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:51:37,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6822917054719023
[2022-12-07 09:51:37,819] [INFO] [runner_train_mujoco] Average state value: 0.5881360921065013
[2022-12-07 09:51:37,819] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 09:51:37,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01091, loss val: 0.04669
[2022-12-07 09:51:38,002] [INFO] [controller] EPOCH 2 loss ppo:  -0.03946, loss val: 0.04621
[2022-12-07 09:51:38,070] [INFO] [controller] EPOCH 3 loss ppo:  -0.05422, loss val: 0.04422
[2022-12-07 09:51:38,138] [INFO] [controller] EPOCH 4 loss ppo:  -0.06729, loss val: 0.04281
[2022-12-07 09:51:38,151] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:51:38,377] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:51:38,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:51:46,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:51:57,598] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:52:04,530] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:52:11,149] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:52:18,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:52:25,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:52:32,832] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:52:39,814] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:52:46,454] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:52:53,056] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9190907020388929
[2022-12-07 09:52:53,057] [INFO] [runner_train_mujoco] Average state value: 0.5571729311148326
[2022-12-07 09:52:53,057] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 09:52:53,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.01256, loss val: 0.04642
[2022-12-07 09:52:53,154] [INFO] [controller] EPOCH 2 loss ppo:  -0.03902, loss val: 0.04196
[2022-12-07 09:52:53,254] [INFO] [controller] EPOCH 3 loss ppo:  -0.05684, loss val: 0.03987
[2022-12-07 09:52:53,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.06975, loss val: 0.03458
[2022-12-07 09:52:53,307] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:52:53,499] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:52:53,499] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:53:00,313] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:53:08,004] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:53:14,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:53:23,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:53:30,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:53:37,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:53:44,191] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:53:51,677] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:53:58,412] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:54:05,203] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8925965014229632
[2022-12-07 09:54:05,203] [INFO] [runner_train_mujoco] Average state value: 0.46773970571408674
[2022-12-07 09:54:05,204] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 09:54:05,254] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.05267
[2022-12-07 09:54:05,296] [INFO] [controller] EPOCH 2 loss ppo:  -0.04205, loss val: 0.05504
[2022-12-07 09:54:05,341] [INFO] [controller] EPOCH 3 loss ppo:  -0.05919, loss val: 0.05538
[2022-12-07 09:54:05,383] [INFO] [controller] EPOCH 4 loss ppo:  -0.07087, loss val: 0.05448
[2022-12-07 09:54:05,393] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:54:05,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:54:05,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:54:12,465] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:54:19,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:54:27,010] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:54:35,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:54:42,436] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:54:49,346] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:54:56,285] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:55:04,196] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:55:11,540] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:55:19,556] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1455701837558574
[2022-12-07 09:55:19,556] [INFO] [runner_train_mujoco] Average state value: 0.45884582572182026
[2022-12-07 09:55:19,556] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 09:55:19,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.05710
[2022-12-07 09:55:19,649] [INFO] [controller] EPOCH 2 loss ppo:  -0.04292, loss val: 0.05393
[2022-12-07 09:55:19,691] [INFO] [controller] EPOCH 3 loss ppo:  -0.06162, loss val: 0.05081
[2022-12-07 09:55:19,739] [INFO] [controller] EPOCH 4 loss ppo:  -0.07496, loss val: 0.04821
[2022-12-07 09:55:19,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:55:19,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:55:19,960] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:55:27,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:55:35,143] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:55:43,073] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:55:50,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:55:57,203] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:56:03,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:56:10,895] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:56:19,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:56:27,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:56:34,791] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3049629391107183
[2022-12-07 09:56:34,792] [INFO] [runner_train_mujoco] Average state value: 0.5298494447867076
[2022-12-07 09:56:34,792] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 09:56:34,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.03970
[2022-12-07 09:56:34,918] [INFO] [controller] EPOCH 2 loss ppo:  -0.05075, loss val: 0.04078
[2022-12-07 09:56:34,980] [INFO] [controller] EPOCH 3 loss ppo:  -0.06662, loss val: 0.04195
[2022-12-07 09:56:35,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.07694, loss val: 0.04198
[2022-12-07 09:56:35,046] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:56:35,263] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:56:35,263] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:56:42,814] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:56:49,999] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:56:57,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:57:04,299] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:57:11,213] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:57:18,228] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:57:24,755] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:57:31,673] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:57:38,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:57:46,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1133780660347192
[2022-12-07 09:57:46,741] [INFO] [runner_train_mujoco] Average state value: 0.5652039426267146
[2022-12-07 09:57:46,742] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 09:57:46,791] [INFO] [controller] EPOCH 1 loss ppo:  -0.01121, loss val: 0.03764
[2022-12-07 09:57:46,837] [INFO] [controller] EPOCH 2 loss ppo:  -0.04200, loss val: 0.03935
[2022-12-07 09:57:46,878] [INFO] [controller] EPOCH 3 loss ppo:  -0.06055, loss val: 0.03873
[2022-12-07 09:57:46,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.07284, loss val: 0.03687
[2022-12-07 09:57:46,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:57:47,134] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:57:47,134] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:57:55,777] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:58:02,761] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:58:09,584] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:58:16,584] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:58:24,344] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:58:31,690] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:58:38,242] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:58:44,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:58:51,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:58:58,008] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2969485877465865
[2022-12-07 09:58:58,008] [INFO] [runner_train_mujoco] Average state value: 0.5522727813820045
[2022-12-07 09:58:58,008] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 09:58:58,053] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.04748
[2022-12-07 09:58:58,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.04154, loss val: 0.04575
[2022-12-07 09:58:58,137] [INFO] [controller] EPOCH 3 loss ppo:  -0.05867, loss val: 0.04339
[2022-12-07 09:58:58,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.07249, loss val: 0.04340
[2022-12-07 09:58:58,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:58:58,380] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:58:58,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:59:05,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:59:12,117] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:59:19,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:59:27,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:59:35,891] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:59:44,097] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:59:51,308] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:59:58,871] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:00:07,571] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:00:15,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7051048934409554
[2022-12-07 10:00:15,572] [INFO] [runner_train_mujoco] Average state value: 0.4995702422360579
[2022-12-07 10:00:15,572] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 10:00:15,629] [INFO] [controller] EPOCH 1 loss ppo:  -0.01558, loss val: 0.04216
[2022-12-07 10:00:15,677] [INFO] [controller] EPOCH 2 loss ppo:  -0.04709, loss val: 0.04643
[2022-12-07 10:00:15,726] [INFO] [controller] EPOCH 3 loss ppo:  -0.06400, loss val: 0.04406
[2022-12-07 10:00:15,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.07638, loss val: 0.04400
[2022-12-07 10:00:15,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:00:15,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:00:15,991] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:00:24,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:00:32,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:00:40,292] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:00:49,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:00:56,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:01:03,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:01:11,444] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:01:19,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:01:28,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:01:35,734] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.370661271630504
[2022-12-07 10:01:35,734] [INFO] [runner_train_mujoco] Average state value: 0.4825070510258277
[2022-12-07 10:01:35,735] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 10:01:35,786] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.03475
[2022-12-07 10:01:35,829] [INFO] [controller] EPOCH 2 loss ppo:  -0.04518, loss val: 0.03552
[2022-12-07 10:01:35,872] [INFO] [controller] EPOCH 3 loss ppo:  -0.06281, loss val: 0.03237
[2022-12-07 10:01:35,915] [INFO] [controller] EPOCH 4 loss ppo:  -0.07589, loss val: 0.03320
[2022-12-07 10:01:35,923] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:01:36,144] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:01:36,145] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:01:44,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:01:55,780] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:02:04,167] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:02:12,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:02:22,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:02:30,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:02:40,117] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:02:48,612] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:02:57,175] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:03:04,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9112436193116402
[2022-12-07 10:03:04,812] [INFO] [runner_train_mujoco] Average state value: 0.5268350109656652
[2022-12-07 10:03:04,813] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 10:03:04,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04570
[2022-12-07 10:03:04,921] [INFO] [controller] EPOCH 2 loss ppo:  -0.04439, loss val: 0.04777
[2022-12-07 10:03:04,967] [INFO] [controller] EPOCH 3 loss ppo:  -0.06324, loss val: 0.04521
[2022-12-07 10:03:05,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.08037, loss val: 0.04423
[2022-12-07 10:03:05,026] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:03:05,251] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:03:05,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:03:13,172] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:03:23,922] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:03:32,712] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:03:41,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:03:49,413] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:03:57,720] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:04:06,510] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:04:14,819] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:04:22,745] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:04:30,716] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.185004109882966
[2022-12-07 10:04:30,716] [INFO] [runner_train_mujoco] Average state value: 0.5236395616730055
[2022-12-07 10:04:30,716] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 10:04:30,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.03488
[2022-12-07 10:04:30,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.04334, loss val: 0.03439
[2022-12-07 10:04:30,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.06068, loss val: 0.03323
[2022-12-07 10:04:30,889] [INFO] [controller] EPOCH 4 loss ppo:  -0.07548, loss val: 0.03204
[2022-12-07 10:04:30,899] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:04:31,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:04:31,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:04:41,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:04:49,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:04:57,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:05:04,397] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:05:11,559] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:05:19,217] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:05:26,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:05:34,891] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:05:42,592] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:05:50,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.149069316592178
[2022-12-07 10:05:50,110] [INFO] [runner_train_mujoco] Average state value: 0.5538555911183357
[2022-12-07 10:05:50,110] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 10:05:50,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01546, loss val: 0.05574
[2022-12-07 10:05:50,202] [INFO] [controller] EPOCH 2 loss ppo:  -0.04303, loss val: 0.05807
[2022-12-07 10:05:50,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.06168, loss val: 0.05685
[2022-12-07 10:05:50,298] [INFO] [controller] EPOCH 4 loss ppo:  -0.07695, loss val: 0.05624
[2022-12-07 10:05:50,310] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:05:50,529] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:05:50,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:05:58,529] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:06:06,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:06:14,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:06:22,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:06:29,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:06:37,512] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:06:45,501] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:06:53,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:07:01,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:07:11,209] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8136254090930826
[2022-12-07 10:07:11,209] [INFO] [runner_train_mujoco] Average state value: 0.5493127124806245
[2022-12-07 10:07:11,209] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 10:07:11,281] [INFO] [controller] EPOCH 1 loss ppo:  -0.01585, loss val: 0.03779
[2022-12-07 10:07:11,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.04506, loss val: 0.03565
[2022-12-07 10:07:11,395] [INFO] [controller] EPOCH 3 loss ppo:  -0.06360, loss val: 0.03524
[2022-12-07 10:07:11,444] [INFO] [controller] EPOCH 4 loss ppo:  -0.07633, loss val: 0.03419
[2022-12-07 10:07:11,455] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:07:11,701] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:07:11,702] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:07:20,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:07:30,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:07:42,940] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:07:53,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:08:02,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:08:11,522] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:08:20,894] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:08:30,462] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:08:39,445] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:08:49,238] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3414674641065956
[2022-12-07 10:08:49,238] [INFO] [runner_train_mujoco] Average state value: 0.5033724981943766
[2022-12-07 10:08:49,238] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 10:08:49,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04426
[2022-12-07 10:08:49,356] [INFO] [controller] EPOCH 2 loss ppo:  -0.04032, loss val: 0.04351
[2022-12-07 10:08:49,407] [INFO] [controller] EPOCH 3 loss ppo:  -0.06029, loss val: 0.04388
[2022-12-07 10:08:49,460] [INFO] [controller] EPOCH 4 loss ppo:  -0.07433, loss val: 0.04438
[2022-12-07 10:08:49,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:08:49,712] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:08:49,713] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:08:59,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:09:11,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:09:29,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:09:40,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:09:50,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:10:01,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:10:12,612] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:10:22,445] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:10:33,338] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:10:42,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6442312875885796
[2022-12-07 10:10:42,166] [INFO] [runner_train_mujoco] Average state value: 0.49162612496813135
[2022-12-07 10:10:42,166] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 10:10:42,229] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.04562
[2022-12-07 10:10:42,278] [INFO] [controller] EPOCH 2 loss ppo:  -0.04011, loss val: 0.04522
[2022-12-07 10:10:42,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.05859, loss val: 0.04667
[2022-12-07 10:10:42,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.07243, loss val: 0.04518
[2022-12-07 10:10:42,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:10:42,631] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:10:42,632] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:10:55,500] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:11:06,709] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:11:16,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:11:26,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:11:35,230] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:11:48,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:11:57,672] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:12:06,301] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:12:14,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:12:23,362] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5049923895923483
[2022-12-07 10:12:23,362] [INFO] [runner_train_mujoco] Average state value: 0.5045025034546853
[2022-12-07 10:12:23,362] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 10:12:23,417] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.04098
[2022-12-07 10:12:23,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.04191, loss val: 0.04101
[2022-12-07 10:12:23,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.06156, loss val: 0.04095
[2022-12-07 10:12:23,561] [INFO] [controller] EPOCH 4 loss ppo:  -0.07639, loss val: 0.04042
[2022-12-07 10:12:23,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:12:23,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:12:23,803] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:12:32,476] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:12:45,533] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:12:55,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:13:03,869] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:13:11,996] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:13:19,674] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:13:29,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:13:38,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:13:46,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:13:54,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5708318640085634
[2022-12-07 10:13:54,475] [INFO] [runner_train_mujoco] Average state value: 0.5021129761735599
[2022-12-07 10:13:54,475] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 10:13:54,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.01497, loss val: 0.04752
[2022-12-07 10:13:54,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.04233, loss val: 0.04818
[2022-12-07 10:13:54,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.06114, loss val: 0.04653
[2022-12-07 10:13:54,660] [INFO] [controller] EPOCH 4 loss ppo:  -0.07862, loss val: 0.04624
[2022-12-07 10:13:54,670] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:13:54,892] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:13:54,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:14:02,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:14:11,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:14:22,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:14:31,083] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:14:39,490] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:14:47,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:14:55,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:15:03,383] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:15:11,450] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:15:20,395] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7226154158752522
[2022-12-07 10:15:20,396] [INFO] [runner_train_mujoco] Average state value: 0.4700108682612578
[2022-12-07 10:15:20,396] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 10:15:20,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.04605
[2022-12-07 10:15:20,513] [INFO] [controller] EPOCH 2 loss ppo:  -0.03706, loss val: 0.04347
[2022-12-07 10:15:20,569] [INFO] [controller] EPOCH 3 loss ppo:  -0.05241, loss val: 0.04070
[2022-12-07 10:15:20,619] [INFO] [controller] EPOCH 4 loss ppo:  -0.06678, loss val: 0.03800
[2022-12-07 10:15:20,629] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:15:20,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:15:20,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:15:31,686] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:15:42,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:15:51,867] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:16:02,536] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:16:10,964] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:16:19,221] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:16:27,666] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:16:38,095] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:16:47,135] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:16:56,027] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6145752119868555
[2022-12-07 10:16:56,028] [INFO] [runner_train_mujoco] Average state value: 0.41532188399632775
[2022-12-07 10:16:56,028] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 10:16:56,094] [INFO] [controller] EPOCH 1 loss ppo:  -0.01623, loss val: 0.04510
[2022-12-07 10:16:56,145] [INFO] [controller] EPOCH 2 loss ppo:  -0.04189, loss val: 0.04640
[2022-12-07 10:16:56,270] [INFO] [controller] EPOCH 3 loss ppo:  -0.05571, loss val: 0.04505
[2022-12-07 10:16:56,325] [INFO] [controller] EPOCH 4 loss ppo:  -0.07244, loss val: 0.04521
[2022-12-07 10:16:56,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:16:56,601] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:16:56,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:17:05,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:17:14,857] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:17:25,170] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:17:34,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:17:44,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:17:54,450] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:18:08,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:18:18,448] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:18:27,443] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:18:36,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.158215550553891
[2022-12-07 10:18:36,932] [INFO] [runner_train_mujoco] Average state value: 0.36990538258353867
[2022-12-07 10:18:36,932] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 10:18:36,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.04907
[2022-12-07 10:18:37,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.04072, loss val: 0.04916
[2022-12-07 10:18:37,106] [INFO] [controller] EPOCH 3 loss ppo:  -0.05693, loss val: 0.04895
[2022-12-07 10:18:37,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.07033, loss val: 0.04762
[2022-12-07 10:18:37,170] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:18:37,404] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:18:37,405] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:18:46,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:18:56,386] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:19:06,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:19:14,980] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:19:24,321] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:19:33,535] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:19:42,479] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:19:50,841] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:20:00,359] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:20:09,200] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.66791975402037
[2022-12-07 10:20:09,200] [INFO] [runner_train_mujoco] Average state value: 0.3918915231327216
[2022-12-07 10:20:09,200] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 10:20:09,262] [INFO] [controller] EPOCH 1 loss ppo:  -0.01511, loss val: 0.05100
[2022-12-07 10:20:09,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.03865, loss val: 0.05081
[2022-12-07 10:20:09,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.05487, loss val: 0.05248
[2022-12-07 10:20:09,404] [INFO] [controller] EPOCH 4 loss ppo:  -0.06897, loss val: 0.05128
[2022-12-07 10:20:09,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:20:09,661] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:20:09,661] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:20:18,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:20:27,444] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:20:37,007] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:20:46,305] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:20:55,038] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:21:03,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:21:11,756] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:21:20,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:21:28,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:21:37,302] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.435604548598065
[2022-12-07 10:21:37,303] [INFO] [runner_train_mujoco] Average state value: 0.4042125982840856
[2022-12-07 10:21:37,303] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 10:21:37,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.04428
[2022-12-07 10:21:37,434] [INFO] [controller] EPOCH 2 loss ppo:  -0.03493, loss val: 0.04443
[2022-12-07 10:21:37,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.05047, loss val: 0.04407
[2022-12-07 10:21:37,550] [INFO] [controller] EPOCH 4 loss ppo:  -0.06697, loss val: 0.04505
[2022-12-07 10:21:37,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:21:37,798] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:21:37,799] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:21:46,623] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:21:54,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:22:08,809] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:22:20,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:22:28,418] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:22:37,200] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:22:45,191] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:22:53,217] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:23:02,648] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:23:13,600] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.527409105640473
[2022-12-07 10:23:13,600] [INFO] [runner_train_mujoco] Average state value: 0.41719271050890294
[2022-12-07 10:23:13,600] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 10:23:13,702] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.04942
[2022-12-07 10:23:13,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.02959, loss val: 0.04920
[2022-12-07 10:23:13,859] [INFO] [controller] EPOCH 3 loss ppo:  -0.04334, loss val: 0.04688
[2022-12-07 10:23:13,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.05940, loss val: 0.04526
[2022-12-07 10:23:13,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:23:14,171] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:23:14,172] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:23:24,918] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:23:32,790] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:23:41,298] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:23:49,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:23:59,340] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:24:07,980] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:24:17,572] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:24:26,397] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:24:35,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:24:44,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.094290116821588
[2022-12-07 10:24:44,013] [INFO] [runner_train_mujoco] Average state value: 0.4438532942384482
[2022-12-07 10:24:44,014] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 10:24:44,068] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.03804
[2022-12-07 10:24:44,117] [INFO] [controller] EPOCH 2 loss ppo:  -0.03465, loss val: 0.03895
[2022-12-07 10:24:44,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.04899, loss val: 0.03987
[2022-12-07 10:24:44,224] [INFO] [controller] EPOCH 4 loss ppo:  -0.06238, loss val: 0.04032
[2022-12-07 10:24:44,236] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:24:44,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:24:44,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:24:53,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:25:01,301] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:25:10,517] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:25:19,290] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:25:28,177] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:25:36,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:25:45,247] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:25:54,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:26:03,882] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:26:12,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.3152449098411125
[2022-12-07 10:26:12,923] [INFO] [runner_train_mujoco] Average state value: 0.44659574705859023
[2022-12-07 10:26:12,923] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 10:26:12,986] [INFO] [controller] EPOCH 1 loss ppo:  -0.01573, loss val: 0.03481
[2022-12-07 10:26:13,032] [INFO] [controller] EPOCH 2 loss ppo:  -0.03694, loss val: 0.03391
[2022-12-07 10:26:13,080] [INFO] [controller] EPOCH 3 loss ppo:  -0.05044, loss val: 0.03445
[2022-12-07 10:26:13,125] [INFO] [controller] EPOCH 4 loss ppo:  -0.06576, loss val: 0.03375
[2022-12-07 10:26:13,136] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:26:13,368] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:26:13,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:26:23,108] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:26:31,366] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:26:40,350] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:26:48,470] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:26:57,438] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:27:05,578] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:27:15,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:27:26,706] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:27:36,181] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:27:46,962] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.466863286710865
[2022-12-07 10:27:46,962] [INFO] [runner_train_mujoco] Average state value: 0.4338858821342389
[2022-12-07 10:27:46,962] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 10:27:47,026] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.05296
[2022-12-07 10:27:47,075] [INFO] [controller] EPOCH 2 loss ppo:  -0.03015, loss val: 0.05317
[2022-12-07 10:27:47,118] [INFO] [controller] EPOCH 3 loss ppo:  -0.04844, loss val: 0.05381
[2022-12-07 10:27:47,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.06428, loss val: 0.05304
[2022-12-07 10:27:47,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:27:47,429] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:27:47,429] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:27:56,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:28:04,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:28:14,271] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:28:24,966] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:28:35,121] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:28:43,960] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:28:52,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:29:01,623] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:29:10,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:29:20,737] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.078952706077266
[2022-12-07 10:29:20,737] [INFO] [runner_train_mujoco] Average state value: 0.43521371668577197
[2022-12-07 10:29:20,738] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 10:29:20,790] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.05559
[2022-12-07 10:29:20,835] [INFO] [controller] EPOCH 2 loss ppo:  -0.03015, loss val: 0.05538
[2022-12-07 10:29:20,886] [INFO] [controller] EPOCH 3 loss ppo:  -0.04396, loss val: 0.05530
[2022-12-07 10:29:20,931] [INFO] [controller] EPOCH 4 loss ppo:  -0.05550, loss val: 0.05311
[2022-12-07 10:29:20,942] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:29:21,161] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:29:21,162] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:29:29,593] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:29:38,152] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:29:47,730] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:29:57,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:30:07,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:30:15,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:30:24,723] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:30:33,643] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:30:42,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:30:51,963] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.632787823102327
[2022-12-07 10:30:51,963] [INFO] [runner_train_mujoco] Average state value: 0.4441454814573128
[2022-12-07 10:30:51,963] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 10:30:52,038] [INFO] [controller] EPOCH 1 loss ppo:  -0.01258, loss val: 0.04003
[2022-12-07 10:30:52,102] [INFO] [controller] EPOCH 2 loss ppo:  -0.03261, loss val: 0.03803
[2022-12-07 10:30:52,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.04938, loss val: 0.03858
[2022-12-07 10:30:52,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.06274, loss val: 0.03856
[2022-12-07 10:30:52,227] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:30:52,467] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:30:52,467] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:31:01,798] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:31:11,039] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:31:19,584] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:31:28,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:31:37,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:31:48,399] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:31:58,688] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:32:08,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:32:17,793] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:32:27,405] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.6992026316883875
[2022-12-07 10:32:27,405] [INFO] [runner_train_mujoco] Average state value: 0.4369755509098371
[2022-12-07 10:32:27,405] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 10:32:27,489] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.05056
[2022-12-07 10:32:27,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.03491, loss val: 0.04939
[2022-12-07 10:32:27,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.04911, loss val: 0.04947
[2022-12-07 10:32:27,678] [INFO] [controller] EPOCH 4 loss ppo:  -0.06407, loss val: 0.04948
[2022-12-07 10:32:27,691] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:32:27,947] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:32:27,947] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:32:38,041] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:32:49,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:32:59,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:33:08,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:33:18,888] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:33:27,983] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:33:36,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:33:45,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:33:55,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:34:05,351] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.255555929406076
[2022-12-07 10:34:05,351] [INFO] [runner_train_mujoco] Average state value: 0.4393358863691489
[2022-12-07 10:34:05,351] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 10:34:05,419] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.04657
[2022-12-07 10:34:05,474] [INFO] [controller] EPOCH 2 loss ppo:  -0.03022, loss val: 0.04654
[2022-12-07 10:34:05,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.04144, loss val: 0.04519
[2022-12-07 10:34:05,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.05582, loss val: 0.04474
[2022-12-07 10:34:05,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:34:05,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:34:05,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:34:14,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:34:23,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:34:32,143] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:34:40,323] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:34:50,427] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:34:59,873] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:35:08,061] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:35:16,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:35:25,477] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:35:33,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.688655628656249
[2022-12-07 10:35:33,378] [INFO] [runner_train_mujoco] Average state value: 0.39412381546199315
[2022-12-07 10:35:33,378] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 10:35:33,433] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.07113
[2022-12-07 10:35:33,478] [INFO] [controller] EPOCH 2 loss ppo:  -0.02897, loss val: 0.07175
[2022-12-07 10:35:33,524] [INFO] [controller] EPOCH 3 loss ppo:  -0.04168, loss val: 0.07010
[2022-12-07 10:35:33,568] [INFO] [controller] EPOCH 4 loss ppo:  -0.05289, loss val: 0.06885
[2022-12-07 10:35:33,578] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:35:33,802] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:35:33,802] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:35:42,790] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:35:52,300] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:36:01,617] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:36:11,043] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:36:20,394] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:36:28,572] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:36:36,954] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:36:45,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:36:53,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:37:02,031] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.72062633909555
[2022-12-07 10:37:02,032] [INFO] [runner_train_mujoco] Average state value: 0.38724907593180735
[2022-12-07 10:37:02,032] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 10:37:02,098] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.07946
[2022-12-07 10:37:02,146] [INFO] [controller] EPOCH 2 loss ppo:  -0.02854, loss val: 0.07802
[2022-12-07 10:37:02,195] [INFO] [controller] EPOCH 3 loss ppo:  -0.04326, loss val: 0.07573
[2022-12-07 10:37:02,243] [INFO] [controller] EPOCH 4 loss ppo:  -0.05553, loss val: 0.07310
[2022-12-07 10:37:02,255] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:37:02,499] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:37:02,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:37:11,237] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:37:19,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:37:27,627] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:37:36,667] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:37:45,413] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:37:54,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:38:03,889] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:38:13,038] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:38:21,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:38:29,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.83759396883619
[2022-12-07 10:38:29,917] [INFO] [runner_train_mujoco] Average state value: 0.43366383486986165
[2022-12-07 10:38:29,917] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 10:38:29,974] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.04868
[2022-12-07 10:38:30,021] [INFO] [controller] EPOCH 2 loss ppo:  -0.02843, loss val: 0.04787
[2022-12-07 10:38:30,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.04127, loss val: 0.04527
[2022-12-07 10:38:30,117] [INFO] [controller] EPOCH 4 loss ppo:  -0.05201, loss val: 0.05071
[2022-12-07 10:38:30,129] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:38:30,374] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:38:30,374] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:38:40,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:38:50,029] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:38:59,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:39:08,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:39:16,520] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:39:25,083] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:39:33,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:39:41,737] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:39:50,099] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:40:00,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.124363670283321
[2022-12-07 10:40:00,116] [INFO] [runner_train_mujoco] Average state value: 0.47484273765484497
[2022-12-07 10:40:00,117] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 10:40:00,185] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04514
[2022-12-07 10:40:00,234] [INFO] [controller] EPOCH 2 loss ppo:  -0.03188, loss val: 0.04550
[2022-12-07 10:40:00,285] [INFO] [controller] EPOCH 3 loss ppo:  -0.04896, loss val: 0.04537
[2022-12-07 10:40:00,343] [INFO] [controller] EPOCH 4 loss ppo:  -0.05837, loss val: 0.04436
[2022-12-07 10:40:00,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:40:00,596] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:40:00,596] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:40:08,954] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:40:17,411] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:40:25,946] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:40:35,296] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:40:44,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:40:53,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:41:03,007] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:41:11,137] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:41:19,075] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:41:27,012] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.224867312113432
[2022-12-07 10:41:27,012] [INFO] [runner_train_mujoco] Average state value: 0.4725081168115139
[2022-12-07 10:41:27,012] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 10:41:27,077] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.04227
[2022-12-07 10:41:27,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.02752, loss val: 0.04343
[2022-12-07 10:41:27,173] [INFO] [controller] EPOCH 3 loss ppo:  -0.03959, loss val: 0.04161
[2022-12-07 10:41:27,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.04854, loss val: 0.04225
[2022-12-07 10:41:27,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:41:27,463] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:41:27,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:41:35,902] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:41:45,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:41:54,311] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:42:04,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:42:12,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:42:20,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:42:28,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:42:36,501] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:42:45,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:42:54,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.878786240319414
[2022-12-07 10:42:54,515] [INFO] [runner_train_mujoco] Average state value: 0.4640502903287609
[2022-12-07 10:42:54,515] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 10:42:54,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.06393
[2022-12-07 10:42:54,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.02783, loss val: 0.06586
[2022-12-07 10:42:54,744] [INFO] [controller] EPOCH 3 loss ppo:  -0.03923, loss val: 0.06565
[2022-12-07 10:42:54,792] [INFO] [controller] EPOCH 4 loss ppo:  -0.05010, loss val: 0.06478
[2022-12-07 10:42:54,802] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:42:55,042] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:42:55,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:43:04,133] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:43:13,207] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:43:22,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:43:31,843] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:43:40,232] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:43:48,994] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:43:57,510] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:44:06,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:44:15,703] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:44:24,307] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.84483046057821
[2022-12-07 10:44:24,307] [INFO] [runner_train_mujoco] Average state value: 0.46319565350065633
[2022-12-07 10:44:24,307] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 10:44:24,366] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.05014
[2022-12-07 10:44:24,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.02735, loss val: 0.05088
[2022-12-07 10:44:24,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.04021, loss val: 0.05040
[2022-12-07 10:44:24,509] [INFO] [controller] EPOCH 4 loss ppo:  -0.04924, loss val: 0.05247
[2022-12-07 10:44:24,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:44:24,748] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:44:24,748] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:44:33,389] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:44:43,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:44:54,275] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:45:04,957] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:45:13,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:45:21,948] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:45:30,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:45:42,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:45:57,500] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:46:07,453] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.619216694574094
[2022-12-07 10:46:07,454] [INFO] [runner_train_mujoco] Average state value: 0.4854792348444462
[2022-12-07 10:46:07,454] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 10:46:07,561] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.04394
[2022-12-07 10:46:07,657] [INFO] [controller] EPOCH 2 loss ppo:  -0.02861, loss val: 0.04400
[2022-12-07 10:46:07,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.03989, loss val: 0.04264
[2022-12-07 10:46:07,807] [INFO] [controller] EPOCH 4 loss ppo:  -0.04978, loss val: 0.04264
[2022-12-07 10:46:07,820] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:46:08,125] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:46:08,126] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:46:18,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:46:27,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:46:36,158] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:46:46,770] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:46:55,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:47:06,175] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:47:15,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:47:24,354] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:47:33,488] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:47:43,992] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.233921367109804
[2022-12-07 10:47:43,992] [INFO] [runner_train_mujoco] Average state value: 0.479306540141503
[2022-12-07 10:47:43,992] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 10:47:44,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04235
[2022-12-07 10:47:44,114] [INFO] [controller] EPOCH 2 loss ppo:  -0.02424, loss val: 0.04177
[2022-12-07 10:47:44,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.03681, loss val: 0.04223
[2022-12-07 10:47:44,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.04848, loss val: 0.04114
[2022-12-07 10:47:44,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:47:44,465] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:47:44,465] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:47:54,320] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:48:03,367] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:48:14,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:48:23,780] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:48:33,480] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:48:42,747] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:48:51,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:49:01,210] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:49:09,739] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:49:19,763] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.202147176983383
[2022-12-07 10:49:19,763] [INFO] [runner_train_mujoco] Average state value: 0.4692643903791905
[2022-12-07 10:49:19,763] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 10:49:19,827] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04614
[2022-12-07 10:49:19,884] [INFO] [controller] EPOCH 2 loss ppo:  -0.02101, loss val: 0.04359
[2022-12-07 10:49:19,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.02801, loss val: 0.04511
[2022-12-07 10:49:20,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.03589, loss val: 0.04290
[2022-12-07 10:49:20,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:49:20,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:49:20,370] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:49:30,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:49:39,307] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:49:49,069] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:50:01,225] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:50:09,725] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:50:18,672] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:50:27,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:50:36,912] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:50:49,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:50:59,008] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.113878481376342
[2022-12-07 10:50:59,009] [INFO] [runner_train_mujoco] Average state value: 0.44744399849573774
[2022-12-07 10:50:59,009] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 10:50:59,066] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.04431
[2022-12-07 10:50:59,113] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.04410
[2022-12-07 10:50:59,163] [INFO] [controller] EPOCH 3 loss ppo:  -0.03329, loss val: 0.04451
[2022-12-07 10:50:59,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.04092, loss val: 0.04334
[2022-12-07 10:50:59,231] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:50:59,461] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:50:59,462] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:51:08,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:51:17,845] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:51:27,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:51:38,393] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:51:49,625] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:51:59,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:52:09,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:52:20,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:52:31,044] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:52:43,411] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.7285540961608765
[2022-12-07 10:52:43,411] [INFO] [runner_train_mujoco] Average state value: 0.4214554986432195
[2022-12-07 10:52:43,411] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 10:52:43,471] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.05632
[2022-12-07 10:52:43,521] [INFO] [controller] EPOCH 2 loss ppo:  -0.01962, loss val: 0.05669
[2022-12-07 10:52:43,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.03065, loss val: 0.05764
[2022-12-07 10:52:43,635] [INFO] [controller] EPOCH 4 loss ppo:  -0.03936, loss val: 0.05605
[2022-12-07 10:52:43,647] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:52:43,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:52:43,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:52:54,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:53:04,675] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:53:14,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:53:23,757] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:53:33,890] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:53:44,429] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:53:54,334] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:54:03,141] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:54:11,261] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:54:20,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.025037976164609
[2022-12-07 10:54:20,570] [INFO] [runner_train_mujoco] Average state value: 0.4151710183471441
[2022-12-07 10:54:20,571] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 10:54:20,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.05407
[2022-12-07 10:54:20,671] [INFO] [controller] EPOCH 2 loss ppo:  -0.01877, loss val: 0.05261
[2022-12-07 10:54:20,719] [INFO] [controller] EPOCH 3 loss ppo:  -0.02842, loss val: 0.05266
[2022-12-07 10:54:20,767] [INFO] [controller] EPOCH 4 loss ppo:  -0.03766, loss val: 0.05236
[2022-12-07 10:54:20,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:54:20,997] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:54:20,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:54:30,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:54:39,611] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:54:49,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:54:58,701] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:55:07,310] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:55:15,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:55:23,978] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:55:33,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:55:43,686] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:55:52,573] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.201283361828525
[2022-12-07 10:55:52,573] [INFO] [runner_train_mujoco] Average state value: 0.4399308103869359
[2022-12-07 10:55:52,573] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 10:55:52,631] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.03730
[2022-12-07 10:55:52,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.01568, loss val: 0.03564
[2022-12-07 10:55:52,725] [INFO] [controller] EPOCH 3 loss ppo:  -0.02077, loss val: 0.03564
[2022-12-07 10:55:52,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.02806, loss val: 0.03494
[2022-12-07 10:55:52,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:55:52,995] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:55:52,996] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:56:03,404] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:56:11,387] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:56:22,098] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:56:34,571] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:56:45,313] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:56:53,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:57:02,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:57:11,390] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:57:20,171] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:57:28,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.148094836497024
[2022-12-07 10:57:28,273] [INFO] [runner_train_mujoco] Average state value: 0.4419334178268909
[2022-12-07 10:57:28,273] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 10:57:28,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04823
[2022-12-07 10:57:28,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.01675, loss val: 0.04766
[2022-12-07 10:57:28,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.02145, loss val: 0.04768
[2022-12-07 10:57:28,521] [INFO] [controller] EPOCH 4 loss ppo:  -0.02747, loss val: 0.04856
[2022-12-07 10:57:28,540] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:57:28,768] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:57:28,768] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:57:41,479] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:57:50,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:58:01,566] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:58:13,843] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:58:22,158] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:58:31,918] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:58:40,946] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:58:51,638] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:59:00,902] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:59:10,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.589541217418852
[2022-12-07 10:59:10,273] [INFO] [runner_train_mujoco] Average state value: 0.4425011224647363
[2022-12-07 10:59:10,273] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 10:59:10,362] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04706
[2022-12-07 10:59:10,428] [INFO] [controller] EPOCH 2 loss ppo:  -0.01527, loss val: 0.04708
[2022-12-07 10:59:10,483] [INFO] [controller] EPOCH 3 loss ppo:  -0.01789, loss val: 0.04708
[2022-12-07 10:59:10,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.02138, loss val: 0.04729
[2022-12-07 10:59:10,547] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:59:10,692] [INFO] [optimize] Finished learning.
