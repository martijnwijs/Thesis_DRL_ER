[2022-12-06 19:40:57,793] [INFO] [optimize] Starting learning
[2022-12-06 19:40:57,824] [INFO] [optimize] Starting learning process..
[2022-12-06 19:40:58,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:40:58,032] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:41:14,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:41:29,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:41:45,735] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:42:01,977] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:42:17,987] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:42:34,582] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:42:51,654] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:43:09,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:43:29,591] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:43:47,312] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6576796187219547
[2022-12-06 19:43:47,312] [INFO] [runner_train_mujoco] Average state value: -0.28679670102645954
[2022-12-06 19:43:47,312] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 19:43:47,410] [INFO] [controller] EPOCH 1 loss ppo:  -0.01249, loss val: 0.59704
[2022-12-06 19:43:47,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.05183, loss val: 0.55675
[2022-12-06 19:43:47,582] [INFO] [controller] EPOCH 3 loss ppo:  -0.06881, loss val: 0.50671
[2022-12-06 19:43:47,662] [INFO] [controller] EPOCH 4 loss ppo:  -0.08198, loss val: 0.44116
[2022-12-06 19:43:47,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:43:48,013] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:43:48,013] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:44:06,278] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:44:20,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:44:33,905] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:44:47,652] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:45:01,553] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:45:15,091] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:45:28,233] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:45:41,113] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:45:53,509] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:46:07,863] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5076618539218349
[2022-12-06 19:46:07,863] [INFO] [runner_train_mujoco] Average state value: -0.12408570632711054
[2022-12-06 19:46:07,863] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 19:46:07,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.54095
[2022-12-06 19:46:08,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.04879, loss val: 0.48776
[2022-12-06 19:46:08,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.06901, loss val: 0.42434
[2022-12-06 19:46:08,151] [INFO] [controller] EPOCH 4 loss ppo:  -0.08014, loss val: 0.38496
[2022-12-06 19:46:08,164] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:46:08,469] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:46:08,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:46:20,873] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:46:32,720] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:46:44,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:46:57,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:47:10,002] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:47:21,790] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:47:33,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:47:44,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:47:55,087] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:48:08,739] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5330860448784711
[2022-12-06 19:48:08,739] [INFO] [runner_train_mujoco] Average state value: 0.0579252006871005
[2022-12-06 19:48:08,739] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 19:48:09,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01275, loss val: 0.26030
[2022-12-06 19:48:09,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.04541, loss val: 0.23515
[2022-12-06 19:48:09,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.06588, loss val: 0.19637
[2022-12-06 19:48:09,537] [INFO] [controller] EPOCH 4 loss ppo:  -0.07750, loss val: 0.17717
[2022-12-06 19:48:09,549] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:48:09,840] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:48:09,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:48:21,692] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:48:33,456] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:48:44,940] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:48:56,435] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:49:08,124] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:49:19,757] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:49:31,743] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:49:43,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:49:56,053] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:50:08,293] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6401450470963427
[2022-12-06 19:50:08,293] [INFO] [runner_train_mujoco] Average state value: 0.2222799041097363
[2022-12-06 19:50:08,294] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 19:50:08,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.19146
[2022-12-06 19:50:08,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.04524, loss val: 0.16995
[2022-12-06 19:50:08,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.06404, loss val: 0.14886
[2022-12-06 19:50:08,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.07829, loss val: 0.12815
[2022-12-06 19:50:08,591] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:50:08,888] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:50:08,889] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:50:21,435] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:50:32,822] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:50:44,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:50:54,861] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:51:05,935] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:51:16,809] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:51:27,951] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:51:38,335] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:51:49,167] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:52:00,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6429117370167308
[2022-12-06 19:52:00,070] [INFO] [runner_train_mujoco] Average state value: 0.3678858238173028
[2022-12-06 19:52:00,070] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 19:52:00,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.08857
[2022-12-06 19:52:00,205] [INFO] [controller] EPOCH 2 loss ppo:  -0.04944, loss val: 0.08011
[2022-12-06 19:52:00,263] [INFO] [controller] EPOCH 3 loss ppo:  -0.06904, loss val: 0.07076
[2022-12-06 19:52:00,319] [INFO] [controller] EPOCH 4 loss ppo:  -0.08111, loss val: 0.06471
[2022-12-06 19:52:00,332] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:52:00,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:52:00,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:52:11,861] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:52:22,241] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:52:32,274] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:52:42,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:52:52,517] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:53:03,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:53:13,469] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:53:23,627] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:53:33,159] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:53:43,685] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3603904999561183
[2022-12-06 19:53:43,685] [INFO] [runner_train_mujoco] Average state value: 0.46154711179062724
[2022-12-06 19:53:43,685] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 19:53:43,756] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.06873
[2022-12-06 19:53:43,814] [INFO] [controller] EPOCH 2 loss ppo:  -0.04675, loss val: 0.06489
[2022-12-06 19:53:43,872] [INFO] [controller] EPOCH 3 loss ppo:  -0.06781, loss val: 0.06047
[2022-12-06 19:53:43,925] [INFO] [controller] EPOCH 4 loss ppo:  -0.07954, loss val: 0.05751
[2022-12-06 19:53:43,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:53:44,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:53:44,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:53:54,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:54:04,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:54:14,673] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:54:24,795] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:54:34,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:54:44,012] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:54:54,060] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:55:02,905] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:55:12,403] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:55:22,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5655881229384075
[2022-12-06 19:55:22,147] [INFO] [runner_train_mujoco] Average state value: 0.5189374135881663
[2022-12-06 19:55:22,147] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 19:55:22,241] [INFO] [controller] EPOCH 1 loss ppo:  -0.01195, loss val: 0.06243
[2022-12-06 19:55:22,316] [INFO] [controller] EPOCH 2 loss ppo:  -0.04430, loss val: 0.06067
[2022-12-06 19:55:22,398] [INFO] [controller] EPOCH 3 loss ppo:  -0.05886, loss val: 0.05623
[2022-12-06 19:55:22,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.07176, loss val: 0.05310
[2022-12-06 19:55:22,463] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:55:22,699] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:55:22,699] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:55:32,746] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:55:44,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:55:55,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:56:04,514] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:56:13,524] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:56:22,634] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:56:31,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:56:41,422] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:56:51,221] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:57:01,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6403368766228531
[2022-12-06 19:57:01,167] [INFO] [runner_train_mujoco] Average state value: 0.5423259868746003
[2022-12-06 19:57:01,167] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 19:57:01,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.05294
[2022-12-06 19:57:01,295] [INFO] [controller] EPOCH 2 loss ppo:  -0.04492, loss val: 0.05127
[2022-12-06 19:57:01,340] [INFO] [controller] EPOCH 3 loss ppo:  -0.05948, loss val: 0.05148
[2022-12-06 19:57:01,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.06991, loss val: 0.04885
[2022-12-06 19:57:01,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:57:01,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:57:01,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:57:11,409] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:57:20,473] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:57:29,641] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:57:38,542] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:57:46,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:57:54,692] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:58:02,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:58:09,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:58:17,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:58:25,493] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6351409161123815
[2022-12-06 19:58:25,493] [INFO] [runner_train_mujoco] Average state value: 0.5631225896179677
[2022-12-06 19:58:25,493] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 19:58:25,545] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.04743
[2022-12-06 19:58:25,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.04627, loss val: 0.04955
[2022-12-06 19:58:25,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.06261, loss val: 0.04798
[2022-12-06 19:58:25,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.07524, loss val: 0.04528
[2022-12-06 19:58:25,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:58:25,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:58:25,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:58:33,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:58:40,455] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:58:47,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:58:54,636] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:59:01,729] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:59:08,809] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:59:15,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:59:22,894] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:59:29,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:59:37,333] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5836999581530022
[2022-12-06 19:59:37,334] [INFO] [runner_train_mujoco] Average state value: 0.5285397890607516
[2022-12-06 19:59:37,334] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 19:59:37,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.04085
[2022-12-06 19:59:37,422] [INFO] [controller] EPOCH 2 loss ppo:  -0.04839, loss val: 0.04025
[2022-12-06 19:59:37,458] [INFO] [controller] EPOCH 3 loss ppo:  -0.06517, loss val: 0.04090
[2022-12-06 19:59:37,499] [INFO] [controller] EPOCH 4 loss ppo:  -0.07576, loss val: 0.04059
[2022-12-06 19:59:37,508] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:59:37,712] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:59:37,712] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:59:45,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:59:53,835] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:00:00,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:00:08,113] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:00:15,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:00:22,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:00:30,024] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:00:37,987] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:00:45,430] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:00:52,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5775121159372848
[2022-12-06 20:00:52,521] [INFO] [runner_train_mujoco] Average state value: 0.5036641186277071
[2022-12-06 20:00:52,521] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 20:00:52,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01048, loss val: 0.03941
[2022-12-06 20:00:52,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.03944, loss val: 0.03862
[2022-12-06 20:00:52,664] [INFO] [controller] EPOCH 3 loss ppo:  -0.05910, loss val: 0.03900
[2022-12-06 20:00:52,704] [INFO] [controller] EPOCH 4 loss ppo:  -0.07046, loss val: 0.03514
[2022-12-06 20:00:52,713] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:00:52,931] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:00:52,932] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:01:00,520] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:01:08,261] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:01:15,761] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:01:23,337] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:01:31,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:01:38,521] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:01:46,118] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:01:53,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:02:01,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:02:08,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7934077855718132
[2022-12-06 20:02:08,894] [INFO] [runner_train_mujoco] Average state value: 0.4573375159402688
[2022-12-06 20:02:08,894] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 20:02:08,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01157, loss val: 0.03584
[2022-12-06 20:02:08,990] [INFO] [controller] EPOCH 2 loss ppo:  -0.04350, loss val: 0.03596
[2022-12-06 20:02:09,027] [INFO] [controller] EPOCH 3 loss ppo:  -0.06139, loss val: 0.03633
[2022-12-06 20:02:09,066] [INFO] [controller] EPOCH 4 loss ppo:  -0.07272, loss val: 0.03561
[2022-12-06 20:02:09,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:02:09,286] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:02:09,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:02:17,143] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:02:24,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:02:32,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:02:40,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:02:48,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:02:55,667] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:03:03,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:03:10,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:03:18,352] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:03:26,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.052599868019787
[2022-12-06 20:03:26,305] [INFO] [runner_train_mujoco] Average state value: 0.4399330944915613
[2022-12-06 20:03:26,305] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 20:03:26,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.04390
[2022-12-06 20:03:26,405] [INFO] [controller] EPOCH 2 loss ppo:  -0.04209, loss val: 0.04213
[2022-12-06 20:03:26,452] [INFO] [controller] EPOCH 3 loss ppo:  -0.05840, loss val: 0.04000
[2022-12-06 20:03:26,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.07026, loss val: 0.03726
[2022-12-06 20:03:26,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:03:26,717] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:03:26,718] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:03:34,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:03:42,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:03:49,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:03:57,110] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:04:04,487] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:04:11,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:04:19,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:04:26,967] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:04:34,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:04:41,325] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3707573568672942
[2022-12-06 20:04:41,325] [INFO] [runner_train_mujoco] Average state value: 0.4998930043876172
[2022-12-06 20:04:41,325] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 20:04:41,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.05745
[2022-12-06 20:04:41,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.04273, loss val: 0.05925
[2022-12-06 20:04:41,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.05945, loss val: 0.05914
[2022-12-06 20:04:41,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.06857, loss val: 0.05735
[2022-12-06 20:04:41,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:04:41,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:04:41,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:04:48,850] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:04:56,903] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:05:05,350] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:05:13,012] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:05:20,018] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:05:27,088] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:05:34,292] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:05:41,552] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:05:49,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:05:56,270] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8830169932013419
[2022-12-06 20:05:56,271] [INFO] [runner_train_mujoco] Average state value: 0.48772429730246464
[2022-12-06 20:05:56,271] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 20:05:56,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01561, loss val: 0.04554
[2022-12-06 20:05:56,364] [INFO] [controller] EPOCH 2 loss ppo:  -0.04602, loss val: 0.04220
[2022-12-06 20:05:56,407] [INFO] [controller] EPOCH 3 loss ppo:  -0.06302, loss val: 0.03728
[2022-12-06 20:05:56,451] [INFO] [controller] EPOCH 4 loss ppo:  -0.07706, loss val: 0.03442
[2022-12-06 20:05:56,461] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:05:56,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:05:56,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:06:04,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:06:11,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:06:18,791] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:06:25,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:06:32,727] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:06:39,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:06:47,433] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:06:54,417] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:07:01,911] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:07:10,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8015188610423027
[2022-12-06 20:07:10,390] [INFO] [runner_train_mujoco] Average state value: 0.40413383442163464
[2022-12-06 20:07:10,390] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 20:07:10,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.04356
[2022-12-06 20:07:10,491] [INFO] [controller] EPOCH 2 loss ppo:  -0.04481, loss val: 0.05150
[2022-12-06 20:07:10,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.05974, loss val: 0.04700
[2022-12-06 20:07:10,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.07206, loss val: 0.04560
[2022-12-06 20:07:10,598] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:07:10,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:07:10,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:07:18,438] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:07:25,615] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:07:32,758] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:07:39,998] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:07:47,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:07:55,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:08:02,656] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:08:09,913] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:08:17,103] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:08:24,311] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.499162160358565
[2022-12-06 20:08:24,312] [INFO] [runner_train_mujoco] Average state value: 0.3873018393268188
[2022-12-06 20:08:24,312] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 20:08:24,363] [INFO] [controller] EPOCH 1 loss ppo:  -0.01852, loss val: 0.05931
[2022-12-06 20:08:24,399] [INFO] [controller] EPOCH 2 loss ppo:  -0.05054, loss val: 0.05551
[2022-12-06 20:08:24,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.06516, loss val: 0.05383
[2022-12-06 20:08:24,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.07625, loss val: 0.05021
[2022-12-06 20:08:24,491] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:08:24,686] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:08:24,686] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:08:31,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:08:38,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:08:46,881] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:08:54,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:09:01,402] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:09:08,906] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:09:16,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:09:23,513] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:09:30,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:09:37,921] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0861469107046573
[2022-12-06 20:09:37,921] [INFO] [runner_train_mujoco] Average state value: 0.44029864468177154
[2022-12-06 20:09:37,921] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 20:09:37,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01565, loss val: 0.04919
[2022-12-06 20:09:38,016] [INFO] [controller] EPOCH 2 loss ppo:  -0.04842, loss val: 0.04822
[2022-12-06 20:09:38,062] [INFO] [controller] EPOCH 3 loss ppo:  -0.06699, loss val: 0.04825
[2022-12-06 20:09:38,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.07978, loss val: 0.04950
[2022-12-06 20:09:38,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:09:38,330] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:09:38,331] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:09:45,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:09:53,236] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:10:00,911] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:10:08,390] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:10:15,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:10:23,060] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:10:30,307] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:10:38,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:10:45,734] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:10:53,282] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.160273801981611
[2022-12-06 20:10:53,282] [INFO] [runner_train_mujoco] Average state value: 0.4774401600658894
[2022-12-06 20:10:53,282] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 20:10:53,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01704, loss val: 0.03824
[2022-12-06 20:10:53,394] [INFO] [controller] EPOCH 2 loss ppo:  -0.04635, loss val: 0.03823
[2022-12-06 20:10:53,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.06244, loss val: 0.03745
[2022-12-06 20:10:53,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.07917, loss val: 0.03782
[2022-12-06 20:10:53,506] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:10:53,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:10:53,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:11:01,434] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:11:08,934] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:11:16,289] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:11:23,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:11:31,540] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:11:40,622] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:11:48,556] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:11:55,559] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:12:02,825] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:12:09,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.286362669068314
[2022-12-06 20:12:09,983] [INFO] [runner_train_mujoco] Average state value: 0.48113697190086036
[2022-12-06 20:12:09,983] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 20:12:10,054] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.03530
[2022-12-06 20:12:10,101] [INFO] [controller] EPOCH 2 loss ppo:  -0.04383, loss val: 0.03955
[2022-12-06 20:12:10,150] [INFO] [controller] EPOCH 3 loss ppo:  -0.06361, loss val: 0.03475
[2022-12-06 20:12:10,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.08107, loss val: 0.03431
[2022-12-06 20:12:10,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:12:10,416] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:12:10,416] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:12:18,189] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:12:25,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:12:33,332] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:12:40,807] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:12:48,162] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:12:55,395] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:13:03,952] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:13:11,185] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:13:19,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:13:26,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.528918996876806
[2022-12-06 20:13:26,477] [INFO] [runner_train_mujoco] Average state value: 0.45601989831527073
[2022-12-06 20:13:26,477] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 20:13:26,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.04236
[2022-12-06 20:13:26,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.04249, loss val: 0.04203
[2022-12-06 20:13:26,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.06121, loss val: 0.04102
[2022-12-06 20:13:26,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.07714, loss val: 0.04265
[2022-12-06 20:13:26,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:13:26,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:13:26,869] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:13:34,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:13:41,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:13:48,572] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:13:56,008] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:14:03,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:14:11,943] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:14:19,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:14:26,494] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:14:33,514] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:14:40,336] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5700884013107155
[2022-12-06 20:14:40,336] [INFO] [runner_train_mujoco] Average state value: 0.43302344848712293
[2022-12-06 20:14:40,337] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 20:14:40,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01676, loss val: 0.04120
[2022-12-06 20:14:40,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.04282, loss val: 0.04003
[2022-12-06 20:14:40,465] [INFO] [controller] EPOCH 3 loss ppo:  -0.06191, loss val: 0.03980
[2022-12-06 20:14:40,509] [INFO] [controller] EPOCH 4 loss ppo:  -0.07311, loss val: 0.04020
[2022-12-06 20:14:40,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:14:40,727] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:14:40,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:14:47,937] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:14:55,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:15:02,048] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:15:09,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:15:16,577] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:15:24,045] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:15:31,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:15:38,789] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:15:45,911] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:15:53,622] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.749179958793316
[2022-12-06 20:15:53,622] [INFO] [runner_train_mujoco] Average state value: 0.41065835127234457
[2022-12-06 20:15:53,623] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 20:15:53,679] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.06478
[2022-12-06 20:15:53,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.03781, loss val: 0.06194
[2022-12-06 20:15:53,760] [INFO] [controller] EPOCH 3 loss ppo:  -0.05459, loss val: 0.06403
[2022-12-06 20:15:53,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.06826, loss val: 0.05682
[2022-12-06 20:15:53,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:15:53,997] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:15:53,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:16:00,822] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:16:08,630] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:16:15,528] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:16:22,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:16:30,365] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:16:38,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:16:45,320] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:16:52,510] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:16:59,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:17:07,320] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.698604341174548
[2022-12-06 20:17:07,321] [INFO] [runner_train_mujoco] Average state value: 0.4498737127681573
[2022-12-06 20:17:07,321] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 20:17:07,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01643, loss val: 0.04831
[2022-12-06 20:17:07,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.04446, loss val: 0.04724
[2022-12-06 20:17:07,466] [INFO] [controller] EPOCH 3 loss ppo:  -0.06388, loss val: 0.04764
[2022-12-06 20:17:07,514] [INFO] [controller] EPOCH 4 loss ppo:  -0.07952, loss val: 0.04766
[2022-12-06 20:17:07,524] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:17:07,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:17:07,737] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:17:14,966] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:17:22,155] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:17:29,144] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:17:36,173] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:17:45,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:17:52,245] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:17:59,739] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:18:06,675] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:18:13,678] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:18:20,859] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5267980178170095
[2022-12-06 20:18:20,859] [INFO] [runner_train_mujoco] Average state value: 0.48491928245623905
[2022-12-06 20:18:20,859] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 20:18:20,928] [INFO] [controller] EPOCH 1 loss ppo:  -0.01628, loss val: 0.04743
[2022-12-06 20:18:20,973] [INFO] [controller] EPOCH 2 loss ppo:  -0.04551, loss val: 0.04713
[2022-12-06 20:18:21,022] [INFO] [controller] EPOCH 3 loss ppo:  -0.06165, loss val: 0.04673
[2022-12-06 20:18:21,071] [INFO] [controller] EPOCH 4 loss ppo:  -0.07914, loss val: 0.04552
[2022-12-06 20:18:21,080] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:18:21,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:18:21,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:18:28,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:18:35,978] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:18:43,176] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:18:50,633] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:18:58,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:19:07,503] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:19:15,343] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:19:23,592] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:19:31,279] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:19:38,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.399427522517145
[2022-12-06 20:19:38,544] [INFO] [runner_train_mujoco] Average state value: 0.46895103055238724
[2022-12-06 20:19:38,544] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 20:19:38,599] [INFO] [controller] EPOCH 1 loss ppo:  -0.01692, loss val: 0.03179
[2022-12-06 20:19:38,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.04138, loss val: 0.03236
[2022-12-06 20:19:38,692] [INFO] [controller] EPOCH 3 loss ppo:  -0.05777, loss val: 0.03127
[2022-12-06 20:19:38,739] [INFO] [controller] EPOCH 4 loss ppo:  -0.07427, loss val: 0.03132
[2022-12-06 20:19:38,749] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:19:38,961] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:19:38,962] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:19:46,507] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:19:53,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:20:00,153] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:20:06,602] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:20:13,315] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:20:20,223] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:20:26,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:20:33,403] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:20:39,822] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:20:46,279] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.356816424698138
[2022-12-06 20:20:46,279] [INFO] [runner_train_mujoco] Average state value: 0.4485299658576647
[2022-12-06 20:20:46,279] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 20:20:46,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01631, loss val: 0.04627
[2022-12-06 20:20:46,373] [INFO] [controller] EPOCH 2 loss ppo:  -0.03964, loss val: 0.04718
[2022-12-06 20:20:46,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.05990, loss val: 0.04589
[2022-12-06 20:20:46,448] [INFO] [controller] EPOCH 4 loss ppo:  -0.07381, loss val: 0.04621
[2022-12-06 20:20:46,457] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:20:46,659] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:20:46,660] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:20:53,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:20:59,728] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:21:06,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:21:12,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:21:19,582] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:21:26,368] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:21:32,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:21:39,298] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:21:45,834] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:21:52,030] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.030611532930851
[2022-12-06 20:21:52,030] [INFO] [runner_train_mujoco] Average state value: 0.43805661343534785
[2022-12-06 20:21:52,030] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 20:21:52,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.03213
[2022-12-06 20:21:52,115] [INFO] [controller] EPOCH 2 loss ppo:  -0.04608, loss val: 0.03199
[2022-12-06 20:21:52,151] [INFO] [controller] EPOCH 3 loss ppo:  -0.06280, loss val: 0.03362
[2022-12-06 20:21:52,186] [INFO] [controller] EPOCH 4 loss ppo:  -0.07279, loss val: 0.03656
[2022-12-06 20:21:52,195] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:21:52,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:21:52,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:21:58,807] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:22:05,349] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:22:11,772] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:22:18,211] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:22:24,658] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:22:30,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:22:38,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:22:44,961] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:22:51,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:22:57,396] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.14390488411703
[2022-12-06 20:22:57,397] [INFO] [runner_train_mujoco] Average state value: 0.4540452574888866
[2022-12-06 20:22:57,397] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 20:22:57,443] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.03734
[2022-12-06 20:22:57,479] [INFO] [controller] EPOCH 2 loss ppo:  -0.04115, loss val: 0.03808
[2022-12-06 20:22:57,519] [INFO] [controller] EPOCH 3 loss ppo:  -0.05852, loss val: 0.03793
[2022-12-06 20:22:57,560] [INFO] [controller] EPOCH 4 loss ppo:  -0.06928, loss val: 0.03793
[2022-12-06 20:22:57,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:22:57,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:22:57,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:23:04,622] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:23:10,972] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:23:17,260] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:23:23,589] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:23:30,566] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:23:37,107] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:23:43,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:23:50,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:23:56,696] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:24:02,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.963347532850452
[2022-12-06 20:24:02,983] [INFO] [runner_train_mujoco] Average state value: 0.44912117077906927
[2022-12-06 20:24:02,983] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 20:24:03,033] [INFO] [controller] EPOCH 1 loss ppo:  -0.01518, loss val: 0.03459
[2022-12-06 20:24:03,077] [INFO] [controller] EPOCH 2 loss ppo:  -0.03700, loss val: 0.03476
[2022-12-06 20:24:03,122] [INFO] [controller] EPOCH 3 loss ppo:  -0.05458, loss val: 0.03554
[2022-12-06 20:24:03,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.06946, loss val: 0.03499
[2022-12-06 20:24:03,173] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:24:03,327] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:24:03,327] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:24:09,766] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:24:16,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:24:22,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:24:29,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:24:35,917] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:24:42,462] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:24:49,066] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:24:55,960] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:25:02,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:25:09,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.456647952510804
[2022-12-06 20:25:09,214] [INFO] [runner_train_mujoco] Average state value: 0.4485446242590746
[2022-12-06 20:25:09,215] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 20:25:09,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01580, loss val: 0.03458
[2022-12-06 20:25:09,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.04089, loss val: 0.03453
[2022-12-06 20:25:09,391] [INFO] [controller] EPOCH 3 loss ppo:  -0.05651, loss val: 0.03421
[2022-12-06 20:25:09,433] [INFO] [controller] EPOCH 4 loss ppo:  -0.07426, loss val: 0.03437
[2022-12-06 20:25:09,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:25:09,635] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:25:09,635] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:25:16,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:25:22,753] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:25:29,270] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:25:35,661] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:25:42,382] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:25:48,827] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:25:55,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:26:02,960] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:26:09,706] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:26:16,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.624618790710784
[2022-12-06 20:26:16,116] [INFO] [runner_train_mujoco] Average state value: 0.4780535228649775
[2022-12-06 20:26:16,117] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 20:26:16,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.04366
[2022-12-06 20:26:16,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.03190, loss val: 0.05029
[2022-12-06 20:26:16,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.04504, loss val: 0.04311
[2022-12-06 20:26:16,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.05842, loss val: 0.04369
[2022-12-06 20:26:16,278] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:26:16,451] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:26:16,452] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:26:22,919] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:26:29,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:26:36,315] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:26:42,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:26:49,837] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:26:56,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:27:02,408] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:27:08,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:27:15,425] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:27:22,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.6907502258065445
[2022-12-06 20:27:22,218] [INFO] [runner_train_mujoco] Average state value: 0.4571316951811313
[2022-12-06 20:27:22,219] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 20:27:22,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.05737
[2022-12-06 20:27:22,303] [INFO] [controller] EPOCH 2 loss ppo:  -0.03757, loss val: 0.05555
[2022-12-06 20:27:22,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.05298, loss val: 0.05525
[2022-12-06 20:27:22,376] [INFO] [controller] EPOCH 4 loss ppo:  -0.06835, loss val: 0.05417
[2022-12-06 20:27:22,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:27:22,543] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:27:22,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:27:29,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:27:36,015] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:27:42,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:27:48,784] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:27:55,225] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:28:01,452] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:28:08,746] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:28:15,092] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:28:21,382] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:28:27,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.736280242053512
[2022-12-06 20:28:27,799] [INFO] [runner_train_mujoco] Average state value: 0.35668488961209854
[2022-12-06 20:28:27,799] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 20:28:27,843] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.09112
[2022-12-06 20:28:27,882] [INFO] [controller] EPOCH 2 loss ppo:  -0.03282, loss val: 0.09168
[2022-12-06 20:28:27,934] [INFO] [controller] EPOCH 3 loss ppo:  -0.04770, loss val: 0.09014
[2022-12-06 20:28:27,977] [INFO] [controller] EPOCH 4 loss ppo:  -0.06087, loss val: 0.08920
[2022-12-06 20:28:27,986] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:28:28,155] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:28:28,155] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:28:34,293] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:28:40,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:28:46,509] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:28:52,714] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:28:58,940] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:29:05,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:29:11,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:29:17,902] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:29:24,715] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:29:31,707] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.722946165371944
[2022-12-06 20:29:31,708] [INFO] [runner_train_mujoco] Average state value: 0.4279935676356157
[2022-12-06 20:29:31,708] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 20:29:31,757] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04527
[2022-12-06 20:29:31,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.03617, loss val: 0.04622
[2022-12-06 20:29:31,843] [INFO] [controller] EPOCH 3 loss ppo:  -0.05348, loss val: 0.04540
[2022-12-06 20:29:31,883] [INFO] [controller] EPOCH 4 loss ppo:  -0.07006, loss val: 0.04613
[2022-12-06 20:29:31,892] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:29:32,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:29:32,074] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:29:38,787] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:29:45,270] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:29:51,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:29:59,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:30:05,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:30:12,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:30:18,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:30:24,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:30:31,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:30:38,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.74697594419091
[2022-12-06 20:30:38,440] [INFO] [runner_train_mujoco] Average state value: 0.4341370823283991
[2022-12-06 20:30:38,440] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 20:30:38,486] [INFO] [controller] EPOCH 1 loss ppo:  -0.01655, loss val: 0.05889
[2022-12-06 20:30:38,528] [INFO] [controller] EPOCH 2 loss ppo:  -0.03467, loss val: 0.05469
[2022-12-06 20:30:38,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.04552, loss val: 0.05317
[2022-12-06 20:30:38,611] [INFO] [controller] EPOCH 4 loss ppo:  -0.05936, loss val: 0.05162
[2022-12-06 20:30:38,620] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:30:38,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:30:38,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:30:45,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:30:52,035] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:30:58,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:31:05,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:31:11,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:31:18,209] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:31:24,661] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:31:31,047] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:31:38,892] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:31:45,875] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.108414589876001
[2022-12-06 20:31:45,875] [INFO] [runner_train_mujoco] Average state value: 0.4702193417946498
[2022-12-06 20:31:45,875] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 20:31:45,926] [INFO] [controller] EPOCH 1 loss ppo:  -0.01631, loss val: 0.05961
[2022-12-06 20:31:45,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.03293, loss val: 0.06146
[2022-12-06 20:31:46,009] [INFO] [controller] EPOCH 3 loss ppo:  -0.04419, loss val: 0.06046
[2022-12-06 20:31:46,052] [INFO] [controller] EPOCH 4 loss ppo:  -0.05616, loss val: 0.05964
[2022-12-06 20:31:46,062] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:31:46,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:31:46,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:31:52,832] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:31:59,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:32:05,543] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:32:12,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:32:19,216] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:32:26,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:32:32,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:32:39,277] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:32:45,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:32:52,220] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.109430230452304
[2022-12-06 20:32:52,220] [INFO] [runner_train_mujoco] Average state value: 0.46008862624565766
[2022-12-06 20:32:52,220] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 20:32:52,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.04008
[2022-12-06 20:32:52,323] [INFO] [controller] EPOCH 2 loss ppo:  -0.03518, loss val: 0.04252
[2022-12-06 20:32:52,366] [INFO] [controller] EPOCH 3 loss ppo:  -0.05436, loss val: 0.04102
[2022-12-06 20:32:52,408] [INFO] [controller] EPOCH 4 loss ppo:  -0.06375, loss val: 0.04040
[2022-12-06 20:32:52,417] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:32:52,615] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:32:52,616] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:32:59,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:33:05,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:33:12,101] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:33:18,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:33:24,596] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:33:31,001] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:33:37,078] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:33:43,701] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:33:49,746] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:33:55,957] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.607087650226697
[2022-12-06 20:33:55,957] [INFO] [runner_train_mujoco] Average state value: 0.4603730704387029
[2022-12-06 20:33:55,957] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 20:33:55,998] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.03556
[2022-12-06 20:33:56,038] [INFO] [controller] EPOCH 2 loss ppo:  -0.03467, loss val: 0.03471
[2022-12-06 20:33:56,069] [INFO] [controller] EPOCH 3 loss ppo:  -0.05173, loss val: 0.03357
[2022-12-06 20:33:56,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.06863, loss val: 0.03350
[2022-12-06 20:33:56,115] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:33:56,284] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:33:56,284] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:34:02,960] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:34:09,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:34:15,658] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:34:21,908] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:34:28,116] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:34:34,442] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:34:40,433] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:34:46,479] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:34:52,569] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:34:58,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.6329793640467845
[2022-12-06 20:34:58,981] [INFO] [runner_train_mujoco] Average state value: 0.4971094242197772
[2022-12-06 20:34:58,981] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 20:34:59,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.03603
[2022-12-06 20:34:59,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.03001, loss val: 0.03553
[2022-12-06 20:34:59,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.04577, loss val: 0.03585
[2022-12-06 20:34:59,152] [INFO] [controller] EPOCH 4 loss ppo:  -0.05829, loss val: 0.03536
[2022-12-06 20:34:59,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:34:59,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:34:59,359] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:35:06,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:35:12,569] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:35:19,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:35:25,424] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:35:31,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:35:38,225] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:35:44,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:35:50,548] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:35:56,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:36:03,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.93763682569264
[2022-12-06 20:36:03,127] [INFO] [runner_train_mujoco] Average state value: 0.49404105306168394
[2022-12-06 20:36:03,127] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 20:36:03,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.05055
[2022-12-06 20:36:03,212] [INFO] [controller] EPOCH 2 loss ppo:  -0.02468, loss val: 0.05036
[2022-12-06 20:36:03,245] [INFO] [controller] EPOCH 3 loss ppo:  -0.04348, loss val: 0.05035
[2022-12-06 20:36:03,287] [INFO] [controller] EPOCH 4 loss ppo:  -0.05851, loss val: 0.05028
[2022-12-06 20:36:03,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:36:03,512] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:36:03,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:36:10,047] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:36:16,665] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:36:23,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:36:29,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:36:36,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:36:43,223] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:36:50,125] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:36:56,438] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:37:02,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:37:09,450] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.008524356993389
[2022-12-06 20:37:09,451] [INFO] [runner_train_mujoco] Average state value: 0.5222804988423982
[2022-12-06 20:37:09,451] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 20:37:09,502] [INFO] [controller] EPOCH 1 loss ppo:  -0.01526, loss val: 0.03542
[2022-12-06 20:37:09,534] [INFO] [controller] EPOCH 2 loss ppo:  -0.03301, loss val: 0.03508
[2022-12-06 20:37:09,570] [INFO] [controller] EPOCH 3 loss ppo:  -0.04581, loss val: 0.03486
[2022-12-06 20:37:09,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.06018, loss val: 0.03487
[2022-12-06 20:37:09,616] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:37:09,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:37:09,800] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:37:16,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:37:23,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:37:30,493] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:37:36,924] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:37:43,495] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:37:50,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:37:56,552] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:38:03,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:38:10,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:38:16,595] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.236931781500482
[2022-12-06 20:38:16,595] [INFO] [runner_train_mujoco] Average state value: 0.5075379846195379
[2022-12-06 20:38:16,595] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 20:38:16,638] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.04553
[2022-12-06 20:38:16,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.02720, loss val: 0.04568
[2022-12-06 20:38:16,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.03650, loss val: 0.04312
[2022-12-06 20:38:16,756] [INFO] [controller] EPOCH 4 loss ppo:  -0.04868, loss val: 0.04146
[2022-12-06 20:38:16,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:38:16,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:38:16,958] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:38:23,925] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:38:30,570] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:38:37,449] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:38:44,146] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:38:50,482] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:38:56,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:39:03,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:39:09,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:39:15,909] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:39:22,164] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.300189420759585
[2022-12-06 20:39:22,164] [INFO] [runner_train_mujoco] Average state value: 0.4785373047788938
[2022-12-06 20:39:22,164] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 20:39:22,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.03933
[2022-12-06 20:39:22,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.02752, loss val: 0.03856
[2022-12-06 20:39:22,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.03952, loss val: 0.04630
[2022-12-06 20:39:22,329] [INFO] [controller] EPOCH 4 loss ppo:  -0.05310, loss val: 0.03881
[2022-12-06 20:39:22,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:39:22,531] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:39:22,531] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:39:29,283] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:39:35,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:39:42,430] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:39:48,916] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:39:55,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:40:01,276] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:40:07,334] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:40:13,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:40:19,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:40:25,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.53724539793584
[2022-12-06 20:40:25,642] [INFO] [runner_train_mujoco] Average state value: 0.4727937818566959
[2022-12-06 20:40:25,642] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 20:40:25,690] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.03623
[2022-12-06 20:40:25,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.02690, loss val: 0.03707
[2022-12-06 20:40:25,773] [INFO] [controller] EPOCH 3 loss ppo:  -0.04023, loss val: 0.03726
[2022-12-06 20:40:25,816] [INFO] [controller] EPOCH 4 loss ppo:  -0.05257, loss val: 0.03646
[2022-12-06 20:40:25,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:40:25,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:40:25,966] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:40:32,258] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:40:38,736] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:40:45,241] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:40:51,669] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:40:57,750] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:41:04,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:41:10,148] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:41:16,182] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:41:22,306] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:41:28,380] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.496691254272708
[2022-12-06 20:41:28,380] [INFO] [runner_train_mujoco] Average state value: 0.48083630379041037
[2022-12-06 20:41:28,380] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 20:41:28,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.05249
[2022-12-06 20:41:28,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.02792, loss val: 0.05227
[2022-12-06 20:41:28,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.03769, loss val: 0.05121
[2022-12-06 20:41:28,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.04854, loss val: 0.05053
[2022-12-06 20:41:28,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:41:28,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:41:28,726] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:41:35,722] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:41:42,254] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:41:48,414] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:41:54,531] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:42:01,222] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:42:07,526] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:42:13,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:42:19,812] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:42:26,406] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:42:32,641] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.289527980352124
[2022-12-06 20:42:32,642] [INFO] [runner_train_mujoco] Average state value: 0.4703597138325374
[2022-12-06 20:42:32,642] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 20:42:32,688] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.03744
[2022-12-06 20:42:32,729] [INFO] [controller] EPOCH 2 loss ppo:  -0.02775, loss val: 0.03733
[2022-12-06 20:42:32,773] [INFO] [controller] EPOCH 3 loss ppo:  -0.03972, loss val: 0.03745
[2022-12-06 20:42:32,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.05264, loss val: 0.03726
[2022-12-06 20:42:32,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:42:32,966] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:42:32,966] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:42:39,192] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:42:45,439] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:42:52,006] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:42:58,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:43:04,724] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:43:11,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:43:18,770] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:43:25,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:43:32,197] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:43:38,463] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.482256603164043
[2022-12-06 20:43:38,463] [INFO] [runner_train_mujoco] Average state value: 0.45784428773323704
[2022-12-06 20:43:38,463] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 20:43:38,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04284
[2022-12-06 20:43:38,556] [INFO] [controller] EPOCH 2 loss ppo:  -0.02835, loss val: 0.04150
[2022-12-06 20:43:38,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.04124, loss val: 0.04143
[2022-12-06 20:43:38,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.05318, loss val: 0.04203
[2022-12-06 20:43:38,716] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:43:38,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:43:38,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:43:45,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:43:51,875] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:44:00,196] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:44:06,987] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:44:13,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:44:20,951] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:44:28,497] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:44:36,804] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:44:44,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:44:51,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.465043652894584
[2022-12-06 20:44:51,297] [INFO] [runner_train_mujoco] Average state value: 0.44707112153371176
[2022-12-06 20:44:51,297] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 20:44:51,355] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.03696
[2022-12-06 20:44:51,401] [INFO] [controller] EPOCH 2 loss ppo:  -0.02531, loss val: 0.03730
[2022-12-06 20:44:51,447] [INFO] [controller] EPOCH 3 loss ppo:  -0.03514, loss val: 0.03736
[2022-12-06 20:44:51,486] [INFO] [controller] EPOCH 4 loss ppo:  -0.04820, loss val: 0.03736
[2022-12-06 20:44:51,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:44:51,698] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:44:51,699] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:44:59,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:45:07,289] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:45:16,171] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:45:23,854] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:45:33,398] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:45:41,621] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:45:49,368] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:45:57,615] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:46:05,531] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:46:13,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.667214491460875
[2022-12-06 20:46:13,341] [INFO] [runner_train_mujoco] Average state value: 0.44764747523268067
[2022-12-06 20:46:13,341] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 20:46:13,404] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04366
[2022-12-06 20:46:13,457] [INFO] [controller] EPOCH 2 loss ppo:  -0.02014, loss val: 0.04125
[2022-12-06 20:46:13,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.03011, loss val: 0.04055
[2022-12-06 20:46:13,557] [INFO] [controller] EPOCH 4 loss ppo:  -0.04023, loss val: 0.04020
[2022-12-06 20:46:13,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:46:13,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:46:13,782] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:46:22,134] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:46:31,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:46:39,065] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:46:47,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:46:54,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:47:01,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:47:08,907] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:47:16,324] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:47:23,324] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:47:30,337] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.338250993731913
[2022-12-06 20:47:30,337] [INFO] [runner_train_mujoco] Average state value: 0.42914881470302746
[2022-12-06 20:47:30,338] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 20:47:30,401] [INFO] [controller] EPOCH 1 loss ppo:  -0.01473, loss val: 0.05691
[2022-12-06 20:47:30,475] [INFO] [controller] EPOCH 2 loss ppo:  -0.02424, loss val: 0.05668
[2022-12-06 20:47:30,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.03094, loss val: 0.05493
[2022-12-06 20:47:30,582] [INFO] [controller] EPOCH 4 loss ppo:  -0.04175, loss val: 0.05509
[2022-12-06 20:47:30,593] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:47:30,802] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:47:30,802] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:47:38,020] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:47:45,359] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:47:52,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:47:59,920] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:48:06,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:48:14,284] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:48:21,579] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:48:28,981] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:48:36,283] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:48:43,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.797038535108655
[2022-12-06 20:48:43,459] [INFO] [runner_train_mujoco] Average state value: 0.4840873776276907
[2022-12-06 20:48:43,459] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 20:48:43,515] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.03671
[2022-12-06 20:48:43,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.02061, loss val: 0.03615
[2022-12-06 20:48:43,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.03077, loss val: 0.03600
[2022-12-06 20:48:43,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.04007, loss val: 0.03674
[2022-12-06 20:48:43,664] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:48:43,882] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:48:43,882] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:48:50,970] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:48:58,400] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:49:06,680] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:49:14,344] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:49:21,844] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:49:29,346] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:49:36,768] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:49:44,296] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:49:51,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:49:58,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.616031087359476
[2022-12-06 20:49:58,572] [INFO] [runner_train_mujoco] Average state value: 0.4973712609112263
[2022-12-06 20:49:58,572] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 20:49:58,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01500, loss val: 0.04228
[2022-12-06 20:49:58,669] [INFO] [controller] EPOCH 2 loss ppo:  -0.02387, loss val: 0.04194
[2022-12-06 20:49:58,712] [INFO] [controller] EPOCH 3 loss ppo:  -0.03090, loss val: 0.04103
[2022-12-06 20:49:58,758] [INFO] [controller] EPOCH 4 loss ppo:  -0.03800, loss val: 0.04021
[2022-12-06 20:49:58,765] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:49:59,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:49:59,002] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:50:06,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:50:14,156] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:50:21,862] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:50:28,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:50:37,488] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:50:44,631] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:50:51,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:50:58,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:51:06,111] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:51:13,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.923595883259475
[2022-12-06 20:51:13,342] [INFO] [runner_train_mujoco] Average state value: 0.5250832053820292
[2022-12-06 20:51:13,342] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 20:51:13,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.03968
[2022-12-06 20:51:13,435] [INFO] [controller] EPOCH 2 loss ppo:  -0.02180, loss val: 0.03996
[2022-12-06 20:51:13,474] [INFO] [controller] EPOCH 3 loss ppo:  -0.03153, loss val: 0.04332
[2022-12-06 20:51:13,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.03939, loss val: 0.04008
[2022-12-06 20:51:13,526] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:51:13,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:51:13,733] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:51:20,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:51:27,839] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:51:35,269] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:51:42,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:51:50,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:51:57,105] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:52:04,107] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:52:11,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:52:17,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:52:24,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 9.249231826703074
[2022-12-06 20:52:24,665] [INFO] [runner_train_mujoco] Average state value: 0.5025986217098931
[2022-12-06 20:52:24,665] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 20:52:24,725] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.05201
[2022-12-06 20:52:24,766] [INFO] [controller] EPOCH 2 loss ppo:  -0.01912, loss val: 0.05093
[2022-12-06 20:52:24,806] [INFO] [controller] EPOCH 3 loss ppo:  -0.02836, loss val: 0.05090
[2022-12-06 20:52:24,848] [INFO] [controller] EPOCH 4 loss ppo:  -0.03641, loss val: 0.05086
[2022-12-06 20:52:24,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:52:25,063] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:52:25,063] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:52:31,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:52:39,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:52:46,234] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:52:53,382] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:53:00,792] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:53:09,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:53:15,930] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:53:22,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:53:29,636] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:53:36,862] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 8.880584089392645
[2022-12-06 20:53:36,862] [INFO] [runner_train_mujoco] Average state value: 0.5216576507687568
[2022-12-06 20:53:36,863] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 20:53:36,917] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.03923
[2022-12-06 20:53:36,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.01629, loss val: 0.03843
[2022-12-06 20:53:37,004] [INFO] [controller] EPOCH 3 loss ppo:  -0.02152, loss val: 0.03837
[2022-12-06 20:53:37,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.02805, loss val: 0.03904
[2022-12-06 20:53:37,061] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:53:37,270] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:53:37,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:53:44,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:53:51,227] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:53:58,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:54:06,099] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:54:13,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:54:20,802] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:54:28,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:54:35,443] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:54:43,065] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:54:50,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 9.022308098115879
[2022-12-06 20:54:50,171] [INFO] [runner_train_mujoco] Average state value: 0.5248382159471511
[2022-12-06 20:54:50,171] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 20:54:50,224] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04861
[2022-12-06 20:54:50,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.01699, loss val: 0.04823
[2022-12-06 20:54:50,307] [INFO] [controller] EPOCH 3 loss ppo:  -0.02086, loss val: 0.04819
[2022-12-06 20:54:50,351] [INFO] [controller] EPOCH 4 loss ppo:  -0.02589, loss val: 0.04814
[2022-12-06 20:54:50,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:54:50,564] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:54:50,564] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:54:57,579] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:55:04,794] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:55:12,366] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:55:20,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:55:29,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:55:36,852] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:55:44,190] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:55:51,339] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:55:58,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:56:06,244] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 9.001788330341048
[2022-12-06 20:56:06,245] [INFO] [runner_train_mujoco] Average state value: 0.4877453473061323
[2022-12-06 20:56:06,245] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 20:56:06,296] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.05382
[2022-12-06 20:56:06,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.01497, loss val: 0.05441
[2022-12-06 20:56:06,383] [INFO] [controller] EPOCH 3 loss ppo:  -0.01654, loss val: 0.05310
[2022-12-06 20:56:06,427] [INFO] [controller] EPOCH 4 loss ppo:  -0.01895, loss val: 0.05746
[2022-12-06 20:56:06,437] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:56:06,562] [INFO] [optimize] Finished learning.
