[2022-12-07 11:55:11,443] [INFO] [optimize] Starting learning
[2022-12-07 11:55:11,475] [INFO] [optimize] Starting learning process..
[2022-12-07 11:55:11,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:55:11,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:55:26,652] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:55:39,941] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:55:49,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:55:59,655] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:56:10,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:56:19,776] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:56:29,180] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:56:38,853] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:56:47,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:56:58,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3595033873317441
[2022-12-07 11:56:58,077] [INFO] [runner_train_mujoco] Average state value: 0.14015656067368884
[2022-12-07 11:56:58,077] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 11:56:58,167] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.29832
[2022-12-07 11:56:58,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.05179, loss val: 0.26437
[2022-12-07 11:56:58,299] [INFO] [controller] EPOCH 3 loss ppo:  -0.06830, loss val: 0.23903
[2022-12-07 11:56:58,370] [INFO] [controller] EPOCH 4 loss ppo:  -0.07956, loss val: 0.20513
[2022-12-07 11:56:58,385] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:56:58,654] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:56:58,655] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:57:08,639] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:57:18,722] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:57:28,728] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:57:37,835] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:57:48,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:57:57,576] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:58:08,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:58:19,813] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:58:30,465] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:58:39,425] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5448504507340228
[2022-12-07 11:58:39,426] [INFO] [runner_train_mujoco] Average state value: 0.321935037272051
[2022-12-07 11:58:39,426] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 11:58:39,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01130, loss val: 0.17926
[2022-12-07 11:58:39,535] [INFO] [controller] EPOCH 2 loss ppo:  -0.04570, loss val: 0.16226
[2022-12-07 11:58:39,577] [INFO] [controller] EPOCH 3 loss ppo:  -0.06271, loss val: 0.14853
[2022-12-07 11:58:39,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.07632, loss val: 0.13561
[2022-12-07 11:58:39,632] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:58:39,878] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:58:39,878] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:58:48,840] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:58:57,699] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:59:08,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:59:25,204] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:59:36,599] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:59:47,650] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:59:56,726] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:00:05,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:00:14,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:00:23,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40817529364443017
[2022-12-07 12:00:23,005] [INFO] [runner_train_mujoco] Average state value: 0.44671537911581494
[2022-12-07 12:00:23,005] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 12:00:23,059] [INFO] [controller] EPOCH 1 loss ppo:  -0.01130, loss val: 0.12512
[2022-12-07 12:00:23,106] [INFO] [controller] EPOCH 2 loss ppo:  -0.04129, loss val: 0.11394
[2022-12-07 12:00:23,157] [INFO] [controller] EPOCH 3 loss ppo:  -0.05889, loss val: 0.10456
[2022-12-07 12:00:23,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.06990, loss val: 0.09696
[2022-12-07 12:00:23,213] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:00:23,437] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:00:23,437] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:00:34,596] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:00:44,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:00:53,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:01:02,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:01:12,256] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:01:20,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:01:28,336] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:01:37,030] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:01:46,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:01:54,249] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6572648353498842
[2022-12-07 12:01:54,249] [INFO] [runner_train_mujoco] Average state value: 0.5514864834168305
[2022-12-07 12:01:54,249] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 12:01:54,302] [INFO] [controller] EPOCH 1 loss ppo:  -0.00990, loss val: 0.10830
[2022-12-07 12:01:54,348] [INFO] [controller] EPOCH 2 loss ppo:  -0.03782, loss val: 0.10185
[2022-12-07 12:01:54,389] [INFO] [controller] EPOCH 3 loss ppo:  -0.05698, loss val: 0.09730
[2022-12-07 12:01:54,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.06666, loss val: 0.09357
[2022-12-07 12:01:54,438] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:01:54,657] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:01:54,657] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:02:04,108] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:02:16,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:02:25,928] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:02:35,559] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:02:44,980] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:02:54,543] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:03:06,424] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:03:18,738] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:03:31,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:03:44,199] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5199220187387356
[2022-12-07 12:03:44,200] [INFO] [runner_train_mujoco] Average state value: 0.577286355321606
[2022-12-07 12:03:44,200] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 12:03:44,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01233, loss val: 0.09986
[2022-12-07 12:03:44,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.04224, loss val: 0.09549
[2022-12-07 12:03:44,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.05918, loss val: 0.09196
[2022-12-07 12:03:44,439] [INFO] [controller] EPOCH 4 loss ppo:  -0.07024, loss val: 0.08769
[2022-12-07 12:03:44,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:03:44,685] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:03:44,686] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:03:59,987] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:04:17,477] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:04:31,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:04:43,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:04:54,608] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:05:04,003] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:05:13,507] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:05:22,913] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:05:32,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:05:41,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.542496957474727
[2022-12-07 12:05:41,643] [INFO] [runner_train_mujoco] Average state value: 0.5661459209745129
[2022-12-07 12:05:41,643] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 12:05:41,703] [INFO] [controller] EPOCH 1 loss ppo:  -0.01198, loss val: 0.07450
[2022-12-07 12:05:41,755] [INFO] [controller] EPOCH 2 loss ppo:  -0.04540, loss val: 0.07235
[2022-12-07 12:05:41,807] [INFO] [controller] EPOCH 3 loss ppo:  -0.06221, loss val: 0.07088
[2022-12-07 12:05:41,857] [INFO] [controller] EPOCH 4 loss ppo:  -0.07304, loss val: 0.07018
[2022-12-07 12:05:41,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:05:42,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:05:42,111] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:05:51,870] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:06:01,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:06:11,355] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:06:22,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:06:34,774] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:06:46,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:06:57,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:07:10,056] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:07:20,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:07:30,885] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6082595590219351
[2022-12-07 12:07:30,885] [INFO] [runner_train_mujoco] Average state value: 0.593501933430632
[2022-12-07 12:07:30,885] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 12:07:30,945] [INFO] [controller] EPOCH 1 loss ppo:  -0.01150, loss val: 0.06966
[2022-12-07 12:07:30,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.04102, loss val: 0.06345
[2022-12-07 12:07:31,045] [INFO] [controller] EPOCH 3 loss ppo:  -0.06148, loss val: 0.05969
[2022-12-07 12:07:31,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.07250, loss val: 0.05733
[2022-12-07 12:07:31,105] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:07:31,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:07:31,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:07:40,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:07:50,775] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:08:00,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:08:09,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:08:18,597] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:08:28,017] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:08:37,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:08:47,090] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:08:56,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:09:05,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6945400696681385
[2022-12-07 12:09:05,515] [INFO] [runner_train_mujoco] Average state value: 0.5837259891877572
[2022-12-07 12:09:05,515] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 12:09:05,574] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.04953
[2022-12-07 12:09:05,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.04173, loss val: 0.04380
[2022-12-07 12:09:05,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.05801, loss val: 0.05057
[2022-12-07 12:09:05,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.07130, loss val: 0.04249
[2022-12-07 12:09:05,729] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:09:05,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:09:05,953] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:09:15,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:09:23,972] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:09:32,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:09:41,214] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:09:49,660] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:09:58,621] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:10:06,656] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:10:14,265] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:10:23,127] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:10:31,175] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6551078228210451
[2022-12-07 12:10:31,175] [INFO] [runner_train_mujoco] Average state value: 0.5613700921138127
[2022-12-07 12:10:31,175] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 12:10:31,230] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.04845
[2022-12-07 12:10:31,279] [INFO] [controller] EPOCH 2 loss ppo:  -0.04809, loss val: 0.04972
[2022-12-07 12:10:31,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.06279, loss val: 0.04613
[2022-12-07 12:10:31,381] [INFO] [controller] EPOCH 4 loss ppo:  -0.07319, loss val: 0.04972
[2022-12-07 12:10:31,391] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:10:31,598] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:10:31,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:10:40,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:10:48,730] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:10:56,714] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:11:03,937] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:11:11,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:11:18,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:11:25,887] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:11:34,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:11:41,891] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:11:48,579] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5583913103412715
[2022-12-07 12:11:48,579] [INFO] [runner_train_mujoco] Average state value: 0.5402358967289328
[2022-12-07 12:11:48,580] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 12:11:48,636] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.06261
[2022-12-07 12:11:48,681] [INFO] [controller] EPOCH 2 loss ppo:  -0.04543, loss val: 0.06147
[2022-12-07 12:11:48,725] [INFO] [controller] EPOCH 3 loss ppo:  -0.06416, loss val: 0.05993
[2022-12-07 12:11:48,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.07652, loss val: 0.05939
[2022-12-07 12:11:48,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:11:48,996] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:11:48,996] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:11:57,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:12:05,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:12:12,477] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:12:19,430] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:12:26,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:12:33,878] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:12:40,998] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:12:47,867] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:12:55,094] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:13:02,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5678722587052806
[2022-12-07 12:13:02,324] [INFO] [runner_train_mujoco] Average state value: 0.5176827550679446
[2022-12-07 12:13:02,324] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 12:13:02,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.00990, loss val: 0.04298
[2022-12-07 12:13:02,423] [INFO] [controller] EPOCH 2 loss ppo:  -0.04021, loss val: 0.04576
[2022-12-07 12:13:02,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.05662, loss val: 0.04152
[2022-12-07 12:13:02,516] [INFO] [controller] EPOCH 4 loss ppo:  -0.06834, loss val: 0.04917
[2022-12-07 12:13:02,525] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:13:02,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:13:02,737] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:13:11,881] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:13:19,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:13:27,359] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:13:35,389] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:13:42,923] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:13:51,665] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:13:59,405] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:14:07,362] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:14:14,973] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:14:22,205] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7765059735531199
[2022-12-07 12:14:22,206] [INFO] [runner_train_mujoco] Average state value: 0.4933394695520401
[2022-12-07 12:14:22,206] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 12:14:22,255] [INFO] [controller] EPOCH 1 loss ppo:  -0.01198, loss val: 0.05254
[2022-12-07 12:14:22,290] [INFO] [controller] EPOCH 2 loss ppo:  -0.04243, loss val: 0.05027
[2022-12-07 12:14:22,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.06082, loss val: 0.04927
[2022-12-07 12:14:22,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.07289, loss val: 0.04740
[2022-12-07 12:14:22,387] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:14:22,619] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:14:22,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:14:30,416] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:14:38,535] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:14:46,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:14:54,715] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:15:02,064] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:15:10,711] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:15:18,615] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:15:26,082] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:15:33,863] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:15:42,216] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8383957276903635
[2022-12-07 12:15:42,217] [INFO] [runner_train_mujoco] Average state value: 0.5464520741999148
[2022-12-07 12:15:42,217] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 12:15:42,267] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.03895
[2022-12-07 12:15:42,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.04389, loss val: 0.03890
[2022-12-07 12:15:42,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.06240, loss val: 0.04055
[2022-12-07 12:15:42,397] [INFO] [controller] EPOCH 4 loss ppo:  -0.07653, loss val: 0.03874
[2022-12-07 12:15:42,405] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:15:42,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:15:42,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:15:50,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:15:58,263] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:16:06,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:16:13,343] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:16:20,312] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:16:27,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:16:34,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:16:43,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:16:51,292] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:16:58,987] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9380181854134731
[2022-12-07 12:16:58,987] [INFO] [runner_train_mujoco] Average state value: 0.5427948860426743
[2022-12-07 12:16:58,987] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 12:16:59,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01253, loss val: 0.03413
[2022-12-07 12:16:59,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.04336, loss val: 0.03257
[2022-12-07 12:16:59,184] [INFO] [controller] EPOCH 3 loss ppo:  -0.06167, loss val: 0.03292
[2022-12-07 12:16:59,225] [INFO] [controller] EPOCH 4 loss ppo:  -0.07044, loss val: 0.03289
[2022-12-07 12:16:59,235] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:16:59,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:16:59,440] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:17:07,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:17:15,005] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:17:22,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:17:29,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:17:36,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:17:43,547] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:17:50,240] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:17:56,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:18:03,614] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:18:10,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.954780485911626
[2022-12-07 12:18:10,703] [INFO] [runner_train_mujoco] Average state value: 0.4907537127335866
[2022-12-07 12:18:10,703] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 12:18:10,752] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04427
[2022-12-07 12:18:10,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.04795, loss val: 0.04315
[2022-12-07 12:18:10,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.06559, loss val: 0.04466
[2022-12-07 12:18:10,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.07735, loss val: 0.04311
[2022-12-07 12:18:10,869] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:18:11,052] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:18:11,052] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:18:18,676] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:18:25,930] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:18:32,915] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:18:40,621] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:18:47,844] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:18:54,978] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:19:02,247] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:19:09,132] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:19:16,105] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:19:23,292] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.151800003126135
[2022-12-07 12:19:23,293] [INFO] [runner_train_mujoco] Average state value: 0.4500328715046247
[2022-12-07 12:19:23,293] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 12:19:23,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04314
[2022-12-07 12:19:23,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.04073, loss val: 0.04369
[2022-12-07 12:19:23,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.05865, loss val: 0.04058
[2022-12-07 12:19:23,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.07143, loss val: 0.04098
[2022-12-07 12:19:23,528] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:19:23,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:19:23,745] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:19:31,163] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:19:38,903] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:19:47,288] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:19:54,845] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:20:01,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:20:09,029] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:20:15,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:20:22,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:20:29,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:20:36,602] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5322873910414605
[2022-12-07 12:20:36,603] [INFO] [runner_train_mujoco] Average state value: 0.4060837439944347
[2022-12-07 12:20:36,603] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 12:20:36,647] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.04517
[2022-12-07 12:20:36,690] [INFO] [controller] EPOCH 2 loss ppo:  -0.03833, loss val: 0.04933
[2022-12-07 12:20:36,736] [INFO] [controller] EPOCH 3 loss ppo:  -0.05747, loss val: 0.04846
[2022-12-07 12:20:36,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.07088, loss val: 0.04756
[2022-12-07 12:20:36,790] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:20:37,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:20:37,005] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:20:44,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:20:51,714] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:20:58,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:21:06,031] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:21:12,973] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:21:20,250] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:21:27,379] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:21:34,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:21:42,104] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:21:49,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7888588882096432
[2022-12-07 12:21:49,166] [INFO] [runner_train_mujoco] Average state value: 0.4210826257392764
[2022-12-07 12:21:49,166] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 12:21:49,217] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.04290
[2022-12-07 12:21:49,261] [INFO] [controller] EPOCH 2 loss ppo:  -0.03768, loss val: 0.04075
[2022-12-07 12:21:49,315] [INFO] [controller] EPOCH 3 loss ppo:  -0.05558, loss val: 0.04167
[2022-12-07 12:21:49,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.06969, loss val: 0.04084
[2022-12-07 12:21:49,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:21:49,563] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:21:49,564] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:21:56,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:22:04,767] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:22:12,393] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:22:19,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:22:26,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:22:34,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:22:41,493] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:22:48,547] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:22:55,580] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:23:02,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1383546987087265
[2022-12-07 12:23:02,544] [INFO] [runner_train_mujoco] Average state value: 0.4697271878421307
[2022-12-07 12:23:02,544] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 12:23:02,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.04899
[2022-12-07 12:23:02,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.03756, loss val: 0.04744
[2022-12-07 12:23:02,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.05326, loss val: 0.04750
[2022-12-07 12:23:02,708] [INFO] [controller] EPOCH 4 loss ppo:  -0.06834, loss val: 0.04362
[2022-12-07 12:23:02,718] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:23:02,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:23:02,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:23:09,970] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:23:16,755] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:23:23,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:23:30,481] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:23:37,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:23:44,493] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:23:50,794] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:23:57,300] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:24:03,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:24:09,966] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5380755863133313
[2022-12-07 12:24:09,966] [INFO] [runner_train_mujoco] Average state value: 0.5368503521879513
[2022-12-07 12:24:09,966] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 12:24:10,014] [INFO] [controller] EPOCH 1 loss ppo:  -0.01653, loss val: 0.06113
[2022-12-07 12:24:10,045] [INFO] [controller] EPOCH 2 loss ppo:  -0.03993, loss val: 0.06241
[2022-12-07 12:24:10,079] [INFO] [controller] EPOCH 3 loss ppo:  -0.05218, loss val: 0.06522
[2022-12-07 12:24:10,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.06227, loss val: 0.05576
[2022-12-07 12:24:10,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:24:10,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:24:10,293] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:24:16,621] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:24:22,979] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:24:29,019] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:24:35,067] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:24:41,382] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:24:47,565] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:24:53,533] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:25:01,816] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:25:07,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:25:14,057] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1198039683310794
[2022-12-07 12:25:14,057] [INFO] [runner_train_mujoco] Average state value: 0.5079924771189689
[2022-12-07 12:25:14,057] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 12:25:14,100] [INFO] [controller] EPOCH 1 loss ppo:  -0.01686, loss val: 0.04119
[2022-12-07 12:25:14,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.04730, loss val: 0.03981
[2022-12-07 12:25:14,168] [INFO] [controller] EPOCH 3 loss ppo:  -0.06629, loss val: 0.03993
[2022-12-07 12:25:14,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.07804, loss val: 0.03965
[2022-12-07 12:25:14,212] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:25:14,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:25:14,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:25:20,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:25:26,918] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:25:33,025] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:25:39,255] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:25:45,547] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:25:51,627] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:25:57,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:26:04,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:26:10,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:26:16,650] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.452989097953913
[2022-12-07 12:26:16,651] [INFO] [runner_train_mujoco] Average state value: 0.4403067563225826
[2022-12-07 12:26:16,651] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 12:26:16,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01719, loss val: 0.04733
[2022-12-07 12:26:16,733] [INFO] [controller] EPOCH 2 loss ppo:  -0.04536, loss val: 0.04779
[2022-12-07 12:26:16,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.05815, loss val: 0.04781
[2022-12-07 12:26:16,796] [INFO] [controller] EPOCH 4 loss ppo:  -0.07375, loss val: 0.04753
[2022-12-07 12:26:16,803] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:26:16,997] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:26:16,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:26:23,498] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:26:29,724] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:26:35,985] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:26:42,371] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:26:49,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:26:55,698] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:27:03,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:27:09,825] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:27:16,679] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:27:22,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2812162735380177
[2022-12-07 12:27:22,751] [INFO] [runner_train_mujoco] Average state value: 0.4267525232620537
[2022-12-07 12:27:22,751] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 12:27:22,799] [INFO] [controller] EPOCH 1 loss ppo:  -0.01566, loss val: 0.04806
[2022-12-07 12:27:22,840] [INFO] [controller] EPOCH 2 loss ppo:  -0.04551, loss val: 0.04716
[2022-12-07 12:27:22,878] [INFO] [controller] EPOCH 3 loss ppo:  -0.06516, loss val: 0.04701
[2022-12-07 12:27:22,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.07694, loss val: 0.04737
[2022-12-07 12:27:22,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:27:23,113] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:27:23,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:27:29,396] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:27:35,583] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:27:41,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:27:47,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:27:56,129] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:28:03,081] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:28:10,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:28:18,521] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:28:26,197] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:28:34,039] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.1936987180258605
[2022-12-07 12:28:34,040] [INFO] [runner_train_mujoco] Average state value: 0.427554703493913
[2022-12-07 12:28:34,040] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 12:28:34,093] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.04642
[2022-12-07 12:28:34,134] [INFO] [controller] EPOCH 2 loss ppo:  -0.03866, loss val: 0.04593
[2022-12-07 12:28:34,174] [INFO] [controller] EPOCH 3 loss ppo:  -0.05425, loss val: 0.04571
[2022-12-07 12:28:34,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.07322, loss val: 0.04569
[2022-12-07 12:28:34,218] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:28:34,419] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:28:34,420] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:28:41,433] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:28:48,701] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:28:55,814] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:29:02,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:29:09,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:29:16,527] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:29:23,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:29:30,131] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:29:37,147] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:29:44,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.423222788283164
[2022-12-07 12:29:44,109] [INFO] [runner_train_mujoco] Average state value: 0.41444979063669835
[2022-12-07 12:29:44,109] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 12:29:44,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.03478
[2022-12-07 12:29:44,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.03969, loss val: 0.03422
[2022-12-07 12:29:44,253] [INFO] [controller] EPOCH 3 loss ppo:  -0.05828, loss val: 0.03392
[2022-12-07 12:29:44,296] [INFO] [controller] EPOCH 4 loss ppo:  -0.07245, loss val: 0.03708
[2022-12-07 12:29:44,305] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:29:44,505] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:29:44,506] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:29:52,050] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:30:00,003] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:30:07,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:30:14,211] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:30:21,237] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:30:28,602] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:30:36,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:30:43,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:30:51,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:30:58,581] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.637454149825555
[2022-12-07 12:30:58,582] [INFO] [runner_train_mujoco] Average state value: 0.3849213129977385
[2022-12-07 12:30:58,582] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 12:30:58,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.04701
[2022-12-07 12:30:58,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.03788, loss val: 0.04596
[2022-12-07 12:30:58,798] [INFO] [controller] EPOCH 3 loss ppo:  -0.05225, loss val: 0.04713
[2022-12-07 12:30:58,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.06719, loss val: 0.04494
[2022-12-07 12:30:58,867] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:30:59,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:30:59,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:31:06,167] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:31:13,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:31:20,675] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:31:27,793] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:31:34,917] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:31:42,631] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:31:50,180] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:31:57,334] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:32:04,694] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:32:12,473] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.944903518548775
[2022-12-07 12:32:12,473] [INFO] [runner_train_mujoco] Average state value: 0.38634268326312304
[2022-12-07 12:32:12,473] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 12:32:12,525] [INFO] [controller] EPOCH 1 loss ppo:  -0.01719, loss val: 0.04016
[2022-12-07 12:32:12,571] [INFO] [controller] EPOCH 2 loss ppo:  -0.03756, loss val: 0.04039
[2022-12-07 12:32:12,616] [INFO] [controller] EPOCH 3 loss ppo:  -0.05452, loss val: 0.04031
[2022-12-07 12:32:12,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.07075, loss val: 0.04118
[2022-12-07 12:32:12,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:32:12,890] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:32:12,890] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:32:21,326] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:32:28,771] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:32:36,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:32:43,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:32:51,507] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:32:58,658] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:33:06,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:33:15,015] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:33:22,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:33:29,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.854267438684806
[2022-12-07 12:33:29,738] [INFO] [runner_train_mujoco] Average state value: 0.4083991662170738
[2022-12-07 12:33:29,738] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 12:33:29,787] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.07352
[2022-12-07 12:33:29,825] [INFO] [controller] EPOCH 2 loss ppo:  -0.03028, loss val: 0.06807
[2022-12-07 12:33:29,866] [INFO] [controller] EPOCH 3 loss ppo:  -0.03838, loss val: 0.06347
[2022-12-07 12:33:29,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.05691, loss val: 0.05763
[2022-12-07 12:33:29,921] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:33:30,128] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:33:30,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:33:37,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:33:44,552] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:33:51,629] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:33:58,705] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:34:06,341] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:34:15,343] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:34:22,274] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:34:29,462] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:34:36,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:34:43,704] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.27826728057549
[2022-12-07 12:34:43,704] [INFO] [runner_train_mujoco] Average state value: 0.4731891094446182
[2022-12-07 12:34:43,705] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 12:34:43,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.05717
[2022-12-07 12:34:43,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.03865, loss val: 0.05898
[2022-12-07 12:34:43,900] [INFO] [controller] EPOCH 3 loss ppo:  -0.05891, loss val: 0.05982
[2022-12-07 12:34:43,955] [INFO] [controller] EPOCH 4 loss ppo:  -0.07388, loss val: 0.06031
[2022-12-07 12:34:43,966] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:34:44,178] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:34:44,178] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:34:51,395] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:34:58,282] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:35:05,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:35:12,126] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:35:18,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:35:26,062] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:35:32,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:35:40,181] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:35:47,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:35:53,918] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.704443956191375
[2022-12-07 12:35:53,918] [INFO] [runner_train_mujoco] Average state value: 0.512139477322499
[2022-12-07 12:35:53,918] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 12:35:53,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.07435
[2022-12-07 12:35:54,010] [INFO] [controller] EPOCH 2 loss ppo:  -0.03412, loss val: 0.07200
[2022-12-07 12:35:54,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.04993, loss val: 0.06816
[2022-12-07 12:35:54,096] [INFO] [controller] EPOCH 4 loss ppo:  -0.06696, loss val: 0.06512
[2022-12-07 12:35:54,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:35:54,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:35:54,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:36:01,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:36:08,632] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:36:15,359] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:36:23,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:36:31,293] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:36:39,264] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:36:49,478] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:36:56,893] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:37:04,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:37:10,934] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.290839430654489
[2022-12-07 12:37:10,934] [INFO] [runner_train_mujoco] Average state value: 0.4484976351261138
[2022-12-07 12:37:10,934] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 12:37:10,986] [INFO] [controller] EPOCH 1 loss ppo:  -0.01603, loss val: 0.05706
[2022-12-07 12:37:11,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.03684, loss val: 0.05494
[2022-12-07 12:37:11,145] [INFO] [controller] EPOCH 3 loss ppo:  -0.04974, loss val: 0.05402
[2022-12-07 12:37:11,189] [INFO] [controller] EPOCH 4 loss ppo:  -0.06508, loss val: 0.05315
[2022-12-07 12:37:11,199] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:37:11,379] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:37:11,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:37:19,328] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:37:26,254] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:37:34,052] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:37:41,454] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:37:50,223] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:37:57,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:38:04,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:38:12,277] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:38:19,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:38:26,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.693568106345881
[2022-12-07 12:38:26,368] [INFO] [runner_train_mujoco] Average state value: 0.38782302265365914
[2022-12-07 12:38:26,368] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 12:38:26,620] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.03556
[2022-12-07 12:38:26,671] [INFO] [controller] EPOCH 2 loss ppo:  -0.03478, loss val: 0.03628
[2022-12-07 12:38:26,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.04915, loss val: 0.03551
[2022-12-07 12:38:26,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.06549, loss val: 0.03562
[2022-12-07 12:38:26,791] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:38:27,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:38:27,069] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:38:35,274] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:38:42,905] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:38:50,423] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:38:57,831] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:39:05,657] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:39:13,158] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:39:21,814] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:39:29,399] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:39:37,144] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:39:44,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.700921097330843
[2022-12-07 12:39:44,440] [INFO] [runner_train_mujoco] Average state value: 0.3569027955234051
[2022-12-07 12:39:44,440] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 12:39:44,492] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.04454
[2022-12-07 12:39:44,527] [INFO] [controller] EPOCH 2 loss ppo:  -0.02734, loss val: 0.04914
[2022-12-07 12:39:44,564] [INFO] [controller] EPOCH 3 loss ppo:  -0.04514, loss val: 0.04380
[2022-12-07 12:39:44,609] [INFO] [controller] EPOCH 4 loss ppo:  -0.06081, loss val: 0.04307
[2022-12-07 12:39:44,619] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:39:44,822] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:39:44,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:39:52,285] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:40:01,293] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:40:08,753] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:40:15,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:40:22,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:40:29,850] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:40:37,064] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:40:44,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:40:51,987] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:40:59,471] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.14781908333763
[2022-12-07 12:40:59,471] [INFO] [runner_train_mujoco] Average state value: 0.3764580150047938
[2022-12-07 12:40:59,471] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 12:40:59,525] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.04938
[2022-12-07 12:40:59,564] [INFO] [controller] EPOCH 2 loss ppo:  -0.03240, loss val: 0.04882
[2022-12-07 12:40:59,602] [INFO] [controller] EPOCH 3 loss ppo:  -0.04863, loss val: 0.04784
[2022-12-07 12:40:59,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.06601, loss val: 0.04730
[2022-12-07 12:40:59,659] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:40:59,883] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:40:59,883] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:41:07,830] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:41:15,529] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:41:22,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:41:30,906] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:41:38,904] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:41:46,819] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:41:54,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:42:02,190] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:42:09,692] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:42:17,060] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.060062532020008
[2022-12-07 12:42:17,060] [INFO] [runner_train_mujoco] Average state value: 0.4132680421769619
[2022-12-07 12:42:17,060] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 12:42:17,112] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.05203
[2022-12-07 12:42:17,158] [INFO] [controller] EPOCH 2 loss ppo:  -0.03636, loss val: 0.05161
[2022-12-07 12:42:17,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.04721, loss val: 0.04982
[2022-12-07 12:42:17,252] [INFO] [controller] EPOCH 4 loss ppo:  -0.06167, loss val: 0.05063
[2022-12-07 12:42:17,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:42:17,481] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:42:17,481] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:42:25,287] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:42:33,144] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:42:42,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:42:52,464] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:43:01,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:43:08,990] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:43:17,525] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:43:27,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:43:35,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:43:43,095] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.396831044438818
[2022-12-07 12:43:43,095] [INFO] [runner_train_mujoco] Average state value: 0.4401432148019473
[2022-12-07 12:43:43,095] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 12:43:43,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01128, loss val: 0.05539
[2022-12-07 12:43:43,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.02927, loss val: 0.05259
[2022-12-07 12:43:43,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.04566, loss val: 0.05232
[2022-12-07 12:43:43,292] [INFO] [controller] EPOCH 4 loss ppo:  -0.05994, loss val: 0.05426
[2022-12-07 12:43:43,302] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:43:43,515] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:43:43,515] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:43:51,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:43:59,695] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:44:07,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:44:15,492] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:44:23,404] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:44:31,256] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:44:38,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:44:46,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:44:55,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:45:04,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.170934585039568
[2022-12-07 12:45:04,480] [INFO] [runner_train_mujoco] Average state value: 0.3958154885359108
[2022-12-07 12:45:04,480] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 12:45:04,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.08436
[2022-12-07 12:45:04,586] [INFO] [controller] EPOCH 2 loss ppo:  -0.02883, loss val: 0.08353
[2022-12-07 12:45:04,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.04380, loss val: 0.08210
[2022-12-07 12:45:04,688] [INFO] [controller] EPOCH 4 loss ppo:  -0.05809, loss val: 0.08088
[2022-12-07 12:45:04,699] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:45:04,914] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:45:04,914] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:45:14,359] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:45:23,000] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:45:35,400] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:45:46,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:45:55,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:46:10,054] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:46:19,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:46:29,020] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:46:38,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:46:48,501] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.165672257230521
[2022-12-07 12:46:48,502] [INFO] [runner_train_mujoco] Average state value: 0.45078475487232206
[2022-12-07 12:46:48,502] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 12:46:48,569] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.05435
[2022-12-07 12:46:48,624] [INFO] [controller] EPOCH 2 loss ppo:  -0.02941, loss val: 0.05543
[2022-12-07 12:46:48,676] [INFO] [controller] EPOCH 3 loss ppo:  -0.04345, loss val: 0.05494
[2022-12-07 12:46:48,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.05699, loss val: 0.05399
[2022-12-07 12:46:48,742] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:46:49,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:46:49,019] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:47:00,180] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:47:10,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:47:19,293] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:47:28,121] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:47:37,143] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:47:46,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:47:55,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:48:04,025] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:48:13,527] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:48:22,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.496786584600618
[2022-12-07 12:48:22,887] [INFO] [runner_train_mujoco] Average state value: 0.45104303933183354
[2022-12-07 12:48:22,887] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 12:48:22,949] [INFO] [controller] EPOCH 1 loss ppo:  -0.01117, loss val: 0.05524
[2022-12-07 12:48:23,004] [INFO] [controller] EPOCH 2 loss ppo:  -0.02584, loss val: 0.05359
[2022-12-07 12:48:23,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.04065, loss val: 0.05507
[2022-12-07 12:48:23,111] [INFO] [controller] EPOCH 4 loss ppo:  -0.05617, loss val: 0.05397
[2022-12-07 12:48:23,124] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:48:23,359] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:48:23,360] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:48:32,576] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:48:41,509] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:48:50,905] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:49:01,865] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:49:10,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:49:18,274] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:49:25,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:49:34,538] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:49:43,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:49:52,540] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.356289696510047
[2022-12-07 12:49:52,540] [INFO] [runner_train_mujoco] Average state value: 0.4289440010090669
[2022-12-07 12:49:52,540] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 12:49:52,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04198
[2022-12-07 12:49:52,635] [INFO] [controller] EPOCH 2 loss ppo:  -0.03082, loss val: 0.04141
[2022-12-07 12:49:52,676] [INFO] [controller] EPOCH 3 loss ppo:  -0.04234, loss val: 0.04140
[2022-12-07 12:49:52,715] [INFO] [controller] EPOCH 4 loss ppo:  -0.05797, loss val: 0.04108
[2022-12-07 12:49:52,726] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:49:52,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:49:52,936] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:50:00,822] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:50:08,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:50:18,164] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:50:26,982] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:50:34,888] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:50:44,792] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:50:53,015] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:51:01,385] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:51:09,426] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:51:17,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.372152075260581
[2022-12-07 12:51:17,070] [INFO] [runner_train_mujoco] Average state value: 0.40182967371245226
[2022-12-07 12:51:17,070] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 12:51:17,122] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.04730
[2022-12-07 12:51:17,167] [INFO] [controller] EPOCH 2 loss ppo:  -0.02756, loss val: 0.04758
[2022-12-07 12:51:17,215] [INFO] [controller] EPOCH 3 loss ppo:  -0.04216, loss val: 0.05105
[2022-12-07 12:51:17,261] [INFO] [controller] EPOCH 4 loss ppo:  -0.05671, loss val: 0.04738
[2022-12-07 12:51:17,271] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:51:17,485] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:51:17,485] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:51:27,854] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:51:35,546] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:51:43,733] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:51:52,619] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:52:00,702] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:52:08,091] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:52:16,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:52:24,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:52:31,880] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:52:39,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.90514983206044
[2022-12-07 12:52:39,515] [INFO] [runner_train_mujoco] Average state value: 0.3974174004048109
[2022-12-07 12:52:39,515] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 12:52:39,568] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.06439
[2022-12-07 12:52:39,607] [INFO] [controller] EPOCH 2 loss ppo:  -0.02526, loss val: 0.06341
[2022-12-07 12:52:39,650] [INFO] [controller] EPOCH 3 loss ppo:  -0.03667, loss val: 0.06161
[2022-12-07 12:52:39,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.05323, loss val: 0.05993
[2022-12-07 12:52:39,706] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:52:39,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:52:39,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:52:47,763] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:52:54,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:53:02,096] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:53:09,063] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:53:18,048] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:53:26,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:53:35,628] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:53:42,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:53:49,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:53:57,057] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.649299239707642
[2022-12-07 12:53:57,058] [INFO] [runner_train_mujoco] Average state value: 0.4276689690848192
[2022-12-07 12:53:57,058] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 12:53:57,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.04768
[2022-12-07 12:53:57,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.02417, loss val: 0.04530
[2022-12-07 12:53:57,197] [INFO] [controller] EPOCH 3 loss ppo:  -0.03635, loss val: 0.04382
[2022-12-07 12:53:57,242] [INFO] [controller] EPOCH 4 loss ppo:  -0.05047, loss val: 0.04183
[2022-12-07 12:53:57,248] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:53:57,438] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:53:57,438] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:54:04,708] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:54:13,831] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:54:21,373] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:54:28,406] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:54:37,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:54:44,686] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:54:51,515] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:54:59,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:55:06,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:55:13,898] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.1324158032696925
[2022-12-07 12:55:13,899] [INFO] [runner_train_mujoco] Average state value: 0.472348225787282
[2022-12-07 12:55:13,899] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 12:55:13,955] [INFO] [controller] EPOCH 1 loss ppo:  -0.01275, loss val: 0.05776
[2022-12-07 12:55:14,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.02314, loss val: 0.05995
[2022-12-07 12:55:14,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.03187, loss val: 0.05913
[2022-12-07 12:55:14,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.04697, loss val: 0.05899
[2022-12-07 12:55:14,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:55:14,307] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:55:14,307] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:55:21,569] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:55:29,900] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:55:37,412] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:55:46,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:55:54,872] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:56:01,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:56:09,328] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:56:16,441] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:56:25,178] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:56:34,952] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.859529551110329
[2022-12-07 12:56:34,953] [INFO] [runner_train_mujoco] Average state value: 0.4584921880960464
[2022-12-07 12:56:34,953] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 12:56:35,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.06898
[2022-12-07 12:56:35,041] [INFO] [controller] EPOCH 2 loss ppo:  -0.02046, loss val: 0.06725
[2022-12-07 12:56:35,088] [INFO] [controller] EPOCH 3 loss ppo:  -0.03401, loss val: 0.06881
[2022-12-07 12:56:35,130] [INFO] [controller] EPOCH 4 loss ppo:  -0.04529, loss val: 0.06854
[2022-12-07 12:56:35,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:56:35,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:56:35,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:56:43,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:56:50,761] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:56:58,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:57:06,200] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:57:14,475] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:57:24,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:57:31,952] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:57:39,709] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:57:47,065] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:57:54,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.57929017861823
[2022-12-07 12:57:54,441] [INFO] [runner_train_mujoco] Average state value: 0.4741638493935267
[2022-12-07 12:57:54,441] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 12:57:54,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.05859
[2022-12-07 12:57:54,538] [INFO] [controller] EPOCH 2 loss ppo:  -0.02596, loss val: 0.06049
[2022-12-07 12:57:54,591] [INFO] [controller] EPOCH 3 loss ppo:  -0.03642, loss val: 0.05600
[2022-12-07 12:57:54,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.05190, loss val: 0.05642
[2022-12-07 12:57:54,647] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:57:54,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:57:54,870] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:58:02,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:58:11,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:58:19,962] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:58:30,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:58:41,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:58:49,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:58:57,200] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:59:07,018] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:59:14,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:59:23,207] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.141294691305079
[2022-12-07 12:59:23,208] [INFO] [runner_train_mujoco] Average state value: 0.4680513550837834
[2022-12-07 12:59:23,208] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 12:59:23,262] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.05649
[2022-12-07 12:59:23,310] [INFO] [controller] EPOCH 2 loss ppo:  -0.02492, loss val: 0.05606
[2022-12-07 12:59:23,357] [INFO] [controller] EPOCH 3 loss ppo:  -0.03641, loss val: 0.05584
[2022-12-07 12:59:23,401] [INFO] [controller] EPOCH 4 loss ppo:  -0.04925, loss val: 0.05532
[2022-12-07 12:59:23,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:59:23,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:59:23,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:59:32,735] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:59:43,493] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:59:51,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:59:57,882] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:00:05,217] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:00:13,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:00:20,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:00:29,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:00:36,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:00:43,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.722673582825378
[2022-12-07 13:00:43,905] [INFO] [runner_train_mujoco] Average state value: 0.4578471055229505
[2022-12-07 13:00:43,905] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 13:00:43,958] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.05019
[2022-12-07 13:00:44,004] [INFO] [controller] EPOCH 2 loss ppo:  -0.02536, loss val: 0.05026
[2022-12-07 13:00:44,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.03859, loss val: 0.05013
[2022-12-07 13:00:44,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.05165, loss val: 0.04986
[2022-12-07 13:00:44,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:00:44,381] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:00:44,381] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:00:51,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:00:59,939] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:01:08,028] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:01:17,610] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:01:24,601] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:01:31,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:01:40,844] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:01:47,846] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:01:55,472] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:02:03,061] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.670978129544762
[2022-12-07 13:02:03,061] [INFO] [runner_train_mujoco] Average state value: 0.44448308222989236
[2022-12-07 13:02:03,061] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 13:02:03,110] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.04877
[2022-12-07 13:02:03,147] [INFO] [controller] EPOCH 2 loss ppo:  -0.02136, loss val: 0.04972
[2022-12-07 13:02:03,188] [INFO] [controller] EPOCH 3 loss ppo:  -0.03119, loss val: 0.04797
[2022-12-07 13:02:03,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.04159, loss val: 0.04800
[2022-12-07 13:02:03,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:02:03,433] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:02:03,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:02:10,954] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:02:17,730] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:02:26,795] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:02:33,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:02:40,293] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:02:47,623] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:02:54,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:03:03,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:03:11,662] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:03:19,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.681206257017112
[2022-12-07 13:03:19,160] [INFO] [runner_train_mujoco] Average state value: 0.4458524948159853
[2022-12-07 13:03:19,160] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 13:03:19,211] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.04507
[2022-12-07 13:03:19,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.02338, loss val: 0.04440
[2022-12-07 13:03:19,302] [INFO] [controller] EPOCH 3 loss ppo:  -0.03068, loss val: 0.04373
[2022-12-07 13:03:19,348] [INFO] [controller] EPOCH 4 loss ppo:  -0.04173, loss val: 0.04391
[2022-12-07 13:03:19,358] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:03:19,573] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:03:19,574] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:03:27,220] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:03:35,843] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:03:45,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:03:51,993] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:03:59,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:04:07,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:04:15,063] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:04:22,896] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:04:30,830] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:04:38,192] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.940288871125449
[2022-12-07 13:04:38,192] [INFO] [runner_train_mujoco] Average state value: 0.4530560435553392
[2022-12-07 13:04:38,193] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 13:04:38,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.01179, loss val: 0.06580
[2022-12-07 13:04:38,288] [INFO] [controller] EPOCH 2 loss ppo:  -0.01845, loss val: 0.06559
[2022-12-07 13:04:38,331] [INFO] [controller] EPOCH 3 loss ppo:  -0.02674, loss val: 0.06432
[2022-12-07 13:04:38,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.03562, loss val: 0.06208
[2022-12-07 13:04:38,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:04:38,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:04:38,597] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:04:46,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:04:53,695] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:05:02,475] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:05:10,406] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:05:18,810] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:05:26,846] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:05:34,924] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:05:43,988] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:05:51,952] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:05:59,792] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.840551590552268
[2022-12-07 13:05:59,792] [INFO] [runner_train_mujoco] Average state value: 0.46442523242036504
[2022-12-07 13:05:59,792] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 13:05:59,848] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.05632
[2022-12-07 13:05:59,901] [INFO] [controller] EPOCH 2 loss ppo:  -0.02104, loss val: 0.05703
[2022-12-07 13:05:59,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.03037, loss val: 0.05790
[2022-12-07 13:05:59,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.03767, loss val: 0.05625
[2022-12-07 13:06:00,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:06:00,256] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:06:00,256] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:06:08,423] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:06:16,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:06:24,673] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:06:32,076] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:06:39,534] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:06:47,144] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:06:54,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:07:02,571] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:07:11,642] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:07:20,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.767849055137425
[2022-12-07 13:07:20,192] [INFO] [runner_train_mujoco] Average state value: 0.44704996526738017
[2022-12-07 13:07:20,192] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 13:07:20,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.07506
[2022-12-07 13:07:20,358] [INFO] [controller] EPOCH 2 loss ppo:  -0.01986, loss val: 0.07534
[2022-12-07 13:07:20,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.03047, loss val: 0.07481
[2022-12-07 13:07:20,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.03730, loss val: 0.07510
[2022-12-07 13:07:20,530] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:07:20,784] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:07:20,784] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:07:29,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:07:36,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:07:43,736] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:07:50,737] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:07:59,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:08:07,675] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:08:16,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:08:25,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:08:32,505] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:08:41,002] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.295928809906753
[2022-12-07 13:08:41,002] [INFO] [runner_train_mujoco] Average state value: 0.41605105769510065
[2022-12-07 13:08:41,002] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 13:08:41,050] [INFO] [controller] EPOCH 1 loss ppo:  -0.01258, loss val: 0.09051
[2022-12-07 13:08:41,095] [INFO] [controller] EPOCH 2 loss ppo:  -0.01853, loss val: 0.08958
[2022-12-07 13:08:41,137] [INFO] [controller] EPOCH 3 loss ppo:  -0.02762, loss val: 0.08938
[2022-12-07 13:08:41,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.03574, loss val: 0.08900
[2022-12-07 13:08:41,179] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:08:41,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:08:41,391] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:08:48,987] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:08:55,925] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:09:02,824] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:09:10,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:09:17,336] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:09:24,357] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:09:31,287] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:09:38,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:09:45,503] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:09:53,288] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.723664817323419
[2022-12-07 13:09:53,288] [INFO] [runner_train_mujoco] Average state value: 0.4729542209866146
[2022-12-07 13:09:53,288] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 13:09:53,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.05129
[2022-12-07 13:09:53,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.01777, loss val: 0.05108
[2022-12-07 13:09:53,426] [INFO] [controller] EPOCH 3 loss ppo:  -0.02578, loss val: 0.05104
[2022-12-07 13:09:53,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.03216, loss val: 0.05105
[2022-12-07 13:09:53,473] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:09:53,677] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:09:53,677] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:10:00,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:10:09,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:10:17,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:10:25,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:10:33,005] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:10:40,032] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:10:47,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:10:55,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:11:03,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:11:11,850] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.977423108869223
[2022-12-07 13:11:11,850] [INFO] [runner_train_mujoco] Average state value: 0.4589691767518719
[2022-12-07 13:11:11,850] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 13:11:11,902] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.06001
[2022-12-07 13:11:11,942] [INFO] [controller] EPOCH 2 loss ppo:  -0.01732, loss val: 0.05986
[2022-12-07 13:11:11,987] [INFO] [controller] EPOCH 3 loss ppo:  -0.02337, loss val: 0.06146
[2022-12-07 13:11:12,032] [INFO] [controller] EPOCH 4 loss ppo:  -0.02924, loss val: 0.05967
[2022-12-07 13:11:12,042] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:11:12,273] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:11:12,273] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:11:20,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:11:28,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:11:37,299] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:11:46,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:11:56,814] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:12:05,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:12:13,479] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:12:21,237] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:12:29,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:12:37,145] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.713516461118499
[2022-12-07 13:12:37,145] [INFO] [runner_train_mujoco] Average state value: 0.46819414181510616
[2022-12-07 13:12:37,145] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 13:12:37,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.04778
[2022-12-07 13:12:37,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.01441, loss val: 0.04942
[2022-12-07 13:12:37,298] [INFO] [controller] EPOCH 3 loss ppo:  -0.01851, loss val: 0.04769
[2022-12-07 13:12:37,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.02387, loss val: 0.04782
[2022-12-07 13:12:37,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:12:37,572] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:12:37,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:12:45,635] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:12:53,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:13:02,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:13:10,226] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:13:17,930] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:13:24,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:13:32,419] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:13:39,108] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:13:47,544] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:13:56,382] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 7.02289960943193
[2022-12-07 13:13:56,383] [INFO] [runner_train_mujoco] Average state value: 0.48786037389437364
[2022-12-07 13:13:56,383] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 13:13:56,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04524
[2022-12-07 13:13:56,471] [INFO] [controller] EPOCH 2 loss ppo:  -0.01412, loss val: 0.04658
[2022-12-07 13:13:56,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.01615, loss val: 0.04651
[2022-12-07 13:13:56,554] [INFO] [controller] EPOCH 4 loss ppo:  -0.01868, loss val: 0.04547
[2022-12-07 13:13:56,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:13:56,679] [INFO] [optimize] Finished learning.
