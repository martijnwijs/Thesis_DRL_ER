[2022-12-06 18:17:44,316] [INFO] [optimize] Starting learning
[2022-12-06 18:17:44,326] [INFO] [optimize] Starting learning process..
[2022-12-06 18:17:44,441] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:17:44,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:17:52,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:17:57,647] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:18:03,125] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:18:08,571] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:18:14,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:18:19,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:18:25,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:18:31,168] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:18:36,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:18:42,794] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9046292286888706
[2022-12-06 18:18:42,794] [INFO] [runner_train_mujoco] Average state value: 0.027663610669473808
[2022-12-06 18:18:42,794] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 18:18:42,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.00846, loss val: 0.48456
[2022-12-06 18:18:42,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.03810, loss val: 0.43283
[2022-12-06 18:18:42,938] [INFO] [controller] EPOCH 3 loss ppo:  -0.04984, loss val: 0.39198
[2022-12-06 18:18:42,981] [INFO] [controller] EPOCH 4 loss ppo:  -0.05719, loss val: 0.33692
[2022-12-06 18:18:42,988] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:18:43,162] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:18:43,162] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:18:49,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:18:55,007] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:19:00,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:19:05,671] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:19:11,357] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:19:16,521] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:19:22,007] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:19:27,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:19:33,454] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:19:38,756] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9828295189392078
[2022-12-06 18:19:38,756] [INFO] [runner_train_mujoco] Average state value: 0.19059273900743573
[2022-12-06 18:19:38,757] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 18:19:38,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.28825
[2022-12-06 18:19:38,846] [INFO] [controller] EPOCH 2 loss ppo:  -0.03844, loss val: 0.26177
[2022-12-06 18:19:38,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.05238, loss val: 0.22008
[2022-12-06 18:19:38,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.05901, loss val: 0.19585
[2022-12-06 18:19:38,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:19:39,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:19:39,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:19:44,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:19:50,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:19:55,519] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:20:01,368] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:20:07,018] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:20:12,423] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:20:17,815] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:20:23,330] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:20:28,766] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:20:34,377] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0869881695511296
[2022-12-06 18:20:34,377] [INFO] [runner_train_mujoco] Average state value: 0.3440300693760316
[2022-12-06 18:20:34,377] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 18:20:34,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01585, loss val: 0.19458
[2022-12-06 18:20:34,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.03881, loss val: 0.17097
[2022-12-06 18:20:34,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.04872, loss val: 0.14825
[2022-12-06 18:20:34,582] [INFO] [controller] EPOCH 4 loss ppo:  -0.05517, loss val: 0.12559
[2022-12-06 18:20:34,593] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:20:34,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:20:34,806] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:20:40,540] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:20:46,054] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:20:51,564] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:20:57,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:21:02,658] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:21:08,500] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:21:14,017] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:21:19,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:21:25,612] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:21:31,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1105094416767582
[2022-12-06 18:21:31,177] [INFO] [runner_train_mujoco] Average state value: 0.49294427797695006
[2022-12-06 18:21:31,177] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 18:21:31,232] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.10635
[2022-12-06 18:21:31,278] [INFO] [controller] EPOCH 2 loss ppo:  -0.04359, loss val: 0.09905
[2022-12-06 18:21:31,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.05662, loss val: 0.09182
[2022-12-06 18:21:31,374] [INFO] [controller] EPOCH 4 loss ppo:  -0.06204, loss val: 0.08710
[2022-12-06 18:21:31,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:21:31,577] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:21:31,577] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:21:37,316] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:21:43,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:21:48,789] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:21:54,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:22:00,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:22:06,468] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:22:12,136] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:22:17,974] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:22:23,818] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:22:29,592] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8791877324700955
[2022-12-06 18:22:29,592] [INFO] [runner_train_mujoco] Average state value: 0.5691176527837912
[2022-12-06 18:22:29,592] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 18:22:29,648] [INFO] [controller] EPOCH 1 loss ppo:  -0.01166, loss val: 0.08955
[2022-12-06 18:22:29,695] [INFO] [controller] EPOCH 2 loss ppo:  -0.03388, loss val: 0.08550
[2022-12-06 18:22:29,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.08254
[2022-12-06 18:22:29,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.05378, loss val: 0.07527
[2022-12-06 18:22:29,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:22:30,007] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:22:30,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:22:36,274] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:22:42,563] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:22:48,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:22:54,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:23:02,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:23:10,145] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:23:17,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:23:25,204] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:23:33,020] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:23:39,962] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8167212272845006
[2022-12-06 18:23:39,962] [INFO] [runner_train_mujoco] Average state value: 0.5824654678019384
[2022-12-06 18:23:39,963] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 18:23:40,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.01117, loss val: 0.07790
[2022-12-06 18:23:40,065] [INFO] [controller] EPOCH 2 loss ppo:  -0.03243, loss val: 0.07242
[2022-12-06 18:23:40,112] [INFO] [controller] EPOCH 3 loss ppo:  -0.04442, loss val: 0.06878
[2022-12-06 18:23:40,159] [INFO] [controller] EPOCH 4 loss ppo:  -0.05051, loss val: 0.06571
[2022-12-06 18:23:40,170] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:23:40,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:23:40,357] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:23:46,742] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:23:53,020] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:23:59,480] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:24:05,963] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:24:11,779] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:24:18,116] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:24:24,441] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:24:30,664] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:24:36,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:24:42,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1243611279775223
[2022-12-06 18:24:42,171] [INFO] [runner_train_mujoco] Average state value: 0.534008486315608
[2022-12-06 18:24:42,171] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 18:24:42,234] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.06780
[2022-12-06 18:24:42,283] [INFO] [controller] EPOCH 2 loss ppo:  -0.03922, loss val: 0.06506
[2022-12-06 18:24:42,331] [INFO] [controller] EPOCH 3 loss ppo:  -0.05454, loss val: 0.06227
[2022-12-06 18:24:42,375] [INFO] [controller] EPOCH 4 loss ppo:  -0.06164, loss val: 0.06051
[2022-12-06 18:24:42,386] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:24:42,594] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:24:42,595] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:24:48,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:24:54,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:25:00,797] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:25:07,005] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:25:12,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:25:19,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:25:24,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:25:30,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:25:36,528] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:25:42,597] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9687031494301876
[2022-12-06 18:25:42,597] [INFO] [runner_train_mujoco] Average state value: 0.5655666452894608
[2022-12-06 18:25:42,597] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 18:25:42,653] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.05048
[2022-12-06 18:25:42,698] [INFO] [controller] EPOCH 2 loss ppo:  -0.03300, loss val: 0.04962
[2022-12-06 18:25:42,740] [INFO] [controller] EPOCH 3 loss ppo:  -0.04595, loss val: 0.04683
[2022-12-06 18:25:42,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.05834, loss val: 0.04507
[2022-12-06 18:25:42,795] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:25:42,988] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:25:42,988] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:25:48,622] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:25:54,393] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:26:00,409] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:26:05,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:26:11,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:26:17,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:26:23,537] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:26:28,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:26:34,406] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:26:41,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1431164959236078
[2022-12-06 18:26:41,971] [INFO] [runner_train_mujoco] Average state value: 0.54339986269176
[2022-12-06 18:26:41,972] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 18:26:42,408] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.04519
[2022-12-06 18:26:42,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.03923, loss val: 0.04349
[2022-12-06 18:26:43,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.05050, loss val: 0.04400
[2022-12-06 18:26:43,589] [INFO] [controller] EPOCH 4 loss ppo:  -0.05871, loss val: 0.04485
[2022-12-06 18:26:43,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:26:43,808] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:26:43,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:26:50,694] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:26:57,569] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:27:04,033] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:27:10,923] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:27:17,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:27:23,936] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:27:30,306] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:27:38,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:27:47,839] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:27:55,429] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0666197390675531
[2022-12-06 18:27:55,429] [INFO] [runner_train_mujoco] Average state value: 0.4969142601688703
[2022-12-06 18:27:55,429] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 18:27:55,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04506
[2022-12-06 18:27:55,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.03876, loss val: 0.04403
[2022-12-06 18:27:55,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.05200, loss val: 0.04346
[2022-12-06 18:27:55,670] [INFO] [controller] EPOCH 4 loss ppo:  -0.05939, loss val: 0.04227
[2022-12-06 18:27:55,681] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:27:55,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:27:55,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:28:03,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:28:11,851] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:28:19,464] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:28:26,905] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:28:35,296] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:28:43,335] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:28:51,279] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:28:58,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:29:07,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:29:14,985] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.325620548983687
[2022-12-06 18:29:14,985] [INFO] [runner_train_mujoco] Average state value: 0.5191500757485629
[2022-12-06 18:29:14,985] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 18:29:15,094] [INFO] [controller] EPOCH 1 loss ppo:  -0.01570, loss val: 0.04775
[2022-12-06 18:29:15,157] [INFO] [controller] EPOCH 2 loss ppo:  -0.03800, loss val: 0.04809
[2022-12-06 18:29:15,218] [INFO] [controller] EPOCH 3 loss ppo:  -0.04874, loss val: 0.04712
[2022-12-06 18:29:15,275] [INFO] [controller] EPOCH 4 loss ppo:  -0.05814, loss val: 0.04565
[2022-12-06 18:29:15,288] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:29:15,512] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:29:15,512] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:29:23,762] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:29:31,779] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:29:40,220] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:29:48,046] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:29:56,081] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:30:04,094] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:30:12,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:30:20,112] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:30:28,123] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:30:35,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9904929814033254
[2022-12-06 18:30:35,782] [INFO] [runner_train_mujoco] Average state value: 0.49656785462920877
[2022-12-06 18:30:35,782] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 18:30:35,913] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.08046
[2022-12-06 18:30:35,975] [INFO] [controller] EPOCH 2 loss ppo:  -0.03580, loss val: 0.08017
[2022-12-06 18:30:36,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.04965, loss val: 0.07909
[2022-12-06 18:30:36,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.05810, loss val: 0.07786
[2022-12-06 18:30:36,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:30:36,437] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:30:36,437] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:30:43,974] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:30:52,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:31:00,521] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:31:08,360] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:31:16,177] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:31:23,997] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:31:31,511] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:31:38,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:31:46,312] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:31:53,921] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0025392007672622
[2022-12-06 18:31:53,921] [INFO] [runner_train_mujoco] Average state value: 0.5290233515699704
[2022-12-06 18:31:53,921] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 18:31:54,000] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04301
[2022-12-06 18:31:54,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.03513, loss val: 0.04041
[2022-12-06 18:31:54,111] [INFO] [controller] EPOCH 3 loss ppo:  -0.04488, loss val: 0.03659
[2022-12-06 18:31:54,160] [INFO] [controller] EPOCH 4 loss ppo:  -0.05567, loss val: 0.03503
[2022-12-06 18:31:54,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:31:54,379] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:31:54,379] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:32:02,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:32:09,797] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:32:17,066] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:32:24,383] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:32:31,537] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:32:38,643] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:32:45,928] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:32:52,848] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:33:00,171] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:33:07,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8584985746729223
[2022-12-06 18:33:07,445] [INFO] [runner_train_mujoco] Average state value: 0.477945307234923
[2022-12-06 18:33:07,445] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 18:33:07,638] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.03293
[2022-12-06 18:33:07,859] [INFO] [controller] EPOCH 2 loss ppo:  -0.03295, loss val: 0.03158
[2022-12-06 18:33:07,927] [INFO] [controller] EPOCH 3 loss ppo:  -0.04177, loss val: 0.03171
[2022-12-06 18:33:08,068] [INFO] [controller] EPOCH 4 loss ppo:  -0.05353, loss val: 0.03087
[2022-12-06 18:33:08,080] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:33:08,294] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:33:08,295] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:33:15,359] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:33:22,384] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:33:30,045] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:33:37,000] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:33:43,902] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:33:50,819] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:33:57,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:34:05,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:34:12,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:34:19,757] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.980903087891463
[2022-12-06 18:34:19,758] [INFO] [runner_train_mujoco] Average state value: 0.47521621388196944
[2022-12-06 18:34:19,758] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 18:34:19,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.03557
[2022-12-06 18:34:19,879] [INFO] [controller] EPOCH 2 loss ppo:  -0.03964, loss val: 0.03631
[2022-12-06 18:34:19,929] [INFO] [controller] EPOCH 3 loss ppo:  -0.05496, loss val: 0.03676
[2022-12-06 18:34:19,978] [INFO] [controller] EPOCH 4 loss ppo:  -0.06492, loss val: 0.03484
[2022-12-06 18:34:19,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:34:20,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:34:20,195] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:34:28,233] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:34:35,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:34:43,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:34:51,024] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:35:02,716] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:35:10,166] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:35:17,074] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:35:24,342] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:35:31,279] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:35:38,816] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0685737844716958
[2022-12-06 18:35:38,816] [INFO] [runner_train_mujoco] Average state value: 0.5021209719777108
[2022-12-06 18:35:38,816] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 18:35:38,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.03639
[2022-12-06 18:35:38,950] [INFO] [controller] EPOCH 2 loss ppo:  -0.03498, loss val: 0.03618
[2022-12-06 18:35:39,021] [INFO] [controller] EPOCH 3 loss ppo:  -0.04513, loss val: 0.03677
[2022-12-06 18:35:39,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.05472, loss val: 0.03565
[2022-12-06 18:35:39,158] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:35:39,377] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:35:39,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:35:46,940] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:35:54,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:36:01,981] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:36:09,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:36:17,322] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:36:28,209] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:36:38,459] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:36:49,197] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:37:01,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:37:10,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0191418027162937
[2022-12-06 18:37:10,633] [INFO] [runner_train_mujoco] Average state value: 0.4941791510979335
[2022-12-06 18:37:10,633] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 18:37:10,707] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04446
[2022-12-06 18:37:10,772] [INFO] [controller] EPOCH 2 loss ppo:  -0.03552, loss val: 0.04419
[2022-12-06 18:37:10,839] [INFO] [controller] EPOCH 3 loss ppo:  -0.04844, loss val: 0.04476
[2022-12-06 18:37:10,903] [INFO] [controller] EPOCH 4 loss ppo:  -0.05569, loss val: 0.04232
[2022-12-06 18:37:10,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:37:11,151] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:37:11,152] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:37:20,914] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:37:32,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:37:41,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:37:51,865] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:38:04,632] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:38:14,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:38:24,259] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:38:33,959] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:38:45,081] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:38:55,995] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1266034915963004
[2022-12-06 18:38:55,997] [INFO] [runner_train_mujoco] Average state value: 0.5181972387830417
[2022-12-06 18:38:55,997] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 18:38:56,359] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.03832
[2022-12-06 18:38:56,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.03554, loss val: 0.03648
[2022-12-06 18:38:57,280] [INFO] [controller] EPOCH 3 loss ppo:  -0.05049, loss val: 0.03513
[2022-12-06 18:38:57,526] [INFO] [controller] EPOCH 4 loss ppo:  -0.06149, loss val: 0.03637
[2022-12-06 18:38:57,547] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:38:57,932] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:38:57,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:39:08,069] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:39:17,592] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:39:27,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:39:36,875] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:39:46,845] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:39:56,316] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:40:05,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:40:17,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:40:28,207] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:40:38,224] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.246471000552243
[2022-12-06 18:40:38,224] [INFO] [runner_train_mujoco] Average state value: 0.574517006834348
[2022-12-06 18:40:38,224] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 18:40:38,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.03795
[2022-12-06 18:40:38,532] [INFO] [controller] EPOCH 2 loss ppo:  -0.03294, loss val: 0.03798
[2022-12-06 18:40:38,662] [INFO] [controller] EPOCH 3 loss ppo:  -0.04490, loss val: 0.03726
[2022-12-06 18:40:38,762] [INFO] [controller] EPOCH 4 loss ppo:  -0.05400, loss val: 0.03677
[2022-12-06 18:40:38,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:40:39,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:40:39,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:40:55,186] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:41:10,458] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:41:20,032] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:41:28,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:41:37,851] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:41:46,954] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:41:55,603] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:42:03,932] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:42:12,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:42:20,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9827250318780901
[2022-12-06 18:42:20,806] [INFO] [runner_train_mujoco] Average state value: 0.5697726896206537
[2022-12-06 18:42:20,807] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 18:42:20,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.03947
[2022-12-06 18:42:20,945] [INFO] [controller] EPOCH 2 loss ppo:  -0.03746, loss val: 0.03989
[2022-12-06 18:42:21,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.04621, loss val: 0.03856
[2022-12-06 18:42:21,061] [INFO] [controller] EPOCH 4 loss ppo:  -0.05619, loss val: 0.03848
[2022-12-06 18:42:21,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:42:21,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:42:21,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:42:29,852] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:42:40,327] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:42:51,138] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:43:01,554] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:43:11,045] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:43:21,242] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:43:31,231] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:43:40,786] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:43:51,040] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:44:01,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2516836458922531
[2022-12-06 18:44:01,046] [INFO] [runner_train_mujoco] Average state value: 0.5547953680555027
[2022-12-06 18:44:01,046] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 18:44:01,134] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.03281
[2022-12-06 18:44:01,219] [INFO] [controller] EPOCH 2 loss ppo:  -0.03380, loss val: 0.03217
[2022-12-06 18:44:01,292] [INFO] [controller] EPOCH 3 loss ppo:  -0.04737, loss val: 0.03066
[2022-12-06 18:44:01,380] [INFO] [controller] EPOCH 4 loss ppo:  -0.05743, loss val: 0.03003
[2022-12-06 18:44:01,395] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:44:01,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:44:01,649] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:44:11,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:44:21,468] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:44:31,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:44:40,920] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:44:50,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:44:59,598] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:45:09,885] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:45:19,307] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:45:29,544] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:45:39,387] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.200478393072515
[2022-12-06 18:45:39,388] [INFO] [runner_train_mujoco] Average state value: 0.5179136550525825
[2022-12-06 18:45:39,388] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 18:45:39,507] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04386
[2022-12-06 18:45:39,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.03352, loss val: 0.04521
[2022-12-06 18:45:39,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.04724, loss val: 0.04451
[2022-12-06 18:45:39,728] [INFO] [controller] EPOCH 4 loss ppo:  -0.05586, loss val: 0.04427
[2022-12-06 18:45:39,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:45:40,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:45:40,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:45:50,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:45:59,503] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:46:09,537] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:46:19,506] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:46:28,984] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:46:38,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:46:48,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:46:57,901] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:47:07,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:47:17,247] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2122914325074052
[2022-12-06 18:47:17,248] [INFO] [runner_train_mujoco] Average state value: 0.5145612802604833
[2022-12-06 18:47:17,248] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 18:47:17,341] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.04271
[2022-12-06 18:47:17,422] [INFO] [controller] EPOCH 2 loss ppo:  -0.03652, loss val: 0.04093
[2022-12-06 18:47:17,487] [INFO] [controller] EPOCH 3 loss ppo:  -0.05382, loss val: 0.03924
[2022-12-06 18:47:17,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.06638, loss val: 0.03784
[2022-12-06 18:47:17,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:47:17,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:47:17,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:47:27,835] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:47:37,565] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:47:47,290] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:47:57,041] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:48:06,680] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:48:16,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:48:26,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:48:36,948] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:48:46,113] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:48:55,663] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1902320475873263
[2022-12-06 18:48:55,663] [INFO] [runner_train_mujoco] Average state value: 0.5579667010307311
[2022-12-06 18:48:55,663] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 18:48:55,761] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.03387
[2022-12-06 18:48:55,823] [INFO] [controller] EPOCH 2 loss ppo:  -0.03431, loss val: 0.03503
[2022-12-06 18:48:55,901] [INFO] [controller] EPOCH 3 loss ppo:  -0.04698, loss val: 0.04354
[2022-12-06 18:48:55,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.05603, loss val: 0.03523
[2022-12-06 18:48:55,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:48:56,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:48:56,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:49:05,929] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:49:15,104] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:49:24,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:49:34,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:49:43,929] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:49:53,223] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:50:03,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:50:12,600] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:50:21,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:50:31,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.060189921552203
[2022-12-06 18:50:31,042] [INFO] [runner_train_mujoco] Average state value: 0.5652412885228794
[2022-12-06 18:50:31,042] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 18:50:31,140] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04516
[2022-12-06 18:50:31,225] [INFO] [controller] EPOCH 2 loss ppo:  -0.03344, loss val: 0.04386
[2022-12-06 18:50:31,304] [INFO] [controller] EPOCH 3 loss ppo:  -0.04828, loss val: 0.04328
[2022-12-06 18:50:31,471] [INFO] [controller] EPOCH 4 loss ppo:  -0.05807, loss val: 0.04133
[2022-12-06 18:50:31,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:50:31,741] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:50:31,742] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:50:41,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:50:51,526] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:51:01,269] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:51:10,379] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:51:19,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:51:29,633] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:51:39,256] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:51:48,962] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:51:58,855] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:52:08,689] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.172868248219506
[2022-12-06 18:52:08,689] [INFO] [runner_train_mujoco] Average state value: 0.5250562855998676
[2022-12-06 18:52:08,689] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 18:52:08,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01198, loss val: 0.03288
[2022-12-06 18:52:08,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.02911, loss val: 0.03125
[2022-12-06 18:52:08,926] [INFO] [controller] EPOCH 3 loss ppo:  -0.04360, loss val: 0.02997
[2022-12-06 18:52:08,999] [INFO] [controller] EPOCH 4 loss ppo:  -0.05320, loss val: 0.02909
[2022-12-06 18:52:09,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:52:09,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:52:09,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:52:18,817] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:52:28,411] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:52:37,840] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:52:47,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:52:57,245] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:53:07,045] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:53:16,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:53:26,200] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:53:35,666] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:53:45,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1319481934407776
[2022-12-06 18:53:45,167] [INFO] [runner_train_mujoco] Average state value: 0.4729199004371961
[2022-12-06 18:53:45,167] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 18:53:45,263] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.03705
[2022-12-06 18:53:45,355] [INFO] [controller] EPOCH 2 loss ppo:  -0.03213, loss val: 0.03553
[2022-12-06 18:53:45,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.04574, loss val: 0.03542
[2022-12-06 18:53:45,532] [INFO] [controller] EPOCH 4 loss ppo:  -0.05630, loss val: 0.03415
[2022-12-06 18:53:45,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:53:45,796] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:53:45,797] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:53:55,527] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:54:05,078] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:54:14,643] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:54:23,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:54:33,303] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:54:42,934] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:54:52,645] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:55:02,208] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:55:11,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:55:21,397] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3824275694953534
[2022-12-06 18:55:21,397] [INFO] [runner_train_mujoco] Average state value: 0.42039858840902655
[2022-12-06 18:55:21,397] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 18:55:21,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.03721
[2022-12-06 18:55:21,542] [INFO] [controller] EPOCH 2 loss ppo:  -0.03102, loss val: 0.03800
[2022-12-06 18:55:21,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.03959, loss val: 0.03837
[2022-12-06 18:55:21,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.05067, loss val: 0.03763
[2022-12-06 18:55:21,772] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:55:22,038] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:55:22,038] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:55:32,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:55:41,437] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:55:50,650] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:56:00,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:56:09,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:56:18,586] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:56:27,954] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:56:37,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:56:46,846] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:56:55,299] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5153049443314839
[2022-12-06 18:56:55,300] [INFO] [runner_train_mujoco] Average state value: 0.4251814640561739
[2022-12-06 18:56:55,300] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 18:56:55,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.03761
[2022-12-06 18:56:55,448] [INFO] [controller] EPOCH 2 loss ppo:  -0.03409, loss val: 0.03813
[2022-12-06 18:56:55,515] [INFO] [controller] EPOCH 3 loss ppo:  -0.04671, loss val: 0.03758
[2022-12-06 18:56:55,572] [INFO] [controller] EPOCH 4 loss ppo:  -0.05933, loss val: 0.03576
[2022-12-06 18:56:55,585] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:56:55,854] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:56:55,855] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:57:04,288] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:57:12,643] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:57:20,690] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:57:30,243] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:57:39,719] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:57:48,730] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:57:58,472] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:58:08,635] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:58:18,269] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:58:27,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5519621795783956
[2022-12-06 18:58:27,813] [INFO] [runner_train_mujoco] Average state value: 0.4359041201074918
[2022-12-06 18:58:27,813] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 18:58:27,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.03567
[2022-12-06 18:58:27,965] [INFO] [controller] EPOCH 2 loss ppo:  -0.03458, loss val: 0.03476
[2022-12-06 18:58:28,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.04683, loss val: 0.03384
[2022-12-06 18:58:28,141] [INFO] [controller] EPOCH 4 loss ppo:  -0.05752, loss val: 0.03399
[2022-12-06 18:58:28,155] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:58:28,449] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:58:28,449] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:58:38,206] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:58:47,356] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:58:56,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:59:05,845] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:59:14,908] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:59:23,849] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:59:33,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:59:43,638] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:59:54,400] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:00:04,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.770912716356852
[2022-12-06 19:00:04,917] [INFO] [runner_train_mujoco] Average state value: 0.45360819418231646
[2022-12-06 19:00:04,917] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 19:00:05,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.01609, loss val: 0.04401
[2022-12-06 19:00:05,095] [INFO] [controller] EPOCH 2 loss ppo:  -0.03407, loss val: 0.04244
[2022-12-06 19:00:05,187] [INFO] [controller] EPOCH 3 loss ppo:  -0.04242, loss val: 0.04056
[2022-12-06 19:00:05,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.05300, loss val: 0.03940
[2022-12-06 19:00:05,288] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:00:05,586] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:00:05,587] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:00:17,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:00:27,741] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:00:37,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:00:47,941] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:00:58,289] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:01:09,167] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:01:19,739] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:01:30,014] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:01:40,432] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:01:50,757] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.773581493508532
[2022-12-06 19:01:50,758] [INFO] [runner_train_mujoco] Average state value: 0.42643396732831995
[2022-12-06 19:01:50,758] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 19:01:50,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.09311
[2022-12-06 19:01:51,031] [INFO] [controller] EPOCH 2 loss ppo:  -0.03017, loss val: 0.08838
[2022-12-06 19:01:51,125] [INFO] [controller] EPOCH 3 loss ppo:  -0.04347, loss val: 0.09250
[2022-12-06 19:01:51,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.05822, loss val: 0.08715
[2022-12-06 19:01:51,247] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:01:51,504] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:01:51,504] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:02:01,710] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:02:12,147] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:02:22,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:02:33,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:02:44,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:02:54,406] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:03:04,490] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:03:14,845] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:03:25,078] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:03:35,503] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.799668193078891
[2022-12-06 19:03:35,504] [INFO] [runner_train_mujoco] Average state value: 0.5152169321576754
[2022-12-06 19:03:35,504] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 19:03:35,712] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.03684
[2022-12-06 19:03:35,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.02988, loss val: 0.04057
[2022-12-06 19:03:35,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.03974, loss val: 0.03612
[2022-12-06 19:03:35,954] [INFO] [controller] EPOCH 4 loss ppo:  -0.05142, loss val: 0.03960
[2022-12-06 19:03:35,971] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:03:36,239] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:03:36,240] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:03:46,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:03:57,770] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:04:08,624] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:04:18,865] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:04:29,007] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:04:39,249] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:04:49,307] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:04:59,925] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:05:10,426] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:05:20,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8126392914636416
[2022-12-06 19:05:20,809] [INFO] [runner_train_mujoco] Average state value: 0.5088787569105626
[2022-12-06 19:05:20,809] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 19:05:20,934] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.05328
[2022-12-06 19:05:21,031] [INFO] [controller] EPOCH 2 loss ppo:  -0.03070, loss val: 0.05496
[2022-12-06 19:05:21,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.04161, loss val: 0.05397
[2022-12-06 19:05:21,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.05258, loss val: 0.05379
[2022-12-06 19:05:21,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:05:21,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:05:21,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:05:32,422] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:05:42,989] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:05:52,555] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:06:01,623] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:06:10,561] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:06:19,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:06:28,288] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:06:37,430] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:06:46,831] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:06:57,292] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3736613239175846
[2022-12-06 19:06:57,292] [INFO] [runner_train_mujoco] Average state value: 0.5034285265505314
[2022-12-06 19:06:57,292] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 19:06:57,413] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.04245
[2022-12-06 19:06:57,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.03056, loss val: 0.04243
[2022-12-06 19:06:57,634] [INFO] [controller] EPOCH 3 loss ppo:  -0.04109, loss val: 0.04221
[2022-12-06 19:06:57,778] [INFO] [controller] EPOCH 4 loss ppo:  -0.05372, loss val: 0.04190
[2022-12-06 19:06:57,791] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:06:58,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:06:58,057] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:07:10,332] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:07:21,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:07:32,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:07:42,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:07:52,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:08:02,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:08:13,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:08:23,335] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:08:34,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:08:44,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2315680451525473
[2022-12-06 19:08:44,728] [INFO] [runner_train_mujoco] Average state value: 0.501617161055406
[2022-12-06 19:08:44,728] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 19:08:44,872] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.03952
[2022-12-06 19:08:45,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.03195, loss val: 0.03910
[2022-12-06 19:08:45,195] [INFO] [controller] EPOCH 3 loss ppo:  -0.04402, loss val: 0.04031
[2022-12-06 19:08:45,320] [INFO] [controller] EPOCH 4 loss ppo:  -0.05450, loss val: 0.03937
[2022-12-06 19:08:45,335] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:08:45,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:08:45,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:08:55,492] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:09:05,922] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:09:16,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:09:26,490] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:09:37,002] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:09:47,060] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:09:57,338] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:10:07,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:10:18,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:10:28,350] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8316185357089303
[2022-12-06 19:10:28,350] [INFO] [runner_train_mujoco] Average state value: 0.4954046892325083
[2022-12-06 19:10:28,350] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 19:10:28,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.03273
[2022-12-06 19:10:28,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.02989, loss val: 0.03419
[2022-12-06 19:10:28,593] [INFO] [controller] EPOCH 3 loss ppo:  -0.03941, loss val: 0.03243
[2022-12-06 19:10:28,683] [INFO] [controller] EPOCH 4 loss ppo:  -0.05346, loss val: 0.03289
[2022-12-06 19:10:28,706] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:10:28,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:10:28,966] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:10:39,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:10:49,553] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:11:00,073] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:11:09,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:11:19,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:11:29,581] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:11:40,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:11:50,762] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:12:00,900] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:12:11,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6764962796338394
[2022-12-06 19:12:11,026] [INFO] [runner_train_mujoco] Average state value: 0.4703738942059378
[2022-12-06 19:12:11,026] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 19:12:11,125] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.04410
[2022-12-06 19:12:11,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.02308, loss val: 0.04401
[2022-12-06 19:12:11,428] [INFO] [controller] EPOCH 3 loss ppo:  -0.03800, loss val: 0.04432
[2022-12-06 19:12:11,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.05239, loss val: 0.04349
[2022-12-06 19:12:11,549] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:12:11,863] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:12:11,863] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:12:22,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:12:33,107] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:12:43,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:12:53,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:13:03,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:13:13,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:13:23,909] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:13:34,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:13:44,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:13:54,994] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.280451308459812
[2022-12-06 19:13:54,995] [INFO] [runner_train_mujoco] Average state value: 0.48692833801110585
[2022-12-06 19:13:54,995] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 19:13:55,091] [INFO] [controller] EPOCH 1 loss ppo:  -0.01615, loss val: 0.04533
[2022-12-06 19:13:55,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.02807, loss val: 0.04448
[2022-12-06 19:13:55,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.03913, loss val: 0.04446
[2022-12-06 19:13:55,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.04967, loss val: 0.04331
[2022-12-06 19:13:55,422] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:13:55,713] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:13:55,715] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:14:06,160] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:14:16,238] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:14:26,104] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:14:36,159] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:14:46,216] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:14:56,184] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:15:05,911] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:15:16,045] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:15:26,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:15:37,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9448282882812515
[2022-12-06 19:15:37,570] [INFO] [runner_train_mujoco] Average state value: 0.4688625173668067
[2022-12-06 19:15:37,571] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 19:15:37,722] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.03450
[2022-12-06 19:15:37,881] [INFO] [controller] EPOCH 2 loss ppo:  -0.02559, loss val: 0.03637
[2022-12-06 19:15:38,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.03872, loss val: 0.03674
[2022-12-06 19:15:38,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.04900, loss val: 0.03435
[2022-12-06 19:15:38,217] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:15:38,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:15:38,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:15:48,937] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:15:58,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:16:10,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:16:21,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:16:31,276] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:16:41,596] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:16:52,300] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:17:03,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:17:12,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:17:23,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2605703685033034
[2022-12-06 19:17:23,704] [INFO] [runner_train_mujoco] Average state value: 0.47389754112561533
[2022-12-06 19:17:23,704] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 19:17:25,165] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.03023
[2022-12-06 19:17:26,707] [INFO] [controller] EPOCH 2 loss ppo:  -0.02558, loss val: 0.03208
[2022-12-06 19:17:27,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.03194, loss val: 0.03113
[2022-12-06 19:17:27,618] [INFO] [controller] EPOCH 4 loss ppo:  -0.04111, loss val: 0.02993
[2022-12-06 19:17:27,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:17:28,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:17:28,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:17:39,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:17:50,905] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:18:01,164] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:18:11,346] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:18:20,738] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:18:29,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:18:40,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:19:07,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:19:22,196] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:19:34,754] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.362671250433774
[2022-12-06 19:19:34,755] [INFO] [runner_train_mujoco] Average state value: 0.4141026562688251
[2022-12-06 19:19:34,755] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 19:19:36,057] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.07567
[2022-12-06 19:19:36,318] [INFO] [controller] EPOCH 2 loss ppo:  -0.02068, loss val: 0.07118
[2022-12-06 19:19:36,410] [INFO] [controller] EPOCH 3 loss ppo:  -0.03079, loss val: 0.07081
[2022-12-06 19:19:37,299] [INFO] [controller] EPOCH 4 loss ppo:  -0.03858, loss val: 0.07899
[2022-12-06 19:19:37,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:19:37,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:19:37,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:19:46,165] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:19:53,614] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:20:00,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:20:07,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:20:14,426] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:20:21,007] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:20:27,689] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:20:34,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:20:40,962] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:20:47,662] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1994425167634644
[2022-12-06 19:20:47,662] [INFO] [runner_train_mujoco] Average state value: 0.4886863315304121
[2022-12-06 19:20:47,662] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 19:20:47,725] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.02869
[2022-12-06 19:20:47,774] [INFO] [controller] EPOCH 2 loss ppo:  -0.02583, loss val: 0.02748
[2022-12-06 19:20:47,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.03272, loss val: 0.02923
[2022-12-06 19:20:47,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.04188, loss val: 0.03085
[2022-12-06 19:20:47,887] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:20:48,073] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:20:48,073] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:20:55,056] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:21:01,931] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:21:08,907] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:21:15,707] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:21:22,639] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:21:29,209] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:21:35,739] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:21:42,390] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:21:48,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:21:55,395] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.342506605844837
[2022-12-06 19:21:55,395] [INFO] [runner_train_mujoco] Average state value: 0.45565649561211463
[2022-12-06 19:21:55,395] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 19:21:55,453] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.05413
[2022-12-06 19:21:55,502] [INFO] [controller] EPOCH 2 loss ppo:  -0.02485, loss val: 0.05450
[2022-12-06 19:21:55,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.02944, loss val: 0.05285
[2022-12-06 19:21:55,617] [INFO] [controller] EPOCH 4 loss ppo:  -0.03831, loss val: 0.05587
[2022-12-06 19:21:55,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:21:55,820] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:21:55,821] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:22:02,615] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:22:09,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:22:16,130] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:22:22,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:22:29,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:22:36,715] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:22:43,989] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:22:50,719] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:22:57,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:23:04,538] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.158411491499163
[2022-12-06 19:23:04,538] [INFO] [runner_train_mujoco] Average state value: 0.4770768723487854
[2022-12-06 19:23:04,539] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 19:23:04,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04199
[2022-12-06 19:23:04,651] [INFO] [controller] EPOCH 2 loss ppo:  -0.01882, loss val: 0.04020
[2022-12-06 19:23:04,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.02400, loss val: 0.04068
[2022-12-06 19:23:04,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.03347, loss val: 0.03983
[2022-12-06 19:23:04,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:23:04,984] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:23:04,984] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:23:12,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:23:19,447] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:23:26,569] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:23:34,209] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:23:41,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:23:48,873] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:23:56,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:24:03,788] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:24:11,465] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:24:18,597] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8217168010099036
[2022-12-06 19:24:18,597] [INFO] [runner_train_mujoco] Average state value: 0.4851953025360903
[2022-12-06 19:24:18,597] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 19:24:18,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.04197
[2022-12-06 19:24:18,716] [INFO] [controller] EPOCH 2 loss ppo:  -0.01939, loss val: 0.03999
[2022-12-06 19:24:18,850] [INFO] [controller] EPOCH 3 loss ppo:  -0.02851, loss val: 0.04187
[2022-12-06 19:24:18,902] [INFO] [controller] EPOCH 4 loss ppo:  -0.03790, loss val: 0.04378
[2022-12-06 19:24:18,912] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:24:19,129] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:24:19,129] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:24:26,414] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:24:34,234] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:24:42,048] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:24:49,516] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:24:56,709] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:25:03,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:25:11,183] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:25:18,984] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:25:26,528] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:25:33,363] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4067980654734726
[2022-12-06 19:25:33,363] [INFO] [runner_train_mujoco] Average state value: 0.48558810394754015
[2022-12-06 19:25:33,363] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 19:25:33,447] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.03227
[2022-12-06 19:25:33,499] [INFO] [controller] EPOCH 2 loss ppo:  -0.01996, loss val: 0.03300
[2022-12-06 19:25:33,580] [INFO] [controller] EPOCH 3 loss ppo:  -0.02527, loss val: 0.03211
[2022-12-06 19:25:33,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.03169, loss val: 0.03190
[2022-12-06 19:25:33,648] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:25:33,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:25:33,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:25:41,810] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:25:50,062] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:25:57,776] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:26:05,482] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:26:13,452] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:26:21,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:26:28,970] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:26:37,014] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:26:44,973] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:26:53,100] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7052353903824793
[2022-12-06 19:26:53,100] [INFO] [runner_train_mujoco] Average state value: 0.45614123353113734
[2022-12-06 19:26:53,100] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 19:26:53,178] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.06248
[2022-12-06 19:26:53,245] [INFO] [controller] EPOCH 2 loss ppo:  -0.02061, loss val: 0.06136
[2022-12-06 19:26:53,313] [INFO] [controller] EPOCH 3 loss ppo:  -0.02711, loss val: 0.06034
[2022-12-06 19:26:53,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.03569, loss val: 0.06086
[2022-12-06 19:26:53,381] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:26:53,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:26:53,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:27:01,779] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:27:10,164] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:27:18,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:27:26,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:27:34,588] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:27:43,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:27:51,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:27:59,483] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:28:07,835] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:28:16,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6030082992039896
[2022-12-06 19:28:16,666] [INFO] [runner_train_mujoco] Average state value: 0.42912973447889086
[2022-12-06 19:28:16,666] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 19:28:16,806] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.06352
[2022-12-06 19:28:16,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.01829, loss val: 0.06327
[2022-12-06 19:28:16,966] [INFO] [controller] EPOCH 3 loss ppo:  -0.02503, loss val: 0.06475
[2022-12-06 19:28:17,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.03328, loss val: 0.06291
[2022-12-06 19:28:17,045] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:28:17,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:28:17,287] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:28:25,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:28:33,932] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:28:42,772] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:28:51,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:29:00,626] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:29:09,788] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:29:18,976] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:29:27,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:29:37,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:29:46,197] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6699555715261645
[2022-12-06 19:29:46,198] [INFO] [runner_train_mujoco] Average state value: 0.44684414457778143
[2022-12-06 19:29:46,198] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 19:29:46,283] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.05799
[2022-12-06 19:29:46,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.02095, loss val: 0.05799
[2022-12-06 19:29:46,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.02779, loss val: 0.05787
[2022-12-06 19:29:46,532] [INFO] [controller] EPOCH 4 loss ppo:  -0.03467, loss val: 0.06018
[2022-12-06 19:29:46,549] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:29:46,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:29:46,835] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:29:56,392] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:30:06,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:30:16,361] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:30:26,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:30:37,010] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:30:47,570] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:30:57,657] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:31:07,852] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:31:17,714] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:31:27,529] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0657193494078427
[2022-12-06 19:31:27,530] [INFO] [runner_train_mujoco] Average state value: 0.44478369354705016
[2022-12-06 19:31:27,530] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 19:31:27,638] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.07148
[2022-12-06 19:31:27,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.01613, loss val: 0.07577
[2022-12-06 19:31:27,826] [INFO] [controller] EPOCH 3 loss ppo:  -0.01959, loss val: 0.06807
[2022-12-06 19:31:27,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.02459, loss val: 0.06749
[2022-12-06 19:31:27,918] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:31:28,203] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:31:28,204] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:31:39,558] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:31:51,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:32:02,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:32:14,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:32:26,137] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:32:38,121] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:32:50,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:33:03,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:33:15,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:33:28,816] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7411052186884852
[2022-12-06 19:33:28,816] [INFO] [runner_train_mujoco] Average state value: 0.48538873169074453
[2022-12-06 19:33:28,817] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 19:33:28,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.03887
[2022-12-06 19:33:29,110] [INFO] [controller] EPOCH 2 loss ppo:  -0.02063, loss val: 0.03883
[2022-12-06 19:33:29,225] [INFO] [controller] EPOCH 3 loss ppo:  -0.03035, loss val: 0.03930
[2022-12-06 19:33:29,365] [INFO] [controller] EPOCH 4 loss ppo:  -0.03420, loss val: 0.03955
[2022-12-06 19:33:29,387] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:33:29,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:33:29,791] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:33:43,496] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:33:57,199] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:34:10,452] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:34:23,676] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:34:35,995] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:34:48,701] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:35:01,088] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:35:12,492] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:35:23,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:35:34,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.876094196180618
[2022-12-06 19:35:34,043] [INFO] [runner_train_mujoco] Average state value: 0.4729574403588971
[2022-12-06 19:35:34,043] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 19:35:34,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.06306
[2022-12-06 19:35:34,446] [INFO] [controller] EPOCH 2 loss ppo:  -0.01731, loss val: 0.06252
[2022-12-06 19:35:34,538] [INFO] [controller] EPOCH 3 loss ppo:  -0.02397, loss val: 0.06117
[2022-12-06 19:35:34,614] [INFO] [controller] EPOCH 4 loss ppo:  -0.02885, loss val: 0.06242
[2022-12-06 19:35:34,630] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:35:34,922] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:35:34,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:35:45,848] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:35:56,217] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:36:06,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:36:16,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:36:27,516] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:36:37,772] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:36:48,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:36:58,099] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:37:07,866] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:37:17,834] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.312940800374953
[2022-12-06 19:37:17,834] [INFO] [runner_train_mujoco] Average state value: 0.515760683496793
[2022-12-06 19:37:17,834] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 19:37:17,913] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04398
[2022-12-06 19:37:17,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.01790, loss val: 0.04492
[2022-12-06 19:37:18,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.02460, loss val: 0.04452
[2022-12-06 19:37:18,114] [INFO] [controller] EPOCH 4 loss ppo:  -0.02880, loss val: 0.04522
[2022-12-06 19:37:18,127] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:37:18,372] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:37:18,372] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:37:27,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:37:36,286] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:37:45,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:37:54,621] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:38:03,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:38:12,584] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:38:21,332] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:38:30,219] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:38:38,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:38:46,989] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.2821933947923485
[2022-12-06 19:38:46,989] [INFO] [runner_train_mujoco] Average state value: 0.5184926003416379
[2022-12-06 19:38:46,990] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 19:38:47,067] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.03772
[2022-12-06 19:38:47,123] [INFO] [controller] EPOCH 2 loss ppo:  -0.01714, loss val: 0.03573
[2022-12-06 19:38:47,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.02309, loss val: 0.03462
[2022-12-06 19:38:47,235] [INFO] [controller] EPOCH 4 loss ppo:  -0.02713, loss val: 0.03918
[2022-12-06 19:38:47,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:38:47,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:38:47,493] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:38:56,227] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:39:04,653] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:39:13,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:39:22,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:39:30,868] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:39:39,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:39:48,906] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:39:57,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:40:07,162] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:40:16,152] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.523416551480821
[2022-12-06 19:40:16,153] [INFO] [runner_train_mujoco] Average state value: 0.4911563328690828
[2022-12-06 19:40:16,153] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 19:40:16,297] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.05331
[2022-12-06 19:40:16,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.01527, loss val: 0.05327
[2022-12-06 19:40:16,478] [INFO] [controller] EPOCH 3 loss ppo:  -0.01927, loss val: 0.05282
[2022-12-06 19:40:16,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.02308, loss val: 0.05309
[2022-12-06 19:40:16,556] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:40:16,820] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:40:16,821] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:40:26,292] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:40:35,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:40:45,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:40:56,158] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:41:06,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:41:18,607] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:41:27,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:41:38,388] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:41:49,328] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:42:00,156] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.41321189776101
[2022-12-06 19:42:00,156] [INFO] [runner_train_mujoco] Average state value: 0.4956683725217979
[2022-12-06 19:42:00,156] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 19:42:00,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.03926
[2022-12-06 19:42:00,372] [INFO] [controller] EPOCH 2 loss ppo:  -0.01379, loss val: 0.03930
[2022-12-06 19:42:00,457] [INFO] [controller] EPOCH 3 loss ppo:  -0.01600, loss val: 0.03929
[2022-12-06 19:42:00,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.01927, loss val: 0.03989
[2022-12-06 19:42:00,586] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:42:00,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:42:00,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:42:12,242] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:42:23,112] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:42:34,201] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:42:45,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:42:57,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:43:09,704] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:43:22,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:43:36,420] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:43:47,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:43:59,925] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.382275435764249
[2022-12-06 19:43:59,925] [INFO] [runner_train_mujoco] Average state value: 0.46357304758702716
[2022-12-06 19:43:59,925] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 19:44:00,217] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.05464
[2022-12-06 19:44:00,296] [INFO] [controller] EPOCH 2 loss ppo:  -0.01504, loss val: 0.05319
[2022-12-06 19:44:00,387] [INFO] [controller] EPOCH 3 loss ppo:  -0.01686, loss val: 0.05351
[2022-12-06 19:44:00,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.01893, loss val: 0.05395
[2022-12-06 19:44:00,517] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:44:00,756] [INFO] [optimize] Finished learning.
