[2022-12-07 02:19:28,236] [INFO] [optimize] Starting learning
[2022-12-07 02:19:28,244] [INFO] [optimize] Starting learning process..
[2022-12-07 02:19:28,321] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:19:28,322] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:19:35,344] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:19:41,252] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:19:46,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:19:52,204] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:19:57,837] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:20:03,288] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:20:08,973] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:20:15,218] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:20:20,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:20:26,039] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0139456235282143
[2022-12-07 02:20:26,039] [INFO] [runner_train_mujoco] Average state value: -0.12745826114962497
[2022-12-07 02:20:26,039] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 02:20:26,090] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.55602
[2022-12-07 02:20:26,128] [INFO] [controller] EPOCH 2 loss ppo:  -0.04734, loss val: 0.49886
[2022-12-07 02:20:26,168] [INFO] [controller] EPOCH 3 loss ppo:  -0.05877, loss val: 0.44800
[2022-12-07 02:20:26,206] [INFO] [controller] EPOCH 4 loss ppo:  -0.06940, loss val: 0.40293
[2022-12-07 02:20:26,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:20:26,385] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:20:26,385] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:20:31,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:20:36,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:20:42,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:20:47,265] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:20:52,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:20:57,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:21:02,887] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:21:07,672] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:21:12,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:21:17,820] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9720253045657715
[2022-12-07 02:21:17,820] [INFO] [runner_train_mujoco] Average state value: 0.015178455148513117
[2022-12-07 02:21:17,821] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 02:21:17,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.38784
[2022-12-07 02:21:17,914] [INFO] [controller] EPOCH 2 loss ppo:  -0.03844, loss val: 0.34726
[2022-12-07 02:21:17,955] [INFO] [controller] EPOCH 3 loss ppo:  -0.05247, loss val: 0.31553
[2022-12-07 02:21:17,996] [INFO] [controller] EPOCH 4 loss ppo:  -0.05833, loss val: 0.27874
[2022-12-07 02:21:18,005] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:21:18,174] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:21:18,174] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:21:23,364] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:21:28,658] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:21:34,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:21:39,345] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:21:44,536] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:21:49,678] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:21:55,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:22:00,166] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:22:05,630] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:22:10,878] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1115576182098617
[2022-12-07 02:22:10,878] [INFO] [runner_train_mujoco] Average state value: 0.18128490046660103
[2022-12-07 02:22:10,879] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 02:22:10,925] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.22418
[2022-12-07 02:22:10,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.03994, loss val: 0.20296
[2022-12-07 02:22:11,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.04852, loss val: 0.17675
[2022-12-07 02:22:11,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.05784, loss val: 0.15538
[2022-12-07 02:22:11,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:22:11,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:22:11,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:22:16,880] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:22:22,087] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:22:27,045] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:22:32,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:22:37,295] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:22:42,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:22:47,866] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:22:53,208] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:22:58,507] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:23:03,518] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1232254640888315
[2022-12-07 02:23:03,518] [INFO] [runner_train_mujoco] Average state value: 0.3323300774805248
[2022-12-07 02:23:03,518] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 02:23:03,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.13267
[2022-12-07 02:23:03,608] [INFO] [controller] EPOCH 2 loss ppo:  -0.04458, loss val: 0.12363
[2022-12-07 02:23:03,652] [INFO] [controller] EPOCH 3 loss ppo:  -0.06024, loss val: 0.11039
[2022-12-07 02:23:03,692] [INFO] [controller] EPOCH 4 loss ppo:  -0.06759, loss val: 0.09980
[2022-12-07 02:23:03,701] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:23:03,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:23:03,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:23:09,280] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:23:14,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:23:19,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:23:24,772] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:23:29,942] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:23:35,244] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:23:40,227] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:23:45,705] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:23:50,638] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:23:56,164] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0179367416041654
[2022-12-07 02:23:56,164] [INFO] [runner_train_mujoco] Average state value: 0.43109682086234286
[2022-12-07 02:23:56,164] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 02:23:56,215] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.10523
[2022-12-07 02:23:56,260] [INFO] [controller] EPOCH 2 loss ppo:  -0.04296, loss val: 0.09446
[2022-12-07 02:23:56,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.05490, loss val: 0.08740
[2022-12-07 02:23:56,357] [INFO] [controller] EPOCH 4 loss ppo:  -0.06359, loss val: 0.08168
[2022-12-07 02:23:56,366] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:23:56,548] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:23:56,548] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:24:01,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:24:06,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:24:12,089] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:24:17,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:24:22,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:24:27,198] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:24:31,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:24:37,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:24:42,647] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:24:47,899] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0811103812245508
[2022-12-07 02:24:47,899] [INFO] [runner_train_mujoco] Average state value: 0.5151291638799012
[2022-12-07 02:24:47,899] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 02:24:47,952] [INFO] [controller] EPOCH 1 loss ppo:  -0.01210, loss val: 0.07509
[2022-12-07 02:24:47,997] [INFO] [controller] EPOCH 2 loss ppo:  -0.03668, loss val: 0.07413
[2022-12-07 02:24:48,040] [INFO] [controller] EPOCH 3 loss ppo:  -0.04957, loss val: 0.07441
[2022-12-07 02:24:48,082] [INFO] [controller] EPOCH 4 loss ppo:  -0.05620, loss val: 0.06601
[2022-12-07 02:24:48,094] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:24:48,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:24:48,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:24:53,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:24:58,575] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:25:03,743] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:25:08,906] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:25:13,934] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:25:19,247] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:25:24,185] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:25:29,441] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:25:34,510] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:25:39,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8460842771271867
[2022-12-07 02:25:39,703] [INFO] [runner_train_mujoco] Average state value: 0.5717754902193943
[2022-12-07 02:25:39,703] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 02:25:39,754] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.06124
[2022-12-07 02:25:39,796] [INFO] [controller] EPOCH 2 loss ppo:  -0.03908, loss val: 0.05888
[2022-12-07 02:25:39,838] [INFO] [controller] EPOCH 3 loss ppo:  -0.05077, loss val: 0.05637
[2022-12-07 02:25:39,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.05657, loss val: 0.05174
[2022-12-07 02:25:39,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:25:40,048] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:25:40,049] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:25:45,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:25:50,444] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:25:55,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:26:00,963] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:26:06,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:26:11,311] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:26:16,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:26:21,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:26:26,240] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:26:31,076] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9791936074171618
[2022-12-07 02:26:31,076] [INFO] [runner_train_mujoco] Average state value: 0.5399665168027084
[2022-12-07 02:26:31,076] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 02:26:31,132] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.05062
[2022-12-07 02:26:31,173] [INFO] [controller] EPOCH 2 loss ppo:  -0.03867, loss val: 0.04657
[2022-12-07 02:26:31,213] [INFO] [controller] EPOCH 3 loss ppo:  -0.04535, loss val: 0.04822
[2022-12-07 02:26:31,255] [INFO] [controller] EPOCH 4 loss ppo:  -0.05458, loss val: 0.04783
[2022-12-07 02:26:31,264] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:26:31,443] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:26:31,443] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:26:36,700] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:26:42,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:26:47,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:26:52,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:26:57,604] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:27:02,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:27:08,090] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:27:13,478] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:27:18,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:27:24,133] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8224235485562229
[2022-12-07 02:27:24,133] [INFO] [runner_train_mujoco] Average state value: 0.5225774071613947
[2022-12-07 02:27:24,133] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 02:27:24,183] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.04571
[2022-12-07 02:27:24,220] [INFO] [controller] EPOCH 2 loss ppo:  -0.03523, loss val: 0.04386
[2022-12-07 02:27:24,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.04760, loss val: 0.04250
[2022-12-07 02:27:24,304] [INFO] [controller] EPOCH 4 loss ppo:  -0.05836, loss val: 0.04098
[2022-12-07 02:27:24,314] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:27:24,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:27:24,483] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:27:29,606] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:27:34,862] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:27:40,058] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:27:45,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:27:50,480] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:27:55,649] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:28:00,427] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:28:05,912] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:28:11,164] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:28:16,465] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0708224789375858
[2022-12-07 02:28:16,465] [INFO] [runner_train_mujoco] Average state value: 0.475370544364055
[2022-12-07 02:28:16,465] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 02:28:16,515] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04699
[2022-12-07 02:28:16,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.03412, loss val: 0.05024
[2022-12-07 02:28:16,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.04415, loss val: 0.04907
[2022-12-07 02:28:16,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.05539, loss val: 0.04307
[2022-12-07 02:28:16,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:28:16,831] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:28:16,831] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:28:21,844] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:28:27,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:28:32,639] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:28:37,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:28:42,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:28:47,633] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:28:52,711] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:28:57,648] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:29:02,899] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:29:08,069] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1020671009279746
[2022-12-07 02:29:08,069] [INFO] [runner_train_mujoco] Average state value: 0.49691298079490664
[2022-12-07 02:29:08,069] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 02:29:08,116] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.03925
[2022-12-07 02:29:08,156] [INFO] [controller] EPOCH 2 loss ppo:  -0.03520, loss val: 0.03881
[2022-12-07 02:29:08,199] [INFO] [controller] EPOCH 3 loss ppo:  -0.04778, loss val: 0.03864
[2022-12-07 02:29:08,243] [INFO] [controller] EPOCH 4 loss ppo:  -0.05750, loss val: 0.04063
[2022-12-07 02:29:08,252] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:29:08,419] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:29:08,420] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:29:13,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:29:18,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:29:24,184] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:29:29,130] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:29:34,293] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:29:39,929] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:29:45,032] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:29:50,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:29:55,292] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:30:00,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0567946469507123
[2022-12-07 02:30:00,327] [INFO] [runner_train_mujoco] Average state value: 0.5212149558365344
[2022-12-07 02:30:00,327] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 02:30:00,374] [INFO] [controller] EPOCH 1 loss ppo:  -0.01233, loss val: 0.04533
[2022-12-07 02:30:00,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.03650, loss val: 0.04400
[2022-12-07 02:30:00,520] [INFO] [controller] EPOCH 3 loss ppo:  -0.05001, loss val: 0.04471
[2022-12-07 02:30:00,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.06029, loss val: 0.04317
[2022-12-07 02:30:00,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:30:00,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:30:00,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:30:06,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:30:11,088] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:30:16,364] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:30:21,706] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:30:26,574] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:30:31,395] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:30:36,557] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:30:41,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:30:46,761] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:30:51,858] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1557248693052093
[2022-12-07 02:30:51,858] [INFO] [runner_train_mujoco] Average state value: 0.4921089680443207
[2022-12-07 02:30:51,859] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 02:30:51,908] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.03767
[2022-12-07 02:30:51,948] [INFO] [controller] EPOCH 2 loss ppo:  -0.03754, loss val: 0.03839
[2022-12-07 02:30:51,987] [INFO] [controller] EPOCH 3 loss ppo:  -0.05063, loss val: 0.03801
[2022-12-07 02:30:52,030] [INFO] [controller] EPOCH 4 loss ppo:  -0.05860, loss val: 0.03757
[2022-12-07 02:30:52,038] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:30:52,196] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:30:52,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:30:57,557] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:31:03,260] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:31:08,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:31:13,590] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:31:18,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:31:23,602] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:31:28,666] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:31:33,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:31:38,751] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:31:43,616] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2527750462666245
[2022-12-07 02:31:43,616] [INFO] [runner_train_mujoco] Average state value: 0.4772173536618551
[2022-12-07 02:31:43,616] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 02:31:43,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.04648
[2022-12-07 02:31:43,723] [INFO] [controller] EPOCH 2 loss ppo:  -0.03721, loss val: 0.04554
[2022-12-07 02:31:43,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.04991, loss val: 0.04448
[2022-12-07 02:31:43,809] [INFO] [controller] EPOCH 4 loss ppo:  -0.05851, loss val: 0.04313
[2022-12-07 02:31:43,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:31:44,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:31:44,002] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:31:49,345] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:31:54,736] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:31:59,836] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:32:05,494] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:32:10,701] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:32:16,199] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:32:21,169] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:32:26,198] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:32:31,385] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:32:36,546] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0117458766688032
[2022-12-07 02:32:36,547] [INFO] [runner_train_mujoco] Average state value: 0.5221237172583739
[2022-12-07 02:32:36,547] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 02:32:36,602] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.03727
[2022-12-07 02:32:36,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.03522, loss val: 0.03784
[2022-12-07 02:32:36,685] [INFO] [controller] EPOCH 3 loss ppo:  -0.05005, loss val: 0.03729
[2022-12-07 02:32:36,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.05943, loss val: 0.03669
[2022-12-07 02:32:36,737] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:32:36,908] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:32:36,908] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:32:42,111] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:32:47,138] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:32:52,383] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:32:57,340] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:33:02,619] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:33:07,707] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:33:12,927] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:33:17,971] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:33:22,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:33:27,710] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2175778786457705
[2022-12-07 02:33:27,710] [INFO] [runner_train_mujoco] Average state value: 0.5120248318711915
[2022-12-07 02:33:27,710] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 02:33:27,756] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.03657
[2022-12-07 02:33:27,800] [INFO] [controller] EPOCH 2 loss ppo:  -0.03643, loss val: 0.03776
[2022-12-07 02:33:27,844] [INFO] [controller] EPOCH 3 loss ppo:  -0.04422, loss val: 0.03823
[2022-12-07 02:33:27,882] [INFO] [controller] EPOCH 4 loss ppo:  -0.05304, loss val: 0.03605
[2022-12-07 02:33:27,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:33:28,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:33:28,053] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:33:32,919] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:33:38,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:33:43,721] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:33:49,054] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:33:54,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:33:59,474] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:34:04,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:34:09,976] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:34:15,044] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:34:20,260] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6163200518788723
[2022-12-07 02:34:20,260] [INFO] [runner_train_mujoco] Average state value: 0.4979607332497835
[2022-12-07 02:34:20,260] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 02:34:20,309] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.04960
[2022-12-07 02:34:20,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.03570, loss val: 0.04727
[2022-12-07 02:34:20,387] [INFO] [controller] EPOCH 3 loss ppo:  -0.04694, loss val: 0.04803
[2022-12-07 02:34:20,429] [INFO] [controller] EPOCH 4 loss ppo:  -0.05600, loss val: 0.04861
[2022-12-07 02:34:20,438] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:34:20,611] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:34:20,612] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:34:26,134] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:34:31,178] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:34:36,463] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:34:41,562] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:34:46,820] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:34:52,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:34:56,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:35:01,889] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:35:07,068] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:35:12,113] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7817738091269057
[2022-12-07 02:35:12,114] [INFO] [runner_train_mujoco] Average state value: 0.5282582260469596
[2022-12-07 02:35:12,114] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 02:35:12,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01592, loss val: 0.04685
[2022-12-07 02:35:12,220] [INFO] [controller] EPOCH 2 loss ppo:  -0.03685, loss val: 0.04504
[2022-12-07 02:35:12,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.04907, loss val: 0.04417
[2022-12-07 02:35:12,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.05761, loss val: 0.04583
[2022-12-07 02:35:12,312] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:35:12,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:35:12,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:35:17,794] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:35:23,078] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:35:28,238] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:35:33,900] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:35:38,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:35:43,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:35:48,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:35:53,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:35:58,879] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:36:03,905] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6496220000103325
[2022-12-07 02:36:03,905] [INFO] [runner_train_mujoco] Average state value: 0.453613741453737
[2022-12-07 02:36:03,905] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 02:36:03,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.01211, loss val: 0.06352
[2022-12-07 02:36:04,012] [INFO] [controller] EPOCH 2 loss ppo:  -0.03160, loss val: 0.06477
[2022-12-07 02:36:04,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.04332, loss val: 0.06200
[2022-12-07 02:36:04,092] [INFO] [controller] EPOCH 4 loss ppo:  -0.05329, loss val: 0.06118
[2022-12-07 02:36:04,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:36:04,257] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:36:04,257] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:36:09,804] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:36:14,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:36:20,022] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:36:25,148] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:36:29,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:36:35,170] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:36:40,412] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:36:45,703] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:36:50,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:36:56,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7323866008453368
[2022-12-07 02:36:56,053] [INFO] [runner_train_mujoco] Average state value: 0.47930053817232443
[2022-12-07 02:36:56,053] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 02:36:56,100] [INFO] [controller] EPOCH 1 loss ppo:  -0.01283, loss val: 0.03322
[2022-12-07 02:36:56,137] [INFO] [controller] EPOCH 2 loss ppo:  -0.03235, loss val: 0.03224
[2022-12-07 02:36:56,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.04714, loss val: 0.03063
[2022-12-07 02:36:56,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.05677, loss val: 0.03271
[2022-12-07 02:36:56,229] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:36:56,389] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:36:56,389] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:37:01,545] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:37:06,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:37:12,007] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:37:17,052] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:37:22,330] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:37:27,224] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:37:32,437] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:37:37,361] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:37:42,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:37:47,612] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8405818778682541
[2022-12-07 02:37:47,612] [INFO] [runner_train_mujoco] Average state value: 0.5074537788132828
[2022-12-07 02:37:47,612] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 02:37:47,680] [INFO] [controller] EPOCH 1 loss ppo:  -0.01165, loss val: 0.03250
[2022-12-07 02:37:47,727] [INFO] [controller] EPOCH 2 loss ppo:  -0.03437, loss val: 0.03330
[2022-12-07 02:37:47,776] [INFO] [controller] EPOCH 3 loss ppo:  -0.04461, loss val: 0.03146
[2022-12-07 02:37:47,849] [INFO] [controller] EPOCH 4 loss ppo:  -0.05537, loss val: 0.03295
[2022-12-07 02:37:47,860] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:37:48,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:37:48,040] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:37:53,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:37:58,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:38:03,513] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:38:08,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:38:13,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:38:18,686] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:38:23,659] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:38:28,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:38:33,749] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:38:38,656] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9242862801911553
[2022-12-07 02:38:38,657] [INFO] [runner_train_mujoco] Average state value: 0.5122817101366818
[2022-12-07 02:38:38,657] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 02:38:38,705] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.07157
[2022-12-07 02:38:38,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.03289, loss val: 0.06984
[2022-12-07 02:38:38,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.04675, loss val: 0.06912
[2022-12-07 02:38:38,837] [INFO] [controller] EPOCH 4 loss ppo:  -0.05650, loss val: 0.06792
[2022-12-07 02:38:38,846] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:38:39,035] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:38:39,035] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:38:44,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:38:49,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:38:54,937] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:38:59,760] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:39:05,191] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:39:10,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:39:15,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:39:20,291] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:39:25,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:39:30,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7855821365243778
[2022-12-07 02:39:30,047] [INFO] [runner_train_mujoco] Average state value: 0.5073830044567587
[2022-12-07 02:39:30,047] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 02:39:30,095] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.03860
[2022-12-07 02:39:30,141] [INFO] [controller] EPOCH 2 loss ppo:  -0.03443, loss val: 0.03831
[2022-12-07 02:39:30,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.04800, loss val: 0.03902
[2022-12-07 02:39:30,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.06091, loss val: 0.03888
[2022-12-07 02:39:30,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:39:30,400] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:39:30,400] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:39:35,662] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:39:40,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:39:45,604] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:39:50,806] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:39:55,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:40:01,042] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:40:06,054] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:40:11,576] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:40:16,880] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:40:22,063] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1571923042615437
[2022-12-07 02:40:22,063] [INFO] [runner_train_mujoco] Average state value: 0.4486732024252415
[2022-12-07 02:40:22,063] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 02:40:22,115] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.05050
[2022-12-07 02:40:22,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.02965, loss val: 0.04927
[2022-12-07 02:40:22,208] [INFO] [controller] EPOCH 3 loss ppo:  -0.03842, loss val: 0.04793
[2022-12-07 02:40:22,254] [INFO] [controller] EPOCH 4 loss ppo:  -0.05134, loss val: 0.04814
[2022-12-07 02:40:22,264] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:40:22,435] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:40:22,435] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:40:27,744] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:40:32,760] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:40:37,836] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:40:42,581] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:40:47,734] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:40:52,528] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:40:57,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:41:02,300] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:41:09,206] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:41:16,003] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.910529748975795
[2022-12-07 02:41:16,004] [INFO] [runner_train_mujoco] Average state value: 0.49266171004374826
[2022-12-07 02:41:16,004] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 02:41:16,071] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.03809
[2022-12-07 02:41:16,120] [INFO] [controller] EPOCH 2 loss ppo:  -0.03578, loss val: 0.03781
[2022-12-07 02:41:16,170] [INFO] [controller] EPOCH 3 loss ppo:  -0.05144, loss val: 0.04207
[2022-12-07 02:41:16,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.06179, loss val: 0.03847
[2022-12-07 02:41:16,307] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:41:16,497] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:41:16,498] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:41:22,214] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:41:28,079] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:41:33,843] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:41:39,787] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:41:45,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:41:51,193] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:41:57,315] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:42:03,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:42:09,379] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:42:15,217] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.257215060894647
[2022-12-07 02:42:15,217] [INFO] [runner_train_mujoco] Average state value: 0.5376097488005956
[2022-12-07 02:42:15,217] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 02:42:15,267] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.03050
[2022-12-07 02:42:15,310] [INFO] [controller] EPOCH 2 loss ppo:  -0.03307, loss val: 0.03005
[2022-12-07 02:42:15,351] [INFO] [controller] EPOCH 3 loss ppo:  -0.04683, loss val: 0.02990
[2022-12-07 02:42:15,394] [INFO] [controller] EPOCH 4 loss ppo:  -0.05746, loss val: 0.02968
[2022-12-07 02:42:15,400] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:42:15,569] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:42:15,569] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:42:21,124] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:42:26,714] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:42:32,613] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:42:38,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:42:43,797] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:42:51,353] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:42:57,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:43:03,918] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:43:10,857] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:43:17,158] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.559382989653659
[2022-12-07 02:43:17,158] [INFO] [runner_train_mujoco] Average state value: 0.5326272659103075
[2022-12-07 02:43:17,158] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 02:43:17,233] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.03921
[2022-12-07 02:43:17,288] [INFO] [controller] EPOCH 2 loss ppo:  -0.03022, loss val: 0.04290
[2022-12-07 02:43:17,350] [INFO] [controller] EPOCH 3 loss ppo:  -0.04581, loss val: 0.04055
[2022-12-07 02:43:17,404] [INFO] [controller] EPOCH 4 loss ppo:  -0.05370, loss val: 0.03885
[2022-12-07 02:43:17,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:43:17,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:43:17,620] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:43:24,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:43:31,430] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:43:37,755] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:43:43,950] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:43:50,579] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:43:56,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:44:03,081] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:44:09,512] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:44:15,613] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:44:21,699] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.892722987959245
[2022-12-07 02:44:21,700] [INFO] [runner_train_mujoco] Average state value: 0.5219949358900389
[2022-12-07 02:44:21,700] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 02:44:21,753] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.03741
[2022-12-07 02:44:21,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.03092, loss val: 0.04342
[2022-12-07 02:44:21,861] [INFO] [controller] EPOCH 3 loss ppo:  -0.04212, loss val: 0.03931
[2022-12-07 02:44:21,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.05594, loss val: 0.03749
[2022-12-07 02:44:21,923] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:44:22,123] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:44:22,123] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:44:28,562] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:44:35,357] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:44:41,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:44:48,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:44:54,397] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:45:00,936] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:45:07,425] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:45:13,813] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:45:20,115] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:45:26,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.777185223840571
[2022-12-07 02:45:26,635] [INFO] [runner_train_mujoco] Average state value: 0.5057668651342393
[2022-12-07 02:45:26,636] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 02:45:26,714] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.03871
[2022-12-07 02:45:26,770] [INFO] [controller] EPOCH 2 loss ppo:  -0.03051, loss val: 0.04019
[2022-12-07 02:45:26,822] [INFO] [controller] EPOCH 3 loss ppo:  -0.04190, loss val: 0.03938
[2022-12-07 02:45:26,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.05368, loss val: 0.03932
[2022-12-07 02:45:26,883] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:45:27,076] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:45:27,076] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:45:33,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:45:40,425] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:45:46,914] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:45:53,404] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:45:59,915] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:46:06,412] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:46:12,994] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:46:19,622] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:46:25,902] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:46:32,155] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7628381665982498
[2022-12-07 02:46:32,155] [INFO] [runner_train_mujoco] Average state value: 0.5068104432920615
[2022-12-07 02:46:32,155] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 02:46:32,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03673
[2022-12-07 02:46:32,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.03097, loss val: 0.03457
[2022-12-07 02:46:32,292] [INFO] [controller] EPOCH 3 loss ppo:  -0.04186, loss val: 0.03345
[2022-12-07 02:46:32,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.05442, loss val: 0.03369
[2022-12-07 02:46:32,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:46:32,549] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:46:32,549] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:46:39,605] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:46:46,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:46:52,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:46:59,503] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:47:05,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:47:11,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:47:18,630] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:47:24,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:47:31,599] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:47:38,263] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6393006034979107
[2022-12-07 02:47:38,263] [INFO] [runner_train_mujoco] Average state value: 0.5180628753701846
[2022-12-07 02:47:38,263] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 02:47:38,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.04195
[2022-12-07 02:47:38,537] [INFO] [controller] EPOCH 2 loss ppo:  -0.02749, loss val: 0.04197
[2022-12-07 02:47:38,594] [INFO] [controller] EPOCH 3 loss ppo:  -0.03868, loss val: 0.04203
[2022-12-07 02:47:38,657] [INFO] [controller] EPOCH 4 loss ppo:  -0.05453, loss val: 0.04204
[2022-12-07 02:47:38,667] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:47:38,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:47:38,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:47:45,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:47:51,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:47:58,016] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:48:04,470] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:48:11,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:48:18,000] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:48:24,272] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:48:30,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:48:36,448] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:48:42,880] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9464165441169037
[2022-12-07 02:48:42,880] [INFO] [runner_train_mujoco] Average state value: 0.5266257154146831
[2022-12-07 02:48:42,880] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 02:48:42,948] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04491
[2022-12-07 02:48:43,002] [INFO] [controller] EPOCH 2 loss ppo:  -0.02950, loss val: 0.04588
[2022-12-07 02:48:43,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.04129, loss val: 0.04337
[2022-12-07 02:48:43,113] [INFO] [controller] EPOCH 4 loss ppo:  -0.05382, loss val: 0.04303
[2022-12-07 02:48:43,124] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:48:43,326] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:48:43,327] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:48:49,839] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:48:56,321] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:49:02,826] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:49:09,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:49:15,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:49:22,360] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:49:28,798] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:49:35,218] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:49:41,506] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:49:47,775] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.597804346185887
[2022-12-07 02:49:47,775] [INFO] [runner_train_mujoco] Average state value: 0.5012232945760091
[2022-12-07 02:49:47,775] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 02:49:47,894] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.04410
[2022-12-07 02:49:47,945] [INFO] [controller] EPOCH 2 loss ppo:  -0.02628, loss val: 0.04259
[2022-12-07 02:49:48,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.03377, loss val: 0.04282
[2022-12-07 02:49:48,053] [INFO] [controller] EPOCH 4 loss ppo:  -0.04574, loss val: 0.04163
[2022-12-07 02:49:48,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:49:48,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:49:48,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:49:54,468] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:50:00,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:50:06,960] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:50:13,512] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:50:19,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:50:26,038] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:50:32,185] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:50:38,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:50:44,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:50:51,473] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.760815012578662
[2022-12-07 02:50:51,473] [INFO] [runner_train_mujoco] Average state value: 0.46810414746403695
[2022-12-07 02:50:51,473] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 02:50:51,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01558, loss val: 0.02910
[2022-12-07 02:50:51,604] [INFO] [controller] EPOCH 2 loss ppo:  -0.03257, loss val: 0.02941
[2022-12-07 02:50:51,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.04132, loss val: 0.02915
[2022-12-07 02:50:51,709] [INFO] [controller] EPOCH 4 loss ppo:  -0.05413, loss val: 0.03120
[2022-12-07 02:50:51,719] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:50:51,904] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:50:51,904] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:50:58,184] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:51:04,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:51:10,905] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:51:17,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:51:23,569] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:51:29,398] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:51:35,936] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:51:42,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:51:48,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:51:54,260] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.887816971953766
[2022-12-07 02:51:54,260] [INFO] [runner_train_mujoco] Average state value: 0.4188003493199746
[2022-12-07 02:51:54,261] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 02:51:54,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.05434
[2022-12-07 02:51:54,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.02991, loss val: 0.05504
[2022-12-07 02:51:54,435] [INFO] [controller] EPOCH 3 loss ppo:  -0.04156, loss val: 0.05388
[2022-12-07 02:51:54,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.05540, loss val: 0.05355
[2022-12-07 02:51:54,493] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:51:54,678] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:51:54,678] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:52:01,035] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:52:07,483] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:52:14,093] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:52:20,478] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:52:26,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:52:33,580] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:52:39,973] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:52:46,537] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:52:52,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:52:59,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1450031295868897
[2022-12-07 02:52:59,148] [INFO] [runner_train_mujoco] Average state value: 0.46179700388511025
[2022-12-07 02:52:59,148] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 02:52:59,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.03940
[2022-12-07 02:52:59,265] [INFO] [controller] EPOCH 2 loss ppo:  -0.02848, loss val: 0.03959
[2022-12-07 02:52:59,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.03881, loss val: 0.04121
[2022-12-07 02:52:59,370] [INFO] [controller] EPOCH 4 loss ppo:  -0.05105, loss val: 0.04081
[2022-12-07 02:52:59,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:52:59,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:52:59,584] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:53:05,962] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:53:12,786] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:53:19,206] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:53:25,635] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:53:31,908] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:53:38,400] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:53:44,338] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:53:50,667] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:53:57,203] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:54:03,611] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5466514342023374
[2022-12-07 02:54:03,611] [INFO] [runner_train_mujoco] Average state value: 0.45569335738817857
[2022-12-07 02:54:03,612] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 02:54:03,669] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.03586
[2022-12-07 02:54:03,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.02802, loss val: 0.03571
[2022-12-07 02:54:03,770] [INFO] [controller] EPOCH 3 loss ppo:  -0.03515, loss val: 0.03425
[2022-12-07 02:54:03,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.04612, loss val: 0.03535
[2022-12-07 02:54:03,850] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:54:04,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:54:04,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:54:10,246] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:54:16,894] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:54:23,386] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:54:29,909] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:54:36,315] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:54:42,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:54:48,510] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:54:54,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:55:00,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:55:07,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1243041332574975
[2022-12-07 02:55:07,195] [INFO] [runner_train_mujoco] Average state value: 0.43002879228194557
[2022-12-07 02:55:07,195] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 02:55:07,272] [INFO] [controller] EPOCH 1 loss ppo:  -0.01039, loss val: 0.04405
[2022-12-07 02:55:07,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.02124, loss val: 0.04426
[2022-12-07 02:55:07,394] [INFO] [controller] EPOCH 3 loss ppo:  -0.03638, loss val: 0.04516
[2022-12-07 02:55:07,446] [INFO] [controller] EPOCH 4 loss ppo:  -0.04690, loss val: 0.04343
[2022-12-07 02:55:07,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:55:07,646] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:55:07,646] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:55:14,316] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:55:20,779] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:55:27,350] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:55:33,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:55:39,423] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:55:45,654] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:55:51,581] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:55:57,888] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:56:04,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:56:10,183] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.163126288874383
[2022-12-07 02:56:10,183] [INFO] [runner_train_mujoco] Average state value: 0.4424023887018363
[2022-12-07 02:56:10,184] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 02:56:10,248] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03954
[2022-12-07 02:56:10,299] [INFO] [controller] EPOCH 2 loss ppo:  -0.02596, loss val: 0.03996
[2022-12-07 02:56:10,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.03863, loss val: 0.03891
[2022-12-07 02:56:10,406] [INFO] [controller] EPOCH 4 loss ppo:  -0.04884, loss val: 0.03924
[2022-12-07 02:56:10,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:56:10,609] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:56:10,610] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:56:16,917] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:56:22,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:56:30,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:56:37,225] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:56:43,854] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:56:49,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:56:55,983] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:57:02,604] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:57:08,947] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:57:15,097] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3215336905592396
[2022-12-07 02:57:15,097] [INFO] [runner_train_mujoco] Average state value: 0.44704151571914563
[2022-12-07 02:57:15,097] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 02:57:15,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.04760
[2022-12-07 02:57:15,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.02557, loss val: 0.04697
[2022-12-07 02:57:15,285] [INFO] [controller] EPOCH 3 loss ppo:  -0.03685, loss val: 0.05036
[2022-12-07 02:57:15,347] [INFO] [controller] EPOCH 4 loss ppo:  -0.04641, loss val: 0.04682
[2022-12-07 02:57:15,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:57:15,539] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:57:15,539] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:57:22,753] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:57:29,260] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:57:35,886] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:57:42,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:57:48,556] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:57:55,050] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:58:01,407] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:58:07,809] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:58:14,193] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:58:20,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2686009568349172
[2022-12-07 02:58:20,149] [INFO] [runner_train_mujoco] Average state value: 0.485060409684976
[2022-12-07 02:58:20,149] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 02:58:20,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04485
[2022-12-07 02:58:20,375] [INFO] [controller] EPOCH 2 loss ppo:  -0.02755, loss val: 0.04477
[2022-12-07 02:58:20,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.03879, loss val: 0.04480
[2022-12-07 02:58:20,564] [INFO] [controller] EPOCH 4 loss ppo:  -0.04701, loss val: 0.04380
[2022-12-07 02:58:20,576] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:58:20,785] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:58:20,785] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:58:26,952] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:58:33,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:58:39,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:58:45,764] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:58:52,411] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:58:58,358] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:59:04,741] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:59:10,637] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:59:16,631] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:59:22,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3602862959662714
[2022-12-07 02:59:22,570] [INFO] [runner_train_mujoco] Average state value: 0.4723800140420596
[2022-12-07 02:59:22,570] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 02:59:22,629] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.03606
[2022-12-07 02:59:22,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.02897, loss val: 0.03477
[2022-12-07 02:59:22,731] [INFO] [controller] EPOCH 3 loss ppo:  -0.04108, loss val: 0.03478
[2022-12-07 02:59:22,777] [INFO] [controller] EPOCH 4 loss ppo:  -0.04966, loss val: 0.03461
[2022-12-07 02:59:22,786] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:59:22,969] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:59:22,969] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:59:29,247] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:59:35,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:59:42,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:59:48,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:59:54,245] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:00:00,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:00:07,132] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:00:13,233] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:00:19,460] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:00:25,816] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2526495737524916
[2022-12-07 03:00:25,816] [INFO] [runner_train_mujoco] Average state value: 0.43999088322743773
[2022-12-07 03:00:25,816] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 03:00:25,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.05471
[2022-12-07 03:00:25,918] [INFO] [controller] EPOCH 2 loss ppo:  -0.02883, loss val: 0.05648
[2022-12-07 03:00:25,971] [INFO] [controller] EPOCH 3 loss ppo:  -0.04124, loss val: 0.05332
[2022-12-07 03:00:26,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.05141, loss val: 0.05437
[2022-12-07 03:00:26,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:00:26,215] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:00:26,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:00:32,359] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:00:38,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:00:44,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:00:51,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:00:57,093] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:01:03,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:01:09,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:01:15,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:01:21,973] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:01:28,556] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.296852842580634
[2022-12-07 03:01:28,556] [INFO] [runner_train_mujoco] Average state value: 0.4616719256093105
[2022-12-07 03:01:28,557] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 03:01:28,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.04851
[2022-12-07 03:01:28,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.02471, loss val: 0.04830
[2022-12-07 03:01:28,728] [INFO] [controller] EPOCH 3 loss ppo:  -0.03731, loss val: 0.04562
[2022-12-07 03:01:28,781] [INFO] [controller] EPOCH 4 loss ppo:  -0.04722, loss val: 0.04618
[2022-12-07 03:01:28,793] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:01:28,994] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:01:28,995] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:01:35,901] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:01:42,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:01:48,317] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:01:54,601] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:02:00,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:02:06,683] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:02:12,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:02:18,955] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:02:25,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:02:31,377] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3601878898001813
[2022-12-07 03:02:31,377] [INFO] [runner_train_mujoco] Average state value: 0.48204103335738174
[2022-12-07 03:02:31,378] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 03:02:31,439] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04403
[2022-12-07 03:02:31,482] [INFO] [controller] EPOCH 2 loss ppo:  -0.02210, loss val: 0.04390
[2022-12-07 03:02:31,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.03213, loss val: 0.04368
[2022-12-07 03:02:31,571] [INFO] [controller] EPOCH 4 loss ppo:  -0.04166, loss val: 0.04372
[2022-12-07 03:02:31,581] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:02:31,764] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:02:31,764] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:02:38,379] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:02:44,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:02:51,004] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:02:57,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:03:03,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:03:10,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:03:16,223] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:03:22,682] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:03:29,058] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:03:35,552] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6895542160989345
[2022-12-07 03:03:35,552] [INFO] [runner_train_mujoco] Average state value: 0.46870663245518995
[2022-12-07 03:03:35,552] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 03:03:35,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03953
[2022-12-07 03:03:35,663] [INFO] [controller] EPOCH 2 loss ppo:  -0.02510, loss val: 0.03940
[2022-12-07 03:03:35,771] [INFO] [controller] EPOCH 3 loss ppo:  -0.03938, loss val: 0.03851
[2022-12-07 03:03:35,834] [INFO] [controller] EPOCH 4 loss ppo:  -0.04695, loss val: 0.03935
[2022-12-07 03:03:35,843] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:03:36,023] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:03:36,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:03:42,027] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:03:48,333] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:03:54,655] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:04:00,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:04:06,804] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:04:13,217] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:04:19,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:04:25,506] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:04:31,936] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:04:38,263] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.556032332363139
[2022-12-07 03:04:38,263] [INFO] [runner_train_mujoco] Average state value: 0.4500525892352064
[2022-12-07 03:04:38,263] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 03:04:38,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.05910
[2022-12-07 03:04:38,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.01897, loss val: 0.05340
[2022-12-07 03:04:38,431] [INFO] [controller] EPOCH 3 loss ppo:  -0.02782, loss val: 0.05239
[2022-12-07 03:04:38,497] [INFO] [controller] EPOCH 4 loss ppo:  -0.03579, loss val: 0.05040
[2022-12-07 03:04:38,507] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:04:38,699] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:04:38,700] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:04:45,108] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:04:51,393] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:04:57,683] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:05:03,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:05:09,863] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:05:16,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:05:21,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:05:28,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:05:34,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:05:40,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.585742362176538
[2022-12-07 03:05:40,760] [INFO] [runner_train_mujoco] Average state value: 0.47840159186720843
[2022-12-07 03:05:40,760] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 03:05:40,821] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.04468
[2022-12-07 03:05:40,895] [INFO] [controller] EPOCH 2 loss ppo:  -0.02262, loss val: 0.04290
[2022-12-07 03:05:40,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.03461, loss val: 0.04327
[2022-12-07 03:05:41,011] [INFO] [controller] EPOCH 4 loss ppo:  -0.04265, loss val: 0.04281
[2022-12-07 03:05:41,020] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:05:41,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:05:41,218] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:05:47,578] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:05:54,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:06:00,203] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:06:06,387] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:06:12,768] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:06:19,122] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:06:25,418] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:06:32,231] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:06:38,585] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:06:44,734] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.267726170461762
[2022-12-07 03:06:44,734] [INFO] [runner_train_mujoco] Average state value: 0.45115551702429857
[2022-12-07 03:06:44,734] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 03:06:44,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.06516
[2022-12-07 03:06:44,865] [INFO] [controller] EPOCH 2 loss ppo:  -0.02393, loss val: 0.06970
[2022-12-07 03:06:44,924] [INFO] [controller] EPOCH 3 loss ppo:  -0.03524, loss val: 0.06866
[2022-12-07 03:06:44,985] [INFO] [controller] EPOCH 4 loss ppo:  -0.03954, loss val: 0.06458
[2022-12-07 03:06:44,996] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:06:45,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:06:45,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:06:51,234] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:06:57,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:07:04,229] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:07:11,478] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:07:18,352] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:07:24,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:07:31,631] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:07:37,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:07:44,159] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:07:50,724] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.856093710749346
[2022-12-07 03:07:50,724] [INFO] [runner_train_mujoco] Average state value: 0.518365290681521
[2022-12-07 03:07:50,724] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 03:07:50,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.03607
[2022-12-07 03:07:50,830] [INFO] [controller] EPOCH 2 loss ppo:  -0.02374, loss val: 0.03747
[2022-12-07 03:07:50,880] [INFO] [controller] EPOCH 3 loss ppo:  -0.03393, loss val: 0.03455
[2022-12-07 03:07:50,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.04076, loss val: 0.03719
[2022-12-07 03:07:50,935] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:07:51,118] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:07:51,118] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:07:57,364] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:08:03,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:08:10,272] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:08:16,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:08:22,630] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:08:29,186] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:08:35,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:08:41,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:08:47,419] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:08:53,082] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.409902465514029
[2022-12-07 03:08:53,082] [INFO] [runner_train_mujoco] Average state value: 0.5141258047223092
[2022-12-07 03:08:53,082] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 03:08:53,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.03554
[2022-12-07 03:08:53,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.02398, loss val: 0.03632
[2022-12-07 03:08:53,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.03364, loss val: 0.03553
[2022-12-07 03:08:53,289] [INFO] [controller] EPOCH 4 loss ppo:  -0.03909, loss val: 0.03532
[2022-12-07 03:08:53,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:08:53,495] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:08:53,495] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:08:59,799] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:09:06,493] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:09:12,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:09:19,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:09:25,328] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:09:31,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:09:37,708] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:09:43,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:09:49,323] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:09:55,424] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4483916371703343
[2022-12-07 03:09:55,425] [INFO] [runner_train_mujoco] Average state value: 0.49650848750273385
[2022-12-07 03:09:55,425] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 03:09:55,486] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04509
[2022-12-07 03:09:55,538] [INFO] [controller] EPOCH 2 loss ppo:  -0.02009, loss val: 0.04502
[2022-12-07 03:09:55,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.03050, loss val: 0.04466
[2022-12-07 03:09:55,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.03901, loss val: 0.04532
[2022-12-07 03:09:55,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:09:55,864] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:09:55,865] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:10:02,259] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:09,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:10:15,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:10:21,308] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:10:27,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:10:33,620] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:10:39,743] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:10:46,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:10:52,134] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:10:58,499] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7299924632229895
[2022-12-07 03:10:58,499] [INFO] [runner_train_mujoco] Average state value: 0.4894129434227944
[2022-12-07 03:10:58,499] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 03:10:58,552] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.03404
[2022-12-07 03:10:58,604] [INFO] [controller] EPOCH 2 loss ppo:  -0.01829, loss val: 0.03200
[2022-12-07 03:10:58,655] [INFO] [controller] EPOCH 3 loss ppo:  -0.02687, loss val: 0.03399
[2022-12-07 03:10:58,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.03403, loss val: 0.03518
[2022-12-07 03:10:58,711] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:10:58,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:10:58,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:11:04,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:11:11,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:17,514] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:11:23,236] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:11:29,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:11:35,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:11:42,193] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:11:48,185] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:11:54,646] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:12:00,431] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.721020743742769
[2022-12-07 03:12:00,431] [INFO] [runner_train_mujoco] Average state value: 0.4786595187187196
[2022-12-07 03:12:00,431] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 03:12:00,485] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03566
[2022-12-07 03:12:00,533] [INFO] [controller] EPOCH 2 loss ppo:  -0.01761, loss val: 0.03574
[2022-12-07 03:12:00,581] [INFO] [controller] EPOCH 3 loss ppo:  -0.02393, loss val: 0.03545
[2022-12-07 03:12:00,632] [INFO] [controller] EPOCH 4 loss ppo:  -0.03096, loss val: 0.03571
[2022-12-07 03:12:00,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:12:00,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:12:00,824] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:12:07,016] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:12:13,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:12:19,290] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:12:25,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:31,972] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:12:38,515] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:12:45,035] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:12:51,013] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:12:57,155] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:13:02,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4464612479367673
[2022-12-07 03:13:02,837] [INFO] [runner_train_mujoco] Average state value: 0.47396812097231555
[2022-12-07 03:13:02,837] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 03:13:02,908] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.03618
[2022-12-07 03:13:02,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.01904, loss val: 0.03404
[2022-12-07 03:13:03,008] [INFO] [controller] EPOCH 3 loss ppo:  -0.02777, loss val: 0.03822
[2022-12-07 03:13:03,057] [INFO] [controller] EPOCH 4 loss ppo:  -0.03471, loss val: 0.03421
[2022-12-07 03:13:03,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:13:03,257] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:13:03,258] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:13:09,021] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:13:15,217] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:13:21,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:13:27,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:13:33,982] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:13:40,139] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:13:46,190] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:13:52,039] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:13:58,034] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:14:04,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5510796024774036
[2022-12-07 03:14:04,378] [INFO] [runner_train_mujoco] Average state value: 0.4606354848444463
[2022-12-07 03:14:04,378] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 03:14:04,442] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04158
[2022-12-07 03:14:04,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.01651, loss val: 0.04147
[2022-12-07 03:14:04,548] [INFO] [controller] EPOCH 3 loss ppo:  -0.02233, loss val: 0.04155
[2022-12-07 03:14:04,624] [INFO] [controller] EPOCH 4 loss ppo:  -0.02785, loss val: 0.04166
[2022-12-07 03:14:04,636] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:14:04,822] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:14:04,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:14:10,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:14:17,098] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:14:23,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:14:29,184] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:14:35,290] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:14:41,359] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:14:47,397] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:14:53,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:14:59,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:15:05,921] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7292569358290684
[2022-12-07 03:15:05,921] [INFO] [runner_train_mujoco] Average state value: 0.4649090340534846
[2022-12-07 03:15:05,921] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 03:15:06,002] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.04255
[2022-12-07 03:15:06,064] [INFO] [controller] EPOCH 2 loss ppo:  -0.01657, loss val: 0.04042
[2022-12-07 03:15:06,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.02058, loss val: 0.04030
[2022-12-07 03:15:06,176] [INFO] [controller] EPOCH 4 loss ppo:  -0.02474, loss val: 0.04042
[2022-12-07 03:15:06,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:15:06,381] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:15:06,382] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:15:12,549] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:15:18,990] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:15:25,122] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:15:31,140] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:15:37,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:15:44,092] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:15:50,140] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:15:56,358] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:16:02,616] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:16:09,029] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6825095401519254
[2022-12-07 03:16:09,029] [INFO] [runner_train_mujoco] Average state value: 0.4640621893604596
[2022-12-07 03:16:09,029] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 03:16:09,090] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.04064
[2022-12-07 03:16:09,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.01408, loss val: 0.04155
[2022-12-07 03:16:09,185] [INFO] [controller] EPOCH 3 loss ppo:  -0.01577, loss val: 0.04021
[2022-12-07 03:16:09,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.01789, loss val: 0.04103
[2022-12-07 03:16:09,243] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:16:09,366] [INFO] [optimize] Finished learning.
