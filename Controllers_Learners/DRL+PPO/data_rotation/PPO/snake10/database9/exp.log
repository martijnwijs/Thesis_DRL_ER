[2022-12-07 08:08:12,197] [INFO] [optimize] Starting learning
[2022-12-07 08:08:12,211] [INFO] [optimize] Starting learning process..
[2022-12-07 08:08:12,301] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:08:12,302] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:08:19,199] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:08:25,191] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:08:31,113] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:08:37,042] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:08:43,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:08:48,701] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:08:54,590] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:09:00,587] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:09:06,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:09:12,467] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.023983500088572
[2022-12-07 08:09:12,468] [INFO] [runner_train_mujoco] Average state value: -0.40495090484122437
[2022-12-07 08:09:12,468] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:09:12,527] [INFO] [controller] EPOCH 1 loss ppo:  -0.01553, loss val: 1.08972
[2022-12-07 08:09:12,571] [INFO] [controller] EPOCH 2 loss ppo:  -0.04237, loss val: 1.01400
[2022-12-07 08:09:12,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.05577, loss val: 0.98908
[2022-12-07 08:09:12,663] [INFO] [controller] EPOCH 4 loss ppo:  -0.06231, loss val: 0.86715
[2022-12-07 08:09:12,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:09:12,863] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:09:12,863] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:09:19,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:09:25,714] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:09:31,598] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:09:36,908] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:09:42,516] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:09:48,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:09:53,973] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:09:59,809] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:10:05,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:10:11,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1237548931100572
[2022-12-07 08:10:11,052] [INFO] [runner_train_mujoco] Average state value: -0.26603502906238036
[2022-12-07 08:10:11,052] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:10:11,101] [INFO] [controller] EPOCH 1 loss ppo:  -0.01570, loss val: 0.56975
[2022-12-07 08:10:11,145] [INFO] [controller] EPOCH 2 loss ppo:  -0.04130, loss val: 0.51870
[2022-12-07 08:10:11,190] [INFO] [controller] EPOCH 3 loss ppo:  -0.05715, loss val: 0.48065
[2022-12-07 08:10:11,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.06599, loss val: 0.43725
[2022-12-07 08:10:11,244] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:10:11,422] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:10:11,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:10:17,419] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:10:23,038] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:10:29,266] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:10:34,814] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:10:40,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:10:45,753] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:10:51,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:56,514] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:11:02,050] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:11:07,928] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1371371645784252
[2022-12-07 08:11:07,929] [INFO] [runner_train_mujoco] Average state value: -0.12403390367950003
[2022-12-07 08:11:07,929] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:11:07,994] [INFO] [controller] EPOCH 1 loss ppo:  -0.01259, loss val: 0.57099
[2022-12-07 08:11:08,045] [INFO] [controller] EPOCH 2 loss ppo:  -0.03703, loss val: 0.51543
[2022-12-07 08:11:08,094] [INFO] [controller] EPOCH 3 loss ppo:  -0.05181, loss val: 0.46715
[2022-12-07 08:11:08,153] [INFO] [controller] EPOCH 4 loss ppo:  -0.06111, loss val: 0.42437
[2022-12-07 08:11:08,163] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:08,344] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:08,344] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:11:14,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:11:20,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:11:26,710] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:11:32,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:11:37,617] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:11:43,187] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:11:48,516] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:11:54,252] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:12:00,116] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:12:05,509] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9089344902414223
[2022-12-07 08:12:05,509] [INFO] [runner_train_mujoco] Average state value: 0.01360581886023283
[2022-12-07 08:12:05,509] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:12:05,568] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.35100
[2022-12-07 08:12:05,616] [INFO] [controller] EPOCH 2 loss ppo:  -0.03757, loss val: 0.32484
[2022-12-07 08:12:05,664] [INFO] [controller] EPOCH 3 loss ppo:  -0.05031, loss val: 0.31050
[2022-12-07 08:12:05,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.05748, loss val: 0.27183
[2022-12-07 08:12:05,715] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:12:05,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:12:05,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:12:11,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:12:17,813] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:12:23,302] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:12:29,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:12:35,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:12:40,549] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:12:46,131] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:12:51,630] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:12:57,180] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:13:02,815] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0107687017297144
[2022-12-07 08:13:02,815] [INFO] [runner_train_mujoco] Average state value: 0.16351212845866878
[2022-12-07 08:13:02,815] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:13:02,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.19259
[2022-12-07 08:13:02,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.03759, loss val: 0.17056
[2022-12-07 08:13:02,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.04964, loss val: 0.15118
[2022-12-07 08:13:03,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.05901, loss val: 0.13003
[2022-12-07 08:13:03,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:13:03,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:13:03,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:13:09,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:13:14,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:13:21,109] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:13:26,756] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:13:32,295] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:13:37,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:13:43,007] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:13:48,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:13:54,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:14:00,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9553858003209348
[2022-12-07 08:14:00,304] [INFO] [runner_train_mujoco] Average state value: 0.2813297559681038
[2022-12-07 08:14:00,305] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:14:00,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.19605
[2022-12-07 08:14:00,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.03221, loss val: 0.16669
[2022-12-07 08:14:00,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.04660, loss val: 0.14741
[2022-12-07 08:14:00,501] [INFO] [controller] EPOCH 4 loss ppo:  -0.05371, loss val: 0.12415
[2022-12-07 08:14:00,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:14:00,676] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:14:00,676] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:14:06,488] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:14:12,067] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:14:17,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:23,231] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:14:29,061] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:14:34,485] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:14:40,466] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:14:46,062] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:14:51,626] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:14:57,183] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9660371524243703
[2022-12-07 08:14:57,184] [INFO] [runner_train_mujoco] Average state value: 0.4323755921895306
[2022-12-07 08:14:57,184] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:14:57,238] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.08060
[2022-12-07 08:14:57,280] [INFO] [controller] EPOCH 2 loss ppo:  -0.04201, loss val: 0.08004
[2022-12-07 08:14:57,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.05468, loss val: 0.07013
[2022-12-07 08:14:57,370] [INFO] [controller] EPOCH 4 loss ppo:  -0.06289, loss val: 0.06279
[2022-12-07 08:14:57,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:14:57,542] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:14:57,542] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:15:02,916] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:15:08,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:15:14,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:15:19,596] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:15:25,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:15:31,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:15:36,519] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:15:42,147] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:15:47,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:15:54,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2959104287087575
[2022-12-07 08:15:54,042] [INFO] [runner_train_mujoco] Average state value: 0.5347938477508725
[2022-12-07 08:15:54,042] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:15:54,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.01558, loss val: 0.06195
[2022-12-07 08:15:54,152] [INFO] [controller] EPOCH 2 loss ppo:  -0.03945, loss val: 0.05924
[2022-12-07 08:15:54,196] [INFO] [controller] EPOCH 3 loss ppo:  -0.04883, loss val: 0.05627
[2022-12-07 08:15:54,243] [INFO] [controller] EPOCH 4 loss ppo:  -0.05936, loss val: 0.05332
[2022-12-07 08:15:54,254] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:15:54,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:15:54,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:16:00,423] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:16:06,294] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:16:11,672] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:16:17,126] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:16:23,211] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:28,681] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:34,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:16:40,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:16:46,573] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:16:51,885] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0591642194093682
[2022-12-07 08:16:51,885] [INFO] [runner_train_mujoco] Average state value: 0.5444768238502244
[2022-12-07 08:16:51,885] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:16:51,935] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.04944
[2022-12-07 08:16:51,975] [INFO] [controller] EPOCH 2 loss ppo:  -0.03763, loss val: 0.05056
[2022-12-07 08:16:52,017] [INFO] [controller] EPOCH 3 loss ppo:  -0.04813, loss val: 0.04796
[2022-12-07 08:16:52,061] [INFO] [controller] EPOCH 4 loss ppo:  -0.05923, loss val: 0.04286
[2022-12-07 08:16:52,071] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:16:52,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:16:52,250] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:16:57,614] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:17:03,415] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:17:09,004] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:17:14,706] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:17:20,402] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:17:26,196] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:17:31,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:17:37,416] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:17:42,588] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:17:48,152] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0422429065479102
[2022-12-07 08:17:48,152] [INFO] [runner_train_mujoco] Average state value: 0.5351543284555277
[2022-12-07 08:17:48,152] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 08:17:48,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01145, loss val: 0.05480
[2022-12-07 08:17:48,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.03648, loss val: 0.05407
[2022-12-07 08:17:48,286] [INFO] [controller] EPOCH 3 loss ppo:  -0.05092, loss val: 0.05223
[2022-12-07 08:17:48,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.06166, loss val: 0.05172
[2022-12-07 08:17:48,334] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:17:48,518] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:17:48,519] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:17:54,443] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:18:00,352] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:18:06,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:18:12,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:18:19,536] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:18:25,479] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:18:31,247] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:18:37,232] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:18:42,909] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:18:48,450] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9303165907246946
[2022-12-07 08:18:48,450] [INFO] [runner_train_mujoco] Average state value: 0.5230237389256557
[2022-12-07 08:18:48,450] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 08:18:48,498] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.03783
[2022-12-07 08:18:48,532] [INFO] [controller] EPOCH 2 loss ppo:  -0.03644, loss val: 0.03771
[2022-12-07 08:18:48,574] [INFO] [controller] EPOCH 3 loss ppo:  -0.04862, loss val: 0.03431
[2022-12-07 08:18:48,616] [INFO] [controller] EPOCH 4 loss ppo:  -0.05707, loss val: 0.03124
[2022-12-07 08:18:48,626] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:18:48,790] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:18:48,791] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:18:54,101] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:18:59,642] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:19:05,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:19:10,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:19:16,585] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:19:22,651] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:19:28,662] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:19:34,299] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:19:39,993] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:45,323] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0162530226994266
[2022-12-07 08:19:45,323] [INFO] [runner_train_mujoco] Average state value: 0.5139706256786982
[2022-12-07 08:19:45,324] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 08:19:45,379] [INFO] [controller] EPOCH 1 loss ppo:  -0.01215, loss val: 0.03837
[2022-12-07 08:19:45,425] [INFO] [controller] EPOCH 2 loss ppo:  -0.03699, loss val: 0.03763
[2022-12-07 08:19:45,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.04847, loss val: 0.03790
[2022-12-07 08:19:45,585] [INFO] [controller] EPOCH 4 loss ppo:  -0.05765, loss val: 0.03993
[2022-12-07 08:19:45,594] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:45,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:45,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:51,542] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:19:57,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:20:02,796] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:20:08,434] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:20:13,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:20:18,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:20:24,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:20:30,314] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:20:35,939] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:20:41,920] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2263107804443814
[2022-12-07 08:20:41,921] [INFO] [runner_train_mujoco] Average state value: 0.510133692825834
[2022-12-07 08:20:41,921] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 08:20:41,974] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.04260
[2022-12-07 08:20:42,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.03226, loss val: 0.04212
[2022-12-07 08:20:42,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.04601, loss val: 0.04202
[2022-12-07 08:20:42,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.05810, loss val: 0.04164
[2022-12-07 08:20:42,115] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:20:42,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:20:42,288] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:20:48,072] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:20:53,962] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:20:59,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:05,647] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:21:11,324] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:21:16,776] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:21:22,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:21:27,812] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:21:33,314] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:21:39,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2273054478019847
[2022-12-07 08:21:39,092] [INFO] [runner_train_mujoco] Average state value: 0.5388147794008254
[2022-12-07 08:21:39,092] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 08:21:39,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.01006, loss val: 0.02759
[2022-12-07 08:21:39,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.03570, loss val: 0.02832
[2022-12-07 08:21:39,239] [INFO] [controller] EPOCH 3 loss ppo:  -0.04537, loss val: 0.02658
[2022-12-07 08:21:39,289] [INFO] [controller] EPOCH 4 loss ppo:  -0.05441, loss val: 0.02704
[2022-12-07 08:21:39,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:21:39,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:21:39,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:21:45,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:21:50,807] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:56,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:22:01,889] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:07,466] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:22:13,008] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:22:18,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:22:24,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:22:30,468] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:22:36,157] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1249021058387674
[2022-12-07 08:22:36,157] [INFO] [runner_train_mujoco] Average state value: 0.563010968287786
[2022-12-07 08:22:36,157] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 08:22:36,208] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.03232
[2022-12-07 08:22:36,252] [INFO] [controller] EPOCH 2 loss ppo:  -0.04135, loss val: 0.03242
[2022-12-07 08:22:36,296] [INFO] [controller] EPOCH 3 loss ppo:  -0.05232, loss val: 0.03522
[2022-12-07 08:22:36,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.06256, loss val: 0.03265
[2022-12-07 08:22:36,348] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:22:36,528] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:22:36,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:22:42,175] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:22:47,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:22:53,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:22:58,548] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:23:03,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:23:09,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:23:14,904] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:23:20,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:23:26,125] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:23:31,807] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2392740218534501
[2022-12-07 08:23:31,807] [INFO] [runner_train_mujoco] Average state value: 0.563847865362962
[2022-12-07 08:23:31,807] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 08:23:31,876] [INFO] [controller] EPOCH 1 loss ppo:  -0.01146, loss val: 0.04100
[2022-12-07 08:23:31,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.03190, loss val: 0.03664
[2022-12-07 08:23:31,980] [INFO] [controller] EPOCH 3 loss ppo:  -0.04889, loss val: 0.03765
[2022-12-07 08:23:32,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.05858, loss val: 0.03389
[2022-12-07 08:23:32,038] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:23:32,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:23:32,219] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:23:38,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:23:43,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:23:49,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:23:55,171] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:24:00,407] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:24:06,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:24:11,682] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:17,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:24:22,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:24:28,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1413021804397336
[2022-12-07 08:24:28,402] [INFO] [runner_train_mujoco] Average state value: 0.5237820124824842
[2022-12-07 08:24:28,402] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 08:24:28,463] [INFO] [controller] EPOCH 1 loss ppo:  -0.01239, loss val: 0.03749
[2022-12-07 08:24:28,512] [INFO] [controller] EPOCH 2 loss ppo:  -0.03831, loss val: 0.03659
[2022-12-07 08:24:28,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.05073, loss val: 0.03932
[2022-12-07 08:24:28,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.06011, loss val: 0.03609
[2022-12-07 08:24:28,620] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:24:28,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:24:28,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:24:34,615] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:24:40,289] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:24:45,740] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:24:51,519] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:24:56,858] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:02,714] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:25:08,380] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:25:13,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:25:19,264] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:25:24,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4344504426330984
[2022-12-07 08:25:24,979] [INFO] [runner_train_mujoco] Average state value: 0.47054300663868587
[2022-12-07 08:25:24,979] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 08:25:25,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.01567, loss val: 0.03039
[2022-12-07 08:25:25,075] [INFO] [controller] EPOCH 2 loss ppo:  -0.04394, loss val: 0.03170
[2022-12-07 08:25:25,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.05607, loss val: 0.03066
[2022-12-07 08:25:25,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.06410, loss val: 0.03016
[2022-12-07 08:25:25,168] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:25:25,343] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:25:25,343] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:25:30,524] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:25:36,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:25:41,546] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:25:47,439] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:25:52,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:58,098] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:26:03,542] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:26:09,373] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:26:14,654] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:26:20,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5048514139885993
[2022-12-07 08:26:20,459] [INFO] [runner_train_mujoco] Average state value: 0.4293572292501728
[2022-12-07 08:26:20,459] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 08:26:20,516] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04675
[2022-12-07 08:26:20,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.03352, loss val: 0.04655
[2022-12-07 08:26:20,606] [INFO] [controller] EPOCH 3 loss ppo:  -0.04566, loss val: 0.04490
[2022-12-07 08:26:20,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.05955, loss val: 0.04404
[2022-12-07 08:26:20,665] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:26:20,854] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:26:20,855] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:26,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:26:32,096] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:26:37,861] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:26:43,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:26:49,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:26:55,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:27:00,747] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:27:06,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:27:11,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:27:17,141] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3064684875818107
[2022-12-07 08:27:17,142] [INFO] [runner_train_mujoco] Average state value: 0.4446010799979169
[2022-12-07 08:27:17,142] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 08:27:17,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01207, loss val: 0.05741
[2022-12-07 08:27:17,246] [INFO] [controller] EPOCH 2 loss ppo:  -0.03731, loss val: 0.05717
[2022-12-07 08:27:17,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.05112, loss val: 0.05507
[2022-12-07 08:27:17,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.06097, loss val: 0.05451
[2022-12-07 08:27:17,348] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:27:17,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:27:17,526] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:27:23,239] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:27:29,140] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:27:34,887] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:27:40,809] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:27:46,588] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:27:51,885] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:27:57,485] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:28:02,855] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:28:08,145] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:28:13,899] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.447881400509445
[2022-12-07 08:28:13,899] [INFO] [runner_train_mujoco] Average state value: 0.5003414975466828
[2022-12-07 08:28:13,899] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 08:28:13,946] [INFO] [controller] EPOCH 1 loss ppo:  -0.01198, loss val: 0.04653
[2022-12-07 08:28:13,989] [INFO] [controller] EPOCH 2 loss ppo:  -0.03495, loss val: 0.04581
[2022-12-07 08:28:14,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.05316, loss val: 0.04675
[2022-12-07 08:28:14,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.06385, loss val: 0.04675
[2022-12-07 08:28:14,088] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:28:14,279] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:28:14,279] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:28:19,656] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:28:25,255] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:28:30,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:28:36,549] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:28:42,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:28:47,737] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:28:53,444] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:28:58,976] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:29:04,366] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:29:09,927] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7503295504144833
[2022-12-07 08:29:09,927] [INFO] [runner_train_mujoco] Average state value: 0.5265597769816717
[2022-12-07 08:29:09,927] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 08:29:09,976] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04417
[2022-12-07 08:29:10,020] [INFO] [controller] EPOCH 2 loss ppo:  -0.03628, loss val: 0.04377
[2022-12-07 08:29:10,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.04943, loss val: 0.04396
[2022-12-07 08:29:10,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.05780, loss val: 0.04587
[2022-12-07 08:29:10,115] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:29:10,285] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:29:10,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:29:15,704] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:29:21,465] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:29:26,759] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:29:32,418] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:29:38,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:43,783] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:29:49,064] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:29:54,671] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:30:00,472] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:30:06,167] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7235796144983724
[2022-12-07 08:30:06,168] [INFO] [runner_train_mujoco] Average state value: 0.5592364990313847
[2022-12-07 08:30:06,168] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 08:30:06,222] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.04798
[2022-12-07 08:30:06,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.03124, loss val: 0.04850
[2022-12-07 08:30:06,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.04350, loss val: 0.04508
[2022-12-07 08:30:06,374] [INFO] [controller] EPOCH 4 loss ppo:  -0.05509, loss val: 0.04227
[2022-12-07 08:30:06,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:30:06,553] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:30:06,553] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:30:12,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:30:17,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:30:23,399] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:30:28,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:30:34,482] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:30:40,272] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:30:45,834] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:30:51,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:30:56,616] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:01,840] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.735879629143485
[2022-12-07 08:31:01,840] [INFO] [runner_train_mujoco] Average state value: 0.5243429634769757
[2022-12-07 08:31:01,840] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 08:31:01,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.04272
[2022-12-07 08:31:01,937] [INFO] [controller] EPOCH 2 loss ppo:  -0.03596, loss val: 0.03982
[2022-12-07 08:31:01,987] [INFO] [controller] EPOCH 3 loss ppo:  -0.04823, loss val: 0.03721
[2022-12-07 08:31:02,033] [INFO] [controller] EPOCH 4 loss ppo:  -0.06217, loss val: 0.03578
[2022-12-07 08:31:02,042] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:02,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:02,227] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:31:07,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:31:13,363] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:31:18,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:31:24,482] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:31:30,242] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:31:35,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:31:41,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:31:46,988] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:52,699] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:58,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9948242248502754
[2022-12-07 08:31:58,219] [INFO] [runner_train_mujoco] Average state value: 0.4094491135329008
[2022-12-07 08:31:58,219] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 08:31:58,283] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.05190
[2022-12-07 08:31:58,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.03441, loss val: 0.05529
[2022-12-07 08:31:58,371] [INFO] [controller] EPOCH 3 loss ppo:  -0.04906, loss val: 0.05346
[2022-12-07 08:31:58,476] [INFO] [controller] EPOCH 4 loss ppo:  -0.06132, loss val: 0.05441
[2022-12-07 08:31:58,485] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:58,657] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:58,658] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:32:03,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:32:09,406] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:32:14,727] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:32:20,509] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:32:25,815] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:32:31,303] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:32:37,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:32:42,325] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:32:47,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:32:53,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.754282358609166
[2022-12-07 08:32:53,297] [INFO] [runner_train_mujoco] Average state value: 0.42683223022023836
[2022-12-07 08:32:53,298] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 08:32:53,350] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04357
[2022-12-07 08:32:53,391] [INFO] [controller] EPOCH 2 loss ppo:  -0.03077, loss val: 0.04258
[2022-12-07 08:32:53,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.04528, loss val: 0.04522
[2022-12-07 08:32:53,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.05572, loss val: 0.04210
[2022-12-07 08:32:53,485] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:32:53,660] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:32:53,660] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:32:59,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:33:05,322] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:33:11,155] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:33:16,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:33:22,034] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:33:27,165] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:33:32,481] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:33:38,091] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:33:43,580] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:33:49,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.046154699320626
[2022-12-07 08:33:49,542] [INFO] [runner_train_mujoco] Average state value: 0.43644114681333307
[2022-12-07 08:33:49,542] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 08:33:49,599] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04529
[2022-12-07 08:33:49,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.03985, loss val: 0.04451
[2022-12-07 08:33:49,682] [INFO] [controller] EPOCH 3 loss ppo:  -0.05193, loss val: 0.04568
[2022-12-07 08:33:49,724] [INFO] [controller] EPOCH 4 loss ppo:  -0.06142, loss val: 0.04468
[2022-12-07 08:33:49,733] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:33:49,912] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:33:49,913] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:55,781] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:01,509] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:34:06,797] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:34:12,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:34:17,358] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:34:23,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:34:28,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:34:34,273] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:34:39,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:34:45,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.228945819122891
[2022-12-07 08:34:45,505] [INFO] [runner_train_mujoco] Average state value: 0.4646530468960603
[2022-12-07 08:34:45,505] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 08:34:45,563] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.03017
[2022-12-07 08:34:45,611] [INFO] [controller] EPOCH 2 loss ppo:  -0.03263, loss val: 0.02997
[2022-12-07 08:34:45,664] [INFO] [controller] EPOCH 3 loss ppo:  -0.04466, loss val: 0.03156
[2022-12-07 08:34:45,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.05605, loss val: 0.02965
[2022-12-07 08:34:45,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:34:45,907] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:34:45,908] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:34:51,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:57,512] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:35:03,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:08,373] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:35:14,046] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:35:19,616] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:35:25,325] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:35:30,917] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:35:36,284] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:35:42,046] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3166808151908542
[2022-12-07 08:35:42,047] [INFO] [runner_train_mujoco] Average state value: 0.44284138218561814
[2022-12-07 08:35:42,047] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 08:35:42,099] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.05313
[2022-12-07 08:35:42,146] [INFO] [controller] EPOCH 2 loss ppo:  -0.02626, loss val: 0.05213
[2022-12-07 08:35:42,192] [INFO] [controller] EPOCH 3 loss ppo:  -0.03673, loss val: 0.05054
[2022-12-07 08:35:42,240] [INFO] [controller] EPOCH 4 loss ppo:  -0.05005, loss val: 0.04744
[2022-12-07 08:35:42,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:35:42,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:35:42,432] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:35:48,064] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:35:53,869] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:35:59,188] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:36:04,829] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:10,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:36:15,613] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:36:21,209] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:36:26,453] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:36:32,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:36:37,484] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.112143264654978
[2022-12-07 08:36:37,485] [INFO] [runner_train_mujoco] Average state value: 0.478514428794384
[2022-12-07 08:36:37,485] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 08:36:37,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01550, loss val: 0.03888
[2022-12-07 08:36:37,591] [INFO] [controller] EPOCH 2 loss ppo:  -0.03498, loss val: 0.03999
[2022-12-07 08:36:37,645] [INFO] [controller] EPOCH 3 loss ppo:  -0.04396, loss val: 0.04053
[2022-12-07 08:36:37,691] [INFO] [controller] EPOCH 4 loss ppo:  -0.05942, loss val: 0.04139
[2022-12-07 08:36:37,700] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:36:37,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:36:37,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:36:43,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:36:49,443] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:36:55,226] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:37:00,410] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:37:06,123] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:37:11,379] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:37:16,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:37:22,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:37:28,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:37:34,095] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0794123486841114
[2022-12-07 08:37:34,095] [INFO] [runner_train_mujoco] Average state value: 0.4922837556228042
[2022-12-07 08:37:34,095] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 08:37:34,164] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04205
[2022-12-07 08:37:34,216] [INFO] [controller] EPOCH 2 loss ppo:  -0.02725, loss val: 0.04191
[2022-12-07 08:37:34,264] [INFO] [controller] EPOCH 3 loss ppo:  -0.04100, loss val: 0.04230
[2022-12-07 08:37:34,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.05622, loss val: 0.04054
[2022-12-07 08:37:34,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:37:34,527] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:37:34,528] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:37:39,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:37:45,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:37:51,446] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:37:58,709] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:38:04,826] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:38:10,333] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:38:16,016] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:38:22,405] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:38:28,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:38:34,625] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.160743669856255
[2022-12-07 08:38:34,625] [INFO] [runner_train_mujoco] Average state value: 0.47856218923628335
[2022-12-07 08:38:34,625] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 08:38:34,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.04382
[2022-12-07 08:38:34,736] [INFO] [controller] EPOCH 2 loss ppo:  -0.03004, loss val: 0.04437
[2022-12-07 08:38:34,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.04262, loss val: 0.04553
[2022-12-07 08:38:34,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.05412, loss val: 0.04456
[2022-12-07 08:38:34,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:38:35,094] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:38:35,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:38:40,650] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:38:46,021] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:38:52,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:38:58,891] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:39:04,455] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:39:09,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:39:15,595] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:39:21,000] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:39:26,407] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:39:31,840] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4609780057390913
[2022-12-07 08:39:31,840] [INFO] [runner_train_mujoco] Average state value: 0.5064138302008311
[2022-12-07 08:39:31,840] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 08:39:31,944] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.03299
[2022-12-07 08:39:31,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.03029, loss val: 0.03407
[2022-12-07 08:39:32,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.04108, loss val: 0.03317
[2022-12-07 08:39:32,071] [INFO] [controller] EPOCH 4 loss ppo:  -0.05515, loss val: 0.03080
[2022-12-07 08:39:32,081] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:39:32,253] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:39:32,253] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:39:37,748] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:39:43,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:39:48,716] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:39:54,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:00,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:40:05,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:40:11,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:40:17,228] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:40:22,742] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:40:27,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.477047161605925
[2022-12-07 08:40:27,958] [INFO] [runner_train_mujoco] Average state value: 0.47114425282677014
[2022-12-07 08:40:27,958] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 08:40:28,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.04551
[2022-12-07 08:40:28,066] [INFO] [controller] EPOCH 2 loss ppo:  -0.02964, loss val: 0.04645
[2022-12-07 08:40:28,108] [INFO] [controller] EPOCH 3 loss ppo:  -0.04427, loss val: 0.04683
[2022-12-07 08:40:28,151] [INFO] [controller] EPOCH 4 loss ppo:  -0.05602, loss val: 0.04563
[2022-12-07 08:40:28,159] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:40:28,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:40:28,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:40:34,289] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:40:40,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:40:45,436] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:40:50,805] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:56,449] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:41:01,468] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:41:07,095] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:41:12,953] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:41:18,134] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:41:23,714] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6950361362544983
[2022-12-07 08:41:23,714] [INFO] [runner_train_mujoco] Average state value: 0.46772782129049306
[2022-12-07 08:41:23,714] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 08:41:23,764] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.03656
[2022-12-07 08:41:23,815] [INFO] [controller] EPOCH 2 loss ppo:  -0.03032, loss val: 0.03479
[2022-12-07 08:41:23,864] [INFO] [controller] EPOCH 3 loss ppo:  -0.04372, loss val: 0.03607
[2022-12-07 08:41:23,907] [INFO] [controller] EPOCH 4 loss ppo:  -0.05750, loss val: 0.03523
[2022-12-07 08:41:23,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:41:24,097] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:41:24,097] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:41:29,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:41:35,302] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:41:41,137] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:41:47,180] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:41:53,071] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:41:58,676] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:42:03,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:42:10,061] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:42:15,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:42:20,908] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.696544054009147
[2022-12-07 08:42:20,908] [INFO] [runner_train_mujoco] Average state value: 0.4710690414309502
[2022-12-07 08:42:20,908] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 08:42:21,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.04279
[2022-12-07 08:42:21,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.03086, loss val: 0.04326
[2022-12-07 08:42:21,102] [INFO] [controller] EPOCH 3 loss ppo:  -0.04470, loss val: 0.04273
[2022-12-07 08:42:21,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.05870, loss val: 0.04163
[2022-12-07 08:42:21,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:42:21,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:42:21,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:42:26,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:42:32,555] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:42:38,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:42:43,729] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:42:49,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:42:54,711] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:43:00,410] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:43:05,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:43:11,338] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:43:17,167] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.521129538472478
[2022-12-07 08:43:17,167] [INFO] [runner_train_mujoco] Average state value: 0.4491368665471673
[2022-12-07 08:43:17,168] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 08:43:17,226] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.05103
[2022-12-07 08:43:17,267] [INFO] [controller] EPOCH 2 loss ppo:  -0.02595, loss val: 0.05074
[2022-12-07 08:43:17,308] [INFO] [controller] EPOCH 3 loss ppo:  -0.03679, loss val: 0.04845
[2022-12-07 08:43:17,350] [INFO] [controller] EPOCH 4 loss ppo:  -0.04915, loss val: 0.04741
[2022-12-07 08:43:17,359] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:43:17,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:43:17,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:43:23,961] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:43:29,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:43:35,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:43:40,498] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:43:45,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:43:51,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:43:56,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:44:02,044] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:44:07,956] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:44:13,575] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5016463673858587
[2022-12-07 08:44:13,575] [INFO] [runner_train_mujoco] Average state value: 0.4878605952759584
[2022-12-07 08:44:13,575] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 08:44:13,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.03721
[2022-12-07 08:44:13,667] [INFO] [controller] EPOCH 2 loss ppo:  -0.02907, loss val: 0.03758
[2022-12-07 08:44:13,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.04294, loss val: 0.03763
[2022-12-07 08:44:13,751] [INFO] [controller] EPOCH 4 loss ppo:  -0.05526, loss val: 0.03745
[2022-12-07 08:44:13,760] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:44:13,943] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:44:13,944] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:44:19,923] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:44:25,751] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:44:30,892] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:44:36,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:44:41,822] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:44:47,400] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:44:52,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:44:58,161] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:45:03,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:45:08,850] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6774273339902033
[2022-12-07 08:45:08,850] [INFO] [runner_train_mujoco] Average state value: 0.4978302137951056
[2022-12-07 08:45:08,850] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 08:45:08,902] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04253
[2022-12-07 08:45:08,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.02558, loss val: 0.04248
[2022-12-07 08:45:08,984] [INFO] [controller] EPOCH 3 loss ppo:  -0.03828, loss val: 0.04317
[2022-12-07 08:45:09,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.04991, loss val: 0.04355
[2022-12-07 08:45:09,031] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:45:09,227] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:45:09,227] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:45:15,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:45:21,037] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:45:28,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:45:35,552] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:45:41,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:45:47,337] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:45:53,572] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:45:59,219] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:46:05,126] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:46:11,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7531240064289513
[2022-12-07 08:46:11,328] [INFO] [runner_train_mujoco] Average state value: 0.515784471626083
[2022-12-07 08:46:11,328] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 08:46:11,392] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.03576
[2022-12-07 08:46:11,453] [INFO] [controller] EPOCH 2 loss ppo:  -0.03094, loss val: 0.03567
[2022-12-07 08:46:11,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.04188, loss val: 0.03573
[2022-12-07 08:46:11,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.05252, loss val: 0.03639
[2022-12-07 08:46:11,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:46:11,774] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:46:11,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:46:18,247] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:46:24,510] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:46:31,519] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:46:37,376] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:46:43,106] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:46:48,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:46:55,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:47:01,384] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:47:07,494] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:47:13,416] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.046553712753729
[2022-12-07 08:47:13,416] [INFO] [runner_train_mujoco] Average state value: 0.5226089362899463
[2022-12-07 08:47:13,416] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 08:47:13,473] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.03957
[2022-12-07 08:47:13,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.02967, loss val: 0.04014
[2022-12-07 08:47:13,566] [INFO] [controller] EPOCH 3 loss ppo:  -0.04364, loss val: 0.04000
[2022-12-07 08:47:13,617] [INFO] [controller] EPOCH 4 loss ppo:  -0.05384, loss val: 0.03938
[2022-12-07 08:47:13,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:47:13,811] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:47:13,811] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:47:19,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:47:25,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:47:30,670] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:47:36,047] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:47:42,451] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:47:49,676] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:47:55,914] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:48:02,220] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:48:07,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:48:13,097] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1468690595927358
[2022-12-07 08:48:13,097] [INFO] [runner_train_mujoco] Average state value: 0.5248110257188479
[2022-12-07 08:48:13,097] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 08:48:13,147] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.03643
[2022-12-07 08:48:13,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.02760, loss val: 0.03634
[2022-12-07 08:48:13,236] [INFO] [controller] EPOCH 3 loss ppo:  -0.03780, loss val: 0.03649
[2022-12-07 08:48:13,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.04788, loss val: 0.03647
[2022-12-07 08:48:13,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:48:13,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:48:13,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:48:19,549] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:48:25,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:48:31,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:48:36,480] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:48:42,014] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:48:47,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:48:53,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:48:58,536] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:49:03,699] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:49:08,803] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.925396895584796
[2022-12-07 08:49:08,804] [INFO] [runner_train_mujoco] Average state value: 0.5286089035769305
[2022-12-07 08:49:08,804] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 08:49:08,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.03812
[2022-12-07 08:49:08,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.02747, loss val: 0.03814
[2022-12-07 08:49:08,947] [INFO] [controller] EPOCH 3 loss ppo:  -0.03852, loss val: 0.03983
[2022-12-07 08:49:08,983] [INFO] [controller] EPOCH 4 loss ppo:  -0.05006, loss val: 0.04029
[2022-12-07 08:49:08,992] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:49:09,175] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:49:09,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:49:14,634] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:49:20,370] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:49:25,799] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:49:31,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:49:38,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:49:44,999] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:49:51,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:49:57,790] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:50:04,338] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:50:10,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.668826701713629
[2022-12-07 08:50:10,447] [INFO] [runner_train_mujoco] Average state value: 0.5129574591914812
[2022-12-07 08:50:10,447] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 08:50:10,510] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.05242
[2022-12-07 08:50:10,565] [INFO] [controller] EPOCH 2 loss ppo:  -0.02191, loss val: 0.05197
[2022-12-07 08:50:10,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.03300, loss val: 0.04922
[2022-12-07 08:50:10,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.04201, loss val: 0.05229
[2022-12-07 08:50:10,665] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:50:10,852] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:50:10,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:50:17,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:50:23,588] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:50:29,824] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:50:36,274] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:50:42,328] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:50:48,796] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:50:55,093] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:51:01,373] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:51:07,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:51:13,932] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.684369242500258
[2022-12-07 08:51:13,932] [INFO] [runner_train_mujoco] Average state value: 0.5129585847953956
[2022-12-07 08:51:13,932] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 08:51:14,092] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.04703
[2022-12-07 08:51:14,141] [INFO] [controller] EPOCH 2 loss ppo:  -0.02343, loss val: 0.04558
[2022-12-07 08:51:14,197] [INFO] [controller] EPOCH 3 loss ppo:  -0.03463, loss val: 0.04535
[2022-12-07 08:51:14,252] [INFO] [controller] EPOCH 4 loss ppo:  -0.04549, loss val: 0.04618
[2022-12-07 08:51:14,262] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:51:14,466] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:51:14,467] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:20,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:51:26,902] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:51:33,060] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:51:39,380] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:51:45,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:51:51,681] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:51:57,780] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:52:03,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:52:10,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:52:15,877] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5249569230957754
[2022-12-07 08:52:15,877] [INFO] [runner_train_mujoco] Average state value: 0.4984852451781432
[2022-12-07 08:52:15,877] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 08:52:15,944] [INFO] [controller] EPOCH 1 loss ppo:  -0.01253, loss val: 0.03101
[2022-12-07 08:52:15,998] [INFO] [controller] EPOCH 2 loss ppo:  -0.02027, loss val: 0.03089
[2022-12-07 08:52:16,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.03187, loss val: 0.03229
[2022-12-07 08:52:16,162] [INFO] [controller] EPOCH 4 loss ppo:  -0.04276, loss val: 0.03271
[2022-12-07 08:52:16,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:52:16,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:52:16,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:52:22,460] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:52:28,787] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:52:34,819] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:52:40,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:52:47,065] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:52:53,047] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:52:59,192] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:53:05,675] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:53:11,544] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:53:17,820] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.345285867870918
[2022-12-07 08:53:17,820] [INFO] [runner_train_mujoco] Average state value: 0.48772812207539884
[2022-12-07 08:53:17,821] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 08:53:17,884] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04104
[2022-12-07 08:53:17,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.02557, loss val: 0.04313
[2022-12-07 08:53:17,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.03540, loss val: 0.04161
[2022-12-07 08:53:18,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.04391, loss val: 0.04092
[2022-12-07 08:53:18,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:53:18,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:53:18,227] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:53:24,591] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:53:30,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:36,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:42,773] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:53:48,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:54,784] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:54:00,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:54:07,009] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:54:12,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:54:19,121] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.064915117686909
[2022-12-07 08:54:19,121] [INFO] [runner_train_mujoco] Average state value: 0.4801839339782794
[2022-12-07 08:54:19,121] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 08:54:19,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.03966
[2022-12-07 08:54:19,259] [INFO] [controller] EPOCH 2 loss ppo:  -0.02410, loss val: 0.03923
[2022-12-07 08:54:19,333] [INFO] [controller] EPOCH 3 loss ppo:  -0.03294, loss val: 0.03923
[2022-12-07 08:54:19,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.03964, loss val: 0.03879
[2022-12-07 08:54:19,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:54:19,585] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:54:19,585] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:54:26,008] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:54:32,483] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:54:38,949] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:54:45,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:54:51,159] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:54:56,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:02,754] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:55:08,961] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:55:15,139] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:55:21,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7487841325923656
[2022-12-07 08:55:21,298] [INFO] [runner_train_mujoco] Average state value: 0.4805148823559285
[2022-12-07 08:55:21,298] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 08:55:21,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.04347
[2022-12-07 08:55:21,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.02215, loss val: 0.04320
[2022-12-07 08:55:21,480] [INFO] [controller] EPOCH 3 loss ppo:  -0.03094, loss val: 0.04220
[2022-12-07 08:55:21,549] [INFO] [controller] EPOCH 4 loss ppo:  -0.03883, loss val: 0.04322
[2022-12-07 08:55:21,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:55:21,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:55:21,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:55:27,985] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:55:34,453] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:55:40,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:55:46,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:55:52,780] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:55:58,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:56:04,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:56:10,823] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:56:17,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:56:23,441] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.282267360526183
[2022-12-07 08:56:23,441] [INFO] [runner_train_mujoco] Average state value: 0.48699013030529026
[2022-12-07 08:56:23,441] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 08:56:23,500] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04072
[2022-12-07 08:56:23,550] [INFO] [controller] EPOCH 2 loss ppo:  -0.02067, loss val: 0.04091
[2022-12-07 08:56:23,599] [INFO] [controller] EPOCH 3 loss ppo:  -0.03319, loss val: 0.04086
[2022-12-07 08:56:23,645] [INFO] [controller] EPOCH 4 loss ppo:  -0.04046, loss val: 0.04071
[2022-12-07 08:56:23,657] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:56:23,882] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:56:23,882] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:56:30,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:56:36,852] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:56:42,934] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:56:49,487] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:56:55,675] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:57:01,746] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:57:07,964] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:57:14,170] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:20,432] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:26,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.34942974652551
[2022-12-07 08:57:26,420] [INFO] [runner_train_mujoco] Average state value: 0.48337398784359287
[2022-12-07 08:57:26,420] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 08:57:26,492] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04114
[2022-12-07 08:57:26,538] [INFO] [controller] EPOCH 2 loss ppo:  -0.02284, loss val: 0.03592
[2022-12-07 08:57:26,595] [INFO] [controller] EPOCH 3 loss ppo:  -0.03538, loss val: 0.03670
[2022-12-07 08:57:26,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.04262, loss val: 0.03680
[2022-12-07 08:57:26,655] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:26,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:26,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:57:33,399] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:57:39,710] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:57:45,931] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:57:52,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:57:57,953] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:58:03,647] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:58:09,668] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:15,561] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:58:21,520] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:58:27,655] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4068164704000687
[2022-12-07 08:58:27,656] [INFO] [runner_train_mujoco] Average state value: 0.4690154979030291
[2022-12-07 08:58:27,656] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 08:58:27,713] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.05287
[2022-12-07 08:58:27,758] [INFO] [controller] EPOCH 2 loss ppo:  -0.01986, loss val: 0.05210
[2022-12-07 08:58:27,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.02724, loss val: 0.05281
[2022-12-07 08:58:27,848] [INFO] [controller] EPOCH 4 loss ppo:  -0.03445, loss val: 0.05292
[2022-12-07 08:58:27,857] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:58:28,049] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:58:28,049] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:58:33,908] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:58:40,089] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:58:46,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:58:52,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:58:58,798] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:59:05,188] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:59:11,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:59:17,429] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:59:23,697] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:59:29,385] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4679041957838606
[2022-12-07 08:59:29,386] [INFO] [runner_train_mujoco] Average state value: 0.48452499536673227
[2022-12-07 08:59:29,386] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 08:59:29,443] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.03765
[2022-12-07 08:59:29,486] [INFO] [controller] EPOCH 2 loss ppo:  -0.01867, loss val: 0.03749
[2022-12-07 08:59:29,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.02839, loss val: 0.03801
[2022-12-07 08:59:29,570] [INFO] [controller] EPOCH 4 loss ppo:  -0.03577, loss val: 0.03762
[2022-12-07 08:59:29,580] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:59:29,767] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:59:29,768] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:59:35,605] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:59:42,207] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:59:48,236] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:59:54,470] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:00:00,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:00:06,686] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:00:12,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:00:18,642] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:00:24,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:00:30,372] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.511417471313938
[2022-12-07 09:00:30,373] [INFO] [runner_train_mujoco] Average state value: 0.46833338774243993
[2022-12-07 09:00:30,373] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 09:00:30,433] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.03377
[2022-12-07 09:00:30,480] [INFO] [controller] EPOCH 2 loss ppo:  -0.01725, loss val: 0.03508
[2022-12-07 09:00:30,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.02440, loss val: 0.03442
[2022-12-07 09:00:30,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.03056, loss val: 0.03418
[2022-12-07 09:00:30,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:00:30,801] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:00:30,801] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:00:37,010] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:00:43,232] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:00:49,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:00:55,809] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:01:01,788] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:07,757] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:13,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:01:19,874] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:01:26,015] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:01:31,807] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.492104990214962
[2022-12-07 09:01:31,807] [INFO] [runner_train_mujoco] Average state value: 0.49052229732275004
[2022-12-07 09:01:31,807] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 09:01:31,863] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.03061
[2022-12-07 09:01:31,930] [INFO] [controller] EPOCH 2 loss ppo:  -0.01654, loss val: 0.03097
[2022-12-07 09:01:31,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.02282, loss val: 0.03141
[2022-12-07 09:01:32,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.03037, loss val: 0.03083
[2022-12-07 09:01:32,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:01:32,212] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:01:32,212] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:01:38,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:01:44,850] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:01:50,577] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:01:56,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:02:02,522] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:02:08,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:02:15,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:02:21,866] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:02:28,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:02:34,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.811430226655168
[2022-12-07 09:02:34,341] [INFO] [runner_train_mujoco] Average state value: 0.49002256391445786
[2022-12-07 09:02:34,341] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 09:02:34,399] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.03820
[2022-12-07 09:02:34,444] [INFO] [controller] EPOCH 2 loss ppo:  -0.01640, loss val: 0.03827
[2022-12-07 09:02:34,488] [INFO] [controller] EPOCH 3 loss ppo:  -0.02197, loss val: 0.03870
[2022-12-07 09:02:34,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.02893, loss val: 0.03872
[2022-12-07 09:02:34,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:02:34,748] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:02:34,748] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:40,735] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:02:46,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:02:52,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:02:58,722] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:03:04,651] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:03:10,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:03:17,060] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:03:23,553] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:03:29,726] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:35,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7207046596861915
[2022-12-07 09:03:35,676] [INFO] [runner_train_mujoco] Average state value: 0.48934133525689444
[2022-12-07 09:03:35,676] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 09:03:35,737] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.03892
[2022-12-07 09:03:35,780] [INFO] [controller] EPOCH 2 loss ppo:  -0.01415, loss val: 0.03880
[2022-12-07 09:03:35,825] [INFO] [controller] EPOCH 3 loss ppo:  -0.01696, loss val: 0.03878
[2022-12-07 09:03:35,867] [INFO] [controller] EPOCH 4 loss ppo:  -0.02112, loss val: 0.04093
[2022-12-07 09:03:35,877] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:03:36,065] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:03:36,066] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:03:42,262] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:03:48,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:03:54,687] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:04:00,941] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:04:07,355] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:04:13,268] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:04:19,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:04:25,190] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:04:31,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:04:36,993] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4125120942989695
[2022-12-07 09:04:36,993] [INFO] [runner_train_mujoco] Average state value: 0.4579395075092713
[2022-12-07 09:04:36,993] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 09:04:37,051] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04040
[2022-12-07 09:04:37,102] [INFO] [controller] EPOCH 2 loss ppo:  -0.01384, loss val: 0.04102
[2022-12-07 09:04:37,154] [INFO] [controller] EPOCH 3 loss ppo:  -0.01579, loss val: 0.04087
[2022-12-07 09:04:37,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.01850, loss val: 0.04052
[2022-12-07 09:04:37,245] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:04:37,390] [INFO] [optimize] Finished learning.
