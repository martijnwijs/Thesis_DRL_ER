[2022-12-06 20:44:15,789] [INFO] [optimize] Starting learning
[2022-12-06 20:44:15,799] [INFO] [optimize] Starting learning process..
[2022-12-06 20:44:15,884] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:44:15,885] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:44:21,480] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:44:27,118] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:44:33,397] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:44:38,919] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:44:44,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:44:49,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:44:55,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:45:01,405] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:45:07,344] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:45:14,419] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9656599274212937
[2022-12-06 20:45:14,419] [INFO] [runner_train_mujoco] Average state value: 0.08097888879229624
[2022-12-06 20:45:14,419] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 20:45:14,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01140, loss val: 0.32206
[2022-12-06 20:45:14,521] [INFO] [controller] EPOCH 2 loss ppo:  -0.03915, loss val: 0.29012
[2022-12-06 20:45:14,573] [INFO] [controller] EPOCH 3 loss ppo:  -0.05287, loss val: 0.24154
[2022-12-06 20:45:14,621] [INFO] [controller] EPOCH 4 loss ppo:  -0.05829, loss val: 0.20219
[2022-12-06 20:45:14,632] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:45:14,808] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:45:14,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:45:20,508] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:45:26,799] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:45:33,870] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:45:39,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:45:45,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:45:51,784] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:45:57,657] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:46:03,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:46:09,785] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:46:16,135] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9039520472272156
[2022-12-06 20:46:16,136] [INFO] [runner_train_mujoco] Average state value: 0.25234147847940525
[2022-12-06 20:46:16,136] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 20:46:16,187] [INFO] [controller] EPOCH 1 loss ppo:  -0.01504, loss val: 0.18227
[2022-12-06 20:46:16,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.03982, loss val: 0.16350
[2022-12-06 20:46:16,285] [INFO] [controller] EPOCH 3 loss ppo:  -0.04852, loss val: 0.13699
[2022-12-06 20:46:16,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.05944, loss val: 0.11574
[2022-12-06 20:46:16,350] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:46:16,560] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:46:16,560] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:46:23,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:46:29,744] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:46:35,779] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:46:41,408] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:46:46,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:46:52,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:46:57,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:47:02,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:47:07,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:47:13,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9633321327093671
[2022-12-06 20:47:13,014] [INFO] [runner_train_mujoco] Average state value: 0.4104250519859294
[2022-12-06 20:47:13,014] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 20:47:13,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.08176
[2022-12-06 20:47:13,123] [INFO] [controller] EPOCH 2 loss ppo:  -0.03942, loss val: 0.07303
[2022-12-06 20:47:13,170] [INFO] [controller] EPOCH 3 loss ppo:  -0.05396, loss val: 0.06763
[2022-12-06 20:47:13,221] [INFO] [controller] EPOCH 4 loss ppo:  -0.06315, loss val: 0.06278
[2022-12-06 20:47:13,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:47:13,424] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:47:13,424] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:47:18,923] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:47:24,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:47:29,168] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:47:34,859] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:47:40,149] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:47:45,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:47:51,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:47:56,666] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:48:01,937] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:48:07,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.992977686792727
[2022-12-06 20:48:07,389] [INFO] [runner_train_mujoco] Average state value: 0.5274995761550964
[2022-12-06 20:48:07,390] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 20:48:07,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01068, loss val: 0.05982
[2022-12-06 20:48:07,483] [INFO] [controller] EPOCH 2 loss ppo:  -0.03606, loss val: 0.05619
[2022-12-06 20:48:07,535] [INFO] [controller] EPOCH 3 loss ppo:  -0.04834, loss val: 0.05300
[2022-12-06 20:48:07,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.05425, loss val: 0.05035
[2022-12-06 20:48:07,594] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:48:07,786] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:48:07,786] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:48:13,258] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:48:18,989] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:48:24,440] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:48:29,978] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:48:35,362] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:48:40,817] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:48:46,422] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:48:51,861] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:48:57,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:49:03,282] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8772716057589305
[2022-12-06 20:49:03,282] [INFO] [runner_train_mujoco] Average state value: 0.5494040155876427
[2022-12-06 20:49:03,283] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 20:49:03,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.01157, loss val: 0.05608
[2022-12-06 20:49:03,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.03339, loss val: 0.05411
[2022-12-06 20:49:03,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.04495, loss val: 0.04960
[2022-12-06 20:49:03,479] [INFO] [controller] EPOCH 4 loss ppo:  -0.05692, loss val: 0.04799
[2022-12-06 20:49:03,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:49:03,691] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:49:03,692] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:49:09,564] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:49:15,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:49:21,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:49:26,520] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:49:31,907] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:49:37,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:49:42,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:49:47,936] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:49:53,240] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:49:58,759] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0493767698963716
[2022-12-06 20:49:58,759] [INFO] [runner_train_mujoco] Average state value: 0.5222850441038609
[2022-12-06 20:49:58,759] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 20:49:58,828] [INFO] [controller] EPOCH 1 loss ppo:  -0.01211, loss val: 0.04784
[2022-12-06 20:49:58,876] [INFO] [controller] EPOCH 2 loss ppo:  -0.03820, loss val: 0.04430
[2022-12-06 20:49:58,925] [INFO] [controller] EPOCH 3 loss ppo:  -0.05297, loss val: 0.04328
[2022-12-06 20:49:58,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.05885, loss val: 0.04082
[2022-12-06 20:49:58,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:49:59,180] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:49:59,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:50:05,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:50:10,753] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:50:16,393] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:50:22,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:50:27,444] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:50:33,243] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:50:38,526] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:50:43,809] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:50:49,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:50:54,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2162022004298758
[2022-12-06 20:50:54,192] [INFO] [runner_train_mujoco] Average state value: 0.5350102622459332
[2022-12-06 20:50:54,192] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 20:50:54,242] [INFO] [controller] EPOCH 1 loss ppo:  -0.01281, loss val: 0.05315
[2022-12-06 20:50:54,285] [INFO] [controller] EPOCH 2 loss ppo:  -0.03687, loss val: 0.05109
[2022-12-06 20:50:54,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.05016, loss val: 0.05156
[2022-12-06 20:50:54,365] [INFO] [controller] EPOCH 4 loss ppo:  -0.05571, loss val: 0.04960
[2022-12-06 20:50:54,375] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:50:54,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:50:54,562] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:51:00,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:51:05,295] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:51:10,704] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:51:16,041] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:51:21,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:51:26,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:51:31,937] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:51:37,550] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:51:43,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:51:48,604] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.106555966165703
[2022-12-06 20:51:48,604] [INFO] [runner_train_mujoco] Average state value: 0.5519947718580565
[2022-12-06 20:51:48,605] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 20:51:48,655] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.03833
[2022-12-06 20:51:48,698] [INFO] [controller] EPOCH 2 loss ppo:  -0.03589, loss val: 0.03791
[2022-12-06 20:51:48,744] [INFO] [controller] EPOCH 3 loss ppo:  -0.04828, loss val: 0.03741
[2022-12-06 20:51:48,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.05317, loss val: 0.04012
[2022-12-06 20:51:48,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:51:48,983] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:51:48,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:51:54,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:51:59,507] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:52:04,741] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:52:09,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:52:15,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:52:20,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:52:25,410] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:52:30,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:52:35,546] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:52:40,740] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0817355209658457
[2022-12-06 20:52:40,740] [INFO] [runner_train_mujoco] Average state value: 0.5368803221583367
[2022-12-06 20:52:40,740] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 20:52:40,813] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04519
[2022-12-06 20:52:40,869] [INFO] [controller] EPOCH 2 loss ppo:  -0.03977, loss val: 0.04127
[2022-12-06 20:52:40,919] [INFO] [controller] EPOCH 3 loss ppo:  -0.05099, loss val: 0.03954
[2022-12-06 20:52:40,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.05929, loss val: 0.03816
[2022-12-06 20:52:40,980] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:52:41,180] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:52:41,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:52:46,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:52:51,674] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:52:57,424] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:53:02,633] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:53:07,922] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:53:13,035] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:53:18,236] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:53:23,745] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:53:28,783] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:53:34,059] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0921513890605323
[2022-12-06 20:53:34,059] [INFO] [runner_train_mujoco] Average state value: 0.47588944547375034
[2022-12-06 20:53:34,059] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 20:53:34,127] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.05495
[2022-12-06 20:53:34,177] [INFO] [controller] EPOCH 2 loss ppo:  -0.02933, loss val: 0.05301
[2022-12-06 20:53:34,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.04121, loss val: 0.05064
[2022-12-06 20:53:34,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.05088, loss val: 0.04596
[2022-12-06 20:53:34,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:53:34,481] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:53:34,482] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:53:39,977] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:53:45,022] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:53:50,277] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:53:55,603] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:54:00,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:54:06,302] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:54:11,701] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:54:16,984] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:54:22,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:54:27,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2543057811126812
[2022-12-06 20:54:27,659] [INFO] [runner_train_mujoco] Average state value: 0.5175782473683357
[2022-12-06 20:54:27,660] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 20:54:27,732] [INFO] [controller] EPOCH 1 loss ppo:  -0.01500, loss val: 0.03876
[2022-12-06 20:54:27,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.03753, loss val: 0.04018
[2022-12-06 20:54:27,819] [INFO] [controller] EPOCH 3 loss ppo:  -0.04623, loss val: 0.04134
[2022-12-06 20:54:27,865] [INFO] [controller] EPOCH 4 loss ppo:  -0.05451, loss val: 0.04094
[2022-12-06 20:54:27,875] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:54:28,059] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:54:28,060] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:54:33,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:54:38,949] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:54:44,600] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:54:50,046] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:54:55,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:55:00,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:55:06,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:55:11,712] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:55:17,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:55:23,249] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2432463857955143
[2022-12-06 20:55:23,249] [INFO] [runner_train_mujoco] Average state value: 0.48855369058127207
[2022-12-06 20:55:23,249] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 20:55:23,306] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.09211
[2022-12-06 20:55:23,352] [INFO] [controller] EPOCH 2 loss ppo:  -0.03575, loss val: 0.09123
[2022-12-06 20:55:23,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.04879, loss val: 0.08996
[2022-12-06 20:55:23,516] [INFO] [controller] EPOCH 4 loss ppo:  -0.05784, loss val: 0.08874
[2022-12-06 20:55:23,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:55:23,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:55:23,711] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:55:29,571] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:55:35,008] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:55:40,644] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:55:45,947] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:55:51,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:55:57,174] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:56:02,720] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:56:08,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:56:14,822] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:56:21,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3289114066497405
[2022-12-06 20:56:21,013] [INFO] [runner_train_mujoco] Average state value: 0.5285675959189733
[2022-12-06 20:56:21,013] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 20:56:21,099] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.03608
[2022-12-06 20:56:21,149] [INFO] [controller] EPOCH 2 loss ppo:  -0.03256, loss val: 0.03485
[2022-12-06 20:56:21,203] [INFO] [controller] EPOCH 3 loss ppo:  -0.04364, loss val: 0.03427
[2022-12-06 20:56:21,254] [INFO] [controller] EPOCH 4 loss ppo:  -0.05389, loss val: 0.03486
[2022-12-06 20:56:21,264] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:56:21,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:56:21,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:56:27,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:56:34,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:56:40,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:56:47,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:56:53,215] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:56:59,415] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:57:06,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:57:13,777] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:57:21,249] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:57:27,820] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3987332253779647
[2022-12-06 20:57:27,821] [INFO] [runner_train_mujoco] Average state value: 0.5572468358973663
[2022-12-06 20:57:27,821] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 20:57:27,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.04232
[2022-12-06 20:57:27,928] [INFO] [controller] EPOCH 2 loss ppo:  -0.03469, loss val: 0.04299
[2022-12-06 20:57:27,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.04755, loss val: 0.04241
[2022-12-06 20:57:28,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.05531, loss val: 0.04245
[2022-12-06 20:57:28,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:57:28,237] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:57:28,237] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:57:34,350] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:57:40,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:57:46,519] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:57:53,491] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:58:00,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:58:07,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:58:15,368] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:58:21,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:58:28,407] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:58:35,277] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.374866861259262
[2022-12-06 20:58:35,277] [INFO] [runner_train_mujoco] Average state value: 0.5502156494259836
[2022-12-06 20:58:35,277] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 20:58:35,348] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.03765
[2022-12-06 20:58:35,402] [INFO] [controller] EPOCH 2 loss ppo:  -0.03447, loss val: 0.03562
[2022-12-06 20:58:35,454] [INFO] [controller] EPOCH 3 loss ppo:  -0.04597, loss val: 0.03570
[2022-12-06 20:58:35,507] [INFO] [controller] EPOCH 4 loss ppo:  -0.05574, loss val: 0.03716
[2022-12-06 20:58:35,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:58:35,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:58:35,720] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:58:42,591] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:58:49,233] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:58:56,432] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:59:03,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:59:10,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:59:17,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:59:24,118] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:59:30,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:59:37,400] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:59:44,520] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4357829694500757
[2022-12-06 20:59:44,521] [INFO] [runner_train_mujoco] Average state value: 0.5163264239132405
[2022-12-06 20:59:44,521] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 20:59:44,587] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.04049
[2022-12-06 20:59:44,662] [INFO] [controller] EPOCH 2 loss ppo:  -0.03812, loss val: 0.03844
[2022-12-06 20:59:44,714] [INFO] [controller] EPOCH 3 loss ppo:  -0.05144, loss val: 0.03877
[2022-12-06 20:59:44,764] [INFO] [controller] EPOCH 4 loss ppo:  -0.05639, loss val: 0.03766
[2022-12-06 20:59:44,774] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:59:44,973] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:59:44,974] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:59:52,221] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:59:59,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:00:06,522] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:00:13,412] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:00:20,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:00:27,702] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:00:34,637] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:00:41,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:00:48,997] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:00:56,078] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4850605799682026
[2022-12-06 21:00:56,078] [INFO] [runner_train_mujoco] Average state value: 0.5450136503775914
[2022-12-06 21:00:56,078] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 21:00:56,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.03912
[2022-12-06 21:00:56,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.03753, loss val: 0.03941
[2022-12-06 21:00:56,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.04722, loss val: 0.04031
[2022-12-06 21:00:56,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.05781, loss val: 0.03912
[2022-12-06 21:00:56,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:00:56,544] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:00:56,545] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:01:04,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:01:11,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:01:19,064] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:01:25,986] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:01:33,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:01:40,630] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:01:48,074] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:01:55,393] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:02:02,589] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:02:09,613] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.380235358837171
[2022-12-06 21:02:09,613] [INFO] [runner_train_mujoco] Average state value: 0.5617199142078559
[2022-12-06 21:02:09,613] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 21:02:09,669] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04218
[2022-12-06 21:02:09,717] [INFO] [controller] EPOCH 2 loss ppo:  -0.03636, loss val: 0.04306
[2022-12-06 21:02:09,770] [INFO] [controller] EPOCH 3 loss ppo:  -0.05036, loss val: 0.04143
[2022-12-06 21:02:09,818] [INFO] [controller] EPOCH 4 loss ppo:  -0.05734, loss val: 0.04232
[2022-12-06 21:02:09,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:02:10,030] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:02:10,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:02:17,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:02:23,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:02:30,820] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:02:37,472] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:02:44,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:02:51,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:02:58,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:03:05,203] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:03:12,087] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:03:19,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6274759076763103
[2022-12-06 21:03:19,077] [INFO] [runner_train_mujoco] Average state value: 0.532788231352965
[2022-12-06 21:03:19,077] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 21:03:19,136] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03881
[2022-12-06 21:03:19,188] [INFO] [controller] EPOCH 2 loss ppo:  -0.03091, loss val: 0.03759
[2022-12-06 21:03:19,238] [INFO] [controller] EPOCH 3 loss ppo:  -0.04367, loss val: 0.03647
[2022-12-06 21:03:19,288] [INFO] [controller] EPOCH 4 loss ppo:  -0.05756, loss val: 0.03612
[2022-12-06 21:03:19,298] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:03:19,510] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:03:19,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:03:26,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:03:33,677] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:03:40,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:03:47,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:03:53,717] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:04:00,299] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:04:07,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:04:13,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:04:20,442] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:04:26,863] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7433574282342037
[2022-12-06 21:04:26,863] [INFO] [runner_train_mujoco] Average state value: 0.4808781004150708
[2022-12-06 21:04:26,863] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 21:04:26,926] [INFO] [controller] EPOCH 1 loss ppo:  -0.01497, loss val: 0.04254
[2022-12-06 21:04:26,992] [INFO] [controller] EPOCH 2 loss ppo:  -0.03806, loss val: 0.04306
[2022-12-06 21:04:27,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.04925, loss val: 0.04312
[2022-12-06 21:04:27,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.05886, loss val: 0.04259
[2022-12-06 21:04:27,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:04:27,301] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:04:27,302] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:04:34,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:04:40,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:04:47,612] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:04:54,204] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:05:01,115] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:05:07,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:05:14,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:05:21,528] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:05:28,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:05:35,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7409218675649254
[2022-12-06 21:05:35,284] [INFO] [runner_train_mujoco] Average state value: 0.4799606893161933
[2022-12-06 21:05:35,284] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 21:05:35,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04040
[2022-12-06 21:05:35,406] [INFO] [controller] EPOCH 2 loss ppo:  -0.03515, loss val: 0.03999
[2022-12-06 21:05:35,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.04714, loss val: 0.04220
[2022-12-06 21:05:35,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.05899, loss val: 0.04010
[2022-12-06 21:05:35,528] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:05:35,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:05:35,731] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:05:42,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:05:49,503] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:05:56,330] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:06:02,855] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:06:09,982] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:06:16,939] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:06:23,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:06:31,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:06:38,436] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:06:45,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.732566736630093
[2022-12-06 21:06:45,291] [INFO] [runner_train_mujoco] Average state value: 0.5129085467060407
[2022-12-06 21:06:45,291] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 21:06:45,361] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.03323
[2022-12-06 21:06:45,412] [INFO] [controller] EPOCH 2 loss ppo:  -0.03447, loss val: 0.03608
[2022-12-06 21:06:45,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.04635, loss val: 0.03320
[2022-12-06 21:06:45,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.05737, loss val: 0.03314
[2022-12-06 21:06:45,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:06:45,730] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:06:45,731] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:06:52,726] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:06:59,689] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:07:08,371] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:07:16,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:07:24,254] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:07:31,068] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:07:38,439] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:07:45,611] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:07:52,696] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:08:00,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0019807127853175
[2022-12-06 21:08:00,056] [INFO] [runner_train_mujoco] Average state value: 0.5294021044969559
[2022-12-06 21:08:00,056] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 21:08:00,122] [INFO] [controller] EPOCH 1 loss ppo:  -0.01558, loss val: 0.03919
[2022-12-06 21:08:00,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.03801, loss val: 0.03945
[2022-12-06 21:08:00,245] [INFO] [controller] EPOCH 3 loss ppo:  -0.05071, loss val: 0.03841
[2022-12-06 21:08:00,305] [INFO] [controller] EPOCH 4 loss ppo:  -0.06175, loss val: 0.03760
[2022-12-06 21:08:00,317] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:08:00,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:08:00,532] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:08:07,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:08:15,256] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:08:22,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:08:29,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:08:37,259] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:08:44,655] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:08:51,478] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:08:58,094] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:09:05,196] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:09:12,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1701952225190433
[2022-12-06 21:09:12,146] [INFO] [runner_train_mujoco] Average state value: 0.5023888118366402
[2022-12-06 21:09:12,146] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 21:09:12,216] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.03410
[2022-12-06 21:09:12,269] [INFO] [controller] EPOCH 2 loss ppo:  -0.03432, loss val: 0.03501
[2022-12-06 21:09:12,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.04927, loss val: 0.03434
[2022-12-06 21:09:12,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.05925, loss val: 0.03420
[2022-12-06 21:09:12,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:09:12,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:09:12,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:09:19,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:09:27,151] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:09:34,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:09:41,943] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:09:48,536] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:09:55,586] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:10:02,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:10:09,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:10:16,078] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:10:22,807] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.203956280231678
[2022-12-06 21:10:22,808] [INFO] [runner_train_mujoco] Average state value: 0.4717999180356662
[2022-12-06 21:10:22,808] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 21:10:22,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.03695
[2022-12-06 21:10:22,929] [INFO] [controller] EPOCH 2 loss ppo:  -0.03212, loss val: 0.03711
[2022-12-06 21:10:22,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.04549, loss val: 0.03659
[2022-12-06 21:10:23,107] [INFO] [controller] EPOCH 4 loss ppo:  -0.05688, loss val: 0.03666
[2022-12-06 21:10:23,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:10:23,320] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:10:23,321] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:10:30,029] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:10:36,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:10:43,527] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:10:50,300] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:10:57,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:11:04,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:11:10,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:11:17,072] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:11:23,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:11:30,260] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0515019813566915
[2022-12-06 21:11:30,260] [INFO] [runner_train_mujoco] Average state value: 0.44370085701346396
[2022-12-06 21:11:30,261] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 21:11:30,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04322
[2022-12-06 21:11:30,366] [INFO] [controller] EPOCH 2 loss ppo:  -0.02976, loss val: 0.04242
[2022-12-06 21:11:30,425] [INFO] [controller] EPOCH 3 loss ppo:  -0.04094, loss val: 0.04319
[2022-12-06 21:11:30,477] [INFO] [controller] EPOCH 4 loss ppo:  -0.05380, loss val: 0.04065
[2022-12-06 21:11:30,488] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:11:30,690] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:11:30,692] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:11:37,579] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:11:44,667] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:11:51,219] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:11:57,384] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:12:04,016] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:12:10,357] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:12:17,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:12:23,790] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:12:30,684] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:12:37,192] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.309268688624043
[2022-12-06 21:12:37,192] [INFO] [runner_train_mujoco] Average state value: 0.4761054539779822
[2022-12-06 21:12:37,192] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 21:12:37,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.04555
[2022-12-06 21:12:37,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.03022, loss val: 0.04471
[2022-12-06 21:12:37,371] [INFO] [controller] EPOCH 3 loss ppo:  -0.04458, loss val: 0.04593
[2022-12-06 21:12:37,418] [INFO] [controller] EPOCH 4 loss ppo:  -0.05636, loss val: 0.04458
[2022-12-06 21:12:37,429] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:12:37,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:12:37,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:12:44,394] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:12:51,028] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:12:57,302] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:13:04,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:13:10,687] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:13:17,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:13:24,692] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:13:31,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:13:37,700] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:13:44,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.410911458122393
[2022-12-06 21:13:44,468] [INFO] [runner_train_mujoco] Average state value: 0.5277881976564724
[2022-12-06 21:13:44,468] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 21:13:44,550] [INFO] [controller] EPOCH 1 loss ppo:  -0.01494, loss val: 0.03326
[2022-12-06 21:13:44,605] [INFO] [controller] EPOCH 2 loss ppo:  -0.03249, loss val: 0.03325
[2022-12-06 21:13:44,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.04557, loss val: 0.03253
[2022-12-06 21:13:44,718] [INFO] [controller] EPOCH 4 loss ppo:  -0.05597, loss val: 0.03250
[2022-12-06 21:13:44,729] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:13:44,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:13:44,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:13:52,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:13:59,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:14:06,500] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:14:13,291] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:14:19,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:14:27,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:14:33,970] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:14:41,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:14:47,825] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:14:54,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4472097167481612
[2022-12-06 21:14:54,696] [INFO] [runner_train_mujoco] Average state value: 0.5558209849695365
[2022-12-06 21:14:54,696] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 21:14:54,761] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.03744
[2022-12-06 21:14:54,814] [INFO] [controller] EPOCH 2 loss ppo:  -0.02906, loss val: 0.03807
[2022-12-06 21:14:54,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.04109, loss val: 0.03807
[2022-12-06 21:14:54,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.04932, loss val: 0.03713
[2022-12-06 21:14:54,937] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:14:55,145] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:14:55,145] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:15:02,548] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:15:09,769] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:15:16,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:15:24,062] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:15:32,046] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:15:38,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:15:45,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:15:52,937] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:15:59,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:16:07,097] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.799495199378127
[2022-12-06 21:16:07,098] [INFO] [runner_train_mujoco] Average state value: 0.5449912227193514
[2022-12-06 21:16:07,098] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 21:16:07,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04394
[2022-12-06 21:16:07,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.02983, loss val: 0.04110
[2022-12-06 21:16:07,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.04305, loss val: 0.03959
[2022-12-06 21:16:07,333] [INFO] [controller] EPOCH 4 loss ppo:  -0.05449, loss val: 0.03633
[2022-12-06 21:16:07,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:16:07,553] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:16:07,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:16:14,626] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:16:21,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:16:29,099] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:16:36,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:16:43,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:16:50,072] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:16:57,260] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:17:04,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:17:11,005] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:17:17,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.381253443176047
[2022-12-06 21:17:17,640] [INFO] [runner_train_mujoco] Average state value: 0.4838031050066153
[2022-12-06 21:17:17,640] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 21:17:17,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.04014
[2022-12-06 21:17:17,744] [INFO] [controller] EPOCH 2 loss ppo:  -0.03612, loss val: 0.04042
[2022-12-06 21:17:17,791] [INFO] [controller] EPOCH 3 loss ppo:  -0.04498, loss val: 0.04151
[2022-12-06 21:17:17,840] [INFO] [controller] EPOCH 4 loss ppo:  -0.05009, loss val: 0.04124
[2022-12-06 21:17:17,851] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:17:18,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:17:18,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:17:24,744] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:17:31,453] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:17:38,021] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:17:44,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:17:51,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:17:57,712] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:18:04,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:18:10,812] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:18:17,632] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:18:23,776] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7801413564722823
[2022-12-06 21:18:23,776] [INFO] [runner_train_mujoco] Average state value: 0.4604389983912309
[2022-12-06 21:18:23,776] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 21:18:23,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04129
[2022-12-06 21:18:23,889] [INFO] [controller] EPOCH 2 loss ppo:  -0.02361, loss val: 0.03962
[2022-12-06 21:18:23,938] [INFO] [controller] EPOCH 3 loss ppo:  -0.03858, loss val: 0.03899
[2022-12-06 21:18:23,989] [INFO] [controller] EPOCH 4 loss ppo:  -0.05027, loss val: 0.03713
[2022-12-06 21:18:23,999] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:18:24,201] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:18:24,201] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:18:30,885] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:18:37,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:18:44,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:18:51,032] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:18:57,428] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:19:04,140] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:19:10,276] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:19:16,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:19:23,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:19:30,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6576636328132026
[2022-12-06 21:19:30,427] [INFO] [runner_train_mujoco] Average state value: 0.5093707856337228
[2022-12-06 21:19:30,427] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 21:19:30,546] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.03798
[2022-12-06 21:19:30,598] [INFO] [controller] EPOCH 2 loss ppo:  -0.02815, loss val: 0.03754
[2022-12-06 21:19:30,656] [INFO] [controller] EPOCH 3 loss ppo:  -0.03981, loss val: 0.03539
[2022-12-06 21:19:30,703] [INFO] [controller] EPOCH 4 loss ppo:  -0.05274, loss val: 0.03486
[2022-12-06 21:19:30,713] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:19:30,915] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:19:30,916] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:19:37,694] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:19:44,707] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:19:51,827] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:19:58,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:20:05,255] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:20:12,285] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:20:19,384] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:20:26,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:20:33,547] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:20:40,675] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7869289421823256
[2022-12-06 21:20:40,676] [INFO] [runner_train_mujoco] Average state value: 0.5563527134234707
[2022-12-06 21:20:40,676] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 21:20:40,738] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.05202
[2022-12-06 21:20:40,793] [INFO] [controller] EPOCH 2 loss ppo:  -0.02764, loss val: 0.05305
[2022-12-06 21:20:40,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.03884, loss val: 0.05563
[2022-12-06 21:20:40,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.04811, loss val: 0.05145
[2022-12-06 21:20:40,914] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:20:41,115] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:20:41,115] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:20:48,201] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:20:55,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:21:02,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:21:09,046] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:21:16,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:21:23,498] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:21:31,035] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:21:38,200] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:21:45,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:21:52,326] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6287520117782326
[2022-12-06 21:21:52,326] [INFO] [runner_train_mujoco] Average state value: 0.5138287277892232
[2022-12-06 21:21:52,326] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 21:21:52,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.07175
[2022-12-06 21:21:52,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.02867, loss val: 0.06967
[2022-12-06 21:21:52,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.03978, loss val: 0.06675
[2022-12-06 21:21:52,561] [INFO] [controller] EPOCH 4 loss ppo:  -0.05134, loss val: 0.06512
[2022-12-06 21:21:52,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:21:52,784] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:21:52,784] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:21:59,937] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:22:07,240] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:22:14,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:22:21,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:22:29,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:22:36,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:22:43,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:22:50,337] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:22:57,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:23:04,700] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4170408155260397
[2022-12-06 21:23:04,700] [INFO] [runner_train_mujoco] Average state value: 0.5121208694875241
[2022-12-06 21:23:04,700] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 21:23:04,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01267, loss val: 0.04092
[2022-12-06 21:23:04,840] [INFO] [controller] EPOCH 2 loss ppo:  -0.02487, loss val: 0.04100
[2022-12-06 21:23:04,896] [INFO] [controller] EPOCH 3 loss ppo:  -0.03729, loss val: 0.04087
[2022-12-06 21:23:04,950] [INFO] [controller] EPOCH 4 loss ppo:  -0.04858, loss val: 0.04094
[2022-12-06 21:23:04,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:23:05,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:23:05,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:23:12,538] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:23:19,700] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:23:26,890] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:23:33,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:23:40,478] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:23:47,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:23:53,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:24:00,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:24:06,792] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:24:14,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.259981573872566
[2022-12-06 21:24:14,110] [INFO] [runner_train_mujoco] Average state value: 0.48479052817821505
[2022-12-06 21:24:14,110] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 21:24:14,168] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.03714
[2022-12-06 21:24:14,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.02876, loss val: 0.03780
[2022-12-06 21:24:14,274] [INFO] [controller] EPOCH 3 loss ppo:  -0.03724, loss val: 0.03705
[2022-12-06 21:24:14,332] [INFO] [controller] EPOCH 4 loss ppo:  -0.05063, loss val: 0.03751
[2022-12-06 21:24:14,345] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:24:14,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:24:14,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:24:21,339] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:24:28,253] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:24:35,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:24:41,586] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:24:48,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:24:54,889] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:25:01,601] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:25:08,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:25:15,086] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:25:21,717] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4665423472022754
[2022-12-06 21:25:21,717] [INFO] [runner_train_mujoco] Average state value: 0.4807609508434932
[2022-12-06 21:25:21,717] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 21:25:21,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.03830
[2022-12-06 21:25:21,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.02780, loss val: 0.03842
[2022-12-06 21:25:21,879] [INFO] [controller] EPOCH 3 loss ppo:  -0.04388, loss val: 0.04145
[2022-12-06 21:25:21,939] [INFO] [controller] EPOCH 4 loss ppo:  -0.05357, loss val: 0.03959
[2022-12-06 21:25:21,949] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:25:22,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:25:22,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:25:29,028] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:25:35,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:25:42,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:25:48,762] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:25:55,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:26:01,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:26:09,824] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:26:16,742] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:26:23,249] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:26:29,568] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0687567869329255
[2022-12-06 21:26:29,568] [INFO] [runner_train_mujoco] Average state value: 0.48017304082711537
[2022-12-06 21:26:29,568] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 21:26:29,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01176, loss val: 0.03935
[2022-12-06 21:26:29,684] [INFO] [controller] EPOCH 2 loss ppo:  -0.02471, loss val: 0.04052
[2022-12-06 21:26:29,736] [INFO] [controller] EPOCH 3 loss ppo:  -0.03433, loss val: 0.04048
[2022-12-06 21:26:29,797] [INFO] [controller] EPOCH 4 loss ppo:  -0.04408, loss val: 0.03804
[2022-12-06 21:26:29,808] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:26:30,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:26:30,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:26:36,361] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:26:42,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:26:49,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:26:55,842] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:27:02,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:27:09,500] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:27:16,230] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:27:23,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:27:29,966] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:27:36,301] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3216247604283864
[2022-12-06 21:27:36,301] [INFO] [runner_train_mujoco] Average state value: 0.4655253911415736
[2022-12-06 21:27:36,301] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 21:27:36,358] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04137
[2022-12-06 21:27:36,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.02779, loss val: 0.03959
[2022-12-06 21:27:36,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.03904, loss val: 0.03770
[2022-12-06 21:27:36,518] [INFO] [controller] EPOCH 4 loss ppo:  -0.04947, loss val: 0.03766
[2022-12-06 21:27:36,529] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:27:36,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:27:36,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:27:43,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:27:49,910] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:27:57,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:28:04,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:28:11,021] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:28:17,780] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:28:24,286] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:28:30,915] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:28:37,759] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:28:44,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1918168638657756
[2022-12-06 21:28:44,702] [INFO] [runner_train_mujoco] Average state value: 0.46071655362844466
[2022-12-06 21:28:44,702] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 21:28:44,769] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.02989
[2022-12-06 21:28:44,824] [INFO] [controller] EPOCH 2 loss ppo:  -0.02572, loss val: 0.02991
[2022-12-06 21:28:44,876] [INFO] [controller] EPOCH 3 loss ppo:  -0.03667, loss val: 0.03137
[2022-12-06 21:28:44,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.04764, loss val: 0.03143
[2022-12-06 21:28:44,941] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:28:45,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:28:45,160] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:28:52,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:28:59,938] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:29:07,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:29:13,991] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:29:20,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:29:27,830] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:29:34,424] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:29:41,597] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:29:48,443] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:29:55,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.106614951274235
[2022-12-06 21:29:55,329] [INFO] [runner_train_mujoco] Average state value: 0.46350224674741425
[2022-12-06 21:29:55,329] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 21:29:55,387] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.04228
[2022-12-06 21:29:55,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.02683, loss val: 0.04166
[2022-12-06 21:29:55,501] [INFO] [controller] EPOCH 3 loss ppo:  -0.03932, loss val: 0.04349
[2022-12-06 21:29:55,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.04922, loss val: 0.04187
[2022-12-06 21:29:55,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:29:55,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:29:55,773] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:30:03,075] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:30:10,195] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:30:17,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:30:24,402] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:30:31,768] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:30:39,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:30:46,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:30:53,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:31:00,285] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:31:07,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3621698905623303
[2022-12-06 21:31:07,604] [INFO] [runner_train_mujoco] Average state value: 0.46773343033591913
[2022-12-06 21:31:07,604] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 21:31:07,684] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.04183
[2022-12-06 21:31:07,745] [INFO] [controller] EPOCH 2 loss ppo:  -0.02567, loss val: 0.03918
[2022-12-06 21:31:07,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.03393, loss val: 0.03953
[2022-12-06 21:31:07,863] [INFO] [controller] EPOCH 4 loss ppo:  -0.04159, loss val: 0.04102
[2022-12-06 21:31:07,874] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:31:08,081] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:31:08,082] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:31:15,134] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:31:21,793] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:31:28,450] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:31:35,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:31:42,822] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:31:49,860] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:31:57,054] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:32:03,948] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:32:10,741] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:32:17,390] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.183344188119154
[2022-12-06 21:32:17,390] [INFO] [runner_train_mujoco] Average state value: 0.46632996836304663
[2022-12-06 21:32:17,391] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 21:32:17,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04522
[2022-12-06 21:32:17,519] [INFO] [controller] EPOCH 2 loss ppo:  -0.02437, loss val: 0.04569
[2022-12-06 21:32:17,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.03678, loss val: 0.04858
[2022-12-06 21:32:17,621] [INFO] [controller] EPOCH 4 loss ppo:  -0.04840, loss val: 0.05138
[2022-12-06 21:32:17,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:32:17,831] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:32:17,832] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:32:24,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:32:31,044] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:32:37,795] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:32:44,404] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:32:52,015] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:32:59,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:33:07,028] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:33:15,636] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:33:22,430] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:33:30,100] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.452958951110155
[2022-12-06 21:33:30,100] [INFO] [runner_train_mujoco] Average state value: 0.46620806054274244
[2022-12-06 21:33:30,100] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 21:33:30,192] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.03824
[2022-12-06 21:33:30,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.02463, loss val: 0.04046
[2022-12-06 21:33:30,307] [INFO] [controller] EPOCH 3 loss ppo:  -0.03712, loss val: 0.03821
[2022-12-06 21:33:30,421] [INFO] [controller] EPOCH 4 loss ppo:  -0.04577, loss val: 0.03873
[2022-12-06 21:33:30,432] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:33:30,633] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:33:30,634] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:33:37,652] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:33:44,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:33:52,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:33:59,208] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:34:07,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:34:15,259] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:34:22,321] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:34:29,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:34:37,337] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:34:44,803] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.250325978403435
[2022-12-06 21:34:44,803] [INFO] [runner_train_mujoco] Average state value: 0.4617270481189092
[2022-12-06 21:34:44,803] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 21:34:44,873] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.03558
[2022-12-06 21:34:44,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.02379, loss val: 0.03266
[2022-12-06 21:34:45,065] [INFO] [controller] EPOCH 3 loss ppo:  -0.03544, loss val: 0.03392
[2022-12-06 21:34:45,126] [INFO] [controller] EPOCH 4 loss ppo:  -0.04198, loss val: 0.03404
[2022-12-06 21:34:45,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:34:45,337] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:34:45,337] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:34:52,823] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:35:00,378] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:35:07,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:35:15,243] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:35:22,987] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:35:30,352] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:35:37,944] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:35:45,526] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:35:53,469] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:36:01,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.338470157530625
[2022-12-06 21:36:01,285] [INFO] [runner_train_mujoco] Average state value: 0.4586029987931252
[2022-12-06 21:36:01,285] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 21:36:01,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.03777
[2022-12-06 21:36:01,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.02292, loss val: 0.03662
[2022-12-06 21:36:01,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.03624, loss val: 0.03654
[2022-12-06 21:36:01,628] [INFO] [controller] EPOCH 4 loss ppo:  -0.04548, loss val: 0.03757
[2022-12-06 21:36:01,640] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:36:01,845] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:36:01,846] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:36:09,256] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:36:16,771] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:36:24,178] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:36:32,033] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:36:40,073] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:36:47,905] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:36:55,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:37:03,223] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:37:11,525] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:37:19,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.260582157387449
[2022-12-06 21:37:19,341] [INFO] [runner_train_mujoco] Average state value: 0.45224607185522714
[2022-12-06 21:37:19,341] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 21:37:19,442] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.04843
[2022-12-06 21:37:19,662] [INFO] [controller] EPOCH 2 loss ppo:  -0.02203, loss val: 0.04562
[2022-12-06 21:37:19,727] [INFO] [controller] EPOCH 3 loss ppo:  -0.03173, loss val: 0.04615
[2022-12-06 21:37:19,801] [INFO] [controller] EPOCH 4 loss ppo:  -0.04047, loss val: 0.04652
[2022-12-06 21:37:19,825] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:37:20,044] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:37:20,045] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:37:28,222] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:37:36,251] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:37:44,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:37:52,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:38:00,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:38:08,954] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:38:16,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:38:24,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:38:31,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:38:40,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.489262199065672
[2022-12-06 21:38:40,172] [INFO] [runner_train_mujoco] Average state value: 0.43465110008915264
[2022-12-06 21:38:40,172] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 21:38:40,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04385
[2022-12-06 21:38:40,347] [INFO] [controller] EPOCH 2 loss ppo:  -0.02246, loss val: 0.04428
[2022-12-06 21:38:40,401] [INFO] [controller] EPOCH 3 loss ppo:  -0.03070, loss val: 0.04348
[2022-12-06 21:38:40,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.03724, loss val: 0.04303
[2022-12-06 21:38:40,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:38:40,683] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:38:40,684] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:38:48,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:38:56,363] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:39:03,956] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:39:11,642] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:39:19,273] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:39:26,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:39:34,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:39:42,363] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:39:49,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:39:57,188] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.448369474339004
[2022-12-06 21:39:57,189] [INFO] [runner_train_mujoco] Average state value: 0.4451341604789098
[2022-12-06 21:39:57,189] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 21:39:57,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.03954
[2022-12-06 21:39:57,331] [INFO] [controller] EPOCH 2 loss ppo:  -0.02133, loss val: 0.03039
[2022-12-06 21:39:57,392] [INFO] [controller] EPOCH 3 loss ppo:  -0.03057, loss val: 0.03224
[2022-12-06 21:39:57,464] [INFO] [controller] EPOCH 4 loss ppo:  -0.03874, loss val: 0.03492
[2022-12-06 21:39:57,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:39:57,686] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:39:57,687] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:40:05,070] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:40:12,845] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:40:20,141] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:40:27,323] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:40:34,773] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:40:50,483] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:42:45,379] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:42:59,213] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:43:13,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:43:24,908] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5420901401113047
[2022-12-06 21:43:24,908] [INFO] [runner_train_mujoco] Average state value: 0.4617824881275495
[2022-12-06 21:43:24,909] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 21:43:25,187] [INFO] [controller] EPOCH 1 loss ppo:  -0.01385, loss val: 0.04419
[2022-12-06 21:43:25,380] [INFO] [controller] EPOCH 2 loss ppo:  -0.02244, loss val: 0.04364
[2022-12-06 21:43:25,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.03283, loss val: 0.04427
[2022-12-06 21:43:26,102] [INFO] [controller] EPOCH 4 loss ppo:  -0.04008, loss val: 0.04370
[2022-12-06 21:43:26,134] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:43:26,458] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:43:26,459] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:43:40,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:43:51,711] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:44:01,246] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:44:10,348] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:44:19,471] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:44:28,550] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:44:37,568] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:44:46,765] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:44:57,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:45:06,775] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.618207324926103
[2022-12-06 21:45:06,776] [INFO] [runner_train_mujoco] Average state value: 0.47346591995159787
[2022-12-06 21:45:06,776] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 21:45:06,871] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.03394
[2022-12-06 21:45:06,939] [INFO] [controller] EPOCH 2 loss ppo:  -0.02048, loss val: 0.03410
[2022-12-06 21:45:07,031] [INFO] [controller] EPOCH 3 loss ppo:  -0.03104, loss val: 0.03398
[2022-12-06 21:45:07,120] [INFO] [controller] EPOCH 4 loss ppo:  -0.03911, loss val: 0.03406
[2022-12-06 21:45:07,132] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:45:07,391] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:45:07,391] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:45:16,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:45:26,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:45:35,526] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:45:44,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:45:53,329] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:46:02,075] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:46:11,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:46:20,155] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:46:29,036] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:46:38,268] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.658526290732118
[2022-12-06 21:46:38,269] [INFO] [runner_train_mujoco] Average state value: 0.48497765529155734
[2022-12-06 21:46:38,269] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 21:46:38,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04148
[2022-12-06 21:46:38,428] [INFO] [controller] EPOCH 2 loss ppo:  -0.01890, loss val: 0.04264
[2022-12-06 21:46:38,493] [INFO] [controller] EPOCH 3 loss ppo:  -0.02697, loss val: 0.04227
[2022-12-06 21:46:38,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.03417, loss val: 0.04128
[2022-12-06 21:46:38,586] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:46:38,829] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:46:38,829] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:46:48,252] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:46:57,355] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:47:06,421] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:47:15,485] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:47:24,173] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:47:33,659] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:47:42,681] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:47:52,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:48:00,984] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:48:10,281] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8311340240203813
[2022-12-06 21:48:10,281] [INFO] [runner_train_mujoco] Average state value: 0.4742124093472958
[2022-12-06 21:48:10,281] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 21:48:10,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.04540
[2022-12-06 21:48:10,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.02001, loss val: 0.04744
[2022-12-06 21:48:10,479] [INFO] [controller] EPOCH 3 loss ppo:  -0.02914, loss val: 0.04527
[2022-12-06 21:48:10,556] [INFO] [controller] EPOCH 4 loss ppo:  -0.03607, loss val: 0.04592
[2022-12-06 21:48:10,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:48:10,824] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:48:10,825] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:48:20,031] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:48:29,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:48:38,037] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:48:46,987] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:48:55,890] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:49:04,764] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:49:14,402] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:49:23,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:49:32,859] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:49:42,167] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8720933749150896
[2022-12-06 21:49:42,167] [INFO] [runner_train_mujoco] Average state value: 0.4706649163564046
[2022-12-06 21:49:42,167] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 21:49:42,244] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04671
[2022-12-06 21:49:42,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.01743, loss val: 0.04671
[2022-12-06 21:49:42,393] [INFO] [controller] EPOCH 3 loss ppo:  -0.02417, loss val: 0.04692
[2022-12-06 21:49:42,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.03133, loss val: 0.04826
[2022-12-06 21:49:42,501] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:49:42,745] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:49:42,746] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:49:53,781] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:50:04,210] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:50:16,512] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:50:27,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:50:39,442] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:50:50,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:51:02,095] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:51:13,570] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:51:24,907] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:51:35,825] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8450583062531445
[2022-12-06 21:51:35,826] [INFO] [runner_train_mujoco] Average state value: 0.46909903840223943
[2022-12-06 21:51:35,826] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 21:51:35,954] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.03831
[2022-12-06 21:51:36,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.01760, loss val: 0.03924
[2022-12-06 21:51:36,145] [INFO] [controller] EPOCH 3 loss ppo:  -0.02464, loss val: 0.03774
[2022-12-06 21:51:36,223] [INFO] [controller] EPOCH 4 loss ppo:  -0.03211, loss val: 0.03957
[2022-12-06 21:51:36,237] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:51:36,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:51:36,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:51:47,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:51:58,986] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:52:09,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:52:20,445] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:52:32,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:52:43,093] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:52:53,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:53:04,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:53:15,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:53:26,750] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.455075517964686
[2022-12-06 21:53:26,750] [INFO] [runner_train_mujoco] Average state value: 0.4659026498397192
[2022-12-06 21:53:26,751] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 21:53:27,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.03918
[2022-12-06 21:53:27,101] [INFO] [controller] EPOCH 2 loss ppo:  -0.01640, loss val: 0.03920
[2022-12-06 21:53:27,182] [INFO] [controller] EPOCH 3 loss ppo:  -0.02083, loss val: 0.03895
[2022-12-06 21:53:27,279] [INFO] [controller] EPOCH 4 loss ppo:  -0.02594, loss val: 0.03893
[2022-12-06 21:53:27,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:53:27,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:53:27,550] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:53:37,433] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:53:46,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:53:56,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:54:05,652] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:54:15,141] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:54:24,515] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:54:33,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:54:42,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:54:51,577] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:55:00,821] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.795897711830282
[2022-12-06 21:55:00,821] [INFO] [runner_train_mujoco] Average state value: 0.4684952717820803
[2022-12-06 21:55:00,822] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 21:55:00,925] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.03457
[2022-12-06 21:55:00,997] [INFO] [controller] EPOCH 2 loss ppo:  -0.01437, loss val: 0.03249
[2022-12-06 21:55:01,082] [INFO] [controller] EPOCH 3 loss ppo:  -0.01621, loss val: 0.03184
[2022-12-06 21:55:01,155] [INFO] [controller] EPOCH 4 loss ppo:  -0.01888, loss val: 0.03191
[2022-12-06 21:55:01,169] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:55:01,339] [INFO] [optimize] Finished learning.
