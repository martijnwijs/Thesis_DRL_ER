[2022-12-07 10:07:31,162] [INFO] [optimize] Starting learning
[2022-12-07 10:07:31,177] [INFO] [optimize] Starting learning process..
[2022-12-07 10:07:31,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:07:31,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:07:40,395] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:07:47,382] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:07:54,032] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:08:00,460] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:08:07,475] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:08:13,968] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:08:20,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:08:27,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:08:33,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:08:39,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0492683595626733
[2022-12-07 10:08:39,824] [INFO] [runner_train_mujoco] Average state value: -0.10139821466555196
[2022-12-07 10:08:39,825] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 10:08:39,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.71271
[2022-12-07 10:08:39,930] [INFO] [controller] EPOCH 2 loss ppo:  -0.03934, loss val: 0.68416
[2022-12-07 10:08:39,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.05377, loss val: 0.59346
[2022-12-07 10:08:40,021] [INFO] [controller] EPOCH 4 loss ppo:  -0.06079, loss val: 0.57006
[2022-12-07 10:08:40,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:08:40,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:08:40,227] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:08:46,514] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:08:53,203] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:09:00,106] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:09:08,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:09:19,314] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:09:30,644] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:09:38,464] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:09:45,099] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:09:53,955] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:10:01,759] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0561784962000609
[2022-12-07 10:10:01,759] [INFO] [runner_train_mujoco] Average state value: 0.05036160820225875
[2022-12-07 10:10:01,759] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 10:10:01,817] [INFO] [controller] EPOCH 1 loss ppo:  -0.01581, loss val: 0.34392
[2022-12-07 10:10:01,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.04343, loss val: 0.31337
[2022-12-07 10:10:01,923] [INFO] [controller] EPOCH 3 loss ppo:  -0.05332, loss val: 0.27964
[2022-12-07 10:10:01,986] [INFO] [controller] EPOCH 4 loss ppo:  -0.06160, loss val: 0.24997
[2022-12-07 10:10:01,998] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:10:02,231] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:10:02,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:10:09,473] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:10:16,724] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:10:23,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:10:31,907] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:10:38,023] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:10:44,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:10:53,758] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:11:03,027] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:11:09,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:11:16,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.030445272739019
[2022-12-07 10:11:16,550] [INFO] [runner_train_mujoco] Average state value: 0.17953743861243127
[2022-12-07 10:11:16,550] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 10:11:16,610] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.27589
[2022-12-07 10:11:16,660] [INFO] [controller] EPOCH 2 loss ppo:  -0.03689, loss val: 0.23894
[2022-12-07 10:11:16,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.04833, loss val: 0.21627
[2022-12-07 10:11:16,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.05685, loss val: 0.18515
[2022-12-07 10:11:16,765] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:11:16,963] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:11:16,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:11:23,248] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:11:30,141] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:11:36,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:11:46,547] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:11:53,964] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:11:59,995] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:12:05,974] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:12:12,061] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:12:17,703] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:12:24,124] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9877245558599199
[2022-12-07 10:12:24,124] [INFO] [runner_train_mujoco] Average state value: 0.3370115580745041
[2022-12-07 10:12:24,125] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 10:12:24,195] [INFO] [controller] EPOCH 1 loss ppo:  -0.01591, loss val: 0.15936
[2022-12-07 10:12:24,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.04389, loss val: 0.13976
[2022-12-07 10:12:24,288] [INFO] [controller] EPOCH 3 loss ppo:  -0.05585, loss val: 0.12641
[2022-12-07 10:12:24,335] [INFO] [controller] EPOCH 4 loss ppo:  -0.06548, loss val: 0.11000
[2022-12-07 10:12:24,345] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:12:24,538] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:12:24,539] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:12:30,718] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:12:37,194] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:12:45,753] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:12:53,098] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:12:59,874] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:13:05,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:13:11,340] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:13:17,004] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:13:22,734] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:13:28,474] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.034611301117321
[2022-12-07 10:13:28,474] [INFO] [runner_train_mujoco] Average state value: 0.43281249177580083
[2022-12-07 10:13:28,474] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 10:13:28,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.14073
[2022-12-07 10:13:28,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.03640, loss val: 0.12989
[2022-12-07 10:13:28,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.04727, loss val: 0.12145
[2022-12-07 10:13:28,686] [INFO] [controller] EPOCH 4 loss ppo:  -0.05548, loss val: 0.11493
[2022-12-07 10:13:28,695] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:13:28,888] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:13:28,889] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:13:34,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:13:40,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:13:46,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:13:52,173] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:13:57,848] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:14:03,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:14:09,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:14:15,256] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:14:21,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:14:27,680] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0606010297793595
[2022-12-07 10:14:27,680] [INFO] [runner_train_mujoco] Average state value: 0.5609552740529179
[2022-12-07 10:14:27,681] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 10:14:27,766] [INFO] [controller] EPOCH 1 loss ppo:  -0.01138, loss val: 0.08350
[2022-12-07 10:14:27,836] [INFO] [controller] EPOCH 2 loss ppo:  -0.03515, loss val: 0.07864
[2022-12-07 10:14:27,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.04365, loss val: 0.07455
[2022-12-07 10:14:27,953] [INFO] [controller] EPOCH 4 loss ppo:  -0.05355, loss val: 0.07076
[2022-12-07 10:14:27,965] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:14:28,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:14:28,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:14:34,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:14:40,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:14:46,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:14:51,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:14:57,557] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:15:03,569] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:15:09,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:15:14,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:15:21,069] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:15:27,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.142549854676288
[2022-12-07 10:15:27,447] [INFO] [runner_train_mujoco] Average state value: 0.5820727558284998
[2022-12-07 10:15:27,447] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 10:15:27,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01319, loss val: 0.06088
[2022-12-07 10:15:27,590] [INFO] [controller] EPOCH 2 loss ppo:  -0.03797, loss val: 0.05717
[2022-12-07 10:15:27,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.04493, loss val: 0.05819
[2022-12-07 10:15:27,699] [INFO] [controller] EPOCH 4 loss ppo:  -0.05104, loss val: 0.05078
[2022-12-07 10:15:27,717] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:15:27,943] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:15:27,944] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:15:34,936] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:15:42,457] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:15:49,911] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:15:56,898] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:16:02,818] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:16:08,617] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:16:14,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:16:20,327] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:16:26,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:16:33,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0312990547291898
[2022-12-07 10:16:33,773] [INFO] [runner_train_mujoco] Average state value: 0.5846634374757608
[2022-12-07 10:16:33,773] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 10:16:33,834] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.05345
[2022-12-07 10:16:33,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.03560, loss val: 0.05070
[2022-12-07 10:16:33,941] [INFO] [controller] EPOCH 3 loss ppo:  -0.04355, loss val: 0.05107
[2022-12-07 10:16:33,992] [INFO] [controller] EPOCH 4 loss ppo:  -0.05474, loss val: 0.04790
[2022-12-07 10:16:34,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:16:34,235] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:16:34,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:16:41,128] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:16:47,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:16:53,872] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:17:00,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:17:07,100] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:17:13,675] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:17:19,975] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:17:26,327] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:17:33,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:17:39,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3155591726710407
[2022-12-07 10:17:39,782] [INFO] [runner_train_mujoco] Average state value: 0.5528847393890222
[2022-12-07 10:17:39,782] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 10:17:39,847] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04922
[2022-12-07 10:17:39,903] [INFO] [controller] EPOCH 2 loss ppo:  -0.03540, loss val: 0.04513
[2022-12-07 10:17:39,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.04602, loss val: 0.04361
[2022-12-07 10:17:40,013] [INFO] [controller] EPOCH 4 loss ppo:  -0.05286, loss val: 0.04116
[2022-12-07 10:17:40,025] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:17:40,236] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:17:40,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:17:47,579] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:17:55,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:18:05,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:18:12,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:18:19,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:18:25,481] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:18:31,994] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:18:38,484] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:18:44,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:18:51,412] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.153869142433978
[2022-12-07 10:18:51,412] [INFO] [runner_train_mujoco] Average state value: 0.48107802525162696
[2022-12-07 10:18:51,412] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 10:18:51,470] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04880
[2022-12-07 10:18:51,522] [INFO] [controller] EPOCH 2 loss ppo:  -0.03697, loss val: 0.04886
[2022-12-07 10:18:51,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.04711, loss val: 0.04961
[2022-12-07 10:18:51,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.05612, loss val: 0.04761
[2022-12-07 10:18:51,633] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:18:51,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:18:51,835] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:18:59,417] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:19:06,321] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:19:12,410] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:19:18,692] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:19:24,883] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:19:31,180] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:19:37,635] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:19:43,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:19:49,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:19:55,586] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0040491326256573
[2022-12-07 10:19:55,587] [INFO] [runner_train_mujoco] Average state value: 0.4888087545831998
[2022-12-07 10:19:55,587] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 10:19:55,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.01152, loss val: 0.05814
[2022-12-07 10:19:55,680] [INFO] [controller] EPOCH 2 loss ppo:  -0.03281, loss val: 0.05336
[2022-12-07 10:19:55,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.04575, loss val: 0.04783
[2022-12-07 10:19:55,767] [INFO] [controller] EPOCH 4 loss ppo:  -0.05489, loss val: 0.04414
[2022-12-07 10:19:55,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:19:55,970] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:19:55,970] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:20:02,223] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:20:08,462] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:20:15,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:20:21,820] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:20:27,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:20:34,146] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:20:40,316] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:20:45,996] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:20:51,639] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:20:57,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2039101922033315
[2022-12-07 10:20:57,291] [INFO] [runner_train_mujoco] Average state value: 0.5682035300433637
[2022-12-07 10:20:57,291] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 10:20:57,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04788
[2022-12-07 10:20:57,392] [INFO] [controller] EPOCH 2 loss ppo:  -0.03192, loss val: 0.04849
[2022-12-07 10:20:57,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.04418, loss val: 0.04981
[2022-12-07 10:20:57,560] [INFO] [controller] EPOCH 4 loss ppo:  -0.05258, loss val: 0.04855
[2022-12-07 10:20:57,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:20:57,760] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:20:57,761] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:21:03,629] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:21:09,496] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:21:15,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:21:20,681] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:21:26,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:21:32,159] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:21:38,498] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:21:45,099] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:21:51,112] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:21:56,993] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1566542418899854
[2022-12-07 10:21:56,993] [INFO] [runner_train_mujoco] Average state value: 0.5739401657680671
[2022-12-07 10:21:56,994] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 10:21:57,070] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.03448
[2022-12-07 10:21:57,127] [INFO] [controller] EPOCH 2 loss ppo:  -0.03333, loss val: 0.03418
[2022-12-07 10:21:57,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.04504, loss val: 0.03188
[2022-12-07 10:21:57,248] [INFO] [controller] EPOCH 4 loss ppo:  -0.05179, loss val: 0.03113
[2022-12-07 10:21:57,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:21:57,465] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:21:57,466] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:22:04,412] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:22:10,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:22:15,713] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:22:21,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:22:27,297] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:22:32,695] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:22:38,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:22:44,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:22:50,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:22:55,742] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1773230830252825
[2022-12-07 10:22:55,742] [INFO] [runner_train_mujoco] Average state value: 0.5254125748872757
[2022-12-07 10:22:55,742] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 10:22:55,803] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.03986
[2022-12-07 10:22:55,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.03556, loss val: 0.04065
[2022-12-07 10:22:55,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.04999, loss val: 0.03838
[2022-12-07 10:22:55,937] [INFO] [controller] EPOCH 4 loss ppo:  -0.05816, loss val: 0.03920
[2022-12-07 10:22:55,946] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:22:56,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:22:56,148] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:23:02,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:23:09,360] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:23:17,936] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:23:25,767] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:23:31,413] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:23:37,622] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:23:43,287] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:23:49,050] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:23:55,840] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:24:02,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0476925527024237
[2022-12-07 10:24:02,089] [INFO] [runner_train_mujoco] Average state value: 0.4872029206156731
[2022-12-07 10:24:02,089] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 10:24:02,156] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.05166
[2022-12-07 10:24:02,204] [INFO] [controller] EPOCH 2 loss ppo:  -0.03489, loss val: 0.05083
[2022-12-07 10:24:02,248] [INFO] [controller] EPOCH 3 loss ppo:  -0.04839, loss val: 0.04974
[2022-12-07 10:24:02,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.05620, loss val: 0.04702
[2022-12-07 10:24:02,308] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:24:02,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:24:02,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:24:08,694] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:24:14,839] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:24:20,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:24:27,146] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:24:33,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:24:39,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:24:46,070] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:24:52,313] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:24:58,208] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:25:04,492] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2295253144215814
[2022-12-07 10:25:04,492] [INFO] [runner_train_mujoco] Average state value: 0.5115892141163348
[2022-12-07 10:25:04,492] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 10:25:04,563] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04925
[2022-12-07 10:25:04,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.03684, loss val: 0.04924
[2022-12-07 10:25:04,691] [INFO] [controller] EPOCH 3 loss ppo:  -0.05031, loss val: 0.04692
[2022-12-07 10:25:04,751] [INFO] [controller] EPOCH 4 loss ppo:  -0.05915, loss val: 0.04655
[2022-12-07 10:25:04,763] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:25:04,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:25:04,965] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:25:11,411] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:25:17,835] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:25:23,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:25:30,279] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:25:36,412] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:25:42,332] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:25:48,307] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:25:54,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:26:01,039] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:26:06,992] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0319269186232678
[2022-12-07 10:26:06,992] [INFO] [runner_train_mujoco] Average state value: 0.5737671296397846
[2022-12-07 10:26:06,992] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 10:26:07,046] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.03629
[2022-12-07 10:26:07,086] [INFO] [controller] EPOCH 2 loss ppo:  -0.03845, loss val: 0.03612
[2022-12-07 10:26:07,133] [INFO] [controller] EPOCH 3 loss ppo:  -0.04709, loss val: 0.03655
[2022-12-07 10:26:07,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.05762, loss val: 0.03635
[2022-12-07 10:26:07,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:26:07,396] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:26:07,396] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:26:13,939] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:26:20,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:26:27,135] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:26:33,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:26:39,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:26:45,044] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:26:51,555] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:26:57,744] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:27:03,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:27:10,069] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2112688375160157
[2022-12-07 10:27:10,069] [INFO] [runner_train_mujoco] Average state value: 0.5378839856435855
[2022-12-07 10:27:10,069] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 10:27:10,139] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.07617
[2022-12-07 10:27:10,191] [INFO] [controller] EPOCH 2 loss ppo:  -0.03577, loss val: 0.07562
[2022-12-07 10:27:10,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.04655, loss val: 0.07492
[2022-12-07 10:27:10,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.05362, loss val: 0.07398
[2022-12-07 10:27:10,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:27:10,537] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:27:10,537] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:27:16,544] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:27:23,325] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:27:30,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:27:36,818] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:27:43,244] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:27:49,320] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:27:55,055] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:28:01,161] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:28:07,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:28:14,262] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.236569277560934
[2022-12-07 10:28:14,262] [INFO] [runner_train_mujoco] Average state value: 0.570679562608401
[2022-12-07 10:28:14,262] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 10:28:14,321] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.04900
[2022-12-07 10:28:14,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.03209, loss val: 0.04746
[2022-12-07 10:28:14,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.04863, loss val: 0.04573
[2022-12-07 10:28:14,466] [INFO] [controller] EPOCH 4 loss ppo:  -0.05666, loss val: 0.04200
[2022-12-07 10:28:14,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:28:14,685] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:28:14,685] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:28:21,439] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:28:27,924] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:28:34,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:28:40,848] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:28:47,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:28:52,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:28:59,345] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:29:05,361] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:29:11,717] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:29:17,489] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.280467263470657
[2022-12-07 10:29:17,489] [INFO] [runner_train_mujoco] Average state value: 0.5035958370963732
[2022-12-07 10:29:17,489] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 10:29:17,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04584
[2022-12-07 10:29:17,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.03648, loss val: 0.04796
[2022-12-07 10:29:17,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.04915, loss val: 0.04831
[2022-12-07 10:29:17,688] [INFO] [controller] EPOCH 4 loss ppo:  -0.05418, loss val: 0.04862
[2022-12-07 10:29:17,698] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:29:17,881] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:29:17,881] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:29:24,054] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:29:30,148] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:29:36,134] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:29:42,619] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:29:49,331] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:29:55,944] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:30:02,484] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:30:08,730] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:30:14,694] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:30:20,622] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3878873858364513
[2022-12-07 10:30:20,622] [INFO] [runner_train_mujoco] Average state value: 0.4926136334041754
[2022-12-07 10:30:20,622] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 10:30:20,675] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03685
[2022-12-07 10:30:20,724] [INFO] [controller] EPOCH 2 loss ppo:  -0.03821, loss val: 0.03516
[2022-12-07 10:30:20,775] [INFO] [controller] EPOCH 3 loss ppo:  -0.05094, loss val: 0.03529
[2022-12-07 10:30:20,825] [INFO] [controller] EPOCH 4 loss ppo:  -0.05884, loss val: 0.03743
[2022-12-07 10:30:20,835] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:30:21,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:30:21,041] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:30:27,304] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:30:33,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:30:39,930] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:30:45,916] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:30:52,810] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:30:59,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:31:06,256] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:31:12,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:31:18,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:31:24,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3707216165602754
[2022-12-07 10:31:24,330] [INFO] [runner_train_mujoco] Average state value: 0.5017467652261257
[2022-12-07 10:31:24,330] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 10:31:24,403] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.03028
[2022-12-07 10:31:24,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.03691, loss val: 0.03091
[2022-12-07 10:31:24,516] [INFO] [controller] EPOCH 3 loss ppo:  -0.04992, loss val: 0.03120
[2022-12-07 10:31:24,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.05935, loss val: 0.02971
[2022-12-07 10:31:24,580] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:31:24,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:31:24,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:31:31,029] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:31:38,029] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:31:45,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:31:53,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:31:59,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:32:07,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:32:13,172] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:32:20,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:32:26,435] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:32:33,503] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.035506782825641
[2022-12-07 10:32:33,504] [INFO] [runner_train_mujoco] Average state value: 0.521057304074367
[2022-12-07 10:32:33,504] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 10:32:33,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01260, loss val: 0.03341
[2022-12-07 10:32:33,612] [INFO] [controller] EPOCH 2 loss ppo:  -0.03190, loss val: 0.03342
[2022-12-07 10:32:33,658] [INFO] [controller] EPOCH 3 loss ppo:  -0.04249, loss val: 0.03529
[2022-12-07 10:32:33,709] [INFO] [controller] EPOCH 4 loss ppo:  -0.05236, loss val: 0.03462
[2022-12-07 10:32:33,719] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:32:33,942] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:32:33,942] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:32:40,901] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:32:47,514] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:32:54,541] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:33:01,620] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:33:08,402] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:33:14,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:33:21,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:33:28,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:33:34,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:33:40,140] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4163362798997328
[2022-12-07 10:33:40,140] [INFO] [runner_train_mujoco] Average state value: 0.5200766707857449
[2022-12-07 10:33:40,140] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 10:33:40,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04620
[2022-12-07 10:33:40,247] [INFO] [controller] EPOCH 2 loss ppo:  -0.03535, loss val: 0.04643
[2022-12-07 10:33:40,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.04949, loss val: 0.04535
[2022-12-07 10:33:40,382] [INFO] [controller] EPOCH 4 loss ppo:  -0.05775, loss val: 0.04598
[2022-12-07 10:33:40,395] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:33:40,607] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:33:40,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:33:47,434] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:33:54,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:34:00,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:34:08,187] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:34:14,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:34:20,655] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:34:27,269] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:34:33,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:34:39,208] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:34:46,358] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.257976341673588
[2022-12-07 10:34:46,358] [INFO] [runner_train_mujoco] Average state value: 0.5368242218494416
[2022-12-07 10:34:46,358] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 10:34:46,440] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.03660
[2022-12-07 10:34:46,505] [INFO] [controller] EPOCH 2 loss ppo:  -0.03192, loss val: 0.04048
[2022-12-07 10:34:46,562] [INFO] [controller] EPOCH 3 loss ppo:  -0.04462, loss val: 0.03771
[2022-12-07 10:34:46,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.05604, loss val: 0.03767
[2022-12-07 10:34:46,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:34:46,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:34:46,957] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:34:53,154] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:34:59,871] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:35:05,797] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:35:11,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:35:17,981] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:35:24,245] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:35:29,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:35:35,931] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:35:41,937] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:35:48,529] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1960632884648352
[2022-12-07 10:35:48,530] [INFO] [runner_train_mujoco] Average state value: 0.5230120034317176
[2022-12-07 10:35:48,530] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 10:35:48,652] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.03670
[2022-12-07 10:35:48,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.03658, loss val: 0.03432
[2022-12-07 10:35:48,790] [INFO] [controller] EPOCH 3 loss ppo:  -0.04705, loss val: 0.03490
[2022-12-07 10:35:48,843] [INFO] [controller] EPOCH 4 loss ppo:  -0.05664, loss val: 0.03432
[2022-12-07 10:35:48,854] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:35:49,045] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:35:49,046] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:35:56,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:36:02,570] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:36:09,377] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:36:16,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:36:22,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:36:27,683] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:36:33,159] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:36:39,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:36:44,850] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:36:50,509] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3538414738827877
[2022-12-07 10:36:50,510] [INFO] [runner_train_mujoco] Average state value: 0.5185483714342116
[2022-12-07 10:36:50,510] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 10:36:50,576] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.03006
[2022-12-07 10:36:50,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.03433, loss val: 0.03074
[2022-12-07 10:36:50,678] [INFO] [controller] EPOCH 3 loss ppo:  -0.04647, loss val: 0.03204
[2022-12-07 10:36:50,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.05559, loss val: 0.03154
[2022-12-07 10:36:50,741] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:36:50,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:36:50,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:36:57,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:37:03,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:37:09,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:37:15,415] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:37:21,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:37:27,072] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:37:33,238] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:37:39,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:37:45,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:37:51,691] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2039267916024743
[2022-12-07 10:37:51,691] [INFO] [runner_train_mujoco] Average state value: 0.5250624220967293
[2022-12-07 10:37:51,691] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 10:37:51,748] [INFO] [controller] EPOCH 1 loss ppo:  -0.01244, loss val: 0.03685
[2022-12-07 10:37:51,792] [INFO] [controller] EPOCH 2 loss ppo:  -0.03132, loss val: 0.03687
[2022-12-07 10:37:51,834] [INFO] [controller] EPOCH 3 loss ppo:  -0.04589, loss val: 0.03651
[2022-12-07 10:37:51,882] [INFO] [controller] EPOCH 4 loss ppo:  -0.05295, loss val: 0.03472
[2022-12-07 10:37:51,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:37:52,089] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:37:52,089] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:37:58,114] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:38:04,516] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:38:10,464] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:38:16,535] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:38:22,580] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:38:28,418] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:38:34,780] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:38:41,044] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:38:47,434] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:38:53,700] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5809256903924969
[2022-12-07 10:38:53,701] [INFO] [runner_train_mujoco] Average state value: 0.5567144871354104
[2022-12-07 10:38:53,701] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 10:38:53,759] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.03787
[2022-12-07 10:38:53,805] [INFO] [controller] EPOCH 2 loss ppo:  -0.03436, loss val: 0.03640
[2022-12-07 10:38:53,853] [INFO] [controller] EPOCH 3 loss ppo:  -0.04910, loss val: 0.03664
[2022-12-07 10:38:53,899] [INFO] [controller] EPOCH 4 loss ppo:  -0.06033, loss val: 0.03665
[2022-12-07 10:38:53,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:38:54,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:38:54,111] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:39:00,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:39:06,890] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:39:13,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:39:19,127] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:39:25,206] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:39:31,100] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:39:37,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:39:43,303] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:39:48,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:39:54,684] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.666274456161623
[2022-12-07 10:39:54,684] [INFO] [runner_train_mujoco] Average state value: 0.5758768151899178
[2022-12-07 10:39:54,684] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 10:39:54,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.04989
[2022-12-07 10:39:54,799] [INFO] [controller] EPOCH 2 loss ppo:  -0.02655, loss val: 0.05189
[2022-12-07 10:39:54,855] [INFO] [controller] EPOCH 3 loss ppo:  -0.03686, loss val: 0.03978
[2022-12-07 10:39:54,902] [INFO] [controller] EPOCH 4 loss ppo:  -0.04819, loss val: 0.04178
[2022-12-07 10:39:54,913] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:39:55,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:39:55,112] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:40:01,112] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:40:07,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:40:12,741] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:40:18,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:40:24,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:40:31,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:40:37,000] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:40:42,749] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:40:49,083] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:40:54,688] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.607436010877387
[2022-12-07 10:40:54,688] [INFO] [runner_train_mujoco] Average state value: 0.5162931046846012
[2022-12-07 10:40:54,688] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 10:40:54,751] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04531
[2022-12-07 10:40:54,795] [INFO] [controller] EPOCH 2 loss ppo:  -0.03610, loss val: 0.04691
[2022-12-07 10:40:54,839] [INFO] [controller] EPOCH 3 loss ppo:  -0.05117, loss val: 0.04582
[2022-12-07 10:40:54,884] [INFO] [controller] EPOCH 4 loss ppo:  -0.06437, loss val: 0.04661
[2022-12-07 10:40:54,895] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:40:55,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:40:55,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:41:00,787] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:41:06,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:41:12,083] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:41:17,475] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:41:22,839] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:41:29,114] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:41:34,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:41:42,061] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:41:47,537] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:41:53,706] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.768524259443915
[2022-12-07 10:41:53,706] [INFO] [runner_train_mujoco] Average state value: 0.5210936764280001
[2022-12-07 10:41:53,706] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 10:41:53,768] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.03444
[2022-12-07 10:41:53,823] [INFO] [controller] EPOCH 2 loss ppo:  -0.03212, loss val: 0.03874
[2022-12-07 10:41:53,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.04354, loss val: 0.03803
[2022-12-07 10:41:53,916] [INFO] [controller] EPOCH 4 loss ppo:  -0.05413, loss val: 0.03524
[2022-12-07 10:41:53,926] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:41:54,122] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:41:54,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:42:00,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:42:06,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:42:12,326] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:42:17,838] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:42:23,590] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:42:28,999] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:42:34,922] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:42:40,600] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:42:46,509] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:42:52,502] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5590502583823855
[2022-12-07 10:42:52,503] [INFO] [runner_train_mujoco] Average state value: 0.5052140845457712
[2022-12-07 10:42:52,503] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 10:42:52,629] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03419
[2022-12-07 10:42:52,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.02730, loss val: 0.03238
[2022-12-07 10:42:52,721] [INFO] [controller] EPOCH 3 loss ppo:  -0.04284, loss val: 0.03509
[2022-12-07 10:42:52,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.05331, loss val: 0.03271
[2022-12-07 10:42:52,771] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:42:52,948] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:42:52,948] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:42:59,152] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:43:05,139] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:43:10,976] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:43:16,761] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:43:23,768] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:43:30,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:43:36,303] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:43:42,035] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:43:48,011] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:43:53,910] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.572322584954517
[2022-12-07 10:43:53,910] [INFO] [runner_train_mujoco] Average state value: 0.48250500424082077
[2022-12-07 10:43:53,911] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 10:43:53,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.05153
[2022-12-07 10:43:54,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.02819, loss val: 0.04950
[2022-12-07 10:43:54,102] [INFO] [controller] EPOCH 3 loss ppo:  -0.04561, loss val: 0.04928
[2022-12-07 10:43:54,150] [INFO] [controller] EPOCH 4 loss ppo:  -0.05445, loss val: 0.04907
[2022-12-07 10:43:54,160] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:43:54,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:43:54,349] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:44:00,235] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:44:06,392] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:44:12,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:44:18,796] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:44:24,703] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:44:30,851] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:44:36,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:44:43,043] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:44:49,283] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:44:55,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6790366212665202
[2022-12-07 10:44:55,421] [INFO] [runner_train_mujoco] Average state value: 0.4821206754793724
[2022-12-07 10:44:55,421] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 10:44:55,496] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04478
[2022-12-07 10:44:55,564] [INFO] [controller] EPOCH 2 loss ppo:  -0.03207, loss val: 0.04747
[2022-12-07 10:44:55,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.04635, loss val: 0.04483
[2022-12-07 10:44:55,668] [INFO] [controller] EPOCH 4 loss ppo:  -0.05879, loss val: 0.04394
[2022-12-07 10:44:55,680] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:44:55,894] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:44:55,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:45:02,321] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:45:08,626] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:45:14,682] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:45:20,642] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:45:26,919] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:45:32,793] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:45:40,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:45:47,247] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:45:54,420] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:46:01,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.961621096879293
[2022-12-07 10:46:01,105] [INFO] [runner_train_mujoco] Average state value: 0.48813606761520106
[2022-12-07 10:46:01,105] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 10:46:01,156] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.06256
[2022-12-07 10:46:01,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.02866, loss val: 0.06241
[2022-12-07 10:46:01,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.03985, loss val: 0.06315
[2022-12-07 10:46:01,295] [INFO] [controller] EPOCH 4 loss ppo:  -0.04857, loss val: 0.06334
[2022-12-07 10:46:01,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:46:01,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:46:01,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:46:08,514] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:46:16,155] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:46:22,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:46:29,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:46:35,620] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:46:42,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:46:49,068] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:46:55,215] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:47:02,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:47:08,398] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.11550860850499
[2022-12-07 10:47:08,398] [INFO] [runner_train_mujoco] Average state value: 0.5419901088029146
[2022-12-07 10:47:08,398] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 10:47:08,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.04167
[2022-12-07 10:47:08,506] [INFO] [controller] EPOCH 2 loss ppo:  -0.03046, loss val: 0.03696
[2022-12-07 10:47:08,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.04260, loss val: 0.03672
[2022-12-07 10:47:08,600] [INFO] [controller] EPOCH 4 loss ppo:  -0.05219, loss val: 0.03656
[2022-12-07 10:47:08,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:47:08,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:47:08,814] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:47:14,774] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:47:21,405] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:47:27,358] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:47:33,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:47:39,978] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:47:46,208] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:47:53,260] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:47:59,329] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:48:05,995] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:48:12,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8583910574441531
[2022-12-07 10:48:12,370] [INFO] [runner_train_mujoco] Average state value: 0.5571049598331252
[2022-12-07 10:48:12,370] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 10:48:12,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.03890
[2022-12-07 10:48:12,479] [INFO] [controller] EPOCH 2 loss ppo:  -0.02995, loss val: 0.03842
[2022-12-07 10:48:12,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.04157, loss val: 0.03796
[2022-12-07 10:48:12,583] [INFO] [controller] EPOCH 4 loss ppo:  -0.05235, loss val: 0.04192
[2022-12-07 10:48:12,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:48:12,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:48:12,823] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:48:19,585] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:48:25,867] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:48:31,770] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:48:38,016] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:48:43,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:48:50,491] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:48:56,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:49:02,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:49:08,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:49:15,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.219061897270443
[2022-12-07 10:49:15,112] [INFO] [runner_train_mujoco] Average state value: 0.5423384576936563
[2022-12-07 10:49:15,113] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 10:49:15,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04199
[2022-12-07 10:49:15,218] [INFO] [controller] EPOCH 2 loss ppo:  -0.03026, loss val: 0.04207
[2022-12-07 10:49:15,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.04295, loss val: 0.04114
[2022-12-07 10:49:15,305] [INFO] [controller] EPOCH 4 loss ppo:  -0.05152, loss val: 0.04113
[2022-12-07 10:49:15,316] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:49:15,511] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:49:15,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:49:23,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:49:29,784] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:49:36,230] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:49:42,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:49:49,979] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:49:58,701] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:50:05,038] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:50:10,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:50:16,455] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:50:22,589] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.298027546041575
[2022-12-07 10:50:22,589] [INFO] [runner_train_mujoco] Average state value: 0.5064002682467301
[2022-12-07 10:50:22,589] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 10:50:22,655] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04048
[2022-12-07 10:50:22,702] [INFO] [controller] EPOCH 2 loss ppo:  -0.03221, loss val: 0.04036
[2022-12-07 10:50:22,753] [INFO] [controller] EPOCH 3 loss ppo:  -0.04221, loss val: 0.03994
[2022-12-07 10:50:22,801] [INFO] [controller] EPOCH 4 loss ppo:  -0.05141, loss val: 0.04011
[2022-12-07 10:50:22,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:50:23,023] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:50:23,023] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:50:29,177] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:50:36,039] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:50:45,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:50:53,058] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:50:59,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:51:05,541] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:51:12,193] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:51:18,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:51:24,442] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:51:31,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7034198125533733
[2022-12-07 10:51:31,109] [INFO] [runner_train_mujoco] Average state value: 0.49736743358771
[2022-12-07 10:51:31,109] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 10:51:31,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.04106
[2022-12-07 10:51:31,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.02543, loss val: 0.04076
[2022-12-07 10:51:31,288] [INFO] [controller] EPOCH 3 loss ppo:  -0.03838, loss val: 0.03956
[2022-12-07 10:51:31,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.04852, loss val: 0.04130
[2022-12-07 10:51:31,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:51:31,564] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:51:31,565] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:51:37,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:51:45,183] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:51:50,852] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:51:56,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:52:02,708] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:52:08,713] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:52:15,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:52:21,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:52:29,548] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:52:36,240] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7127838099902113
[2022-12-07 10:52:36,240] [INFO] [runner_train_mujoco] Average state value: 0.5042407192985218
[2022-12-07 10:52:36,240] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 10:52:36,319] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.03187
[2022-12-07 10:52:36,373] [INFO] [controller] EPOCH 2 loss ppo:  -0.02814, loss val: 0.03200
[2022-12-07 10:52:36,430] [INFO] [controller] EPOCH 3 loss ppo:  -0.03825, loss val: 0.03212
[2022-12-07 10:52:36,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.04856, loss val: 0.03242
[2022-12-07 10:52:36,495] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:52:36,713] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:52:36,714] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:52:44,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:52:50,835] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:52:57,129] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:53:03,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:53:09,512] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:53:15,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:53:22,358] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:53:28,679] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:53:35,502] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:53:42,238] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.409600404195069
[2022-12-07 10:53:42,239] [INFO] [runner_train_mujoco] Average state value: 0.5030034653544426
[2022-12-07 10:53:42,239] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 10:53:42,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01514, loss val: 0.05042
[2022-12-07 10:53:42,354] [INFO] [controller] EPOCH 2 loss ppo:  -0.02760, loss val: 0.05124
[2022-12-07 10:53:42,400] [INFO] [controller] EPOCH 3 loss ppo:  -0.03711, loss val: 0.04994
[2022-12-07 10:53:42,447] [INFO] [controller] EPOCH 4 loss ppo:  -0.04598, loss val: 0.04987
[2022-12-07 10:53:42,457] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:53:42,651] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:53:42,651] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:53:49,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:53:55,845] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:54:01,538] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:54:07,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:54:13,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:54:19,165] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:54:25,372] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:54:31,275] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:54:37,316] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:54:43,639] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.736450409887727
[2022-12-07 10:54:43,639] [INFO] [runner_train_mujoco] Average state value: 0.5309667220513026
[2022-12-07 10:54:43,639] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 10:54:43,703] [INFO] [controller] EPOCH 1 loss ppo:  -0.01514, loss val: 0.03597
[2022-12-07 10:54:43,760] [INFO] [controller] EPOCH 2 loss ppo:  -0.02762, loss val: 0.03618
[2022-12-07 10:54:43,815] [INFO] [controller] EPOCH 3 loss ppo:  -0.03433, loss val: 0.03655
[2022-12-07 10:54:43,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.04518, loss val: 0.03872
[2022-12-07 10:54:43,884] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:54:44,082] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:54:44,082] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:54:50,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:54:56,485] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:55:01,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:55:07,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:55:13,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:55:19,227] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:55:25,285] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:55:31,253] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:55:36,783] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:55:43,059] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7338176509734695
[2022-12-07 10:55:43,059] [INFO] [runner_train_mujoco] Average state value: 0.5311396039326985
[2022-12-07 10:55:43,059] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 10:55:43,114] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.03395
[2022-12-07 10:55:43,160] [INFO] [controller] EPOCH 2 loss ppo:  -0.02425, loss val: 0.03381
[2022-12-07 10:55:43,209] [INFO] [controller] EPOCH 3 loss ppo:  -0.03459, loss val: 0.03527
[2022-12-07 10:55:43,257] [INFO] [controller] EPOCH 4 loss ppo:  -0.04514, loss val: 0.03485
[2022-12-07 10:55:43,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:55:43,469] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:55:43,469] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:55:49,340] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:55:55,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:56:01,486] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:56:07,031] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:56:12,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:56:20,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:56:28,115] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:56:33,817] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:56:39,910] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:56:45,792] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9459482264089094
[2022-12-07 10:56:45,793] [INFO] [runner_train_mujoco] Average state value: 0.501071322520574
[2022-12-07 10:56:45,793] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 10:56:45,847] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.04788
[2022-12-07 10:56:45,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.02467, loss val: 0.04820
[2022-12-07 10:56:46,010] [INFO] [controller] EPOCH 3 loss ppo:  -0.03661, loss val: 0.04840
[2022-12-07 10:56:46,062] [INFO] [controller] EPOCH 4 loss ppo:  -0.04680, loss val: 0.04814
[2022-12-07 10:56:46,071] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:56:46,264] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:56:46,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:56:52,014] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:56:58,468] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:57:04,183] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:57:10,257] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:57:15,872] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:57:21,552] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:57:27,195] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:57:33,489] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:57:40,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:57:46,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9954034637040685
[2022-12-07 10:57:46,671] [INFO] [runner_train_mujoco] Average state value: 0.49098764656235777
[2022-12-07 10:57:46,671] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 10:57:46,729] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04220
[2022-12-07 10:57:46,777] [INFO] [controller] EPOCH 2 loss ppo:  -0.02254, loss val: 0.04207
[2022-12-07 10:57:46,821] [INFO] [controller] EPOCH 3 loss ppo:  -0.03345, loss val: 0.04224
[2022-12-07 10:57:46,867] [INFO] [controller] EPOCH 4 loss ppo:  -0.04276, loss val: 0.04227
[2022-12-07 10:57:46,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:57:47,065] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:57:47,065] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:57:54,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:58:01,035] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:58:09,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:58:15,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:58:22,058] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:58:27,857] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:58:33,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:58:39,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:58:45,525] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:58:52,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6749112383247615
[2022-12-07 10:58:52,632] [INFO] [runner_train_mujoco] Average state value: 0.5073664475604891
[2022-12-07 10:58:52,632] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 10:58:52,690] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.04402
[2022-12-07 10:58:52,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.02306, loss val: 0.04341
[2022-12-07 10:58:52,780] [INFO] [controller] EPOCH 3 loss ppo:  -0.02936, loss val: 0.04649
[2022-12-07 10:58:52,830] [INFO] [controller] EPOCH 4 loss ppo:  -0.03523, loss val: 0.04343
[2022-12-07 10:58:52,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:58:53,042] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:58:53,043] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:58:59,252] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:59:06,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:59:13,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:59:21,901] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:59:29,840] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:59:37,410] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:59:44,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:59:52,369] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:59:59,880] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:00:07,372] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.219712141947703
[2022-12-07 11:00:07,372] [INFO] [runner_train_mujoco] Average state value: 0.503173222889503
[2022-12-07 11:00:07,372] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 11:00:07,440] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.03790
[2022-12-07 11:00:07,492] [INFO] [controller] EPOCH 2 loss ppo:  -0.02427, loss val: 0.03779
[2022-12-07 11:00:07,549] [INFO] [controller] EPOCH 3 loss ppo:  -0.03379, loss val: 0.03821
[2022-12-07 11:00:07,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.04343, loss val: 0.03775
[2022-12-07 11:00:07,612] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:00:07,833] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:00:07,834] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:00:14,734] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:00:22,673] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:00:30,572] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:00:38,488] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:00:46,123] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:00:53,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:01:01,536] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:01:09,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:01:16,743] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:01:24,113] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3533439806121335
[2022-12-07 11:01:24,113] [INFO] [runner_train_mujoco] Average state value: 0.4964654833873112
[2022-12-07 11:01:24,113] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 11:01:24,185] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.03867
[2022-12-07 11:01:24,241] [INFO] [controller] EPOCH 2 loss ppo:  -0.02182, loss val: 0.03750
[2022-12-07 11:01:24,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.03236, loss val: 0.03765
[2022-12-07 11:01:24,390] [INFO] [controller] EPOCH 4 loss ppo:  -0.03990, loss val: 0.03691
[2022-12-07 11:01:24,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:01:24,633] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:01:24,633] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:01:34,052] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:01:42,645] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:01:50,514] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:01:59,066] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:02:07,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:02:16,073] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:02:24,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:02:32,036] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:02:40,036] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:02:47,695] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.187094213747734
[2022-12-07 11:02:47,695] [INFO] [runner_train_mujoco] Average state value: 0.4815880180050929
[2022-12-07 11:02:47,695] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 11:02:47,772] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.04255
[2022-12-07 11:02:47,830] [INFO] [controller] EPOCH 2 loss ppo:  -0.02051, loss val: 0.04167
[2022-12-07 11:02:47,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.02946, loss val: 0.04306
[2022-12-07 11:02:47,952] [INFO] [controller] EPOCH 4 loss ppo:  -0.03754, loss val: 0.04310
[2022-12-07 11:02:47,966] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:02:48,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:02:48,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:02:56,011] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:03:04,028] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:03:11,716] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:03:19,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:03:27,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:03:35,103] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:03:42,703] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:03:50,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:03:59,093] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:04:07,076] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3606096675238613
[2022-12-07 11:04:07,076] [INFO] [runner_train_mujoco] Average state value: 0.4787624927833676
[2022-12-07 11:04:07,076] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 11:04:07,162] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.05374
[2022-12-07 11:04:07,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.02034, loss val: 0.05432
[2022-12-07 11:04:07,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.02957, loss val: 0.05216
[2022-12-07 11:04:07,423] [INFO] [controller] EPOCH 4 loss ppo:  -0.03802, loss val: 0.05184
[2022-12-07 11:04:07,437] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:04:07,656] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:04:07,657] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:04:15,180] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:04:22,561] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:04:29,892] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:04:37,371] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:04:44,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:04:51,930] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:04:59,098] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:05:05,887] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:05:12,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:05:20,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7250992482124823
[2022-12-07 11:05:20,481] [INFO] [runner_train_mujoco] Average state value: 0.4756825213879347
[2022-12-07 11:05:20,481] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 11:05:20,548] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.03951
[2022-12-07 11:05:20,607] [INFO] [controller] EPOCH 2 loss ppo:  -0.01956, loss val: 0.03954
[2022-12-07 11:05:20,663] [INFO] [controller] EPOCH 3 loss ppo:  -0.02761, loss val: 0.04078
[2022-12-07 11:05:20,723] [INFO] [controller] EPOCH 4 loss ppo:  -0.03377, loss val: 0.03951
[2022-12-07 11:05:20,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:05:20,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:05:20,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:05:28,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:05:35,983] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:05:42,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:05:49,858] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:05:57,115] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:06:04,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:06:11,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:06:18,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:06:25,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:06:33,186] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4190579072054126
[2022-12-07 11:06:33,187] [INFO] [runner_train_mujoco] Average state value: 0.4677183486285309
[2022-12-07 11:06:33,187] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 11:06:33,265] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.03683
[2022-12-07 11:06:33,336] [INFO] [controller] EPOCH 2 loss ppo:  -0.02003, loss val: 0.03602
[2022-12-07 11:06:33,397] [INFO] [controller] EPOCH 3 loss ppo:  -0.02785, loss val: 0.03548
[2022-12-07 11:06:33,475] [INFO] [controller] EPOCH 4 loss ppo:  -0.03458, loss val: 0.03672
[2022-12-07 11:06:33,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:06:33,710] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:06:33,710] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:06:41,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:06:48,587] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:06:55,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:07:03,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:07:13,182] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:07:22,807] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:07:32,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:07:41,232] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:07:48,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:07:56,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3108913150680137
[2022-12-07 11:07:56,335] [INFO] [runner_train_mujoco] Average state value: 0.4829344692627589
[2022-12-07 11:07:56,335] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 11:07:56,424] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.03739
[2022-12-07 11:07:56,493] [INFO] [controller] EPOCH 2 loss ppo:  -0.01601, loss val: 0.03476
[2022-12-07 11:07:56,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.02071, loss val: 0.03418
[2022-12-07 11:07:56,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.02734, loss val: 0.03414
[2022-12-07 11:07:56,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:07:56,848] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:07:56,848] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:08:04,612] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:08:12,796] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:08:20,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:08:29,149] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:08:37,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:08:46,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:08:54,271] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:09:02,486] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:09:10,502] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:09:18,687] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.907087479434714
[2022-12-07 11:09:18,687] [INFO] [runner_train_mujoco] Average state value: 0.472198985743026
[2022-12-07 11:09:18,687] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 11:09:18,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.04879
[2022-12-07 11:09:18,834] [INFO] [controller] EPOCH 2 loss ppo:  -0.01755, loss val: 0.04800
[2022-12-07 11:09:18,898] [INFO] [controller] EPOCH 3 loss ppo:  -0.02231, loss val: 0.04878
[2022-12-07 11:09:18,957] [INFO] [controller] EPOCH 4 loss ppo:  -0.02752, loss val: 0.04765
[2022-12-07 11:09:18,970] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:09:19,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:09:19,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:09:28,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:09:37,507] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:09:46,289] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:09:54,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:10:01,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:10:09,359] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:10:16,614] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:10:24,152] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:10:31,865] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:10:39,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4660607904958054
[2022-12-07 11:10:39,284] [INFO] [runner_train_mujoco] Average state value: 0.4855585712442796
[2022-12-07 11:10:39,284] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 11:10:39,366] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.03375
[2022-12-07 11:10:39,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.01668, loss val: 0.03309
[2022-12-07 11:10:39,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.02052, loss val: 0.03580
[2022-12-07 11:10:39,554] [INFO] [controller] EPOCH 4 loss ppo:  -0.02540, loss val: 0.03315
[2022-12-07 11:10:39,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:10:39,798] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:10:39,798] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:10:47,410] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:10:54,513] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:11:02,271] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:11:10,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:11:18,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:11:26,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:11:33,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:11:40,860] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:11:48,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:11:56,204] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.569680447322444
[2022-12-07 11:11:56,204] [INFO] [runner_train_mujoco] Average state value: 0.4890860416094463
[2022-12-07 11:11:56,204] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 11:11:56,288] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.05025
[2022-12-07 11:11:56,347] [INFO] [controller] EPOCH 2 loss ppo:  -0.01583, loss val: 0.04879
[2022-12-07 11:11:56,408] [INFO] [controller] EPOCH 3 loss ppo:  -0.01845, loss val: 0.04830
[2022-12-07 11:11:56,476] [INFO] [controller] EPOCH 4 loss ppo:  -0.02207, loss val: 0.04814
[2022-12-07 11:11:56,488] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:11:56,633] [INFO] [optimize] Finished learning.
