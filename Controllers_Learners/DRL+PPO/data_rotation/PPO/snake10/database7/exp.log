[2022-12-07 04:15:55,308] [INFO] [optimize] Starting learning
[2022-12-07 04:15:55,323] [INFO] [optimize] Starting learning process..
[2022-12-07 04:15:55,408] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:15:55,409] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:16:02,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:16:08,261] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:16:14,117] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:16:20,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:16:26,406] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:16:32,355] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:16:38,131] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:16:43,763] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:16:49,596] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:16:55,509] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0017769300703514
[2022-12-07 04:16:55,509] [INFO] [runner_train_mujoco] Average state value: -0.08845520476872722
[2022-12-07 04:16:55,509] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 04:16:55,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.58046
[2022-12-07 04:16:55,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.04499, loss val: 0.53592
[2022-12-07 04:16:55,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.05561, loss val: 0.47431
[2022-12-07 04:16:55,708] [INFO] [controller] EPOCH 4 loss ppo:  -0.06346, loss val: 0.42629
[2022-12-07 04:16:55,718] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:16:55,892] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:16:55,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:17:01,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:17:07,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:17:13,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:17:18,868] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:17:24,740] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:17:30,445] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:17:36,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:17:41,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:17:47,980] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:17:54,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9151925676004355
[2022-12-07 04:17:54,195] [INFO] [runner_train_mujoco] Average state value: 0.05524050989995399
[2022-12-07 04:17:54,196] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 04:17:54,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.32023
[2022-12-07 04:17:54,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.03888, loss val: 0.28883
[2022-12-07 04:17:54,338] [INFO] [controller] EPOCH 3 loss ppo:  -0.05012, loss val: 0.25069
[2022-12-07 04:17:54,385] [INFO] [controller] EPOCH 4 loss ppo:  -0.05829, loss val: 0.22026
[2022-12-07 04:17:54,395] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:17:54,579] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:17:54,580] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:18:00,289] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:18:06,485] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:18:12,386] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:18:17,884] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:18:23,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:18:29,207] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:18:34,767] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:18:40,715] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:18:46,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:18:51,850] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9708933011963637
[2022-12-07 04:18:51,850] [INFO] [runner_train_mujoco] Average state value: 0.22079587538540366
[2022-12-07 04:18:51,850] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 04:18:51,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.23529
[2022-12-07 04:18:51,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.03478, loss val: 0.20809
[2022-12-07 04:18:51,990] [INFO] [controller] EPOCH 3 loss ppo:  -0.05006, loss val: 0.18130
[2022-12-07 04:18:52,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.05942, loss val: 0.14834
[2022-12-07 04:18:52,048] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:18:52,227] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:18:52,228] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:18:58,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:19:04,802] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:19:10,989] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:19:16,714] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:19:22,467] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:19:28,537] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:19:34,509] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:19:40,259] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:19:45,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:19:51,125] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1484914603026326
[2022-12-07 04:19:51,125] [INFO] [runner_train_mujoco] Average state value: 0.3467638239947458
[2022-12-07 04:19:51,125] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 04:19:51,187] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.13893
[2022-12-07 04:19:51,225] [INFO] [controller] EPOCH 2 loss ppo:  -0.03672, loss val: 0.12378
[2022-12-07 04:19:51,270] [INFO] [controller] EPOCH 3 loss ppo:  -0.04976, loss val: 0.10858
[2022-12-07 04:19:51,315] [INFO] [controller] EPOCH 4 loss ppo:  -0.05663, loss val: 0.09507
[2022-12-07 04:19:51,321] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:19:51,509] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:19:51,509] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:19:57,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:20:02,787] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:20:09,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:20:15,090] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:20:21,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:20:26,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:20:32,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:20:38,222] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:20:43,782] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:20:49,394] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0234285993818462
[2022-12-07 04:20:49,394] [INFO] [runner_train_mujoco] Average state value: 0.4832825441670915
[2022-12-07 04:20:49,395] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 04:20:49,461] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.09895
[2022-12-07 04:20:49,508] [INFO] [controller] EPOCH 2 loss ppo:  -0.03972, loss val: 0.08780
[2022-12-07 04:20:49,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.05273, loss val: 0.07832
[2022-12-07 04:20:49,595] [INFO] [controller] EPOCH 4 loss ppo:  -0.06324, loss val: 0.07504
[2022-12-07 04:20:49,604] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:20:49,799] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:20:49,799] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:20:55,715] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:21:01,837] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:21:07,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:21:13,585] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:21:18,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:21:24,356] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:21:30,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:21:35,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:21:41,654] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:21:47,429] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1465724196505538
[2022-12-07 04:21:47,429] [INFO] [runner_train_mujoco] Average state value: 0.565732242166996
[2022-12-07 04:21:47,430] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 04:21:47,486] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.07541
[2022-12-07 04:21:47,529] [INFO] [controller] EPOCH 2 loss ppo:  -0.04261, loss val: 0.07053
[2022-12-07 04:21:47,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.05381, loss val: 0.06753
[2022-12-07 04:21:47,617] [INFO] [controller] EPOCH 4 loss ppo:  -0.06040, loss val: 0.06440
[2022-12-07 04:21:47,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:21:47,822] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:21:47,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:21:53,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:22:00,605] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:22:06,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:22:13,079] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:22:18,503] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:22:24,006] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:22:29,894] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:22:35,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:22:40,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:22:46,445] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0873195148860426
[2022-12-07 04:22:46,445] [INFO] [runner_train_mujoco] Average state value: 0.6166583942684034
[2022-12-07 04:22:46,445] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 04:22:46,509] [INFO] [controller] EPOCH 1 loss ppo:  -0.01080, loss val: 0.06465
[2022-12-07 04:22:46,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.03659, loss val: 0.06042
[2022-12-07 04:22:46,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.04827, loss val: 0.05837
[2022-12-07 04:22:46,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.05766, loss val: 0.05625
[2022-12-07 04:22:46,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:22:46,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:22:46,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:22:52,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:22:59,071] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:23:05,515] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:23:11,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:23:17,140] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:23:22,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:23:28,139] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:23:33,847] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:23:39,398] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:23:45,075] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.138293245626919
[2022-12-07 04:23:45,075] [INFO] [runner_train_mujoco] Average state value: 0.6097981446062525
[2022-12-07 04:23:45,075] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 04:23:45,136] [INFO] [controller] EPOCH 1 loss ppo:  -0.01072, loss val: 0.05004
[2022-12-07 04:23:45,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.03593, loss val: 0.04883
[2022-12-07 04:23:45,227] [INFO] [controller] EPOCH 3 loss ppo:  -0.05147, loss val: 0.04732
[2022-12-07 04:23:45,277] [INFO] [controller] EPOCH 4 loss ppo:  -0.05972, loss val: 0.04603
[2022-12-07 04:23:45,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:23:45,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:23:45,469] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:23:50,856] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:23:56,549] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:24:02,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:24:07,778] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:24:13,885] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:24:19,301] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:24:25,537] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:24:31,266] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:24:36,713] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:24:42,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3854136291727364
[2022-12-07 04:24:42,201] [INFO] [runner_train_mujoco] Average state value: 0.5821216459485392
[2022-12-07 04:24:42,201] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 04:24:42,263] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.04578
[2022-12-07 04:24:42,307] [INFO] [controller] EPOCH 2 loss ppo:  -0.03889, loss val: 0.04500
[2022-12-07 04:24:42,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.04894, loss val: 0.04327
[2022-12-07 04:24:42,407] [INFO] [controller] EPOCH 4 loss ppo:  -0.05762, loss val: 0.04215
[2022-12-07 04:24:42,418] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:24:42,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:24:42,616] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:24:48,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:24:54,082] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:24:59,591] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:25:05,399] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:25:11,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:25:17,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:25:22,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:25:28,106] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:25:34,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:25:39,859] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0728673164022284
[2022-12-07 04:25:39,859] [INFO] [runner_train_mujoco] Average state value: 0.5677679078976313
[2022-12-07 04:25:39,859] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 04:25:39,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01248, loss val: 0.04838
[2022-12-07 04:25:39,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.03839, loss val: 0.04957
[2022-12-07 04:25:40,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.04598, loss val: 0.04703
[2022-12-07 04:25:40,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.05315, loss val: 0.04655
[2022-12-07 04:25:40,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:25:40,231] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:25:40,231] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:25:46,228] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:25:51,902] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:25:57,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:26:03,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:26:09,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:26:15,242] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:26:20,775] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:26:26,098] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:26:31,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:26:37,096] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.168283763780286
[2022-12-07 04:26:37,096] [INFO] [runner_train_mujoco] Average state value: 0.5413656274477641
[2022-12-07 04:26:37,096] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 04:26:37,162] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.03913
[2022-12-07 04:26:37,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.04564, loss val: 0.03655
[2022-12-07 04:26:37,296] [INFO] [controller] EPOCH 3 loss ppo:  -0.05481, loss val: 0.03608
[2022-12-07 04:26:37,362] [INFO] [controller] EPOCH 4 loss ppo:  -0.06185, loss val: 0.03636
[2022-12-07 04:26:37,373] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:26:37,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:26:37,562] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:26:43,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:26:49,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:26:54,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:27:00,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:27:06,810] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:27:12,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:27:18,193] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:27:23,726] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:27:29,366] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:27:34,915] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.014671590914617
[2022-12-07 04:27:34,915] [INFO] [runner_train_mujoco] Average state value: 0.5205820212364196
[2022-12-07 04:27:34,915] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 04:27:34,982] [INFO] [controller] EPOCH 1 loss ppo:  -0.01060, loss val: 0.03886
[2022-12-07 04:27:35,051] [INFO] [controller] EPOCH 2 loss ppo:  -0.03584, loss val: 0.03671
[2022-12-07 04:27:35,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.04909, loss val: 0.03680
[2022-12-07 04:27:35,230] [INFO] [controller] EPOCH 4 loss ppo:  -0.05866, loss val: 0.03516
[2022-12-07 04:27:35,240] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:27:35,426] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:27:35,426] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:27:41,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:27:46,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:27:52,630] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:27:58,073] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:28:03,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:28:09,535] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:28:15,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:28:21,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:28:27,043] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:28:32,657] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9974084245991859
[2022-12-07 04:28:32,657] [INFO] [runner_train_mujoco] Average state value: 0.4833358604883154
[2022-12-07 04:28:32,657] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 04:28:32,710] [INFO] [controller] EPOCH 1 loss ppo:  -0.01191, loss val: 0.03239
[2022-12-07 04:28:32,751] [INFO] [controller] EPOCH 2 loss ppo:  -0.03300, loss val: 0.03522
[2022-12-07 04:28:32,793] [INFO] [controller] EPOCH 3 loss ppo:  -0.04404, loss val: 0.03361
[2022-12-07 04:28:32,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.05192, loss val: 0.03308
[2022-12-07 04:28:32,851] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:28:33,028] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:28:33,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:28:38,750] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:28:44,370] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:28:49,784] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:28:55,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:29:01,163] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:29:07,164] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:29:12,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:29:18,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:29:23,742] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:29:29,152] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.338361884397125
[2022-12-07 04:29:29,152] [INFO] [runner_train_mujoco] Average state value: 0.4752172505656878
[2022-12-07 04:29:29,152] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 04:29:29,204] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.03449
[2022-12-07 04:29:29,246] [INFO] [controller] EPOCH 2 loss ppo:  -0.03553, loss val: 0.03231
[2022-12-07 04:29:29,295] [INFO] [controller] EPOCH 3 loss ppo:  -0.04729, loss val: 0.03336
[2022-12-07 04:29:29,338] [INFO] [controller] EPOCH 4 loss ppo:  -0.06013, loss val: 0.03510
[2022-12-07 04:29:29,350] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:29:29,527] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:29:29,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:29:35,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:29:40,999] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:29:47,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:29:52,868] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:29:58,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:30:03,478] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:30:08,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:30:14,180] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:30:19,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:30:24,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.078095593738325
[2022-12-07 04:30:24,634] [INFO] [runner_train_mujoco] Average state value: 0.4024633294281861
[2022-12-07 04:30:24,634] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 04:30:24,691] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.10417
[2022-12-07 04:30:24,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.03616, loss val: 0.10239
[2022-12-07 04:30:24,776] [INFO] [controller] EPOCH 3 loss ppo:  -0.04856, loss val: 0.09931
[2022-12-07 04:30:24,816] [INFO] [controller] EPOCH 4 loss ppo:  -0.05744, loss val: 0.09834
[2022-12-07 04:30:24,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:30:24,999] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:30:24,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:30:29,950] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:30:35,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:30:40,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:30:44,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:30:50,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:30:54,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:31:00,380] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:31:05,538] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:31:10,545] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:31:15,649] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2704196768588782
[2022-12-07 04:31:15,650] [INFO] [runner_train_mujoco] Average state value: 0.48087402574221294
[2022-12-07 04:31:15,650] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 04:31:15,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.04644
[2022-12-07 04:31:15,741] [INFO] [controller] EPOCH 2 loss ppo:  -0.03540, loss val: 0.04498
[2022-12-07 04:31:15,782] [INFO] [controller] EPOCH 3 loss ppo:  -0.04721, loss val: 0.04626
[2022-12-07 04:31:15,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.05953, loss val: 0.04369
[2022-12-07 04:31:15,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:31:15,995] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:31:15,995] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:31:21,023] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:31:26,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:31:31,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:31:36,968] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:31:42,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:31:46,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:31:52,084] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:31:57,003] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:32:02,434] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:32:07,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2371497164107095
[2022-12-07 04:32:07,428] [INFO] [runner_train_mujoco] Average state value: 0.5410398298588891
[2022-12-07 04:32:07,428] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 04:32:07,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04161
[2022-12-07 04:32:07,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.03790, loss val: 0.04287
[2022-12-07 04:32:07,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.04937, loss val: 0.04242
[2022-12-07 04:32:07,605] [INFO] [controller] EPOCH 4 loss ppo:  -0.05640, loss val: 0.04028
[2022-12-07 04:32:07,615] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:32:07,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:32:07,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:32:13,447] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:32:18,579] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:32:23,853] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:32:28,671] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:32:33,643] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:32:38,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:32:44,045] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:32:49,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:32:54,445] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:32:59,433] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2940179815761188
[2022-12-07 04:32:59,433] [INFO] [runner_train_mujoco] Average state value: 0.5268988194825749
[2022-12-07 04:32:59,433] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 04:32:59,502] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.04400
[2022-12-07 04:32:59,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.03607, loss val: 0.04476
[2022-12-07 04:32:59,601] [INFO] [controller] EPOCH 3 loss ppo:  -0.04545, loss val: 0.04426
[2022-12-07 04:32:59,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.05731, loss val: 0.04463
[2022-12-07 04:32:59,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:32:59,865] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:32:59,866] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:33:05,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:33:10,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:33:15,937] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:33:21,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:33:26,237] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:33:31,204] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:33:36,278] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:33:41,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:33:46,085] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:33:51,152] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.172818496135935
[2022-12-07 04:33:51,152] [INFO] [runner_train_mujoco] Average state value: 0.5387220895886422
[2022-12-07 04:33:51,152] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 04:33:51,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04216
[2022-12-07 04:33:51,243] [INFO] [controller] EPOCH 2 loss ppo:  -0.03445, loss val: 0.04350
[2022-12-07 04:33:51,283] [INFO] [controller] EPOCH 3 loss ppo:  -0.04690, loss val: 0.04172
[2022-12-07 04:33:51,317] [INFO] [controller] EPOCH 4 loss ppo:  -0.05636, loss val: 0.03854
[2022-12-07 04:33:51,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:33:51,485] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:33:51,486] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:33:56,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:34:01,210] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:34:06,600] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:34:11,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:34:17,037] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:34:22,437] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:34:27,629] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:34:32,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:34:37,569] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:34:42,611] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3110170767545193
[2022-12-07 04:34:42,611] [INFO] [runner_train_mujoco] Average state value: 0.4939025937517484
[2022-12-07 04:34:42,611] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 04:34:42,658] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.03562
[2022-12-07 04:34:42,697] [INFO] [controller] EPOCH 2 loss ppo:  -0.03305, loss val: 0.03661
[2022-12-07 04:34:42,740] [INFO] [controller] EPOCH 3 loss ppo:  -0.04612, loss val: 0.03461
[2022-12-07 04:34:42,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.05591, loss val: 0.03819
[2022-12-07 04:34:42,793] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:34:42,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:34:42,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:34:48,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:34:53,352] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:34:58,053] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:35:03,194] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:35:08,239] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:35:13,044] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:35:18,280] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:35:23,402] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:35:28,835] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:35:34,083] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3324105454547195
[2022-12-07 04:35:34,083] [INFO] [runner_train_mujoco] Average state value: 0.4612887550294399
[2022-12-07 04:35:34,083] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 04:35:34,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01277, loss val: 0.04076
[2022-12-07 04:35:34,174] [INFO] [controller] EPOCH 2 loss ppo:  -0.03071, loss val: 0.03820
[2022-12-07 04:35:34,216] [INFO] [controller] EPOCH 3 loss ppo:  -0.04405, loss val: 0.04039
[2022-12-07 04:35:34,259] [INFO] [controller] EPOCH 4 loss ppo:  -0.05595, loss val: 0.03888
[2022-12-07 04:35:34,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:35:34,443] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:35:34,443] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:35:39,285] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:35:44,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:35:49,587] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:35:54,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:35:59,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:36:04,833] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:36:10,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:36:14,897] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:36:20,180] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:36:25,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.373889132939388
[2022-12-07 04:36:25,111] [INFO] [runner_train_mujoco] Average state value: 0.48285614221294715
[2022-12-07 04:36:25,111] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 04:36:25,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.03165
[2022-12-07 04:36:25,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.03020, loss val: 0.03202
[2022-12-07 04:36:25,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.04367, loss val: 0.03176
[2022-12-07 04:36:25,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.05679, loss val: 0.03093
[2022-12-07 04:36:25,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:36:25,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:36:25,493] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:36:31,005] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:36:36,421] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:36:41,827] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:36:46,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:36:51,798] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:36:56,646] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:37:01,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:37:06,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:37:11,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:37:17,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3679986876306476
[2022-12-07 04:37:17,099] [INFO] [runner_train_mujoco] Average state value: 0.5158565856218338
[2022-12-07 04:37:17,099] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 04:37:17,148] [INFO] [controller] EPOCH 1 loss ppo:  -0.01211, loss val: 0.03317
[2022-12-07 04:37:17,190] [INFO] [controller] EPOCH 2 loss ppo:  -0.02848, loss val: 0.03299
[2022-12-07 04:37:17,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.04012, loss val: 0.03449
[2022-12-07 04:37:17,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.05526, loss val: 0.03552
[2022-12-07 04:37:17,285] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:37:17,469] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:37:17,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:37:22,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:37:27,375] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:37:32,771] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:37:37,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:37:43,068] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:37:47,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:37:52,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:37:57,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:38:02,729] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:38:07,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6458090273387949
[2022-12-07 04:38:07,696] [INFO] [runner_train_mujoco] Average state value: 0.5321366885701815
[2022-12-07 04:38:07,696] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 04:38:07,755] [INFO] [controller] EPOCH 1 loss ppo:  -0.01496, loss val: 0.03793
[2022-12-07 04:38:07,803] [INFO] [controller] EPOCH 2 loss ppo:  -0.03514, loss val: 0.03778
[2022-12-07 04:38:07,853] [INFO] [controller] EPOCH 3 loss ppo:  -0.04762, loss val: 0.03483
[2022-12-07 04:38:07,900] [INFO] [controller] EPOCH 4 loss ppo:  -0.05929, loss val: 0.03497
[2022-12-07 04:38:07,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:38:08,096] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:38:08,097] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:38:13,320] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:38:18,734] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:38:23,663] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:38:28,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:38:33,984] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:38:38,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:38:43,594] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:38:48,535] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:38:53,644] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:38:58,583] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8303895028824304
[2022-12-07 04:38:58,583] [INFO] [runner_train_mujoco] Average state value: 0.4956214498281478
[2022-12-07 04:38:58,583] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 04:38:58,631] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.04283
[2022-12-07 04:38:58,674] [INFO] [controller] EPOCH 2 loss ppo:  -0.03023, loss val: 0.04104
[2022-12-07 04:38:58,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.04329, loss val: 0.03970
[2022-12-07 04:38:58,828] [INFO] [controller] EPOCH 4 loss ppo:  -0.05462, loss val: 0.03922
[2022-12-07 04:38:58,838] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:38:58,980] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:38:58,981] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:39:04,066] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:39:09,361] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:39:13,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:39:18,856] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:39:23,776] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:39:28,860] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:39:33,818] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:39:39,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:39:44,144] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:39:48,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8592748388700702
[2022-12-07 04:39:48,991] [INFO] [runner_train_mujoco] Average state value: 0.43177751833200456
[2022-12-07 04:39:48,991] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 04:39:49,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04895
[2022-12-07 04:39:49,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.03270, loss val: 0.04629
[2022-12-07 04:39:49,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.04648, loss val: 0.04597
[2022-12-07 04:39:49,152] [INFO] [controller] EPOCH 4 loss ppo:  -0.05603, loss val: 0.04503
[2022-12-07 04:39:49,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:39:49,314] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:39:49,315] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:39:54,078] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:39:59,592] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:40:04,837] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:40:10,163] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:40:15,518] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:40:20,509] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:40:25,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:40:30,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:40:35,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:40:40,907] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8413497401378454
[2022-12-07 04:40:40,907] [INFO] [runner_train_mujoco] Average state value: 0.4430748025377592
[2022-12-07 04:40:40,907] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 04:40:40,963] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.04290
[2022-12-07 04:40:41,003] [INFO] [controller] EPOCH 2 loss ppo:  -0.03610, loss val: 0.03968
[2022-12-07 04:40:41,046] [INFO] [controller] EPOCH 3 loss ppo:  -0.05141, loss val: 0.04321
[2022-12-07 04:40:41,101] [INFO] [controller] EPOCH 4 loss ppo:  -0.06231, loss val: 0.04013
[2022-12-07 04:40:41,111] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:40:41,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:40:41,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:40:46,287] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:40:51,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:40:56,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:41:01,662] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:41:06,662] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:41:11,927] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:41:17,172] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:41:22,308] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:41:27,152] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:41:32,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0052301536642037
[2022-12-07 04:41:32,014] [INFO] [runner_train_mujoco] Average state value: 0.4799045480688413
[2022-12-07 04:41:32,014] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 04:41:32,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.04216
[2022-12-07 04:41:32,101] [INFO] [controller] EPOCH 2 loss ppo:  -0.03421, loss val: 0.04213
[2022-12-07 04:41:32,151] [INFO] [controller] EPOCH 3 loss ppo:  -0.04575, loss val: 0.04202
[2022-12-07 04:41:32,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.05376, loss val: 0.04303
[2022-12-07 04:41:32,211] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:41:32,379] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:41:32,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:41:37,571] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:41:42,489] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:41:47,952] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:41:52,925] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:41:58,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:42:03,001] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:42:08,100] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:42:13,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:42:17,825] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:42:23,062] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2627891378085536
[2022-12-07 04:42:23,062] [INFO] [runner_train_mujoco] Average state value: 0.49624738262097035
[2022-12-07 04:42:23,062] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 04:42:23,108] [INFO] [controller] EPOCH 1 loss ppo:  -0.01129, loss val: 0.03282
[2022-12-07 04:42:23,152] [INFO] [controller] EPOCH 2 loss ppo:  -0.02791, loss val: 0.03389
[2022-12-07 04:42:23,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.04491, loss val: 0.03370
[2022-12-07 04:42:23,237] [INFO] [controller] EPOCH 4 loss ppo:  -0.05888, loss val: 0.03249
[2022-12-07 04:42:23,246] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:42:23,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:42:23,397] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:42:28,636] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:42:33,880] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:42:38,914] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:42:44,065] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:42:48,813] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:42:53,491] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:42:58,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:43:03,087] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:43:08,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:43:15,583] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4697567105200466
[2022-12-07 04:43:15,583] [INFO] [runner_train_mujoco] Average state value: 0.502155936807394
[2022-12-07 04:43:15,583] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 04:43:15,643] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.03507
[2022-12-07 04:43:15,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.03405, loss val: 0.03744
[2022-12-07 04:43:15,738] [INFO] [controller] EPOCH 3 loss ppo:  -0.04624, loss val: 0.04286
[2022-12-07 04:43:15,787] [INFO] [controller] EPOCH 4 loss ppo:  -0.05660, loss val: 0.03553
[2022-12-07 04:43:15,796] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:43:15,983] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:43:15,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:43:22,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:43:29,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:43:34,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:43:41,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:43:47,365] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:43:52,945] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:43:58,589] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:44:04,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:44:10,131] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:44:16,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4231156813036625
[2022-12-07 04:44:16,017] [INFO] [runner_train_mujoco] Average state value: 0.5033734721839428
[2022-12-07 04:44:16,018] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 04:44:16,067] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04580
[2022-12-07 04:44:16,109] [INFO] [controller] EPOCH 2 loss ppo:  -0.02757, loss val: 0.04508
[2022-12-07 04:44:16,154] [INFO] [controller] EPOCH 3 loss ppo:  -0.04347, loss val: 0.04435
[2022-12-07 04:44:16,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.05370, loss val: 0.04161
[2022-12-07 04:44:16,205] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:44:16,380] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:44:16,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:44:21,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:44:27,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:44:33,290] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:44:38,597] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:44:44,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:44:49,919] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:44:55,556] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:45:03,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:45:09,878] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:45:16,289] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.578265640059193
[2022-12-07 04:45:16,290] [INFO] [runner_train_mujoco] Average state value: 0.4733163995047411
[2022-12-07 04:45:16,290] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 04:45:16,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01546, loss val: 0.04416
[2022-12-07 04:45:16,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.03077, loss val: 0.04483
[2022-12-07 04:45:16,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.04334, loss val: 0.04502
[2022-12-07 04:45:16,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.05648, loss val: 0.04528
[2022-12-07 04:45:16,497] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:45:16,690] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:45:16,690] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:45:23,799] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:45:30,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:45:38,158] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:45:45,323] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:45:52,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:45:58,983] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:46:06,069] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:46:13,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:46:20,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:46:27,556] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6092197580289094
[2022-12-07 04:46:27,557] [INFO] [runner_train_mujoco] Average state value: 0.45620002146561933
[2022-12-07 04:46:27,557] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 04:46:27,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.03884
[2022-12-07 04:46:27,764] [INFO] [controller] EPOCH 2 loss ppo:  -0.02860, loss val: 0.03779
[2022-12-07 04:46:27,818] [INFO] [controller] EPOCH 3 loss ppo:  -0.03962, loss val: 0.03724
[2022-12-07 04:46:27,877] [INFO] [controller] EPOCH 4 loss ppo:  -0.05085, loss val: 0.03565
[2022-12-07 04:46:27,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:46:28,101] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:46:28,102] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:46:34,875] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:46:42,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:46:49,434] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:46:56,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:47:03,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:47:10,725] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:47:17,472] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:47:25,069] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:47:32,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:47:39,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.860970392563565
[2022-12-07 04:47:39,089] [INFO] [runner_train_mujoco] Average state value: 0.4837605835398038
[2022-12-07 04:47:39,089] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 04:47:39,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.03923
[2022-12-07 04:47:39,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.03199, loss val: 0.03914
[2022-12-07 04:47:39,280] [INFO] [controller] EPOCH 3 loss ppo:  -0.04371, loss val: 0.03798
[2022-12-07 04:47:39,334] [INFO] [controller] EPOCH 4 loss ppo:  -0.05422, loss val: 0.04091
[2022-12-07 04:47:39,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:47:39,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:47:39,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:47:46,048] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:47:52,490] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:47:58,995] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:48:05,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:48:11,744] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:48:17,945] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:48:24,418] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:48:31,048] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:48:37,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:48:44,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8296659547941667
[2022-12-07 04:48:44,055] [INFO] [runner_train_mujoco] Average state value: 0.5151302475954095
[2022-12-07 04:48:44,055] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 04:48:44,131] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.03876
[2022-12-07 04:48:44,186] [INFO] [controller] EPOCH 2 loss ppo:  -0.02633, loss val: 0.03784
[2022-12-07 04:48:44,239] [INFO] [controller] EPOCH 3 loss ppo:  -0.04070, loss val: 0.03809
[2022-12-07 04:48:44,291] [INFO] [controller] EPOCH 4 loss ppo:  -0.05388, loss val: 0.03828
[2022-12-07 04:48:44,301] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:48:44,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:48:44,488] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:48:50,519] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:48:56,652] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:49:03,461] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:49:09,883] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:49:16,229] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:49:22,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:49:28,703] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:49:34,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:49:41,109] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:49:47,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.855835734162836
[2022-12-07 04:49:47,483] [INFO] [runner_train_mujoco] Average state value: 0.5373816384474437
[2022-12-07 04:49:47,484] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 04:49:47,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04923
[2022-12-07 04:49:47,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.02754, loss val: 0.04599
[2022-12-07 04:49:47,676] [INFO] [controller] EPOCH 3 loss ppo:  -0.03694, loss val: 0.04656
[2022-12-07 04:49:47,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.04767, loss val: 0.04487
[2022-12-07 04:49:47,763] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:49:47,951] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:49:47,951] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:49:54,285] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:50:00,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:50:07,332] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:50:13,560] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:50:20,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:50:26,799] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:33,151] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:50:39,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:50:45,595] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:50:52,009] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9187270567815027
[2022-12-07 04:50:52,010] [INFO] [runner_train_mujoco] Average state value: 0.5190030815203984
[2022-12-07 04:50:52,010] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 04:50:52,069] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04234
[2022-12-07 04:50:52,117] [INFO] [controller] EPOCH 2 loss ppo:  -0.02473, loss val: 0.04051
[2022-12-07 04:50:52,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.03271, loss val: 0.03900
[2022-12-07 04:50:52,217] [INFO] [controller] EPOCH 4 loss ppo:  -0.04388, loss val: 0.03746
[2022-12-07 04:50:52,227] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:50:52,410] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:50:52,410] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:50:58,860] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:51:05,550] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:51:12,022] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:51:18,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:51:24,914] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:51:31,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:51:36,927] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:51:43,318] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:51:49,932] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:51:56,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.175516263829101
[2022-12-07 04:51:56,264] [INFO] [runner_train_mujoco] Average state value: 0.4463232278476159
[2022-12-07 04:51:56,265] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 04:51:56,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04592
[2022-12-07 04:51:56,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.02657, loss val: 0.04826
[2022-12-07 04:51:56,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.03933, loss val: 0.04481
[2022-12-07 04:51:56,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.04895, loss val: 0.04558
[2022-12-07 04:51:56,491] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:51:56,680] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:51:56,682] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:52:03,014] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:52:09,342] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:52:16,049] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:52:22,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:52:28,378] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:52:34,767] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:52:40,931] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:52:47,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:52:53,210] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:52:59,437] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.032377728860073
[2022-12-07 04:52:59,437] [INFO] [runner_train_mujoco] Average state value: 0.4378992175757885
[2022-12-07 04:52:59,437] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 04:52:59,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04116
[2022-12-07 04:52:59,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.01984, loss val: 0.04014
[2022-12-07 04:52:59,627] [INFO] [controller] EPOCH 3 loss ppo:  -0.03165, loss val: 0.03921
[2022-12-07 04:52:59,677] [INFO] [controller] EPOCH 4 loss ppo:  -0.04116, loss val: 0.03766
[2022-12-07 04:52:59,686] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:52:59,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:52:59,875] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:06,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:53:14,272] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:53:20,665] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:53:26,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:53:32,959] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:53:38,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:53:45,428] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:53:51,619] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:53:57,899] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:54:04,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1078762747761504
[2022-12-07 04:54:04,165] [INFO] [runner_train_mujoco] Average state value: 0.4494555931836367
[2022-12-07 04:54:04,166] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 04:54:04,234] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.05605
[2022-12-07 04:54:04,286] [INFO] [controller] EPOCH 2 loss ppo:  -0.02990, loss val: 0.05634
[2022-12-07 04:54:04,336] [INFO] [controller] EPOCH 3 loss ppo:  -0.03711, loss val: 0.05691
[2022-12-07 04:54:04,387] [INFO] [controller] EPOCH 4 loss ppo:  -0.04478, loss val: 0.05680
[2022-12-07 04:54:04,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:54:04,601] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:54:04,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:54:10,769] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:54:17,129] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:54:23,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:54:29,473] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:54:35,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:54:41,812] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:54:48,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:54:54,749] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:55:01,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:55:07,600] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.201600189515556
[2022-12-07 04:55:07,600] [INFO] [runner_train_mujoco] Average state value: 0.490702513585488
[2022-12-07 04:55:07,600] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 04:55:07,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.03435
[2022-12-07 04:55:07,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.02677, loss val: 0.03138
[2022-12-07 04:55:07,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.04057, loss val: 0.03133
[2022-12-07 04:55:07,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.05184, loss val: 0.03116
[2022-12-07 04:55:07,832] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:55:08,019] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:55:08,020] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:55:14,003] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:55:20,383] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:55:26,648] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:55:33,025] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:55:38,915] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:55:45,546] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:55:51,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:55:57,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:56:04,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:56:10,022] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.90993959310552
[2022-12-07 04:56:10,023] [INFO] [runner_train_mujoco] Average state value: 0.4906505513290565
[2022-12-07 04:56:10,023] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 04:56:10,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.02169
[2022-12-07 04:56:10,146] [INFO] [controller] EPOCH 2 loss ppo:  -0.02479, loss val: 0.02518
[2022-12-07 04:56:10,193] [INFO] [controller] EPOCH 3 loss ppo:  -0.03072, loss val: 0.02223
[2022-12-07 04:56:10,246] [INFO] [controller] EPOCH 4 loss ppo:  -0.03897, loss val: 0.02227
[2022-12-07 04:56:10,256] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:56:10,453] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:56:10,453] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:56:16,826] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:56:23,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:56:29,682] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:56:35,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:56:42,265] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:56:48,616] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:56:55,031] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:57:00,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:57:07,229] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:57:12,990] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.947670552711576
[2022-12-07 04:57:12,990] [INFO] [runner_train_mujoco] Average state value: 0.44882053415228923
[2022-12-07 04:57:12,990] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 04:57:13,044] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.05474
[2022-12-07 04:57:13,088] [INFO] [controller] EPOCH 2 loss ppo:  -0.02440, loss val: 0.05720
[2022-12-07 04:57:13,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.03558, loss val: 0.05405
[2022-12-07 04:57:13,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.04556, loss val: 0.05674
[2022-12-07 04:57:13,218] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:57:13,402] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:57:13,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:57:19,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:57:25,839] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:57:31,942] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:57:38,158] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:57:44,667] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:57:51,592] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:57:58,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:58:05,122] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:58:11,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:58:17,814] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.432619202503036
[2022-12-07 04:58:17,815] [INFO] [runner_train_mujoco] Average state value: 0.4731443011959394
[2022-12-07 04:58:17,815] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 04:58:17,873] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.05345
[2022-12-07 04:58:17,930] [INFO] [controller] EPOCH 2 loss ppo:  -0.02742, loss val: 0.05330
[2022-12-07 04:58:17,989] [INFO] [controller] EPOCH 3 loss ppo:  -0.03705, loss val: 0.05364
[2022-12-07 04:58:18,044] [INFO] [controller] EPOCH 4 loss ppo:  -0.04707, loss val: 0.05254
[2022-12-07 04:58:18,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:58:18,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:58:18,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:58:24,509] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:58:30,766] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:58:36,861] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:58:43,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:58:49,329] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:58:55,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:59:01,575] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:59:07,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:59:13,678] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:59:19,793] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1853248492070323
[2022-12-07 04:59:19,793] [INFO] [runner_train_mujoco] Average state value: 0.4982738067110379
[2022-12-07 04:59:19,793] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 04:59:19,858] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.04494
[2022-12-07 04:59:19,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.02166, loss val: 0.04459
[2022-12-07 04:59:19,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.03163, loss val: 0.04823
[2022-12-07 04:59:20,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.04126, loss val: 0.04387
[2022-12-07 04:59:20,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:59:20,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:59:20,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:59:26,597] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:59:32,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:59:39,155] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:59:45,318] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:59:51,352] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:59:57,475] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:00:03,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:00:09,797] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:00:15,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:00:21,998] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0745697032848573
[2022-12-07 05:00:21,999] [INFO] [runner_train_mujoco] Average state value: 0.4877108505566915
[2022-12-07 05:00:21,999] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 05:00:22,052] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.03716
[2022-12-07 05:00:22,107] [INFO] [controller] EPOCH 2 loss ppo:  -0.02354, loss val: 0.03627
[2022-12-07 05:00:22,214] [INFO] [controller] EPOCH 3 loss ppo:  -0.03023, loss val: 0.03606
[2022-12-07 05:00:22,259] [INFO] [controller] EPOCH 4 loss ppo:  -0.03774, loss val: 0.03615
[2022-12-07 05:00:22,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:00:22,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:00:22,465] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:00:28,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:00:35,102] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:00:41,199] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:00:47,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:00:53,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:00:59,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:01:05,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:01:12,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:01:18,379] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:01:24,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.378281781370962
[2022-12-07 05:01:24,530] [INFO] [runner_train_mujoco] Average state value: 0.4468378898911178
[2022-12-07 05:01:24,530] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 05:01:24,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.04227
[2022-12-07 05:01:24,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.02612, loss val: 0.03967
[2022-12-07 05:01:24,692] [INFO] [controller] EPOCH 3 loss ppo:  -0.03469, loss val: 0.04257
[2022-12-07 05:01:24,739] [INFO] [controller] EPOCH 4 loss ppo:  -0.04303, loss val: 0.03987
[2022-12-07 05:01:24,749] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:01:24,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:01:24,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:01:31,024] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:01:37,650] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:01:43,912] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:01:49,882] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:01:55,664] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:02:01,469] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:02:07,700] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:02:13,921] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:02:20,271] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:02:26,623] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.433376708731766
[2022-12-07 05:02:26,624] [INFO] [runner_train_mujoco] Average state value: 0.4520435538788636
[2022-12-07 05:02:26,624] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 05:02:26,689] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.04806
[2022-12-07 05:02:26,743] [INFO] [controller] EPOCH 2 loss ppo:  -0.02088, loss val: 0.04711
[2022-12-07 05:02:26,794] [INFO] [controller] EPOCH 3 loss ppo:  -0.02695, loss val: 0.04671
[2022-12-07 05:02:26,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.03468, loss val: 0.04524
[2022-12-07 05:02:26,872] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:02:27,063] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:02:27,064] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:02:33,350] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:02:39,551] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:02:45,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:02:52,051] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:02:57,875] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:03:03,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:03:09,704] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:03:15,982] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:03:22,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:03:28,287] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5230527912658034
[2022-12-07 05:03:28,288] [INFO] [runner_train_mujoco] Average state value: 0.4653027553980548
[2022-12-07 05:03:28,288] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 05:03:28,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.03930
[2022-12-07 05:03:28,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.02049, loss val: 0.03933
[2022-12-07 05:03:28,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.02683, loss val: 0.03901
[2022-12-07 05:03:28,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.03466, loss val: 0.03890
[2022-12-07 05:03:28,513] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:03:28,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:03:28,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:03:34,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:03:40,703] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:03:47,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:03:52,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:03:59,328] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:04:05,762] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:04:11,623] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:04:18,322] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:04:24,508] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:04:30,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7906980119647935
[2022-12-07 05:04:30,485] [INFO] [runner_train_mujoco] Average state value: 0.4918392503311237
[2022-12-07 05:04:30,485] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 05:04:30,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01259, loss val: 0.03710
[2022-12-07 05:04:30,609] [INFO] [controller] EPOCH 2 loss ppo:  -0.01793, loss val: 0.04061
[2022-12-07 05:04:30,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.02763, loss val: 0.03715
[2022-12-07 05:04:30,712] [INFO] [controller] EPOCH 4 loss ppo:  -0.03692, loss val: 0.03993
[2022-12-07 05:04:30,723] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:30,919] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:30,919] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:04:36,954] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:04:43,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:04:48,805] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:04:54,989] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:05:00,881] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:05:07,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:05:13,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:05:19,643] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:05:25,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:05:32,124] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6030353016121337
[2022-12-07 05:05:32,124] [INFO] [runner_train_mujoco] Average state value: 0.4813949746663372
[2022-12-07 05:05:32,124] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 05:05:32,192] [INFO] [controller] EPOCH 1 loss ppo:  -0.01319, loss val: 0.04540
[2022-12-07 05:05:32,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.02091, loss val: 0.04511
[2022-12-07 05:05:32,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.04710
[2022-12-07 05:05:32,373] [INFO] [controller] EPOCH 4 loss ppo:  -0.03373, loss val: 0.04726
[2022-12-07 05:05:32,383] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:05:32,571] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:05:32,572] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:05:38,927] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:05:45,325] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:05:51,582] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:05:57,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:06:03,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:06:09,453] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:06:15,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:06:21,226] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:06:27,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:06:33,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7955827247283644
[2022-12-07 05:06:33,486] [INFO] [runner_train_mujoco] Average state value: 0.5079174034992853
[2022-12-07 05:06:33,486] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 05:06:33,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.03848
[2022-12-07 05:06:33,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.01867, loss val: 0.03776
[2022-12-07 05:06:33,672] [INFO] [controller] EPOCH 3 loss ppo:  -0.02739, loss val: 0.03858
[2022-12-07 05:06:33,727] [INFO] [controller] EPOCH 4 loss ppo:  -0.03426, loss val: 0.03568
[2022-12-07 05:06:33,738] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:06:33,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:06:33,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:06:40,291] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:06:46,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:06:52,766] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:06:58,498] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:07:05,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:07:12,447] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:07:18,905] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:07:25,816] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:07:31,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:07:38,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.004420895348723
[2022-12-07 05:07:38,446] [INFO] [runner_train_mujoco] Average state value: 0.49480825262516737
[2022-12-07 05:07:38,446] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 05:07:38,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04781
[2022-12-07 05:07:38,652] [INFO] [controller] EPOCH 2 loss ppo:  -0.01717, loss val: 0.04554
[2022-12-07 05:07:38,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.02376, loss val: 0.04588
[2022-12-07 05:07:38,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.02824, loss val: 0.04444
[2022-12-07 05:07:38,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:07:39,036] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:07:39,036] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:07:45,465] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:07:51,488] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:07:57,520] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:08:03,520] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:08:09,513] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:08:15,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:08:21,575] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:08:27,857] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:08:33,969] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:08:40,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.996834705273641
[2022-12-07 05:08:40,480] [INFO] [runner_train_mujoco] Average state value: 0.49650074579318354
[2022-12-07 05:08:40,480] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 05:08:40,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.04144
[2022-12-07 05:08:40,584] [INFO] [controller] EPOCH 2 loss ppo:  -0.01899, loss val: 0.04408
[2022-12-07 05:08:40,631] [INFO] [controller] EPOCH 3 loss ppo:  -0.02604, loss val: 0.04143
[2022-12-07 05:08:40,673] [INFO] [controller] EPOCH 4 loss ppo:  -0.03053, loss val: 0.04119
[2022-12-07 05:08:40,682] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:08:40,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:08:40,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:08:47,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:08:53,494] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:08:59,514] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:09:05,651] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:09:11,763] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:09:17,805] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:09:23,548] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:09:29,524] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:09:35,616] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:09:42,064] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7423796005151835
[2022-12-07 05:09:42,064] [INFO] [runner_train_mujoco] Average state value: 0.48170136633267
[2022-12-07 05:09:42,064] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 05:09:42,128] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04159
[2022-12-07 05:09:42,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.01643, loss val: 0.04150
[2022-12-07 05:09:42,253] [INFO] [controller] EPOCH 3 loss ppo:  -0.02336, loss val: 0.04149
[2022-12-07 05:09:42,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.02933, loss val: 0.04174
[2022-12-07 05:09:42,315] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:09:42,508] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:09:42,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:09:48,498] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:09:54,717] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:10:00,715] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:10:07,065] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:10:13,346] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:10:19,623] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:10:25,465] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:10:31,838] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:10:37,892] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:10:43,957] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.009522914743733
[2022-12-07 05:10:43,957] [INFO] [runner_train_mujoco] Average state value: 0.4657685415049394
[2022-12-07 05:10:43,957] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 05:10:44,038] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.04200
[2022-12-07 05:10:44,093] [INFO] [controller] EPOCH 2 loss ppo:  -0.01616, loss val: 0.04179
[2022-12-07 05:10:44,153] [INFO] [controller] EPOCH 3 loss ppo:  -0.02053, loss val: 0.04180
[2022-12-07 05:10:44,225] [INFO] [controller] EPOCH 4 loss ppo:  -0.02473, loss val: 0.04178
[2022-12-07 05:10:44,235] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:10:44,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:10:44,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:10:50,573] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:10:56,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:11:02,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:11:08,590] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:11:14,249] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:11:20,337] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:11:26,221] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:11:31,947] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:11:38,405] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:11:44,768] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.287101683719004
[2022-12-07 05:11:44,768] [INFO] [runner_train_mujoco] Average state value: 0.48659778484702104
[2022-12-07 05:11:44,769] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 05:11:44,834] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04186
[2022-12-07 05:11:44,883] [INFO] [controller] EPOCH 2 loss ppo:  -0.01461, loss val: 0.04269
[2022-12-07 05:11:44,969] [INFO] [controller] EPOCH 3 loss ppo:  -0.01821, loss val: 0.04192
[2022-12-07 05:11:45,033] [INFO] [controller] EPOCH 4 loss ppo:  -0.02223, loss val: 0.04249
[2022-12-07 05:11:45,042] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:11:45,286] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:11:45,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:11:51,835] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:11:58,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:12:04,302] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:12:10,135] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:12:16,016] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:12:22,044] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:12:28,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:12:34,146] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:12:40,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:12:46,016] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9567494386749993
[2022-12-07 05:12:46,016] [INFO] [runner_train_mujoco] Average state value: 0.47432636082172397
[2022-12-07 05:12:46,016] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 05:12:46,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04376
[2022-12-07 05:12:46,140] [INFO] [controller] EPOCH 2 loss ppo:  -0.01365, loss val: 0.04383
[2022-12-07 05:12:46,202] [INFO] [controller] EPOCH 3 loss ppo:  -0.01516, loss val: 0.04366
[2022-12-07 05:12:46,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.01712, loss val: 0.04543
[2022-12-07 05:12:46,265] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:12:46,417] [INFO] [optimize] Finished learning.
