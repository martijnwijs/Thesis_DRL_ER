[2022-12-06 13:30:37,400] [INFO] [optimize] Starting learning
[2022-12-06 13:30:37,409] [INFO] [optimize] Starting learning process..
[2022-12-06 13:30:37,524] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:30:37,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:30:44,127] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:30:48,916] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:30:54,275] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:31:01,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:31:08,080] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:31:14,133] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:31:20,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:31:31,354] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:31:39,233] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:31:46,815] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0247036723008547
[2022-12-06 13:31:46,815] [INFO] [runner_train_mujoco] Average state value: -0.15859922278920807
[2022-12-06 13:31:46,816] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 13:31:46,913] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.59923
[2022-12-06 13:31:46,970] [INFO] [controller] EPOCH 2 loss ppo:  -0.04358, loss val: 0.54978
[2022-12-06 13:31:47,031] [INFO] [controller] EPOCH 3 loss ppo:  -0.05380, loss val: 0.49755
[2022-12-06 13:31:47,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.06275, loss val: 0.44413
[2022-12-06 13:31:47,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:31:47,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:31:47,333] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:31:55,716] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:32:05,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:32:13,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:32:20,698] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:32:28,373] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:32:36,115] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:32:43,321] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:32:50,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:32:58,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:33:06,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9818362578385204
[2022-12-06 13:33:06,052] [INFO] [runner_train_mujoco] Average state value: -0.006904720724870761
[2022-12-06 13:33:06,052] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 13:33:06,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.43820
[2022-12-06 13:33:06,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.03766, loss val: 0.39114
[2022-12-06 13:33:06,240] [INFO] [controller] EPOCH 3 loss ppo:  -0.04994, loss val: 0.34820
[2022-12-06 13:33:06,309] [INFO] [controller] EPOCH 4 loss ppo:  -0.05743, loss val: 0.29340
[2022-12-06 13:33:06,320] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:33:06,539] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:33:06,540] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:33:14,081] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:33:21,380] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:33:29,274] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:33:37,146] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:33:45,071] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:33:53,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:34:01,202] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:34:09,320] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:34:17,258] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:34:25,136] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.893505474900851
[2022-12-06 13:34:25,136] [INFO] [runner_train_mujoco] Average state value: 0.16640639389740924
[2022-12-06 13:34:25,136] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 13:34:25,225] [INFO] [controller] EPOCH 1 loss ppo:  -0.01609, loss val: 0.26716
[2022-12-06 13:34:25,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.04001, loss val: 0.22983
[2022-12-06 13:34:25,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.05200, loss val: 0.19416
[2022-12-06 13:34:25,473] [INFO] [controller] EPOCH 4 loss ppo:  -0.05944, loss val: 0.17835
[2022-12-06 13:34:25,485] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:34:25,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:34:25,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:34:33,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:34:41,972] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:34:50,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:34:58,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:35:07,349] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:35:15,552] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:35:24,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:35:33,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:35:41,698] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:35:50,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.976669528678513
[2022-12-06 13:35:50,255] [INFO] [runner_train_mujoco] Average state value: 0.3136854615261157
[2022-12-06 13:35:50,255] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 13:35:50,338] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.14414
[2022-12-06 13:35:50,399] [INFO] [controller] EPOCH 2 loss ppo:  -0.04294, loss val: 0.12887
[2022-12-06 13:35:50,478] [INFO] [controller] EPOCH 3 loss ppo:  -0.05377, loss val: 0.12433
[2022-12-06 13:35:50,536] [INFO] [controller] EPOCH 4 loss ppo:  -0.05974, loss val: 0.10463
[2022-12-06 13:35:50,548] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:35:50,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:35:50,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:35:59,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:36:07,969] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:36:16,847] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:36:25,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:36:34,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:36:42,868] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:36:51,678] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:37:00,627] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:37:09,972] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:37:18,449] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9844034260858582
[2022-12-06 13:37:18,450] [INFO] [runner_train_mujoco] Average state value: 0.4280451279605428
[2022-12-06 13:37:18,450] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 13:37:18,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.09941
[2022-12-06 13:37:18,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.03994, loss val: 0.08789
[2022-12-06 13:37:18,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.05337, loss val: 0.08525
[2022-12-06 13:37:18,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.06031, loss val: 0.07667
[2022-12-06 13:37:18,718] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:37:18,949] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:37:18,949] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:37:27,287] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:37:35,665] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:37:44,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:37:52,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:38:00,231] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:38:08,539] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:38:16,574] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:38:24,966] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:38:33,006] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:38:41,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7576848708271783
[2022-12-06 13:38:41,085] [INFO] [runner_train_mujoco] Average state value: 0.5171584995687007
[2022-12-06 13:38:41,085] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 13:38:41,183] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.07599
[2022-12-06 13:38:41,239] [INFO] [controller] EPOCH 2 loss ppo:  -0.03931, loss val: 0.06895
[2022-12-06 13:38:41,311] [INFO] [controller] EPOCH 3 loss ppo:  -0.04915, loss val: 0.06522
[2022-12-06 13:38:41,372] [INFO] [controller] EPOCH 4 loss ppo:  -0.05750, loss val: 0.06231
[2022-12-06 13:38:41,385] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:38:41,631] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:38:41,632] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:38:49,426] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:38:57,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:39:05,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:39:13,065] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:39:21,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:39:28,663] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:39:35,958] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:39:43,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:39:50,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:39:58,973] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9562531574851058
[2022-12-06 13:39:58,973] [INFO] [runner_train_mujoco] Average state value: 0.5246861807530124
[2022-12-06 13:39:58,974] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 13:39:59,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.06045
[2022-12-06 13:39:59,099] [INFO] [controller] EPOCH 2 loss ppo:  -0.03501, loss val: 0.05723
[2022-12-06 13:39:59,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.04493, loss val: 0.05523
[2022-12-06 13:39:59,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.05402, loss val: 0.05444
[2022-12-06 13:39:59,233] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:39:59,442] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:39:59,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:40:07,857] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:40:16,934] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:40:24,587] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:40:32,090] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:40:39,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:40:46,586] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:40:53,810] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:41:01,396] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:41:09,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:41:17,167] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9434700927661623
[2022-12-06 13:41:17,168] [INFO] [runner_train_mujoco] Average state value: 0.5479046069867908
[2022-12-06 13:41:17,168] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 13:41:17,236] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.05041
[2022-12-06 13:41:17,290] [INFO] [controller] EPOCH 2 loss ppo:  -0.03734, loss val: 0.04858
[2022-12-06 13:41:17,347] [INFO] [controller] EPOCH 3 loss ppo:  -0.05249, loss val: 0.04690
[2022-12-06 13:41:17,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.06275, loss val: 0.04619
[2022-12-06 13:41:17,415] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:41:17,637] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:41:17,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:41:25,788] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:41:33,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:41:41,567] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:41:49,353] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:41:57,084] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:42:04,808] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:42:12,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:42:21,034] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:42:29,420] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:42:37,228] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9372370576953692
[2022-12-06 13:42:37,229] [INFO] [runner_train_mujoco] Average state value: 0.545258592536052
[2022-12-06 13:42:37,229] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 13:42:37,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.05065
[2022-12-06 13:42:37,367] [INFO] [controller] EPOCH 2 loss ppo:  -0.03697, loss val: 0.04715
[2022-12-06 13:42:37,431] [INFO] [controller] EPOCH 3 loss ppo:  -0.05146, loss val: 0.04641
[2022-12-06 13:42:37,489] [INFO] [controller] EPOCH 4 loss ppo:  -0.06235, loss val: 0.04571
[2022-12-06 13:42:37,500] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:42:37,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:42:37,726] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:42:45,859] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:42:54,303] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:43:02,569] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:43:10,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:43:18,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:43:27,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:43:35,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:43:43,171] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:43:51,419] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:43:59,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0504369652375791
[2022-12-06 13:43:59,913] [INFO] [runner_train_mujoco] Average state value: 0.5579269366363684
[2022-12-06 13:43:59,913] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 13:43:59,979] [INFO] [controller] EPOCH 1 loss ppo:  -0.01151, loss val: 0.04564
[2022-12-06 13:44:00,048] [INFO] [controller] EPOCH 2 loss ppo:  -0.03496, loss val: 0.04458
[2022-12-06 13:44:00,109] [INFO] [controller] EPOCH 3 loss ppo:  -0.04828, loss val: 0.04371
[2022-12-06 13:44:00,168] [INFO] [controller] EPOCH 4 loss ppo:  -0.05703, loss val: 0.04470
[2022-12-06 13:44:00,181] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:44:00,411] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:44:00,412] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:44:09,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:44:17,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:44:27,138] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:44:35,549] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:44:44,340] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:44:52,892] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:45:01,228] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:45:09,854] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:45:19,075] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:45:27,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.132798137792612
[2022-12-06 13:45:27,817] [INFO] [runner_train_mujoco] Average state value: 0.5554302167544762
[2022-12-06 13:45:27,817] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 13:45:27,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01039, loss val: 0.03973
[2022-12-06 13:45:27,941] [INFO] [controller] EPOCH 2 loss ppo:  -0.03113, loss val: 0.04184
[2022-12-06 13:45:28,000] [INFO] [controller] EPOCH 3 loss ppo:  -0.04668, loss val: 0.03727
[2022-12-06 13:45:28,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.05744, loss val: 0.04058
[2022-12-06 13:45:28,074] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:45:28,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:45:28,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:45:36,376] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:45:44,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:45:53,765] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:46:02,433] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:46:10,715] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:46:18,603] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:46:26,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:46:33,392] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:46:41,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:46:48,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2233222860996873
[2022-12-06 13:46:48,573] [INFO] [runner_train_mujoco] Average state value: 0.5525075983901818
[2022-12-06 13:46:48,573] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 13:46:48,660] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.04553
[2022-12-06 13:46:48,732] [INFO] [controller] EPOCH 2 loss ppo:  -0.03640, loss val: 0.04506
[2022-12-06 13:46:48,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.04946, loss val: 0.04479
[2022-12-06 13:46:48,989] [INFO] [controller] EPOCH 4 loss ppo:  -0.06234, loss val: 0.04327
[2022-12-06 13:46:49,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:46:49,236] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:46:49,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:46:57,175] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:47:05,109] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:47:13,379] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:47:21,387] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:47:29,018] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:47:36,458] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:47:43,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:47:51,436] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:47:58,812] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:48:06,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9916122459938961
[2022-12-06 13:48:06,254] [INFO] [runner_train_mujoco] Average state value: 0.5216380009551843
[2022-12-06 13:48:06,254] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 13:48:06,327] [INFO] [controller] EPOCH 1 loss ppo:  -0.01125, loss val: 0.03799
[2022-12-06 13:48:06,380] [INFO] [controller] EPOCH 2 loss ppo:  -0.03245, loss val: 0.03814
[2022-12-06 13:48:06,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.04415, loss val: 0.03819
[2022-12-06 13:48:06,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.05575, loss val: 0.03717
[2022-12-06 13:48:06,515] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:48:06,729] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:48:06,729] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:48:14,626] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:48:22,429] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:48:29,897] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:48:37,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:48:44,760] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:48:52,144] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:48:59,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:49:06,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:49:13,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:49:21,069] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9722913041587044
[2022-12-06 13:49:21,070] [INFO] [runner_train_mujoco] Average state value: 0.5288216408093771
[2022-12-06 13:49:21,070] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 13:49:21,177] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.03976
[2022-12-06 13:49:21,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.03692, loss val: 0.03991
[2022-12-06 13:49:21,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.05063, loss val: 0.04074
[2022-12-06 13:49:21,430] [INFO] [controller] EPOCH 4 loss ppo:  -0.05916, loss val: 0.04085
[2022-12-06 13:49:21,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:49:21,673] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:49:21,673] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:49:29,055] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:49:36,487] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:49:44,250] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:49:51,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:49:59,224] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:50:06,782] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:50:14,235] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:50:22,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:50:30,366] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:50:37,690] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1520993491487563
[2022-12-06 13:50:37,690] [INFO] [runner_train_mujoco] Average state value: 0.5455916699171066
[2022-12-06 13:50:37,690] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 13:50:37,755] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.04527
[2022-12-06 13:50:37,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.03502, loss val: 0.04332
[2022-12-06 13:50:37,864] [INFO] [controller] EPOCH 3 loss ppo:  -0.04679, loss val: 0.04275
[2022-12-06 13:50:37,924] [INFO] [controller] EPOCH 4 loss ppo:  -0.05508, loss val: 0.04031
[2022-12-06 13:50:37,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:50:38,155] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:50:38,155] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:50:45,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:50:53,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:51:01,075] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:51:08,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:51:17,356] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:51:25,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:51:32,722] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:51:40,880] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:51:48,742] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:51:56,792] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.313746657351468
[2022-12-06 13:51:56,793] [INFO] [runner_train_mujoco] Average state value: 0.5717494658430418
[2022-12-06 13:51:56,793] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 13:51:56,860] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.04139
[2022-12-06 13:51:56,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.03285, loss val: 0.04060
[2022-12-06 13:51:56,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.04794, loss val: 0.04119
[2022-12-06 13:51:57,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.05768, loss val: 0.03989
[2022-12-06 13:51:57,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:51:57,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:51:57,311] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:52:05,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:52:12,916] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:52:21,461] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:52:29,918] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:52:38,130] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:52:46,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:52:54,966] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:53:03,085] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:53:11,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:53:20,388] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9768616480118164
[2022-12-06 13:53:20,389] [INFO] [runner_train_mujoco] Average state value: 0.5866039768457413
[2022-12-06 13:53:20,389] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 13:53:20,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.00996, loss val: 0.03715
[2022-12-06 13:53:20,587] [INFO] [controller] EPOCH 2 loss ppo:  -0.03277, loss val: 0.03894
[2022-12-06 13:53:20,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.04666, loss val: 0.03618
[2022-12-06 13:53:20,703] [INFO] [controller] EPOCH 4 loss ppo:  -0.05588, loss val: 0.03480
[2022-12-06 13:53:20,716] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:53:20,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:53:20,952] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:53:29,983] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:53:38,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:53:46,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:53:54,912] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:54:03,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:54:11,592] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:54:20,064] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:54:27,947] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:54:35,702] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:54:43,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1521716234406187
[2022-12-06 13:54:43,660] [INFO] [runner_train_mujoco] Average state value: 0.5219157770574092
[2022-12-06 13:54:43,660] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 13:54:43,750] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.05871
[2022-12-06 13:54:43,805] [INFO] [controller] EPOCH 2 loss ppo:  -0.03651, loss val: 0.05968
[2022-12-06 13:54:43,860] [INFO] [controller] EPOCH 3 loss ppo:  -0.04879, loss val: 0.05847
[2022-12-06 13:54:43,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.05965, loss val: 0.05940
[2022-12-06 13:54:43,941] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:54:44,174] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:54:44,174] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:54:52,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:55:00,464] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:55:08,658] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:55:17,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:55:25,315] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:55:33,347] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:55:41,106] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:55:48,593] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:55:56,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:56:03,869] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.395724974031331
[2022-12-06 13:56:03,870] [INFO] [runner_train_mujoco] Average state value: 0.5440855716168881
[2022-12-06 13:56:03,870] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 13:56:03,963] [INFO] [controller] EPOCH 1 loss ppo:  -0.01143, loss val: 0.04306
[2022-12-06 13:56:04,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.03362, loss val: 0.04643
[2022-12-06 13:56:04,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.04792, loss val: 0.04417
[2022-12-06 13:56:04,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.05671, loss val: 0.04281
[2022-12-06 13:56:04,211] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:56:04,424] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:56:04,425] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:56:12,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:56:19,644] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:56:27,823] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:56:35,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:56:43,756] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:56:51,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:56:58,924] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:57:06,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:57:13,513] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:57:20,953] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.190462963166987
[2022-12-06 13:57:20,953] [INFO] [runner_train_mujoco] Average state value: 0.5528204334179561
[2022-12-06 13:57:20,953] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 13:57:21,011] [INFO] [controller] EPOCH 1 loss ppo:  -0.01252, loss val: 0.04652
[2022-12-06 13:57:21,069] [INFO] [controller] EPOCH 2 loss ppo:  -0.02909, loss val: 0.04285
[2022-12-06 13:57:21,124] [INFO] [controller] EPOCH 3 loss ppo:  -0.04286, loss val: 0.03957
[2022-12-06 13:57:21,185] [INFO] [controller] EPOCH 4 loss ppo:  -0.05511, loss val: 0.03727
[2022-12-06 13:57:21,196] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:57:21,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:57:21,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:57:28,736] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:57:36,403] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:57:44,320] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:57:52,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:58:00,175] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:58:11,106] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:58:21,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:58:31,197] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:58:39,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:58:50,445] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3573820157150147
[2022-12-06 13:58:50,446] [INFO] [runner_train_mujoco] Average state value: 0.47646779055396715
[2022-12-06 13:58:50,446] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 13:58:50,935] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.03713
[2022-12-06 13:58:51,055] [INFO] [controller] EPOCH 2 loss ppo:  -0.03987, loss val: 0.03730
[2022-12-06 13:58:51,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.05008, loss val: 0.03833
[2022-12-06 13:58:51,387] [INFO] [controller] EPOCH 4 loss ppo:  -0.05845, loss val: 0.03646
[2022-12-06 13:58:51,403] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:58:51,693] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:58:51,694] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:59:03,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:59:13,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:59:23,583] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:59:34,138] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:59:45,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:59:55,181] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:00:04,136] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:00:13,046] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:00:22,815] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:00:31,864] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.203299709324515
[2022-12-06 14:00:31,864] [INFO] [runner_train_mujoco] Average state value: 0.4418528651495774
[2022-12-06 14:00:31,864] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 14:00:31,962] [INFO] [controller] EPOCH 1 loss ppo:  -0.01166, loss val: 0.04521
[2022-12-06 14:00:32,029] [INFO] [controller] EPOCH 2 loss ppo:  -0.02740, loss val: 0.04143
[2022-12-06 14:00:32,105] [INFO] [controller] EPOCH 3 loss ppo:  -0.04346, loss val: 0.03994
[2022-12-06 14:00:32,226] [INFO] [controller] EPOCH 4 loss ppo:  -0.05459, loss val: 0.03807
[2022-12-06 14:00:32,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:00:32,476] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:00:32,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:00:42,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:00:56,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:01:09,002] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:01:21,519] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:01:33,573] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:01:48,521] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:02:00,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:02:09,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:02:18,472] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:02:27,743] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1638422376104653
[2022-12-06 14:02:27,744] [INFO] [runner_train_mujoco] Average state value: 0.4833266990383467
[2022-12-06 14:02:27,744] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 14:02:27,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.04026
[2022-12-06 14:02:27,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.03355, loss val: 0.04041
[2022-12-06 14:02:28,028] [INFO] [controller] EPOCH 3 loss ppo:  -0.04508, loss val: 0.03975
[2022-12-06 14:02:28,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.05634, loss val: 0.04105
[2022-12-06 14:02:28,134] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:02:28,396] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:02:28,396] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:02:38,481] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:02:47,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:02:56,713] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:03:05,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:03:16,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:03:26,531] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:03:35,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:03:44,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:03:52,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:04:01,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3136801817557022
[2022-12-06 14:04:01,340] [INFO] [runner_train_mujoco] Average state value: 0.5219815661857525
[2022-12-06 14:04:01,340] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 14:04:01,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01211, loss val: 0.03525
[2022-12-06 14:04:01,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.03581, loss val: 0.03475
[2022-12-06 14:04:01,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.04837, loss val: 0.03516
[2022-12-06 14:04:01,594] [INFO] [controller] EPOCH 4 loss ppo:  -0.05913, loss val: 0.03350
[2022-12-06 14:04:01,606] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:04:01,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:04:01,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:04:09,907] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:04:18,195] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:04:27,065] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:04:35,249] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:04:43,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:04:51,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:04:59,129] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:05:07,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:05:15,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:05:23,672] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3599650135997077
[2022-12-06 14:05:23,673] [INFO] [runner_train_mujoco] Average state value: 0.5151543359197676
[2022-12-06 14:05:23,673] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 14:05:23,775] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.07980
[2022-12-06 14:05:23,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.03066, loss val: 0.07982
[2022-12-06 14:05:24,096] [INFO] [controller] EPOCH 3 loss ppo:  -0.04687, loss val: 0.07929
[2022-12-06 14:05:24,315] [INFO] [controller] EPOCH 4 loss ppo:  -0.05743, loss val: 0.07763
[2022-12-06 14:05:24,330] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:05:24,591] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:05:24,592] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:05:33,865] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:05:42,351] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:05:50,276] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:05:57,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:06:05,583] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:06:13,539] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:06:22,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:06:34,981] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:06:45,644] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:06:55,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2868632948054821
[2022-12-06 14:06:55,833] [INFO] [runner_train_mujoco] Average state value: 0.5510062790413698
[2022-12-06 14:06:55,833] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 14:06:55,977] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.04412
[2022-12-06 14:06:56,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.03641, loss val: 0.04162
[2022-12-06 14:06:56,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.05166, loss val: 0.03916
[2022-12-06 14:06:56,300] [INFO] [controller] EPOCH 4 loss ppo:  -0.05946, loss val: 0.03913
[2022-12-06 14:06:56,333] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:06:56,602] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:06:56,603] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:07:08,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:07:18,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:07:28,699] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:07:40,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:07:50,530] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:07:58,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:08:06,183] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:08:14,564] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:08:22,864] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:08:31,140] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3472913892086695
[2022-12-06 14:08:31,141] [INFO] [runner_train_mujoco] Average state value: 0.4939217014710109
[2022-12-06 14:08:31,141] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 14:08:31,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01500, loss val: 0.03792
[2022-12-06 14:08:31,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.03471, loss val: 0.03491
[2022-12-06 14:08:31,534] [INFO] [controller] EPOCH 3 loss ppo:  -0.05148, loss val: 0.03269
[2022-12-06 14:08:31,599] [INFO] [controller] EPOCH 4 loss ppo:  -0.06254, loss val: 0.03645
[2022-12-06 14:08:31,620] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:08:31,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:08:31,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:08:40,617] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:08:49,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:08:57,138] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:09:05,385] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:09:13,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:09:22,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:09:30,414] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:09:38,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:09:47,022] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:09:55,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4732777133507464
[2022-12-06 14:09:55,666] [INFO] [runner_train_mujoco] Average state value: 0.4654800310830275
[2022-12-06 14:09:55,666] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 14:09:55,797] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.04647
[2022-12-06 14:09:55,871] [INFO] [controller] EPOCH 2 loss ppo:  -0.03103, loss val: 0.04582
[2022-12-06 14:09:55,946] [INFO] [controller] EPOCH 3 loss ppo:  -0.04333, loss val: 0.04438
[2022-12-06 14:09:56,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.05389, loss val: 0.04254
[2022-12-06 14:09:56,053] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:09:56,284] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:09:56,284] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:10:05,027] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:10:13,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:10:22,171] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:10:30,380] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:10:39,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:10:47,648] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:10:56,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:11:04,599] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:11:13,260] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:11:21,852] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5913134143713275
[2022-12-06 14:11:21,853] [INFO] [runner_train_mujoco] Average state value: 0.4218808517244955
[2022-12-06 14:11:21,853] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 14:11:21,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.01598, loss val: 0.07815
[2022-12-06 14:11:22,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.03381, loss val: 0.07818
[2022-12-06 14:11:22,107] [INFO] [controller] EPOCH 3 loss ppo:  -0.04697, loss val: 0.07700
[2022-12-06 14:11:22,175] [INFO] [controller] EPOCH 4 loss ppo:  -0.05822, loss val: 0.07585
[2022-12-06 14:11:22,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:11:22,429] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:11:22,430] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:11:31,743] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:11:40,320] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:11:48,545] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:11:56,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:12:03,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:12:11,670] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:12:19,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:12:27,162] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:12:34,991] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:12:42,678] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6588736501849297
[2022-12-06 14:12:42,678] [INFO] [runner_train_mujoco] Average state value: 0.5002125726143519
[2022-12-06 14:12:42,679] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 14:12:42,757] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.04421
[2022-12-06 14:12:42,806] [INFO] [controller] EPOCH 2 loss ppo:  -0.03273, loss val: 0.04452
[2022-12-06 14:12:42,904] [INFO] [controller] EPOCH 3 loss ppo:  -0.04721, loss val: 0.04360
[2022-12-06 14:12:42,964] [INFO] [controller] EPOCH 4 loss ppo:  -0.05843, loss val: 0.04338
[2022-12-06 14:12:42,976] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:12:43,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:12:43,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:12:51,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:12:59,241] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:13:07,073] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:13:14,575] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:13:22,175] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:13:29,663] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:13:36,758] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:13:44,210] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:13:52,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:13:59,486] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.707058952432174
[2022-12-06 14:13:59,486] [INFO] [runner_train_mujoco] Average state value: 0.5101786436736584
[2022-12-06 14:13:59,486] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 14:13:59,546] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.04519
[2022-12-06 14:13:59,615] [INFO] [controller] EPOCH 2 loss ppo:  -0.02884, loss val: 0.03942
[2022-12-06 14:13:59,680] [INFO] [controller] EPOCH 3 loss ppo:  -0.03835, loss val: 0.03605
[2022-12-06 14:13:59,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.04643, loss val: 0.03239
[2022-12-06 14:13:59,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:13:59,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:13:59,958] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:14:07,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:14:16,029] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:14:24,295] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:14:32,981] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:14:40,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:14:48,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:14:56,227] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:15:03,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:15:11,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:15:20,888] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8762483563079422
[2022-12-06 14:15:20,889] [INFO] [runner_train_mujoco] Average state value: 0.57381693983078
[2022-12-06 14:15:20,889] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 14:15:20,977] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.04347
[2022-12-06 14:15:21,028] [INFO] [controller] EPOCH 2 loss ppo:  -0.02705, loss val: 0.04508
[2022-12-06 14:15:21,082] [INFO] [controller] EPOCH 3 loss ppo:  -0.04022, loss val: 0.04528
[2022-12-06 14:15:21,137] [INFO] [controller] EPOCH 4 loss ppo:  -0.05046, loss val: 0.04486
[2022-12-06 14:15:21,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:15:21,407] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:15:21,408] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:15:29,869] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:15:39,101] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:15:47,945] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:15:56,876] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:16:05,865] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:16:16,521] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:16:27,776] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:16:37,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:16:49,088] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:17:00,241] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7398101819774894
[2022-12-06 14:17:00,241] [INFO] [runner_train_mujoco] Average state value: 0.5307336984376112
[2022-12-06 14:17:00,241] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 14:17:00,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.06519
[2022-12-06 14:17:00,702] [INFO] [controller] EPOCH 2 loss ppo:  -0.03249, loss val: 0.06530
[2022-12-06 14:17:00,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.04820, loss val: 0.06522
[2022-12-06 14:17:00,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.05882, loss val: 0.06308
[2022-12-06 14:17:00,913] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:17:01,145] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:17:01,146] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:17:10,315] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:17:19,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:17:28,076] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:17:36,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:17:45,965] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:17:55,901] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:18:04,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:18:13,348] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:18:23,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:18:32,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5138870142623928
[2022-12-06 14:18:32,807] [INFO] [runner_train_mujoco] Average state value: 0.5518419740200042
[2022-12-06 14:18:32,807] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 14:18:32,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.04085
[2022-12-06 14:18:33,124] [INFO] [controller] EPOCH 2 loss ppo:  -0.02823, loss val: 0.03913
[2022-12-06 14:18:33,218] [INFO] [controller] EPOCH 3 loss ppo:  -0.04408, loss val: 0.03847
[2022-12-06 14:18:33,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.05290, loss val: 0.03556
[2022-12-06 14:18:33,327] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:18:33,572] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:18:33,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:18:43,263] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:18:52,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:19:02,284] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:19:11,516] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:19:20,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:19:29,787] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:19:38,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:19:47,868] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:19:56,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:20:05,003] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9395829102578896
[2022-12-06 14:20:05,003] [INFO] [runner_train_mujoco] Average state value: 0.49966356830795605
[2022-12-06 14:20:05,003] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 14:20:05,098] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04324
[2022-12-06 14:20:05,444] [INFO] [controller] EPOCH 2 loss ppo:  -0.02922, loss val: 0.03782
[2022-12-06 14:20:05,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.03980, loss val: 0.03834
[2022-12-06 14:20:05,566] [INFO] [controller] EPOCH 4 loss ppo:  -0.05141, loss val: 0.03838
[2022-12-06 14:20:05,578] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:20:05,810] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:20:05,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:20:15,031] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:20:24,020] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:20:32,474] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:20:41,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:20:49,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:20:57,656] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:21:07,147] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:21:17,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:21:28,027] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:21:37,513] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.03899213157007
[2022-12-06 14:21:37,513] [INFO] [runner_train_mujoco] Average state value: 0.48253245359659197
[2022-12-06 14:21:37,513] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 14:21:37,712] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.03093
[2022-12-06 14:21:38,052] [INFO] [controller] EPOCH 2 loss ppo:  -0.02973, loss val: 0.03067
[2022-12-06 14:21:38,281] [INFO] [controller] EPOCH 3 loss ppo:  -0.04566, loss val: 0.03185
[2022-12-06 14:21:38,469] [INFO] [controller] EPOCH 4 loss ppo:  -0.05748, loss val: 0.03076
[2022-12-06 14:21:38,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:21:38,752] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:21:38,752] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:21:50,174] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:21:58,988] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:22:07,116] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:22:14,877] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:22:23,031] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:22:31,153] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:22:38,996] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:22:47,615] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:22:55,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:23:04,313] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0436561256479244
[2022-12-06 14:23:04,314] [INFO] [runner_train_mujoco] Average state value: 0.4632396201044321
[2022-12-06 14:23:04,314] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 14:23:04,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.03942
[2022-12-06 14:23:04,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.02933, loss val: 0.03995
[2022-12-06 14:23:04,511] [INFO] [controller] EPOCH 3 loss ppo:  -0.04208, loss val: 0.03911
[2022-12-06 14:23:04,614] [INFO] [controller] EPOCH 4 loss ppo:  -0.05171, loss val: 0.04043
[2022-12-06 14:23:04,632] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:23:04,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:23:04,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:23:13,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:23:22,677] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:23:31,424] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:23:39,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:23:48,010] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:23:56,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:24:04,223] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:24:12,497] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:24:22,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:24:31,038] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1269593581815593
[2022-12-06 14:24:31,039] [INFO] [runner_train_mujoco] Average state value: 0.45807864625503625
[2022-12-06 14:24:31,039] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 14:24:31,193] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.03671
[2022-12-06 14:24:31,293] [INFO] [controller] EPOCH 2 loss ppo:  -0.02726, loss val: 0.03484
[2022-12-06 14:24:31,382] [INFO] [controller] EPOCH 3 loss ppo:  -0.04287, loss val: 0.03476
[2022-12-06 14:24:31,460] [INFO] [controller] EPOCH 4 loss ppo:  -0.05247, loss val: 0.03573
[2022-12-06 14:24:31,473] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:24:31,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:24:31,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:24:40,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:24:48,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:24:56,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:25:06,398] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:25:15,357] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:25:24,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:25:35,321] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:25:45,720] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:25:56,501] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:26:05,402] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8544838625039415
[2022-12-06 14:26:05,403] [INFO] [runner_train_mujoco] Average state value: 0.4878601792405049
[2022-12-06 14:26:05,403] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 14:26:05,509] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.03615
[2022-12-06 14:26:05,579] [INFO] [controller] EPOCH 2 loss ppo:  -0.02489, loss val: 0.03766
[2022-12-06 14:26:05,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.03863, loss val: 0.03589
[2022-12-06 14:26:05,742] [INFO] [controller] EPOCH 4 loss ppo:  -0.05089, loss val: 0.03584
[2022-12-06 14:26:05,756] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:26:06,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:26:06,010] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:26:16,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:26:26,578] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:26:38,494] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:26:49,380] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:26:58,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:27:08,155] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:27:17,111] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:27:26,440] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:27:36,850] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:27:46,582] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2479314665105616
[2022-12-06 14:27:46,582] [INFO] [runner_train_mujoco] Average state value: 0.480514003376166
[2022-12-06 14:27:46,582] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 14:27:46,665] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.03850
[2022-12-06 14:27:46,761] [INFO] [controller] EPOCH 2 loss ppo:  -0.02646, loss val: 0.03774
[2022-12-06 14:27:46,821] [INFO] [controller] EPOCH 3 loss ppo:  -0.03229, loss val: 0.03687
[2022-12-06 14:27:46,888] [INFO] [controller] EPOCH 4 loss ppo:  -0.04438, loss val: 0.03779
[2022-12-06 14:27:46,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:27:47,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:27:47,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:27:57,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:28:09,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:28:22,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:28:34,351] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:28:44,231] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:28:55,504] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:29:05,689] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:29:15,615] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:29:25,878] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:29:36,691] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.389370812474058
[2022-12-06 14:29:36,691] [INFO] [runner_train_mujoco] Average state value: 0.5050882598956427
[2022-12-06 14:29:36,692] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 14:29:36,801] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.04849
[2022-12-06 14:29:36,918] [INFO] [controller] EPOCH 2 loss ppo:  -0.02464, loss val: 0.04775
[2022-12-06 14:29:37,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.03893, loss val: 0.04718
[2022-12-06 14:29:37,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.05309, loss val: 0.04748
[2022-12-06 14:29:37,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:29:37,396] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:29:37,397] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:29:48,937] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:30:00,110] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:30:11,349] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:30:23,070] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:30:34,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:30:47,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:30:58,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:31:09,805] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:31:20,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:31:31,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5439319970031606
[2022-12-06 14:31:31,065] [INFO] [runner_train_mujoco] Average state value: 0.5459445589582126
[2022-12-06 14:31:31,066] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 14:31:31,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04109
[2022-12-06 14:31:31,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.02665, loss val: 0.04004
[2022-12-06 14:31:31,352] [INFO] [controller] EPOCH 3 loss ppo:  -0.03743, loss val: 0.03996
[2022-12-06 14:31:31,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.04782, loss val: 0.03979
[2022-12-06 14:31:31,457] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:31:31,752] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:31:31,753] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:31:43,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:31:54,644] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:32:04,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:32:15,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:32:24,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:32:34,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:32:44,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:32:54,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:33:03,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:33:12,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.255325956727921
[2022-12-06 14:33:12,545] [INFO] [runner_train_mujoco] Average state value: 0.5507018827597301
[2022-12-06 14:33:12,545] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 14:33:12,633] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04392
[2022-12-06 14:33:12,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.02472, loss val: 0.04239
[2022-12-06 14:33:12,763] [INFO] [controller] EPOCH 3 loss ppo:  -0.03590, loss val: 0.04059
[2022-12-06 14:33:12,829] [INFO] [controller] EPOCH 4 loss ppo:  -0.04708, loss val: 0.04016
[2022-12-06 14:33:12,842] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:33:13,064] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:33:13,064] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:33:22,150] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:33:31,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:33:41,020] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:33:49,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:33:58,855] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:34:07,970] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:34:17,365] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:34:27,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:34:36,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:34:46,537] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2020906049632987
[2022-12-06 14:34:46,538] [INFO] [runner_train_mujoco] Average state value: 0.506119637042284
[2022-12-06 14:34:46,538] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 14:34:46,665] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.03362
[2022-12-06 14:34:46,742] [INFO] [controller] EPOCH 2 loss ppo:  -0.02634, loss val: 0.03759
[2022-12-06 14:34:46,826] [INFO] [controller] EPOCH 3 loss ppo:  -0.04143, loss val: 0.03574
[2022-12-06 14:34:46,884] [INFO] [controller] EPOCH 4 loss ppo:  -0.05324, loss val: 0.03617
[2022-12-06 14:34:46,898] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:34:47,151] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:34:47,151] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:34:57,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:35:07,604] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:35:17,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:35:26,987] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:35:36,455] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:35:45,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:35:53,766] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:36:01,922] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:36:10,003] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:36:19,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4530256869887666
[2022-12-06 14:36:19,634] [INFO] [runner_train_mujoco] Average state value: 0.4438588416849574
[2022-12-06 14:36:19,634] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 14:36:20,791] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.04993
[2022-12-06 14:36:20,898] [INFO] [controller] EPOCH 2 loss ppo:  -0.02401, loss val: 0.04918
[2022-12-06 14:36:20,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.03408, loss val: 0.04942
[2022-12-06 14:36:21,062] [INFO] [controller] EPOCH 4 loss ppo:  -0.04308, loss val: 0.04897
[2022-12-06 14:36:21,078] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:36:21,303] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:36:21,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:36:30,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:36:38,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:36:47,014] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:36:54,874] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:37:02,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:37:10,709] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:37:19,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:37:27,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:37:34,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:37:42,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8553363076548237
[2022-12-06 14:37:42,565] [INFO] [runner_train_mujoco] Average state value: 0.4530061981280644
[2022-12-06 14:37:42,565] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 14:37:42,730] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.03346
[2022-12-06 14:37:42,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.02549, loss val: 0.03356
[2022-12-06 14:37:43,040] [INFO] [controller] EPOCH 3 loss ppo:  -0.03830, loss val: 0.03372
[2022-12-06 14:37:43,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.04735, loss val: 0.03371
[2022-12-06 14:37:43,117] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:37:43,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:37:43,341] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:37:51,665] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:37:59,915] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:38:08,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:38:19,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:38:27,442] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:38:35,915] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:38:44,231] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:38:52,025] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:39:00,034] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:39:07,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.557257966081553
[2022-12-06 14:39:07,978] [INFO] [runner_train_mujoco] Average state value: 0.4520776278773943
[2022-12-06 14:39:07,978] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 14:39:08,065] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.05331
[2022-12-06 14:39:08,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.02665, loss val: 0.05460
[2022-12-06 14:39:08,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.03665, loss val: 0.05083
[2022-12-06 14:39:08,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.04562, loss val: 0.05180
[2022-12-06 14:39:08,334] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:39:08,580] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:39:08,581] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:39:17,329] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:39:26,104] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:39:34,598] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:39:43,057] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:39:52,409] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:40:01,548] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:40:10,185] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:40:19,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:40:28,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:40:37,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5855490287749032
[2022-12-06 14:40:37,887] [INFO] [runner_train_mujoco] Average state value: 0.45856457474827766
[2022-12-06 14:40:37,887] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 14:40:37,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.05031
[2022-12-06 14:40:38,025] [INFO] [controller] EPOCH 2 loss ppo:  -0.02500, loss val: 0.05024
[2022-12-06 14:40:38,102] [INFO] [controller] EPOCH 3 loss ppo:  -0.03811, loss val: 0.04911
[2022-12-06 14:40:38,182] [INFO] [controller] EPOCH 4 loss ppo:  -0.04766, loss val: 0.04897
[2022-12-06 14:40:38,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:40:38,497] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:40:38,497] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:40:47,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:40:57,228] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:41:08,250] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:41:16,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:41:25,134] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:41:34,160] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:41:42,483] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:41:50,266] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:41:59,151] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:42:07,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.529762527601948
[2022-12-06 14:42:07,839] [INFO] [runner_train_mujoco] Average state value: 0.43957684582471845
[2022-12-06 14:42:07,839] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 14:42:07,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.05172
[2022-12-06 14:42:07,998] [INFO] [controller] EPOCH 2 loss ppo:  -0.02149, loss val: 0.05057
[2022-12-06 14:42:08,079] [INFO] [controller] EPOCH 3 loss ppo:  -0.03386, loss val: 0.04865
[2022-12-06 14:42:08,149] [INFO] [controller] EPOCH 4 loss ppo:  -0.04700, loss val: 0.04794
[2022-12-06 14:42:08,162] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:42:08,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:42:08,394] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:42:16,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:42:25,523] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:42:34,849] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:42:43,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:42:52,700] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:43:01,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:43:10,692] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:43:20,349] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:43:29,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:43:37,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.698756484052543
[2022-12-06 14:43:37,332] [INFO] [runner_train_mujoco] Average state value: 0.4626530756056309
[2022-12-06 14:43:37,333] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 14:43:37,445] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.02811
[2022-12-06 14:43:37,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.01990, loss val: 0.02860
[2022-12-06 14:43:37,583] [INFO] [controller] EPOCH 3 loss ppo:  -0.03048, loss val: 0.02788
[2022-12-06 14:43:37,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.03886, loss val: 0.02752
[2022-12-06 14:43:37,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:43:37,914] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:43:37,915] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:43:46,185] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:43:54,381] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:44:02,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:44:10,749] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:44:18,663] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:44:26,654] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:44:34,706] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:44:42,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:44:50,935] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:44:59,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5715995680200203
[2022-12-06 14:44:59,273] [INFO] [runner_train_mujoco] Average state value: 0.4512112925102314
[2022-12-06 14:44:59,273] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 14:44:59,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.04366
[2022-12-06 14:44:59,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.02186, loss val: 0.04397
[2022-12-06 14:44:59,550] [INFO] [controller] EPOCH 3 loss ppo:  -0.03292, loss val: 0.04335
[2022-12-06 14:44:59,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.03905, loss val: 0.04305
[2022-12-06 14:44:59,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:44:59,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:44:59,910] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:45:08,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:45:18,858] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:45:27,485] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:45:35,977] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:45:43,950] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:45:52,494] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:46:00,708] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:46:09,390] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:46:17,680] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:46:26,119] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7784473352652985
[2022-12-06 14:46:26,120] [INFO] [runner_train_mujoco] Average state value: 0.46159808901945754
[2022-12-06 14:46:26,120] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 14:46:26,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03577
[2022-12-06 14:46:26,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.02318, loss val: 0.03700
[2022-12-06 14:46:26,330] [INFO] [controller] EPOCH 3 loss ppo:  -0.03441, loss val: 0.03830
[2022-12-06 14:46:26,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.04391, loss val: 0.03560
[2022-12-06 14:46:26,398] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:46:26,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:46:26,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:46:35,621] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:46:44,948] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:46:53,669] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:47:02,814] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:47:12,023] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:47:20,923] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:47:30,465] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:47:39,075] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:47:48,225] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:47:57,343] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7501452251371363
[2022-12-06 14:47:57,343] [INFO] [runner_train_mujoco] Average state value: 0.4550092400809129
[2022-12-06 14:47:57,344] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 14:47:57,437] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.03936
[2022-12-06 14:47:57,540] [INFO] [controller] EPOCH 2 loss ppo:  -0.02009, loss val: 0.03918
[2022-12-06 14:47:57,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.03050, loss val: 0.03820
[2022-12-06 14:47:57,743] [INFO] [controller] EPOCH 4 loss ppo:  -0.03878, loss val: 0.03779
[2022-12-06 14:47:57,757] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:47:58,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:47:58,016] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:48:06,895] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:48:15,560] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:48:24,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:48:32,418] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:48:40,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:48:49,172] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:48:57,574] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:49:05,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:49:14,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:49:22,896] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7396867167722365
[2022-12-06 14:49:22,897] [INFO] [runner_train_mujoco] Average state value: 0.46894139742851254
[2022-12-06 14:49:22,897] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 14:49:22,973] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.03572
[2022-12-06 14:49:23,028] [INFO] [controller] EPOCH 2 loss ppo:  -0.01797, loss val: 0.03655
[2022-12-06 14:49:23,086] [INFO] [controller] EPOCH 3 loss ppo:  -0.02544, loss val: 0.03579
[2022-12-06 14:49:23,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.03325, loss val: 0.03581
[2022-12-06 14:49:23,160] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:49:23,395] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:49:23,396] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:49:31,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:49:39,492] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:49:47,377] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:49:54,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:50:02,467] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:50:10,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:50:18,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:50:25,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:50:33,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:50:40,602] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.786701701643982
[2022-12-06 14:50:40,602] [INFO] [runner_train_mujoco] Average state value: 0.44742134551455576
[2022-12-06 14:50:40,602] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 14:50:40,683] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04078
[2022-12-06 14:50:40,733] [INFO] [controller] EPOCH 2 loss ppo:  -0.01782, loss val: 0.04128
[2022-12-06 14:50:40,785] [INFO] [controller] EPOCH 3 loss ppo:  -0.02401, loss val: 0.04062
[2022-12-06 14:50:40,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.03228, loss val: 0.04095
[2022-12-06 14:50:40,854] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:50:41,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:50:41,063] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:50:49,684] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:50:57,901] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:51:06,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:51:13,668] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:51:21,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:51:30,150] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:51:36,960] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:51:44,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:51:52,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:52:00,685] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.033569719872742
[2022-12-06 14:52:00,686] [INFO] [runner_train_mujoco] Average state value: 0.4687515287597974
[2022-12-06 14:52:00,686] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 14:52:00,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04474
[2022-12-06 14:52:00,815] [INFO] [controller] EPOCH 2 loss ppo:  -0.01650, loss val: 0.04547
[2022-12-06 14:52:00,866] [INFO] [controller] EPOCH 3 loss ppo:  -0.02095, loss val: 0.04504
[2022-12-06 14:52:00,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.02627, loss val: 0.04559
[2022-12-06 14:52:00,942] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:52:01,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:52:01,161] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:52:09,715] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:52:17,627] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:52:25,655] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:52:33,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:52:42,007] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:52:50,141] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:52:58,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:53:06,232] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:53:15,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:53:25,646] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1959555042625603
[2022-12-06 14:53:25,647] [INFO] [runner_train_mujoco] Average state value: 0.4543348362570008
[2022-12-06 14:53:25,647] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 14:53:25,766] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.05041
[2022-12-06 14:53:25,831] [INFO] [controller] EPOCH 2 loss ppo:  -0.01617, loss val: 0.05045
[2022-12-06 14:53:25,944] [INFO] [controller] EPOCH 3 loss ppo:  -0.02000, loss val: 0.05171
[2022-12-06 14:53:26,087] [INFO] [controller] EPOCH 4 loss ppo:  -0.02489, loss val: 0.05139
[2022-12-06 14:53:26,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:53:26,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:53:26,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:53:34,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:53:43,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:53:52,051] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:54:00,403] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:54:08,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:54:17,592] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:54:27,327] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:54:36,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:54:44,705] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:54:53,489] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.220277368639948
[2022-12-06 14:54:53,489] [INFO] [runner_train_mujoco] Average state value: 0.45889349289238457
[2022-12-06 14:54:53,489] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 14:54:53,559] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04623
[2022-12-06 14:54:53,626] [INFO] [controller] EPOCH 2 loss ppo:  -0.01541, loss val: 0.04689
[2022-12-06 14:54:53,716] [INFO] [controller] EPOCH 3 loss ppo:  -0.01811, loss val: 0.04785
[2022-12-06 14:54:53,837] [INFO] [controller] EPOCH 4 loss ppo:  -0.02129, loss val: 0.04781
[2022-12-06 14:54:53,850] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:54:54,050] [INFO] [optimize] Finished learning.
