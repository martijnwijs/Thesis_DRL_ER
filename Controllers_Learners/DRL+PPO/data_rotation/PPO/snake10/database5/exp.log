[2022-12-07 00:17:31,395] [INFO] [optimize] Starting learning
[2022-12-07 00:17:31,411] [INFO] [optimize] Starting learning process..
[2022-12-07 00:17:31,501] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:17:31,502] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:17:38,951] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:17:44,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:17:50,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:17:55,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:18:01,248] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:18:06,529] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:18:11,535] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:18:17,132] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:18:22,664] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:18:27,774] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1275400186953457
[2022-12-07 00:18:27,774] [INFO] [runner_train_mujoco] Average state value: 0.1593914627507329
[2022-12-07 00:18:27,774] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 00:18:27,821] [INFO] [controller] EPOCH 1 loss ppo:  -0.01629, loss val: 0.32870
[2022-12-07 00:18:27,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.04228, loss val: 0.29266
[2022-12-07 00:18:27,900] [INFO] [controller] EPOCH 3 loss ppo:  -0.05297, loss val: 0.25162
[2022-12-07 00:18:27,941] [INFO] [controller] EPOCH 4 loss ppo:  -0.05891, loss val: 0.22450
[2022-12-07 00:18:27,951] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:18:28,122] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:18:28,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:18:33,398] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:18:38,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:18:44,027] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:18:49,722] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:18:55,209] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:19:01,128] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:19:06,928] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:19:12,389] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:19:17,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:19:23,759] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1149491493835886
[2022-12-07 00:19:23,760] [INFO] [runner_train_mujoco] Average state value: 0.3187023690138012
[2022-12-07 00:19:23,760] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 00:19:23,819] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.18639
[2022-12-07 00:19:23,861] [INFO] [controller] EPOCH 2 loss ppo:  -0.03868, loss val: 0.15715
[2022-12-07 00:19:23,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.05131, loss val: 0.14036
[2022-12-07 00:19:23,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.05884, loss val: 0.12422
[2022-12-07 00:19:23,950] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:19:24,134] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:19:24,134] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:19:29,666] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:19:35,615] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:19:41,121] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:19:46,715] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:19:52,224] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:19:57,844] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:20:03,214] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:20:08,971] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:20:14,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:20:20,512] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0775917077912944
[2022-12-07 00:20:20,512] [INFO] [runner_train_mujoco] Average state value: 0.45101128152509534
[2022-12-07 00:20:20,513] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 00:20:20,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.13482
[2022-12-07 00:20:20,610] [INFO] [controller] EPOCH 2 loss ppo:  -0.03829, loss val: 0.12075
[2022-12-07 00:20:20,659] [INFO] [controller] EPOCH 3 loss ppo:  -0.05290, loss val: 0.11021
[2022-12-07 00:20:20,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.06258, loss val: 0.10017
[2022-12-07 00:20:20,712] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:20:20,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:20:20,898] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:20:26,894] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:20:32,680] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:20:38,153] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:20:43,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:20:49,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:20:54,851] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:21:00,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:21:06,080] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:21:11,705] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:21:17,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7851117199830766
[2022-12-07 00:21:17,169] [INFO] [runner_train_mujoco] Average state value: 0.5952055095390727
[2022-12-07 00:21:17,169] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 00:21:17,221] [INFO] [controller] EPOCH 1 loss ppo:  -0.01040, loss val: 0.08914
[2022-12-07 00:21:17,265] [INFO] [controller] EPOCH 2 loss ppo:  -0.03209, loss val: 0.08369
[2022-12-07 00:21:17,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.04770, loss val: 0.07964
[2022-12-07 00:21:17,347] [INFO] [controller] EPOCH 4 loss ppo:  -0.05541, loss val: 0.07579
[2022-12-07 00:21:17,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:21:17,541] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:21:17,542] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:21:23,685] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:21:29,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:21:35,357] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:21:41,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:21:47,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:21:52,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:21:58,195] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:22:03,687] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:22:09,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:22:15,425] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1892917056699477
[2022-12-07 00:22:15,425] [INFO] [runner_train_mujoco] Average state value: 0.6121505667194724
[2022-12-07 00:22:15,425] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 00:22:15,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.07164
[2022-12-07 00:22:15,521] [INFO] [controller] EPOCH 2 loss ppo:  -0.03349, loss val: 0.06846
[2022-12-07 00:22:15,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.04241, loss val: 0.06470
[2022-12-07 00:22:15,621] [INFO] [controller] EPOCH 4 loss ppo:  -0.05247, loss val: 0.06053
[2022-12-07 00:22:15,629] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:22:15,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:22:15,843] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:22:21,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:22:26,824] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:22:32,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:22:37,750] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:22:43,326] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:22:48,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:22:54,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:23:00,154] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:23:05,825] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:23:11,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8077527854165572
[2022-12-07 00:23:11,342] [INFO] [runner_train_mujoco] Average state value: 0.5657896095265944
[2022-12-07 00:23:11,342] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 00:23:11,392] [INFO] [controller] EPOCH 1 loss ppo:  -0.00858, loss val: 0.06151
[2022-12-07 00:23:11,437] [INFO] [controller] EPOCH 2 loss ppo:  -0.02861, loss val: 0.06017
[2022-12-07 00:23:11,483] [INFO] [controller] EPOCH 3 loss ppo:  -0.04090, loss val: 0.05787
[2022-12-07 00:23:11,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.04912, loss val: 0.05420
[2022-12-07 00:23:11,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:23:11,730] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:23:11,730] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:23:16,882] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:23:22,324] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:23:27,589] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:23:32,661] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:23:38,174] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:23:43,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:23:49,439] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:23:54,962] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:24:00,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:24:05,198] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0708189024717973
[2022-12-07 00:24:05,199] [INFO] [runner_train_mujoco] Average state value: 0.5904120921244224
[2022-12-07 00:24:05,199] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 00:24:05,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.05135
[2022-12-07 00:24:05,290] [INFO] [controller] EPOCH 2 loss ppo:  -0.03356, loss val: 0.05157
[2022-12-07 00:24:05,333] [INFO] [controller] EPOCH 3 loss ppo:  -0.04782, loss val: 0.05023
[2022-12-07 00:24:05,374] [INFO] [controller] EPOCH 4 loss ppo:  -0.05446, loss val: 0.04820
[2022-12-07 00:24:05,383] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:24:05,549] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:24:05,549] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:24:11,536] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:24:16,953] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:24:22,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:24:27,857] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:24:32,923] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:24:38,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:24:43,631] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:24:48,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:24:54,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:24:59,965] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0822980998287564
[2022-12-07 00:24:59,965] [INFO] [runner_train_mujoco] Average state value: 0.6164166468977927
[2022-12-07 00:24:59,965] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 00:25:00,025] [INFO] [controller] EPOCH 1 loss ppo:  -0.01213, loss val: 0.05086
[2022-12-07 00:25:00,073] [INFO] [controller] EPOCH 2 loss ppo:  -0.03227, loss val: 0.04891
[2022-12-07 00:25:00,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.04565, loss val: 0.04633
[2022-12-07 00:25:00,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.05308, loss val: 0.04356
[2022-12-07 00:25:00,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:25:00,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:25:00,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:25:06,059] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:25:11,403] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:25:16,704] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:25:21,900] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:25:27,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:25:33,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:25:39,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:25:44,525] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:25:49,800] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:25:55,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0577783551095419
[2022-12-07 00:25:55,391] [INFO] [runner_train_mujoco] Average state value: 0.5610045971274376
[2022-12-07 00:25:55,391] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 00:25:55,443] [INFO] [controller] EPOCH 1 loss ppo:  -0.01096, loss val: 0.03555
[2022-12-07 00:25:55,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.03736, loss val: 0.03469
[2022-12-07 00:25:55,529] [INFO] [controller] EPOCH 3 loss ppo:  -0.04589, loss val: 0.03575
[2022-12-07 00:25:55,575] [INFO] [controller] EPOCH 4 loss ppo:  -0.05353, loss val: 0.03664
[2022-12-07 00:25:55,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:25:55,761] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:25:55,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:26:01,286] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:26:06,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:26:12,284] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:26:17,990] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:26:23,509] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:26:29,017] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:26:34,646] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:26:40,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:26:46,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:26:53,210] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.162144138651112
[2022-12-07 00:26:53,210] [INFO] [runner_train_mujoco] Average state value: 0.5059321411972244
[2022-12-07 00:26:53,210] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 00:26:53,270] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.03872
[2022-12-07 00:26:53,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.03467, loss val: 0.03868
[2022-12-07 00:26:53,374] [INFO] [controller] EPOCH 3 loss ppo:  -0.04819, loss val: 0.03783
[2022-12-07 00:26:53,423] [INFO] [controller] EPOCH 4 loss ppo:  -0.05759, loss val: 0.03852
[2022-12-07 00:26:53,434] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:26:53,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:26:53,615] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:26:59,664] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:27:05,224] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:27:10,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:27:16,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:27:21,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:27:27,578] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:27:32,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:27:38,805] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:27:44,685] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:27:50,136] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.311228091524702
[2022-12-07 00:27:50,136] [INFO] [runner_train_mujoco] Average state value: 0.49932830207546547
[2022-12-07 00:27:50,136] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 00:27:50,195] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.03420
[2022-12-07 00:27:50,241] [INFO] [controller] EPOCH 2 loss ppo:  -0.03759, loss val: 0.03493
[2022-12-07 00:27:50,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.04906, loss val: 0.03334
[2022-12-07 00:27:50,331] [INFO] [controller] EPOCH 4 loss ppo:  -0.05833, loss val: 0.03322
[2022-12-07 00:27:50,340] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:27:50,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:27:50,526] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:27:55,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:28:01,990] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:28:07,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:28:13,511] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:28:19,433] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:28:24,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:28:30,282] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:28:36,042] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:28:41,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:28:47,168] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3029070200518589
[2022-12-07 00:28:47,168] [INFO] [runner_train_mujoco] Average state value: 0.4782039208610852
[2022-12-07 00:28:47,168] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 00:28:47,228] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.03732
[2022-12-07 00:28:47,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.03752, loss val: 0.03776
[2022-12-07 00:28:47,384] [INFO] [controller] EPOCH 3 loss ppo:  -0.05192, loss val: 0.03767
[2022-12-07 00:28:47,438] [INFO] [controller] EPOCH 4 loss ppo:  -0.06004, loss val: 0.03509
[2022-12-07 00:28:47,449] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:28:47,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:28:47,626] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:28:53,119] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:28:58,696] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:29:04,031] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:29:09,419] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:29:14,526] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:29:20,126] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:29:25,365] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:29:30,952] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:29:36,732] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:29:42,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2400800197584307
[2022-12-07 00:29:42,109] [INFO] [runner_train_mujoco] Average state value: 0.44013145765662187
[2022-12-07 00:29:42,110] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 00:29:42,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.07546
[2022-12-07 00:29:42,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03006, loss val: 0.07246
[2022-12-07 00:29:42,245] [INFO] [controller] EPOCH 3 loss ppo:  -0.04170, loss val: 0.06996
[2022-12-07 00:29:42,288] [INFO] [controller] EPOCH 4 loss ppo:  -0.05041, loss val: 0.06524
[2022-12-07 00:29:42,298] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:29:42,453] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:29:42,453] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:29:47,636] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:29:52,973] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:29:58,373] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:30:03,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:30:09,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:30:14,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:30:19,614] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:30:24,677] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:30:29,648] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:30:35,224] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4565686570580303
[2022-12-07 00:30:35,224] [INFO] [runner_train_mujoco] Average state value: 0.5075324298342068
[2022-12-07 00:30:35,224] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 00:30:35,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.01082, loss val: 0.03667
[2022-12-07 00:30:35,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.03242, loss val: 0.03585
[2022-12-07 00:30:35,362] [INFO] [controller] EPOCH 3 loss ppo:  -0.04460, loss val: 0.03460
[2022-12-07 00:30:35,405] [INFO] [controller] EPOCH 4 loss ppo:  -0.05248, loss val: 0.03536
[2022-12-07 00:30:35,415] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:30:35,595] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:30:35,596] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:30:41,192] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:30:46,891] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:30:52,049] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:30:57,658] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:31:02,761] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:31:08,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:31:13,637] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:31:18,742] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:31:24,227] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:31:29,898] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3706925635146523
[2022-12-07 00:31:29,898] [INFO] [runner_train_mujoco] Average state value: 0.5673413109680018
[2022-12-07 00:31:29,898] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 00:31:29,958] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.04319
[2022-12-07 00:31:29,999] [INFO] [controller] EPOCH 2 loss ppo:  -0.03685, loss val: 0.04296
[2022-12-07 00:31:30,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.05266, loss val: 0.04280
[2022-12-07 00:31:30,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.06187, loss val: 0.04146
[2022-12-07 00:31:30,103] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:31:30,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:31:30,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:31:35,402] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:31:40,793] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:31:46,456] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:31:51,765] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:31:57,588] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:32:03,352] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:32:08,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:32:14,061] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:32:19,478] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:32:25,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6948443421492787
[2022-12-07 00:32:25,051] [INFO] [runner_train_mujoco] Average state value: 0.5352028390169143
[2022-12-07 00:32:25,051] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 00:32:25,105] [INFO] [controller] EPOCH 1 loss ppo:  -0.01114, loss val: 0.04650
[2022-12-07 00:32:25,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.02883, loss val: 0.04368
[2022-12-07 00:32:25,197] [INFO] [controller] EPOCH 3 loss ppo:  -0.04114, loss val: 0.04156
[2022-12-07 00:32:25,242] [INFO] [controller] EPOCH 4 loss ppo:  -0.05345, loss val: 0.04160
[2022-12-07 00:32:25,252] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:32:25,441] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:32:25,441] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:32:30,956] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:32:36,628] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:32:42,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:32:47,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:32:53,134] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:32:58,663] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:33:04,437] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:33:10,147] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:33:15,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:33:21,245] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.669382836827961
[2022-12-07 00:33:21,245] [INFO] [runner_train_mujoco] Average state value: 0.4671012587199609
[2022-12-07 00:33:21,245] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 00:33:21,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.03669
[2022-12-07 00:33:21,394] [INFO] [controller] EPOCH 2 loss ppo:  -0.03531, loss val: 0.03840
[2022-12-07 00:33:21,451] [INFO] [controller] EPOCH 3 loss ppo:  -0.05094, loss val: 0.03915
[2022-12-07 00:33:21,504] [INFO] [controller] EPOCH 4 loss ppo:  -0.06092, loss val: 0.03650
[2022-12-07 00:33:21,515] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:33:21,725] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:33:21,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:33:27,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:33:32,465] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:33:38,066] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:33:43,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:33:49,680] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:33:55,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:34:01,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:34:06,751] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:34:12,301] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:34:17,810] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7300014614124926
[2022-12-07 00:34:17,811] [INFO] [runner_train_mujoco] Average state value: 0.38927946624780696
[2022-12-07 00:34:17,811] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 00:34:17,866] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.07067
[2022-12-07 00:34:17,913] [INFO] [controller] EPOCH 2 loss ppo:  -0.03418, loss val: 0.07110
[2022-12-07 00:34:17,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.04582, loss val: 0.06910
[2022-12-07 00:34:18,007] [INFO] [controller] EPOCH 4 loss ppo:  -0.05744, loss val: 0.06761
[2022-12-07 00:34:18,017] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:34:18,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:34:18,208] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:34:24,810] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:34:33,979] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:34:40,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:34:47,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:34:53,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:35:00,775] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:35:07,159] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:35:13,753] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:35:20,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:35:27,147] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8233454369467126
[2022-12-07 00:35:27,147] [INFO] [runner_train_mujoco] Average state value: 0.456149012674888
[2022-12-07 00:35:27,147] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 00:35:27,212] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04695
[2022-12-07 00:35:27,260] [INFO] [controller] EPOCH 2 loss ppo:  -0.03441, loss val: 0.04404
[2022-12-07 00:35:27,311] [INFO] [controller] EPOCH 3 loss ppo:  -0.04546, loss val: 0.04317
[2022-12-07 00:35:27,358] [INFO] [controller] EPOCH 4 loss ppo:  -0.05667, loss val: 0.04225
[2022-12-07 00:35:27,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:35:27,573] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:35:27,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:35:33,649] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:35:40,207] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:35:46,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:35:52,789] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:35:58,829] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:36:04,878] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:36:11,128] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:36:17,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:36:23,888] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:36:30,175] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7832257098125759
[2022-12-07 00:36:30,176] [INFO] [runner_train_mujoco] Average state value: 0.4883265024324258
[2022-12-07 00:36:30,176] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 00:36:30,234] [INFO] [controller] EPOCH 1 loss ppo:  -0.01602, loss val: 0.04981
[2022-12-07 00:36:30,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.03711, loss val: 0.04849
[2022-12-07 00:36:30,318] [INFO] [controller] EPOCH 3 loss ppo:  -0.04872, loss val: 0.04750
[2022-12-07 00:36:30,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.06146, loss val: 0.04722
[2022-12-07 00:36:30,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:36:30,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:36:30,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:36:39,238] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:36:46,473] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:36:53,363] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:37:00,272] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:37:07,064] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:37:13,846] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:37:20,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:37:27,192] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:37:34,589] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:37:41,607] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8128422302250082
[2022-12-07 00:37:41,607] [INFO] [runner_train_mujoco] Average state value: 0.47274138494332635
[2022-12-07 00:37:41,607] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 00:37:41,675] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.07758
[2022-12-07 00:37:41,727] [INFO] [controller] EPOCH 2 loss ppo:  -0.03385, loss val: 0.07741
[2022-12-07 00:37:41,783] [INFO] [controller] EPOCH 3 loss ppo:  -0.04627, loss val: 0.07631
[2022-12-07 00:37:41,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.05537, loss val: 0.07422
[2022-12-07 00:37:41,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:37:42,066] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:37:42,066] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:37:48,516] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:37:55,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:38:03,196] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:38:10,494] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:38:17,738] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:38:24,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:38:32,166] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:38:39,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:38:46,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:38:52,774] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.23735961996415
[2022-12-07 00:38:52,774] [INFO] [runner_train_mujoco] Average state value: 0.5205361580650011
[2022-12-07 00:38:52,774] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 00:38:52,835] [INFO] [controller] EPOCH 1 loss ppo:  -0.01253, loss val: 0.03800
[2022-12-07 00:38:52,886] [INFO] [controller] EPOCH 2 loss ppo:  -0.03165, loss val: 0.03875
[2022-12-07 00:38:52,949] [INFO] [controller] EPOCH 3 loss ppo:  -0.04657, loss val: 0.03888
[2022-12-07 00:38:53,000] [INFO] [controller] EPOCH 4 loss ppo:  -0.05742, loss val: 0.03915
[2022-12-07 00:38:53,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:38:53,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:38:53,219] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:39:00,420] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:39:07,933] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:39:14,937] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:39:22,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:39:29,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:39:36,508] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:39:43,918] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:39:51,138] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:39:58,425] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:40:06,193] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.071805193533564
[2022-12-07 00:40:06,193] [INFO] [runner_train_mujoco] Average state value: 0.49484845029314356
[2022-12-07 00:40:06,193] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 00:40:06,265] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.03660
[2022-12-07 00:40:06,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.03080, loss val: 0.03399
[2022-12-07 00:40:06,403] [INFO] [controller] EPOCH 3 loss ppo:  -0.04051, loss val: 0.03338
[2022-12-07 00:40:06,472] [INFO] [controller] EPOCH 4 loss ppo:  -0.05211, loss val: 0.03485
[2022-12-07 00:40:06,483] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:40:06,725] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:40:06,726] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:40:14,031] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:40:21,585] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:40:29,199] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:40:36,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:40:43,949] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:40:50,978] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:40:58,425] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:41:05,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:41:12,589] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:41:19,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2790708118731695
[2022-12-07 00:41:19,550] [INFO] [runner_train_mujoco] Average state value: 0.4494616423348585
[2022-12-07 00:41:19,550] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 00:41:19,616] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.03889
[2022-12-07 00:41:19,680] [INFO] [controller] EPOCH 2 loss ppo:  -0.03689, loss val: 0.03677
[2022-12-07 00:41:19,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.05020, loss val: 0.03627
[2022-12-07 00:41:19,830] [INFO] [controller] EPOCH 4 loss ppo:  -0.06345, loss val: 0.03702
[2022-12-07 00:41:19,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:41:20,070] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:41:20,071] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:41:27,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:41:34,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:41:41,738] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:41:48,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:41:55,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:42:03,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:42:10,100] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:42:17,138] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:42:24,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:42:31,187] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.236950279341332
[2022-12-07 00:42:31,187] [INFO] [runner_train_mujoco] Average state value: 0.394482042496403
[2022-12-07 00:42:31,187] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 00:42:31,250] [INFO] [controller] EPOCH 1 loss ppo:  -0.01215, loss val: 0.05847
[2022-12-07 00:42:31,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.02585, loss val: 0.05825
[2022-12-07 00:42:31,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.03684, loss val: 0.05639
[2022-12-07 00:42:31,490] [INFO] [controller] EPOCH 4 loss ppo:  -0.04520, loss val: 0.05304
[2022-12-07 00:42:31,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:42:31,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:42:31,709] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:42:38,511] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:42:45,715] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:42:52,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:42:58,971] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:43:06,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:43:13,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:43:20,351] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:43:28,361] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:43:34,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:43:41,441] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1712169721888848
[2022-12-07 00:43:41,441] [INFO] [runner_train_mujoco] Average state value: 0.42670683839917184
[2022-12-07 00:43:41,441] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 00:43:41,498] [INFO] [controller] EPOCH 1 loss ppo:  -0.01283, loss val: 0.03243
[2022-12-07 00:43:41,548] [INFO] [controller] EPOCH 2 loss ppo:  -0.02838, loss val: 0.03893
[2022-12-07 00:43:41,603] [INFO] [controller] EPOCH 3 loss ppo:  -0.03910, loss val: 0.03413
[2022-12-07 00:43:41,651] [INFO] [controller] EPOCH 4 loss ppo:  -0.05262, loss val: 0.03775
[2022-12-07 00:43:41,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:43:41,867] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:43:41,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:43:48,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:43:55,515] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:44:02,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:44:09,262] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:44:16,441] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:44:23,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:44:30,504] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:44:37,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:44:44,366] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:44:51,518] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7316838872124807
[2022-12-07 00:44:51,518] [INFO] [runner_train_mujoco] Average state value: 0.43010532560944553
[2022-12-07 00:44:51,518] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 00:44:51,583] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.03702
[2022-12-07 00:44:51,633] [INFO] [controller] EPOCH 2 loss ppo:  -0.03346, loss val: 0.03614
[2022-12-07 00:44:51,688] [INFO] [controller] EPOCH 3 loss ppo:  -0.04858, loss val: 0.03995
[2022-12-07 00:44:51,751] [INFO] [controller] EPOCH 4 loss ppo:  -0.05588, loss val: 0.03997
[2022-12-07 00:44:51,762] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:44:51,970] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:44:51,971] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:44:59,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:45:06,600] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:45:13,548] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:45:21,050] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:45:28,818] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:45:37,397] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:45:45,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:45:53,335] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:46:01,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:46:09,827] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6331501013976712
[2022-12-07 00:46:09,828] [INFO] [runner_train_mujoco] Average state value: 0.405597238920629
[2022-12-07 00:46:09,828] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 00:46:09,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01318, loss val: 0.03671
[2022-12-07 00:46:09,981] [INFO] [controller] EPOCH 2 loss ppo:  -0.03355, loss val: 0.03561
[2022-12-07 00:46:10,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.04683, loss val: 0.03565
[2022-12-07 00:46:10,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.05785, loss val: 0.03490
[2022-12-07 00:46:10,146] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:46:10,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:46:10,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:46:18,535] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:46:26,877] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:46:35,128] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:46:43,963] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:46:52,201] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:47:00,668] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:47:09,150] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:47:17,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:47:24,905] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:47:32,683] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9463679970356362
[2022-12-07 00:47:32,683] [INFO] [runner_train_mujoco] Average state value: 0.4179051448702812
[2022-12-07 00:47:32,683] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 00:47:32,751] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.05501
[2022-12-07 00:47:32,814] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.05101
[2022-12-07 00:47:32,877] [INFO] [controller] EPOCH 3 loss ppo:  -0.03534, loss val: 0.05010
[2022-12-07 00:47:32,941] [INFO] [controller] EPOCH 4 loss ppo:  -0.04507, loss val: 0.04209
[2022-12-07 00:47:32,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:47:33,185] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:47:33,185] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:47:41,030] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:47:48,748] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:47:56,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:48:04,058] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:48:11,874] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:48:19,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:48:27,587] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:48:35,195] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:48:42,446] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:48:49,883] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0835435652181644
[2022-12-07 00:48:49,884] [INFO] [runner_train_mujoco] Average state value: 0.47013154648741085
[2022-12-07 00:48:49,884] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 00:48:49,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.04029
[2022-12-07 00:48:50,017] [INFO] [controller] EPOCH 2 loss ppo:  -0.02919, loss val: 0.04095
[2022-12-07 00:48:50,073] [INFO] [controller] EPOCH 3 loss ppo:  -0.04083, loss val: 0.04134
[2022-12-07 00:48:50,131] [INFO] [controller] EPOCH 4 loss ppo:  -0.05229, loss val: 0.04128
[2022-12-07 00:48:50,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:48:50,382] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:48:50,387] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:48:58,001] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:49:06,174] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:49:13,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:49:20,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:49:28,043] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:49:35,176] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:49:42,065] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:49:49,187] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:49:56,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:50:03,228] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2927709991910525
[2022-12-07 00:50:03,228] [INFO] [runner_train_mujoco] Average state value: 0.45743098360300066
[2022-12-07 00:50:03,228] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 00:50:03,303] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.06107
[2022-12-07 00:50:03,369] [INFO] [controller] EPOCH 2 loss ppo:  -0.02692, loss val: 0.06087
[2022-12-07 00:50:03,427] [INFO] [controller] EPOCH 3 loss ppo:  -0.04091, loss val: 0.06207
[2022-12-07 00:50:03,489] [INFO] [controller] EPOCH 4 loss ppo:  -0.05199, loss val: 0.06186
[2022-12-07 00:50:03,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:50:03,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:50:03,709] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:50:11,270] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:50:18,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:50:25,063] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:50:31,902] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:50:38,909] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:50:45,884] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:50:52,726] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:50:59,785] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:51:06,567] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:51:13,465] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1311068901780152
[2022-12-07 00:51:13,465] [INFO] [runner_train_mujoco] Average state value: 0.4904927602509658
[2022-12-07 00:51:13,466] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 00:51:13,534] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.02426
[2022-12-07 00:51:13,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.02866, loss val: 0.02390
[2022-12-07 00:51:13,664] [INFO] [controller] EPOCH 3 loss ppo:  -0.03905, loss val: 0.02341
[2022-12-07 00:51:13,735] [INFO] [controller] EPOCH 4 loss ppo:  -0.04784, loss val: 0.02406
[2022-12-07 00:51:13,746] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:51:13,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:51:13,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:51:20,410] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:51:27,165] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:51:34,161] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:51:40,827] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:51:47,255] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:51:54,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:52:00,309] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:52:07,291] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:52:14,217] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:52:21,541] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.158418138981093
[2022-12-07 00:52:21,541] [INFO] [runner_train_mujoco] Average state value: 0.5137364578942457
[2022-12-07 00:52:21,541] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 00:52:21,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04493
[2022-12-07 00:52:21,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.02595, loss val: 0.04474
[2022-12-07 00:52:21,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.03552, loss val: 0.04265
[2022-12-07 00:52:22,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.04521, loss val: 0.03751
[2022-12-07 00:52:22,051] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:52:22,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:52:22,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:52:28,977] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:52:35,614] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:52:42,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:52:48,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:52:55,016] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:53:01,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:53:08,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:53:14,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:53:20,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:53:27,337] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.158586984816011
[2022-12-07 00:53:27,337] [INFO] [runner_train_mujoco] Average state value: 0.4721053798149029
[2022-12-07 00:53:27,338] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 00:53:27,427] [INFO] [controller] EPOCH 1 loss ppo:  -0.01498, loss val: 0.03933
[2022-12-07 00:53:27,481] [INFO] [controller] EPOCH 2 loss ppo:  -0.02912, loss val: 0.03848
[2022-12-07 00:53:27,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.03796, loss val: 0.03804
[2022-12-07 00:53:27,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.04874, loss val: 0.03919
[2022-12-07 00:53:27,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:53:27,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:53:27,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:53:34,187] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:53:40,962] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:53:47,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:53:53,791] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:54:00,443] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:54:07,303] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:54:14,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:54:20,506] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:54:27,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:54:33,463] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.094717171686926
[2022-12-07 00:54:33,463] [INFO] [runner_train_mujoco] Average state value: 0.4452783413032691
[2022-12-07 00:54:33,463] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 00:54:33,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.03264
[2022-12-07 00:54:33,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.02583, loss val: 0.03320
[2022-12-07 00:54:33,650] [INFO] [controller] EPOCH 3 loss ppo:  -0.04154, loss val: 0.03182
[2022-12-07 00:54:33,699] [INFO] [controller] EPOCH 4 loss ppo:  -0.05631, loss val: 0.03288
[2022-12-07 00:54:33,709] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:54:33,907] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:54:33,908] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:54:40,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:54:47,087] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:54:53,518] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:55:00,145] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:55:07,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:55:14,219] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:55:21,346] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:55:28,207] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:55:35,192] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:55:41,762] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.740059619783689
[2022-12-07 00:55:41,763] [INFO] [runner_train_mujoco] Average state value: 0.4324785558680693
[2022-12-07 00:55:41,763] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 00:55:41,819] [INFO] [controller] EPOCH 1 loss ppo:  -0.01169, loss val: 0.03042
[2022-12-07 00:55:41,867] [INFO] [controller] EPOCH 2 loss ppo:  -0.02535, loss val: 0.03038
[2022-12-07 00:55:41,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.03685, loss val: 0.03019
[2022-12-07 00:55:41,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.05004, loss val: 0.03053
[2022-12-07 00:55:41,984] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:55:42,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:55:42,195] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:55:49,030] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:55:56,213] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:56:03,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:56:10,376] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:56:17,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:56:24,026] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:56:30,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:56:37,766] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:56:44,371] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:56:51,365] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.948149963167593
[2022-12-07 00:56:51,365] [INFO] [runner_train_mujoco] Average state value: 0.41832674325754243
[2022-12-07 00:56:51,366] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 00:56:51,423] [INFO] [controller] EPOCH 1 loss ppo:  -0.01168, loss val: 0.05402
[2022-12-07 00:56:51,486] [INFO] [controller] EPOCH 2 loss ppo:  -0.02630, loss val: 0.05397
[2022-12-07 00:56:51,540] [INFO] [controller] EPOCH 3 loss ppo:  -0.04070, loss val: 0.05385
[2022-12-07 00:56:51,590] [INFO] [controller] EPOCH 4 loss ppo:  -0.05094, loss val: 0.05380
[2022-12-07 00:56:51,602] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:56:51,825] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:56:51,825] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:56:58,620] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:57:06,390] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:57:13,843] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:57:21,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:57:29,019] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:57:35,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:57:42,600] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:57:49,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:57:56,114] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:58:02,656] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9305540169484328
[2022-12-07 00:58:02,656] [INFO] [runner_train_mujoco] Average state value: 0.42382407450924314
[2022-12-07 00:58:02,656] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 00:58:02,727] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.04884
[2022-12-07 00:58:02,778] [INFO] [controller] EPOCH 2 loss ppo:  -0.02499, loss val: 0.04794
[2022-12-07 00:58:02,833] [INFO] [controller] EPOCH 3 loss ppo:  -0.03696, loss val: 0.04713
[2022-12-07 00:58:02,904] [INFO] [controller] EPOCH 4 loss ppo:  -0.04855, loss val: 0.04660
[2022-12-07 00:58:02,915] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:58:03,122] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:58:03,123] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:58:09,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:58:16,932] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:58:23,543] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:58:30,013] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:58:36,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:58:43,067] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:58:49,774] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:58:56,465] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:59:03,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:59:09,593] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.113400376938733
[2022-12-07 00:59:09,593] [INFO] [runner_train_mujoco] Average state value: 0.46407736486196516
[2022-12-07 00:59:09,593] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 00:59:09,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.03877
[2022-12-07 00:59:09,700] [INFO] [controller] EPOCH 2 loss ppo:  -0.02442, loss val: 0.03982
[2022-12-07 00:59:09,748] [INFO] [controller] EPOCH 3 loss ppo:  -0.03380, loss val: 0.03989
[2022-12-07 00:59:09,800] [INFO] [controller] EPOCH 4 loss ppo:  -0.04274, loss val: 0.03929
[2022-12-07 00:59:09,811] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:59:10,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:59:10,011] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:59:16,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:59:23,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:59:29,579] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:59:36,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:59:43,714] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:59:50,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:59:56,486] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:00:02,895] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:00:09,298] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:00:15,504] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4013119073777824
[2022-12-07 01:00:15,504] [INFO] [runner_train_mujoco] Average state value: 0.47163572195172315
[2022-12-07 01:00:15,504] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 01:00:15,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01122, loss val: 0.03926
[2022-12-07 01:00:15,612] [INFO] [controller] EPOCH 2 loss ppo:  -0.02316, loss val: 0.03887
[2022-12-07 01:00:15,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.03641, loss val: 0.03874
[2022-12-07 01:00:15,723] [INFO] [controller] EPOCH 4 loss ppo:  -0.04888, loss val: 0.03867
[2022-12-07 01:00:15,733] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:00:15,939] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:00:15,940] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:00:22,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:00:28,328] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:00:34,765] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:00:41,059] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:00:47,584] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:00:53,580] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:00:59,726] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:01:05,728] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:01:12,014] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:01:18,385] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8779787836046804
[2022-12-07 01:01:18,385] [INFO] [runner_train_mujoco] Average state value: 0.4618407588501771
[2022-12-07 01:01:18,385] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 01:01:18,454] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.04871
[2022-12-07 01:01:18,504] [INFO] [controller] EPOCH 2 loss ppo:  -0.02184, loss val: 0.04424
[2022-12-07 01:01:18,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.02909, loss val: 0.04307
[2022-12-07 01:01:18,604] [INFO] [controller] EPOCH 4 loss ppo:  -0.04089, loss val: 0.04454
[2022-12-07 01:01:18,619] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:01:18,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:01:18,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:01:24,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:01:30,990] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:01:36,989] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:01:42,625] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:01:48,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:01:54,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:02:00,301] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:02:06,149] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:02:12,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:02:18,785] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.57987534020954
[2022-12-07 01:02:18,786] [INFO] [runner_train_mujoco] Average state value: 0.4850444147090117
[2022-12-07 01:02:18,786] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 01:02:18,854] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.03148
[2022-12-07 01:02:18,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.02146, loss val: 0.03232
[2022-12-07 01:02:18,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.03323, loss val: 0.03501
[2022-12-07 01:02:19,006] [INFO] [controller] EPOCH 4 loss ppo:  -0.04614, loss val: 0.03255
[2022-12-07 01:02:19,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:02:19,203] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:02:19,204] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:02:25,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:02:31,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:02:37,635] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:02:43,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:02:49,543] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:02:55,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:03:01,619] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:03:08,106] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:03:14,127] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:03:20,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2086819813404235
[2022-12-07 01:03:20,285] [INFO] [runner_train_mujoco] Average state value: 0.47520585960025585
[2022-12-07 01:03:20,285] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 01:03:20,338] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.05772
[2022-12-07 01:03:20,395] [INFO] [controller] EPOCH 2 loss ppo:  -0.02468, loss val: 0.05866
[2022-12-07 01:03:20,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.03317, loss val: 0.05812
[2022-12-07 01:03:20,485] [INFO] [controller] EPOCH 4 loss ppo:  -0.04294, loss val: 0.05628
[2022-12-07 01:03:20,495] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:03:20,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:03:20,679] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:03:26,916] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:03:33,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:03:39,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:03:44,745] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:03:50,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:03:56,708] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:04:03,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:04:09,402] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:04:15,753] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:04:22,064] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5610005208487054
[2022-12-07 01:04:22,064] [INFO] [runner_train_mujoco] Average state value: 0.4918964456294974
[2022-12-07 01:04:22,064] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 01:04:22,123] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.04917
[2022-12-07 01:04:22,169] [INFO] [controller] EPOCH 2 loss ppo:  -0.02222, loss val: 0.05414
[2022-12-07 01:04:22,216] [INFO] [controller] EPOCH 3 loss ppo:  -0.03004, loss val: 0.05062
[2022-12-07 01:04:22,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.04145, loss val: 0.04964
[2022-12-07 01:04:22,274] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:04:22,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:04:22,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:04:28,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:04:34,484] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:04:40,216] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:04:45,819] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:04:51,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:04:57,568] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:05:03,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:05:09,523] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:05:15,328] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:05:22,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3455195792942334
[2022-12-07 01:05:22,420] [INFO] [runner_train_mujoco] Average state value: 0.5162857181442281
[2022-12-07 01:05:22,420] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 01:05:22,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04245
[2022-12-07 01:05:22,526] [INFO] [controller] EPOCH 2 loss ppo:  -0.02186, loss val: 0.04246
[2022-12-07 01:05:22,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.03105, loss val: 0.04374
[2022-12-07 01:05:22,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.03764, loss val: 0.04402
[2022-12-07 01:05:22,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:05:22,826] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:05:22,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:05:28,845] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:05:35,284] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:05:41,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:05:47,847] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:05:54,092] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:06:00,167] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:06:06,343] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:06:12,417] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:06:18,840] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:06:25,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7175875767736075
[2022-12-07 01:06:25,257] [INFO] [runner_train_mujoco] Average state value: 0.534167787293593
[2022-12-07 01:06:25,257] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 01:06:25,327] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.05072
[2022-12-07 01:06:25,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.01858, loss val: 0.05086
[2022-12-07 01:06:25,527] [INFO] [controller] EPOCH 3 loss ppo:  -0.02782, loss val: 0.05414
[2022-12-07 01:06:25,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.03446, loss val: 0.04817
[2022-12-07 01:06:25,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:06:25,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:06:25,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:06:32,063] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:06:38,879] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:06:45,427] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:06:52,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:06:59,212] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:07:06,451] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:07:12,651] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:07:19,091] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:07:25,785] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:07:31,723] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.829725577373074
[2022-12-07 01:07:31,723] [INFO] [runner_train_mujoco] Average state value: 0.5252809797326724
[2022-12-07 01:07:31,723] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 01:07:31,780] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.04157
[2022-12-07 01:07:31,826] [INFO] [controller] EPOCH 2 loss ppo:  -0.02070, loss val: 0.03956
[2022-12-07 01:07:31,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.02748, loss val: 0.03947
[2022-12-07 01:07:31,913] [INFO] [controller] EPOCH 4 loss ppo:  -0.03733, loss val: 0.03868
[2022-12-07 01:07:31,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:07:32,100] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:07:32,100] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:07:37,839] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:07:43,803] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:07:49,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:07:55,078] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:08:01,140] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:08:06,726] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:08:12,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:08:18,705] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:08:24,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:08:30,458] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.657445789760056
[2022-12-07 01:08:30,459] [INFO] [runner_train_mujoco] Average state value: 0.49034972830613455
[2022-12-07 01:08:30,459] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 01:08:30,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.03091
[2022-12-07 01:08:30,563] [INFO] [controller] EPOCH 2 loss ppo:  -0.02270, loss val: 0.03098
[2022-12-07 01:08:30,608] [INFO] [controller] EPOCH 3 loss ppo:  -0.02455, loss val: 0.03131
[2022-12-07 01:08:30,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.03346, loss val: 0.03172
[2022-12-07 01:08:30,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:08:30,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:08:30,842] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:08:36,617] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:08:42,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:08:48,711] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:08:54,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:09:00,607] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:09:06,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:09:12,593] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:09:18,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:09:23,765] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:09:29,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.300687230327136
[2022-12-07 01:09:29,329] [INFO] [runner_train_mujoco] Average state value: 0.4772804443836212
[2022-12-07 01:09:29,329] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 01:09:29,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.03859
[2022-12-07 01:09:29,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.01947, loss val: 0.03795
[2022-12-07 01:09:29,521] [INFO] [controller] EPOCH 3 loss ppo:  -0.02579, loss val: 0.03835
[2022-12-07 01:09:29,579] [INFO] [controller] EPOCH 4 loss ppo:  -0.03460, loss val: 0.03708
[2022-12-07 01:09:29,589] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:09:29,793] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:09:29,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:09:36,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:09:42,236] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:09:48,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:09:54,515] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:10:00,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:10:06,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:10:12,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:10:18,063] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:10:23,855] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:10:29,692] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.795352622967487
[2022-12-07 01:10:29,693] [INFO] [runner_train_mujoco] Average state value: 0.46132954339683047
[2022-12-07 01:10:29,693] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 01:10:29,756] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.04253
[2022-12-07 01:10:29,805] [INFO] [controller] EPOCH 2 loss ppo:  -0.02025, loss val: 0.04248
[2022-12-07 01:10:29,853] [INFO] [controller] EPOCH 3 loss ppo:  -0.02621, loss val: 0.04092
[2022-12-07 01:10:29,906] [INFO] [controller] EPOCH 4 loss ppo:  -0.03526, loss val: 0.04113
[2022-12-07 01:10:29,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:10:30,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:10:30,099] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:10:36,120] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:10:42,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:10:48,311] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:10:54,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:11:00,238] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:11:06,261] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:11:12,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:11:18,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:11:24,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:11:30,546] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3549606486639214
[2022-12-07 01:11:30,547] [INFO] [runner_train_mujoco] Average state value: 0.44862666922559347
[2022-12-07 01:11:30,547] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 01:11:30,645] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.05672
[2022-12-07 01:11:30,700] [INFO] [controller] EPOCH 2 loss ppo:  -0.01745, loss val: 0.05697
[2022-12-07 01:11:30,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.02307, loss val: 0.05653
[2022-12-07 01:11:30,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.03189, loss val: 0.05641
[2022-12-07 01:11:30,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:11:31,009] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:11:31,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:11:37,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:11:43,728] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:11:49,807] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:11:56,006] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:12:01,731] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:12:07,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:12:13,983] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:12:20,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:12:26,313] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:12:32,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.221570552557126
[2022-12-07 01:12:32,148] [INFO] [runner_train_mujoco] Average state value: 0.4595626231580973
[2022-12-07 01:12:32,148] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 01:12:32,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.04833
[2022-12-07 01:12:32,259] [INFO] [controller] EPOCH 2 loss ppo:  -0.01955, loss val: 0.04814
[2022-12-07 01:12:32,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.02549, loss val: 0.04798
[2022-12-07 01:12:32,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.03149, loss val: 0.04895
[2022-12-07 01:12:32,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:12:32,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:12:32,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:12:38,306] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:12:43,938] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:12:50,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:12:55,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:13:01,714] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:13:08,074] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:13:14,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:13:20,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:13:26,574] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:13:32,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9047759473518466
[2022-12-07 01:13:32,477] [INFO] [runner_train_mujoco] Average state value: 0.4991328205168248
[2022-12-07 01:13:32,477] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 01:13:32,657] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.03673
[2022-12-07 01:13:32,731] [INFO] [controller] EPOCH 2 loss ppo:  -0.01647, loss val: 0.03770
[2022-12-07 01:13:32,780] [INFO] [controller] EPOCH 3 loss ppo:  -0.02447, loss val: 0.03635
[2022-12-07 01:13:32,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.03353, loss val: 0.03644
[2022-12-07 01:13:32,854] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:13:33,047] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:13:33,047] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:13:38,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:13:44,760] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:13:50,355] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:13:56,387] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:14:02,558] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:14:08,437] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:14:14,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:14:20,059] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:14:26,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:14:32,037] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.733351914402326
[2022-12-07 01:14:32,038] [INFO] [runner_train_mujoco] Average state value: 0.47979930635790036
[2022-12-07 01:14:32,038] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 01:14:32,091] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.04474
[2022-12-07 01:14:32,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.01593, loss val: 0.04604
[2022-12-07 01:14:32,188] [INFO] [controller] EPOCH 3 loss ppo:  -0.02179, loss val: 0.04520
[2022-12-07 01:14:32,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.02761, loss val: 0.04452
[2022-12-07 01:14:32,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:14:32,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:14:32,455] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:14:38,461] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:14:44,643] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:14:50,557] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:14:56,469] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:15:02,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:15:08,592] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:15:14,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:15:20,233] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:15:26,236] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:15:32,154] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4443792694940045
[2022-12-07 01:15:32,154] [INFO] [runner_train_mujoco] Average state value: 0.48680394498383006
[2022-12-07 01:15:32,154] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 01:15:32,212] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.04385
[2022-12-07 01:15:32,283] [INFO] [controller] EPOCH 2 loss ppo:  -0.01600, loss val: 0.04483
[2022-12-07 01:15:32,360] [INFO] [controller] EPOCH 3 loss ppo:  -0.02192, loss val: 0.04366
[2022-12-07 01:15:32,418] [INFO] [controller] EPOCH 4 loss ppo:  -0.02788, loss val: 0.04356
[2022-12-07 01:15:32,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:15:32,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:15:32,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:15:39,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:15:45,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:15:51,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:15:57,357] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:16:03,455] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:16:09,860] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:16:16,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:16:22,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:16:28,068] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:16:34,166] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0886639171923145
[2022-12-07 01:16:34,167] [INFO] [runner_train_mujoco] Average state value: 0.47510273267204567
[2022-12-07 01:16:34,167] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 01:16:34,228] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.05363
[2022-12-07 01:16:34,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.01420, loss val: 0.05455
[2022-12-07 01:16:34,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.01814, loss val: 0.05448
[2022-12-07 01:16:34,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.02315, loss val: 0.05347
[2022-12-07 01:16:34,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:16:34,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:16:34,567] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:16:40,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:16:46,884] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:16:52,964] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:16:58,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:17:04,557] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:17:10,581] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:17:16,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:17:22,372] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:17:28,040] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:17:33,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7035381991673795
[2022-12-07 01:17:33,808] [INFO] [runner_train_mujoco] Average state value: 0.4869882609533767
[2022-12-07 01:17:33,808] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 01:17:33,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.03956
[2022-12-07 01:17:33,937] [INFO] [controller] EPOCH 2 loss ppo:  -0.01429, loss val: 0.03969
[2022-12-07 01:17:34,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.01718, loss val: 0.03948
[2022-12-07 01:17:34,258] [INFO] [controller] EPOCH 4 loss ppo:  -0.02093, loss val: 0.03947
[2022-12-07 01:17:34,271] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:17:34,478] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:17:34,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:17:40,992] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:17:47,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:17:53,287] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:17:59,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:18:05,089] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:18:11,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:18:17,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:18:23,775] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:18:29,833] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:18:35,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.010030209796651
[2022-12-07 01:18:35,738] [INFO] [runner_train_mujoco] Average state value: 0.4942851276199024
[2022-12-07 01:18:35,738] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 01:18:35,794] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.03256
[2022-12-07 01:18:35,842] [INFO] [controller] EPOCH 2 loss ppo:  -0.01328, loss val: 0.03172
[2022-12-07 01:18:35,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.01482, loss val: 0.03300
[2022-12-07 01:18:35,950] [INFO] [controller] EPOCH 4 loss ppo:  -0.01691, loss val: 0.03395
[2022-12-07 01:18:35,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:18:36,083] [INFO] [optimize] Finished learning.
