[2022-12-07 06:11:44,170] [INFO] [optimize] Starting learning
[2022-12-07 06:11:44,180] [INFO] [optimize] Starting learning process..
[2022-12-07 06:11:44,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:11:44,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:11:51,781] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:11:57,680] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:12:03,480] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:12:09,605] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:12:15,233] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:12:21,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:12:27,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:12:33,213] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:12:38,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:12:44,845] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9721057635303204
[2022-12-07 06:12:44,845] [INFO] [runner_train_mujoco] Average state value: 0.1559881882642706
[2022-12-07 06:12:44,846] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 06:12:44,922] [INFO] [controller] EPOCH 1 loss ppo:  -0.01045, loss val: 0.26739
[2022-12-07 06:12:44,981] [INFO] [controller] EPOCH 2 loss ppo:  -0.03968, loss val: 0.23541
[2022-12-07 06:12:45,039] [INFO] [controller] EPOCH 3 loss ppo:  -0.05266, loss val: 0.20745
[2022-12-07 06:12:45,098] [INFO] [controller] EPOCH 4 loss ppo:  -0.06110, loss val: 0.17684
[2022-12-07 06:12:45,110] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:12:45,353] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:12:45,354] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:12:51,447] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:12:57,381] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:13:03,423] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:13:09,517] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:13:15,026] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:13:21,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:13:27,399] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:13:33,151] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:13:38,969] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:13:44,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9830283993563045
[2022-12-07 06:13:44,515] [INFO] [runner_train_mujoco] Average state value: 0.3130005335708459
[2022-12-07 06:13:44,515] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 06:13:44,575] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.15701
[2022-12-07 06:13:44,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.03744, loss val: 0.14078
[2022-12-07 06:13:44,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.05088, loss val: 0.12694
[2022-12-07 06:13:44,710] [INFO] [controller] EPOCH 4 loss ppo:  -0.06089, loss val: 0.11237
[2022-12-07 06:13:44,720] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:13:44,906] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:13:44,906] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:13:50,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:13:56,237] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:14:02,105] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:14:08,174] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:14:13,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:14:19,228] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:14:24,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:14:30,153] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:14:36,409] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:14:41,970] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0481638792492904
[2022-12-07 06:14:41,970] [INFO] [runner_train_mujoco] Average state value: 0.4377385387923568
[2022-12-07 06:14:41,970] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 06:14:42,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.10883
[2022-12-07 06:14:42,079] [INFO] [controller] EPOCH 2 loss ppo:  -0.03970, loss val: 0.09960
[2022-12-07 06:14:42,125] [INFO] [controller] EPOCH 3 loss ppo:  -0.05261, loss val: 0.09358
[2022-12-07 06:14:42,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.05840, loss val: 0.08606
[2022-12-07 06:14:42,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:14:42,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:14:42,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:14:48,798] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:14:54,449] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:15:00,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:15:06,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:15:11,915] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:15:17,599] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:15:22,981] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:15:29,087] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:15:34,998] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:15:40,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.022250808263323
[2022-12-07 06:15:40,591] [INFO] [runner_train_mujoco] Average state value: 0.5542171484269202
[2022-12-07 06:15:40,591] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 06:15:40,645] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.07837
[2022-12-07 06:15:40,697] [INFO] [controller] EPOCH 2 loss ppo:  -0.04042, loss val: 0.07433
[2022-12-07 06:15:40,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.05447, loss val: 0.07065
[2022-12-07 06:15:40,814] [INFO] [controller] EPOCH 4 loss ppo:  -0.06441, loss val: 0.06533
[2022-12-07 06:15:40,825] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:15:41,009] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:15:41,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:15:47,440] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:15:53,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:15:58,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:16:04,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:16:10,393] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:16:16,114] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:16:21,907] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:16:27,336] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:16:33,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:16:39,481] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9434331006308586
[2022-12-07 06:16:39,482] [INFO] [runner_train_mujoco] Average state value: 0.5492421455557148
[2022-12-07 06:16:39,482] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 06:16:39,536] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.05229
[2022-12-07 06:16:39,586] [INFO] [controller] EPOCH 2 loss ppo:  -0.03443, loss val: 0.05429
[2022-12-07 06:16:39,637] [INFO] [controller] EPOCH 3 loss ppo:  -0.04647, loss val: 0.04990
[2022-12-07 06:16:39,683] [INFO] [controller] EPOCH 4 loss ppo:  -0.05263, loss val: 0.04801
[2022-12-07 06:16:39,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:16:39,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:16:39,875] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:16:45,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:16:51,517] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:16:56,932] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:17:02,532] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:17:07,960] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:17:13,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:17:19,554] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:17:25,367] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:17:31,396] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:17:37,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0821042808593933
[2022-12-07 06:17:37,066] [INFO] [runner_train_mujoco] Average state value: 0.46721817965805534
[2022-12-07 06:17:37,066] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 06:17:37,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.08572
[2022-12-07 06:17:37,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.03693, loss val: 0.08304
[2022-12-07 06:17:37,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.05169, loss val: 0.07909
[2022-12-07 06:17:37,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.05923, loss val: 0.07595
[2022-12-07 06:17:37,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:17:37,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:17:37,465] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:17:43,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:17:49,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:17:54,862] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:18:00,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:18:06,415] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:18:12,279] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:18:18,202] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:18:23,440] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:18:28,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:18:34,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0260391713260781
[2022-12-07 06:18:34,549] [INFO] [runner_train_mujoco] Average state value: 0.4907201462835073
[2022-12-07 06:18:34,549] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 06:18:34,614] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.04690
[2022-12-07 06:18:34,659] [INFO] [controller] EPOCH 2 loss ppo:  -0.03660, loss val: 0.04486
[2022-12-07 06:18:34,716] [INFO] [controller] EPOCH 3 loss ppo:  -0.04701, loss val: 0.04862
[2022-12-07 06:18:34,762] [INFO] [controller] EPOCH 4 loss ppo:  -0.05456, loss val: 0.04261
[2022-12-07 06:18:34,772] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:18:34,951] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:18:34,951] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:18:40,723] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:18:46,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:18:52,707] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:18:58,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:19:04,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:19:10,302] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:19:15,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:19:21,961] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:19:28,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:19:34,114] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9328687518844376
[2022-12-07 06:19:34,115] [INFO] [runner_train_mujoco] Average state value: 0.4770878067562977
[2022-12-07 06:19:34,115] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 06:19:34,166] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.05269
[2022-12-07 06:19:34,208] [INFO] [controller] EPOCH 2 loss ppo:  -0.03347, loss val: 0.05286
[2022-12-07 06:19:34,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.04809, loss val: 0.05434
[2022-12-07 06:19:34,292] [INFO] [controller] EPOCH 4 loss ppo:  -0.05513, loss val: 0.05441
[2022-12-07 06:19:34,301] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:19:34,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:19:34,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:19:40,487] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:19:46,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:19:52,580] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:19:58,348] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:20:04,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:20:10,202] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:20:16,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:20:21,723] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:20:26,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:20:32,592] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0741323293369107
[2022-12-07 06:20:32,592] [INFO] [runner_train_mujoco] Average state value: 0.4728938248275469
[2022-12-07 06:20:32,592] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 06:20:32,659] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04284
[2022-12-07 06:20:32,706] [INFO] [controller] EPOCH 2 loss ppo:  -0.03524, loss val: 0.04273
[2022-12-07 06:20:32,761] [INFO] [controller] EPOCH 3 loss ppo:  -0.04806, loss val: 0.04052
[2022-12-07 06:20:32,832] [INFO] [controller] EPOCH 4 loss ppo:  -0.05314, loss val: 0.03908
[2022-12-07 06:20:32,843] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:20:33,030] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:20:33,030] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:20:38,483] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:20:44,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:20:50,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:20:56,156] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:21:02,078] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:21:07,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:21:12,789] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:21:18,546] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:21:24,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:21:30,629] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3571725284212
[2022-12-07 06:21:30,629] [INFO] [runner_train_mujoco] Average state value: 0.4811818076924731
[2022-12-07 06:21:30,629] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 06:21:30,682] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.05839
[2022-12-07 06:21:30,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.03578, loss val: 0.05805
[2022-12-07 06:21:30,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.05178, loss val: 0.05731
[2022-12-07 06:21:30,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.05932, loss val: 0.05715
[2022-12-07 06:21:30,824] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:21:31,006] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:21:31,006] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:21:37,142] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:21:43,390] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:21:48,975] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:21:54,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:22:00,028] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:22:05,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:22:11,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:22:18,204] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:22:24,219] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:22:30,159] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.32136784625938
[2022-12-07 06:22:30,159] [INFO] [runner_train_mujoco] Average state value: 0.5192732518911362
[2022-12-07 06:22:30,159] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 06:22:30,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.03922
[2022-12-07 06:22:30,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.03754, loss val: 0.03838
[2022-12-07 06:22:30,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.05180, loss val: 0.04007
[2022-12-07 06:22:30,394] [INFO] [controller] EPOCH 4 loss ppo:  -0.05873, loss val: 0.03719
[2022-12-07 06:22:30,405] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:22:30,584] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:22:30,584] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:22:36,296] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:22:41,938] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:22:48,405] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:22:54,388] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:23:00,332] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:23:05,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:23:11,222] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:23:17,071] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:23:22,813] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:23:28,537] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2435000167478418
[2022-12-07 06:23:28,537] [INFO] [runner_train_mujoco] Average state value: 0.5386172682046889
[2022-12-07 06:23:28,537] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 06:23:28,596] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.03356
[2022-12-07 06:23:28,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.03765, loss val: 0.03212
[2022-12-07 06:23:28,807] [INFO] [controller] EPOCH 3 loss ppo:  -0.05196, loss val: 0.03215
[2022-12-07 06:23:28,855] [INFO] [controller] EPOCH 4 loss ppo:  -0.05844, loss val: 0.03032
[2022-12-07 06:23:28,864] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:23:29,042] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:23:29,043] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:23:34,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:23:40,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:23:47,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:23:52,959] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:23:58,843] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:24:04,610] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:24:10,778] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:24:16,814] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:24:22,795] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:24:27,830] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2628565721813632
[2022-12-07 06:24:27,830] [INFO] [runner_train_mujoco] Average state value: 0.5091327229142188
[2022-12-07 06:24:27,830] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 06:24:27,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.04008
[2022-12-07 06:24:27,946] [INFO] [controller] EPOCH 2 loss ppo:  -0.03771, loss val: 0.03989
[2022-12-07 06:24:27,998] [INFO] [controller] EPOCH 3 loss ppo:  -0.04670, loss val: 0.04024
[2022-12-07 06:24:28,062] [INFO] [controller] EPOCH 4 loss ppo:  -0.05475, loss val: 0.04034
[2022-12-07 06:24:28,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:24:28,260] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:24:28,260] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:24:33,881] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:24:39,547] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:24:44,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:24:50,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:24:56,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:25:02,850] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:25:08,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:25:14,121] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:25:19,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:25:25,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4848365517067967
[2022-12-07 06:25:25,444] [INFO] [runner_train_mujoco] Average state value: 0.4814126770297687
[2022-12-07 06:25:25,444] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 06:25:25,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01457, loss val: 0.03736
[2022-12-07 06:25:25,534] [INFO] [controller] EPOCH 2 loss ppo:  -0.03980, loss val: 0.03752
[2022-12-07 06:25:25,573] [INFO] [controller] EPOCH 3 loss ppo:  -0.05358, loss val: 0.03595
[2022-12-07 06:25:25,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.06243, loss val: 0.03527
[2022-12-07 06:25:25,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:25:25,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:25:25,800] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:25:31,739] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:25:37,588] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:25:43,374] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:25:49,097] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:25:54,917] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:26:00,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:26:06,162] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:26:11,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:26:17,356] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:26:23,345] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.519201694740001
[2022-12-07 06:26:23,345] [INFO] [runner_train_mujoco] Average state value: 0.43538988641897836
[2022-12-07 06:26:23,345] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 06:26:23,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01540, loss val: 0.04267
[2022-12-07 06:26:23,455] [INFO] [controller] EPOCH 2 loss ppo:  -0.04053, loss val: 0.04159
[2022-12-07 06:26:23,516] [INFO] [controller] EPOCH 3 loss ppo:  -0.04948, loss val: 0.04162
[2022-12-07 06:26:23,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.06019, loss val: 0.04159
[2022-12-07 06:26:23,584] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:26:23,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:26:23,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:26:29,649] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:26:35,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:26:42,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:26:48,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:26:54,362] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:00,224] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:27:06,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:27:11,925] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:27:17,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:27:23,092] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.491032259104634
[2022-12-07 06:27:23,092] [INFO] [runner_train_mujoco] Average state value: 0.40926557152469945
[2022-12-07 06:27:23,092] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 06:27:23,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.02700
[2022-12-07 06:27:23,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.04197, loss val: 0.02772
[2022-12-07 06:27:23,236] [INFO] [controller] EPOCH 3 loss ppo:  -0.05385, loss val: 0.02674
[2022-12-07 06:27:23,288] [INFO] [controller] EPOCH 4 loss ppo:  -0.06053, loss val: 0.02687
[2022-12-07 06:27:23,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:27:23,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:27:23,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:27:29,149] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:27:35,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:27:40,991] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:27:46,781] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:27:52,509] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:58,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:28:04,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:28:09,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:28:15,556] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:28:21,728] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.614586672024639
[2022-12-07 06:28:21,729] [INFO] [runner_train_mujoco] Average state value: 0.34889970533798137
[2022-12-07 06:28:21,729] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 06:28:21,789] [INFO] [controller] EPOCH 1 loss ppo:  -0.01606, loss val: 0.10000
[2022-12-07 06:28:21,845] [INFO] [controller] EPOCH 2 loss ppo:  -0.03472, loss val: 0.09964
[2022-12-07 06:28:21,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.04703, loss val: 0.09340
[2022-12-07 06:28:21,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.05574, loss val: 0.08788
[2022-12-07 06:28:21,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:28:22,131] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:28:22,131] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:28:27,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:28:33,563] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:28:38,784] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:28:44,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:28:49,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:28:55,347] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:29:01,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:29:06,818] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:29:12,700] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:29:18,800] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9368935142912918
[2022-12-07 06:29:18,800] [INFO] [runner_train_mujoco] Average state value: 0.4541740631659826
[2022-12-07 06:29:18,800] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 06:29:18,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.04287
[2022-12-07 06:29:18,908] [INFO] [controller] EPOCH 2 loss ppo:  -0.03884, loss val: 0.04062
[2022-12-07 06:29:18,958] [INFO] [controller] EPOCH 3 loss ppo:  -0.05369, loss val: 0.03942
[2022-12-07 06:29:19,008] [INFO] [controller] EPOCH 4 loss ppo:  -0.06683, loss val: 0.04006
[2022-12-07 06:29:19,020] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:29:19,199] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:29:19,199] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:29:24,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:29:30,676] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:29:36,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:29:42,186] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:29:47,919] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:29:53,451] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:29:59,232] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:30:06,263] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:30:12,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:30:18,565] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8935273788646718
[2022-12-07 06:30:18,565] [INFO] [runner_train_mujoco] Average state value: 0.531152641137441
[2022-12-07 06:30:18,565] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 06:30:18,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.05312
[2022-12-07 06:30:18,688] [INFO] [controller] EPOCH 2 loss ppo:  -0.03740, loss val: 0.05256
[2022-12-07 06:30:18,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.05222, loss val: 0.05316
[2022-12-07 06:30:18,836] [INFO] [controller] EPOCH 4 loss ppo:  -0.06190, loss val: 0.04931
[2022-12-07 06:30:18,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:30:19,046] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:30:19,047] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:30:24,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:30:30,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:30:36,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:30:43,068] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:30:49,114] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:30:55,224] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:31:00,614] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:31:06,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:31:12,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:31:17,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9918527025184332
[2022-12-07 06:31:17,809] [INFO] [runner_train_mujoco] Average state value: 0.5135118257800738
[2022-12-07 06:31:17,809] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 06:31:17,864] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04542
[2022-12-07 06:31:17,908] [INFO] [controller] EPOCH 2 loss ppo:  -0.03896, loss val: 0.04514
[2022-12-07 06:31:17,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.05145, loss val: 0.04548
[2022-12-07 06:31:18,002] [INFO] [controller] EPOCH 4 loss ppo:  -0.06015, loss val: 0.04590
[2022-12-07 06:31:18,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:31:18,180] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:31:18,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:31:23,519] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:31:29,133] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:31:35,216] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:31:40,717] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:31:46,568] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:31:51,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:31:56,979] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:32:02,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:32:08,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:32:14,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.254671251986656
[2022-12-07 06:32:14,340] [INFO] [runner_train_mujoco] Average state value: 0.47234810414661965
[2022-12-07 06:32:14,340] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 06:32:14,399] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.04578
[2022-12-07 06:32:14,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.03620, loss val: 0.04796
[2022-12-07 06:32:14,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.04701, loss val: 0.04500
[2022-12-07 06:32:14,554] [INFO] [controller] EPOCH 4 loss ppo:  -0.05654, loss val: 0.04689
[2022-12-07 06:32:14,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:32:14,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:32:14,745] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:32:20,772] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:32:26,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:32:31,530] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:32:36,777] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:32:42,006] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:32:47,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:32:53,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:32:58,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:33:04,818] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:33:10,390] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.259118670365358
[2022-12-07 06:33:10,391] [INFO] [runner_train_mujoco] Average state value: 0.4993596262435118
[2022-12-07 06:33:10,391] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 06:33:10,445] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.05137
[2022-12-07 06:33:10,493] [INFO] [controller] EPOCH 2 loss ppo:  -0.03872, loss val: 0.05164
[2022-12-07 06:33:10,543] [INFO] [controller] EPOCH 3 loss ppo:  -0.05296, loss val: 0.05119
[2022-12-07 06:33:10,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.06174, loss val: 0.05063
[2022-12-07 06:33:10,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:33:10,782] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:33:10,782] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:33:16,449] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:33:22,827] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:33:27,958] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:33:34,047] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:33:39,904] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:33:45,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:33:50,735] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:33:56,279] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:34:01,928] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:34:07,496] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.168094446433524
[2022-12-07 06:34:07,497] [INFO] [runner_train_mujoco] Average state value: 0.4798600787321726
[2022-12-07 06:34:07,497] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 06:34:07,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.04367
[2022-12-07 06:34:07,592] [INFO] [controller] EPOCH 2 loss ppo:  -0.03709, loss val: 0.04412
[2022-12-07 06:34:07,636] [INFO] [controller] EPOCH 3 loss ppo:  -0.05290, loss val: 0.04401
[2022-12-07 06:34:07,684] [INFO] [controller] EPOCH 4 loss ppo:  -0.06598, loss val: 0.04211
[2022-12-07 06:34:07,693] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:34:07,869] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:34:07,869] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:34:13,775] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:34:19,608] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:34:25,743] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:34:31,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:34:36,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:34:42,122] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:34:47,850] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:34:53,338] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:34:58,937] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:35:04,361] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5214011510161383
[2022-12-07 06:35:04,362] [INFO] [runner_train_mujoco] Average state value: 0.482549886673689
[2022-12-07 06:35:04,362] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 06:35:04,417] [INFO] [controller] EPOCH 1 loss ppo:  -0.01496, loss val: 0.04999
[2022-12-07 06:35:04,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.03576, loss val: 0.05033
[2022-12-07 06:35:04,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.04722, loss val: 0.05010
[2022-12-07 06:35:04,557] [INFO] [controller] EPOCH 4 loss ppo:  -0.05816, loss val: 0.04966
[2022-12-07 06:35:04,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:35:04,745] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:35:04,745] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:35:10,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:35:15,400] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:35:21,259] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:35:26,877] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:35:32,201] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:35:38,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:35:43,635] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:35:49,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:35:54,640] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:35:59,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.462228545601509
[2022-12-07 06:35:59,917] [INFO] [runner_train_mujoco] Average state value: 0.5180417541066805
[2022-12-07 06:35:59,918] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 06:35:59,969] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.02810
[2022-12-07 06:36:00,035] [INFO] [controller] EPOCH 2 loss ppo:  -0.03090, loss val: 0.02795
[2022-12-07 06:36:00,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.04351, loss val: 0.02750
[2022-12-07 06:36:00,210] [INFO] [controller] EPOCH 4 loss ppo:  -0.05461, loss val: 0.02742
[2022-12-07 06:36:00,220] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:36:00,408] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:36:00,408] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:36:06,583] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:36:12,455] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:36:18,343] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:36:24,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:36:29,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:36:34,661] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:36:40,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:36:45,669] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:36:51,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:36:56,772] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6360894562184924
[2022-12-07 06:36:56,773] [INFO] [runner_train_mujoco] Average state value: 0.5101855611304442
[2022-12-07 06:36:56,773] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 06:36:56,828] [INFO] [controller] EPOCH 1 loss ppo:  -0.01830, loss val: 0.03778
[2022-12-07 06:36:56,881] [INFO] [controller] EPOCH 2 loss ppo:  -0.03780, loss val: 0.03913
[2022-12-07 06:36:56,931] [INFO] [controller] EPOCH 3 loss ppo:  -0.04618, loss val: 0.03892
[2022-12-07 06:36:56,980] [INFO] [controller] EPOCH 4 loss ppo:  -0.05966, loss val: 0.03671
[2022-12-07 06:36:56,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:36:57,178] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:36:57,179] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:37:02,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:37:08,286] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:37:14,468] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:37:20,159] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:37:26,137] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:37:31,494] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:37:37,253] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:37:42,368] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:37:47,644] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:37:52,764] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.476183488013377
[2022-12-07 06:37:52,764] [INFO] [runner_train_mujoco] Average state value: 0.5049820878704389
[2022-12-07 06:37:52,764] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 06:37:52,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.04146
[2022-12-07 06:37:52,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.03262, loss val: 0.04151
[2022-12-07 06:37:52,922] [INFO] [controller] EPOCH 3 loss ppo:  -0.04795, loss val: 0.04120
[2022-12-07 06:37:52,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.05740, loss val: 0.04264
[2022-12-07 06:37:52,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:37:53,187] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:37:53,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:37:58,709] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:38:04,515] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:38:10,282] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:38:15,957] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:38:21,472] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:38:27,112] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:38:32,550] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:38:38,343] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:38:44,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:38:50,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5592664390330726
[2022-12-07 06:38:50,256] [INFO] [runner_train_mujoco] Average state value: 0.4676732259343067
[2022-12-07 06:38:50,257] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 06:38:50,306] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.05713
[2022-12-07 06:38:50,351] [INFO] [controller] EPOCH 2 loss ppo:  -0.03454, loss val: 0.05706
[2022-12-07 06:38:50,396] [INFO] [controller] EPOCH 3 loss ppo:  -0.05194, loss val: 0.05657
[2022-12-07 06:38:50,446] [INFO] [controller] EPOCH 4 loss ppo:  -0.06287, loss val: 0.05587
[2022-12-07 06:38:50,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:38:50,629] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:38:50,629] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:38:56,370] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:39:02,004] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:39:07,330] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:39:12,463] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:39:17,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:39:22,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:39:27,859] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:39:32,432] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:39:37,171] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:39:42,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7222965779467936
[2022-12-07 06:39:42,371] [INFO] [runner_train_mujoco] Average state value: 0.45395451597993564
[2022-12-07 06:39:42,371] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 06:39:42,423] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.06135
[2022-12-07 06:39:42,466] [INFO] [controller] EPOCH 2 loss ppo:  -0.02623, loss val: 0.05764
[2022-12-07 06:39:42,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.03587, loss val: 0.05421
[2022-12-07 06:39:42,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.04597, loss val: 0.05035
[2022-12-07 06:39:42,557] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:39:42,729] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:39:42,729] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:39:47,719] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:39:52,924] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:39:57,908] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:40:03,117] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:40:07,928] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:40:12,883] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:40:17,817] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:40:22,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:40:27,469] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:40:32,333] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8919526737784347
[2022-12-07 06:40:32,333] [INFO] [runner_train_mujoco] Average state value: 0.49525905195375286
[2022-12-07 06:40:32,334] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 06:40:32,377] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.03808
[2022-12-07 06:40:32,417] [INFO] [controller] EPOCH 2 loss ppo:  -0.03151, loss val: 0.03915
[2022-12-07 06:40:32,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.04440, loss val: 0.03998
[2022-12-07 06:40:32,501] [INFO] [controller] EPOCH 4 loss ppo:  -0.05897, loss val: 0.03827
[2022-12-07 06:40:32,509] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:40:32,681] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:40:32,682] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:40:37,787] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:40:42,828] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:40:47,660] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:40:52,595] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:40:57,624] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:41:02,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:41:07,569] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:41:12,703] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:41:17,585] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:41:22,215] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0496574835363295
[2022-12-07 06:41:22,215] [INFO] [runner_train_mujoco] Average state value: 0.5502098259925843
[2022-12-07 06:41:22,216] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 06:41:22,260] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04460
[2022-12-07 06:41:22,300] [INFO] [controller] EPOCH 2 loss ppo:  -0.02824, loss val: 0.04415
[2022-12-07 06:41:22,337] [INFO] [controller] EPOCH 3 loss ppo:  -0.04170, loss val: 0.04252
[2022-12-07 06:41:22,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.05415, loss val: 0.04086
[2022-12-07 06:41:22,386] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:41:22,559] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:41:22,559] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:41:27,951] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:41:32,898] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:41:37,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:41:42,669] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:41:47,685] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:41:52,689] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:41:57,630] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:42:02,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:42:07,429] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:42:12,793] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1907346274315285
[2022-12-07 06:42:12,794] [INFO] [runner_train_mujoco] Average state value: 0.5221431107223035
[2022-12-07 06:42:12,794] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 06:42:12,843] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.04908
[2022-12-07 06:42:12,888] [INFO] [controller] EPOCH 2 loss ppo:  -0.03207, loss val: 0.04804
[2022-12-07 06:42:12,929] [INFO] [controller] EPOCH 3 loss ppo:  -0.04449, loss val: 0.04604
[2022-12-07 06:42:12,967] [INFO] [controller] EPOCH 4 loss ppo:  -0.05485, loss val: 0.04468
[2022-12-07 06:42:12,976] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:42:13,139] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:42:13,139] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:42:18,480] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:42:23,776] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:42:28,713] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:42:33,671] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:42:38,412] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:42:43,541] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:42:48,499] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:42:53,036] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:42:57,838] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:43:02,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3086026091404945
[2022-12-07 06:43:02,476] [INFO] [runner_train_mujoco] Average state value: 0.4543695448239644
[2022-12-07 06:43:02,476] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 06:43:02,575] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.04128
[2022-12-07 06:43:02,615] [INFO] [controller] EPOCH 2 loss ppo:  -0.03186, loss val: 0.04180
[2022-12-07 06:43:02,654] [INFO] [controller] EPOCH 3 loss ppo:  -0.04321, loss val: 0.03983
[2022-12-07 06:43:02,694] [INFO] [controller] EPOCH 4 loss ppo:  -0.05885, loss val: 0.03975
[2022-12-07 06:43:02,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:43:02,873] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:43:02,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:43:07,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:43:12,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:43:18,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:43:25,013] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:43:29,906] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:43:34,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:43:39,787] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:43:44,836] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:43:50,042] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:43:54,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.222411251798582
[2022-12-07 06:43:54,913] [INFO] [runner_train_mujoco] Average state value: 0.445517029205958
[2022-12-07 06:43:54,914] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 06:43:54,964] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.03685
[2022-12-07 06:43:55,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.03000, loss val: 0.03757
[2022-12-07 06:43:55,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.04310, loss val: 0.03807
[2022-12-07 06:43:55,101] [INFO] [controller] EPOCH 4 loss ppo:  -0.05255, loss val: 0.03759
[2022-12-07 06:43:55,110] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:43:55,285] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:43:55,285] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:44:00,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:44:05,644] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:44:10,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:44:15,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:44:20,019] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:44:25,103] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:44:29,833] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:44:35,437] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:44:40,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:44:45,246] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1721496370426747
[2022-12-07 06:44:45,246] [INFO] [runner_train_mujoco] Average state value: 0.44746498658259715
[2022-12-07 06:44:45,246] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 06:44:45,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04065
[2022-12-07 06:44:45,337] [INFO] [controller] EPOCH 2 loss ppo:  -0.02582, loss val: 0.03903
[2022-12-07 06:44:45,377] [INFO] [controller] EPOCH 3 loss ppo:  -0.04020, loss val: 0.03970
[2022-12-07 06:44:45,417] [INFO] [controller] EPOCH 4 loss ppo:  -0.05154, loss val: 0.03946
[2022-12-07 06:44:45,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:44:45,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:44:45,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:44:50,746] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:44:56,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:45:00,794] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:45:06,085] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:45:12,972] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:45:18,873] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:45:24,456] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:45:30,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:45:35,793] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:45:41,386] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.95580876352654
[2022-12-07 06:45:41,386] [INFO] [runner_train_mujoco] Average state value: 0.4473189142843087
[2022-12-07 06:45:41,386] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 06:45:41,448] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.04559
[2022-12-07 06:45:41,493] [INFO] [controller] EPOCH 2 loss ppo:  -0.02851, loss val: 0.04537
[2022-12-07 06:45:41,538] [INFO] [controller] EPOCH 3 loss ppo:  -0.03745, loss val: 0.04276
[2022-12-07 06:45:41,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.04987, loss val: 0.04068
[2022-12-07 06:45:41,592] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:45:41,767] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:45:41,767] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:45:48,222] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:45:53,408] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:45:58,999] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:46:04,620] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:46:10,143] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:46:15,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:46:21,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:46:27,553] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:46:32,831] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:46:38,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3341950612543165
[2022-12-07 06:46:38,304] [INFO] [runner_train_mujoco] Average state value: 0.47506669591118894
[2022-12-07 06:46:38,304] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 06:46:38,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01565, loss val: 0.04985
[2022-12-07 06:46:38,421] [INFO] [controller] EPOCH 2 loss ppo:  -0.03401, loss val: 0.05193
[2022-12-07 06:46:38,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.04589, loss val: 0.04949
[2022-12-07 06:46:38,519] [INFO] [controller] EPOCH 4 loss ppo:  -0.05567, loss val: 0.05004
[2022-12-07 06:46:38,530] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:46:38,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:46:38,717] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:46:44,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:46:50,316] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:46:56,223] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:47:03,751] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:47:10,603] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:47:16,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:47:23,171] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:47:29,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:47:36,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:47:43,127] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2810630663324725
[2022-12-07 06:47:43,128] [INFO] [runner_train_mujoco] Average state value: 0.5083516197080413
[2022-12-07 06:47:43,128] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 06:47:43,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04633
[2022-12-07 06:47:43,261] [INFO] [controller] EPOCH 2 loss ppo:  -0.02267, loss val: 0.04581
[2022-12-07 06:47:43,308] [INFO] [controller] EPOCH 3 loss ppo:  -0.03291, loss val: 0.04439
[2022-12-07 06:47:43,354] [INFO] [controller] EPOCH 4 loss ppo:  -0.04617, loss val: 0.04255
[2022-12-07 06:47:43,364] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:47:43,554] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:47:43,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:47:50,200] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:47:56,018] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:48:02,443] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:48:08,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:48:14,472] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:48:20,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:48:26,948] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:48:33,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:48:40,055] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:48:46,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.566916819204412
[2022-12-07 06:48:46,123] [INFO] [runner_train_mujoco] Average state value: 0.4798943055272102
[2022-12-07 06:48:46,123] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 06:48:46,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.01581, loss val: 0.04952
[2022-12-07 06:48:46,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.03234, loss val: 0.04793
[2022-12-07 06:48:46,280] [INFO] [controller] EPOCH 3 loss ppo:  -0.04470, loss val: 0.04523
[2022-12-07 06:48:46,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.05627, loss val: 0.04488
[2022-12-07 06:48:46,353] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:48:46,556] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:48:46,556] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:48:52,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:48:58,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:49:05,457] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:49:11,793] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:49:18,406] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:49:24,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:49:31,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:49:37,766] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:49:43,985] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:49:51,456] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3049173157065233
[2022-12-07 06:49:51,456] [INFO] [runner_train_mujoco] Average state value: 0.45051055345932645
[2022-12-07 06:49:51,456] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 06:49:51,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.04964
[2022-12-07 06:49:51,568] [INFO] [controller] EPOCH 2 loss ppo:  -0.02371, loss val: 0.04714
[2022-12-07 06:49:51,637] [INFO] [controller] EPOCH 3 loss ppo:  -0.02792, loss val: 0.04622
[2022-12-07 06:49:51,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.03716, loss val: 0.04495
[2022-12-07 06:49:51,699] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:49:51,889] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:49:51,890] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:49:58,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:50:04,503] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:50:10,619] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:50:16,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:50:22,368] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:50:28,791] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:50:35,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:50:41,266] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:50:47,444] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:50:53,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4897458115006863
[2022-12-07 06:50:53,562] [INFO] [runner_train_mujoco] Average state value: 0.463419375081857
[2022-12-07 06:50:53,562] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 06:50:53,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.04880
[2022-12-07 06:50:53,688] [INFO] [controller] EPOCH 2 loss ppo:  -0.02905, loss val: 0.04748
[2022-12-07 06:50:53,754] [INFO] [controller] EPOCH 3 loss ppo:  -0.03958, loss val: 0.04684
[2022-12-07 06:50:53,816] [INFO] [controller] EPOCH 4 loss ppo:  -0.04838, loss val: 0.04580
[2022-12-07 06:50:53,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:50:54,024] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:50:54,024] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:51:00,231] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:51:06,373] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:51:12,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:51:18,653] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:51:24,999] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:51:31,383] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:51:37,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:51:44,251] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:51:50,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:51:57,403] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4371933794923217
[2022-12-07 06:51:57,403] [INFO] [runner_train_mujoco] Average state value: 0.5023558451334635
[2022-12-07 06:51:57,403] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 06:51:57,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04166
[2022-12-07 06:51:57,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.02736, loss val: 0.04226
[2022-12-07 06:51:57,606] [INFO] [controller] EPOCH 3 loss ppo:  -0.03702, loss val: 0.04117
[2022-12-07 06:51:57,660] [INFO] [controller] EPOCH 4 loss ppo:  -0.04654, loss val: 0.04208
[2022-12-07 06:51:57,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:51:57,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:51:57,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:52:04,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:52:11,779] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:52:18,505] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:52:24,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:52:31,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:52:37,675] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:52:43,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:52:49,674] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:52:55,966] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:53:02,624] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.580200220135661
[2022-12-07 06:53:02,625] [INFO] [runner_train_mujoco] Average state value: 0.5239728871360422
[2022-12-07 06:53:02,625] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 06:53:02,702] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.03566
[2022-12-07 06:53:02,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.02773, loss val: 0.03694
[2022-12-07 06:53:02,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.03820, loss val: 0.03680
[2022-12-07 06:53:02,835] [INFO] [controller] EPOCH 4 loss ppo:  -0.04683, loss val: 0.03707
[2022-12-07 06:53:02,845] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:53:03,028] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:53:03,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:53:09,342] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:53:15,674] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:53:21,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:53:27,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:53:33,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:53:40,012] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:53:46,167] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:53:52,625] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:53:58,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:54:04,953] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8325954689632864
[2022-12-07 06:54:04,954] [INFO] [runner_train_mujoco] Average state value: 0.5403656386931738
[2022-12-07 06:54:04,954] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 06:54:05,010] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04641
[2022-12-07 06:54:05,060] [INFO] [controller] EPOCH 2 loss ppo:  -0.02314, loss val: 0.04577
[2022-12-07 06:54:05,122] [INFO] [controller] EPOCH 3 loss ppo:  -0.03399, loss val: 0.04525
[2022-12-07 06:54:05,177] [INFO] [controller] EPOCH 4 loss ppo:  -0.04165, loss val: 0.04214
[2022-12-07 06:54:05,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:54:05,386] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:54:05,387] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:54:11,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:54:18,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:54:24,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:54:30,478] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:54:36,802] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:54:43,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:54:49,191] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:54:55,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:55:01,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:55:08,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.779253344652222
[2022-12-07 06:55:08,266] [INFO] [runner_train_mujoco] Average state value: 0.5125531595448652
[2022-12-07 06:55:08,266] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 06:55:08,358] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.04117
[2022-12-07 06:55:08,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.02806, loss val: 0.03910
[2022-12-07 06:55:08,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.03784, loss val: 0.04094
[2022-12-07 06:55:08,566] [INFO] [controller] EPOCH 4 loss ppo:  -0.04527, loss val: 0.03939
[2022-12-07 06:55:08,578] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:55:08,787] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:55:08,788] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:55:14,737] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:55:21,238] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:55:27,821] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:55:33,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:55:40,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:55:46,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:55:52,360] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:55:58,529] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:56:04,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:56:10,807] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8230805930373015
[2022-12-07 06:56:10,807] [INFO] [runner_train_mujoco] Average state value: 0.5036973267793655
[2022-12-07 06:56:10,807] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 06:56:10,864] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04201
[2022-12-07 06:56:10,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.02431, loss val: 0.04192
[2022-12-07 06:56:11,016] [INFO] [controller] EPOCH 3 loss ppo:  -0.03760, loss val: 0.04224
[2022-12-07 06:56:11,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.04500, loss val: 0.04131
[2022-12-07 06:56:11,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:56:11,256] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:56:11,257] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:56:17,549] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:56:23,852] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:56:30,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:56:36,408] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:56:42,933] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:56:50,743] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:56:57,346] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:57:03,793] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:57:09,914] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:57:15,531] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.155610648229687
[2022-12-07 06:57:15,532] [INFO] [runner_train_mujoco] Average state value: 0.4721194704249501
[2022-12-07 06:57:15,532] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 06:57:15,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04896
[2022-12-07 06:57:15,657] [INFO] [controller] EPOCH 2 loss ppo:  -0.02553, loss val: 0.05056
[2022-12-07 06:57:15,701] [INFO] [controller] EPOCH 3 loss ppo:  -0.03331, loss val: 0.04967
[2022-12-07 06:57:15,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.04008, loss val: 0.05022
[2022-12-07 06:57:15,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:57:15,943] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:57:15,943] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:57:22,138] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:57:28,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:57:34,996] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:57:41,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:57:47,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:57:53,737] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:57:59,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:58:05,558] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:58:11,431] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:58:17,616] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8038030013740944
[2022-12-07 06:58:17,616] [INFO] [runner_train_mujoco] Average state value: 0.49643887319167457
[2022-12-07 06:58:17,616] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 06:58:17,709] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.03335
[2022-12-07 06:58:17,799] [INFO] [controller] EPOCH 2 loss ppo:  -0.02406, loss val: 0.03334
[2022-12-07 06:58:17,856] [INFO] [controller] EPOCH 3 loss ppo:  -0.03517, loss val: 0.03500
[2022-12-07 06:58:17,962] [INFO] [controller] EPOCH 4 loss ppo:  -0.04268, loss val: 0.03284
[2022-12-07 06:58:17,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:58:18,157] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:58:18,157] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:58:24,694] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:58:31,336] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:58:37,706] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:58:43,789] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:58:49,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:58:55,577] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:59:01,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:59:07,780] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:59:14,210] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:59:20,181] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.089264316840737
[2022-12-07 06:59:20,181] [INFO] [runner_train_mujoco] Average state value: 0.49805831827720004
[2022-12-07 06:59:20,181] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 06:59:20,251] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04079
[2022-12-07 06:59:20,307] [INFO] [controller] EPOCH 2 loss ppo:  -0.02521, loss val: 0.04179
[2022-12-07 06:59:20,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.03252, loss val: 0.03615
[2022-12-07 06:59:20,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.03877, loss val: 0.04082
[2022-12-07 06:59:20,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:59:20,612] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:59:20,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:59:26,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:59:32,813] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:59:38,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:59:44,989] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:59:51,587] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:59:57,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:00:04,174] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:00:09,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:00:15,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:00:21,845] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.63384629461882
[2022-12-07 07:00:21,845] [INFO] [runner_train_mujoco] Average state value: 0.479436162079374
[2022-12-07 07:00:21,845] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 07:00:21,927] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04969
[2022-12-07 07:00:21,985] [INFO] [controller] EPOCH 2 loss ppo:  -0.02014, loss val: 0.04821
[2022-12-07 07:00:22,037] [INFO] [controller] EPOCH 3 loss ppo:  -0.02858, loss val: 0.04687
[2022-12-07 07:00:22,095] [INFO] [controller] EPOCH 4 loss ppo:  -0.03735, loss val: 0.04605
[2022-12-07 07:00:22,105] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:00:22,300] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:00:22,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:00:28,271] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:00:34,297] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:00:40,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:00:46,334] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:00:52,354] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:00:58,450] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:01:04,873] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:01:10,924] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:01:16,538] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:01:22,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.3018838994681925
[2022-12-07 07:01:22,665] [INFO] [runner_train_mujoco] Average state value: 0.4976432083447775
[2022-12-07 07:01:22,665] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 07:01:22,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.03811
[2022-12-07 07:01:22,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.01992, loss val: 0.03802
[2022-12-07 07:01:22,855] [INFO] [controller] EPOCH 3 loss ppo:  -0.02860, loss val: 0.03949
[2022-12-07 07:01:22,909] [INFO] [controller] EPOCH 4 loss ppo:  -0.03678, loss val: 0.03871
[2022-12-07 07:01:22,919] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:01:23,097] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:01:23,098] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:01:29,446] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:01:35,674] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:01:41,880] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:01:48,074] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:01:54,629] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:02:00,826] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:02:07,110] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:02:13,051] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:02:19,468] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:02:25,316] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9194793132182517
[2022-12-07 07:02:25,317] [INFO] [runner_train_mujoco] Average state value: 0.5112572101950645
[2022-12-07 07:02:25,317] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 07:02:25,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.04161
[2022-12-07 07:02:25,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.01909, loss val: 0.04170
[2022-12-07 07:02:25,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.02596, loss val: 0.04160
[2022-12-07 07:02:25,506] [INFO] [controller] EPOCH 4 loss ppo:  -0.03357, loss val: 0.04128
[2022-12-07 07:02:25,516] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:02:25,700] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:02:25,700] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:02:31,981] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:02:38,227] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:02:44,423] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:02:50,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:02:56,756] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:03:02,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:03:08,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:03:15,151] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:03:20,993] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:03:27,039] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.046225415058148
[2022-12-07 07:03:27,040] [INFO] [runner_train_mujoco] Average state value: 0.5061229966282845
[2022-12-07 07:03:27,040] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 07:03:27,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.03770
[2022-12-07 07:03:27,164] [INFO] [controller] EPOCH 2 loss ppo:  -0.01808, loss val: 0.03912
[2022-12-07 07:03:27,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.02646, loss val: 0.03756
[2022-12-07 07:03:27,267] [INFO] [controller] EPOCH 4 loss ppo:  -0.03518, loss val: 0.03700
[2022-12-07 07:03:27,277] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:03:27,459] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:03:27,460] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:03:33,858] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:03:40,062] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:03:46,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:03:52,247] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:03:57,988] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:04:04,103] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:04:10,232] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:04:16,134] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:04:22,628] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:04:28,671] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.228853458047874
[2022-12-07 07:04:28,671] [INFO] [runner_train_mujoco] Average state value: 0.5023734367688497
[2022-12-07 07:04:28,671] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 07:04:28,745] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.03876
[2022-12-07 07:04:28,795] [INFO] [controller] EPOCH 2 loss ppo:  -0.01776, loss val: 0.03721
[2022-12-07 07:04:28,857] [INFO] [controller] EPOCH 3 loss ppo:  -0.02634, loss val: 0.03640
[2022-12-07 07:04:28,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.03266, loss val: 0.03653
[2022-12-07 07:04:28,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:04:29,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:04:29,147] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:04:35,468] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:04:41,528] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:04:47,323] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:04:53,046] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:04:58,906] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:05:04,805] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:05:10,630] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:05:17,052] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:05:23,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:05:29,057] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.104800691965324
[2022-12-07 07:05:29,058] [INFO] [runner_train_mujoco] Average state value: 0.4982560227811336
[2022-12-07 07:05:29,058] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 07:05:29,123] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.03747
[2022-12-07 07:05:29,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.01934, loss val: 0.03865
[2022-12-07 07:05:29,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.02675, loss val: 0.03558
[2022-12-07 07:05:29,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.03301, loss val: 0.03551
[2022-12-07 07:05:29,303] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:05:29,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:05:29,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:05:35,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:05:42,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:05:48,196] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:05:54,209] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:06:00,215] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:06:06,103] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:06:12,370] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:06:18,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:06:24,575] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:06:30,796] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.645457888544646
[2022-12-07 07:06:30,797] [INFO] [runner_train_mujoco] Average state value: 0.47116308239102367
[2022-12-07 07:06:30,797] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 07:06:30,876] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.04850
[2022-12-07 07:06:30,931] [INFO] [controller] EPOCH 2 loss ppo:  -0.01470, loss val: 0.04850
[2022-12-07 07:06:30,984] [INFO] [controller] EPOCH 3 loss ppo:  -0.01809, loss val: 0.04750
[2022-12-07 07:06:31,132] [INFO] [controller] EPOCH 4 loss ppo:  -0.02228, loss val: 0.04721
[2022-12-07 07:06:31,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:06:31,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:06:31,342] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:06:37,551] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:06:43,934] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:06:49,932] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:06:56,352] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:07:02,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:07:09,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:07:16,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:07:23,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:07:29,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:07:36,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.72790992681347
[2022-12-07 07:07:36,084] [INFO] [runner_train_mujoco] Average state value: 0.48801991940041384
[2022-12-07 07:07:36,084] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 07:07:36,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04552
[2022-12-07 07:07:36,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.01433, loss val: 0.04416
[2022-12-07 07:07:36,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.01708, loss val: 0.04440
[2022-12-07 07:07:36,294] [INFO] [controller] EPOCH 4 loss ppo:  -0.02100, loss val: 0.04398
[2022-12-07 07:07:36,304] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:07:36,490] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:07:36,490] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:07:42,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:07:48,879] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:07:55,046] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:08:00,925] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:08:06,916] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:08:12,655] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:08:18,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:08:24,532] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:08:30,528] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:08:36,528] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.188247348839554
[2022-12-07 07:08:36,528] [INFO] [runner_train_mujoco] Average state value: 0.4920250635345777
[2022-12-07 07:08:36,528] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 07:08:36,586] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03227
[2022-12-07 07:08:36,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.01413, loss val: 0.03182
[2022-12-07 07:08:36,691] [INFO] [controller] EPOCH 3 loss ppo:  -0.01569, loss val: 0.03253
[2022-12-07 07:08:36,742] [INFO] [controller] EPOCH 4 loss ppo:  -0.01790, loss val: 0.03254
[2022-12-07 07:08:36,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:08:36,881] [INFO] [optimize] Finished learning.
