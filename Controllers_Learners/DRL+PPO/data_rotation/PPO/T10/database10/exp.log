[2022-12-07 11:01:30,192] [INFO] [optimize] Starting learning
[2022-12-07 11:01:30,211] [INFO] [optimize] Starting learning process..
[2022-12-07 11:01:30,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:01:30,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:01:40,423] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:01:49,118] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:01:57,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:02:07,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:02:16,508] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:02:25,303] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:02:34,241] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:02:42,602] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:02:51,565] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:02:59,990] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37960183005383547
[2022-12-07 11:02:59,990] [INFO] [runner_train_mujoco] Average state value: 0.26805644838511944
[2022-12-07 11:02:59,990] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 11:03:00,127] [INFO] [controller] EPOCH 1 loss ppo:  -0.01053, loss val: 0.29119
[2022-12-07 11:03:00,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.03838, loss val: 0.25597
[2022-12-07 11:03:00,330] [INFO] [controller] EPOCH 3 loss ppo:  -0.04913, loss val: 0.22915
[2022-12-07 11:03:00,396] [INFO] [controller] EPOCH 4 loss ppo:  -0.05753, loss val: 0.20441
[2022-12-07 11:03:00,410] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:03:00,657] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:03:00,657] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:03:09,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:03:17,868] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:03:26,334] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:03:34,550] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:03:42,867] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:03:51,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:04:00,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:04:08,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:04:17,011] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:04:25,031] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42982551000260416
[2022-12-07 11:04:25,032] [INFO] [runner_train_mujoco] Average state value: 0.4217073401343077
[2022-12-07 11:04:25,032] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 11:04:25,112] [INFO] [controller] EPOCH 1 loss ppo:  -0.01088, loss val: 0.17897
[2022-12-07 11:04:25,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.03854, loss val: 0.16568
[2022-12-07 11:04:25,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.05316, loss val: 0.15691
[2022-12-07 11:04:25,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.05974, loss val: 0.14468
[2022-12-07 11:04:25,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:04:25,570] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:04:25,571] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:04:33,833] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:04:41,771] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:04:49,958] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:04:57,487] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:05:05,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:05:12,840] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:05:21,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:05:29,611] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:05:37,782] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:05:45,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4116914658706562
[2022-12-07 11:05:45,342] [INFO] [runner_train_mujoco] Average state value: 0.524423743740966
[2022-12-07 11:05:45,342] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 11:05:45,415] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.14110
[2022-12-07 11:05:45,477] [INFO] [controller] EPOCH 2 loss ppo:  -0.03687, loss val: 0.13024
[2022-12-07 11:05:45,544] [INFO] [controller] EPOCH 3 loss ppo:  -0.05092, loss val: 0.12204
[2022-12-07 11:05:45,608] [INFO] [controller] EPOCH 4 loss ppo:  -0.05834, loss val: 0.11443
[2022-12-07 11:05:45,619] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:05:45,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:05:45,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:05:53,649] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:06:01,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:06:09,170] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:06:16,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:06:24,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:06:33,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:06:41,664] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:06:49,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:06:58,013] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:07:08,051] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5578881634627524
[2022-12-07 11:07:08,051] [INFO] [runner_train_mujoco] Average state value: 0.5734082800491402
[2022-12-07 11:07:08,051] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 11:07:08,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.10510
[2022-12-07 11:07:08,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.03328, loss val: 0.09759
[2022-12-07 11:07:08,421] [INFO] [controller] EPOCH 3 loss ppo:  -0.04680, loss val: 0.09119
[2022-12-07 11:07:08,481] [INFO] [controller] EPOCH 4 loss ppo:  -0.05591, loss val: 0.08528
[2022-12-07 11:07:08,497] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:07:08,721] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:07:08,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:07:19,250] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:07:29,773] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:07:39,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:07:48,045] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:07:56,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:08:05,565] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:08:14,701] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:08:23,752] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:08:33,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:08:42,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.43991701882259127
[2022-12-07 11:08:42,344] [INFO] [runner_train_mujoco] Average state value: 0.562655518024539
[2022-12-07 11:08:42,344] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 11:08:42,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.01095, loss val: 0.08367
[2022-12-07 11:08:42,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.03569, loss val: 0.07767
[2022-12-07 11:08:42,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.05000, loss val: 0.07353
[2022-12-07 11:08:42,699] [INFO] [controller] EPOCH 4 loss ppo:  -0.05853, loss val: 0.06847
[2022-12-07 11:08:42,710] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:08:42,966] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:08:42,967] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:08:52,132] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:09:00,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:09:09,558] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:09:18,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:09:28,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:09:38,669] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:09:48,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:09:57,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:10:05,230] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:10:13,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4903450226069756
[2022-12-07 11:10:13,378] [INFO] [runner_train_mujoco] Average state value: 0.4817813421270499
[2022-12-07 11:10:13,379] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 11:10:13,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01176, loss val: 0.07335
[2022-12-07 11:10:13,531] [INFO] [controller] EPOCH 2 loss ppo:  -0.02998, loss val: 0.06771
[2022-12-07 11:10:13,593] [INFO] [controller] EPOCH 3 loss ppo:  -0.04532, loss val: 0.06548
[2022-12-07 11:10:13,659] [INFO] [controller] EPOCH 4 loss ppo:  -0.05123, loss val: 0.06421
[2022-12-07 11:10:13,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:10:13,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:10:13,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:10:22,093] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:10:30,710] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:10:38,734] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:10:46,834] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:10:54,571] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:11:02,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:11:12,322] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:11:21,177] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:11:29,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:11:37,749] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4063310961619816
[2022-12-07 11:11:37,749] [INFO] [runner_train_mujoco] Average state value: 0.4663461381358405
[2022-12-07 11:11:37,749] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 11:11:37,830] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.06677
[2022-12-07 11:11:37,893] [INFO] [controller] EPOCH 2 loss ppo:  -0.03789, loss val: 0.06539
[2022-12-07 11:11:37,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.05096, loss val: 0.06298
[2022-12-07 11:11:38,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.05840, loss val: 0.06015
[2022-12-07 11:11:38,049] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:11:38,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:11:38,279] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:11:46,395] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:11:54,681] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:12:02,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:12:10,404] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:12:17,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:12:23,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:12:30,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:12:37,053] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:12:43,896] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:12:50,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4483065352535269
[2022-12-07 11:12:50,635] [INFO] [runner_train_mujoco] Average state value: 0.4580672980193049
[2022-12-07 11:12:50,635] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 11:12:50,734] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.06003
[2022-12-07 11:12:50,805] [INFO] [controller] EPOCH 2 loss ppo:  -0.03900, loss val: 0.05455
[2022-12-07 11:12:50,870] [INFO] [controller] EPOCH 3 loss ppo:  -0.05185, loss val: 0.05771
[2022-12-07 11:12:50,935] [INFO] [controller] EPOCH 4 loss ppo:  -0.05956, loss val: 0.06068
[2022-12-07 11:12:50,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:12:51,184] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:12:51,185] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:12:58,246] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:13:04,901] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:13:11,275] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:13:17,481] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:13:24,204] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:13:31,173] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:13:37,285] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:13:43,385] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:13:49,356] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:13:55,244] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5609493232780611
[2022-12-07 11:13:55,245] [INFO] [runner_train_mujoco] Average state value: 0.45474885818393274
[2022-12-07 11:13:55,245] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 11:13:55,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04653
[2022-12-07 11:13:55,373] [INFO] [controller] EPOCH 2 loss ppo:  -0.03273, loss val: 0.04552
[2022-12-07 11:13:55,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.04376, loss val: 0.04685
[2022-12-07 11:13:55,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.05570, loss val: 0.04309
[2022-12-07 11:13:55,472] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:13:55,663] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:13:55,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:14:01,692] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:14:08,192] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:14:14,361] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:14:21,142] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:14:27,564] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:14:33,780] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:14:40,466] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:14:46,440] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:14:52,662] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:14:59,453] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7373097399477461
[2022-12-07 11:14:59,453] [INFO] [runner_train_mujoco] Average state value: 0.4948762750128905
[2022-12-07 11:14:59,453] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 11:14:59,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04586
[2022-12-07 11:14:59,568] [INFO] [controller] EPOCH 2 loss ppo:  -0.03698, loss val: 0.04506
[2022-12-07 11:14:59,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.04820, loss val: 0.04389
[2022-12-07 11:14:59,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.05434, loss val: 0.04339
[2022-12-07 11:14:59,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:14:59,852] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:14:59,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:15:07,688] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:15:15,943] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:15:22,042] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:15:28,776] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:15:36,599] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:15:44,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:15:51,401] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:16:00,505] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:16:08,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:16:15,333] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6981559626326739
[2022-12-07 11:16:15,334] [INFO] [runner_train_mujoco] Average state value: 0.4703607115522027
[2022-12-07 11:16:15,334] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 11:16:15,397] [INFO] [controller] EPOCH 1 loss ppo:  -0.01281, loss val: 0.04761
[2022-12-07 11:16:15,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.03429, loss val: 0.04685
[2022-12-07 11:16:15,492] [INFO] [controller] EPOCH 3 loss ppo:  -0.04535, loss val: 0.05248
[2022-12-07 11:16:15,562] [INFO] [controller] EPOCH 4 loss ppo:  -0.05403, loss val: 0.04498
[2022-12-07 11:16:15,573] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:16:15,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:16:15,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:16:22,980] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:16:29,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:16:36,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:16:42,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:16:50,534] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:16:58,300] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:17:05,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:17:12,670] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:17:19,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:17:26,205] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8190725251709626
[2022-12-07 11:17:26,205] [INFO] [runner_train_mujoco] Average state value: 0.5057507019937039
[2022-12-07 11:17:26,205] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 11:17:26,262] [INFO] [controller] EPOCH 1 loss ppo:  -0.01253, loss val: 0.04163
[2022-12-07 11:17:26,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.03341, loss val: 0.04239
[2022-12-07 11:17:26,430] [INFO] [controller] EPOCH 3 loss ppo:  -0.04639, loss val: 0.04108
[2022-12-07 11:17:26,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.05590, loss val: 0.04183
[2022-12-07 11:17:26,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:17:26,705] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:17:26,705] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:17:33,631] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:17:41,711] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:17:50,414] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:17:57,393] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:18:04,869] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:18:12,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:18:18,920] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:18:25,431] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:18:32,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:18:38,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0129728403046925
[2022-12-07 11:18:38,562] [INFO] [runner_train_mujoco] Average state value: 0.5329216250479221
[2022-12-07 11:18:38,562] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 11:18:38,616] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.03236
[2022-12-07 11:18:38,661] [INFO] [controller] EPOCH 2 loss ppo:  -0.03466, loss val: 0.03269
[2022-12-07 11:18:38,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.04643, loss val: 0.03339
[2022-12-07 11:18:38,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.05262, loss val: 0.03142
[2022-12-07 11:18:38,784] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:18:39,006] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:18:39,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:18:46,095] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:18:52,955] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:18:59,429] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:19:06,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:19:13,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:19:20,871] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:19:28,566] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:19:35,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:19:42,715] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:19:50,250] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0606579254567172
[2022-12-07 11:19:50,251] [INFO] [runner_train_mujoco] Average state value: 0.5104179130593935
[2022-12-07 11:19:50,251] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 11:19:50,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01620, loss val: 0.03708
[2022-12-07 11:19:50,393] [INFO] [controller] EPOCH 2 loss ppo:  -0.03745, loss val: 0.03611
[2022-12-07 11:19:50,443] [INFO] [controller] EPOCH 3 loss ppo:  -0.04959, loss val: 0.03700
[2022-12-07 11:19:50,491] [INFO] [controller] EPOCH 4 loss ppo:  -0.05870, loss val: 0.03624
[2022-12-07 11:19:50,507] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:19:50,713] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:19:50,713] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:19:58,290] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:20:05,405] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:20:11,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:20:18,190] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:20:25,014] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:20:32,212] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:20:39,427] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:20:46,237] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:20:53,131] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:21:00,069] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4242945030990941
[2022-12-07 11:21:00,069] [INFO] [runner_train_mujoco] Average state value: 0.49292754062016797
[2022-12-07 11:21:00,069] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 11:21:00,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.04930
[2022-12-07 11:21:00,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.03972, loss val: 0.04972
[2022-12-07 11:21:00,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.05268, loss val: 0.04866
[2022-12-07 11:21:00,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.06108, loss val: 0.04879
[2022-12-07 11:21:00,363] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:21:00,571] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:21:00,572] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:21:08,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:21:16,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:21:22,921] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:21:29,857] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:21:36,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:21:44,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:21:51,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:21:57,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:22:03,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:22:09,753] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5984332370067327
[2022-12-07 11:22:09,753] [INFO] [runner_train_mujoco] Average state value: 0.5191557750503222
[2022-12-07 11:22:09,754] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 11:22:09,816] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04524
[2022-12-07 11:22:09,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.03408, loss val: 0.04494
[2022-12-07 11:22:09,919] [INFO] [controller] EPOCH 3 loss ppo:  -0.04620, loss val: 0.04255
[2022-12-07 11:22:09,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.05574, loss val: 0.03883
[2022-12-07 11:22:09,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:22:10,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:22:10,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:22:16,722] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:22:23,218] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:22:30,308] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:22:36,887] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:22:44,040] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:22:50,694] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:22:57,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:23:03,323] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:23:09,979] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:23:16,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6470230087754225
[2022-12-07 11:23:16,626] [INFO] [runner_train_mujoco] Average state value: 0.4621075990200042
[2022-12-07 11:23:16,626] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 11:23:16,688] [INFO] [controller] EPOCH 1 loss ppo:  -0.01647, loss val: 0.04047
[2022-12-07 11:23:16,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.04112, loss val: 0.03889
[2022-12-07 11:23:16,787] [INFO] [controller] EPOCH 3 loss ppo:  -0.05374, loss val: 0.04024
[2022-12-07 11:23:16,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.06548, loss val: 0.04034
[2022-12-07 11:23:16,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:23:17,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:23:17,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:23:24,228] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:23:31,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:23:37,606] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:23:43,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:23:50,579] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:23:57,872] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:24:05,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:24:12,739] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:24:19,181] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:24:25,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9410986075554764
[2022-12-07 11:24:25,626] [INFO] [runner_train_mujoco] Average state value: 0.4108770099480947
[2022-12-07 11:24:25,626] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 11:24:25,689] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.04015
[2022-12-07 11:24:25,743] [INFO] [controller] EPOCH 2 loss ppo:  -0.03197, loss val: 0.03842
[2022-12-07 11:24:25,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.04620, loss val: 0.03665
[2022-12-07 11:24:25,847] [INFO] [controller] EPOCH 4 loss ppo:  -0.05317, loss val: 0.04574
[2022-12-07 11:24:25,858] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:24:26,071] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:24:26,071] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:24:32,798] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:24:39,533] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:24:46,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:24:53,889] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:25:00,626] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:25:07,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:25:13,934] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:25:20,240] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:25:26,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:25:33,940] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1171754798201405
[2022-12-07 11:25:33,940] [INFO] [runner_train_mujoco] Average state value: 0.4628226338922977
[2022-12-07 11:25:33,941] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 11:25:33,997] [INFO] [controller] EPOCH 1 loss ppo:  -0.01701, loss val: 0.04222
[2022-12-07 11:25:34,045] [INFO] [controller] EPOCH 2 loss ppo:  -0.03606, loss val: 0.03992
[2022-12-07 11:25:34,097] [INFO] [controller] EPOCH 3 loss ppo:  -0.04431, loss val: 0.03864
[2022-12-07 11:25:34,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.05645, loss val: 0.03937
[2022-12-07 11:25:34,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:25:34,370] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:25:34,370] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:25:41,884] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:25:49,071] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:25:56,281] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:26:03,172] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:26:10,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:26:17,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:26:25,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:26:31,952] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:26:38,746] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:26:45,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2625479937973036
[2022-12-07 11:26:45,549] [INFO] [runner_train_mujoco] Average state value: 0.5546334113081297
[2022-12-07 11:26:45,549] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 11:26:45,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.04168
[2022-12-07 11:26:45,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.03409, loss val: 0.03650
[2022-12-07 11:26:45,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.04957, loss val: 0.03703
[2022-12-07 11:26:45,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.05642, loss val: 0.03723
[2022-12-07 11:26:45,763] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:26:45,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:26:45,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:26:54,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:27:01,448] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:27:07,956] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:27:14,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:27:20,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:27:27,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:27:34,635] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:27:42,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:27:48,831] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:27:54,987] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5869053177120414
[2022-12-07 11:27:54,988] [INFO] [runner_train_mujoco] Average state value: 0.6074523353576661
[2022-12-07 11:27:54,988] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 11:27:55,049] [INFO] [controller] EPOCH 1 loss ppo:  -0.01495, loss val: 0.06175
[2022-12-07 11:27:55,093] [INFO] [controller] EPOCH 2 loss ppo:  -0.03179, loss val: 0.05776
[2022-12-07 11:27:55,136] [INFO] [controller] EPOCH 3 loss ppo:  -0.04081, loss val: 0.05955
[2022-12-07 11:27:55,184] [INFO] [controller] EPOCH 4 loss ppo:  -0.05089, loss val: 0.05221
[2022-12-07 11:27:55,195] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:27:55,404] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:27:55,405] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:28:01,808] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:28:08,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:28:14,132] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:28:20,412] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:28:26,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:28:33,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:28:39,618] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:28:46,835] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:28:53,822] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:29:00,097] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9034009392792823
[2022-12-07 11:29:00,097] [INFO] [runner_train_mujoco] Average state value: 0.5599522921741009
[2022-12-07 11:29:00,098] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 11:29:00,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.04550
[2022-12-07 11:29:00,204] [INFO] [controller] EPOCH 2 loss ppo:  -0.03523, loss val: 0.04330
[2022-12-07 11:29:00,250] [INFO] [controller] EPOCH 3 loss ppo:  -0.04649, loss val: 0.04447
[2022-12-07 11:29:00,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.05553, loss val: 0.04519
[2022-12-07 11:29:00,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:29:00,523] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:29:00,524] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:29:07,451] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:29:13,973] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:29:20,003] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:29:26,752] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:29:33,708] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:29:41,852] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:29:50,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:29:57,134] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:30:03,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:30:09,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.498736725444761
[2022-12-07 11:30:09,998] [INFO] [runner_train_mujoco] Average state value: 0.4899321186840534
[2022-12-07 11:30:09,998] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 11:30:10,095] [INFO] [controller] EPOCH 1 loss ppo:  -0.01196, loss val: 0.03119
[2022-12-07 11:30:10,208] [INFO] [controller] EPOCH 2 loss ppo:  -0.03176, loss val: 0.03310
[2022-12-07 11:30:10,338] [INFO] [controller] EPOCH 3 loss ppo:  -0.04409, loss val: 0.03516
[2022-12-07 11:30:10,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.05725, loss val: 0.03108
[2022-12-07 11:30:10,494] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:30:10,737] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:30:10,737] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:30:18,588] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:30:24,564] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:30:30,525] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:30:36,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:30:43,200] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:30:48,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:30:55,084] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:31:00,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:31:07,144] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:31:12,902] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.824347248543028
[2022-12-07 11:31:12,903] [INFO] [runner_train_mujoco] Average state value: 0.4636572724084059
[2022-12-07 11:31:12,903] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 11:31:12,964] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.03744
[2022-12-07 11:31:13,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.03557, loss val: 0.03786
[2022-12-07 11:31:13,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.04813, loss val: 0.03595
[2022-12-07 11:31:13,095] [INFO] [controller] EPOCH 4 loss ppo:  -0.06128, loss val: 0.03593
[2022-12-07 11:31:13,105] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:31:13,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:31:13,306] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:31:19,763] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:31:26,008] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:31:32,515] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:31:38,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:31:45,756] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:31:54,972] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:32:02,157] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:32:08,906] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:32:15,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:32:22,081] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.921700954287288
[2022-12-07 11:32:22,081] [INFO] [runner_train_mujoco] Average state value: 0.4425256230831146
[2022-12-07 11:32:22,081] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 11:32:22,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01505, loss val: 0.04623
[2022-12-07 11:32:22,207] [INFO] [controller] EPOCH 2 loss ppo:  -0.03199, loss val: 0.04713
[2022-12-07 11:32:22,330] [INFO] [controller] EPOCH 3 loss ppo:  -0.04526, loss val: 0.04625
[2022-12-07 11:32:22,381] [INFO] [controller] EPOCH 4 loss ppo:  -0.05520, loss val: 0.04680
[2022-12-07 11:32:22,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:32:22,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:32:22,606] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:32:29,146] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:32:36,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:32:42,542] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:32:48,793] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:32:57,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:33:04,348] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:33:10,591] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:33:17,310] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:33:24,008] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:33:30,451] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.88100761894124
[2022-12-07 11:33:30,451] [INFO] [runner_train_mujoco] Average state value: 0.4429818162123363
[2022-12-07 11:33:30,451] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 11:33:30,507] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03188
[2022-12-07 11:33:30,557] [INFO] [controller] EPOCH 2 loss ppo:  -0.03504, loss val: 0.03462
[2022-12-07 11:33:30,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.04840, loss val: 0.03423
[2022-12-07 11:33:30,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.06010, loss val: 0.03099
[2022-12-07 11:33:30,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:33:30,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:33:30,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:33:37,296] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:33:43,997] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:33:50,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:34:00,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:34:08,443] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:34:15,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:34:23,185] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:34:31,354] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:34:38,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:34:45,612] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.181223258259286
[2022-12-07 11:34:45,613] [INFO] [runner_train_mujoco] Average state value: 0.4486109516024589
[2022-12-07 11:34:45,613] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 11:34:45,678] [INFO] [controller] EPOCH 1 loss ppo:  -0.01591, loss val: 0.03750
[2022-12-07 11:34:45,727] [INFO] [controller] EPOCH 2 loss ppo:  -0.03128, loss val: 0.03697
[2022-12-07 11:34:45,779] [INFO] [controller] EPOCH 3 loss ppo:  -0.04326, loss val: 0.03529
[2022-12-07 11:34:45,833] [INFO] [controller] EPOCH 4 loss ppo:  -0.05176, loss val: 0.03413
[2022-12-07 11:34:45,845] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:34:46,059] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:34:46,059] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:34:52,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:34:59,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:35:06,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:35:12,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:35:23,850] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:35:34,935] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:35:42,217] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:35:51,522] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:35:59,715] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:36:06,048] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5169245767455086
[2022-12-07 11:36:06,049] [INFO] [runner_train_mujoco] Average state value: 0.404686352600654
[2022-12-07 11:36:06,049] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 11:36:06,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01521, loss val: 0.03952
[2022-12-07 11:36:06,157] [INFO] [controller] EPOCH 2 loss ppo:  -0.03325, loss val: 0.03934
[2022-12-07 11:36:06,203] [INFO] [controller] EPOCH 3 loss ppo:  -0.04403, loss val: 0.03946
[2022-12-07 11:36:06,253] [INFO] [controller] EPOCH 4 loss ppo:  -0.05748, loss val: 0.03957
[2022-12-07 11:36:06,263] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:36:06,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:36:06,526] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:36:14,810] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:36:24,728] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:36:33,838] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:36:42,522] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:36:50,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:36:58,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:37:04,906] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:37:10,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:37:16,948] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:37:22,915] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3185929698699135
[2022-12-07 11:37:22,915] [INFO] [runner_train_mujoco] Average state value: 0.3771689047416051
[2022-12-07 11:37:22,916] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 11:37:22,979] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.03812
[2022-12-07 11:37:23,030] [INFO] [controller] EPOCH 2 loss ppo:  -0.02815, loss val: 0.03828
[2022-12-07 11:37:23,078] [INFO] [controller] EPOCH 3 loss ppo:  -0.04309, loss val: 0.03795
[2022-12-07 11:37:23,122] [INFO] [controller] EPOCH 4 loss ppo:  -0.05410, loss val: 0.03845
[2022-12-07 11:37:23,133] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:37:23,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:37:23,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:37:30,118] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:37:36,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:37:43,216] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:37:49,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:37:55,657] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:38:03,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:38:10,683] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:38:17,712] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:38:26,236] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:38:35,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2878690880189225
[2022-12-07 11:38:35,551] [INFO] [runner_train_mujoco] Average state value: 0.37801813624302544
[2022-12-07 11:38:35,551] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 11:38:35,646] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04397
[2022-12-07 11:38:35,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.03247, loss val: 0.04428
[2022-12-07 11:38:35,812] [INFO] [controller] EPOCH 3 loss ppo:  -0.04643, loss val: 0.04236
[2022-12-07 11:38:35,893] [INFO] [controller] EPOCH 4 loss ppo:  -0.05412, loss val: 0.04182
[2022-12-07 11:38:35,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:38:36,153] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:38:36,154] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:38:44,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:38:51,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:38:57,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:39:04,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:39:14,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:39:22,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:39:29,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:39:37,416] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:39:45,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:39:52,302] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2968697573935337
[2022-12-07 11:39:52,302] [INFO] [runner_train_mujoco] Average state value: 0.4127890597432852
[2022-12-07 11:39:52,302] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 11:39:52,366] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04285
[2022-12-07 11:39:52,417] [INFO] [controller] EPOCH 2 loss ppo:  -0.03007, loss val: 0.03685
[2022-12-07 11:39:52,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.04035, loss val: 0.03620
[2022-12-07 11:39:52,520] [INFO] [controller] EPOCH 4 loss ppo:  -0.04927, loss val: 0.03366
[2022-12-07 11:39:52,532] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:39:52,755] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:39:52,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:39:59,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:40:07,391] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:40:14,661] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:40:21,337] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:40:28,082] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:40:35,686] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:40:42,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:40:49,039] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:40:55,595] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:41:02,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.537359109301415
[2022-12-07 11:41:02,427] [INFO] [runner_train_mujoco] Average state value: 0.47475825300812724
[2022-12-07 11:41:02,427] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 11:41:02,494] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03592
[2022-12-07 11:41:02,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.03126, loss val: 0.03951
[2022-12-07 11:41:02,595] [INFO] [controller] EPOCH 3 loss ppo:  -0.04552, loss val: 0.03744
[2022-12-07 11:41:02,643] [INFO] [controller] EPOCH 4 loss ppo:  -0.05691, loss val: 0.03842
[2022-12-07 11:41:02,654] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:41:02,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:41:02,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:41:09,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:41:17,505] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:41:24,013] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:41:30,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:41:36,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:41:43,354] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:41:49,267] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:41:55,454] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:42:01,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:42:08,704] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.88852519758748
[2022-12-07 11:42:08,704] [INFO] [runner_train_mujoco] Average state value: 0.48753247283895806
[2022-12-07 11:42:08,704] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 11:42:08,864] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04031
[2022-12-07 11:42:08,911] [INFO] [controller] EPOCH 2 loss ppo:  -0.02844, loss val: 0.03943
[2022-12-07 11:42:08,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.04060, loss val: 0.04021
[2022-12-07 11:42:09,043] [INFO] [controller] EPOCH 4 loss ppo:  -0.05093, loss val: 0.04178
[2022-12-07 11:42:09,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:42:09,295] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:42:09,296] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:42:15,817] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:42:21,828] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:42:27,921] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:42:34,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:42:40,349] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:42:46,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:42:52,789] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:42:59,302] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:43:05,432] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:43:11,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.68327004407353
[2022-12-07 11:43:11,780] [INFO] [runner_train_mujoco] Average state value: 0.44619271978735925
[2022-12-07 11:43:11,780] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 11:43:11,835] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.04139
[2022-12-07 11:43:11,889] [INFO] [controller] EPOCH 2 loss ppo:  -0.02662, loss val: 0.04136
[2022-12-07 11:43:11,946] [INFO] [controller] EPOCH 3 loss ppo:  -0.04413, loss val: 0.03907
[2022-12-07 11:43:12,005] [INFO] [controller] EPOCH 4 loss ppo:  -0.05807, loss val: 0.03937
[2022-12-07 11:43:12,015] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:43:12,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:43:12,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:43:18,531] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:43:26,195] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:43:32,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:43:38,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:43:44,366] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:43:50,253] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:43:55,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:44:02,084] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:44:08,544] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:44:15,423] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.973015704634734
[2022-12-07 11:44:15,424] [INFO] [runner_train_mujoco] Average state value: 0.4495703572630883
[2022-12-07 11:44:15,424] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 11:44:15,636] [INFO] [controller] EPOCH 1 loss ppo:  -0.01531, loss val: 0.04308
[2022-12-07 11:44:15,723] [INFO] [controller] EPOCH 2 loss ppo:  -0.02898, loss val: 0.04149
[2022-12-07 11:44:15,800] [INFO] [controller] EPOCH 3 loss ppo:  -0.03915, loss val: 0.03987
[2022-12-07 11:44:15,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.04996, loss val: 0.03819
[2022-12-07 11:44:15,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:44:16,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:44:16,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:44:24,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:44:34,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:44:41,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:44:47,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:44:53,809] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:45:00,510] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:45:06,942] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:45:13,140] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:45:19,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:45:25,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.823634056769798
[2022-12-07 11:45:25,441] [INFO] [runner_train_mujoco] Average state value: 0.49970936196049054
[2022-12-07 11:45:25,441] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 11:45:25,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04242
[2022-12-07 11:45:25,545] [INFO] [controller] EPOCH 2 loss ppo:  -0.02706, loss val: 0.04386
[2022-12-07 11:45:25,595] [INFO] [controller] EPOCH 3 loss ppo:  -0.03284, loss val: 0.04393
[2022-12-07 11:45:25,643] [INFO] [controller] EPOCH 4 loss ppo:  -0.04538, loss val: 0.04282
[2022-12-07 11:45:25,654] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:45:25,883] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:45:25,883] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:45:32,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:45:41,035] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:45:48,902] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:45:56,778] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:46:05,284] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:46:13,353] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:46:20,779] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:46:27,888] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:46:34,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:46:41,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6877788697658063
[2022-12-07 11:46:41,483] [INFO] [runner_train_mujoco] Average state value: 0.49501257218917216
[2022-12-07 11:46:41,483] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 11:46:41,542] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.04707
[2022-12-07 11:46:41,589] [INFO] [controller] EPOCH 2 loss ppo:  -0.02765, loss val: 0.04658
[2022-12-07 11:46:41,639] [INFO] [controller] EPOCH 3 loss ppo:  -0.03842, loss val: 0.04620
[2022-12-07 11:46:41,680] [INFO] [controller] EPOCH 4 loss ppo:  -0.05173, loss val: 0.04764
[2022-12-07 11:46:41,691] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:46:41,910] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:46:41,911] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:46:49,535] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:46:57,112] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:47:03,789] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:47:11,183] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:47:18,202] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:47:25,071] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:47:31,537] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:47:38,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:47:45,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:47:51,943] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.796068311781609
[2022-12-07 11:47:51,943] [INFO] [runner_train_mujoco] Average state value: 0.46192681469519925
[2022-12-07 11:47:51,943] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 11:47:52,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.03680
[2022-12-07 11:47:52,055] [INFO] [controller] EPOCH 2 loss ppo:  -0.02916, loss val: 0.03702
[2022-12-07 11:47:52,107] [INFO] [controller] EPOCH 3 loss ppo:  -0.04155, loss val: 0.03766
[2022-12-07 11:47:52,155] [INFO] [controller] EPOCH 4 loss ppo:  -0.05153, loss val: 0.03760
[2022-12-07 11:47:52,165] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:47:52,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:47:52,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:48:00,013] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:48:07,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:48:13,874] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:48:20,040] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:48:26,295] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:48:32,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:48:39,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:48:45,436] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:48:51,906] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:48:58,465] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8737457097792545
[2022-12-07 11:48:58,465] [INFO] [runner_train_mujoco] Average state value: 0.4571095770299435
[2022-12-07 11:48:58,465] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 11:48:58,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04416
[2022-12-07 11:48:58,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.03092, loss val: 0.04361
[2022-12-07 11:48:58,633] [INFO] [controller] EPOCH 3 loss ppo:  -0.04268, loss val: 0.04375
[2022-12-07 11:48:58,682] [INFO] [controller] EPOCH 4 loss ppo:  -0.05201, loss val: 0.04333
[2022-12-07 11:48:58,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:48:58,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:48:58,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:49:06,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:49:12,728] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:49:19,987] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:49:26,457] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:49:33,732] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:49:40,422] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:49:46,487] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:49:52,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:49:59,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:50:05,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8589164960678217
[2022-12-07 11:50:05,894] [INFO] [runner_train_mujoco] Average state value: 0.4458592736423016
[2022-12-07 11:50:05,894] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 11:50:05,958] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04381
[2022-12-07 11:50:06,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.02669, loss val: 0.04458
[2022-12-07 11:50:06,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.03563, loss val: 0.05258
[2022-12-07 11:50:06,120] [INFO] [controller] EPOCH 4 loss ppo:  -0.04475, loss val: 0.04165
[2022-12-07 11:50:06,130] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:50:06,339] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:50:06,345] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:50:12,766] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:50:18,982] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:50:25,456] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:50:31,038] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:50:37,176] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:50:43,229] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:50:49,668] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:50:55,617] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:51:01,976] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:51:08,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.2251154559162245
[2022-12-07 11:51:08,160] [INFO] [runner_train_mujoco] Average state value: 0.46115239318211876
[2022-12-07 11:51:08,160] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 11:51:08,223] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.04368
[2022-12-07 11:51:08,267] [INFO] [controller] EPOCH 2 loss ppo:  -0.02574, loss val: 0.04404
[2022-12-07 11:51:08,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.03394, loss val: 0.03914
[2022-12-07 11:51:08,374] [INFO] [controller] EPOCH 4 loss ppo:  -0.04422, loss val: 0.03623
[2022-12-07 11:51:08,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:51:08,586] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:51:08,586] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:51:14,331] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:51:20,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:51:26,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:51:31,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:51:37,957] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:51:43,589] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:51:49,520] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:51:55,393] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:52:01,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:52:07,376] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0735694408980105
[2022-12-07 11:52:07,376] [INFO] [runner_train_mujoco] Average state value: 0.5172574864725272
[2022-12-07 11:52:07,376] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 11:52:07,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04094
[2022-12-07 11:52:07,483] [INFO] [controller] EPOCH 2 loss ppo:  -0.02031, loss val: 0.04015
[2022-12-07 11:52:07,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.03230, loss val: 0.04219
[2022-12-07 11:52:07,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.04500, loss val: 0.04092
[2022-12-07 11:52:07,594] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:52:07,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:52:07,806] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:52:13,667] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:52:20,155] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:52:26,211] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:52:32,857] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:52:39,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:52:45,118] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:52:50,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:52:56,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:53:02,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:53:08,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.106336199681477
[2022-12-07 11:53:08,440] [INFO] [runner_train_mujoco] Average state value: 0.5362482913136482
[2022-12-07 11:53:08,440] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 11:53:08,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.04097
[2022-12-07 11:53:08,539] [INFO] [controller] EPOCH 2 loss ppo:  -0.02544, loss val: 0.03917
[2022-12-07 11:53:08,588] [INFO] [controller] EPOCH 3 loss ppo:  -0.03515, loss val: 0.04005
[2022-12-07 11:53:08,640] [INFO] [controller] EPOCH 4 loss ppo:  -0.04606, loss val: 0.04129
[2022-12-07 11:53:08,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:53:08,880] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:53:08,881] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:53:15,130] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:53:21,514] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:53:27,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:53:34,102] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:53:40,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:53:46,444] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:53:52,189] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:53:58,449] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:54:05,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:54:15,085] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.532619258459974
[2022-12-07 11:54:15,085] [INFO] [runner_train_mujoco] Average state value: 0.5120321591099104
[2022-12-07 11:54:15,085] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 11:54:15,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.04415
[2022-12-07 11:54:15,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.02551, loss val: 0.04493
[2022-12-07 11:54:15,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.03488, loss val: 0.04458
[2022-12-07 11:54:15,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.04521, loss val: 0.04431
[2022-12-07 11:54:15,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:54:15,690] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:54:15,691] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:54:22,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:54:29,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:54:38,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:54:47,184] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:54:55,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:55:03,972] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:55:15,331] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:55:25,509] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:55:34,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:55:42,655] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.342901907258613
[2022-12-07 11:55:42,655] [INFO] [runner_train_mujoco] Average state value: 0.5142830631732941
[2022-12-07 11:55:42,655] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 11:55:42,712] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.04596
[2022-12-07 11:55:42,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.02170, loss val: 0.04579
[2022-12-07 11:55:42,812] [INFO] [controller] EPOCH 3 loss ppo:  -0.03027, loss val: 0.04076
[2022-12-07 11:55:42,857] [INFO] [controller] EPOCH 4 loss ppo:  -0.04143, loss val: 0.04446
[2022-12-07 11:55:42,869] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:55:43,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:55:43,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:55:49,734] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:55:56,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:56:03,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:56:11,260] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:56:17,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:56:24,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:56:30,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:56:37,409] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:56:43,894] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:56:50,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.25993479474497
[2022-12-07 11:56:50,378] [INFO] [runner_train_mujoco] Average state value: 0.4991417854527633
[2022-12-07 11:56:50,379] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 11:56:50,453] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.03346
[2022-12-07 11:56:50,506] [INFO] [controller] EPOCH 2 loss ppo:  -0.02710, loss val: 0.03343
[2022-12-07 11:56:50,642] [INFO] [controller] EPOCH 3 loss ppo:  -0.03318, loss val: 0.03152
[2022-12-07 11:56:50,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.04115, loss val: 0.03405
[2022-12-07 11:56:50,709] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:56:50,939] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:56:50,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:56:57,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:57:04,971] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:57:11,596] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:57:18,555] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:57:25,454] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:57:31,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:57:37,750] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:57:44,655] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:57:51,398] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:57:57,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.625140381295138
[2022-12-07 11:57:57,696] [INFO] [runner_train_mujoco] Average state value: 0.4907320821583271
[2022-12-07 11:57:57,696] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 11:57:57,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.03836
[2022-12-07 11:57:57,817] [INFO] [controller] EPOCH 2 loss ppo:  -0.02364, loss val: 0.03907
[2022-12-07 11:57:57,873] [INFO] [controller] EPOCH 3 loss ppo:  -0.03283, loss val: 0.03818
[2022-12-07 11:57:57,933] [INFO] [controller] EPOCH 4 loss ppo:  -0.04220, loss val: 0.03769
[2022-12-07 11:57:57,946] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:57:58,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:57:58,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:58:05,667] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:58:13,660] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:58:21,377] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:58:28,668] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:58:34,893] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:58:41,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:58:47,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:58:53,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:58:59,267] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:59:06,001] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.386773950163453
[2022-12-07 11:59:06,002] [INFO] [runner_train_mujoco] Average state value: 0.48040951113899544
[2022-12-07 11:59:06,002] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 11:59:06,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.03502
[2022-12-07 11:59:06,174] [INFO] [controller] EPOCH 2 loss ppo:  -0.02235, loss val: 0.03525
[2022-12-07 11:59:06,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.03007, loss val: 0.03488
[2022-12-07 11:59:06,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.03990, loss val: 0.03479
[2022-12-07 11:59:06,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:59:06,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:59:06,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:59:19,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:59:28,696] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:59:36,661] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:59:44,388] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:59:51,317] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:59:57,077] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:00:03,353] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:00:09,217] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:00:15,172] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:00:21,263] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.203731646290804
[2022-12-07 12:00:21,264] [INFO] [runner_train_mujoco] Average state value: 0.4723806381324927
[2022-12-07 12:00:21,264] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 12:00:21,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.03566
[2022-12-07 12:00:21,363] [INFO] [controller] EPOCH 2 loss ppo:  -0.01892, loss val: 0.03482
[2022-12-07 12:00:21,408] [INFO] [controller] EPOCH 3 loss ppo:  -0.02642, loss val: 0.03633
[2022-12-07 12:00:21,453] [INFO] [controller] EPOCH 4 loss ppo:  -0.03525, loss val: 0.03360
[2022-12-07 12:00:21,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:00:21,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:00:21,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:00:28,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:00:36,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:00:43,173] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:00:49,111] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:00:55,607] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:01:01,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:01:08,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:01:14,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:01:20,401] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:01:25,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5495048617425216
[2022-12-07 12:01:25,835] [INFO] [runner_train_mujoco] Average state value: 0.487295639594396
[2022-12-07 12:01:25,835] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 12:01:25,886] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.05506
[2022-12-07 12:01:25,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.02274, loss val: 0.05756
[2022-12-07 12:01:25,969] [INFO] [controller] EPOCH 3 loss ppo:  -0.03319, loss val: 0.05504
[2022-12-07 12:01:26,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.04159, loss val: 0.05791
[2022-12-07 12:01:26,027] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:01:26,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:01:26,215] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:01:31,832] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:01:38,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:01:44,707] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:01:50,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:01:56,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:02:03,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:02:11,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:02:19,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:02:26,074] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:02:32,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.529172300085778
[2022-12-07 12:02:32,806] [INFO] [runner_train_mujoco] Average state value: 0.4911188857952754
[2022-12-07 12:02:32,806] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 12:02:32,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.03160
[2022-12-07 12:02:32,914] [INFO] [controller] EPOCH 2 loss ppo:  -0.02085, loss val: 0.03215
[2022-12-07 12:02:32,966] [INFO] [controller] EPOCH 3 loss ppo:  -0.02972, loss val: 0.03206
[2022-12-07 12:02:33,014] [INFO] [controller] EPOCH 4 loss ppo:  -0.03783, loss val: 0.03210
[2022-12-07 12:02:33,024] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:02:33,228] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:02:33,229] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:02:39,333] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:02:46,314] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:02:52,935] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:02:59,764] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:03:09,395] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:03:17,778] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:03:26,724] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:03:35,922] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:03:44,330] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:03:53,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.137107596116386
[2022-12-07 12:03:53,800] [INFO] [runner_train_mujoco] Average state value: 0.4835623388588428
[2022-12-07 12:03:53,800] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 12:03:54,138] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.04202
[2022-12-07 12:03:54,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.02022, loss val: 0.04308
[2022-12-07 12:03:54,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.02833, loss val: 0.04199
[2022-12-07 12:03:54,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.03549, loss val: 0.04262
[2022-12-07 12:03:54,821] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:03:55,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:03:55,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:04:08,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:04:19,875] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:04:29,176] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:04:37,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:04:46,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:04:53,948] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:05:00,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:05:06,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:05:13,724] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:05:20,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.409555443404285
[2022-12-07 12:05:20,014] [INFO] [runner_train_mujoco] Average state value: 0.4861577365497748
[2022-12-07 12:05:20,014] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 12:05:20,070] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.03669
[2022-12-07 12:05:20,117] [INFO] [controller] EPOCH 2 loss ppo:  -0.02156, loss val: 0.04010
[2022-12-07 12:05:20,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.02872, loss val: 0.04125
[2022-12-07 12:05:20,221] [INFO] [controller] EPOCH 4 loss ppo:  -0.03291, loss val: 0.03680
[2022-12-07 12:05:20,233] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:05:20,443] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:05:20,443] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:05:26,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:05:33,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:05:39,899] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:05:46,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:05:53,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:05:59,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:06:06,626] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:06:13,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:06:19,972] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:06:27,733] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.779714082656855
[2022-12-07 12:06:27,734] [INFO] [runner_train_mujoco] Average state value: 0.4942864522536595
[2022-12-07 12:06:27,734] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 12:06:27,821] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.04228
[2022-12-07 12:06:27,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.01886, loss val: 0.04220
[2022-12-07 12:06:27,943] [INFO] [controller] EPOCH 3 loss ppo:  -0.02538, loss val: 0.04469
[2022-12-07 12:06:27,998] [INFO] [controller] EPOCH 4 loss ppo:  -0.03176, loss val: 0.04544
[2022-12-07 12:06:28,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:06:28,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:06:28,243] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:06:37,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:06:45,113] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:06:52,880] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:07:00,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:07:09,066] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:07:16,471] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:07:23,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:07:30,703] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:07:37,033] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:07:43,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.330181406223551
[2022-12-07 12:07:43,761] [INFO] [runner_train_mujoco] Average state value: 0.4865337713658809
[2022-12-07 12:07:43,761] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 12:07:43,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.03441
[2022-12-07 12:07:43,878] [INFO] [controller] EPOCH 2 loss ppo:  -0.01723, loss val: 0.03492
[2022-12-07 12:07:43,930] [INFO] [controller] EPOCH 3 loss ppo:  -0.02374, loss val: 0.03486
[2022-12-07 12:07:43,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.03052, loss val: 0.03436
[2022-12-07 12:07:43,994] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:07:44,201] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:07:44,201] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:07:51,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:07:58,206] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:08:05,084] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:08:11,091] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:08:17,353] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:08:23,722] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:08:30,542] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:08:36,832] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:08:42,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:08:48,706] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.668720290054255
[2022-12-07 12:08:48,706] [INFO] [runner_train_mujoco] Average state value: 0.488855419109265
[2022-12-07 12:08:48,706] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 12:08:48,763] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04863
[2022-12-07 12:08:48,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.01751, loss val: 0.04439
[2022-12-07 12:08:48,856] [INFO] [controller] EPOCH 3 loss ppo:  -0.02292, loss val: 0.04560
[2022-12-07 12:08:48,910] [INFO] [controller] EPOCH 4 loss ppo:  -0.02871, loss val: 0.04626
[2022-12-07 12:08:48,921] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:08:49,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:08:49,112] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:08:55,433] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:09:01,965] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:09:08,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:09:14,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:09:20,481] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:09:26,811] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:09:32,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:09:38,746] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:09:44,338] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:09:50,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.795603402825065
[2022-12-07 12:09:50,476] [INFO] [runner_train_mujoco] Average state value: 0.4857762699425221
[2022-12-07 12:09:50,476] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 12:09:50,537] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04226
[2022-12-07 12:09:50,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.01567, loss val: 0.04575
[2022-12-07 12:09:50,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.01896, loss val: 0.04642
[2022-12-07 12:09:50,687] [INFO] [controller] EPOCH 4 loss ppo:  -0.02294, loss val: 0.04539
[2022-12-07 12:09:50,697] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:09:50,894] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:09:50,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:09:57,001] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:10:02,912] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:10:08,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:10:13,726] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:10:20,146] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:10:25,342] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:10:31,306] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:10:37,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:10:43,412] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:10:48,860] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5940964529660295
[2022-12-07 12:10:48,861] [INFO] [runner_train_mujoco] Average state value: 0.4812607275148233
[2022-12-07 12:10:48,861] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 12:10:48,927] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04023
[2022-12-07 12:10:48,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.01432, loss val: 0.04023
[2022-12-07 12:10:49,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.01560, loss val: 0.03999
[2022-12-07 12:10:49,096] [INFO] [controller] EPOCH 4 loss ppo:  -0.01736, loss val: 0.03978
[2022-12-07 12:10:49,109] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:10:49,232] [INFO] [optimize] Finished learning.
