[2022-12-07 04:44:58,562] [INFO] [optimize] Starting learning
[2022-12-07 04:44:58,575] [INFO] [optimize] Starting learning process..
[2022-12-07 04:44:58,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:44:58,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:45:06,888] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:45:13,899] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:45:20,861] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:45:28,540] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:45:36,187] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:45:43,919] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:45:51,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:45:58,667] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:46:06,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:46:13,790] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.597918908310317
[2022-12-07 04:46:13,790] [INFO] [runner_train_mujoco] Average state value: 0.12922978356728954
[2022-12-07 04:46:13,790] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 04:46:13,903] [INFO] [controller] EPOCH 1 loss ppo:  -0.01628, loss val: 0.25722
[2022-12-07 04:46:13,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.04348, loss val: 0.21841
[2022-12-07 04:46:14,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.05722, loss val: 0.18786
[2022-12-07 04:46:14,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.06252, loss val: 0.16353
[2022-12-07 04:46:14,120] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:46:14,329] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:46:14,329] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:46:21,934] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:46:29,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:46:36,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:46:44,807] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:46:52,403] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:47:00,037] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:47:07,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:47:14,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:47:22,101] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:47:29,532] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4648292993777393
[2022-12-07 04:47:29,533] [INFO] [runner_train_mujoco] Average state value: 0.2741722943664838
[2022-12-07 04:47:29,533] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 04:47:29,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.18513
[2022-12-07 04:47:29,703] [INFO] [controller] EPOCH 2 loss ppo:  -0.04310, loss val: 0.15941
[2022-12-07 04:47:29,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.05796, loss val: 0.13954
[2022-12-07 04:47:29,828] [INFO] [controller] EPOCH 4 loss ppo:  -0.06694, loss val: 0.12058
[2022-12-07 04:47:29,839] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:47:30,034] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:47:30,034] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:47:37,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:47:44,915] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:47:51,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:47:58,472] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:48:05,748] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:48:12,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:48:18,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:48:25,602] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:48:32,282] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:48:38,762] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.49997644836390964
[2022-12-07 04:48:38,762] [INFO] [runner_train_mujoco] Average state value: 0.44268501955394945
[2022-12-07 04:48:38,762] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 04:48:38,845] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.09085
[2022-12-07 04:48:38,902] [INFO] [controller] EPOCH 2 loss ppo:  -0.04482, loss val: 0.08695
[2022-12-07 04:48:38,954] [INFO] [controller] EPOCH 3 loss ppo:  -0.05714, loss val: 0.08353
[2022-12-07 04:48:39,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.06512, loss val: 0.07989
[2022-12-07 04:48:39,022] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:48:39,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:48:39,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:48:46,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:48:52,676] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:48:59,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:49:06,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:49:13,317] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:49:19,911] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:49:26,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:49:33,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:49:40,199] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:49:46,920] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6548750458092771
[2022-12-07 04:49:46,921] [INFO] [runner_train_mujoco] Average state value: 0.5191017552632838
[2022-12-07 04:49:46,921] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 04:49:46,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.07544
[2022-12-07 04:49:47,036] [INFO] [controller] EPOCH 2 loss ppo:  -0.03601, loss val: 0.07372
[2022-12-07 04:49:47,084] [INFO] [controller] EPOCH 3 loss ppo:  -0.04773, loss val: 0.06371
[2022-12-07 04:49:47,135] [INFO] [controller] EPOCH 4 loss ppo:  -0.05479, loss val: 0.05672
[2022-12-07 04:49:47,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:49:47,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:49:47,350] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:49:54,360] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:50:01,400] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:50:08,387] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:50:14,767] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:50:21,771] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:50:28,537] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:35,076] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:50:41,813] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:50:48,598] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:50:55,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6133566899963439
[2022-12-07 04:50:55,354] [INFO] [runner_train_mujoco] Average state value: 0.45928271797734005
[2022-12-07 04:50:55,355] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 04:50:55,427] [INFO] [controller] EPOCH 1 loss ppo:  -0.01195, loss val: 0.06443
[2022-12-07 04:50:55,482] [INFO] [controller] EPOCH 2 loss ppo:  -0.03108, loss val: 0.05808
[2022-12-07 04:50:55,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.04066, loss val: 0.05799
[2022-12-07 04:50:55,587] [INFO] [controller] EPOCH 4 loss ppo:  -0.05198, loss val: 0.05412
[2022-12-07 04:50:55,597] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:50:55,802] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:50:55,803] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:51:02,926] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:51:09,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:51:16,773] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:51:23,774] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:51:30,653] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:51:37,509] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:51:44,149] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:51:50,935] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:51:57,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:52:04,423] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5138864626960509
[2022-12-07 04:52:04,423] [INFO] [runner_train_mujoco] Average state value: 0.4507703844457865
[2022-12-07 04:52:04,423] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 04:52:04,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01122, loss val: 0.06254
[2022-12-07 04:52:04,558] [INFO] [controller] EPOCH 2 loss ppo:  -0.03459, loss val: 0.05996
[2022-12-07 04:52:04,618] [INFO] [controller] EPOCH 3 loss ppo:  -0.04991, loss val: 0.05730
[2022-12-07 04:52:04,830] [INFO] [controller] EPOCH 4 loss ppo:  -0.05841, loss val: 0.05524
[2022-12-07 04:52:04,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:52:05,036] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:52:05,037] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:52:11,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:52:18,941] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:52:25,426] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:52:32,225] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:52:38,991] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:52:45,547] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:52:51,800] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:52:58,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:53:05,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:53:13,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6158905522817448
[2022-12-07 04:53:13,781] [INFO] [runner_train_mujoco] Average state value: 0.4977850573112567
[2022-12-07 04:53:13,781] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 04:53:13,856] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04820
[2022-12-07 04:53:13,917] [INFO] [controller] EPOCH 2 loss ppo:  -0.03657, loss val: 0.04058
[2022-12-07 04:53:13,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.04752, loss val: 0.04056
[2022-12-07 04:53:14,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.05711, loss val: 0.03752
[2022-12-07 04:53:14,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:53:14,260] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:53:14,261] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:20,993] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:53:27,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:53:33,999] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:53:40,522] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:53:47,503] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:53:54,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:54:00,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:54:08,020] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:54:14,378] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:54:20,941] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5580788278434076
[2022-12-07 04:54:20,941] [INFO] [runner_train_mujoco] Average state value: 0.5648661104838053
[2022-12-07 04:54:20,941] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 04:54:20,994] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.05372
[2022-12-07 04:54:21,038] [INFO] [controller] EPOCH 2 loss ppo:  -0.02885, loss val: 0.05441
[2022-12-07 04:54:21,085] [INFO] [controller] EPOCH 3 loss ppo:  -0.03839, loss val: 0.05461
[2022-12-07 04:54:21,128] [INFO] [controller] EPOCH 4 loss ppo:  -0.04645, loss val: 0.04924
[2022-12-07 04:54:21,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:54:21,337] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:54:21,337] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:54:28,136] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:54:34,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:54:41,122] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:54:48,300] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:54:55,127] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:55:01,932] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:55:08,857] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:55:14,987] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:55:21,575] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:55:28,059] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9694069679529391
[2022-12-07 04:55:28,059] [INFO] [runner_train_mujoco] Average state value: 0.5532640150785447
[2022-12-07 04:55:28,059] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 04:55:28,134] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.03795
[2022-12-07 04:55:28,187] [INFO] [controller] EPOCH 2 loss ppo:  -0.03012, loss val: 0.03824
[2022-12-07 04:55:28,238] [INFO] [controller] EPOCH 3 loss ppo:  -0.04403, loss val: 0.03375
[2022-12-07 04:55:28,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.05209, loss val: 0.03365
[2022-12-07 04:55:28,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:55:28,499] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:55:28,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:55:35,227] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:55:41,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:55:48,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:55:54,435] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:56:01,129] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:56:07,794] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:56:14,685] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:56:21,285] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:56:28,266] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:56:34,679] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.045429865675991
[2022-12-07 04:56:34,679] [INFO] [runner_train_mujoco] Average state value: 0.5004511372447015
[2022-12-07 04:56:34,679] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 04:56:34,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.04460
[2022-12-07 04:56:34,793] [INFO] [controller] EPOCH 2 loss ppo:  -0.02875, loss val: 0.04325
[2022-12-07 04:56:34,843] [INFO] [controller] EPOCH 3 loss ppo:  -0.04312, loss val: 0.03943
[2022-12-07 04:56:34,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.05218, loss val: 0.03735
[2022-12-07 04:56:34,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:56:35,091] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:56:35,094] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:56:41,826] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:56:48,515] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:56:55,046] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:57:01,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:57:07,878] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:57:14,385] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:57:21,155] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:57:27,539] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:57:33,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:57:40,019] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0842489785826592
[2022-12-07 04:57:40,019] [INFO] [runner_train_mujoco] Average state value: 0.4274913650949796
[2022-12-07 04:57:40,020] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 04:57:40,092] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.03453
[2022-12-07 04:57:40,140] [INFO] [controller] EPOCH 2 loss ppo:  -0.03514, loss val: 0.03617
[2022-12-07 04:57:40,192] [INFO] [controller] EPOCH 3 loss ppo:  -0.04446, loss val: 0.03775
[2022-12-07 04:57:40,244] [INFO] [controller] EPOCH 4 loss ppo:  -0.05454, loss val: 0.03439
[2022-12-07 04:57:40,254] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:57:40,453] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:57:40,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:57:47,548] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:57:54,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:58:01,813] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:58:08,546] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:58:15,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:58:22,017] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:58:28,768] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:58:35,334] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:58:41,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:58:47,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1832814905853657
[2022-12-07 04:58:47,751] [INFO] [runner_train_mujoco] Average state value: 0.43324607932567594
[2022-12-07 04:58:47,751] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 04:58:47,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.04594
[2022-12-07 04:58:47,875] [INFO] [controller] EPOCH 2 loss ppo:  -0.03391, loss val: 0.03831
[2022-12-07 04:58:47,991] [INFO] [controller] EPOCH 3 loss ppo:  -0.04433, loss val: 0.03389
[2022-12-07 04:58:48,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.05202, loss val: 0.02873
[2022-12-07 04:58:48,050] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:58:48,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:58:48,250] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:58:54,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:59:01,003] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:59:07,540] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:59:14,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:59:21,336] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:59:28,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:59:34,693] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:59:41,090] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:59:47,542] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:59:53,873] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2033357427837188
[2022-12-07 04:59:53,873] [INFO] [runner_train_mujoco] Average state value: 0.5265487222274144
[2022-12-07 04:59:53,873] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 04:59:53,930] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04853
[2022-12-07 04:59:53,972] [INFO] [controller] EPOCH 2 loss ppo:  -0.03684, loss val: 0.04917
[2022-12-07 04:59:54,018] [INFO] [controller] EPOCH 3 loss ppo:  -0.04727, loss val: 0.05008
[2022-12-07 04:59:54,071] [INFO] [controller] EPOCH 4 loss ppo:  -0.05775, loss val: 0.05057
[2022-12-07 04:59:54,080] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:59:54,272] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:59:54,272] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:00:00,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:00:07,300] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:00:13,464] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:00:19,392] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:00:25,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:00:32,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:00:39,144] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:00:45,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:00:51,602] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:00:58,151] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6269781710431954
[2022-12-07 05:00:58,151] [INFO] [runner_train_mujoco] Average state value: 0.5722888789474965
[2022-12-07 05:00:58,152] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 05:00:58,211] [INFO] [controller] EPOCH 1 loss ppo:  -0.01590, loss val: 0.05841
[2022-12-07 05:00:58,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.04321, loss val: 0.05907
[2022-12-07 05:00:58,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.04913, loss val: 0.05873
[2022-12-07 05:00:58,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.05783, loss val: 0.05740
[2022-12-07 05:00:58,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:00:58,573] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:00:58,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:01:05,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:01:11,810] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:01:18,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:01:24,407] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:01:31,163] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:01:37,857] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:01:44,312] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:01:50,737] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:01:56,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:02:03,209] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6934056207138206
[2022-12-07 05:02:03,210] [INFO] [runner_train_mujoco] Average state value: 0.5539366816679637
[2022-12-07 05:02:03,210] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 05:02:03,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.05067
[2022-12-07 05:02:03,321] [INFO] [controller] EPOCH 2 loss ppo:  -0.03290, loss val: 0.04793
[2022-12-07 05:02:03,369] [INFO] [controller] EPOCH 3 loss ppo:  -0.04420, loss val: 0.04557
[2022-12-07 05:02:03,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.05517, loss val: 0.04226
[2022-12-07 05:02:03,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:02:03,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:02:03,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:02:09,769] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:02:16,303] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:02:22,781] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:02:29,241] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:02:35,745] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:02:42,405] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:02:48,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:02:55,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:03:01,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:03:08,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7643611924717573
[2022-12-07 05:03:08,014] [INFO] [runner_train_mujoco] Average state value: 0.48694615300496424
[2022-12-07 05:03:08,014] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 05:03:08,072] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.04671
[2022-12-07 05:03:08,118] [INFO] [controller] EPOCH 2 loss ppo:  -0.03640, loss val: 0.04323
[2022-12-07 05:03:08,163] [INFO] [controller] EPOCH 3 loss ppo:  -0.04456, loss val: 0.04205
[2022-12-07 05:03:08,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.05368, loss val: 0.04080
[2022-12-07 05:03:08,219] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:03:08,408] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:03:08,409] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:03:15,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:03:21,960] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:03:28,537] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:03:35,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:03:41,543] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:03:48,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:03:53,910] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:04:00,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:04:06,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:04:12,880] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0650991257675475
[2022-12-07 05:04:12,881] [INFO] [runner_train_mujoco] Average state value: 0.4002483020474513
[2022-12-07 05:04:12,881] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 05:04:12,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.03820
[2022-12-07 05:04:12,998] [INFO] [controller] EPOCH 2 loss ppo:  -0.03474, loss val: 0.03924
[2022-12-07 05:04:13,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.04424, loss val: 0.04116
[2022-12-07 05:04:13,118] [INFO] [controller] EPOCH 4 loss ppo:  -0.05266, loss val: 0.04168
[2022-12-07 05:04:13,128] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:13,322] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:13,323] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:04:20,255] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:04:26,728] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:04:33,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:04:39,475] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:04:45,550] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:04:51,741] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:04:58,076] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:05:04,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:05:11,289] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:05:17,783] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2190302268462827
[2022-12-07 05:05:17,783] [INFO] [runner_train_mujoco] Average state value: 0.3927559233208497
[2022-12-07 05:05:17,784] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 05:05:17,843] [INFO] [controller] EPOCH 1 loss ppo:  -0.01554, loss val: 0.03119
[2022-12-07 05:05:17,902] [INFO] [controller] EPOCH 2 loss ppo:  -0.03341, loss val: 0.02994
[2022-12-07 05:05:17,950] [INFO] [controller] EPOCH 3 loss ppo:  -0.04797, loss val: 0.02938
[2022-12-07 05:05:18,005] [INFO] [controller] EPOCH 4 loss ppo:  -0.05841, loss val: 0.02820
[2022-12-07 05:05:18,015] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:05:18,202] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:05:18,202] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:05:24,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:05:31,019] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:05:37,321] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:05:43,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:05:50,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:05:56,911] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:06:03,316] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:06:09,411] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:06:15,888] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:06:21,915] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2873512992978964
[2022-12-07 05:06:21,915] [INFO] [runner_train_mujoco] Average state value: 0.4397934933702151
[2022-12-07 05:06:21,915] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 05:06:21,984] [INFO] [controller] EPOCH 1 loss ppo:  -0.01521, loss val: 0.05224
[2022-12-07 05:06:22,034] [INFO] [controller] EPOCH 2 loss ppo:  -0.03400, loss val: 0.05332
[2022-12-07 05:06:22,080] [INFO] [controller] EPOCH 3 loss ppo:  -0.04525, loss val: 0.05119
[2022-12-07 05:06:22,129] [INFO] [controller] EPOCH 4 loss ppo:  -0.05944, loss val: 0.05199
[2022-12-07 05:06:22,139] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:06:22,330] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:06:22,331] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:06:28,561] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:06:35,434] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:06:42,521] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:06:48,745] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:06:55,242] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:07:01,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:07:09,304] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:07:16,326] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:07:23,585] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:07:30,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4722987362968687
[2022-12-07 05:07:30,078] [INFO] [runner_train_mujoco] Average state value: 0.4780352902313073
[2022-12-07 05:07:30,078] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:07:30,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.02999
[2022-12-07 05:07:30,195] [INFO] [controller] EPOCH 2 loss ppo:  -0.03081, loss val: 0.02965
[2022-12-07 05:07:30,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.04406, loss val: 0.02910
[2022-12-07 05:07:30,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.05438, loss val: 0.02982
[2022-12-07 05:07:30,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:07:30,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:07:30,481] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:07:37,418] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:07:44,305] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:07:50,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:07:57,029] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:08:03,066] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:08:09,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:08:15,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:08:22,184] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:08:28,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:08:35,085] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.198782809802686
[2022-12-07 05:08:35,085] [INFO] [runner_train_mujoco] Average state value: 0.5105221735735734
[2022-12-07 05:08:35,085] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 05:08:35,138] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.03502
[2022-12-07 05:08:35,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.03382, loss val: 0.03803
[2022-12-07 05:08:35,238] [INFO] [controller] EPOCH 3 loss ppo:  -0.04736, loss val: 0.03497
[2022-12-07 05:08:35,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.05863, loss val: 0.03450
[2022-12-07 05:08:35,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:08:35,487] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:08:35,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:08:41,839] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:08:48,561] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:08:54,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:09:01,207] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:09:07,726] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:09:13,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:09:20,316] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:09:26,452] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:09:32,427] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:09:39,007] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.51335924440337
[2022-12-07 05:09:39,008] [INFO] [runner_train_mujoco] Average state value: 0.5138063904245693
[2022-12-07 05:09:39,008] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 05:09:39,068] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.05315
[2022-12-07 05:09:39,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.02712, loss val: 0.05016
[2022-12-07 05:09:39,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.03811, loss val: 0.04632
[2022-12-07 05:09:39,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.05069, loss val: 0.04429
[2022-12-07 05:09:39,230] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:09:39,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:09:39,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:09:46,021] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:09:52,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:09:59,077] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:10:05,332] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:10:11,684] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:10:18,277] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:10:24,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:10:31,129] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:10:37,685] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:10:43,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6688886459040413
[2022-12-07 05:10:43,781] [INFO] [runner_train_mujoco] Average state value: 0.46388863374789563
[2022-12-07 05:10:43,781] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 05:10:43,856] [INFO] [controller] EPOCH 1 loss ppo:  -0.01526, loss val: 0.04368
[2022-12-07 05:10:43,911] [INFO] [controller] EPOCH 2 loss ppo:  -0.03392, loss val: 0.04373
[2022-12-07 05:10:43,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.04643, loss val: 0.04361
[2022-12-07 05:10:44,019] [INFO] [controller] EPOCH 4 loss ppo:  -0.05675, loss val: 0.04398
[2022-12-07 05:10:44,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:10:44,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:10:44,231] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:10:50,637] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:10:57,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:11:03,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:11:09,858] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:11:16,204] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:11:22,732] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:11:28,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:11:35,166] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:11:41,730] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:11:48,516] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.054869067527399
[2022-12-07 05:11:48,516] [INFO] [runner_train_mujoco] Average state value: 0.4219212324420611
[2022-12-07 05:11:48,516] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 05:11:48,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.04645
[2022-12-07 05:11:48,655] [INFO] [controller] EPOCH 2 loss ppo:  -0.03233, loss val: 0.04448
[2022-12-07 05:11:48,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.04219, loss val: 0.04728
[2022-12-07 05:11:48,758] [INFO] [controller] EPOCH 4 loss ppo:  -0.05182, loss val: 0.04522
[2022-12-07 05:11:48,768] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:11:48,961] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:11:48,962] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:11:55,332] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:12:01,755] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:12:08,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:12:13,996] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:12:20,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:12:26,200] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:12:32,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:12:38,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:12:45,030] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:12:51,348] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7451178194468144
[2022-12-07 05:12:51,348] [INFO] [runner_train_mujoco] Average state value: 0.4322059147457281
[2022-12-07 05:12:51,348] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 05:12:51,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01680, loss val: 0.03801
[2022-12-07 05:12:51,466] [INFO] [controller] EPOCH 2 loss ppo:  -0.03697, loss val: 0.03810
[2022-12-07 05:12:51,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.04364, loss val: 0.04043
[2022-12-07 05:12:51,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.05511, loss val: 0.04001
[2022-12-07 05:12:51,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:12:51,855] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:12:51,855] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:12:57,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:13:03,654] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:13:09,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:13:15,288] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:13:21,371] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:13:26,902] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:13:32,688] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:13:38,695] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:13:44,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:13:49,667] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7499082406761914
[2022-12-07 05:13:49,667] [INFO] [runner_train_mujoco] Average state value: 0.44445728154977165
[2022-12-07 05:13:49,667] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 05:13:49,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.04507
[2022-12-07 05:13:49,771] [INFO] [controller] EPOCH 2 loss ppo:  -0.03050, loss val: 0.04371
[2022-12-07 05:13:49,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.04008, loss val: 0.04228
[2022-12-07 05:13:49,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.04874, loss val: 0.04380
[2022-12-07 05:13:49,874] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:13:50,046] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:13:50,047] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:13:56,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:01,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:14:07,776] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:14:13,546] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:14:19,012] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:14:24,941] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:14:30,317] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:14:35,711] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:14:41,804] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:14:47,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7300146288605562
[2022-12-07 05:14:47,378] [INFO] [runner_train_mujoco] Average state value: 0.408360677878062
[2022-12-07 05:14:47,378] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 05:14:47,438] [INFO] [controller] EPOCH 1 loss ppo:  -0.01559, loss val: 0.04447
[2022-12-07 05:14:47,481] [INFO] [controller] EPOCH 2 loss ppo:  -0.03438, loss val: 0.04659
[2022-12-07 05:14:47,529] [INFO] [controller] EPOCH 3 loss ppo:  -0.04317, loss val: 0.04713
[2022-12-07 05:14:47,586] [INFO] [controller] EPOCH 4 loss ppo:  -0.05918, loss val: 0.04457
[2022-12-07 05:14:47,595] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:14:47,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:14:47,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:14:53,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:59,722] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:15:05,130] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:15:10,636] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:15:15,818] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:15:21,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:15:26,931] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:15:33,100] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:15:38,979] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:15:45,365] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0147832967445556
[2022-12-07 05:15:45,365] [INFO] [runner_train_mujoco] Average state value: 0.4121297600468
[2022-12-07 05:15:45,365] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 05:15:45,427] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04572
[2022-12-07 05:15:45,479] [INFO] [controller] EPOCH 2 loss ppo:  -0.02579, loss val: 0.04460
[2022-12-07 05:15:45,529] [INFO] [controller] EPOCH 3 loss ppo:  -0.03793, loss val: 0.04323
[2022-12-07 05:15:45,579] [INFO] [controller] EPOCH 4 loss ppo:  -0.04884, loss val: 0.04190
[2022-12-07 05:15:45,590] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:15:45,792] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:15:45,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:15:51,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:15:56,418] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:16:02,027] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:16:07,737] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:16:13,456] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:16:19,531] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:16:24,877] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:16:30,604] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:16:36,040] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:16:41,822] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.971797073284421
[2022-12-07 05:16:41,822] [INFO] [runner_train_mujoco] Average state value: 0.4583934669295947
[2022-12-07 05:16:41,822] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 05:16:41,882] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04730
[2022-12-07 05:16:41,923] [INFO] [controller] EPOCH 2 loss ppo:  -0.03670, loss val: 0.04785
[2022-12-07 05:16:41,963] [INFO] [controller] EPOCH 3 loss ppo:  -0.04750, loss val: 0.04720
[2022-12-07 05:16:42,003] [INFO] [controller] EPOCH 4 loss ppo:  -0.05864, loss val: 0.04720
[2022-12-07 05:16:42,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:16:42,190] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:16:42,190] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:16:48,313] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:16:54,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:16:59,801] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:17:05,867] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:17:10,999] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:17:16,671] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:17:22,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:17:27,579] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:17:32,995] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:17:38,674] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0451433451523284
[2022-12-07 05:17:38,675] [INFO] [runner_train_mujoco] Average state value: 0.48044624408086145
[2022-12-07 05:17:38,675] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 05:17:38,726] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.04172
[2022-12-07 05:17:38,771] [INFO] [controller] EPOCH 2 loss ppo:  -0.03406, loss val: 0.04058
[2022-12-07 05:17:38,818] [INFO] [controller] EPOCH 3 loss ppo:  -0.04281, loss val: 0.04001
[2022-12-07 05:17:38,869] [INFO] [controller] EPOCH 4 loss ppo:  -0.05365, loss val: 0.03893
[2022-12-07 05:17:38,879] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:17:39,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:17:39,076] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:17:45,255] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:17:51,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:17:56,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:18:02,310] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:18:07,948] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:18:13,465] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:18:19,054] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:18:24,787] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:18:30,507] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:18:35,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.056658018977152
[2022-12-07 05:18:35,983] [INFO] [runner_train_mujoco] Average state value: 0.4534230042298636
[2022-12-07 05:18:35,983] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 05:18:36,035] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.03947
[2022-12-07 05:18:36,090] [INFO] [controller] EPOCH 2 loss ppo:  -0.03009, loss val: 0.03857
[2022-12-07 05:18:36,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.04526, loss val: 0.03927
[2022-12-07 05:18:36,184] [INFO] [controller] EPOCH 4 loss ppo:  -0.05583, loss val: 0.04013
[2022-12-07 05:18:36,192] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:18:36,344] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:18:36,345] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:18:42,058] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:18:47,732] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:18:53,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:18:59,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:19:04,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:19:10,330] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:19:15,976] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:19:21,220] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:19:26,934] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:19:32,638] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2512947170174913
[2022-12-07 05:19:32,638] [INFO] [runner_train_mujoco] Average state value: 0.4196874483625094
[2022-12-07 05:19:32,639] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 05:19:32,695] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.04027
[2022-12-07 05:19:32,742] [INFO] [controller] EPOCH 2 loss ppo:  -0.03105, loss val: 0.03674
[2022-12-07 05:19:32,788] [INFO] [controller] EPOCH 3 loss ppo:  -0.04129, loss val: 0.03654
[2022-12-07 05:19:32,834] [INFO] [controller] EPOCH 4 loss ppo:  -0.05045, loss val: 0.03603
[2022-12-07 05:19:32,842] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:19:33,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:19:33,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:19:38,901] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:19:44,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:19:50,433] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:19:56,068] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:20:01,348] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:20:06,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:20:12,574] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:20:17,939] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:20:24,369] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:20:30,207] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.22098527915425
[2022-12-07 05:20:30,208] [INFO] [runner_train_mujoco] Average state value: 0.43373524911204975
[2022-12-07 05:20:30,208] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 05:20:30,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04743
[2022-12-07 05:20:30,349] [INFO] [controller] EPOCH 2 loss ppo:  -0.03279, loss val: 0.04777
[2022-12-07 05:20:30,395] [INFO] [controller] EPOCH 3 loss ppo:  -0.04716, loss val: 0.04866
[2022-12-07 05:20:30,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.05840, loss val: 0.04882
[2022-12-07 05:20:30,449] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:20:30,662] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:20:30,662] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:20:36,615] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:20:42,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:20:48,480] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:20:53,917] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:20:59,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:21:05,478] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:21:10,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:21:16,630] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:21:22,380] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:21:27,871] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1414718942231814
[2022-12-07 05:21:27,871] [INFO] [runner_train_mujoco] Average state value: 0.4423742115994294
[2022-12-07 05:21:27,871] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 05:21:27,931] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.04535
[2022-12-07 05:21:27,980] [INFO] [controller] EPOCH 2 loss ppo:  -0.03241, loss val: 0.04482
[2022-12-07 05:21:28,026] [INFO] [controller] EPOCH 3 loss ppo:  -0.04363, loss val: 0.04451
[2022-12-07 05:21:28,075] [INFO] [controller] EPOCH 4 loss ppo:  -0.05148, loss val: 0.04523
[2022-12-07 05:21:28,091] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:21:28,277] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:21:28,289] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:21:33,741] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:21:39,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:21:45,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:21:51,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:21:57,044] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:22:02,855] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:22:08,560] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:22:13,998] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:22:19,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:22:25,368] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.706111978873056
[2022-12-07 05:22:25,368] [INFO] [runner_train_mujoco] Average state value: 0.4559795732100804
[2022-12-07 05:22:25,368] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 05:22:25,492] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.05098
[2022-12-07 05:22:25,549] [INFO] [controller] EPOCH 2 loss ppo:  -0.03156, loss val: 0.05057
[2022-12-07 05:22:25,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.04709, loss val: 0.04893
[2022-12-07 05:22:25,658] [INFO] [controller] EPOCH 4 loss ppo:  -0.06016, loss val: 0.05051
[2022-12-07 05:22:25,669] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:22:25,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:22:25,869] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:22:31,308] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:22:37,146] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:22:43,104] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:22:48,523] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:22:53,935] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:22:59,415] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:23:04,868] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:23:10,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:23:16,044] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:23:22,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7607955216185553
[2022-12-07 05:23:22,014] [INFO] [runner_train_mujoco] Average state value: 0.4837537710666656
[2022-12-07 05:23:22,014] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 05:23:22,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.04909
[2022-12-07 05:23:22,127] [INFO] [controller] EPOCH 2 loss ppo:  -0.03010, loss val: 0.04914
[2022-12-07 05:23:22,173] [INFO] [controller] EPOCH 3 loss ppo:  -0.04209, loss val: 0.04911
[2022-12-07 05:23:22,229] [INFO] [controller] EPOCH 4 loss ppo:  -0.05538, loss val: 0.04865
[2022-12-07 05:23:22,240] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:23:22,444] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:23:22,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:23:28,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:23:34,274] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:23:40,309] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:23:46,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:23:51,551] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:23:56,666] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:24:01,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:24:07,559] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:24:12,859] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:24:18,932] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5852514680738117
[2022-12-07 05:24:18,932] [INFO] [runner_train_mujoco] Average state value: 0.4823853286802768
[2022-12-07 05:24:18,932] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 05:24:18,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.01172, loss val: 0.03765
[2022-12-07 05:24:19,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.02454, loss val: 0.03799
[2022-12-07 05:24:19,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.03935, loss val: 0.03775
[2022-12-07 05:24:19,117] [INFO] [controller] EPOCH 4 loss ppo:  -0.05458, loss val: 0.03688
[2022-12-07 05:24:19,127] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:24:19,294] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:24:19,295] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:24:25,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:24:30,653] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:24:36,378] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:24:42,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:24:47,711] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:24:53,351] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:24:58,795] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:25:04,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:25:10,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:25:15,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.678221837570109
[2022-12-07 05:25:15,829] [INFO] [runner_train_mujoco] Average state value: 0.4622527908980846
[2022-12-07 05:25:15,829] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 05:25:15,884] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.03142
[2022-12-07 05:25:15,929] [INFO] [controller] EPOCH 2 loss ppo:  -0.02708, loss val: 0.03124
[2022-12-07 05:25:15,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.03665, loss val: 0.03158
[2022-12-07 05:25:16,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.04796, loss val: 0.03264
[2022-12-07 05:25:16,038] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:25:16,229] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:25:16,229] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:25:22,137] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:25:27,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:25:33,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:25:39,294] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:25:44,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:25:50,608] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:25:56,089] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:26:01,508] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:26:06,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:26:12,029] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6778289859085795
[2022-12-07 05:26:12,029] [INFO] [runner_train_mujoco] Average state value: 0.45025371127327274
[2022-12-07 05:26:12,029] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 05:26:12,082] [INFO] [controller] EPOCH 1 loss ppo:  -0.01510, loss val: 0.03914
[2022-12-07 05:26:12,124] [INFO] [controller] EPOCH 2 loss ppo:  -0.03233, loss val: 0.03954
[2022-12-07 05:26:12,168] [INFO] [controller] EPOCH 3 loss ppo:  -0.04374, loss val: 0.03930
[2022-12-07 05:26:12,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.05614, loss val: 0.03936
[2022-12-07 05:26:12,220] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:26:12,398] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:26:12,398] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:26:18,281] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:26:24,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:26:30,146] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:26:36,224] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:26:42,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:26:48,010] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:26:53,419] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:26:58,934] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:27:04,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:27:10,182] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.723374148784457
[2022-12-07 05:27:10,182] [INFO] [runner_train_mujoco] Average state value: 0.4488305105268955
[2022-12-07 05:27:10,182] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 05:27:10,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01526, loss val: 0.04975
[2022-12-07 05:27:10,331] [INFO] [controller] EPOCH 2 loss ppo:  -0.02990, loss val: 0.04934
[2022-12-07 05:27:10,398] [INFO] [controller] EPOCH 3 loss ppo:  -0.04083, loss val: 0.04726
[2022-12-07 05:27:10,449] [INFO] [controller] EPOCH 4 loss ppo:  -0.05010, loss val: 0.04657
[2022-12-07 05:27:10,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:27:10,643] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:27:10,644] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:27:16,318] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:27:22,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:27:28,192] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:27:33,834] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:27:39,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:27:45,027] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:27:50,380] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:27:55,798] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:28:01,475] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:28:07,236] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3575711789154283
[2022-12-07 05:28:07,237] [INFO] [runner_train_mujoco] Average state value: 0.47521671176950137
[2022-12-07 05:28:07,237] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 05:28:07,298] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.03069
[2022-12-07 05:28:07,343] [INFO] [controller] EPOCH 2 loss ppo:  -0.03127, loss val: 0.03246
[2022-12-07 05:28:07,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.04488, loss val: 0.03123
[2022-12-07 05:28:07,426] [INFO] [controller] EPOCH 4 loss ppo:  -0.05346, loss val: 0.03400
[2022-12-07 05:28:07,434] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:28:07,620] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:28:07,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:28:13,119] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:28:19,096] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:28:24,546] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:28:30,339] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:28:36,198] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:28:41,830] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:28:47,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:28:53,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:28:59,003] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:29:04,290] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7588648661101844
[2022-12-07 05:29:04,290] [INFO] [runner_train_mujoco] Average state value: 0.48309023748834934
[2022-12-07 05:29:04,290] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 05:29:04,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.03703
[2022-12-07 05:29:04,405] [INFO] [controller] EPOCH 2 loss ppo:  -0.02673, loss val: 0.03725
[2022-12-07 05:29:04,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.03426, loss val: 0.03658
[2022-12-07 05:29:04,510] [INFO] [controller] EPOCH 4 loss ppo:  -0.04403, loss val: 0.03689
[2022-12-07 05:29:04,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:29:04,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:29:04,711] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:29:10,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:29:16,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:29:21,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:29:27,434] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:29:32,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:29:38,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:29:43,839] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:29:49,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:29:55,979] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:30:02,584] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9303578968506776
[2022-12-07 05:30:02,585] [INFO] [runner_train_mujoco] Average state value: 0.4778268460730712
[2022-12-07 05:30:02,585] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 05:30:02,657] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.03742
[2022-12-07 05:30:02,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.02502, loss val: 0.03781
[2022-12-07 05:30:02,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.03393, loss val: 0.03730
[2022-12-07 05:30:02,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.04363, loss val: 0.03766
[2022-12-07 05:30:02,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:30:03,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:30:03,032] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:30:09,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:30:14,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:30:20,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:30:26,074] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:30:32,286] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:30:37,553] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:30:42,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:30:48,089] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:30:53,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:30:58,891] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9977335839740213
[2022-12-07 05:30:58,891] [INFO] [runner_train_mujoco] Average state value: 0.46174117816487953
[2022-12-07 05:30:58,891] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 05:30:58,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01264, loss val: 0.03991
[2022-12-07 05:30:58,985] [INFO] [controller] EPOCH 2 loss ppo:  -0.02257, loss val: 0.03884
[2022-12-07 05:30:59,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.03562, loss val: 0.04053
[2022-12-07 05:30:59,073] [INFO] [controller] EPOCH 4 loss ppo:  -0.04540, loss val: 0.03864
[2022-12-07 05:30:59,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:30:59,261] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:30:59,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:31:04,984] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:31:10,884] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:31:16,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:31:22,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:31:27,614] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:31:32,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:31:38,100] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:31:43,388] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:31:49,153] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:31:54,881] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.854267863345626
[2022-12-07 05:31:54,881] [INFO] [runner_train_mujoco] Average state value: 0.46243436637520785
[2022-12-07 05:31:54,881] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 05:31:54,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.03855
[2022-12-07 05:31:54,986] [INFO] [controller] EPOCH 2 loss ppo:  -0.02612, loss val: 0.03850
[2022-12-07 05:31:55,031] [INFO] [controller] EPOCH 3 loss ppo:  -0.03745, loss val: 0.03979
[2022-12-07 05:31:55,075] [INFO] [controller] EPOCH 4 loss ppo:  -0.04606, loss val: 0.03946
[2022-12-07 05:31:55,085] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:31:55,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:31:55,276] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:32:00,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:32:06,119] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:32:11,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:32:17,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:32:22,181] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:32:27,144] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:32:32,348] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:32:38,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:32:44,026] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:32:50,131] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.218675132665439
[2022-12-07 05:32:50,131] [INFO] [runner_train_mujoco] Average state value: 0.4614435481230418
[2022-12-07 05:32:50,131] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 05:32:50,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.05424
[2022-12-07 05:32:50,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.02256, loss val: 0.05263
[2022-12-07 05:32:50,362] [INFO] [controller] EPOCH 3 loss ppo:  -0.03274, loss val: 0.05229
[2022-12-07 05:32:50,411] [INFO] [controller] EPOCH 4 loss ppo:  -0.04451, loss val: 0.05198
[2022-12-07 05:32:50,420] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:32:50,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:32:50,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:32:56,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:33:02,104] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:33:07,513] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:33:12,637] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:33:17,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:33:23,331] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:33:28,681] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:33:33,821] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:33:39,085] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:33:44,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9432880154941943
[2022-12-07 05:33:44,561] [INFO] [runner_train_mujoco] Average state value: 0.4630663902759552
[2022-12-07 05:33:44,561] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 05:33:44,613] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.04188
[2022-12-07 05:33:44,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.02430, loss val: 0.04059
[2022-12-07 05:33:44,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.03509, loss val: 0.04075
[2022-12-07 05:33:44,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.04309, loss val: 0.04130
[2022-12-07 05:33:44,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:33:44,927] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:33:44,928] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:33:50,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:33:56,174] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:34:02,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:34:07,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:34:12,773] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:34:18,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:34:24,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:34:29,621] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:34:34,795] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:34:40,114] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0539065704287305
[2022-12-07 05:34:40,114] [INFO] [runner_train_mujoco] Average state value: 0.46376108644405994
[2022-12-07 05:34:40,114] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 05:34:40,165] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.04521
[2022-12-07 05:34:40,210] [INFO] [controller] EPOCH 2 loss ppo:  -0.02385, loss val: 0.04491
[2022-12-07 05:34:40,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.03554, loss val: 0.04639
[2022-12-07 05:34:40,304] [INFO] [controller] EPOCH 4 loss ppo:  -0.04209, loss val: 0.04633
[2022-12-07 05:34:40,313] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:34:40,501] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:34:40,502] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:34:46,267] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:34:53,569] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:34:59,331] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:35:04,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:35:09,844] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:35:15,225] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:35:20,240] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:35:25,829] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:35:31,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:35:37,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.364704931976246
[2022-12-07 05:35:37,218] [INFO] [runner_train_mujoco] Average state value: 0.4642266198794047
[2022-12-07 05:35:37,218] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 05:35:37,282] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.03312
[2022-12-07 05:35:37,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.02256, loss val: 0.03294
[2022-12-07 05:35:37,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.03385, loss val: 0.03279
[2022-12-07 05:35:37,424] [INFO] [controller] EPOCH 4 loss ppo:  -0.04115, loss val: 0.03211
[2022-12-07 05:35:37,434] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:35:37,607] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:35:37,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:35:43,361] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:35:49,259] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:35:54,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:35:59,633] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:36:04,844] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:36:10,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:36:15,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:36:21,181] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:36:26,284] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:36:31,843] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.299746452518765
[2022-12-07 05:36:31,843] [INFO] [runner_train_mujoco] Average state value: 0.4708383231361708
[2022-12-07 05:36:31,843] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 05:36:31,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04920
[2022-12-07 05:36:31,935] [INFO] [controller] EPOCH 2 loss ppo:  -0.02119, loss val: 0.04787
[2022-12-07 05:36:31,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.02972, loss val: 0.04822
[2022-12-07 05:36:32,019] [INFO] [controller] EPOCH 4 loss ppo:  -0.03327, loss val: 0.04643
[2022-12-07 05:36:32,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:36:32,211] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:36:32,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:36:38,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:36:44,116] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:36:49,960] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:36:55,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:37:00,437] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:37:06,024] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:37:11,062] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:37:16,513] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:37:21,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:37:27,286] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.385096550297332
[2022-12-07 05:37:27,286] [INFO] [runner_train_mujoco] Average state value: 0.4979066764612992
[2022-12-07 05:37:27,286] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 05:37:27,350] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.02845
[2022-12-07 05:37:27,391] [INFO] [controller] EPOCH 2 loss ppo:  -0.02091, loss val: 0.02785
[2022-12-07 05:37:27,436] [INFO] [controller] EPOCH 3 loss ppo:  -0.03224, loss val: 0.02799
[2022-12-07 05:37:27,481] [INFO] [controller] EPOCH 4 loss ppo:  -0.03938, loss val: 0.02947
[2022-12-07 05:37:27,490] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:37:27,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:37:27,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:37:33,398] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:37:39,196] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:37:44,658] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:37:49,662] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:37:55,189] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:38:00,369] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:38:06,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:38:11,624] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:38:17,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:38:22,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.2830580977024235
[2022-12-07 05:38:22,703] [INFO] [runner_train_mujoco] Average state value: 0.5226848879655202
[2022-12-07 05:38:22,703] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 05:38:22,769] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.03877
[2022-12-07 05:38:22,825] [INFO] [controller] EPOCH 2 loss ppo:  -0.02033, loss val: 0.03879
[2022-12-07 05:38:22,879] [INFO] [controller] EPOCH 3 loss ppo:  -0.02768, loss val: 0.03925
[2022-12-07 05:38:22,932] [INFO] [controller] EPOCH 4 loss ppo:  -0.03291, loss val: 0.03953
[2022-12-07 05:38:22,941] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:38:23,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:38:23,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:38:29,186] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:38:34,204] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:38:39,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:38:45,138] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:38:50,865] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:38:56,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:39:01,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:39:06,906] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:39:12,404] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:39:17,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.194066504530196
[2022-12-07 05:39:17,752] [INFO] [runner_train_mujoco] Average state value: 0.5282554861605168
[2022-12-07 05:39:17,752] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 05:39:17,813] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04257
[2022-12-07 05:39:17,869] [INFO] [controller] EPOCH 2 loss ppo:  -0.01956, loss val: 0.04623
[2022-12-07 05:39:17,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.02915, loss val: 0.04180
[2022-12-07 05:39:17,958] [INFO] [controller] EPOCH 4 loss ppo:  -0.03703, loss val: 0.04560
[2022-12-07 05:39:17,968] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:39:18,150] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:39:18,151] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:39:24,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:39:29,683] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:39:35,544] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:39:40,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:39:46,238] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:39:51,387] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:39:56,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:40:02,085] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:40:07,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:40:13,104] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.492308536553647
[2022-12-07 05:40:13,104] [INFO] [runner_train_mujoco] Average state value: 0.5197630939284961
[2022-12-07 05:40:13,105] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 05:40:13,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04119
[2022-12-07 05:40:13,225] [INFO] [controller] EPOCH 2 loss ppo:  -0.01826, loss val: 0.03954
[2022-12-07 05:40:13,269] [INFO] [controller] EPOCH 3 loss ppo:  -0.02497, loss val: 0.03872
[2022-12-07 05:40:13,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.03137, loss val: 0.03872
[2022-12-07 05:40:13,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:40:13,508] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:40:13,509] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:40:19,384] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:40:24,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:40:30,266] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:40:35,459] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:40:41,279] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:40:46,787] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:40:52,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:40:57,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:41:02,834] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:41:08,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.121491360755434
[2022-12-07 05:41:08,475] [INFO] [runner_train_mujoco] Average state value: 0.48847055355211105
[2022-12-07 05:41:08,476] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 05:41:08,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.07798
[2022-12-07 05:41:08,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.01600, loss val: 0.07643
[2022-12-07 05:41:08,615] [INFO] [controller] EPOCH 3 loss ppo:  -0.02030, loss val: 0.07815
[2022-12-07 05:41:08,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.02515, loss val: 0.07798
[2022-12-07 05:41:08,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:41:08,844] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:41:08,844] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:41:13,866] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:41:19,528] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:41:25,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:41:30,278] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:41:35,283] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:41:40,554] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:41:46,468] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:41:51,863] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:41:58,258] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:42:05,843] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.715736869828895
[2022-12-07 05:42:05,843] [INFO] [runner_train_mujoco] Average state value: 0.4758894525021315
[2022-12-07 05:42:05,843] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 05:42:05,918] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.06412
[2022-12-07 05:42:05,973] [INFO] [controller] EPOCH 2 loss ppo:  -0.01615, loss val: 0.06344
[2022-12-07 05:42:06,033] [INFO] [controller] EPOCH 3 loss ppo:  -0.02044, loss val: 0.06331
[2022-12-07 05:42:06,084] [INFO] [controller] EPOCH 4 loss ppo:  -0.02632, loss val: 0.06308
[2022-12-07 05:42:06,094] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:42:06,290] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:42:06,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:42:12,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:42:19,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:42:25,483] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:42:31,671] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:42:38,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:42:44,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:42:50,772] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:42:56,754] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:43:02,220] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:43:07,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.4862384530132635
[2022-12-07 05:43:07,819] [INFO] [runner_train_mujoco] Average state value: 0.49950617962082217
[2022-12-07 05:43:07,819] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 05:43:07,870] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04692
[2022-12-07 05:43:07,913] [INFO] [controller] EPOCH 2 loss ppo:  -0.01680, loss val: 0.04622
[2022-12-07 05:43:07,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.02115, loss val: 0.04599
[2022-12-07 05:43:08,001] [INFO] [controller] EPOCH 4 loss ppo:  -0.02648, loss val: 0.04642
[2022-12-07 05:43:08,010] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:43:08,190] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:43:08,190] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:43:14,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:43:20,535] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:43:27,135] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:43:32,252] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:43:37,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:43:43,111] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:43:48,963] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:43:54,235] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:43:59,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:44:05,536] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.401555220368247
[2022-12-07 05:44:05,537] [INFO] [runner_train_mujoco] Average state value: 0.50368707541128
[2022-12-07 05:44:05,537] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 05:44:05,593] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.05159
[2022-12-07 05:44:05,635] [INFO] [controller] EPOCH 2 loss ppo:  -0.01427, loss val: 0.05132
[2022-12-07 05:44:05,684] [INFO] [controller] EPOCH 3 loss ppo:  -0.01576, loss val: 0.05108
[2022-12-07 05:44:05,734] [INFO] [controller] EPOCH 4 loss ppo:  -0.01736, loss val: 0.05035
[2022-12-07 05:44:05,741] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:44:05,864] [INFO] [optimize] Finished learning.
