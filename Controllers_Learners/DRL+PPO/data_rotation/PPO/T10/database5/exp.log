[2022-12-07 00:36:34,424] [INFO] [optimize] Starting learning
[2022-12-07 00:36:34,440] [INFO] [optimize] Starting learning process..
[2022-12-07 00:36:34,533] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:36:34,534] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:36:43,667] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:36:51,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:36:58,557] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:37:05,743] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:37:13,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:37:20,653] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:37:27,924] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:37:35,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:37:43,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:37:50,361] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.552367289052968
[2022-12-07 00:37:50,361] [INFO] [runner_train_mujoco] Average state value: 0.10276548733810584
[2022-12-07 00:37:50,361] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 00:37:50,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.39856
[2022-12-07 00:37:50,502] [INFO] [controller] EPOCH 2 loss ppo:  -0.04738, loss val: 0.36158
[2022-12-07 00:37:50,600] [INFO] [controller] EPOCH 3 loss ppo:  -0.05717, loss val: 0.32003
[2022-12-07 00:37:50,669] [INFO] [controller] EPOCH 4 loss ppo:  -0.06128, loss val: 0.28982
[2022-12-07 00:37:50,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:37:50,903] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:37:50,904] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:37:58,290] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:38:06,000] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:38:13,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:38:21,257] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:38:28,572] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:38:35,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:38:43,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:38:50,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:38:58,626] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:39:05,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4064199011947068
[2022-12-07 00:39:05,981] [INFO] [runner_train_mujoco] Average state value: 0.24133471198379994
[2022-12-07 00:39:05,981] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 00:39:06,060] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.25513
[2022-12-07 00:39:06,113] [INFO] [controller] EPOCH 2 loss ppo:  -0.04269, loss val: 0.23177
[2022-12-07 00:39:06,173] [INFO] [controller] EPOCH 3 loss ppo:  -0.05863, loss val: 0.20344
[2022-12-07 00:39:06,228] [INFO] [controller] EPOCH 4 loss ppo:  -0.06303, loss val: 0.18646
[2022-12-07 00:39:06,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:39:06,474] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:39:06,475] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:39:14,431] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:39:22,367] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:39:30,374] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:39:37,965] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:39:45,337] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:39:53,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:40:01,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:40:09,763] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:40:17,695] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:40:25,803] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5319631596528193
[2022-12-07 00:40:25,804] [INFO] [runner_train_mujoco] Average state value: 0.39899763706326485
[2022-12-07 00:40:25,804] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 00:40:25,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.19899
[2022-12-07 00:40:25,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.03548, loss val: 0.19185
[2022-12-07 00:40:25,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.04411, loss val: 0.16275
[2022-12-07 00:40:26,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.05470, loss val: 0.14521
[2022-12-07 00:40:26,040] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:40:26,259] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:40:26,259] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:40:34,313] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:40:42,117] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:40:50,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:40:58,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:41:06,028] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:41:13,884] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:41:21,612] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:41:29,263] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:41:36,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:41:44,647] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40627401785840345
[2022-12-07 00:41:44,648] [INFO] [runner_train_mujoco] Average state value: 0.5423697384397188
[2022-12-07 00:41:44,648] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 00:41:44,724] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.13419
[2022-12-07 00:41:44,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.03641, loss val: 0.12595
[2022-12-07 00:41:44,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.04825, loss val: 0.11696
[2022-12-07 00:41:44,886] [INFO] [controller] EPOCH 4 loss ppo:  -0.05773, loss val: 0.11154
[2022-12-07 00:41:44,897] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:41:45,113] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:41:45,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:41:52,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:42:00,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:42:08,087] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:42:15,794] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:42:23,463] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:42:30,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:42:38,184] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:42:45,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:42:52,732] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:42:59,788] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.49445772109710634
[2022-12-07 00:42:59,788] [INFO] [runner_train_mujoco] Average state value: 0.6311191910815735
[2022-12-07 00:42:59,788] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 00:42:59,858] [INFO] [controller] EPOCH 1 loss ppo:  -0.01066, loss val: 0.11541
[2022-12-07 00:42:59,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.03123, loss val: 0.10985
[2022-12-07 00:42:59,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.04321, loss val: 0.10348
[2022-12-07 00:43:00,006] [INFO] [controller] EPOCH 4 loss ppo:  -0.05044, loss val: 0.09797
[2022-12-07 00:43:00,021] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:43:00,236] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:43:00,237] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:43:07,794] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:43:15,599] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:43:24,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:43:31,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:43:38,675] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:43:45,927] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:43:53,193] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:44:00,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:44:07,772] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:44:15,063] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6336436415231972
[2022-12-07 00:44:15,063] [INFO] [runner_train_mujoco] Average state value: 0.62714196495153
[2022-12-07 00:44:15,063] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 00:44:15,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01027, loss val: 0.08676
[2022-12-07 00:44:15,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.02990, loss val: 0.08207
[2022-12-07 00:44:15,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.04203, loss val: 0.08001
[2022-12-07 00:44:15,309] [INFO] [controller] EPOCH 4 loss ppo:  -0.05231, loss val: 0.07372
[2022-12-07 00:44:15,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:44:15,536] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:44:15,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:44:22,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:44:30,101] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:44:37,431] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:44:44,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:44:52,166] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:44:59,902] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:45:08,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:45:15,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:45:23,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:45:32,345] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6766583293474799
[2022-12-07 00:45:32,345] [INFO] [runner_train_mujoco] Average state value: 0.5796200292799621
[2022-12-07 00:45:32,346] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 00:45:32,463] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.07075
[2022-12-07 00:45:32,534] [INFO] [controller] EPOCH 2 loss ppo:  -0.03151, loss val: 0.07108
[2022-12-07 00:45:32,616] [INFO] [controller] EPOCH 3 loss ppo:  -0.04390, loss val: 0.06721
[2022-12-07 00:45:32,688] [INFO] [controller] EPOCH 4 loss ppo:  -0.05381, loss val: 0.06501
[2022-12-07 00:45:32,702] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:45:32,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:45:32,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:45:42,170] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:45:51,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:45:59,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:46:08,594] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:46:17,163] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:46:26,311] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:46:35,256] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:46:44,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:46:53,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:47:01,976] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5263097390698428
[2022-12-07 00:47:01,976] [INFO] [runner_train_mujoco] Average state value: 0.5559891808331012
[2022-12-07 00:47:01,976] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 00:47:02,052] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.06512
[2022-12-07 00:47:02,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.03343, loss val: 0.06277
[2022-12-07 00:47:02,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.04721, loss val: 0.05836
[2022-12-07 00:47:02,250] [INFO] [controller] EPOCH 4 loss ppo:  -0.05470, loss val: 0.05619
[2022-12-07 00:47:02,263] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:47:02,515] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:47:02,515] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:47:11,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:47:20,122] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:47:28,482] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:47:37,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:47:45,527] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:47:53,634] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:48:01,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:48:10,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:48:18,676] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:48:26,735] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4435755511829182
[2022-12-07 00:48:26,735] [INFO] [runner_train_mujoco] Average state value: 0.5239566501230002
[2022-12-07 00:48:26,735] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 00:48:26,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01031, loss val: 0.05771
[2022-12-07 00:48:26,876] [INFO] [controller] EPOCH 2 loss ppo:  -0.03505, loss val: 0.05704
[2022-12-07 00:48:26,935] [INFO] [controller] EPOCH 3 loss ppo:  -0.04754, loss val: 0.04665
[2022-12-07 00:48:26,993] [INFO] [controller] EPOCH 4 loss ppo:  -0.05519, loss val: 0.05404
[2022-12-07 00:48:27,005] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:48:27,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:48:27,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:48:35,472] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:48:43,103] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:48:51,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:48:59,884] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:49:08,632] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:49:16,481] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:49:24,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:49:31,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:49:39,340] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:49:46,825] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4635049436754593
[2022-12-07 00:49:46,825] [INFO] [runner_train_mujoco] Average state value: 0.5248525709609191
[2022-12-07 00:49:46,825] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 00:49:46,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.00922, loss val: 0.04099
[2022-12-07 00:49:46,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.03415, loss val: 0.04013
[2022-12-07 00:49:46,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.04513, loss val: 0.03903
[2022-12-07 00:49:47,054] [INFO] [controller] EPOCH 4 loss ppo:  -0.05326, loss val: 0.03749
[2022-12-07 00:49:47,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:49:47,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:49:47,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:49:54,972] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:50:03,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:50:11,204] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:50:18,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:50:25,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:50:32,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:50:40,621] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:50:47,884] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:50:55,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:51:02,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5472076359251494
[2022-12-07 00:51:02,851] [INFO] [runner_train_mujoco] Average state value: 0.5191525820195675
[2022-12-07 00:51:02,851] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 00:51:02,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.00964, loss val: 0.03157
[2022-12-07 00:51:02,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.02864, loss val: 0.03102
[2022-12-07 00:51:03,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.04065, loss val: 0.03474
[2022-12-07 00:51:03,082] [INFO] [controller] EPOCH 4 loss ppo:  -0.05026, loss val: 0.02697
[2022-12-07 00:51:03,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:51:03,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:51:03,298] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:51:10,793] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:51:18,113] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:51:25,665] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:51:32,905] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:51:40,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:51:47,232] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:51:54,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:52:01,747] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:52:09,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:52:16,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4119739040699013
[2022-12-07 00:52:16,550] [INFO] [runner_train_mujoco] Average state value: 0.49836979036529855
[2022-12-07 00:52:16,550] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 00:52:16,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.00905, loss val: 0.03824
[2022-12-07 00:52:16,739] [INFO] [controller] EPOCH 2 loss ppo:  -0.03434, loss val: 0.04027
[2022-12-07 00:52:16,909] [INFO] [controller] EPOCH 3 loss ppo:  -0.04669, loss val: 0.03614
[2022-12-07 00:52:16,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.05496, loss val: 0.03684
[2022-12-07 00:52:16,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:52:17,194] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:52:17,195] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:52:24,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:52:32,081] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:52:39,301] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:52:46,047] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:52:52,817] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:52:59,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:53:06,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:53:13,647] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:53:20,402] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:53:27,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.36618494859058287
[2022-12-07 00:53:27,325] [INFO] [runner_train_mujoco] Average state value: 0.4867266115446885
[2022-12-07 00:53:27,325] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 00:53:27,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.00984, loss val: 0.04539
[2022-12-07 00:53:27,453] [INFO] [controller] EPOCH 2 loss ppo:  -0.03465, loss val: 0.04455
[2022-12-07 00:53:27,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.04752, loss val: 0.04341
[2022-12-07 00:53:27,558] [INFO] [controller] EPOCH 4 loss ppo:  -0.05324, loss val: 0.04238
[2022-12-07 00:53:27,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:53:27,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:53:27,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:53:34,165] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:53:41,385] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:53:48,415] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:53:55,492] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:54:02,579] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:54:09,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:54:16,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:54:23,812] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:54:30,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:54:37,794] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6529619695538982
[2022-12-07 00:54:37,794] [INFO] [runner_train_mujoco] Average state value: 0.5270054813027382
[2022-12-07 00:54:37,794] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 00:54:37,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.01119, loss val: 0.03985
[2022-12-07 00:54:37,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.03994, loss val: 0.04044
[2022-12-07 00:54:37,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.05008, loss val: 0.04132
[2022-12-07 00:54:38,004] [INFO] [controller] EPOCH 4 loss ppo:  -0.05720, loss val: 0.03923
[2022-12-07 00:54:38,015] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:54:38,222] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:54:38,222] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:54:45,239] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:54:52,213] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:54:58,994] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:55:06,645] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:55:14,301] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:55:21,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:55:29,403] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:55:36,159] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:55:43,405] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:55:51,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3265761100258092
[2022-12-07 00:55:51,276] [INFO] [runner_train_mujoco] Average state value: 0.5214180066585541
[2022-12-07 00:55:51,276] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 00:55:51,352] [INFO] [controller] EPOCH 1 loss ppo:  -0.01009, loss val: 0.04163
[2022-12-07 00:55:51,405] [INFO] [controller] EPOCH 2 loss ppo:  -0.03194, loss val: 0.04374
[2022-12-07 00:55:51,455] [INFO] [controller] EPOCH 3 loss ppo:  -0.04167, loss val: 0.04026
[2022-12-07 00:55:51,509] [INFO] [controller] EPOCH 4 loss ppo:  -0.05058, loss val: 0.04442
[2022-12-07 00:55:51,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:55:51,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:55:51,731] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:55:59,321] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:56:07,192] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:56:14,468] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:56:21,762] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:56:29,028] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:56:36,404] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:56:43,762] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:56:51,544] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:56:58,943] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:57:07,326] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5676724546664982
[2022-12-07 00:57:07,327] [INFO] [runner_train_mujoco] Average state value: 0.4857423923611641
[2022-12-07 00:57:07,327] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 00:57:07,392] [INFO] [controller] EPOCH 1 loss ppo:  -0.01136, loss val: 0.04108
[2022-12-07 00:57:07,447] [INFO] [controller] EPOCH 2 loss ppo:  -0.03487, loss val: 0.04058
[2022-12-07 00:57:07,524] [INFO] [controller] EPOCH 3 loss ppo:  -0.04636, loss val: 0.04293
[2022-12-07 00:57:07,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.05582, loss val: 0.04023
[2022-12-07 00:57:07,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:57:07,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:57:07,800] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:57:16,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:57:24,472] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:57:31,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:57:39,160] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:57:46,420] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:57:53,713] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:58:00,857] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:58:08,212] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:58:15,507] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:58:22,553] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7053366452882746
[2022-12-07 00:58:22,553] [INFO] [runner_train_mujoco] Average state value: 0.49553177643815677
[2022-12-07 00:58:22,553] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 00:58:22,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.04759
[2022-12-07 00:58:22,681] [INFO] [controller] EPOCH 2 loss ppo:  -0.03349, loss val: 0.04624
[2022-12-07 00:58:22,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.05050, loss val: 0.04454
[2022-12-07 00:58:22,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.05939, loss val: 0.04435
[2022-12-07 00:58:22,815] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:58:23,023] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:58:23,024] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:58:30,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:58:37,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:58:44,046] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:58:51,346] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:58:58,449] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:59:05,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:59:12,585] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:59:19,973] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:59:26,566] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:59:33,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5411649009218107
[2022-12-07 00:59:33,591] [INFO] [runner_train_mujoco] Average state value: 0.5609092484215894
[2022-12-07 00:59:33,591] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 00:59:33,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.00938, loss val: 0.03475
[2022-12-07 00:59:33,703] [INFO] [controller] EPOCH 2 loss ppo:  -0.03218, loss val: 0.03343
[2022-12-07 00:59:33,756] [INFO] [controller] EPOCH 3 loss ppo:  -0.04459, loss val: 0.03185
[2022-12-07 00:59:33,806] [INFO] [controller] EPOCH 4 loss ppo:  -0.05094, loss val: 0.03200
[2022-12-07 00:59:33,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:59:34,025] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:59:34,025] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:59:42,885] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:59:50,025] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:59:56,971] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:00:03,855] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:00:10,807] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:00:17,867] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:00:24,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:00:31,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:00:37,610] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:00:43,998] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9863236023860262
[2022-12-07 01:00:43,998] [INFO] [runner_train_mujoco] Average state value: 0.6282430081963539
[2022-12-07 01:00:43,998] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 01:00:44,057] [INFO] [controller] EPOCH 1 loss ppo:  -0.01220, loss val: 0.06093
[2022-12-07 01:00:44,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.02764, loss val: 0.05979
[2022-12-07 01:00:44,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.03473, loss val: 0.06308
[2022-12-07 01:00:44,240] [INFO] [controller] EPOCH 4 loss ppo:  -0.04390, loss val: 0.04892
[2022-12-07 01:00:44,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:00:44,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:00:44,446] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:00:51,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:00:57,980] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:01:04,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:01:11,305] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:01:18,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:01:24,767] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:01:31,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:01:38,016] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:01:44,116] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:01:50,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6216946465886547
[2022-12-07 01:01:50,340] [INFO] [runner_train_mujoco] Average state value: 0.5784584256509939
[2022-12-07 01:01:50,340] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 01:01:50,423] [INFO] [controller] EPOCH 1 loss ppo:  -0.00883, loss val: 0.04177
[2022-12-07 01:01:50,468] [INFO] [controller] EPOCH 2 loss ppo:  -0.02956, loss val: 0.04350
[2022-12-07 01:01:50,517] [INFO] [controller] EPOCH 3 loss ppo:  -0.04656, loss val: 0.04341
[2022-12-07 01:01:50,562] [INFO] [controller] EPOCH 4 loss ppo:  -0.05529, loss val: 0.04812
[2022-12-07 01:01:50,571] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:01:50,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:01:50,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:01:57,235] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:02:03,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:02:09,897] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:02:16,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:02:23,081] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:02:29,892] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:02:36,550] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:02:42,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:02:49,126] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:02:55,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6965948179961282
[2022-12-07 01:02:55,666] [INFO] [runner_train_mujoco] Average state value: 0.5541051588257153
[2022-12-07 01:02:55,666] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 01:02:55,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.04070
[2022-12-07 01:02:55,767] [INFO] [controller] EPOCH 2 loss ppo:  -0.03363, loss val: 0.04037
[2022-12-07 01:02:55,825] [INFO] [controller] EPOCH 3 loss ppo:  -0.04585, loss val: 0.04057
[2022-12-07 01:02:55,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.05519, loss val: 0.04050
[2022-12-07 01:02:55,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:02:56,096] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:02:56,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:03:02,456] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:03:09,236] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:03:15,895] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:03:22,479] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:03:28,883] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:03:35,494] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:03:41,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:03:48,129] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:03:54,758] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:04:01,286] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0009272674651226
[2022-12-07 01:04:01,286] [INFO] [runner_train_mujoco] Average state value: 0.5558402712742488
[2022-12-07 01:04:01,286] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 01:04:01,342] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.04452
[2022-12-07 01:04:01,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.03667, loss val: 0.04524
[2022-12-07 01:04:01,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.05214, loss val: 0.04714
[2022-12-07 01:04:01,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.06306, loss val: 0.04559
[2022-12-07 01:04:01,575] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:04:01,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:04:01,770] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:04:08,576] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:04:15,138] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:04:21,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:04:28,528] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:04:35,531] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:04:42,001] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:04:48,352] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:04:54,723] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:05:01,160] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:05:07,545] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0922744625280978
[2022-12-07 01:05:07,546] [INFO] [runner_train_mujoco] Average state value: 0.5384150156180063
[2022-12-07 01:05:07,546] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 01:05:07,609] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.04037
[2022-12-07 01:05:07,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.03023, loss val: 0.04333
[2022-12-07 01:05:07,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.04336, loss val: 0.04203
[2022-12-07 01:05:07,756] [INFO] [controller] EPOCH 4 loss ppo:  -0.05372, loss val: 0.04105
[2022-12-07 01:05:07,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:05:07,953] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:05:07,953] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:05:14,330] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:05:21,898] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:05:28,505] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:05:35,264] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:05:42,277] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:05:48,793] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:05:55,229] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:06:01,751] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:06:08,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:06:14,678] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3031112082495069
[2022-12-07 01:06:14,679] [INFO] [runner_train_mujoco] Average state value: 0.5495133949716886
[2022-12-07 01:06:14,679] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 01:06:14,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04293
[2022-12-07 01:06:14,786] [INFO] [controller] EPOCH 2 loss ppo:  -0.03477, loss val: 0.04448
[2022-12-07 01:06:14,834] [INFO] [controller] EPOCH 3 loss ppo:  -0.04897, loss val: 0.04327
[2022-12-07 01:06:14,880] [INFO] [controller] EPOCH 4 loss ppo:  -0.05684, loss val: 0.04071
[2022-12-07 01:06:14,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:06:15,085] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:06:15,086] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:06:21,416] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:06:28,782] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:06:35,795] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:06:42,962] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:06:50,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:06:57,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:07:05,578] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:07:12,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:07:19,483] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:07:26,580] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4900403229141037
[2022-12-07 01:07:26,580] [INFO] [runner_train_mujoco] Average state value: 0.5172598045368988
[2022-12-07 01:07:26,580] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 01:07:26,638] [INFO] [controller] EPOCH 1 loss ppo:  -0.01614, loss val: 0.04367
[2022-12-07 01:07:26,688] [INFO] [controller] EPOCH 2 loss ppo:  -0.03783, loss val: 0.04232
[2022-12-07 01:07:26,829] [INFO] [controller] EPOCH 3 loss ppo:  -0.05007, loss val: 0.04133
[2022-12-07 01:07:26,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.05960, loss val: 0.04109
[2022-12-07 01:07:26,887] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:07:27,072] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:07:27,073] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:07:33,390] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:07:39,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:07:46,171] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:07:52,145] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:07:58,296] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:08:04,416] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:08:10,631] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:08:16,718] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:08:22,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:08:28,976] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.901718082906242
[2022-12-07 01:08:28,976] [INFO] [runner_train_mujoco] Average state value: 0.45867027430733043
[2022-12-07 01:08:28,976] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 01:08:29,035] [INFO] [controller] EPOCH 1 loss ppo:  -0.01643, loss val: 0.04294
[2022-12-07 01:08:29,093] [INFO] [controller] EPOCH 2 loss ppo:  -0.03785, loss val: 0.04690
[2022-12-07 01:08:29,175] [INFO] [controller] EPOCH 3 loss ppo:  -0.04829, loss val: 0.04309
[2022-12-07 01:08:29,221] [INFO] [controller] EPOCH 4 loss ppo:  -0.06016, loss val: 0.04225
[2022-12-07 01:08:29,230] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:08:29,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:08:29,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:08:35,537] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:08:42,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:08:48,360] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:08:54,622] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:09:01,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:09:07,739] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:09:14,016] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:09:20,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:09:26,081] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:09:32,772] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2038424235422087
[2022-12-07 01:09:32,772] [INFO] [runner_train_mujoco] Average state value: 0.46809251800179486
[2022-12-07 01:09:32,772] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 01:09:32,835] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.04574
[2022-12-07 01:09:32,881] [INFO] [controller] EPOCH 2 loss ppo:  -0.03457, loss val: 0.04409
[2022-12-07 01:09:32,927] [INFO] [controller] EPOCH 3 loss ppo:  -0.04479, loss val: 0.04055
[2022-12-07 01:09:32,980] [INFO] [controller] EPOCH 4 loss ppo:  -0.05576, loss val: 0.03859
[2022-12-07 01:09:32,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:09:33,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:09:33,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:09:40,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:09:46,848] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:09:53,084] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:09:59,455] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:10:05,824] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:10:12,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:10:18,669] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:10:24,746] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:10:31,111] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:10:37,752] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.365656322574515
[2022-12-07 01:10:37,752] [INFO] [runner_train_mujoco] Average state value: 0.534709198753039
[2022-12-07 01:10:37,752] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 01:10:37,819] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.04350
[2022-12-07 01:10:37,874] [INFO] [controller] EPOCH 2 loss ppo:  -0.03171, loss val: 0.04333
[2022-12-07 01:10:37,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.04378
[2022-12-07 01:10:37,984] [INFO] [controller] EPOCH 4 loss ppo:  -0.05465, loss val: 0.04434
[2022-12-07 01:10:37,993] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:10:38,189] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:10:38,189] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:10:44,536] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:10:51,067] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:10:57,368] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:11:03,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:11:10,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:11:16,749] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:11:23,271] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:11:29,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:11:36,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:11:43,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6799887188082185
[2022-12-07 01:11:43,355] [INFO] [runner_train_mujoco] Average state value: 0.5571917304793994
[2022-12-07 01:11:43,355] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 01:11:43,422] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04577
[2022-12-07 01:11:43,473] [INFO] [controller] EPOCH 2 loss ppo:  -0.03251, loss val: 0.04500
[2022-12-07 01:11:43,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.04455, loss val: 0.04384
[2022-12-07 01:11:43,579] [INFO] [controller] EPOCH 4 loss ppo:  -0.05500, loss val: 0.04385
[2022-12-07 01:11:43,589] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:11:43,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:11:43,788] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:11:50,152] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:11:56,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:12:02,833] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:12:09,106] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:12:15,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:12:22,168] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:12:28,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:12:34,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:12:41,074] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:12:47,504] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8414252126754
[2022-12-07 01:12:47,504] [INFO] [runner_train_mujoco] Average state value: 0.5234872129956881
[2022-12-07 01:12:47,505] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 01:12:47,559] [INFO] [controller] EPOCH 1 loss ppo:  -0.01592, loss val: 0.04458
[2022-12-07 01:12:47,604] [INFO] [controller] EPOCH 2 loss ppo:  -0.03450, loss val: 0.04394
[2022-12-07 01:12:47,653] [INFO] [controller] EPOCH 3 loss ppo:  -0.04428, loss val: 0.04399
[2022-12-07 01:12:47,700] [INFO] [controller] EPOCH 4 loss ppo:  -0.05614, loss val: 0.04475
[2022-12-07 01:12:47,710] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:12:47,900] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:12:47,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:12:54,178] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:13:00,391] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:13:06,674] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:13:13,435] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:13:20,096] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:13:26,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:13:32,915] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:13:39,646] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:13:46,039] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:13:52,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2886154010709774
[2022-12-07 01:13:52,047] [INFO] [runner_train_mujoco] Average state value: 0.47684141929944357
[2022-12-07 01:13:52,047] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 01:13:52,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.04507
[2022-12-07 01:13:52,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.03202, loss val: 0.04402
[2022-12-07 01:13:52,263] [INFO] [controller] EPOCH 3 loss ppo:  -0.04275, loss val: 0.04293
[2022-12-07 01:13:52,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.05628, loss val: 0.04292
[2022-12-07 01:13:52,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:13:52,527] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:13:52,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:13:58,793] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:14:05,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:14:12,029] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:14:18,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:14:24,447] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:14:30,659] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:14:36,989] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:14:43,477] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:14:50,024] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:14:56,141] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.556384708070953
[2022-12-07 01:14:56,141] [INFO] [runner_train_mujoco] Average state value: 0.4203192234486341
[2022-12-07 01:14:56,142] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 01:14:56,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.07108
[2022-12-07 01:14:56,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.02675, loss val: 0.07215
[2022-12-07 01:14:56,301] [INFO] [controller] EPOCH 3 loss ppo:  -0.03418, loss val: 0.07129
[2022-12-07 01:14:56,345] [INFO] [controller] EPOCH 4 loss ppo:  -0.04323, loss val: 0.06767
[2022-12-07 01:14:56,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:14:56,556] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:14:56,556] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:15:02,808] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:15:09,580] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:15:15,896] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:15:22,434] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:15:28,614] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:15:36,013] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:15:42,766] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:15:48,920] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:15:55,264] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:16:01,724] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.77865623658595
[2022-12-07 01:16:01,724] [INFO] [runner_train_mujoco] Average state value: 0.4485694119489441
[2022-12-07 01:16:01,724] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 01:16:01,908] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04444
[2022-12-07 01:16:01,965] [INFO] [controller] EPOCH 2 loss ppo:  -0.02656, loss val: 0.04041
[2022-12-07 01:16:02,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.03253, loss val: 0.03732
[2022-12-07 01:16:02,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.04355, loss val: 0.03511
[2022-12-07 01:16:02,111] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:16:02,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:16:02,315] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:16:08,951] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:16:15,626] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:16:22,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:16:28,317] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:16:34,908] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:16:41,325] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:16:47,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:16:53,811] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:17:00,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:17:06,227] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.696842083349688
[2022-12-07 01:17:06,228] [INFO] [runner_train_mujoco] Average state value: 0.5313703136245409
[2022-12-07 01:17:06,228] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 01:17:06,283] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.05629
[2022-12-07 01:17:06,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.02546, loss val: 0.05780
[2022-12-07 01:17:06,398] [INFO] [controller] EPOCH 3 loss ppo:  -0.03548, loss val: 0.05864
[2022-12-07 01:17:06,466] [INFO] [controller] EPOCH 4 loss ppo:  -0.05134, loss val: 0.05868
[2022-12-07 01:17:06,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:17:06,693] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:17:06,693] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:17:12,830] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:17:19,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:17:25,417] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:17:31,553] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:17:38,284] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:17:44,588] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:17:51,112] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:17:57,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:18:03,638] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:18:10,021] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.116893672783464
[2022-12-07 01:18:10,022] [INFO] [runner_train_mujoco] Average state value: 0.5517750827471415
[2022-12-07 01:18:10,022] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 01:18:10,090] [INFO] [controller] EPOCH 1 loss ppo:  -0.01486, loss val: 0.06639
[2022-12-07 01:18:10,138] [INFO] [controller] EPOCH 2 loss ppo:  -0.02752, loss val: 0.06474
[2022-12-07 01:18:10,188] [INFO] [controller] EPOCH 3 loss ppo:  -0.03299, loss val: 0.05937
[2022-12-07 01:18:10,236] [INFO] [controller] EPOCH 4 loss ppo:  -0.04431, loss val: 0.05479
[2022-12-07 01:18:10,245] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:18:10,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:18:10,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:18:16,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:18:23,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:18:29,850] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:18:36,111] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:18:41,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:18:47,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:18:53,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:18:59,678] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:19:05,247] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:19:11,147] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.428767522673093
[2022-12-07 01:19:11,148] [INFO] [runner_train_mujoco] Average state value: 0.5000182103912036
[2022-12-07 01:19:11,148] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 01:19:11,195] [INFO] [controller] EPOCH 1 loss ppo:  -0.01155, loss val: 0.05062
[2022-12-07 01:19:11,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.02690, loss val: 0.04954
[2022-12-07 01:19:11,284] [INFO] [controller] EPOCH 3 loss ppo:  -0.03881, loss val: 0.04805
[2022-12-07 01:19:11,328] [INFO] [controller] EPOCH 4 loss ppo:  -0.04892, loss val: 0.04763
[2022-12-07 01:19:11,336] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:19:11,534] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:19:11,534] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:19:17,349] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:19:22,982] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:19:29,067] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:19:35,022] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:19:40,832] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:19:47,098] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:19:52,624] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:19:57,990] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:20:03,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:20:08,502] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.407353743703977
[2022-12-07 01:20:08,502] [INFO] [runner_train_mujoco] Average state value: 0.43456674068172774
[2022-12-07 01:20:08,502] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 01:20:08,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.05251
[2022-12-07 01:20:08,592] [INFO] [controller] EPOCH 2 loss ppo:  -0.02281, loss val: 0.05302
[2022-12-07 01:20:08,636] [INFO] [controller] EPOCH 3 loss ppo:  -0.02937, loss val: 0.05333
[2022-12-07 01:20:08,678] [INFO] [controller] EPOCH 4 loss ppo:  -0.04003, loss val: 0.05307
[2022-12-07 01:20:08,685] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:20:08,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:20:08,863] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:20:14,403] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:20:20,417] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:20:26,352] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:20:32,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:20:37,981] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:20:43,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:20:48,789] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:20:54,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:21:00,060] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:21:05,834] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5453732695063405
[2022-12-07 01:21:05,835] [INFO] [runner_train_mujoco] Average state value: 0.4411372149139642
[2022-12-07 01:21:05,835] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 01:21:05,902] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.04271
[2022-12-07 01:21:05,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.02275, loss val: 0.04277
[2022-12-07 01:21:06,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.02749, loss val: 0.04678
[2022-12-07 01:21:06,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.04383, loss val: 0.04317
[2022-12-07 01:21:06,065] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:21:06,245] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:21:06,246] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:21:11,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:21:17,658] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:21:22,977] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:21:28,247] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:21:33,513] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:21:38,981] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:21:44,883] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:21:50,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:21:58,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:22:04,793] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7090709199405145
[2022-12-07 01:22:04,793] [INFO] [runner_train_mujoco] Average state value: 0.44950854749480884
[2022-12-07 01:22:04,793] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 01:22:04,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04400
[2022-12-07 01:22:04,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.02165, loss val: 0.04354
[2022-12-07 01:22:04,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.03540, loss val: 0.04355
[2022-12-07 01:22:05,001] [INFO] [controller] EPOCH 4 loss ppo:  -0.04444, loss val: 0.04511
[2022-12-07 01:22:05,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:22:05,203] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:22:05,203] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:22:11,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:22:17,963] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:22:24,603] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:22:31,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:22:38,314] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:22:44,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:22:51,351] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:22:57,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:23:03,894] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:23:10,159] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.865514486703569
[2022-12-07 01:23:10,159] [INFO] [runner_train_mujoco] Average state value: 0.4488267679611842
[2022-12-07 01:23:10,159] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 01:23:10,233] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.04716
[2022-12-07 01:23:10,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.02416, loss val: 0.04647
[2022-12-07 01:23:10,353] [INFO] [controller] EPOCH 3 loss ppo:  -0.03257, loss val: 0.04657
[2022-12-07 01:23:10,412] [INFO] [controller] EPOCH 4 loss ppo:  -0.04199, loss val: 0.04533
[2022-12-07 01:23:10,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:23:10,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:23:10,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:23:17,043] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:23:23,200] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:23:30,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:23:36,407] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:23:43,153] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:23:49,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:23:55,532] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:24:01,800] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:24:08,193] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:24:14,646] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.274556042038681
[2022-12-07 01:24:14,646] [INFO] [runner_train_mujoco] Average state value: 0.4691376429994901
[2022-12-07 01:24:14,647] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 01:24:14,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04100
[2022-12-07 01:24:14,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.02354, loss val: 0.04080
[2022-12-07 01:24:14,832] [INFO] [controller] EPOCH 3 loss ppo:  -0.02723, loss val: 0.04184
[2022-12-07 01:24:14,890] [INFO] [controller] EPOCH 4 loss ppo:  -0.03875, loss val: 0.04082
[2022-12-07 01:24:14,902] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:24:15,102] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:24:15,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:24:21,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:24:28,291] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:24:34,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:24:40,600] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:24:46,755] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:24:52,589] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:24:59,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:25:05,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:25:11,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:25:17,716] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4869476043383205
[2022-12-07 01:25:17,716] [INFO] [runner_train_mujoco] Average state value: 0.4854868486523628
[2022-12-07 01:25:17,716] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 01:25:17,776] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.05216
[2022-12-07 01:25:17,823] [INFO] [controller] EPOCH 2 loss ppo:  -0.02536, loss val: 0.05055
[2022-12-07 01:25:17,872] [INFO] [controller] EPOCH 3 loss ppo:  -0.02828, loss val: 0.04995
[2022-12-07 01:25:17,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.04256, loss val: 0.05074
[2022-12-07 01:25:17,932] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:25:18,123] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:25:18,124] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:25:24,515] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:25:30,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:25:37,310] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:25:43,469] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:25:49,760] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:25:56,528] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:26:04,011] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:26:10,328] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:26:16,562] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:26:22,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.721796654234646
[2022-12-07 01:26:22,364] [INFO] [runner_train_mujoco] Average state value: 0.46687554582953456
[2022-12-07 01:26:22,364] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 01:26:22,441] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.04957
[2022-12-07 01:26:22,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.01713, loss val: 0.04743
[2022-12-07 01:26:22,569] [INFO] [controller] EPOCH 3 loss ppo:  -0.02338, loss val: 0.04754
[2022-12-07 01:26:22,625] [INFO] [controller] EPOCH 4 loss ppo:  -0.03371, loss val: 0.04682
[2022-12-07 01:26:22,634] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:26:22,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:26:22,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:26:29,048] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:26:35,272] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:26:42,194] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:26:48,649] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:26:54,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:27:01,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:27:08,301] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:27:14,669] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:27:21,067] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:27:26,901] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.586020794482211
[2022-12-07 01:27:26,901] [INFO] [runner_train_mujoco] Average state value: 0.43774811028440797
[2022-12-07 01:27:26,902] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 01:27:26,954] [INFO] [controller] EPOCH 1 loss ppo:  -0.01529, loss val: 0.04609
[2022-12-07 01:27:27,003] [INFO] [controller] EPOCH 2 loss ppo:  -0.02185, loss val: 0.04691
[2022-12-07 01:27:27,061] [INFO] [controller] EPOCH 3 loss ppo:  -0.02566, loss val: 0.04798
[2022-12-07 01:27:27,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.03548, loss val: 0.04520
[2022-12-07 01:27:27,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:27:27,308] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:27:27,308] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:27:33,775] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:27:39,799] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:27:47,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:27:53,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:27:59,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:28:05,446] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:28:12,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:28:18,007] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:28:24,245] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:28:30,338] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.817112442391446
[2022-12-07 01:28:30,338] [INFO] [runner_train_mujoco] Average state value: 0.41173486795028047
[2022-12-07 01:28:30,338] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 01:28:30,398] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04581
[2022-12-07 01:28:30,446] [INFO] [controller] EPOCH 2 loss ppo:  -0.02003, loss val: 0.04656
[2022-12-07 01:28:30,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.02466, loss val: 0.04703
[2022-12-07 01:28:30,570] [INFO] [controller] EPOCH 4 loss ppo:  -0.03417, loss val: 0.04577
[2022-12-07 01:28:30,580] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:28:30,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:28:30,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:28:36,862] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:28:42,925] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:28:49,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:28:55,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:29:01,148] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:29:07,542] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:29:13,909] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:29:20,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:29:26,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:29:32,654] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.138907181581579
[2022-12-07 01:29:32,655] [INFO] [runner_train_mujoco] Average state value: 0.4122522614300251
[2022-12-07 01:29:32,655] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 01:29:32,735] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.05005
[2022-12-07 01:29:32,798] [INFO] [controller] EPOCH 2 loss ppo:  -0.01646, loss val: 0.04681
[2022-12-07 01:29:32,926] [INFO] [controller] EPOCH 3 loss ppo:  -0.02503, loss val: 0.04684
[2022-12-07 01:29:33,003] [INFO] [controller] EPOCH 4 loss ppo:  -0.03264, loss val: 0.04730
[2022-12-07 01:29:33,014] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:29:33,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:29:33,247] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:29:39,798] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:29:45,970] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:29:52,178] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:29:58,334] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:30:04,286] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:30:10,634] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:30:17,031] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:30:23,663] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:30:29,755] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:30:36,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.04314953839377
[2022-12-07 01:30:36,354] [INFO] [runner_train_mujoco] Average state value: 0.4296503481666247
[2022-12-07 01:30:36,354] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 01:30:36,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.04934
[2022-12-07 01:30:36,480] [INFO] [controller] EPOCH 2 loss ppo:  -0.01597, loss val: 0.05048
[2022-12-07 01:30:36,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.02288, loss val: 0.05025
[2022-12-07 01:30:36,592] [INFO] [controller] EPOCH 4 loss ppo:  -0.03176, loss val: 0.05010
[2022-12-07 01:30:36,602] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:30:36,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:30:36,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:30:43,014] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:30:49,317] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:30:55,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:31:01,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:31:07,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:31:13,670] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:31:19,697] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:31:26,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:31:32,403] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:31:38,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.280554762174933
[2022-12-07 01:31:38,339] [INFO] [runner_train_mujoco] Average state value: 0.44107215537627537
[2022-12-07 01:31:38,339] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 01:31:38,399] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.04874
[2022-12-07 01:31:38,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.02208, loss val: 0.04918
[2022-12-07 01:31:38,569] [INFO] [controller] EPOCH 3 loss ppo:  -0.02329, loss val: 0.04768
[2022-12-07 01:31:38,620] [INFO] [controller] EPOCH 4 loss ppo:  -0.02959, loss val: 0.04779
[2022-12-07 01:31:38,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:31:38,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:31:38,835] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:31:45,154] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:31:51,285] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:31:57,650] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:32:03,839] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:32:10,953] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:32:17,458] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:32:23,637] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:32:29,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:32:36,094] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:32:42,305] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.344669886318558
[2022-12-07 01:32:42,305] [INFO] [runner_train_mujoco] Average state value: 0.44310747904578845
[2022-12-07 01:32:42,305] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 01:32:42,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.05094
[2022-12-07 01:32:42,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.01884, loss val: 0.05075
[2022-12-07 01:32:42,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.02050, loss val: 0.05293
[2022-12-07 01:32:42,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.02771, loss val: 0.05035
[2022-12-07 01:32:42,763] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:32:42,982] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:32:42,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:32:49,272] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:32:55,575] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:33:01,947] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:33:07,927] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:33:14,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:33:20,537] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:33:26,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:33:32,947] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:33:39,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:33:45,394] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.900967394473931
[2022-12-07 01:33:45,394] [INFO] [runner_train_mujoco] Average state value: 0.4335690483699242
[2022-12-07 01:33:45,394] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 01:33:45,474] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.04607
[2022-12-07 01:33:45,526] [INFO] [controller] EPOCH 2 loss ppo:  -0.01919, loss val: 0.04573
[2022-12-07 01:33:45,583] [INFO] [controller] EPOCH 3 loss ppo:  -0.02313, loss val: 0.04534
[2022-12-07 01:33:45,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.03119, loss val: 0.04553
[2022-12-07 01:33:45,649] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:33:45,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:33:45,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:33:52,412] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:33:58,521] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:34:04,535] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:34:10,841] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:34:16,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:34:23,091] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:34:29,210] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:34:35,664] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:34:41,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:34:47,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.211291619427527
[2022-12-07 01:34:47,912] [INFO] [runner_train_mujoco] Average state value: 0.43952676669756563
[2022-12-07 01:34:47,912] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 01:34:47,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.03506
[2022-12-07 01:34:48,051] [INFO] [controller] EPOCH 2 loss ppo:  -0.01568, loss val: 0.03510
[2022-12-07 01:34:48,101] [INFO] [controller] EPOCH 3 loss ppo:  -0.02354, loss val: 0.03395
[2022-12-07 01:34:48,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.02849, loss val: 0.03413
[2022-12-07 01:34:48,156] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:34:48,346] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:34:48,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:34:54,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:35:00,993] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:35:07,329] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:35:13,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:35:19,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:35:25,602] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:35:31,827] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:35:38,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:35:44,360] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:35:50,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.465843927095127
[2022-12-07 01:35:50,440] [INFO] [runner_train_mujoco] Average state value: 0.4499647396504879
[2022-12-07 01:35:50,440] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 01:35:50,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.04636
[2022-12-07 01:35:50,540] [INFO] [controller] EPOCH 2 loss ppo:  -0.01716, loss val: 0.04637
[2022-12-07 01:35:50,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.02410, loss val: 0.04649
[2022-12-07 01:35:50,631] [INFO] [controller] EPOCH 4 loss ppo:  -0.02941, loss val: 0.04652
[2022-12-07 01:35:50,641] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:35:50,830] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:35:50,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:35:57,079] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:36:03,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:36:09,294] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:36:15,295] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:36:21,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:36:27,665] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:36:34,346] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:36:41,064] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:36:47,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:36:53,555] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.223941634840644
[2022-12-07 01:36:53,555] [INFO] [runner_train_mujoco] Average state value: 0.45442175103227295
[2022-12-07 01:36:53,555] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 01:36:53,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01209, loss val: 0.05440
[2022-12-07 01:36:53,681] [INFO] [controller] EPOCH 2 loss ppo:  -0.01466, loss val: 0.05456
[2022-12-07 01:36:53,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.01957, loss val: 0.05412
[2022-12-07 01:36:53,788] [INFO] [controller] EPOCH 4 loss ppo:  -0.02458, loss val: 0.05407
[2022-12-07 01:36:53,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:36:53,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:36:53,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:37:00,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:37:06,395] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:37:12,697] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:37:18,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:37:24,690] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:37:31,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:37:37,610] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:37:43,965] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:37:50,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:37:56,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.334021899221297
[2022-12-07 01:37:56,570] [INFO] [runner_train_mujoco] Average state value: 0.44601641444365187
[2022-12-07 01:37:56,570] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 01:37:56,633] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.04719
[2022-12-07 01:37:56,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.01715, loss val: 0.04840
[2022-12-07 01:37:56,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.02175, loss val: 0.04853
[2022-12-07 01:37:56,800] [INFO] [controller] EPOCH 4 loss ppo:  -0.02497, loss val: 0.04829
[2022-12-07 01:37:56,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:37:57,007] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:37:57,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:38:03,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:38:09,591] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:38:15,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:38:21,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:38:27,533] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:38:33,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:38:40,238] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:38:46,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:38:52,881] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:38:58,944] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.545481060696957
[2022-12-07 01:38:58,945] [INFO] [runner_train_mujoco] Average state value: 0.4389023954868317
[2022-12-07 01:38:58,945] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 01:38:59,011] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.05476
[2022-12-07 01:38:59,056] [INFO] [controller] EPOCH 2 loss ppo:  -0.01580, loss val: 0.05480
[2022-12-07 01:38:59,112] [INFO] [controller] EPOCH 3 loss ppo:  -0.01970, loss val: 0.05522
[2022-12-07 01:38:59,160] [INFO] [controller] EPOCH 4 loss ppo:  -0.02389, loss val: 0.05446
[2022-12-07 01:38:59,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:38:59,362] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:38:59,365] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:39:05,553] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:39:11,771] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:39:17,892] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:39:24,095] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:39:30,141] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:39:36,477] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:39:43,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:39:49,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:39:55,443] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:40:01,587] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.484922890802548
[2022-12-07 01:40:01,587] [INFO] [runner_train_mujoco] Average state value: 0.4298825308879216
[2022-12-07 01:40:01,587] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 01:40:01,657] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04712
[2022-12-07 01:40:01,703] [INFO] [controller] EPOCH 2 loss ppo:  -0.01712, loss val: 0.04647
[2022-12-07 01:40:01,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.02171, loss val: 0.04596
[2022-12-07 01:40:01,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.02560, loss val: 0.04452
[2022-12-07 01:40:01,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:40:02,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:40:02,020] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:40:08,077] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:40:14,297] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:40:20,335] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:40:26,123] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:40:31,943] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:40:38,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:40:43,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:40:49,426] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:40:55,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:41:01,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.549608613898007
[2022-12-07 01:41:01,214] [INFO] [runner_train_mujoco] Average state value: 0.4197713355918726
[2022-12-07 01:41:01,214] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 01:41:01,272] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04282
[2022-12-07 01:41:01,314] [INFO] [controller] EPOCH 2 loss ppo:  -0.01486, loss val: 0.04186
[2022-12-07 01:41:01,357] [INFO] [controller] EPOCH 3 loss ppo:  -0.01726, loss val: 0.04234
[2022-12-07 01:41:01,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.02054, loss val: 0.04320
[2022-12-07 01:41:01,410] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:41:01,600] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:41:01,601] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:41:07,201] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:41:12,845] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:41:18,597] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:41:24,296] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:41:29,554] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:41:34,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:41:40,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:41:45,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:41:51,545] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:41:57,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.366366874782433
[2022-12-07 01:41:57,111] [INFO] [runner_train_mujoco] Average state value: 0.4138472314774989
[2022-12-07 01:41:57,111] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 01:41:57,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04855
[2022-12-07 01:41:57,203] [INFO] [controller] EPOCH 2 loss ppo:  -0.01397, loss val: 0.04963
[2022-12-07 01:41:57,245] [INFO] [controller] EPOCH 3 loss ppo:  -0.01512, loss val: 0.04911
[2022-12-07 01:41:57,287] [INFO] [controller] EPOCH 4 loss ppo:  -0.01650, loss val: 0.04815
[2022-12-07 01:41:57,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:41:57,419] [INFO] [optimize] Finished learning.
