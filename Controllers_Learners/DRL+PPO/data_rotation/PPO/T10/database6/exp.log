[2022-12-07 02:42:47,490] [INFO] [optimize] Starting learning
[2022-12-07 02:42:47,505] [INFO] [optimize] Starting learning process..
[2022-12-07 02:42:47,590] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:42:47,590] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:42:55,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:43:02,277] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:43:09,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:43:16,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:43:23,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:43:30,646] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:43:37,386] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:43:43,963] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:43:50,711] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:43:57,024] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37415225113754036
[2022-12-07 02:43:57,024] [INFO] [runner_train_mujoco] Average state value: -0.020869118705391883
[2022-12-07 02:43:57,024] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 02:43:57,101] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.43331
[2022-12-07 02:43:57,153] [INFO] [controller] EPOCH 2 loss ppo:  -0.04086, loss val: 0.39786
[2022-12-07 02:43:57,203] [INFO] [controller] EPOCH 3 loss ppo:  -0.05454, loss val: 0.35258
[2022-12-07 02:43:57,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.06076, loss val: 0.30517
[2022-12-07 02:43:57,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:43:57,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:43:57,471] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:44:04,378] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:44:11,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:44:17,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:44:24,145] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:44:31,008] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:44:38,060] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:44:45,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:44:51,390] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:44:58,359] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:45:04,870] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.346791555179634
[2022-12-07 02:45:04,870] [INFO] [runner_train_mujoco] Average state value: 0.12802133241792518
[2022-12-07 02:45:04,871] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 02:45:04,935] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.34489
[2022-12-07 02:45:04,984] [INFO] [controller] EPOCH 2 loss ppo:  -0.03601, loss val: 0.30605
[2022-12-07 02:45:05,033] [INFO] [controller] EPOCH 3 loss ppo:  -0.04889, loss val: 0.27952
[2022-12-07 02:45:05,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.05740, loss val: 0.25390
[2022-12-07 02:45:05,090] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:45:05,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:45:05,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:45:12,303] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:45:19,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:45:26,015] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:45:32,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:45:40,365] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:45:47,374] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:45:54,087] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:46:01,031] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:46:08,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:46:14,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3965563483833755
[2022-12-07 02:46:14,886] [INFO] [runner_train_mujoco] Average state value: 0.27218952078931036
[2022-12-07 02:46:14,886] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 02:46:14,945] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.19690
[2022-12-07 02:46:14,995] [INFO] [controller] EPOCH 2 loss ppo:  -0.03653, loss val: 0.17171
[2022-12-07 02:46:15,040] [INFO] [controller] EPOCH 3 loss ppo:  -0.04908, loss val: 0.15224
[2022-12-07 02:46:15,086] [INFO] [controller] EPOCH 4 loss ppo:  -0.05891, loss val: 0.13940
[2022-12-07 02:46:15,096] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:46:15,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:46:15,288] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:46:22,001] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:46:28,938] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:46:35,568] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:46:42,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:46:50,153] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:46:56,832] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:47:03,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:47:09,779] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:47:16,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:47:23,454] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5588349862684758
[2022-12-07 02:47:23,454] [INFO] [runner_train_mujoco] Average state value: 0.40310915970988564
[2022-12-07 02:47:23,454] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 02:47:23,509] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.17818
[2022-12-07 02:47:23,562] [INFO] [controller] EPOCH 2 loss ppo:  -0.02763, loss val: 0.15755
[2022-12-07 02:47:23,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.03838, loss val: 0.13498
[2022-12-07 02:47:23,660] [INFO] [controller] EPOCH 4 loss ppo:  -0.04916, loss val: 0.11904
[2022-12-07 02:47:23,670] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:47:23,864] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:47:23,865] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:47:30,758] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:47:37,696] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:47:44,682] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:47:51,156] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:47:58,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:48:04,838] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:48:11,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:48:18,970] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:48:25,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:48:32,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4733690991422783
[2022-12-07 02:48:32,332] [INFO] [runner_train_mujoco] Average state value: 0.5557801057348648
[2022-12-07 02:48:32,332] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 02:48:32,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.08975
[2022-12-07 02:48:32,429] [INFO] [controller] EPOCH 2 loss ppo:  -0.04021, loss val: 0.08682
[2022-12-07 02:48:32,476] [INFO] [controller] EPOCH 3 loss ppo:  -0.04982, loss val: 0.08179
[2022-12-07 02:48:32,522] [INFO] [controller] EPOCH 4 loss ppo:  -0.05606, loss val: 0.07802
[2022-12-07 02:48:32,532] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:48:32,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:48:32,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:48:39,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:48:45,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:48:52,951] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:48:59,878] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:49:06,860] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:49:13,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:49:20,744] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:49:27,316] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:49:34,150] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:49:40,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4935557612006082
[2022-12-07 02:49:40,959] [INFO] [runner_train_mujoco] Average state value: 0.6297097497185071
[2022-12-07 02:49:40,959] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 02:49:41,026] [INFO] [controller] EPOCH 1 loss ppo:  -0.00937, loss val: 0.07776
[2022-12-07 02:49:41,085] [INFO] [controller] EPOCH 2 loss ppo:  -0.03394, loss val: 0.07009
[2022-12-07 02:49:41,155] [INFO] [controller] EPOCH 3 loss ppo:  -0.04456, loss val: 0.06839
[2022-12-07 02:49:41,212] [INFO] [controller] EPOCH 4 loss ppo:  -0.05391, loss val: 0.06059
[2022-12-07 02:49:41,223] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:49:41,419] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:49:41,419] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:49:48,000] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:49:54,890] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:50:01,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:50:08,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:50:15,230] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:50:21,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:50:28,783] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:50:35,374] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:50:42,226] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:50:48,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6342597053456058
[2022-12-07 02:50:48,987] [INFO] [runner_train_mujoco] Average state value: 0.6071221782316765
[2022-12-07 02:50:48,987] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 02:50:49,049] [INFO] [controller] EPOCH 1 loss ppo:  -0.01165, loss val: 0.05840
[2022-12-07 02:50:49,108] [INFO] [controller] EPOCH 2 loss ppo:  -0.03592, loss val: 0.05532
[2022-12-07 02:50:49,167] [INFO] [controller] EPOCH 3 loss ppo:  -0.04309, loss val: 0.05252
[2022-12-07 02:50:49,245] [INFO] [controller] EPOCH 4 loss ppo:  -0.04826, loss val: 0.05060
[2022-12-07 02:50:49,269] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:50:49,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:50:49,469] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:50:56,456] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:51:03,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:51:09,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:51:16,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:51:23,226] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:51:29,781] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:51:36,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:51:43,385] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:51:50,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:51:56,798] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4587221343747559
[2022-12-07 02:51:56,798] [INFO] [runner_train_mujoco] Average state value: 0.5579190871020158
[2022-12-07 02:51:56,798] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 02:51:56,866] [INFO] [controller] EPOCH 1 loss ppo:  -0.01275, loss val: 0.04352
[2022-12-07 02:51:56,911] [INFO] [controller] EPOCH 2 loss ppo:  -0.03369, loss val: 0.04216
[2022-12-07 02:51:56,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.04541, loss val: 0.04125
[2022-12-07 02:51:57,004] [INFO] [controller] EPOCH 4 loss ppo:  -0.05457, loss val: 0.03875
[2022-12-07 02:51:57,014] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:51:57,224] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:51:57,225] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:52:03,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:52:11,032] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:52:18,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:52:24,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:52:32,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:52:38,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:52:46,181] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:52:52,881] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:52:59,784] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:53:06,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5377211756670401
[2022-12-07 02:53:06,330] [INFO] [runner_train_mujoco] Average state value: 0.5573808681666852
[2022-12-07 02:53:06,330] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 02:53:06,433] [INFO] [controller] EPOCH 1 loss ppo:  -0.01108, loss val: 0.03574
[2022-12-07 02:53:06,491] [INFO] [controller] EPOCH 2 loss ppo:  -0.03529, loss val: 0.03522
[2022-12-07 02:53:06,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.04676, loss val: 0.03360
[2022-12-07 02:53:06,587] [INFO] [controller] EPOCH 4 loss ppo:  -0.05444, loss val: 0.03629
[2022-12-07 02:53:06,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:53:06,793] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:53:06,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:53:14,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:53:21,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:53:27,987] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:53:34,923] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:53:41,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:53:48,466] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:53:55,422] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:54:01,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:54:08,984] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:54:15,687] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5023484066399492
[2022-12-07 02:54:15,688] [INFO] [runner_train_mujoco] Average state value: 0.5694306016266346
[2022-12-07 02:54:15,688] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 02:54:15,750] [INFO] [controller] EPOCH 1 loss ppo:  -0.00929, loss val: 0.04542
[2022-12-07 02:54:15,817] [INFO] [controller] EPOCH 2 loss ppo:  -0.03544, loss val: 0.04397
[2022-12-07 02:54:15,877] [INFO] [controller] EPOCH 3 loss ppo:  -0.04958, loss val: 0.04366
[2022-12-07 02:54:15,949] [INFO] [controller] EPOCH 4 loss ppo:  -0.05869, loss val: 0.04366
[2022-12-07 02:54:15,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:54:16,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:54:16,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:54:22,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:54:29,541] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:54:36,301] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:54:42,462] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:54:49,075] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:54:55,638] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:55:02,564] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:55:09,653] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:55:16,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:55:23,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4027070735379432
[2022-12-07 02:55:23,427] [INFO] [runner_train_mujoco] Average state value: 0.551543644030889
[2022-12-07 02:55:23,427] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 02:55:23,525] [INFO] [controller] EPOCH 1 loss ppo:  -0.01076, loss val: 0.04148
[2022-12-07 02:55:23,587] [INFO] [controller] EPOCH 2 loss ppo:  -0.03059, loss val: 0.03799
[2022-12-07 02:55:23,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.03953, loss val: 0.03861
[2022-12-07 02:55:23,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.05066, loss val: 0.04176
[2022-12-07 02:55:23,723] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:55:23,925] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:55:23,925] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:55:30,521] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:55:37,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:55:43,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:55:49,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:55:56,764] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:56:03,348] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:56:09,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:56:16,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:56:22,964] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:56:31,261] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5247033258321073
[2022-12-07 02:56:31,261] [INFO] [runner_train_mujoco] Average state value: 0.5212290745476882
[2022-12-07 02:56:31,261] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 02:56:31,329] [INFO] [controller] EPOCH 1 loss ppo:  -0.01103, loss val: 0.04516
[2022-12-07 02:56:31,385] [INFO] [controller] EPOCH 2 loss ppo:  -0.03242, loss val: 0.04183
[2022-12-07 02:56:31,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.04474, loss val: 0.04139
[2022-12-07 02:56:31,568] [INFO] [controller] EPOCH 4 loss ppo:  -0.05203, loss val: 0.04350
[2022-12-07 02:56:31,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:56:31,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:56:31,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:56:38,567] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:56:45,233] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:56:51,819] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:56:58,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:57:05,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:57:12,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:57:19,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:57:27,093] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:57:33,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:57:41,046] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5578712215962424
[2022-12-07 02:57:41,046] [INFO] [runner_train_mujoco] Average state value: 0.5449648386836052
[2022-12-07 02:57:41,046] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 02:57:41,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.00939, loss val: 0.03382
[2022-12-07 02:57:41,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.03375, loss val: 0.03427
[2022-12-07 02:57:41,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.04715, loss val: 0.03327
[2022-12-07 02:57:41,296] [INFO] [controller] EPOCH 4 loss ppo:  -0.05430, loss val: 0.03445
[2022-12-07 02:57:41,307] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:57:41,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:57:41,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:57:48,292] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:57:55,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:58:01,895] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:58:08,749] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:58:15,637] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:58:22,574] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:58:29,093] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:58:36,043] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:58:42,650] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:58:49,252] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5121944908163558
[2022-12-07 02:58:49,252] [INFO] [runner_train_mujoco] Average state value: 0.5319431920895974
[2022-12-07 02:58:49,252] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 02:58:49,306] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.03779
[2022-12-07 02:58:49,359] [INFO] [controller] EPOCH 2 loss ppo:  -0.03469, loss val: 0.03725
[2022-12-07 02:58:49,415] [INFO] [controller] EPOCH 3 loss ppo:  -0.04648, loss val: 0.03608
[2022-12-07 02:58:49,473] [INFO] [controller] EPOCH 4 loss ppo:  -0.05652, loss val: 0.03545
[2022-12-07 02:58:49,484] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:58:49,691] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:58:49,692] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:58:56,421] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:59:03,099] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:59:09,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:59:15,942] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:59:22,429] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:59:29,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:59:36,377] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:59:43,186] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:59:50,001] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:59:56,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6041344733550489
[2022-12-07 02:59:56,567] [INFO] [runner_train_mujoco] Average state value: 0.48324801397323613
[2022-12-07 02:59:56,567] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 02:59:56,631] [INFO] [controller] EPOCH 1 loss ppo:  -0.01083, loss val: 0.03968
[2022-12-07 02:59:56,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.02529, loss val: 0.04220
[2022-12-07 02:59:56,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.03648, loss val: 0.03776
[2022-12-07 02:59:56,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.04594, loss val: 0.03430
[2022-12-07 02:59:56,796] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:59:57,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:59:57,003] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:00:04,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:00:10,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:00:17,167] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:00:23,991] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:00:30,645] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:00:37,577] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:00:44,439] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:00:50,749] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:00:57,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:01:03,854] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7061997491873668
[2022-12-07 03:01:03,854] [INFO] [runner_train_mujoco] Average state value: 0.523512224217256
[2022-12-07 03:01:03,854] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 03:01:03,909] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.03938
[2022-12-07 03:01:03,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.03405, loss val: 0.03840
[2022-12-07 03:01:04,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.04669, loss val: 0.04051
[2022-12-07 03:01:04,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.05542, loss val: 0.03988
[2022-12-07 03:01:04,056] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:01:04,255] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:01:04,255] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:01:10,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:01:17,910] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:01:24,888] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:01:31,933] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:01:38,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:01:45,441] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:01:52,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:01:58,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:02:05,365] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:02:11,623] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7347043832303302
[2022-12-07 03:02:11,624] [INFO] [runner_train_mujoco] Average state value: 0.5460871687531471
[2022-12-07 03:02:11,624] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 03:02:11,692] [INFO] [controller] EPOCH 1 loss ppo:  -0.01244, loss val: 0.03610
[2022-12-07 03:02:11,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.03443, loss val: 0.03724
[2022-12-07 03:02:11,797] [INFO] [controller] EPOCH 3 loss ppo:  -0.04669, loss val: 0.03845
[2022-12-07 03:02:11,847] [INFO] [controller] EPOCH 4 loss ppo:  -0.05244, loss val: 0.03542
[2022-12-07 03:02:11,858] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:02:12,048] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:02:12,049] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:02:18,774] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:02:25,587] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:02:32,461] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:02:39,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:02:46,347] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:02:52,912] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:02:59,468] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:03:06,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:03:13,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:03:19,794] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6613869971233562
[2022-12-07 03:03:19,795] [INFO] [runner_train_mujoco] Average state value: 0.5274588345885277
[2022-12-07 03:03:19,795] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 03:03:19,859] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.04098
[2022-12-07 03:03:19,908] [INFO] [controller] EPOCH 2 loss ppo:  -0.03280, loss val: 0.04241
[2022-12-07 03:03:19,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.04481, loss val: 0.03838
[2022-12-07 03:03:20,023] [INFO] [controller] EPOCH 4 loss ppo:  -0.05346, loss val: 0.03638
[2022-12-07 03:03:20,035] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:03:20,231] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:03:20,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:03:26,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:03:33,737] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:03:40,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:03:47,066] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:03:53,855] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:04:00,598] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:04:06,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:04:13,788] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:04:20,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:04:26,867] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7048359304904143
[2022-12-07 03:04:26,867] [INFO] [runner_train_mujoco] Average state value: 0.4955351201494535
[2022-12-07 03:04:26,867] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 03:04:26,939] [INFO] [controller] EPOCH 1 loss ppo:  -0.01073, loss val: 0.04765
[2022-12-07 03:04:26,995] [INFO] [controller] EPOCH 2 loss ppo:  -0.02948, loss val: 0.04398
[2022-12-07 03:04:27,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.03991, loss val: 0.04585
[2022-12-07 03:04:27,097] [INFO] [controller] EPOCH 4 loss ppo:  -0.04849, loss val: 0.04068
[2022-12-07 03:04:27,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:04:27,308] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:04:27,308] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:04:34,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:04:41,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:04:47,813] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:04:54,751] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:05:00,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:05:07,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:05:14,140] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:05:20,235] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:05:26,958] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:05:33,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7766829011822135
[2022-12-07 03:05:33,464] [INFO] [runner_train_mujoco] Average state value: 0.5355003816286723
[2022-12-07 03:05:33,464] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 03:05:33,521] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.03859
[2022-12-07 03:05:33,569] [INFO] [controller] EPOCH 2 loss ppo:  -0.03589, loss val: 0.03945
[2022-12-07 03:05:33,631] [INFO] [controller] EPOCH 3 loss ppo:  -0.04609, loss val: 0.03984
[2022-12-07 03:05:33,683] [INFO] [controller] EPOCH 4 loss ppo:  -0.05448, loss val: 0.03971
[2022-12-07 03:05:33,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:05:33,894] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:05:33,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:05:40,491] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:05:47,444] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:05:54,470] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:06:00,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:06:08,117] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:06:15,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:06:21,873] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:06:29,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:06:35,796] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:06:42,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8049221467992032
[2022-12-07 03:06:42,564] [INFO] [runner_train_mujoco] Average state value: 0.5437657422423363
[2022-12-07 03:06:42,564] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 03:06:42,618] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04100
[2022-12-07 03:06:42,668] [INFO] [controller] EPOCH 2 loss ppo:  -0.03349, loss val: 0.03983
[2022-12-07 03:06:42,716] [INFO] [controller] EPOCH 3 loss ppo:  -0.04615, loss val: 0.03963
[2022-12-07 03:06:42,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.05420, loss val: 0.04061
[2022-12-07 03:06:42,774] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:06:42,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:06:42,978] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:06:49,598] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:06:56,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:07:03,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:07:11,635] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:07:19,122] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:07:25,950] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:07:32,954] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:07:39,798] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:07:46,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:07:53,296] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7711252855788269
[2022-12-07 03:07:53,296] [INFO] [runner_train_mujoco] Average state value: 0.5590251259704432
[2022-12-07 03:07:53,296] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 03:07:53,371] [INFO] [controller] EPOCH 1 loss ppo:  -0.01152, loss val: 0.03511
[2022-12-07 03:07:53,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.03487, loss val: 0.03428
[2022-12-07 03:07:53,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.04508, loss val: 0.03521
[2022-12-07 03:07:53,554] [INFO] [controller] EPOCH 4 loss ppo:  -0.05475, loss val: 0.03701
[2022-12-07 03:07:53,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:07:53,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:07:53,773] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:08:00,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:08:07,489] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:08:14,270] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:08:20,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:08:27,786] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:08:34,384] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:08:40,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:08:47,247] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:08:53,742] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:09:00,484] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1259775089121764
[2022-12-07 03:09:00,484] [INFO] [runner_train_mujoco] Average state value: 0.5534964636365574
[2022-12-07 03:09:00,484] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 03:09:00,542] [INFO] [controller] EPOCH 1 loss ppo:  -0.01184, loss val: 0.04016
[2022-12-07 03:09:00,592] [INFO] [controller] EPOCH 2 loss ppo:  -0.02899, loss val: 0.03923
[2022-12-07 03:09:00,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.04089, loss val: 0.03455
[2022-12-07 03:09:00,693] [INFO] [controller] EPOCH 4 loss ppo:  -0.05156, loss val: 0.03119
[2022-12-07 03:09:00,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:09:00,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:09:00,898] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:09:07,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:09:14,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:09:21,392] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:09:27,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:09:34,689] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:09:41,313] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:09:47,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:09:54,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:10:00,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:10:08,021] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3349923860491848
[2022-12-07 03:10:08,021] [INFO] [runner_train_mujoco] Average state value: 0.4876309948762258
[2022-12-07 03:10:08,021] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 03:10:08,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.03630
[2022-12-07 03:10:08,158] [INFO] [controller] EPOCH 2 loss ppo:  -0.03127, loss val: 0.03710
[2022-12-07 03:10:08,253] [INFO] [controller] EPOCH 3 loss ppo:  -0.04434, loss val: 0.03827
[2022-12-07 03:10:08,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.05296, loss val: 0.03728
[2022-12-07 03:10:08,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:10:08,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:10:08,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:10:15,142] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:21,720] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:10:28,332] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:10:34,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:10:41,288] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:10:48,146] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:10:54,801] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:11:01,636] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:11:07,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:11:14,500] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1199316338532808
[2022-12-07 03:11:14,500] [INFO] [runner_train_mujoco] Average state value: 0.4704160063465436
[2022-12-07 03:11:14,500] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 03:11:14,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.03249
[2022-12-07 03:11:14,604] [INFO] [controller] EPOCH 2 loss ppo:  -0.03667, loss val: 0.03151
[2022-12-07 03:11:14,714] [INFO] [controller] EPOCH 3 loss ppo:  -0.04809, loss val: 0.03024
[2022-12-07 03:11:14,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.05757, loss val: 0.03123
[2022-12-07 03:11:14,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:11:14,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:11:14,973] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:11:21,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:11:27,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:34,083] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:11:41,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:11:47,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:11:54,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:12:01,275] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:12:07,918] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:12:14,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:12:21,024] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0296598117330504
[2022-12-07 03:12:21,024] [INFO] [runner_train_mujoco] Average state value: 0.4979193510611852
[2022-12-07 03:12:21,024] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 03:12:21,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.04214
[2022-12-07 03:12:21,133] [INFO] [controller] EPOCH 2 loss ppo:  -0.02667, loss val: 0.04052
[2022-12-07 03:12:21,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.04079, loss val: 0.03989
[2022-12-07 03:12:21,227] [INFO] [controller] EPOCH 4 loss ppo:  -0.05058, loss val: 0.03757
[2022-12-07 03:12:21,239] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:12:21,430] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:12:21,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:12:28,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:12:35,320] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:12:42,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:12:48,986] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:55,820] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:13:02,066] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:13:08,578] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:13:15,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:13:21,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:13:28,288] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3709441936238678
[2022-12-07 03:13:28,288] [INFO] [runner_train_mujoco] Average state value: 0.5500720286766688
[2022-12-07 03:13:28,288] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 03:13:28,348] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.03810
[2022-12-07 03:13:28,402] [INFO] [controller] EPOCH 2 loss ppo:  -0.03485, loss val: 0.03833
[2022-12-07 03:13:28,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.04461, loss val: 0.04048
[2022-12-07 03:13:28,509] [INFO] [controller] EPOCH 4 loss ppo:  -0.05420, loss val: 0.03842
[2022-12-07 03:13:28,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:13:28,716] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:13:28,717] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:13:35,848] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:13:42,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:13:49,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:13:55,807] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:14:02,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:14:09,104] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:14:15,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:14:22,296] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:14:28,515] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:14:35,276] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.414750501220237
[2022-12-07 03:14:35,276] [INFO] [runner_train_mujoco] Average state value: 0.5606615772644679
[2022-12-07 03:14:35,276] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 03:14:35,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03969
[2022-12-07 03:14:35,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.03393, loss val: 0.03911
[2022-12-07 03:14:35,435] [INFO] [controller] EPOCH 3 loss ppo:  -0.04665, loss val: 0.03896
[2022-12-07 03:14:35,483] [INFO] [controller] EPOCH 4 loss ppo:  -0.05669, loss val: 0.03819
[2022-12-07 03:14:35,493] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:14:35,688] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:14:35,688] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:14:42,232] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:14:48,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:14:55,323] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:15:01,768] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:15:08,727] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:15:15,406] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:15:22,309] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:15:29,208] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:15:35,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:15:42,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5532879370777635
[2022-12-07 03:15:42,812] [INFO] [runner_train_mujoco] Average state value: 0.5315223852396012
[2022-12-07 03:15:42,812] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 03:15:42,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01497, loss val: 0.03751
[2022-12-07 03:15:42,923] [INFO] [controller] EPOCH 2 loss ppo:  -0.03240, loss val: 0.03516
[2022-12-07 03:15:42,968] [INFO] [controller] EPOCH 3 loss ppo:  -0.04507, loss val: 0.03371
[2022-12-07 03:15:43,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.05589, loss val: 0.03226
[2022-12-07 03:15:43,025] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:15:43,219] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:15:43,219] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:15:49,597] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:15:56,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:16:03,117] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:16:10,225] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:16:16,130] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:16:22,567] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:16:28,017] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:16:33,888] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:16:40,233] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:16:46,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.702657305647444
[2022-12-07 03:16:46,273] [INFO] [runner_train_mujoco] Average state value: 0.4787584554255009
[2022-12-07 03:16:46,273] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 03:16:46,335] [INFO] [controller] EPOCH 1 loss ppo:  -0.01650, loss val: 0.03964
[2022-12-07 03:16:46,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.03305, loss val: 0.03934
[2022-12-07 03:16:46,437] [INFO] [controller] EPOCH 3 loss ppo:  -0.04575, loss val: 0.03945
[2022-12-07 03:16:46,490] [INFO] [controller] EPOCH 4 loss ppo:  -0.05679, loss val: 0.03969
[2022-12-07 03:16:46,501] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:16:46,689] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:16:46,690] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:16:52,487] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:16:58,794] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:17:04,867] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:17:10,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:17:16,742] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:17:22,665] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:17:28,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:17:34,143] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:17:40,311] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:17:46,079] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9371336732263515
[2022-12-07 03:17:46,079] [INFO] [runner_train_mujoco] Average state value: 0.4697836635311445
[2022-12-07 03:17:46,079] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 03:17:46,132] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.03162
[2022-12-07 03:17:46,177] [INFO] [controller] EPOCH 2 loss ppo:  -0.03328, loss val: 0.03072
[2022-12-07 03:17:46,219] [INFO] [controller] EPOCH 3 loss ppo:  -0.04553, loss val: 0.02848
[2022-12-07 03:17:46,266] [INFO] [controller] EPOCH 4 loss ppo:  -0.05525, loss val: 0.02955
[2022-12-07 03:17:46,276] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:17:46,474] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:17:46,474] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:17:52,501] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:17:58,513] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:18:04,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:18:10,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:18:16,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:18:22,570] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:18:28,435] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:18:34,417] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:18:40,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:18:45,783] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.193968019715155
[2022-12-07 03:18:45,783] [INFO] [runner_train_mujoco] Average state value: 0.49990706890821446
[2022-12-07 03:18:45,783] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 03:18:45,832] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.05065
[2022-12-07 03:18:45,873] [INFO] [controller] EPOCH 2 loss ppo:  -0.03277, loss val: 0.04786
[2022-12-07 03:18:45,915] [INFO] [controller] EPOCH 3 loss ppo:  -0.04543, loss val: 0.04519
[2022-12-07 03:18:45,958] [INFO] [controller] EPOCH 4 loss ppo:  -0.05227, loss val: 0.04341
[2022-12-07 03:18:45,969] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:18:46,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:18:46,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:18:52,035] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:18:58,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:19:04,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:19:10,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:19:16,258] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:19:22,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:19:28,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:19:34,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:19:40,622] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:19:46,661] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3352397116517434
[2022-12-07 03:19:46,662] [INFO] [runner_train_mujoco] Average state value: 0.5566336356798807
[2022-12-07 03:19:46,662] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 03:19:46,780] [INFO] [controller] EPOCH 1 loss ppo:  -0.01577, loss val: 0.04200
[2022-12-07 03:19:46,827] [INFO] [controller] EPOCH 2 loss ppo:  -0.03792, loss val: 0.03820
[2022-12-07 03:19:46,870] [INFO] [controller] EPOCH 3 loss ppo:  -0.05103, loss val: 0.04113
[2022-12-07 03:19:46,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.05768, loss val: 0.03894
[2022-12-07 03:19:46,927] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:19:47,115] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:19:47,115] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:19:53,263] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:19:59,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:20:05,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:20:11,113] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:20:17,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:20:22,874] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:20:28,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:20:34,282] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:20:39,968] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:20:46,121] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7173566800444666
[2022-12-07 03:20:46,121] [INFO] [runner_train_mujoco] Average state value: 0.55865153933689
[2022-12-07 03:20:46,121] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 03:20:46,171] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.06386
[2022-12-07 03:20:46,210] [INFO] [controller] EPOCH 2 loss ppo:  -0.03398, loss val: 0.06279
[2022-12-07 03:20:46,253] [INFO] [controller] EPOCH 3 loss ppo:  -0.05097, loss val: 0.06309
[2022-12-07 03:20:46,292] [INFO] [controller] EPOCH 4 loss ppo:  -0.06299, loss val: 0.06223
[2022-12-07 03:20:46,302] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:20:46,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:20:46,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:20:52,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:20:58,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:21:04,731] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:21:10,721] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:21:16,778] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:21:22,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:21:28,320] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:21:33,780] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:21:39,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:21:45,227] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.551433984481869
[2022-12-07 03:21:45,227] [INFO] [runner_train_mujoco] Average state value: 0.590213323632876
[2022-12-07 03:21:45,227] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 03:21:45,289] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.03862
[2022-12-07 03:21:45,338] [INFO] [controller] EPOCH 2 loss ppo:  -0.02819, loss val: 0.03837
[2022-12-07 03:21:45,390] [INFO] [controller] EPOCH 3 loss ppo:  -0.03989, loss val: 0.04030
[2022-12-07 03:21:45,437] [INFO] [controller] EPOCH 4 loss ppo:  -0.05364, loss val: 0.04048
[2022-12-07 03:21:45,446] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:21:45,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:21:45,624] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:21:51,813] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:21:57,814] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:22:03,701] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:22:09,570] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:22:15,174] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:22:20,749] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:22:26,913] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:22:32,605] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:22:38,729] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:22:44,312] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.856855870329779
[2022-12-07 03:22:44,312] [INFO] [runner_train_mujoco] Average state value: 0.5840497474670411
[2022-12-07 03:22:44,312] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 03:22:44,363] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.03889
[2022-12-07 03:22:44,407] [INFO] [controller] EPOCH 2 loss ppo:  -0.02927, loss val: 0.04025
[2022-12-07 03:22:44,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.04537, loss val: 0.03976
[2022-12-07 03:22:44,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.05623, loss val: 0.03749
[2022-12-07 03:22:44,501] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:22:44,683] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:22:44,684] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:22:50,808] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:22:56,757] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:23:02,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:23:08,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:23:14,520] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:23:20,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:23:25,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:23:31,757] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:23:37,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:23:43,719] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.688226167487874
[2022-12-07 03:23:43,719] [INFO] [runner_train_mujoco] Average state value: 0.5518306412100792
[2022-12-07 03:23:43,719] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 03:23:43,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.04082
[2022-12-07 03:23:43,826] [INFO] [controller] EPOCH 2 loss ppo:  -0.03410, loss val: 0.04082
[2022-12-07 03:23:43,872] [INFO] [controller] EPOCH 3 loss ppo:  -0.04661, loss val: 0.03891
[2022-12-07 03:23:43,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.05763, loss val: 0.03822
[2022-12-07 03:23:43,937] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:23:44,120] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:23:44,120] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:23:50,090] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:23:55,664] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:24:01,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:24:07,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:24:13,707] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:24:19,471] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:24:24,992] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:24:30,790] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:24:36,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:24:42,093] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0627530331967705
[2022-12-07 03:24:42,093] [INFO] [runner_train_mujoco] Average state value: 0.5501166713436444
[2022-12-07 03:24:42,093] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 03:24:42,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01518, loss val: 0.04768
[2022-12-07 03:24:42,190] [INFO] [controller] EPOCH 2 loss ppo:  -0.02921, loss val: 0.04763
[2022-12-07 03:24:42,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.03968, loss val: 0.04708
[2022-12-07 03:24:42,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.04946, loss val: 0.04568
[2022-12-07 03:24:42,290] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:24:42,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:24:42,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:24:48,403] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:24:54,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:00,056] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:25:05,848] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:25:12,203] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:25:17,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:25:24,043] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:25:29,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:25:35,237] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:25:41,095] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.05165372986905
[2022-12-07 03:25:41,095] [INFO] [runner_train_mujoco] Average state value: 0.5373853587309518
[2022-12-07 03:25:41,095] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 03:25:41,145] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.04300
[2022-12-07 03:25:41,187] [INFO] [controller] EPOCH 2 loss ppo:  -0.02927, loss val: 0.04106
[2022-12-07 03:25:41,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.04076, loss val: 0.03902
[2022-12-07 03:25:41,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.05086, loss val: 0.03713
[2022-12-07 03:25:41,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:25:41,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:25:41,480] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:25:47,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:25:53,619] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:59,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:26:05,228] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:26:10,936] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:26:16,575] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:26:22,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:26:27,704] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:26:33,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:26:40,495] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3571836716251804
[2022-12-07 03:26:40,495] [INFO] [runner_train_mujoco] Average state value: 0.46969599112247434
[2022-12-07 03:26:40,495] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 03:26:40,601] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.05524
[2022-12-07 03:26:40,668] [INFO] [controller] EPOCH 2 loss ppo:  -0.02411, loss val: 0.05383
[2022-12-07 03:26:40,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.03369, loss val: 0.05427
[2022-12-07 03:26:40,786] [INFO] [controller] EPOCH 4 loss ppo:  -0.04453, loss val: 0.05331
[2022-12-07 03:26:40,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:26:40,996] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:26:40,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:26:47,053] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:26:52,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:26:58,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:27:04,260] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:27:10,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:27:15,944] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:27:21,949] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:27:27,388] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:27:33,460] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:27:39,074] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3091034463477804
[2022-12-07 03:27:39,075] [INFO] [runner_train_mujoco] Average state value: 0.47693969337145486
[2022-12-07 03:27:39,075] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 03:27:39,133] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04371
[2022-12-07 03:27:39,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.02808, loss val: 0.04355
[2022-12-07 03:27:39,227] [INFO] [controller] EPOCH 3 loss ppo:  -0.04301, loss val: 0.04422
[2022-12-07 03:27:39,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.05502, loss val: 0.04192
[2022-12-07 03:27:39,280] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:27:39,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:27:39,471] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:27:45,235] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:27:50,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:27:57,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:28:02,873] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:28:08,837] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:28:15,157] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:28:20,799] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:28:26,173] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:28:31,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:28:37,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4418995259211997
[2022-12-07 03:28:37,516] [INFO] [runner_train_mujoco] Average state value: 0.4880617785255114
[2022-12-07 03:28:37,516] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 03:28:37,589] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.04377
[2022-12-07 03:28:37,646] [INFO] [controller] EPOCH 2 loss ppo:  -0.02766, loss val: 0.04377
[2022-12-07 03:28:37,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.03897, loss val: 0.04285
[2022-12-07 03:28:37,779] [INFO] [controller] EPOCH 4 loss ppo:  -0.04907, loss val: 0.04151
[2022-12-07 03:28:37,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:28:38,000] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:28:38,001] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:28:43,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:28:49,523] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:28:55,414] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:29:01,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:29:06,668] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:29:12,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:29:18,082] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:29:23,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:29:30,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:29:36,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6066410748288833
[2022-12-07 03:29:36,005] [INFO] [runner_train_mujoco] Average state value: 0.46299091676870974
[2022-12-07 03:29:36,005] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 03:29:36,064] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04236
[2022-12-07 03:29:36,108] [INFO] [controller] EPOCH 2 loss ppo:  -0.02751, loss val: 0.04310
[2022-12-07 03:29:36,155] [INFO] [controller] EPOCH 3 loss ppo:  -0.03815, loss val: 0.04288
[2022-12-07 03:29:36,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.04545, loss val: 0.04335
[2022-12-07 03:29:36,214] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:29:36,409] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:29:36,409] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:29:43,928] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:29:49,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:29:55,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:30:01,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:30:06,840] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:30:12,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:30:18,491] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:30:23,835] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:30:30,038] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:30:35,736] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8259313992878625
[2022-12-07 03:30:35,736] [INFO] [runner_train_mujoco] Average state value: 0.4617761390507221
[2022-12-07 03:30:35,737] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 03:30:35,789] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.03691
[2022-12-07 03:30:35,834] [INFO] [controller] EPOCH 2 loss ppo:  -0.02936, loss val: 0.03641
[2022-12-07 03:30:35,879] [INFO] [controller] EPOCH 3 loss ppo:  -0.04435, loss val: 0.03593
[2022-12-07 03:30:35,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.05337, loss val: 0.03544
[2022-12-07 03:30:35,935] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:30:36,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:30:36,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:30:41,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:30:48,146] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:30:54,257] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:31:00,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:31:05,890] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:31:11,769] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:31:17,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:31:23,241] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:31:28,689] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:31:34,294] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.140243245818455
[2022-12-07 03:31:34,294] [INFO] [runner_train_mujoco] Average state value: 0.4823454521584014
[2022-12-07 03:31:34,294] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 03:31:34,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.03929
[2022-12-07 03:31:34,393] [INFO] [controller] EPOCH 2 loss ppo:  -0.02601, loss val: 0.03818
[2022-12-07 03:31:34,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.03634, loss val: 0.03747
[2022-12-07 03:31:34,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.04554, loss val: 0.03589
[2022-12-07 03:31:34,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:31:34,676] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:31:34,676] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:31:40,522] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:31:46,144] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:31:52,287] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:31:57,971] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:32:03,950] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:32:09,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:32:15,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:32:21,712] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:32:27,233] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:32:33,185] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.892995112041425
[2022-12-07 03:32:33,185] [INFO] [runner_train_mujoco] Average state value: 0.503819279299428
[2022-12-07 03:32:33,185] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 03:32:33,240] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.05724
[2022-12-07 03:32:33,285] [INFO] [controller] EPOCH 2 loss ppo:  -0.02420, loss val: 0.05628
[2022-12-07 03:32:33,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.03714, loss val: 0.05446
[2022-12-07 03:32:33,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.04624, loss val: 0.05251
[2022-12-07 03:32:33,473] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:32:33,651] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:32:33,651] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:32:39,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:32:45,672] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:32:51,189] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:32:56,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:33:02,010] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:33:07,506] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:33:12,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:33:20,095] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:33:26,904] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:33:34,748] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.253261983382281
[2022-12-07 03:33:34,748] [INFO] [runner_train_mujoco] Average state value: 0.5592094727158546
[2022-12-07 03:33:34,748] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 03:33:34,825] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.05980
[2022-12-07 03:33:34,875] [INFO] [controller] EPOCH 2 loss ppo:  -0.02629, loss val: 0.06357
[2022-12-07 03:33:34,926] [INFO] [controller] EPOCH 3 loss ppo:  -0.03420, loss val: 0.06125
[2022-12-07 03:33:35,001] [INFO] [controller] EPOCH 4 loss ppo:  -0.04214, loss val: 0.06346
[2022-12-07 03:33:35,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:33:35,208] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:33:35,209] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:33:41,944] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:33:48,461] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:33:54,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:34:01,367] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:34:07,491] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:34:13,764] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:34:20,080] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:34:26,588] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:34:33,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:34:39,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.46347050577342
[2022-12-07 03:34:39,983] [INFO] [runner_train_mujoco] Average state value: 0.5611173566579819
[2022-12-07 03:34:39,983] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 03:34:40,044] [INFO] [controller] EPOCH 1 loss ppo:  -0.01568, loss val: 0.03926
[2022-12-07 03:34:40,097] [INFO] [controller] EPOCH 2 loss ppo:  -0.02548, loss val: 0.03900
[2022-12-07 03:34:40,154] [INFO] [controller] EPOCH 3 loss ppo:  -0.03545, loss val: 0.03971
[2022-12-07 03:34:40,199] [INFO] [controller] EPOCH 4 loss ppo:  -0.04507, loss val: 0.03909
[2022-12-07 03:34:40,210] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:34:40,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:34:40,394] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:34:46,660] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:34:53,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:35:00,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:35:06,334] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:35:12,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:35:18,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:35:25,075] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:35:31,357] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:35:37,777] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:35:44,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.594406454090693
[2022-12-07 03:35:44,160] [INFO] [runner_train_mujoco] Average state value: 0.5231628479051094
[2022-12-07 03:35:44,161] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 03:35:44,225] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.05896
[2022-12-07 03:35:44,277] [INFO] [controller] EPOCH 2 loss ppo:  -0.02343, loss val: 0.05774
[2022-12-07 03:35:44,346] [INFO] [controller] EPOCH 3 loss ppo:  -0.03486, loss val: 0.05785
[2022-12-07 03:35:44,393] [INFO] [controller] EPOCH 4 loss ppo:  -0.04440, loss val: 0.05941
[2022-12-07 03:35:44,403] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:35:44,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:35:44,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:35:51,170] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:35:57,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:36:03,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:36:09,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:36:15,559] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:36:21,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:36:28,278] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:36:34,419] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:36:40,917] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:36:47,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.774302898647025
[2022-12-07 03:36:47,191] [INFO] [runner_train_mujoco] Average state value: 0.5219399802275001
[2022-12-07 03:36:47,192] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 03:36:47,262] [INFO] [controller] EPOCH 1 loss ppo:  -0.01513, loss val: 0.05070
[2022-12-07 03:36:47,314] [INFO] [controller] EPOCH 2 loss ppo:  -0.02250, loss val: 0.05093
[2022-12-07 03:36:47,371] [INFO] [controller] EPOCH 3 loss ppo:  -0.02967, loss val: 0.05075
[2022-12-07 03:36:47,432] [INFO] [controller] EPOCH 4 loss ppo:  -0.03665, loss val: 0.05007
[2022-12-07 03:36:47,442] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:36:47,654] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:36:47,654] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:36:53,879] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:37:00,192] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:37:06,334] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:37:12,759] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:37:18,876] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:37:25,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:37:31,034] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:37:37,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:37:43,364] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:37:49,412] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.994448115902068
[2022-12-07 03:37:49,412] [INFO] [runner_train_mujoco] Average state value: 0.5219097069005171
[2022-12-07 03:37:49,413] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 03:37:49,473] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.03334
[2022-12-07 03:37:49,531] [INFO] [controller] EPOCH 2 loss ppo:  -0.02134, loss val: 0.03359
[2022-12-07 03:37:49,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.02853, loss val: 0.03378
[2022-12-07 03:37:49,625] [INFO] [controller] EPOCH 4 loss ppo:  -0.03418, loss val: 0.03234
[2022-12-07 03:37:49,635] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:37:49,825] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:37:49,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:37:56,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:38:02,945] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:38:08,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:38:15,214] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:38:21,804] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:38:28,413] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:38:34,519] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:38:40,666] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:38:47,095] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:38:53,225] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.932789074200608
[2022-12-07 03:38:53,225] [INFO] [runner_train_mujoco] Average state value: 0.49942861329515775
[2022-12-07 03:38:53,225] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 03:38:53,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.06365
[2022-12-07 03:38:53,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.02238, loss val: 0.06283
[2022-12-07 03:38:53,370] [INFO] [controller] EPOCH 3 loss ppo:  -0.03196, loss val: 0.06167
[2022-12-07 03:38:53,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.03715, loss val: 0.06147
[2022-12-07 03:38:53,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:38:53,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:38:53,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:38:59,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:39:05,949] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:39:12,191] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:39:18,123] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:39:24,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:39:30,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:39:37,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:39:43,171] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:39:49,660] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:39:55,933] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.249769813738029
[2022-12-07 03:39:55,934] [INFO] [runner_train_mujoco] Average state value: 0.5433327610691389
[2022-12-07 03:39:55,934] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 03:39:55,991] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.04852
[2022-12-07 03:39:56,054] [INFO] [controller] EPOCH 2 loss ppo:  -0.01925, loss val: 0.04845
[2022-12-07 03:39:56,107] [INFO] [controller] EPOCH 3 loss ppo:  -0.02674, loss val: 0.04812
[2022-12-07 03:39:56,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.03156, loss val: 0.04816
[2022-12-07 03:39:56,170] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:39:56,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:39:56,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:40:02,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:40:08,948] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:40:15,157] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:40:21,131] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:40:27,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:40:33,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:40:39,755] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:40:45,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:40:52,449] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:40:58,435] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.388580784135182
[2022-12-07 03:40:58,435] [INFO] [runner_train_mujoco] Average state value: 0.5254136942562958
[2022-12-07 03:40:58,435] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 03:40:58,495] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04109
[2022-12-07 03:40:58,545] [INFO] [controller] EPOCH 2 loss ppo:  -0.01985, loss val: 0.04389
[2022-12-07 03:40:58,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.02655, loss val: 0.04350
[2022-12-07 03:40:58,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.03342, loss val: 0.04207
[2022-12-07 03:40:58,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:40:58,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:40:58,870] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:41:04,991] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:41:11,250] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:41:17,457] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:41:23,802] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:41:29,879] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:41:35,723] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:41:42,077] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:41:48,270] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:41:54,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:42:01,003] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.432816125150131
[2022-12-07 03:42:01,004] [INFO] [runner_train_mujoco] Average state value: 0.5255553723673027
[2022-12-07 03:42:01,004] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 03:42:01,061] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04010
[2022-12-07 03:42:01,105] [INFO] [controller] EPOCH 2 loss ppo:  -0.01771, loss val: 0.03970
[2022-12-07 03:42:01,152] [INFO] [controller] EPOCH 3 loss ppo:  -0.02332, loss val: 0.03971
[2022-12-07 03:42:01,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.02843, loss val: 0.04001
[2022-12-07 03:42:01,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:42:01,392] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:42:01,393] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:42:07,821] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:42:14,152] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:42:20,306] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:42:26,229] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:42:31,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:42:37,193] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:42:43,199] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:42:48,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:42:54,718] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:43:00,102] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.769646118028528
[2022-12-07 03:43:00,102] [INFO] [runner_train_mujoco] Average state value: 0.511599312732617
[2022-12-07 03:43:00,102] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 03:43:00,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.05376
[2022-12-07 03:43:00,205] [INFO] [controller] EPOCH 2 loss ppo:  -0.01683, loss val: 0.05286
[2022-12-07 03:43:00,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.02110, loss val: 0.05276
[2022-12-07 03:43:00,292] [INFO] [controller] EPOCH 4 loss ppo:  -0.02639, loss val: 0.05362
[2022-12-07 03:43:00,301] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:43:00,488] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:43:00,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:43:06,206] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:43:11,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:43:17,397] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:43:23,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:43:29,230] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:43:34,418] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:43:39,798] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:43:45,131] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:43:50,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:43:56,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.231776012113846
[2022-12-07 03:43:56,440] [INFO] [runner_train_mujoco] Average state value: 0.5212047155151763
[2022-12-07 03:43:56,440] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 03:43:56,489] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.05988
[2022-12-07 03:43:56,531] [INFO] [controller] EPOCH 2 loss ppo:  -0.01503, loss val: 0.05904
[2022-12-07 03:43:56,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.01671, loss val: 0.06149
[2022-12-07 03:43:56,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.01908, loss val: 0.05908
[2022-12-07 03:43:56,628] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:43:56,821] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:43:56,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:44:02,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:44:08,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:44:14,081] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:44:19,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:44:24,778] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:44:30,064] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:44:35,341] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:44:40,571] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:44:46,349] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:44:51,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.091234380265023
[2022-12-07 03:44:51,917] [INFO] [runner_train_mujoco] Average state value: 0.5343766649961472
[2022-12-07 03:44:51,917] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 03:44:51,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.05055
[2022-12-07 03:44:52,010] [INFO] [controller] EPOCH 2 loss ppo:  -0.01602, loss val: 0.05138
[2022-12-07 03:44:52,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.01766, loss val: 0.05084
[2022-12-07 03:44:52,092] [INFO] [controller] EPOCH 4 loss ppo:  -0.02015, loss val: 0.05239
[2022-12-07 03:44:52,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:44:52,221] [INFO] [optimize] Finished learning.
