[2022-12-06 16:02:43,063] [INFO] [optimize] Starting learning
[2022-12-06 16:02:43,080] [INFO] [optimize] Starting learning process..
[2022-12-06 16:02:43,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:02:43,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:02:53,086] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:03:01,882] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:03:09,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:03:17,222] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:03:25,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:03:33,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:03:42,058] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:03:50,331] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:03:59,214] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:04:08,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5937709010184395
[2022-12-06 16:04:08,148] [INFO] [runner_train_mujoco] Average state value: -0.09083076731363933
[2022-12-06 16:04:08,148] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 16:04:08,223] [INFO] [controller] EPOCH 1 loss ppo:  -0.01024, loss val: 0.58034
[2022-12-06 16:04:08,279] [INFO] [controller] EPOCH 2 loss ppo:  -0.03777, loss val: 0.54812
[2022-12-06 16:04:08,333] [INFO] [controller] EPOCH 3 loss ppo:  -0.05178, loss val: 0.47723
[2022-12-06 16:04:08,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.05804, loss val: 0.42827
[2022-12-06 16:04:08,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:04:08,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:04:08,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:04:17,204] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:04:26,559] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:04:35,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:04:43,982] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:04:53,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:05:03,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:05:11,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:05:19,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:05:29,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:05:37,476] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6368290100137367
[2022-12-06 16:05:37,476] [INFO] [runner_train_mujoco] Average state value: 0.07280620364099741
[2022-12-06 16:05:37,477] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 16:05:37,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.42325
[2022-12-06 16:05:37,632] [INFO] [controller] EPOCH 2 loss ppo:  -0.03930, loss val: 0.38772
[2022-12-06 16:05:37,699] [INFO] [controller] EPOCH 3 loss ppo:  -0.05109, loss val: 0.34471
[2022-12-06 16:05:37,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.06026, loss val: 0.31010
[2022-12-06 16:05:37,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:05:38,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:05:38,008] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:05:46,488] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:05:54,959] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:06:02,995] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:06:10,780] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:06:18,411] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:06:26,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:06:34,729] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:06:42,538] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:06:50,319] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:06:58,274] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.35811373460570983
[2022-12-06 16:06:58,274] [INFO] [runner_train_mujoco] Average state value: 0.23534348328659935
[2022-12-06 16:06:58,274] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 16:06:58,341] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.19143
[2022-12-06 16:06:58,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.04733, loss val: 0.17449
[2022-12-06 16:06:58,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.06100, loss val: 0.16406
[2022-12-06 16:06:58,582] [INFO] [controller] EPOCH 4 loss ppo:  -0.06668, loss val: 0.14778
[2022-12-06 16:06:58,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:06:58,820] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:06:58,821] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:07:08,576] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:07:16,752] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:07:25,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:07:32,850] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:07:40,163] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:07:47,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:07:54,930] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:08:02,152] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:08:09,449] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:08:17,130] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4344543015381722
[2022-12-06 16:08:17,130] [INFO] [runner_train_mujoco] Average state value: 0.39601855574982864
[2022-12-06 16:08:17,130] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 16:08:17,206] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.15317
[2022-12-06 16:08:17,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.03915, loss val: 0.13565
[2022-12-06 16:08:17,330] [INFO] [controller] EPOCH 3 loss ppo:  -0.05426, loss val: 0.12449
[2022-12-06 16:08:17,385] [INFO] [controller] EPOCH 4 loss ppo:  -0.06308, loss val: 0.11566
[2022-12-06 16:08:17,396] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:08:17,620] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:08:17,621] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:08:25,231] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:08:32,719] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:08:39,872] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:08:47,077] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:08:54,286] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:09:01,351] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:09:08,367] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:09:15,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:09:22,700] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:09:30,121] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4370213716717261
[2022-12-06 16:09:30,122] [INFO] [runner_train_mujoco] Average state value: 0.5087205119878053
[2022-12-06 16:09:30,122] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 16:09:30,187] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.11886
[2022-12-06 16:09:30,239] [INFO] [controller] EPOCH 2 loss ppo:  -0.03422, loss val: 0.11075
[2022-12-06 16:09:30,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.04462, loss val: 0.10703
[2022-12-06 16:09:30,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.05183, loss val: 0.09939
[2022-12-06 16:09:30,353] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:09:30,562] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:09:30,562] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:09:37,797] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:09:45,387] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:09:52,773] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:10:00,600] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:10:07,967] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:10:14,700] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:10:21,923] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:10:28,936] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:10:36,167] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:10:44,051] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4292885977910186
[2022-12-06 16:10:44,051] [INFO] [runner_train_mujoco] Average state value: 0.5649637970576683
[2022-12-06 16:10:44,051] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 16:10:44,115] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.09490
[2022-12-06 16:10:44,185] [INFO] [controller] EPOCH 2 loss ppo:  -0.03727, loss val: 0.09098
[2022-12-06 16:10:44,247] [INFO] [controller] EPOCH 3 loss ppo:  -0.04851, loss val: 0.08577
[2022-12-06 16:10:44,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.05441, loss val: 0.08023
[2022-12-06 16:10:44,321] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:10:44,544] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:10:44,545] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:10:52,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:11:01,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:11:08,468] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:11:15,655] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:11:23,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:11:31,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:11:39,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:11:46,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:11:55,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:12:03,622] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5131506929097747
[2022-12-06 16:12:03,623] [INFO] [runner_train_mujoco] Average state value: 0.5559234015705685
[2022-12-06 16:12:03,623] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 16:12:03,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.07297
[2022-12-06 16:12:03,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.03363, loss val: 0.06866
[2022-12-06 16:12:03,810] [INFO] [controller] EPOCH 3 loss ppo:  -0.04424, loss val: 0.06624
[2022-12-06 16:12:03,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.05110, loss val: 0.06252
[2022-12-06 16:12:03,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:12:04,114] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:12:04,115] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:12:12,322] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:12:20,200] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:12:28,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:12:36,184] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:12:44,200] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:12:52,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:13:00,165] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:13:07,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:13:15,684] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:13:23,686] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.400211502033158
[2022-12-06 16:13:23,686] [INFO] [runner_train_mujoco] Average state value: 0.5511017187746863
[2022-12-06 16:13:23,686] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 16:13:23,780] [INFO] [controller] EPOCH 1 loss ppo:  -0.00735, loss val: 0.06216
[2022-12-06 16:13:23,852] [INFO] [controller] EPOCH 2 loss ppo:  -0.03009, loss val: 0.05985
[2022-12-06 16:13:23,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.04237, loss val: 0.05753
[2022-12-06 16:13:23,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.05169, loss val: 0.05568
[2022-12-06 16:13:23,985] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:13:24,221] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:13:24,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:13:32,293] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:13:39,470] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:13:46,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:13:54,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:14:01,864] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:14:09,225] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:14:16,497] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:14:23,985] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:14:31,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:14:39,010] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5524172947520689
[2022-12-06 16:14:39,010] [INFO] [runner_train_mujoco] Average state value: 0.5415289480338494
[2022-12-06 16:14:39,010] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 16:14:39,080] [INFO] [controller] EPOCH 1 loss ppo:  -0.01044, loss val: 0.05193
[2022-12-06 16:14:39,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.03321, loss val: 0.05046
[2022-12-06 16:14:39,184] [INFO] [controller] EPOCH 3 loss ppo:  -0.04180, loss val: 0.04910
[2022-12-06 16:14:39,238] [INFO] [controller] EPOCH 4 loss ppo:  -0.04997, loss val: 0.04761
[2022-12-06 16:14:39,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:14:39,469] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:39,471] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:14:47,094] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:14:56,095] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:15:05,877] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:15:13,917] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:15:22,693] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:15:30,559] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:15:38,737] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:15:47,073] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:15:56,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:16:04,907] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3872981007978649
[2022-12-06 16:16:04,908] [INFO] [runner_train_mujoco] Average state value: 0.5475073758910101
[2022-12-06 16:16:04,908] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 16:16:04,980] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.05042
[2022-12-06 16:16:05,050] [INFO] [controller] EPOCH 2 loss ppo:  -0.03339, loss val: 0.04834
[2022-12-06 16:16:05,113] [INFO] [controller] EPOCH 3 loss ppo:  -0.04559, loss val: 0.04381
[2022-12-06 16:16:05,165] [INFO] [controller] EPOCH 4 loss ppo:  -0.05423, loss val: 0.04625
[2022-12-06 16:16:05,176] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:16:05,406] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:16:05,407] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:16:14,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:16:22,278] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:16:30,649] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:16:39,199] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:16:47,836] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:16:56,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:17:05,842] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:17:14,439] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:17:23,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:17:31,776] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6008112544221597
[2022-12-06 16:17:31,776] [INFO] [runner_train_mujoco] Average state value: 0.5044900572200617
[2022-12-06 16:17:31,776] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 16:17:31,843] [INFO] [controller] EPOCH 1 loss ppo:  -0.01147, loss val: 0.05418
[2022-12-06 16:17:31,901] [INFO] [controller] EPOCH 2 loss ppo:  -0.03215, loss val: 0.05437
[2022-12-06 16:17:31,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.04361, loss val: 0.05328
[2022-12-06 16:17:32,014] [INFO] [controller] EPOCH 4 loss ppo:  -0.05184, loss val: 0.05307
[2022-12-06 16:17:32,026] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:17:32,255] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:17:32,255] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:17:41,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:17:49,717] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:17:59,047] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:18:08,360] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:18:17,239] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:18:25,801] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:18:34,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:18:43,016] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:18:51,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:19:00,287] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6672998310473078
[2022-12-06 16:19:00,287] [INFO] [runner_train_mujoco] Average state value: 0.5240580110649267
[2022-12-06 16:19:00,287] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 16:19:00,403] [INFO] [controller] EPOCH 1 loss ppo:  -0.01175, loss val: 0.04517
[2022-12-06 16:19:00,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.03560, loss val: 0.04509
[2022-12-06 16:19:00,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.04628, loss val: 0.04399
[2022-12-06 16:19:00,717] [INFO] [controller] EPOCH 4 loss ppo:  -0.05483, loss val: 0.04220
[2022-12-06 16:19:00,731] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:19:00,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:19:00,993] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:19:09,719] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:19:18,275] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:26,284] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:19:34,604] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:19:43,092] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:19:51,292] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:19:59,283] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:20:07,584] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:20:15,694] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:20:23,898] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5377817343066256
[2022-12-06 16:20:23,899] [INFO] [runner_train_mujoco] Average state value: 0.5003626944820085
[2022-12-06 16:20:23,899] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 16:20:23,973] [INFO] [controller] EPOCH 1 loss ppo:  -0.01182, loss val: 0.04291
[2022-12-06 16:20:24,037] [INFO] [controller] EPOCH 2 loss ppo:  -0.03181, loss val: 0.04483
[2022-12-06 16:20:24,113] [INFO] [controller] EPOCH 3 loss ppo:  -0.04031, loss val: 0.04238
[2022-12-06 16:20:24,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.05030, loss val: 0.03945
[2022-12-06 16:20:24,185] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:20:24,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:20:24,397] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:20:32,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:20:40,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:20:48,739] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:20:56,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:21:04,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:12,633] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:21:20,481] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:21:28,073] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:21:36,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:21:44,461] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6850235062119097
[2022-12-06 16:21:44,461] [INFO] [runner_train_mujoco] Average state value: 0.5287433920204639
[2022-12-06 16:21:44,461] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 16:21:44,534] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.03558
[2022-12-06 16:21:44,593] [INFO] [controller] EPOCH 2 loss ppo:  -0.04087, loss val: 0.03582
[2022-12-06 16:21:44,666] [INFO] [controller] EPOCH 3 loss ppo:  -0.04771, loss val: 0.03653
[2022-12-06 16:21:44,726] [INFO] [controller] EPOCH 4 loss ppo:  -0.05478, loss val: 0.03704
[2022-12-06 16:21:44,737] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:21:44,990] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:21:44,991] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:21:53,420] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:22:02,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:22:10,325] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:22:18,540] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:22:26,780] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:22:35,373] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:22:43,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:22:51,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:23:00,131] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:23:08,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7299477520190223
[2022-12-06 16:23:08,838] [INFO] [runner_train_mujoco] Average state value: 0.5288685801625251
[2022-12-06 16:23:08,838] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 16:23:08,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01264, loss val: 0.04553
[2022-12-06 16:23:08,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.03752, loss val: 0.04413
[2022-12-06 16:23:09,062] [INFO] [controller] EPOCH 3 loss ppo:  -0.04759, loss val: 0.04310
[2022-12-06 16:23:09,159] [INFO] [controller] EPOCH 4 loss ppo:  -0.05467, loss val: 0.04446
[2022-12-06 16:23:09,174] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:23:09,428] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:23:09,428] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:23:18,116] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:23:26,764] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:23:35,398] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:23:43,524] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:23:52,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:24:00,913] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:24:10,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:24:19,024] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:24:27,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:24:36,821] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8048071987344892
[2022-12-06 16:24:36,822] [INFO] [runner_train_mujoco] Average state value: 0.4961312649150689
[2022-12-06 16:24:36,822] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 16:24:36,898] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.03514
[2022-12-06 16:24:36,955] [INFO] [controller] EPOCH 2 loss ppo:  -0.03953, loss val: 0.03322
[2022-12-06 16:24:37,015] [INFO] [controller] EPOCH 3 loss ppo:  -0.05210, loss val: 0.03467
[2022-12-06 16:24:37,075] [INFO] [controller] EPOCH 4 loss ppo:  -0.05711, loss val: 0.03483
[2022-12-06 16:24:37,087] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:24:37,329] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:24:37,330] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:24:46,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:24:55,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:25:04,118] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:25:13,723] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:25:22,538] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:25:30,899] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:25:39,871] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:25:55,416] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:26:09,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:26:21,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.829353564605458
[2022-12-06 16:26:21,255] [INFO] [runner_train_mujoco] Average state value: 0.4784420106237134
[2022-12-06 16:26:21,255] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 16:26:21,485] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.03748
[2022-12-06 16:26:21,691] [INFO] [controller] EPOCH 2 loss ppo:  -0.03277, loss val: 0.03669
[2022-12-06 16:26:21,827] [INFO] [controller] EPOCH 3 loss ppo:  -0.04327, loss val: 0.03808
[2022-12-06 16:26:22,040] [INFO] [controller] EPOCH 4 loss ppo:  -0.05369, loss val: 0.03608
[2022-12-06 16:26:22,063] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:26:22,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:26:22,376] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:26:35,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:26:46,527] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:26:58,259] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:27:09,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:27:18,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:27:27,201] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:27:36,924] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:27:48,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:28:02,010] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:28:11,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0197809431875144
[2022-12-06 16:28:11,923] [INFO] [runner_train_mujoco] Average state value: 0.4987650259931883
[2022-12-06 16:28:11,924] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 16:28:12,032] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04342
[2022-12-06 16:28:12,219] [INFO] [controller] EPOCH 2 loss ppo:  -0.03493, loss val: 0.04281
[2022-12-06 16:28:12,341] [INFO] [controller] EPOCH 3 loss ppo:  -0.05122, loss val: 0.04341
[2022-12-06 16:28:12,456] [INFO] [controller] EPOCH 4 loss ppo:  -0.06197, loss val: 0.04354
[2022-12-06 16:28:12,474] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:28:12,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:28:12,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:28:22,305] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:28:31,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:28:40,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:28:49,261] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:28:58,058] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:29:06,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:29:16,907] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:29:27,165] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:29:36,539] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:29:46,134] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3150935646158426
[2022-12-06 16:29:46,135] [INFO] [runner_train_mujoco] Average state value: 0.4989048595229784
[2022-12-06 16:29:46,135] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 16:29:46,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01650, loss val: 0.04155
[2022-12-06 16:29:46,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.03702, loss val: 0.03859
[2022-12-06 16:29:46,373] [INFO] [controller] EPOCH 3 loss ppo:  -0.04173, loss val: 0.04003
[2022-12-06 16:29:46,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.04927, loss val: 0.03621
[2022-12-06 16:29:46,474] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:29:46,714] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:29:46,714] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:29:55,723] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:30:04,489] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:30:13,186] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:30:21,738] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:30:30,284] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:30:38,981] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:30:47,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:30:56,423] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:31:04,924] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:31:13,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9619370073027818
[2022-12-06 16:31:13,214] [INFO] [runner_train_mujoco] Average state value: 0.5344455046057701
[2022-12-06 16:31:13,214] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 16:31:13,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04422
[2022-12-06 16:31:13,397] [INFO] [controller] EPOCH 2 loss ppo:  -0.03389, loss val: 0.04504
[2022-12-06 16:31:13,454] [INFO] [controller] EPOCH 3 loss ppo:  -0.04797, loss val: 0.04441
[2022-12-06 16:31:13,520] [INFO] [controller] EPOCH 4 loss ppo:  -0.05804, loss val: 0.04370
[2022-12-06 16:31:13,533] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:31:13,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:31:13,776] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:31:22,002] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:31:30,119] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:31:38,624] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:31:46,627] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:31:55,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:32:03,247] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:32:11,304] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:32:19,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:32:27,772] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:32:36,343] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9214211811720883
[2022-12-06 16:32:36,343] [INFO] [runner_train_mujoco] Average state value: 0.534222145507733
[2022-12-06 16:32:36,343] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 16:32:36,467] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.05132
[2022-12-06 16:32:36,558] [INFO] [controller] EPOCH 2 loss ppo:  -0.03599, loss val: 0.05001
[2022-12-06 16:32:36,670] [INFO] [controller] EPOCH 3 loss ppo:  -0.05371, loss val: 0.04988
[2022-12-06 16:32:36,749] [INFO] [controller] EPOCH 4 loss ppo:  -0.06316, loss val: 0.05078
[2022-12-06 16:32:36,760] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:32:36,985] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:32:36,985] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:32:44,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:32:53,004] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:33:01,039] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:33:09,139] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:33:17,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:33:24,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:33:32,004] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:33:39,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:33:46,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:33:54,601] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.315621614518964
[2022-12-06 16:33:54,601] [INFO] [runner_train_mujoco] Average state value: 0.500323268175125
[2022-12-06 16:33:54,601] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 16:33:54,738] [INFO] [controller] EPOCH 1 loss ppo:  -0.01521, loss val: 0.04468
[2022-12-06 16:33:54,821] [INFO] [controller] EPOCH 2 loss ppo:  -0.03317, loss val: 0.04677
[2022-12-06 16:33:54,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.04096, loss val: 0.04375
[2022-12-06 16:33:54,976] [INFO] [controller] EPOCH 4 loss ppo:  -0.05312, loss val: 0.04066
[2022-12-06 16:33:54,987] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:33:55,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:33:55,217] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:34:03,451] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:34:11,513] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:34:20,427] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:34:29,030] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:34:39,337] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:34:47,497] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:34:59,065] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:35:11,704] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:35:20,405] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:35:29,293] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7054023357352435
[2022-12-06 16:35:29,294] [INFO] [runner_train_mujoco] Average state value: 0.5510785576701164
[2022-12-06 16:35:29,294] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 16:35:29,391] [INFO] [controller] EPOCH 1 loss ppo:  -0.01496, loss val: 0.04502
[2022-12-06 16:35:29,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.03720, loss val: 0.04651
[2022-12-06 16:35:29,594] [INFO] [controller] EPOCH 3 loss ppo:  -0.05116, loss val: 0.04674
[2022-12-06 16:35:29,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.06131, loss val: 0.04512
[2022-12-06 16:35:29,709] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:35:29,979] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:35:29,980] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:35:38,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:35:46,989] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:35:55,042] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:36:02,991] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:36:11,627] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:36:21,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:36:33,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:36:45,149] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:36:54,053] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:37:03,433] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.041259304727982
[2022-12-06 16:37:03,433] [INFO] [runner_train_mujoco] Average state value: 0.5488702701926231
[2022-12-06 16:37:03,433] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 16:37:03,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.04424
[2022-12-06 16:37:03,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.03502, loss val: 0.04224
[2022-12-06 16:37:03,633] [INFO] [controller] EPOCH 3 loss ppo:  -0.04869, loss val: 0.04027
[2022-12-06 16:37:03,717] [INFO] [controller] EPOCH 4 loss ppo:  -0.05956, loss val: 0.03975
[2022-12-06 16:37:03,730] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:37:03,981] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:37:03,982] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:37:13,415] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:37:22,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:37:32,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:37:41,277] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:37:50,202] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:37:59,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:38:08,472] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:38:17,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:38:30,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:38:44,716] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9918676065851675
[2022-12-06 16:38:44,717] [INFO] [runner_train_mujoco] Average state value: 0.4842718699773153
[2022-12-06 16:38:44,717] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 16:38:44,811] [INFO] [controller] EPOCH 1 loss ppo:  -0.01619, loss val: 0.05184
[2022-12-06 16:38:44,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.03700, loss val: 0.05482
[2022-12-06 16:38:45,070] [INFO] [controller] EPOCH 3 loss ppo:  -0.04761, loss val: 0.05403
[2022-12-06 16:38:45,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.05980, loss val: 0.05339
[2022-12-06 16:38:45,221] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:38:45,476] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:38:45,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:38:55,426] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:39:05,267] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:39:16,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:39:28,471] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:39:38,923] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:39:49,651] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:39:59,036] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:40:09,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:40:21,628] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:40:31,366] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.223301436617281
[2022-12-06 16:40:31,367] [INFO] [runner_train_mujoco] Average state value: 0.4560194459209839
[2022-12-06 16:40:31,367] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 16:40:31,473] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.04275
[2022-12-06 16:40:31,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.03274, loss val: 0.04220
[2022-12-06 16:40:31,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.04620, loss val: 0.04216
[2022-12-06 16:40:31,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.05907, loss val: 0.04247
[2022-12-06 16:40:31,719] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:40:31,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:40:31,952] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:40:41,252] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:40:50,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:40:59,650] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:41:08,713] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:41:17,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:26,084] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:41:34,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:41:42,852] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:41:51,738] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:42:01,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3668175207183095
[2022-12-06 16:42:01,026] [INFO] [runner_train_mujoco] Average state value: 0.4563065978189309
[2022-12-06 16:42:01,026] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 16:42:01,272] [INFO] [controller] EPOCH 1 loss ppo:  -0.01624, loss val: 0.04441
[2022-12-06 16:42:01,749] [INFO] [controller] EPOCH 2 loss ppo:  -0.03455, loss val: 0.04399
[2022-12-06 16:42:02,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.04769, loss val: 0.04493
[2022-12-06 16:42:02,370] [INFO] [controller] EPOCH 4 loss ppo:  -0.05988, loss val: 0.04440
[2022-12-06 16:42:02,382] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:42:02,625] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:42:02,626] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:42:11,690] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:42:20,258] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:42:29,258] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:42:37,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:42:45,549] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:42:54,045] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:43:02,764] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:43:11,363] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:43:20,693] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:43:29,938] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4801218057221135
[2022-12-06 16:43:29,938] [INFO] [runner_train_mujoco] Average state value: 0.40306217754632234
[2022-12-06 16:43:29,938] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 16:43:30,047] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.11194
[2022-12-06 16:43:30,106] [INFO] [controller] EPOCH 2 loss ppo:  -0.02531, loss val: 0.10789
[2022-12-06 16:43:30,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.03053, loss val: 0.10418
[2022-12-06 16:43:30,223] [INFO] [controller] EPOCH 4 loss ppo:  -0.03835, loss val: 0.09687
[2022-12-06 16:43:30,235] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:43:30,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:43:30,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:43:38,817] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:43:47,274] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:43:55,431] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:44:04,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:44:12,892] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:44:22,005] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:44:31,485] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:44:40,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:44:49,550] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:44:58,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8356460523966724
[2022-12-06 16:44:58,462] [INFO] [runner_train_mujoco] Average state value: 0.4496244206279516
[2022-12-06 16:44:58,462] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 16:44:58,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01658, loss val: 0.05990
[2022-12-06 16:44:58,589] [INFO] [controller] EPOCH 2 loss ppo:  -0.03860, loss val: 0.05544
[2022-12-06 16:44:58,653] [INFO] [controller] EPOCH 3 loss ppo:  -0.04768, loss val: 0.05317
[2022-12-06 16:44:58,720] [INFO] [controller] EPOCH 4 loss ppo:  -0.05752, loss val: 0.05287
[2022-12-06 16:44:58,733] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:44:58,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:44:58,966] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:45:07,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:45:16,436] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:45:27,677] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:45:37,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:45:47,733] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:45:58,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:46:08,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:46:19,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:46:29,437] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:46:38,977] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5848274227978676
[2022-12-06 16:46:38,977] [INFO] [runner_train_mujoco] Average state value: 0.5492315367261569
[2022-12-06 16:46:38,977] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 16:46:39,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.06066
[2022-12-06 16:46:39,160] [INFO] [controller] EPOCH 2 loss ppo:  -0.03139, loss val: 0.06053
[2022-12-06 16:46:39,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.03962, loss val: 0.06094
[2022-12-06 16:46:39,343] [INFO] [controller] EPOCH 4 loss ppo:  -0.05110, loss val: 0.05705
[2022-12-06 16:46:39,359] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:46:39,643] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:46:39,643] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:46:49,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:47:00,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:47:09,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:47:19,966] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:47:29,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:47:38,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:47:47,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:47:57,025] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:48:06,700] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:48:15,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.029770001182497
[2022-12-06 16:48:15,084] [INFO] [runner_train_mujoco] Average state value: 0.5361913233101369
[2022-12-06 16:48:15,084] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 16:48:15,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.03989
[2022-12-06 16:48:15,214] [INFO] [controller] EPOCH 2 loss ppo:  -0.03505, loss val: 0.04066
[2022-12-06 16:48:15,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.05072, loss val: 0.04071
[2022-12-06 16:48:15,447] [INFO] [controller] EPOCH 4 loss ppo:  -0.05818, loss val: 0.04400
[2022-12-06 16:48:15,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:48:15,696] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:48:15,697] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:48:25,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:48:36,642] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:48:45,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:48:54,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:49:02,841] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:49:11,749] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:49:21,649] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:49:30,860] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:49:40,864] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:49:50,242] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.794163000138167
[2022-12-06 16:49:50,243] [INFO] [runner_train_mujoco] Average state value: 0.48283867603167885
[2022-12-06 16:49:50,243] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 16:49:50,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.07006
[2022-12-06 16:49:50,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.02734, loss val: 0.06840
[2022-12-06 16:49:50,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.04113, loss val: 0.06944
[2022-12-06 16:49:50,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.04775, loss val: 0.06408
[2022-12-06 16:49:50,590] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:49:50,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:49:50,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:49:59,314] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:50:07,471] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:50:16,495] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:50:27,770] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:50:37,099] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:50:46,000] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:50:55,364] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:51:05,143] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:51:14,842] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:51:24,307] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.568416387234749
[2022-12-06 16:51:24,307] [INFO] [runner_train_mujoco] Average state value: 0.5172184196723004
[2022-12-06 16:51:24,307] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 16:51:24,485] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.08336
[2022-12-06 16:51:24,628] [INFO] [controller] EPOCH 2 loss ppo:  -0.02707, loss val: 0.08150
[2022-12-06 16:51:24,712] [INFO] [controller] EPOCH 3 loss ppo:  -0.03877, loss val: 0.07738
[2022-12-06 16:51:24,798] [INFO] [controller] EPOCH 4 loss ppo:  -0.04858, loss val: 0.07397
[2022-12-06 16:51:24,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:51:25,047] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:51:25,048] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:51:35,095] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:51:44,649] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:51:53,468] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:52:03,288] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:52:12,495] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:52:21,497] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:52:30,028] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:52:39,146] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:52:47,957] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:52:56,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.150565060798455
[2022-12-06 16:52:56,671] [INFO] [runner_train_mujoco] Average state value: 0.637177141547203
[2022-12-06 16:52:56,671] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 16:52:56,765] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.05749
[2022-12-06 16:52:56,838] [INFO] [controller] EPOCH 2 loss ppo:  -0.02810, loss val: 0.06176
[2022-12-06 16:52:56,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.04080, loss val: 0.06111
[2022-12-06 16:52:56,949] [INFO] [controller] EPOCH 4 loss ppo:  -0.04909, loss val: 0.05943
[2022-12-06 16:52:56,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:52:57,178] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:52:57,178] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:53:05,571] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:53:14,164] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:53:22,938] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:53:31,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:53:40,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:53:48,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:53:57,229] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:54:05,858] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:54:14,375] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:54:23,379] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.3471571085837
[2022-12-06 16:54:23,380] [INFO] [runner_train_mujoco] Average state value: 0.6357747114896773
[2022-12-06 16:54:23,380] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 16:54:23,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.06419
[2022-12-06 16:54:23,560] [INFO] [controller] EPOCH 2 loss ppo:  -0.02443, loss val: 0.05950
[2022-12-06 16:54:23,640] [INFO] [controller] EPOCH 3 loss ppo:  -0.03466, loss val: 0.05446
[2022-12-06 16:54:23,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.04435, loss val: 0.04995
[2022-12-06 16:54:23,751] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:54:24,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:54:24,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:54:32,235] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:54:40,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:54:48,635] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:54:56,721] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:55:04,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:55:12,675] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:55:21,042] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:55:29,194] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:55:37,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:55:45,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.515946003361951
[2022-12-06 16:55:45,089] [INFO] [runner_train_mujoco] Average state value: 0.5350321829542517
[2022-12-06 16:55:45,089] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 16:55:45,180] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.06434
[2022-12-06 16:55:45,267] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.05995
[2022-12-06 16:55:45,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.03925, loss val: 0.05563
[2022-12-06 16:55:45,393] [INFO] [controller] EPOCH 4 loss ppo:  -0.05018, loss val: 0.05257
[2022-12-06 16:55:45,405] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:55:45,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:55:45,622] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:55:53,451] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:56:01,031] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:56:08,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:56:16,583] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:56:24,568] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:56:33,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:56:42,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:56:50,436] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:56:58,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:57:07,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.299021160232113
[2022-12-06 16:57:07,382] [INFO] [runner_train_mujoco] Average state value: 0.4833879790504773
[2022-12-06 16:57:07,382] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 16:57:07,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04670
[2022-12-06 16:57:07,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.03073, loss val: 0.04599
[2022-12-06 16:57:07,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.04174, loss val: 0.04520
[2022-12-06 16:57:07,687] [INFO] [controller] EPOCH 4 loss ppo:  -0.05170, loss val: 0.04296
[2022-12-06 16:57:07,700] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:57:07,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:57:07,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:57:16,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:57:23,882] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:57:32,509] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:57:41,390] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:57:49,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:57:58,634] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:58:07,285] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:58:15,896] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:58:24,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:58:33,353] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.354847481044083
[2022-12-06 16:58:33,353] [INFO] [runner_train_mujoco] Average state value: 0.4037028954004248
[2022-12-06 16:58:33,354] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 16:58:33,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.07900
[2022-12-06 16:58:33,504] [INFO] [controller] EPOCH 2 loss ppo:  -0.01978, loss val: 0.08072
[2022-12-06 16:58:33,560] [INFO] [controller] EPOCH 3 loss ppo:  -0.02725, loss val: 0.07860
[2022-12-06 16:58:33,619] [INFO] [controller] EPOCH 4 loss ppo:  -0.03798, loss val: 0.07821
[2022-12-06 16:58:33,632] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:58:33,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:58:33,877] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:58:43,370] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:58:52,859] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:59:02,216] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:59:11,682] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:59:21,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:59:30,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:59:40,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:59:49,314] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:59:58,746] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:00:08,425] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.6231368445696095
[2022-12-06 17:00:08,425] [INFO] [runner_train_mujoco] Average state value: 0.42462230815241736
[2022-12-06 17:00:08,425] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 17:00:08,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.05369
[2022-12-06 17:00:08,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.02513, loss val: 0.04815
[2022-12-06 17:00:08,747] [INFO] [controller] EPOCH 3 loss ppo:  -0.03381, loss val: 0.04542
[2022-12-06 17:00:08,822] [INFO] [controller] EPOCH 4 loss ppo:  -0.04184, loss val: 0.04079
[2022-12-06 17:00:08,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:00:09,082] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:00:09,083] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:00:17,874] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:00:26,924] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:00:35,720] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:00:44,647] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:00:53,736] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:01:02,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:01:11,690] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:01:20,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:01:29,050] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:01:37,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7556601421231015
[2022-12-06 17:01:37,782] [INFO] [runner_train_mujoco] Average state value: 0.47149563394486904
[2022-12-06 17:01:37,782] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 17:01:37,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.05514
[2022-12-06 17:01:37,943] [INFO] [controller] EPOCH 2 loss ppo:  -0.02883, loss val: 0.05172
[2022-12-06 17:01:38,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.03714, loss val: 0.04797
[2022-12-06 17:01:38,207] [INFO] [controller] EPOCH 4 loss ppo:  -0.04676, loss val: 0.04495
[2022-12-06 17:01:38,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:01:38,546] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:01:38,547] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:01:47,949] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:01:56,626] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:02:06,480] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:02:15,497] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:02:24,725] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:02:33,458] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:02:41,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:02:50,252] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:02:58,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:03:07,231] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.582057825683462
[2022-12-06 17:03:07,231] [INFO] [runner_train_mujoco] Average state value: 0.5389671973586082
[2022-12-06 17:03:07,231] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 17:03:07,394] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.03365
[2022-12-06 17:03:07,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.02877, loss val: 0.03318
[2022-12-06 17:03:07,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.03832, loss val: 0.03485
[2022-12-06 17:03:07,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.04995, loss val: 0.03484
[2022-12-06 17:03:07,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:03:07,964] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:03:07,965] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:03:16,511] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:03:25,015] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:03:33,256] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:03:41,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:03:49,441] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:03:57,210] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:04:05,375] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:04:13,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:04:21,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:04:29,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.565360026612234
[2022-12-06 17:04:29,641] [INFO] [runner_train_mujoco] Average state value: 0.5592453754420081
[2022-12-06 17:04:29,641] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 17:04:29,733] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.04999
[2022-12-06 17:04:29,814] [INFO] [controller] EPOCH 2 loss ppo:  -0.02769, loss val: 0.05112
[2022-12-06 17:04:30,042] [INFO] [controller] EPOCH 3 loss ppo:  -0.03745, loss val: 0.04906
[2022-12-06 17:04:30,103] [INFO] [controller] EPOCH 4 loss ppo:  -0.04700, loss val: 0.04915
[2022-12-06 17:04:30,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:04:30,333] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:04:30,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:04:38,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:04:47,384] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:04:56,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:05:05,012] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:05:12,943] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:05:20,646] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:05:28,902] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:05:37,548] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:05:46,200] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:05:54,973] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.728704475513082
[2022-12-06 17:05:54,974] [INFO] [runner_train_mujoco] Average state value: 0.6020335967739423
[2022-12-06 17:05:54,974] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 17:05:55,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.06805
[2022-12-06 17:05:55,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.02844, loss val: 0.06789
[2022-12-06 17:05:55,204] [INFO] [controller] EPOCH 3 loss ppo:  -0.03455, loss val: 0.06589
[2022-12-06 17:05:55,257] [INFO] [controller] EPOCH 4 loss ppo:  -0.03902, loss val: 0.06452
[2022-12-06 17:05:55,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:05:55,516] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:05:55,516] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:06:04,599] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:06:13,493] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:06:23,595] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:06:33,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:06:41,582] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:06:50,981] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:07:00,685] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:07:12,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:07:22,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:07:32,907] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.049804232016454
[2022-12-06 17:07:32,907] [INFO] [runner_train_mujoco] Average state value: 0.5772650187412898
[2022-12-06 17:07:32,907] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 17:07:33,026] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.08705
[2022-12-06 17:07:33,093] [INFO] [controller] EPOCH 2 loss ppo:  -0.02055, loss val: 0.08367
[2022-12-06 17:07:33,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.02986, loss val: 0.07946
[2022-12-06 17:07:33,506] [INFO] [controller] EPOCH 4 loss ppo:  -0.03977, loss val: 0.07272
[2022-12-06 17:07:33,533] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:07:33,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:07:33,969] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:07:47,119] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:07:58,541] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:08:09,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:08:20,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:08:32,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:08:42,486] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:08:52,765] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:09:04,225] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:09:16,514] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:09:27,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.764471115152089
[2022-12-06 17:09:27,481] [INFO] [runner_train_mujoco] Average state value: 0.5156538479203979
[2022-12-06 17:09:27,481] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 17:09:27,601] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04789
[2022-12-06 17:09:27,685] [INFO] [controller] EPOCH 2 loss ppo:  -0.02572, loss val: 0.04406
[2022-12-06 17:09:27,791] [INFO] [controller] EPOCH 3 loss ppo:  -0.03663, loss val: 0.04793
[2022-12-06 17:09:27,902] [INFO] [controller] EPOCH 4 loss ppo:  -0.04686, loss val: 0.04811
[2022-12-06 17:09:27,915] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:09:28,168] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:09:28,169] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:09:38,305] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:09:49,196] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:10:00,908] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:10:14,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:10:26,020] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:10:36,966] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:10:49,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:11:02,292] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:11:13,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:11:25,694] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.994061405421378
[2022-12-06 17:11:25,694] [INFO] [runner_train_mujoco] Average state value: 0.4894973738392195
[2022-12-06 17:11:25,694] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 17:11:25,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03862
[2022-12-06 17:11:25,892] [INFO] [controller] EPOCH 2 loss ppo:  -0.02208, loss val: 0.03746
[2022-12-06 17:11:26,099] [INFO] [controller] EPOCH 3 loss ppo:  -0.02884, loss val: 0.03885
[2022-12-06 17:11:26,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.03846, loss val: 0.03727
[2022-12-06 17:11:26,231] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:11:26,539] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:11:26,539] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:11:40,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:11:52,332] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:12:03,948] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:12:16,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:12:27,204] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:12:38,626] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:12:50,764] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:13:05,264] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:13:15,931] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:13:26,993] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.992280181692421
[2022-12-06 17:13:26,994] [INFO] [runner_train_mujoco] Average state value: 0.4700938047394157
[2022-12-06 17:13:26,994] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 17:13:27,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.05731
[2022-12-06 17:13:27,319] [INFO] [controller] EPOCH 2 loss ppo:  -0.01984, loss val: 0.05378
[2022-12-06 17:13:27,675] [INFO] [controller] EPOCH 3 loss ppo:  -0.02918, loss val: 0.05550
[2022-12-06 17:13:28,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.03905, loss val: 0.05151
[2022-12-06 17:13:28,250] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:13:28,650] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:13:28,653] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:13:40,064] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:13:50,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:14:00,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:14:11,143] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:14:22,211] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:14:32,252] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:14:42,506] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:14:51,071] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:15:00,358] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:15:12,357] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.649108541776603
[2022-12-06 17:15:12,357] [INFO] [runner_train_mujoco] Average state value: 0.5022363833598792
[2022-12-06 17:15:12,358] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 17:15:12,621] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.06082
[2022-12-06 17:15:12,895] [INFO] [controller] EPOCH 2 loss ppo:  -0.02244, loss val: 0.05733
[2022-12-06 17:15:13,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.03193, loss val: 0.05807
[2022-12-06 17:15:13,199] [INFO] [controller] EPOCH 4 loss ppo:  -0.03883, loss val: 0.05420
[2022-12-06 17:15:13,214] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:15:13,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:15:13,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:15:23,677] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:15:32,067] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:15:40,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:15:49,605] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:15:58,004] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:16:07,404] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:16:16,202] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:16:24,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:16:33,019] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:16:42,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.838158589820835
[2022-12-06 17:16:42,701] [INFO] [runner_train_mujoco] Average state value: 0.5399816131790478
[2022-12-06 17:16:42,702] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 17:16:42,879] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.03608
[2022-12-06 17:16:42,989] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.03658
[2022-12-06 17:16:43,076] [INFO] [controller] EPOCH 3 loss ppo:  -0.03580, loss val: 0.03564
[2022-12-06 17:16:43,147] [INFO] [controller] EPOCH 4 loss ppo:  -0.04326, loss val: 0.03567
[2022-12-06 17:16:43,160] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:16:43,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:16:43,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:16:51,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:17:00,795] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:17:09,518] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:17:18,067] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:17:27,198] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:17:36,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:17:46,012] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:17:54,060] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:18:02,020] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:18:09,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.995519565741947
[2022-12-06 17:18:09,354] [INFO] [runner_train_mujoco] Average state value: 0.5631143430893619
[2022-12-06 17:18:09,354] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 17:18:09,415] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.02471
[2022-12-06 17:18:09,461] [INFO] [controller] EPOCH 2 loss ppo:  -0.02524, loss val: 0.02525
[2022-12-06 17:18:09,510] [INFO] [controller] EPOCH 3 loss ppo:  -0.03890, loss val: 0.02495
[2022-12-06 17:18:09,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.04460, loss val: 0.02450
[2022-12-06 17:18:09,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:18:09,774] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:18:09,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:18:17,003] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:18:25,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:18:32,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:18:39,582] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:18:47,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:18:55,327] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:19:02,623] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:19:10,172] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:19:17,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:19:25,995] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.090818124374381
[2022-12-06 17:19:25,995] [INFO] [runner_train_mujoco] Average state value: 0.5429496774027744
[2022-12-06 17:19:25,995] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 17:19:26,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.07230
[2022-12-06 17:19:26,125] [INFO] [controller] EPOCH 2 loss ppo:  -0.01786, loss val: 0.07231
[2022-12-06 17:19:26,187] [INFO] [controller] EPOCH 3 loss ppo:  -0.02658, loss val: 0.07171
[2022-12-06 17:19:26,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.03492, loss val: 0.07121
[2022-12-06 17:19:26,272] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:19:26,510] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:19:26,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:19:34,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:19:41,661] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:19:48,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:19:55,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:20:03,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:20:11,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:20:18,645] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:20:26,349] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:20:36,458] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:20:45,481] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0627002018478375
[2022-12-06 17:20:45,482] [INFO] [runner_train_mujoco] Average state value: 0.5719079020222028
[2022-12-06 17:20:45,482] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 17:20:45,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.05804
[2022-12-06 17:20:45,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.01977, loss val: 0.06315
[2022-12-06 17:20:45,739] [INFO] [controller] EPOCH 3 loss ppo:  -0.02642, loss val: 0.05477
[2022-12-06 17:20:45,822] [INFO] [controller] EPOCH 4 loss ppo:  -0.03118, loss val: 0.05347
[2022-12-06 17:20:45,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:20:46,086] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:20:46,086] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:20:56,305] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:21:04,529] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:21:12,955] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:21:21,597] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:21:29,878] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:21:37,400] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:21:44,808] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:21:51,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:21:58,936] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:22:06,523] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.356571475074539
[2022-12-06 17:22:06,523] [INFO] [runner_train_mujoco] Average state value: 0.5560842603345713
[2022-12-06 17:22:06,523] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 17:22:06,583] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.06705
[2022-12-06 17:22:06,637] [INFO] [controller] EPOCH 2 loss ppo:  -0.01686, loss val: 0.06506
[2022-12-06 17:22:06,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.02396, loss val: 0.06317
[2022-12-06 17:22:06,762] [INFO] [controller] EPOCH 4 loss ppo:  -0.03037, loss val: 0.06126
[2022-12-06 17:22:06,773] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:22:06,996] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:22:06,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:22:14,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:22:22,065] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:22:29,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:22:36,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:22:44,017] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:22:51,844] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:22:59,580] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:23:06,934] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:23:14,528] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:23:22,306] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.01735945081424
[2022-12-06 17:23:22,306] [INFO] [runner_train_mujoco] Average state value: 0.5210115318993728
[2022-12-06 17:23:22,306] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 17:23:22,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04358
[2022-12-06 17:23:22,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.01712, loss val: 0.04739
[2022-12-06 17:23:22,487] [INFO] [controller] EPOCH 3 loss ppo:  -0.02526, loss val: 0.04531
[2022-12-06 17:23:22,545] [INFO] [controller] EPOCH 4 loss ppo:  -0.03123, loss val: 0.04403
[2022-12-06 17:23:22,556] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:23:22,785] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:23:22,786] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:23:30,118] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:23:38,388] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:23:46,037] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:23:54,123] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:24:01,864] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:24:09,113] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:24:16,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:24:23,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:24:30,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:24:38,057] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.182059859004484
[2022-12-06 17:24:38,057] [INFO] [runner_train_mujoco] Average state value: 0.5063410350481667
[2022-12-06 17:24:38,058] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 17:24:38,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.04950
[2022-12-06 17:24:38,168] [INFO] [controller] EPOCH 2 loss ppo:  -0.01621, loss val: 0.05318
[2022-12-06 17:24:38,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.02243, loss val: 0.04911
[2022-12-06 17:24:38,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.02953, loss val: 0.05411
[2022-12-06 17:24:38,290] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:24:38,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:24:38,508] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:24:45,951] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:24:53,338] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:25:01,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:25:08,826] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:25:16,164] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:25:23,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:25:30,584] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:25:37,452] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:25:44,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:25:51,048] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.045014519017616
[2022-12-06 17:25:51,048] [INFO] [runner_train_mujoco] Average state value: 0.521870920052131
[2022-12-06 17:25:51,048] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 17:25:51,114] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04434
[2022-12-06 17:25:51,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.01742, loss val: 0.04515
[2022-12-06 17:25:51,211] [INFO] [controller] EPOCH 3 loss ppo:  -0.02375, loss val: 0.04404
[2022-12-06 17:25:51,263] [INFO] [controller] EPOCH 4 loss ppo:  -0.02922, loss val: 0.04534
[2022-12-06 17:25:51,274] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:25:51,485] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:25:51,485] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:25:58,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:26:06,020] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:26:13,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:26:20,560] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:26:27,483] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:26:34,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:26:41,501] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:26:48,440] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:26:55,229] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:27:01,843] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.567032045435293
[2022-12-06 17:27:01,843] [INFO] [runner_train_mujoco] Average state value: 0.48783807803566254
[2022-12-06 17:27:01,843] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 17:27:01,915] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.05648
[2022-12-06 17:27:02,002] [INFO] [controller] EPOCH 2 loss ppo:  -0.01549, loss val: 0.05638
[2022-12-06 17:27:02,077] [INFO] [controller] EPOCH 3 loss ppo:  -0.01960, loss val: 0.05617
[2022-12-06 17:27:02,147] [INFO] [controller] EPOCH 4 loss ppo:  -0.02505, loss val: 0.05668
[2022-12-06 17:27:02,158] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:27:02,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:27:02,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:27:08,844] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:27:15,006] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:27:21,205] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:27:26,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:27:32,543] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:27:38,116] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:27:44,042] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:27:49,694] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:27:55,724] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:28:01,533] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.889374718589101
[2022-12-06 17:28:01,533] [INFO] [runner_train_mujoco] Average state value: 0.44126216132069623
[2022-12-06 17:28:01,533] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 17:28:01,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.09448
[2022-12-06 17:28:01,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.01408, loss val: 0.09600
[2022-12-06 17:28:01,689] [INFO] [controller] EPOCH 3 loss ppo:  -0.01599, loss val: 0.09540
[2022-12-06 17:28:01,736] [INFO] [controller] EPOCH 4 loss ppo:  -0.01833, loss val: 0.09325
[2022-12-06 17:28:01,746] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:28:01,889] [INFO] [optimize] Finished learning.
