[2022-12-06 18:27:36,888] [INFO] [optimize] Starting learning
[2022-12-06 18:27:36,897] [INFO] [optimize] Starting learning process..
[2022-12-06 18:27:36,986] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:27:36,989] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:27:47,257] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:27:55,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:28:03,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:28:11,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:28:19,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:28:27,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:28:36,131] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:28:44,645] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:28:53,089] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:29:01,596] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5708516379147259
[2022-12-06 18:29:01,596] [INFO] [runner_train_mujoco] Average state value: 0.1119901984979709
[2022-12-06 18:29:01,596] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 18:29:01,690] [INFO] [controller] EPOCH 1 loss ppo:  -0.00922, loss val: 0.31467
[2022-12-06 18:29:01,744] [INFO] [controller] EPOCH 2 loss ppo:  -0.04359, loss val: 0.29418
[2022-12-06 18:29:01,799] [INFO] [controller] EPOCH 3 loss ppo:  -0.05693, loss val: 0.24122
[2022-12-06 18:29:01,855] [INFO] [controller] EPOCH 4 loss ppo:  -0.06698, loss val: 0.21113
[2022-12-06 18:29:01,869] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:29:02,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:29:02,089] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:29:10,342] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:29:18,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:29:27,577] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:29:35,493] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:29:43,763] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:29:52,309] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:30:00,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:30:09,155] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:30:17,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:30:25,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48952786249170643
[2022-12-06 18:30:25,562] [INFO] [runner_train_mujoco] Average state value: 0.2770439916693916
[2022-12-06 18:30:25,562] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 18:30:25,622] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.19423
[2022-12-06 18:30:25,682] [INFO] [controller] EPOCH 2 loss ppo:  -0.03894, loss val: 0.17104
[2022-12-06 18:30:25,738] [INFO] [controller] EPOCH 3 loss ppo:  -0.05098, loss val: 0.14715
[2022-12-06 18:30:25,789] [INFO] [controller] EPOCH 4 loss ppo:  -0.06094, loss val: 0.12877
[2022-12-06 18:30:25,800] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:30:26,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:30:26,019] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:30:33,950] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:30:42,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:30:50,683] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:30:59,340] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:31:07,363] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:31:15,669] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:31:23,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:31:31,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:31:39,477] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:31:47,644] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5562577565244827
[2022-12-06 18:31:47,644] [INFO] [runner_train_mujoco] Average state value: 0.4481957405482729
[2022-12-06 18:31:47,644] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 18:31:47,703] [INFO] [controller] EPOCH 1 loss ppo:  -0.01258, loss val: 0.11447
[2022-12-06 18:31:47,757] [INFO] [controller] EPOCH 2 loss ppo:  -0.03919, loss val: 0.10494
[2022-12-06 18:31:47,807] [INFO] [controller] EPOCH 3 loss ppo:  -0.05196, loss val: 0.09678
[2022-12-06 18:31:47,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.05745, loss val: 0.09044
[2022-12-06 18:31:47,871] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:31:48,079] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:31:48,080] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:31:55,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:32:04,021] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:32:11,926] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:32:20,305] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:32:27,761] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:32:35,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:32:43,148] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:32:50,916] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:32:58,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:33:06,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47118393866270464
[2022-12-06 18:33:06,055] [INFO] [runner_train_mujoco] Average state value: 0.5280203972843786
[2022-12-06 18:33:06,055] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 18:33:06,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.01123, loss val: 0.08336
[2022-12-06 18:33:06,167] [INFO] [controller] EPOCH 2 loss ppo:  -0.03830, loss val: 0.07770
[2022-12-06 18:33:06,216] [INFO] [controller] EPOCH 3 loss ppo:  -0.04910, loss val: 0.07586
[2022-12-06 18:33:06,274] [INFO] [controller] EPOCH 4 loss ppo:  -0.05607, loss val: 0.06772
[2022-12-06 18:33:06,285] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:33:06,498] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:33:06,498] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:33:14,204] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:33:21,196] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:33:29,327] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:33:36,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:33:43,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:33:50,572] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:33:58,018] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:34:06,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:34:13,666] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:34:21,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.32354082268100287
[2022-12-06 18:34:21,004] [INFO] [runner_train_mujoco] Average state value: 0.5217275822001198
[2022-12-06 18:34:21,004] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 18:34:21,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.07616
[2022-12-06 18:34:21,186] [INFO] [controller] EPOCH 2 loss ppo:  -0.03825, loss val: 0.07230
[2022-12-06 18:34:21,266] [INFO] [controller] EPOCH 3 loss ppo:  -0.05236, loss val: 0.07073
[2022-12-06 18:34:21,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.06018, loss val: 0.06367
[2022-12-06 18:34:21,360] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:34:21,697] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:34:21,700] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:34:29,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:34:37,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:34:45,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:34:54,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:35:05,655] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:35:12,723] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:35:19,796] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:35:27,212] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:35:34,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:35:42,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3702283362705082
[2022-12-06 18:35:42,572] [INFO] [runner_train_mujoco] Average state value: 0.5583913471996784
[2022-12-06 18:35:42,572] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 18:35:42,657] [INFO] [controller] EPOCH 1 loss ppo:  -0.01049, loss val: 0.06688
[2022-12-06 18:35:42,708] [INFO] [controller] EPOCH 2 loss ppo:  -0.02676, loss val: 0.06167
[2022-12-06 18:35:42,785] [INFO] [controller] EPOCH 3 loss ppo:  -0.03776, loss val: 0.05711
[2022-12-06 18:35:42,850] [INFO] [controller] EPOCH 4 loss ppo:  -0.04595, loss val: 0.05150
[2022-12-06 18:35:42,863] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:35:43,091] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:35:43,092] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:35:50,806] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:35:58,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:36:06,723] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:36:14,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:36:24,942] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:36:35,548] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:36:47,154] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:36:59,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:37:09,477] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:37:19,119] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46650408076049016
[2022-12-06 18:37:19,120] [INFO] [runner_train_mujoco] Average state value: 0.5110900419205426
[2022-12-06 18:37:19,120] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 18:37:19,227] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.04809
[2022-12-06 18:37:19,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.04464, loss val: 0.04282
[2022-12-06 18:37:19,413] [INFO] [controller] EPOCH 3 loss ppo:  -0.05364, loss val: 0.03985
[2022-12-06 18:37:19,524] [INFO] [controller] EPOCH 4 loss ppo:  -0.05690, loss val: 0.03846
[2022-12-06 18:37:19,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:37:19,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:37:19,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:37:32,263] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:37:41,946] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:37:52,370] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:38:05,423] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:38:15,822] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:38:26,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:38:36,701] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:38:48,507] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:38:59,974] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:39:09,947] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5429265771052745
[2022-12-06 18:39:09,948] [INFO] [runner_train_mujoco] Average state value: 0.4291463712478677
[2022-12-06 18:39:09,948] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 18:39:10,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.01177, loss val: 0.07553
[2022-12-06 18:39:10,103] [INFO] [controller] EPOCH 2 loss ppo:  -0.02778, loss val: 0.07490
[2022-12-06 18:39:10,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.03433, loss val: 0.07702
[2022-12-06 18:39:10,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.04248, loss val: 0.06984
[2022-12-06 18:39:10,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:39:10,548] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:39:10,548] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:39:20,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:39:30,608] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:39:40,720] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:39:51,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:40:00,762] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:40:11,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:40:23,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:40:33,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:40:45,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:41:03,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5220054357864778
[2022-12-06 18:41:03,215] [INFO] [runner_train_mujoco] Average state value: 0.4474951215734085
[2022-12-06 18:41:03,215] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 18:41:04,553] [INFO] [controller] EPOCH 1 loss ppo:  -0.01055, loss val: 0.03576
[2022-12-06 18:41:04,744] [INFO] [controller] EPOCH 2 loss ppo:  -0.03447, loss val: 0.03645
[2022-12-06 18:41:04,898] [INFO] [controller] EPOCH 3 loss ppo:  -0.04695, loss val: 0.03679
[2022-12-06 18:41:05,052] [INFO] [controller] EPOCH 4 loss ppo:  -0.05697, loss val: 0.03449
[2022-12-06 18:41:05,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:41:05,356] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:41:05,372] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:41:17,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:41:26,036] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:41:35,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:41:44,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:41:54,006] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:42:02,269] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:42:11,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:42:20,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:42:29,440] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:42:40,263] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48635694460352097
[2022-12-06 18:42:40,263] [INFO] [runner_train_mujoco] Average state value: 0.4515579612851143
[2022-12-06 18:42:40,263] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 18:42:40,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.00968, loss val: 0.05882
[2022-12-06 18:42:40,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.02437, loss val: 0.06421
[2022-12-06 18:42:40,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.03787, loss val: 0.05743
[2022-12-06 18:42:40,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.04855, loss val: 0.05440
[2022-12-06 18:42:40,832] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:42:41,119] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:42:41,119] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:42:52,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:43:03,194] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:43:13,184] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:43:23,927] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:43:33,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:43:43,877] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:43:55,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:44:05,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:44:16,241] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:44:26,294] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4957887797000149
[2022-12-06 18:44:26,295] [INFO] [runner_train_mujoco] Average state value: 0.4796378633404772
[2022-12-06 18:44:26,295] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 18:44:26,504] [INFO] [controller] EPOCH 1 loss ppo:  -0.01035, loss val: 0.03772
[2022-12-06 18:44:26,571] [INFO] [controller] EPOCH 2 loss ppo:  -0.03305, loss val: 0.03808
[2022-12-06 18:44:26,674] [INFO] [controller] EPOCH 3 loss ppo:  -0.04796, loss val: 0.03852
[2022-12-06 18:44:26,742] [INFO] [controller] EPOCH 4 loss ppo:  -0.05805, loss val: 0.03739
[2022-12-06 18:44:26,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:44:27,027] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:44:27,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:44:37,158] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:44:46,629] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:44:57,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:45:07,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:45:17,353] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:45:27,694] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:45:37,907] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:45:48,105] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:45:58,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:46:08,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4266342330392332
[2022-12-06 18:46:08,620] [INFO] [runner_train_mujoco] Average state value: 0.470742052624623
[2022-12-06 18:46:08,620] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 18:46:08,740] [INFO] [controller] EPOCH 1 loss ppo:  -0.01051, loss val: 0.04202
[2022-12-06 18:46:08,850] [INFO] [controller] EPOCH 2 loss ppo:  -0.03428, loss val: 0.04231
[2022-12-06 18:46:09,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.04657, loss val: 0.04070
[2022-12-06 18:46:09,150] [INFO] [controller] EPOCH 4 loss ppo:  -0.05969, loss val: 0.04422
[2022-12-06 18:46:09,166] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:46:09,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:46:09,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:46:20,153] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:46:29,765] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:46:39,964] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:46:50,062] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:47:00,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:47:10,529] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:47:20,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:47:30,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:47:41,568] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:47:51,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5829530538125731
[2022-12-06 18:47:51,432] [INFO] [runner_train_mujoco] Average state value: 0.4924297940631708
[2022-12-06 18:47:51,433] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 18:47:51,528] [INFO] [controller] EPOCH 1 loss ppo:  -0.01103, loss val: 0.04115
[2022-12-06 18:47:51,593] [INFO] [controller] EPOCH 2 loss ppo:  -0.03325, loss val: 0.04069
[2022-12-06 18:47:51,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.04622, loss val: 0.04048
[2022-12-06 18:47:51,874] [INFO] [controller] EPOCH 4 loss ppo:  -0.05611, loss val: 0.04515
[2022-12-06 18:47:51,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:47:52,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:47:52,182] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:48:02,219] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:48:12,201] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:48:22,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:48:33,452] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:48:43,046] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:48:52,842] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:49:02,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:49:12,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:49:22,173] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:49:32,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5852235557246874
[2022-12-06 18:49:32,465] [INFO] [runner_train_mujoco] Average state value: 0.5418322883844375
[2022-12-06 18:49:32,465] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 18:49:32,561] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.03829
[2022-12-06 18:49:32,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.03210, loss val: 0.03772
[2022-12-06 18:49:32,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.04155, loss val: 0.03743
[2022-12-06 18:49:32,843] [INFO] [controller] EPOCH 4 loss ppo:  -0.05169, loss val: 0.03726
[2022-12-06 18:49:32,858] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:49:33,138] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:49:33,139] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:49:43,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:49:52,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:50:02,926] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:50:12,792] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:50:22,499] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:50:32,718] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:50:43,379] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:50:53,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:51:03,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:51:13,071] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7052766332020303
[2022-12-06 18:51:13,072] [INFO] [runner_train_mujoco] Average state value: 0.5544582835535208
[2022-12-06 18:51:13,072] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 18:51:13,165] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.03195
[2022-12-06 18:51:13,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.03228, loss val: 0.03155
[2022-12-06 18:51:13,351] [INFO] [controller] EPOCH 3 loss ppo:  -0.04454, loss val: 0.03262
[2022-12-06 18:51:13,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.05546, loss val: 0.03291
[2022-12-06 18:51:13,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:51:13,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:51:13,733] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:51:23,826] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:51:33,814] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:51:43,967] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:51:54,231] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:52:04,167] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:52:14,476] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:52:24,410] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:52:33,796] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:52:43,816] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:52:53,789] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4629065898262156
[2022-12-06 18:52:53,789] [INFO] [runner_train_mujoco] Average state value: 0.5348353778719902
[2022-12-06 18:52:53,789] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 18:52:53,877] [INFO] [controller] EPOCH 1 loss ppo:  -0.01117, loss val: 0.04823
[2022-12-06 18:52:53,951] [INFO] [controller] EPOCH 2 loss ppo:  -0.03445, loss val: 0.04817
[2022-12-06 18:52:54,026] [INFO] [controller] EPOCH 3 loss ppo:  -0.04380, loss val: 0.04895
[2022-12-06 18:52:54,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.05030, loss val: 0.04765
[2022-12-06 18:52:54,124] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:52:54,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:52:54,391] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:53:04,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:53:14,664] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:53:24,828] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:53:34,775] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:53:44,553] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:53:54,777] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:54:05,121] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:54:15,066] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:54:24,663] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:54:34,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5965111430619865
[2022-12-06 18:54:34,522] [INFO] [runner_train_mujoco] Average state value: 0.5303638963699342
[2022-12-06 18:54:34,522] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 18:54:34,616] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.03705
[2022-12-06 18:54:34,680] [INFO] [controller] EPOCH 2 loss ppo:  -0.03014, loss val: 0.03634
[2022-12-06 18:54:34,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.04374, loss val: 0.03604
[2022-12-06 18:54:34,826] [INFO] [controller] EPOCH 4 loss ppo:  -0.05504, loss val: 0.03528
[2022-12-06 18:54:34,838] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:54:35,133] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:54:35,134] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:54:45,655] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:54:55,663] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:55:05,420] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:55:15,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:55:25,752] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:55:35,769] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:55:45,290] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:55:55,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:56:05,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:56:14,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7934820504329826
[2022-12-06 18:56:14,784] [INFO] [runner_train_mujoco] Average state value: 0.5529009600381056
[2022-12-06 18:56:14,784] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 18:56:14,879] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04316
[2022-12-06 18:56:14,950] [INFO] [controller] EPOCH 2 loss ppo:  -0.03769, loss val: 0.04296
[2022-12-06 18:56:15,018] [INFO] [controller] EPOCH 3 loss ppo:  -0.04709, loss val: 0.04353
[2022-12-06 18:56:15,090] [INFO] [controller] EPOCH 4 loss ppo:  -0.05599, loss val: 0.04337
[2022-12-06 18:56:15,105] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:56:15,365] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:56:15,365] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:56:25,233] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:56:35,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:56:45,019] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:56:53,709] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:57:02,741] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:57:11,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:57:20,329] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:57:29,792] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:57:39,634] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:57:49,267] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7819932913774449
[2022-12-06 18:57:49,268] [INFO] [runner_train_mujoco] Average state value: 0.5264430919090907
[2022-12-06 18:57:49,268] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 18:57:49,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.04260
[2022-12-06 18:57:49,431] [INFO] [controller] EPOCH 2 loss ppo:  -0.03304, loss val: 0.04185
[2022-12-06 18:57:49,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.04849, loss val: 0.03934
[2022-12-06 18:57:49,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.05919, loss val: 0.03899
[2022-12-06 18:57:49,580] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:57:49,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:57:49,851] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:57:59,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:58:10,063] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:58:20,045] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:58:30,299] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:58:40,148] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:58:49,654] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:58:59,036] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:59:09,086] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:59:18,847] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:59:28,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3155909776557375
[2022-12-06 18:59:28,659] [INFO] [runner_train_mujoco] Average state value: 0.4664996705154577
[2022-12-06 18:59:28,660] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 18:59:28,751] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.03867
[2022-12-06 18:59:28,830] [INFO] [controller] EPOCH 2 loss ppo:  -0.03252, loss val: 0.04220
[2022-12-06 18:59:28,905] [INFO] [controller] EPOCH 3 loss ppo:  -0.04610, loss val: 0.03956
[2022-12-06 18:59:28,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.05850, loss val: 0.03894
[2022-12-06 18:59:28,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:59:29,236] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:59:29,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:59:39,603] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:59:50,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:00:01,174] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:00:13,270] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:00:23,971] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:00:34,672] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:00:45,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:00:56,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:01:07,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:01:18,460] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2946269738095482
[2022-12-06 19:01:18,461] [INFO] [runner_train_mujoco] Average state value: 0.43691541999578476
[2022-12-06 19:01:18,461] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 19:01:18,553] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04007
[2022-12-06 19:01:18,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.03265, loss val: 0.03843
[2022-12-06 19:01:18,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.04489, loss val: 0.03892
[2022-12-06 19:01:18,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.05392, loss val: 0.03783
[2022-12-06 19:01:18,832] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:01:19,101] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:01:19,102] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:01:29,827] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:01:40,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:01:51,774] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:02:02,299] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:02:12,921] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:02:23,479] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:02:34,221] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:02:45,680] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:02:56,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:03:06,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7753984728914536
[2022-12-06 19:03:06,829] [INFO] [runner_train_mujoco] Average state value: 0.45222385424375533
[2022-12-06 19:03:06,829] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 19:03:06,981] [INFO] [controller] EPOCH 1 loss ppo:  -0.01255, loss val: 0.05827
[2022-12-06 19:03:07,086] [INFO] [controller] EPOCH 2 loss ppo:  -0.02296, loss val: 0.05039
[2022-12-06 19:03:07,183] [INFO] [controller] EPOCH 3 loss ppo:  -0.03614, loss val: 0.04657
[2022-12-06 19:03:07,282] [INFO] [controller] EPOCH 4 loss ppo:  -0.04941, loss val: 0.03974
[2022-12-06 19:03:07,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:03:07,595] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:03:07,595] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:03:18,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:03:29,007] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:03:39,708] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:03:50,602] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:04:01,767] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:04:12,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:04:23,118] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:04:33,729] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:04:44,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:04:54,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.854759873341219
[2022-12-06 19:04:54,959] [INFO] [runner_train_mujoco] Average state value: 0.5283822969496249
[2022-12-06 19:04:54,959] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 19:04:55,193] [INFO] [controller] EPOCH 1 loss ppo:  -0.01656, loss val: 0.04752
[2022-12-06 19:04:55,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.03524, loss val: 0.04840
[2022-12-06 19:04:55,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.04156, loss val: 0.04960
[2022-12-06 19:04:55,504] [INFO] [controller] EPOCH 4 loss ppo:  -0.05347, loss val: 0.04850
[2022-12-06 19:04:55,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:04:55,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:04:55,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:05:06,833] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:05:17,469] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:05:28,311] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:05:39,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:05:49,734] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:05:59,403] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:06:08,814] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:06:17,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:06:27,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:06:36,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1617791737349803
[2022-12-06 19:06:36,331] [INFO] [runner_train_mujoco] Average state value: 0.5396235371132692
[2022-12-06 19:06:36,331] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 19:06:36,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.04237
[2022-12-06 19:06:36,499] [INFO] [controller] EPOCH 2 loss ppo:  -0.03088, loss val: 0.03894
[2022-12-06 19:06:36,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.04483, loss val: 0.03733
[2022-12-06 19:06:36,628] [INFO] [controller] EPOCH 4 loss ppo:  -0.05470, loss val: 0.03267
[2022-12-06 19:06:36,641] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:06:36,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:06:36,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:06:46,415] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:06:56,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:07:09,867] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:07:21,456] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:07:33,001] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:07:43,582] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:07:54,124] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:08:04,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:08:15,197] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:08:25,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8927309610227936
[2022-12-06 19:08:25,981] [INFO] [runner_train_mujoco] Average state value: 0.45632411351799956
[2022-12-06 19:08:25,981] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 19:08:26,098] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.03733
[2022-12-06 19:08:26,169] [INFO] [controller] EPOCH 2 loss ppo:  -0.03171, loss val: 0.03815
[2022-12-06 19:08:26,330] [INFO] [controller] EPOCH 3 loss ppo:  -0.04576, loss val: 0.04035
[2022-12-06 19:08:26,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.05978, loss val: 0.03864
[2022-12-06 19:08:26,448] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:08:26,734] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:08:26,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:08:38,100] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:08:48,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:08:59,431] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:09:10,101] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:09:20,445] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:09:30,775] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:09:41,593] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:09:52,292] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:10:02,816] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:10:13,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9895359524653697
[2022-12-06 19:10:13,342] [INFO] [runner_train_mujoco] Average state value: 0.44101590232054394
[2022-12-06 19:10:13,343] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 19:10:13,509] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04412
[2022-12-06 19:10:13,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.03573, loss val: 0.04289
[2022-12-06 19:10:13,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.04924, loss val: 0.04226
[2022-12-06 19:10:13,902] [INFO] [controller] EPOCH 4 loss ppo:  -0.05916, loss val: 0.04270
[2022-12-06 19:10:13,915] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:10:14,199] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:10:14,200] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:10:24,864] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:10:35,439] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:10:46,245] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:10:57,146] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:11:07,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:11:17,897] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:11:28,124] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:11:39,259] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:11:50,062] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:12:00,368] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.095287146071726
[2022-12-06 19:12:00,368] [INFO] [runner_train_mujoco] Average state value: 0.4813814373811086
[2022-12-06 19:12:00,369] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 19:12:00,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.03169
[2022-12-06 19:12:00,602] [INFO] [controller] EPOCH 2 loss ppo:  -0.03308, loss val: 0.03147
[2022-12-06 19:12:00,699] [INFO] [controller] EPOCH 3 loss ppo:  -0.04649, loss val: 0.03220
[2022-12-06 19:12:00,783] [INFO] [controller] EPOCH 4 loss ppo:  -0.05745, loss val: 0.03191
[2022-12-06 19:12:00,796] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:12:01,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:12:01,061] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:12:11,945] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:12:22,907] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:12:33,734] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:12:43,935] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:12:54,016] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:13:04,605] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:13:15,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:13:25,044] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:13:35,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:13:46,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0551860978191687
[2022-12-06 19:13:46,254] [INFO] [runner_train_mujoco] Average state value: 0.5028385621110598
[2022-12-06 19:13:46,254] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 19:13:46,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01579, loss val: 0.04578
[2022-12-06 19:13:46,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.03021, loss val: 0.04573
[2022-12-06 19:13:46,549] [INFO] [controller] EPOCH 3 loss ppo:  -0.04145, loss val: 0.04425
[2022-12-06 19:13:46,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.05588, loss val: 0.04235
[2022-12-06 19:13:46,673] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:13:46,940] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:13:46,941] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:13:57,768] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:14:08,059] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:14:18,621] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:14:28,941] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:14:39,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:14:49,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:14:59,834] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:15:10,042] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:15:20,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:15:31,787] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.12373982154868
[2022-12-06 19:15:31,788] [INFO] [runner_train_mujoco] Average state value: 0.46752675834298135
[2022-12-06 19:15:31,788] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 19:15:31,995] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.03794
[2022-12-06 19:15:32,138] [INFO] [controller] EPOCH 2 loss ppo:  -0.03029, loss val: 0.04363
[2022-12-06 19:15:32,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.04310, loss val: 0.03904
[2022-12-06 19:15:32,388] [INFO] [controller] EPOCH 4 loss ppo:  -0.05365, loss val: 0.03879
[2022-12-06 19:15:32,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:15:32,684] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:15:32,685] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:15:43,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:15:53,822] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:16:04,295] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:16:17,294] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:16:27,450] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:16:37,945] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:16:48,319] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:17:00,174] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:17:10,997] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:17:21,615] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4781912938776225
[2022-12-06 19:17:21,616] [INFO] [runner_train_mujoco] Average state value: 0.4553934294084708
[2022-12-06 19:17:21,616] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 19:17:22,112] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.04243
[2022-12-06 19:17:22,335] [INFO] [controller] EPOCH 2 loss ppo:  -0.03080, loss val: 0.04083
[2022-12-06 19:17:22,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.03954, loss val: 0.04229
[2022-12-06 19:17:22,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.05192, loss val: 0.04312
[2022-12-06 19:17:22,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:17:22,964] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:17:22,964] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:17:35,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:17:47,140] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:17:58,390] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:18:09,261] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:18:19,342] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:18:28,529] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:18:38,828] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:19:02,717] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:19:23,784] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:19:36,287] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4785995211813385
[2022-12-06 19:19:36,288] [INFO] [runner_train_mujoco] Average state value: 0.44242426835993925
[2022-12-06 19:19:36,288] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 19:19:36,397] [INFO] [controller] EPOCH 1 loss ppo:  -0.01750, loss val: 0.05293
[2022-12-06 19:19:37,225] [INFO] [controller] EPOCH 2 loss ppo:  -0.03105, loss val: 0.05211
[2022-12-06 19:19:38,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.03848, loss val: 0.05375
[2022-12-06 19:19:38,685] [INFO] [controller] EPOCH 4 loss ppo:  -0.05599, loss val: 0.05123
[2022-12-06 19:19:38,742] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:19:39,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:19:39,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:19:47,597] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:19:54,967] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:20:02,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:20:09,392] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:20:16,308] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:20:23,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:20:29,829] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:20:37,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:20:44,046] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:20:50,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8164549802815264
[2022-12-06 19:20:50,904] [INFO] [runner_train_mujoco] Average state value: 0.46291244924068453
[2022-12-06 19:20:50,904] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 19:20:50,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04634
[2022-12-06 19:20:51,010] [INFO] [controller] EPOCH 2 loss ppo:  -0.02738, loss val: 0.04925
[2022-12-06 19:20:51,078] [INFO] [controller] EPOCH 3 loss ppo:  -0.04203, loss val: 0.05012
[2022-12-06 19:20:51,147] [INFO] [controller] EPOCH 4 loss ppo:  -0.05469, loss val: 0.04633
[2022-12-06 19:20:51,157] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:20:51,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:20:51,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:20:58,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:21:05,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:21:12,334] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:21:19,066] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:21:25,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:21:32,777] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:21:39,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:21:46,586] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:21:53,656] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:22:00,758] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.004553348204135
[2022-12-06 19:22:00,758] [INFO] [runner_train_mujoco] Average state value: 0.46269765806198115
[2022-12-06 19:22:00,758] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 19:22:00,885] [INFO] [controller] EPOCH 1 loss ppo:  -0.01579, loss val: 0.04357
[2022-12-06 19:22:00,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.02597, loss val: 0.04701
[2022-12-06 19:22:00,996] [INFO] [controller] EPOCH 3 loss ppo:  -0.03777, loss val: 0.04260
[2022-12-06 19:22:01,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.05128, loss val: 0.04743
[2022-12-06 19:22:01,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:22:01,259] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:22:01,260] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:22:08,304] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:22:15,340] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:22:22,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:22:29,581] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:22:36,716] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:22:44,176] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:22:51,353] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:22:58,401] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:23:05,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:23:13,155] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.323146954285394
[2022-12-06 19:23:13,155] [INFO] [runner_train_mujoco] Average state value: 0.4533803232510885
[2022-12-06 19:23:13,155] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 19:23:13,225] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04341
[2022-12-06 19:23:13,303] [INFO] [controller] EPOCH 2 loss ppo:  -0.02849, loss val: 0.04594
[2022-12-06 19:23:13,400] [INFO] [controller] EPOCH 3 loss ppo:  -0.03769, loss val: 0.04182
[2022-12-06 19:23:13,455] [INFO] [controller] EPOCH 4 loss ppo:  -0.04831, loss val: 0.04102
[2022-12-06 19:23:13,466] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:23:13,693] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:23:13,693] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:23:20,835] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:23:28,365] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:23:35,881] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:23:43,370] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:23:50,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:23:58,317] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:24:06,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:24:14,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:24:21,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:24:29,715] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.223202153925325
[2022-12-06 19:24:29,715] [INFO] [runner_train_mujoco] Average state value: 0.42909326460957525
[2022-12-06 19:24:29,715] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 19:24:29,794] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.05098
[2022-12-06 19:24:29,921] [INFO] [controller] EPOCH 2 loss ppo:  -0.02523, loss val: 0.05127
[2022-12-06 19:24:29,989] [INFO] [controller] EPOCH 3 loss ppo:  -0.03520, loss val: 0.05379
[2022-12-06 19:24:30,061] [INFO] [controller] EPOCH 4 loss ppo:  -0.04286, loss val: 0.04905
[2022-12-06 19:24:30,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:24:30,297] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:24:30,298] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:24:38,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:24:45,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:24:53,874] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:25:01,502] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:25:09,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:25:17,405] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:25:25,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:25:32,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:25:40,887] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:25:49,099] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.291015442480672
[2022-12-06 19:25:49,099] [INFO] [runner_train_mujoco] Average state value: 0.44692442508538555
[2022-12-06 19:25:49,099] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 19:25:49,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01681, loss val: 0.04713
[2022-12-06 19:25:49,215] [INFO] [controller] EPOCH 2 loss ppo:  -0.03332, loss val: 0.04752
[2022-12-06 19:25:49,269] [INFO] [controller] EPOCH 3 loss ppo:  -0.04048, loss val: 0.04720
[2022-12-06 19:25:49,324] [INFO] [controller] EPOCH 4 loss ppo:  -0.05251, loss val: 0.04709
[2022-12-06 19:25:49,335] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:25:49,568] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:25:49,569] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:25:57,620] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:26:05,984] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:26:14,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:26:22,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:26:30,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:26:38,566] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:26:46,865] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:26:55,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:27:03,855] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:27:11,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.297882652039657
[2022-12-06 19:27:11,997] [INFO] [runner_train_mujoco] Average state value: 0.465128047366937
[2022-12-06 19:27:11,997] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 19:27:12,076] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.03867
[2022-12-06 19:27:12,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.02764, loss val: 0.03641
[2022-12-06 19:27:12,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.03646, loss val: 0.03695
[2022-12-06 19:27:12,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.04547, loss val: 0.03642
[2022-12-06 19:27:12,339] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:27:12,574] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:27:12,575] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:27:21,256] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:27:29,786] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:27:38,168] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:27:46,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:27:55,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:28:03,963] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:28:12,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:28:21,429] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:28:30,126] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:28:38,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.915811044159698
[2022-12-06 19:28:38,778] [INFO] [runner_train_mujoco] Average state value: 0.47261719652016954
[2022-12-06 19:28:38,778] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 19:28:38,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01248, loss val: 0.04117
[2022-12-06 19:28:38,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.02343, loss val: 0.04101
[2022-12-06 19:28:39,000] [INFO] [controller] EPOCH 3 loss ppo:  -0.03428, loss val: 0.04055
[2022-12-06 19:28:39,088] [INFO] [controller] EPOCH 4 loss ppo:  -0.04287, loss val: 0.04196
[2022-12-06 19:28:39,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:28:39,363] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:28:39,367] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:28:48,356] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:28:57,437] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:29:06,899] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:29:16,045] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:29:25,062] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:29:34,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:29:43,406] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:29:52,815] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:30:02,704] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:30:12,868] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.658086449362232
[2022-12-06 19:30:12,869] [INFO] [runner_train_mujoco] Average state value: 0.454704348941644
[2022-12-06 19:30:12,869] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 19:30:12,971] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04020
[2022-12-06 19:30:13,040] [INFO] [controller] EPOCH 2 loss ppo:  -0.02426, loss val: 0.04035
[2022-12-06 19:30:13,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.03208, loss val: 0.04016
[2022-12-06 19:30:13,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.04208, loss val: 0.03805
[2022-12-06 19:30:13,193] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:30:13,497] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:30:13,498] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:30:23,735] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:30:33,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:30:44,561] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:30:54,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:31:04,903] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:31:15,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:31:25,663] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:31:37,033] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:31:48,895] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:32:01,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.630411532497468
[2022-12-06 19:32:01,192] [INFO] [runner_train_mujoco] Average state value: 0.42274725010991104
[2022-12-06 19:32:01,192] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 19:32:01,312] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04243
[2022-12-06 19:32:01,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.02324, loss val: 0.04257
[2022-12-06 19:32:01,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.03603, loss val: 0.04275
[2022-12-06 19:32:01,620] [INFO] [controller] EPOCH 4 loss ppo:  -0.04754, loss val: 0.04268
[2022-12-06 19:32:01,637] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:32:01,982] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:32:01,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:32:14,777] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:32:26,106] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:32:38,432] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:32:51,258] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:33:04,094] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:33:17,142] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:33:30,987] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:33:45,159] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:33:59,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:34:13,585] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.708187649130362
[2022-12-06 19:34:13,586] [INFO] [runner_train_mujoco] Average state value: 0.4186373943984509
[2022-12-06 19:34:13,586] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 19:34:13,704] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.05437
[2022-12-06 19:34:13,812] [INFO] [controller] EPOCH 2 loss ppo:  -0.02519, loss val: 0.05307
[2022-12-06 19:34:13,910] [INFO] [controller] EPOCH 3 loss ppo:  -0.03562, loss val: 0.05111
[2022-12-06 19:34:14,014] [INFO] [controller] EPOCH 4 loss ppo:  -0.04338, loss val: 0.04919
[2022-12-06 19:34:14,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:34:14,426] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:34:14,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:34:27,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:34:40,121] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:34:53,337] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:35:05,269] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:35:17,153] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:35:28,263] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:35:39,408] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:35:51,027] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:36:02,006] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:36:13,000] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.788675809894336
[2022-12-06 19:36:13,001] [INFO] [runner_train_mujoco] Average state value: 0.45302342306574184
[2022-12-06 19:36:13,001] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 19:36:13,095] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.03868
[2022-12-06 19:36:13,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.02605, loss val: 0.04121
[2022-12-06 19:36:13,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.03077, loss val: 0.04037
[2022-12-06 19:36:13,356] [INFO] [controller] EPOCH 4 loss ppo:  -0.04184, loss val: 0.03997
[2022-12-06 19:36:13,381] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:36:13,686] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:36:13,687] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:36:24,854] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:36:35,537] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:36:46,904] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:36:56,815] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:37:06,723] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:37:16,769] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:37:25,949] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:37:35,451] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:37:44,747] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:37:54,316] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.191876079869573
[2022-12-06 19:37:54,317] [INFO] [runner_train_mujoco] Average state value: 0.4791879890759786
[2022-12-06 19:37:54,317] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 19:37:54,394] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.03551
[2022-12-06 19:37:54,453] [INFO] [controller] EPOCH 2 loss ppo:  -0.02185, loss val: 0.03536
[2022-12-06 19:37:54,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.02921, loss val: 0.03486
[2022-12-06 19:37:54,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.03928, loss val: 0.03624
[2022-12-06 19:37:54,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:37:54,844] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:37:54,845] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:38:04,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:38:14,236] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:38:23,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:38:32,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:38:41,478] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:38:50,568] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:38:59,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:39:08,269] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:39:17,288] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:39:26,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4767719964863755
[2022-12-06 19:39:26,285] [INFO] [runner_train_mujoco] Average state value: 0.4891601579189301
[2022-12-06 19:39:26,286] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 19:39:26,372] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.05356
[2022-12-06 19:39:26,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.01857, loss val: 0.05254
[2022-12-06 19:39:26,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.02467, loss val: 0.05345
[2022-12-06 19:39:26,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.03550, loss val: 0.05429
[2022-12-06 19:39:26,555] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:39:26,793] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:39:26,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:39:36,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:39:45,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:39:54,844] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:40:04,408] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:40:13,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:40:23,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:40:33,410] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:40:43,811] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:40:54,695] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:41:05,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.310911984308532
[2022-12-06 19:41:05,042] [INFO] [runner_train_mujoco] Average state value: 0.492185462752978
[2022-12-06 19:41:05,043] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 19:41:05,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01521, loss val: 0.04792
[2022-12-06 19:41:05,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.02393, loss val: 0.04438
[2022-12-06 19:41:05,294] [INFO] [controller] EPOCH 3 loss ppo:  -0.02795, loss val: 0.04546
[2022-12-06 19:41:05,382] [INFO] [controller] EPOCH 4 loss ppo:  -0.03676, loss val: 0.04427
[2022-12-06 19:41:05,398] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:41:05,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:41:05,680] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:41:18,285] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:41:27,945] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:41:38,536] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:41:49,677] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:42:00,854] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:42:12,164] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:42:23,334] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:42:35,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:42:47,144] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:42:58,711] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.231483452551247
[2022-12-06 19:42:58,711] [INFO] [runner_train_mujoco] Average state value: 0.4940559322834014
[2022-12-06 19:42:58,712] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 19:42:58,815] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04116
[2022-12-06 19:42:58,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.02344, loss val: 0.03889
[2022-12-06 19:42:59,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.02807, loss val: 0.03808
[2022-12-06 19:42:59,414] [INFO] [controller] EPOCH 4 loss ppo:  -0.03998, loss val: 0.04045
[2022-12-06 19:42:59,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:42:59,735] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:42:59,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:43:12,344] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:43:26,389] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:43:39,325] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:43:51,249] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:44:04,550] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:44:14,765] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:44:24,048] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:44:33,698] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:44:43,002] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:44:51,896] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.594480634612908
[2022-12-06 19:44:51,896] [INFO] [runner_train_mujoco] Average state value: 0.4962531978090604
[2022-12-06 19:44:51,897] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 19:44:51,986] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04247
[2022-12-06 19:44:52,071] [INFO] [controller] EPOCH 2 loss ppo:  -0.02040, loss val: 0.04394
[2022-12-06 19:44:52,160] [INFO] [controller] EPOCH 3 loss ppo:  -0.03069, loss val: 0.04353
[2022-12-06 19:44:52,227] [INFO] [controller] EPOCH 4 loss ppo:  -0.03597, loss val: 0.04292
[2022-12-06 19:44:52,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:44:52,488] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:44:52,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:45:02,019] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:45:10,606] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:45:19,341] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:45:28,957] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:45:37,594] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:45:46,269] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:45:54,616] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:46:04,945] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:46:14,298] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:46:22,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.3528138045065266
[2022-12-06 19:46:22,563] [INFO] [runner_train_mujoco] Average state value: 0.4814285183846951
[2022-12-06 19:46:22,563] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 19:46:22,631] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03638
[2022-12-06 19:46:22,702] [INFO] [controller] EPOCH 2 loss ppo:  -0.02260, loss val: 0.03624
[2022-12-06 19:46:22,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.02835, loss val: 0.03614
[2022-12-06 19:46:22,872] [INFO] [controller] EPOCH 4 loss ppo:  -0.03368, loss val: 0.03629
[2022-12-06 19:46:22,885] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:46:23,115] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:46:23,115] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:46:31,370] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:46:39,102] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:46:47,248] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:46:55,791] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:47:03,569] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:47:12,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:47:21,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:47:28,687] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:47:36,105] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:47:43,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.564714324985336
[2022-12-06 19:47:43,237] [INFO] [runner_train_mujoco] Average state value: 0.4899876759648323
[2022-12-06 19:47:43,237] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 19:47:43,305] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.04745
[2022-12-06 19:47:43,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.02140, loss val: 0.04356
[2022-12-06 19:47:43,423] [INFO] [controller] EPOCH 3 loss ppo:  -0.02991, loss val: 0.04270
[2022-12-06 19:47:43,479] [INFO] [controller] EPOCH 4 loss ppo:  -0.03448, loss val: 0.04610
[2022-12-06 19:47:43,494] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:47:43,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:47:43,729] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:47:51,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:48:00,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:48:09,769] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:48:17,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:48:25,932] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:48:33,674] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:48:41,482] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:48:49,461] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:48:57,444] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:49:05,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.507232344121947
[2022-12-06 19:49:05,447] [INFO] [runner_train_mujoco] Average state value: 0.48547537600000706
[2022-12-06 19:49:05,448] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 19:49:05,531] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.04157
[2022-12-06 19:49:05,593] [INFO] [controller] EPOCH 2 loss ppo:  -0.01992, loss val: 0.04185
[2022-12-06 19:49:05,651] [INFO] [controller] EPOCH 3 loss ppo:  -0.02960, loss val: 0.04164
[2022-12-06 19:49:05,717] [INFO] [controller] EPOCH 4 loss ppo:  -0.03639, loss val: 0.04162
[2022-12-06 19:49:05,730] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:49:05,955] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:49:05,956] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:49:14,374] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:49:22,193] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:49:30,014] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:49:39,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:49:47,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:49:56,074] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:50:04,818] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:50:13,914] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:50:22,291] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:50:30,259] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.725793562790156
[2022-12-06 19:50:30,259] [INFO] [runner_train_mujoco] Average state value: 0.48530608728528024
[2022-12-06 19:50:30,259] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 19:50:30,328] [INFO] [controller] EPOCH 1 loss ppo:  -0.01581, loss val: 0.03645
[2022-12-06 19:50:30,396] [INFO] [controller] EPOCH 2 loss ppo:  -0.02387, loss val: 0.03726
[2022-12-06 19:50:30,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.02600, loss val: 0.03582
[2022-12-06 19:50:30,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.02833, loss val: 0.03623
[2022-12-06 19:50:30,530] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:50:30,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:50:30,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:50:38,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:50:46,253] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:50:53,741] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:51:01,284] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:51:08,604] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:51:16,180] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:51:23,796] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:51:31,266] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:51:38,666] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:51:45,803] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.775167594759201
[2022-12-06 19:51:45,803] [INFO] [runner_train_mujoco] Average state value: 0.4862706252932549
[2022-12-06 19:51:45,803] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 19:51:45,885] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04301
[2022-12-06 19:51:45,948] [INFO] [controller] EPOCH 2 loss ppo:  -0.02158, loss val: 0.04278
[2022-12-06 19:51:46,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.03033, loss val: 0.04283
[2022-12-06 19:51:46,060] [INFO] [controller] EPOCH 4 loss ppo:  -0.03292, loss val: 0.04310
[2022-12-06 19:51:46,072] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:51:46,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:51:46,299] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:51:53,709] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:52:01,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:52:09,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:52:16,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:52:23,752] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:52:31,113] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:52:38,363] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:52:45,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:52:51,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:52:58,895] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.086852074046202
[2022-12-06 19:52:58,895] [INFO] [runner_train_mujoco] Average state value: 0.49561125740408907
[2022-12-06 19:52:58,895] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 19:52:58,954] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.05739
[2022-12-06 19:52:59,003] [INFO] [controller] EPOCH 2 loss ppo:  -0.02286, loss val: 0.05729
[2022-12-06 19:52:59,061] [INFO] [controller] EPOCH 3 loss ppo:  -0.03096, loss val: 0.05865
[2022-12-06 19:52:59,111] [INFO] [controller] EPOCH 4 loss ppo:  -0.03231, loss val: 0.05619
[2022-12-06 19:52:59,121] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:52:59,337] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:52:59,337] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:53:06,613] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:53:13,464] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:53:20,852] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:53:27,482] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:53:34,149] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:53:41,252] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:53:48,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:53:55,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:54:02,535] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:54:09,044] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.045579233835315
[2022-12-06 19:54:09,045] [INFO] [runner_train_mujoco] Average state value: 0.4859602537751197
[2022-12-06 19:54:09,045] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 19:54:09,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.05761
[2022-12-06 19:54:09,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.01810, loss val: 0.05714
[2022-12-06 19:54:09,221] [INFO] [controller] EPOCH 3 loss ppo:  -0.02469, loss val: 0.05683
[2022-12-06 19:54:09,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.02806, loss val: 0.05598
[2022-12-06 19:54:09,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:54:09,498] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:54:09,499] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:54:16,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:54:23,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:54:29,855] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:54:36,834] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:54:43,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:54:50,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:54:56,753] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:55:03,294] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:55:09,704] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:55:16,405] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.33402569860048
[2022-12-06 19:55:16,405] [INFO] [runner_train_mujoco] Average state value: 0.46877376402417814
[2022-12-06 19:55:16,405] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 19:55:16,486] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.05031
[2022-12-06 19:55:16,545] [INFO] [controller] EPOCH 2 loss ppo:  -0.01960, loss val: 0.05046
[2022-12-06 19:55:16,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.02678, loss val: 0.04966
[2022-12-06 19:55:16,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.03061, loss val: 0.04955
[2022-12-06 19:55:16,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:55:16,864] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:55:16,865] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:55:23,788] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:55:30,576] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:55:37,229] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:55:43,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:55:50,413] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:55:56,777] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:56:02,899] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:56:09,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:56:15,372] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:56:21,519] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.165943225786252
[2022-12-06 19:56:21,519] [INFO] [runner_train_mujoco] Average state value: 0.4525131357610225
[2022-12-06 19:56:21,520] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 19:56:21,575] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.05215
[2022-12-06 19:56:21,621] [INFO] [controller] EPOCH 2 loss ppo:  -0.01770, loss val: 0.05198
[2022-12-06 19:56:21,667] [INFO] [controller] EPOCH 3 loss ppo:  -0.02288, loss val: 0.05283
[2022-12-06 19:56:21,729] [INFO] [controller] EPOCH 4 loss ppo:  -0.02799, loss val: 0.05231
[2022-12-06 19:56:21,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:56:21,947] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:56:21,947] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:56:28,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:56:34,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:56:41,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:56:48,117] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:56:54,878] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:57:01,872] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:57:08,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:57:14,832] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:57:20,996] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:57:27,194] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.388223047417787
[2022-12-06 19:57:27,195] [INFO] [runner_train_mujoco] Average state value: 0.4453104081451893
[2022-12-06 19:57:27,195] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 19:57:27,260] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.03616
[2022-12-06 19:57:27,305] [INFO] [controller] EPOCH 2 loss ppo:  -0.01642, loss val: 0.03656
[2022-12-06 19:57:27,352] [INFO] [controller] EPOCH 3 loss ppo:  -0.02023, loss val: 0.03744
[2022-12-06 19:57:27,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.02454, loss val: 0.03888
[2022-12-06 19:57:27,408] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:57:27,612] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:57:27,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:57:33,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:57:40,051] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:57:45,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:57:51,301] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:57:56,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:58:02,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:58:07,399] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:58:12,811] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:58:18,057] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:58:23,484] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.627756749537022
[2022-12-06 19:58:23,484] [INFO] [runner_train_mujoco] Average state value: 0.4430356719990572
[2022-12-06 19:58:23,484] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 19:58:23,536] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.05144
[2022-12-06 19:58:23,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.01461, loss val: 0.05218
[2022-12-06 19:58:23,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.01598, loss val: 0.05477
[2022-12-06 19:58:23,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.01771, loss val: 0.05269
[2022-12-06 19:58:23,673] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:58:23,797] [INFO] [optimize] Finished learning.
