[2022-12-07 08:49:34,613] [INFO] [optimize] Starting learning
[2022-12-07 08:49:34,626] [INFO] [optimize] Starting learning process..
[2022-12-07 08:49:34,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:49:34,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:49:42,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:49:49,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:49:56,630] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:50:03,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:50:10,525] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:50:17,410] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:50:24,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:50:30,774] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:50:37,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:50:44,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.45403810877552286
[2022-12-07 08:50:44,401] [INFO] [runner_train_mujoco] Average state value: 0.0006971288782854886
[2022-12-07 08:50:44,402] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:50:44,461] [INFO] [controller] EPOCH 1 loss ppo:  -0.01554, loss val: 0.42719
[2022-12-07 08:50:44,508] [INFO] [controller] EPOCH 2 loss ppo:  -0.04553, loss val: 0.37785
[2022-12-07 08:50:44,560] [INFO] [controller] EPOCH 3 loss ppo:  -0.05592, loss val: 0.33839
[2022-12-07 08:50:44,611] [INFO] [controller] EPOCH 4 loss ppo:  -0.06368, loss val: 0.29645
[2022-12-07 08:50:44,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:50:44,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:50:44,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:50:51,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:50:58,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:51:04,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:51:11,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:51:18,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:51:25,268] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:51:32,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:51:38,650] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:51:45,079] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:51:51,672] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39568505415833366
[2022-12-07 08:51:51,672] [INFO] [runner_train_mujoco] Average state value: 0.17645942240643003
[2022-12-07 08:51:51,672] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:51:51,726] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.31593
[2022-12-07 08:51:51,776] [INFO] [controller] EPOCH 2 loss ppo:  -0.03816, loss val: 0.27966
[2022-12-07 08:51:51,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.05338, loss val: 0.25042
[2022-12-07 08:51:51,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.06210, loss val: 0.21683
[2022-12-07 08:51:51,884] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:51:52,081] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:51:52,082] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:58,652] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:52:05,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:52:11,911] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:52:18,704] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:52:25,106] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:52:31,826] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:52:38,506] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:52:44,995] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:52:51,624] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:52:57,989] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4368934825899749
[2022-12-07 08:52:57,990] [INFO] [runner_train_mujoco] Average state value: 0.3438678722741703
[2022-12-07 08:52:57,990] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:52:58,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.15206
[2022-12-07 08:52:58,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.03788, loss val: 0.13417
[2022-12-07 08:52:58,168] [INFO] [controller] EPOCH 3 loss ppo:  -0.05155, loss val: 0.12247
[2022-12-07 08:52:58,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.05884, loss val: 0.11380
[2022-12-07 08:52:58,229] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:52:58,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:52:58,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:53:05,244] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:53:11,807] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:18,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:25,536] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:53:32,543] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:39,234] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:53:45,754] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:53:52,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:53:58,641] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:54:05,019] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3614152136502936
[2022-12-07 08:54:05,019] [INFO] [runner_train_mujoco] Average state value: 0.4810410465846459
[2022-12-07 08:54:05,019] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:54:05,070] [INFO] [controller] EPOCH 1 loss ppo:  -0.01052, loss val: 0.10807
[2022-12-07 08:54:05,112] [INFO] [controller] EPOCH 2 loss ppo:  -0.03347, loss val: 0.10043
[2022-12-07 08:54:05,156] [INFO] [controller] EPOCH 3 loss ppo:  -0.04290, loss val: 0.09321
[2022-12-07 08:54:05,202] [INFO] [controller] EPOCH 4 loss ppo:  -0.05046, loss val: 0.08853
[2022-12-07 08:54:05,212] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:54:05,402] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:54:05,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:54:12,175] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:54:18,800] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:54:25,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:54:32,332] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:54:39,563] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:54:46,611] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:54:52,940] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:54:59,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:55:05,679] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:55:12,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3533949037025353
[2022-12-07 08:55:12,333] [INFO] [runner_train_mujoco] Average state value: 0.5412836762225876
[2022-12-07 08:55:12,333] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:55:12,389] [INFO] [controller] EPOCH 1 loss ppo:  -0.01077, loss val: 0.08714
[2022-12-07 08:55:12,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.03138, loss val: 0.08200
[2022-12-07 08:55:12,487] [INFO] [controller] EPOCH 3 loss ppo:  -0.04500, loss val: 0.07762
[2022-12-07 08:55:12,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.05183, loss val: 0.07331
[2022-12-07 08:55:12,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:55:12,739] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:55:12,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:55:19,508] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:55:26,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:55:33,533] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:55:39,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:55:46,464] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:55:53,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:59,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:56:06,025] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:56:12,703] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:56:19,694] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21893741445179532
[2022-12-07 08:56:19,694] [INFO] [runner_train_mujoco] Average state value: 0.5320556493314605
[2022-12-07 08:56:19,694] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:56:19,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.06872
[2022-12-07 08:56:19,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.03590, loss val: 0.06572
[2022-12-07 08:56:19,862] [INFO] [controller] EPOCH 3 loss ppo:  -0.04731, loss val: 0.06297
[2022-12-07 08:56:19,915] [INFO] [controller] EPOCH 4 loss ppo:  -0.05645, loss val: 0.06332
[2022-12-07 08:56:19,928] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:56:20,123] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:56:20,123] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:56:27,150] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:56:33,975] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:56:40,805] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:56:47,560] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:56:54,398] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:57:01,088] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:57:07,418] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:57:13,985] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:21,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:27,847] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4672795237287555
[2022-12-07 08:57:27,848] [INFO] [runner_train_mujoco] Average state value: 0.5197639791443944
[2022-12-07 08:57:27,848] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:57:28,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.05516
[2022-12-07 08:57:28,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.03157, loss val: 0.05141
[2022-12-07 08:57:28,278] [INFO] [controller] EPOCH 3 loss ppo:  -0.04431, loss val: 0.05057
[2022-12-07 08:57:28,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.05320, loss val: 0.04931
[2022-12-07 08:57:28,349] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:28,605] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:28,605] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:57:35,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:57:42,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:57:49,209] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:57:55,918] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:58:02,317] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:58:08,530] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:58:15,081] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:21,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:58:27,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:58:34,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6086278657055466
[2022-12-07 08:58:34,331] [INFO] [runner_train_mujoco] Average state value: 0.5406527930299442
[2022-12-07 08:58:34,331] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:58:34,386] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.05838
[2022-12-07 08:58:34,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.03351, loss val: 0.05614
[2022-12-07 08:58:34,480] [INFO] [controller] EPOCH 3 loss ppo:  -0.04417, loss val: 0.05343
[2022-12-07 08:58:34,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.04962, loss val: 0.05072
[2022-12-07 08:58:34,538] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:58:34,733] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:58:34,734] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:58:41,867] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:58:48,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:58:55,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:59:02,497] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:59:09,033] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:59:15,972] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:59:22,657] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:59:28,923] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:59:35,339] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:59:42,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4473575550074056
[2022-12-07 08:59:42,292] [INFO] [runner_train_mujoco] Average state value: 0.5108962724208832
[2022-12-07 08:59:42,292] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:59:42,366] [INFO] [controller] EPOCH 1 loss ppo:  -0.01031, loss val: 0.04424
[2022-12-07 08:59:42,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.03457, loss val: 0.04439
[2022-12-07 08:59:42,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.04759, loss val: 0.04493
[2022-12-07 08:59:42,530] [INFO] [controller] EPOCH 4 loss ppo:  -0.05569, loss val: 0.04307
[2022-12-07 08:59:42,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:59:42,739] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:59:42,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:59:49,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:59:55,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:00:02,541] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:00:09,411] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:00:16,191] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:00:22,595] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:00:29,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:00:36,509] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:00:42,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:00:50,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4449577510319987
[2022-12-07 09:00:50,077] [INFO] [runner_train_mujoco] Average state value: 0.4798533095667759
[2022-12-07 09:00:50,077] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 09:00:50,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.00967, loss val: 0.04444
[2022-12-07 09:00:50,180] [INFO] [controller] EPOCH 2 loss ppo:  -0.03464, loss val: 0.04423
[2022-12-07 09:00:50,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.04774, loss val: 0.04130
[2022-12-07 09:00:50,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.05681, loss val: 0.04235
[2022-12-07 09:00:50,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:00:50,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:00:50,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:00:56,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:01:03,170] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:01:10,122] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:01:16,432] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:01:23,285] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:29,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:36,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:01:43,335] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:01:50,000] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:01:56,890] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.507387460643406
[2022-12-07 09:01:56,890] [INFO] [runner_train_mujoco] Average state value: 0.4736847676336765
[2022-12-07 09:01:56,890] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 09:01:56,949] [INFO] [controller] EPOCH 1 loss ppo:  -0.00966, loss val: 0.04293
[2022-12-07 09:01:56,996] [INFO] [controller] EPOCH 2 loss ppo:  -0.03539, loss val: 0.03913
[2022-12-07 09:01:57,297] [INFO] [controller] EPOCH 3 loss ppo:  -0.04741, loss val: 0.03820
[2022-12-07 09:01:57,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.05624, loss val: 0.03846
[2022-12-07 09:01:57,381] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:01:57,570] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:01:57,571] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:04,357] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:02:11,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:02:18,183] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:02:25,091] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:02:31,714] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:02:38,603] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:02:44,794] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:02:51,675] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:02:58,172] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:04,646] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42524788616273135
[2022-12-07 09:03:04,647] [INFO] [runner_train_mujoco] Average state value: 0.4459997129390637
[2022-12-07 09:03:04,647] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 09:03:04,709] [INFO] [controller] EPOCH 1 loss ppo:  -0.01137, loss val: 0.04770
[2022-12-07 09:03:04,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.02648, loss val: 0.04060
[2022-12-07 09:03:04,884] [INFO] [controller] EPOCH 3 loss ppo:  -0.03885, loss val: 0.03706
[2022-12-07 09:03:04,934] [INFO] [controller] EPOCH 4 loss ppo:  -0.04947, loss val: 0.03323
[2022-12-07 09:03:04,943] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:03:05,134] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:03:05,135] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:03:11,922] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:03:18,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:03:25,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:03:32,013] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:03:38,635] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:03:45,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:03:52,055] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:03:58,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:04:05,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:04:12,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5837045102641422
[2022-12-07 09:04:12,381] [INFO] [runner_train_mujoco] Average state value: 0.3664840483951072
[2022-12-07 09:04:12,381] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 09:04:12,433] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.07219
[2022-12-07 09:04:12,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.02705, loss val: 0.07271
[2022-12-07 09:04:12,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.03743, loss val: 0.07325
[2022-12-07 09:04:12,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.04773, loss val: 0.06794
[2022-12-07 09:04:12,586] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:04:12,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:04:12,776] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:04:19,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:04:25,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:04:32,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:04:38,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:04:44,783] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:04:51,155] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:04:57,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:05:03,070] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:05:08,992] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:05:14,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5621899793846756
[2022-12-07 09:05:14,778] [INFO] [runner_train_mujoco] Average state value: 0.3824750194400549
[2022-12-07 09:05:14,778] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 09:05:14,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.03867
[2022-12-07 09:05:14,873] [INFO] [controller] EPOCH 2 loss ppo:  -0.03856, loss val: 0.03621
[2022-12-07 09:05:14,912] [INFO] [controller] EPOCH 3 loss ppo:  -0.05343, loss val: 0.03447
[2022-12-07 09:05:14,953] [INFO] [controller] EPOCH 4 loss ppo:  -0.06097, loss val: 0.03602
[2022-12-07 09:05:14,963] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:05:15,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:05:15,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:05:21,026] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:05:26,709] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:32,649] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:38,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:05:45,272] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:05:51,476] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:05:57,315] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:06:02,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:06:08,527] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:06:14,204] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5383060030906137
[2022-12-07 09:06:14,205] [INFO] [runner_train_mujoco] Average state value: 0.4558290506501993
[2022-12-07 09:06:14,205] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 09:06:14,257] [INFO] [controller] EPOCH 1 loss ppo:  -0.01198, loss val: 0.03765
[2022-12-07 09:06:14,298] [INFO] [controller] EPOCH 2 loss ppo:  -0.03397, loss val: 0.03573
[2022-12-07 09:06:14,339] [INFO] [controller] EPOCH 3 loss ppo:  -0.04692, loss val: 0.03648
[2022-12-07 09:06:14,379] [INFO] [controller] EPOCH 4 loss ppo:  -0.05605, loss val: 0.03782
[2022-12-07 09:06:14,385] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:06:14,589] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:06:14,589] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:06:20,629] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:06:26,515] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:06:32,836] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:06:38,611] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:06:44,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:06:50,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:06:56,051] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:07:01,798] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:07:08,754] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:07:15,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6706067066510693
[2022-12-07 09:07:15,070] [INFO] [runner_train_mujoco] Average state value: 0.4827053260505199
[2022-12-07 09:07:15,070] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 09:07:15,128] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.05082
[2022-12-07 09:07:15,184] [INFO] [controller] EPOCH 2 loss ppo:  -0.03222, loss val: 0.04865
[2022-12-07 09:07:15,231] [INFO] [controller] EPOCH 3 loss ppo:  -0.04467, loss val: 0.04649
[2022-12-07 09:07:15,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.05497, loss val: 0.04252
[2022-12-07 09:07:15,289] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:07:15,489] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:07:15,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:07:22,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:07:28,761] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:07:34,805] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:07:40,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:07:46,412] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:07:52,745] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:07:58,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:08:04,182] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:08:10,153] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:08:15,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1823124649184769
[2022-12-07 09:08:15,696] [INFO] [runner_train_mujoco] Average state value: 0.5357579320569833
[2022-12-07 09:08:15,696] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 09:08:15,747] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03771
[2022-12-07 09:08:15,789] [INFO] [controller] EPOCH 2 loss ppo:  -0.03680, loss val: 0.03626
[2022-12-07 09:08:15,836] [INFO] [controller] EPOCH 3 loss ppo:  -0.04749, loss val: 0.03683
[2022-12-07 09:08:15,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.05762, loss val: 0.03782
[2022-12-07 09:08:15,887] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:08:16,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:08:16,061] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:08:22,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:08:28,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:08:34,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:08:39,758] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:08:45,717] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:08:51,741] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:08:57,144] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:09:03,506] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:09:09,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:09:15,121] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2227011165575319
[2022-12-07 09:09:15,121] [INFO] [runner_train_mujoco] Average state value: 0.5868241438865661
[2022-12-07 09:09:15,121] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 09:09:15,179] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.04276
[2022-12-07 09:09:15,221] [INFO] [controller] EPOCH 2 loss ppo:  -0.03361, loss val: 0.04201
[2022-12-07 09:09:15,264] [INFO] [controller] EPOCH 3 loss ppo:  -0.04369, loss val: 0.04412
[2022-12-07 09:09:15,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.05496, loss val: 0.04195
[2022-12-07 09:09:15,320] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:09:15,510] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:09:15,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:09:21,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:09:26,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:09:33,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:09:39,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:09:44,919] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:09:50,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:09:57,529] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:10:03,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:10:08,941] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:10:14,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2322337498963405
[2022-12-07 09:10:14,784] [INFO] [runner_train_mujoco] Average state value: 0.5803392577966054
[2022-12-07 09:10:14,784] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 09:10:14,841] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.05002
[2022-12-07 09:10:14,885] [INFO] [controller] EPOCH 2 loss ppo:  -0.02960, loss val: 0.04887
[2022-12-07 09:10:14,931] [INFO] [controller] EPOCH 3 loss ppo:  -0.03879, loss val: 0.04822
[2022-12-07 09:10:14,975] [INFO] [controller] EPOCH 4 loss ppo:  -0.04935, loss val: 0.04185
[2022-12-07 09:10:14,984] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:10:15,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:10:15,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:10:21,141] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:10:27,328] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:10:33,250] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:10:38,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:10:44,721] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:10:50,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:10:56,376] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:11:02,299] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:11:08,565] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:11:14,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3891865792256088
[2022-12-07 09:11:14,017] [INFO] [runner_train_mujoco] Average state value: 0.5240433137814204
[2022-12-07 09:11:14,017] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 09:11:14,068] [INFO] [controller] EPOCH 1 loss ppo:  -0.01581, loss val: 0.03762
[2022-12-07 09:11:14,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.04000, loss val: 0.03917
[2022-12-07 09:11:14,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.05320, loss val: 0.03869
[2022-12-07 09:11:14,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.05906, loss val: 0.03755
[2022-12-07 09:11:14,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:11:14,644] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:11:14,645] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:11:20,352] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:11:25,851] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:11:31,766] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:11:37,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:11:43,476] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:11:49,289] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:11:55,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:12:01,196] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:12:06,932] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:12:12,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0058332803675816
[2022-12-07 09:12:12,190] [INFO] [runner_train_mujoco] Average state value: 0.46372018974026047
[2022-12-07 09:12:12,190] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 09:12:12,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.04728
[2022-12-07 09:12:12,277] [INFO] [controller] EPOCH 2 loss ppo:  -0.03481, loss val: 0.04829
[2022-12-07 09:12:12,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.04947, loss val: 0.04581
[2022-12-07 09:12:12,358] [INFO] [controller] EPOCH 4 loss ppo:  -0.06136, loss val: 0.04459
[2022-12-07 09:12:12,367] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:12:12,565] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:12:12,565] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:12:18,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:12:25,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:12:31,032] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:12:36,656] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:12:42,763] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:12:48,180] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:12:54,171] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:12:59,682] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:13:05,217] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:11,251] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9746152908801016
[2022-12-07 09:13:11,252] [INFO] [runner_train_mujoco] Average state value: 0.4943428378204505
[2022-12-07 09:13:11,252] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 09:13:11,313] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.03136
[2022-12-07 09:13:11,356] [INFO] [controller] EPOCH 2 loss ppo:  -0.03730, loss val: 0.03163
[2022-12-07 09:13:11,397] [INFO] [controller] EPOCH 3 loss ppo:  -0.04826, loss val: 0.03360
[2022-12-07 09:13:11,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.05953, loss val: 0.03164
[2022-12-07 09:13:11,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:11,627] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:11,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:13:17,697] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:13:24,060] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:13:30,167] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:13:35,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:13:41,611] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:13:47,540] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:13:53,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:13:59,496] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:14:05,100] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:14:11,153] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.891493665739361
[2022-12-07 09:14:11,153] [INFO] [runner_train_mujoco] Average state value: 0.5231474772940079
[2022-12-07 09:14:11,154] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 09:14:11,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01538, loss val: 0.04322
[2022-12-07 09:14:11,256] [INFO] [controller] EPOCH 2 loss ppo:  -0.03452, loss val: 0.04174
[2022-12-07 09:14:11,300] [INFO] [controller] EPOCH 3 loss ppo:  -0.04651, loss val: 0.03984
[2022-12-07 09:14:11,350] [INFO] [controller] EPOCH 4 loss ppo:  -0.05822, loss val: 0.03905
[2022-12-07 09:14:11,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:14:11,544] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:14:11,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:14:17,321] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:14:23,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:14:28,960] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:14:34,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:14:40,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:14:46,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:14:52,815] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:14:58,529] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:15:04,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:15:10,406] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1829445733883626
[2022-12-07 09:15:10,407] [INFO] [runner_train_mujoco] Average state value: 0.509664111673832
[2022-12-07 09:15:10,407] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 09:15:10,464] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.03737
[2022-12-07 09:15:10,505] [INFO] [controller] EPOCH 2 loss ppo:  -0.03053, loss val: 0.03638
[2022-12-07 09:15:10,548] [INFO] [controller] EPOCH 3 loss ppo:  -0.04511, loss val: 0.03636
[2022-12-07 09:15:10,595] [INFO] [controller] EPOCH 4 loss ppo:  -0.05835, loss val: 0.03752
[2022-12-07 09:15:10,604] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:15:10,782] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:15:10,783] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:15:16,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:15:21,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:15:27,453] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:33,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:15:39,180] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:15:44,722] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:15:50,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:15:57,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:16:02,568] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:16:08,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2180664495002587
[2022-12-07 09:16:08,028] [INFO] [runner_train_mujoco] Average state value: 0.5044516160885493
[2022-12-07 09:16:08,028] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 09:16:08,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03228
[2022-12-07 09:16:08,125] [INFO] [controller] EPOCH 2 loss ppo:  -0.03319, loss val: 0.03152
[2022-12-07 09:16:08,237] [INFO] [controller] EPOCH 3 loss ppo:  -0.04182, loss val: 0.03411
[2022-12-07 09:16:08,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.05507, loss val: 0.03433
[2022-12-07 09:16:08,288] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:16:08,456] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:16:08,457] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:16:14,071] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:16:20,120] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:16:26,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:16:32,084] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:16:37,546] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:16:43,559] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:16:48,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:16:54,715] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:17:00,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:17:06,039] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6175467273717468
[2022-12-07 09:17:06,040] [INFO] [runner_train_mujoco] Average state value: 0.5216489289999008
[2022-12-07 09:17:06,040] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 09:17:06,099] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.03221
[2022-12-07 09:17:06,149] [INFO] [controller] EPOCH 2 loss ppo:  -0.03421, loss val: 0.03080
[2022-12-07 09:17:06,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.04719, loss val: 0.03039
[2022-12-07 09:17:06,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.05803, loss val: 0.02938
[2022-12-07 09:17:06,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:17:06,425] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:17:06,425] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:17:12,500] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:17:18,208] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:17:24,229] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:17:30,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:17:36,089] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:17:41,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:17:46,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:17:52,305] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:17:57,937] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:18:03,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5707479815370866
[2022-12-07 09:18:03,824] [INFO] [runner_train_mujoco] Average state value: 0.4842177470525105
[2022-12-07 09:18:03,824] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 09:18:03,882] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04476
[2022-12-07 09:18:03,933] [INFO] [controller] EPOCH 2 loss ppo:  -0.03060, loss val: 0.04436
[2022-12-07 09:18:04,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.04265, loss val: 0.04721
[2022-12-07 09:18:04,121] [INFO] [controller] EPOCH 4 loss ppo:  -0.05748, loss val: 0.04507
[2022-12-07 09:18:04,129] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:18:04,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:18:04,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:18:10,045] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:18:15,454] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:18:21,540] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:18:26,816] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:18:33,026] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:18:38,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:44,658] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:18:50,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:18:55,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:19:01,289] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5760719294177945
[2022-12-07 09:19:01,290] [INFO] [runner_train_mujoco] Average state value: 0.47625089964518946
[2022-12-07 09:19:01,290] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 09:19:01,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.04406
[2022-12-07 09:19:01,379] [INFO] [controller] EPOCH 2 loss ppo:  -0.02926, loss val: 0.04582
[2022-12-07 09:19:01,421] [INFO] [controller] EPOCH 3 loss ppo:  -0.03862, loss val: 0.04015
[2022-12-07 09:19:01,457] [INFO] [controller] EPOCH 4 loss ppo:  -0.04806, loss val: 0.03386
[2022-12-07 09:19:01,467] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:19:01,640] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:19:01,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:19:07,804] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:19:13,898] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:19:19,840] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:19:26,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:19:31,777] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:19:37,436] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:19:43,166] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:19:49,213] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:19:54,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:20:00,998] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1028888807272588
[2022-12-07 09:20:00,998] [INFO] [runner_train_mujoco] Average state value: 0.5396595538457234
[2022-12-07 09:20:00,998] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 09:20:01,055] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.04858
[2022-12-07 09:20:01,098] [INFO] [controller] EPOCH 2 loss ppo:  -0.03379, loss val: 0.04711
[2022-12-07 09:20:01,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.04034, loss val: 0.04831
[2022-12-07 09:20:01,184] [INFO] [controller] EPOCH 4 loss ppo:  -0.05286, loss val: 0.04842
[2022-12-07 09:20:01,193] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:20:01,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:20:01,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:20:07,177] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:20:12,759] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:20:18,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:20:24,502] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:20:29,933] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:20:35,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:20:41,292] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:20:47,132] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:20:52,649] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:20:58,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.144708930721298
[2022-12-07 09:20:58,590] [INFO] [runner_train_mujoco] Average state value: 0.5761640039483706
[2022-12-07 09:20:58,591] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 09:20:58,641] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.05671
[2022-12-07 09:20:58,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.02668, loss val: 0.05927
[2022-12-07 09:20:58,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.03888, loss val: 0.05583
[2022-12-07 09:20:58,766] [INFO] [controller] EPOCH 4 loss ppo:  -0.05452, loss val: 0.05267
[2022-12-07 09:20:58,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:20:58,961] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:20:58,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:21:04,443] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:21:09,862] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:21:15,865] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:21:21,570] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:21:27,320] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:21:32,772] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:21:38,623] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:21:43,826] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:21:49,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:21:55,245] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.211907377529047
[2022-12-07 09:21:55,245] [INFO] [runner_train_mujoco] Average state value: 0.5253781735872228
[2022-12-07 09:21:55,245] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 09:21:55,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04446
[2022-12-07 09:21:55,344] [INFO] [controller] EPOCH 2 loss ppo:  -0.03109, loss val: 0.04460
[2022-12-07 09:21:55,399] [INFO] [controller] EPOCH 3 loss ppo:  -0.04383, loss val: 0.04370
[2022-12-07 09:21:55,451] [INFO] [controller] EPOCH 4 loss ppo:  -0.05574, loss val: 0.04462
[2022-12-07 09:21:55,461] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:21:55,670] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:21:55,670] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:22:01,394] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:22:07,182] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:22:13,249] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:22:18,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:22:24,738] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:22:30,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:22:36,711] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:22:42,420] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:22:48,053] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:22:53,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3397206233741543
[2022-12-07 09:22:53,751] [INFO] [runner_train_mujoco] Average state value: 0.46749403039614357
[2022-12-07 09:22:53,751] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 09:22:53,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04254
[2022-12-07 09:22:53,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.02390, loss val: 0.04330
[2022-12-07 09:22:53,896] [INFO] [controller] EPOCH 3 loss ppo:  -0.03611, loss val: 0.04369
[2022-12-07 09:22:53,991] [INFO] [controller] EPOCH 4 loss ppo:  -0.04978, loss val: 0.04051
[2022-12-07 09:22:54,001] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:22:54,193] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:22:54,205] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:00,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:23:05,485] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:23:11,450] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:23:17,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:23:23,166] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:23:28,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:23:34,428] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:23:40,131] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:23:45,780] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:23:51,516] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5666507353538863
[2022-12-07 09:23:51,516] [INFO] [runner_train_mujoco] Average state value: 0.4656470764378707
[2022-12-07 09:23:51,516] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 09:23:51,633] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.03713
[2022-12-07 09:23:51,682] [INFO] [controller] EPOCH 2 loss ppo:  -0.02903, loss val: 0.03431
[2022-12-07 09:23:51,725] [INFO] [controller] EPOCH 3 loss ppo:  -0.04100, loss val: 0.03324
[2022-12-07 09:23:51,774] [INFO] [controller] EPOCH 4 loss ppo:  -0.05044, loss val: 0.03259
[2022-12-07 09:23:51,790] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:23:51,997] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:23:51,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:58,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:24:04,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:24:10,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:24:15,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:24:21,257] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:24:26,944] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:24:32,313] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:24:38,335] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:24:44,155] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:24:49,740] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4371658922127644
[2022-12-07 09:24:49,740] [INFO] [runner_train_mujoco] Average state value: 0.499215836207072
[2022-12-07 09:24:49,740] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 09:24:49,802] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04032
[2022-12-07 09:24:49,851] [INFO] [controller] EPOCH 2 loss ppo:  -0.02673, loss val: 0.03487
[2022-12-07 09:24:49,898] [INFO] [controller] EPOCH 3 loss ppo:  -0.03990, loss val: 0.03482
[2022-12-07 09:24:49,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.05277, loss val: 0.03455
[2022-12-07 09:24:49,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:24:50,141] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:24:50,141] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:24:55,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:25:01,270] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:25:07,419] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:25:12,775] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:25:18,585] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:25:24,531] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:25:30,080] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:25:35,149] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:25:40,765] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:25:46,076] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.889318358402727
[2022-12-07 09:25:46,076] [INFO] [runner_train_mujoco] Average state value: 0.5470268641710281
[2022-12-07 09:25:46,076] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 09:25:46,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01560, loss val: 0.04761
[2022-12-07 09:25:46,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.02925, loss val: 0.04947
[2022-12-07 09:25:46,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.03619, loss val: 0.04758
[2022-12-07 09:25:46,432] [INFO] [controller] EPOCH 4 loss ppo:  -0.04913, loss val: 0.04636
[2022-12-07 09:25:46,442] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:25:46,624] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:25:46,624] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:25:52,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:25:58,038] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:26:04,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:26:10,043] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:26:15,815] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:26:21,569] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:26:26,995] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:26:32,458] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:26:38,167] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:44,215] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.627725600789288
[2022-12-07 09:26:44,215] [INFO] [runner_train_mujoco] Average state value: 0.4517912798374891
[2022-12-07 09:26:44,215] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 09:26:44,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.09539
[2022-12-07 09:26:44,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.02611, loss val: 0.09565
[2022-12-07 09:26:44,382] [INFO] [controller] EPOCH 3 loss ppo:  -0.03586, loss val: 0.09259
[2022-12-07 09:26:44,430] [INFO] [controller] EPOCH 4 loss ppo:  -0.04805, loss val: 0.09095
[2022-12-07 09:26:44,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:44,603] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:44,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:26:50,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:26:56,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:02,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:27:07,818] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:27:13,658] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:27:19,317] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:27:24,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:27:30,394] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:27:35,872] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:27:41,103] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.004988515674007
[2022-12-07 09:27:41,103] [INFO] [runner_train_mujoco] Average state value: 0.5048888202706974
[2022-12-07 09:27:41,104] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 09:27:41,154] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04170
[2022-12-07 09:27:41,195] [INFO] [controller] EPOCH 2 loss ppo:  -0.02613, loss val: 0.04393
[2022-12-07 09:27:41,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.03483, loss val: 0.04107
[2022-12-07 09:27:41,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.04796, loss val: 0.04091
[2022-12-07 09:27:41,280] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:27:41,460] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:27:41,461] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:27:47,255] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:27:53,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:59,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:28:05,284] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:28:10,698] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:28:16,399] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:28:21,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:28:27,305] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:28:33,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:28:38,737] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9210099699927206
[2022-12-07 09:28:38,737] [INFO] [runner_train_mujoco] Average state value: 0.5106464528143406
[2022-12-07 09:28:38,737] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 09:28:38,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.04204
[2022-12-07 09:28:38,832] [INFO] [controller] EPOCH 2 loss ppo:  -0.02801, loss val: 0.03807
[2022-12-07 09:28:38,873] [INFO] [controller] EPOCH 3 loss ppo:  -0.03823, loss val: 0.03808
[2022-12-07 09:28:38,914] [INFO] [controller] EPOCH 4 loss ppo:  -0.04735, loss val: 0.03901
[2022-12-07 09:28:38,923] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:28:39,100] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:28:39,101] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:28:44,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:28:51,037] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:28:56,936] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:02,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:29:08,241] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:29:13,681] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:29:19,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:25,042] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:29:30,947] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:29:36,605] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.810253986288798
[2022-12-07 09:29:36,605] [INFO] [runner_train_mujoco] Average state value: 0.47293283995985985
[2022-12-07 09:29:36,605] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 09:29:36,678] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.08465
[2022-12-07 09:29:36,733] [INFO] [controller] EPOCH 2 loss ppo:  -0.02773, loss val: 0.07555
[2022-12-07 09:29:36,775] [INFO] [controller] EPOCH 3 loss ppo:  -0.04133, loss val: 0.07482
[2022-12-07 09:29:36,821] [INFO] [controller] EPOCH 4 loss ppo:  -0.05069, loss val: 0.08096
[2022-12-07 09:29:36,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:29:37,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:29:37,006] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:29:42,456] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:29:48,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:29:53,504] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:59,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:30:04,729] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:30:10,891] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:30:16,641] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:30:22,212] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:27,625] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:33,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.754813487395667
[2022-12-07 09:30:33,046] [INFO] [runner_train_mujoco] Average state value: 0.44656001927082734
[2022-12-07 09:30:33,046] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 09:30:33,094] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.10764
[2022-12-07 09:30:33,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.02657, loss val: 0.10594
[2022-12-07 09:30:33,178] [INFO] [controller] EPOCH 3 loss ppo:  -0.03373, loss val: 0.10405
[2022-12-07 09:30:33,217] [INFO] [controller] EPOCH 4 loss ppo:  -0.04177, loss val: 0.10336
[2022-12-07 09:30:33,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:33,415] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:33,416] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:38,864] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:30:44,458] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:30:50,000] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:30:55,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:31:01,787] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:31:07,432] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:31:13,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:31:18,743] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:31:24,456] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:31:30,058] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0609654290065365
[2022-12-07 09:31:30,059] [INFO] [runner_train_mujoco] Average state value: 0.5507402787307898
[2022-12-07 09:31:30,059] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 09:31:30,114] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.03461
[2022-12-07 09:31:30,155] [INFO] [controller] EPOCH 2 loss ppo:  -0.02887, loss val: 0.03415
[2022-12-07 09:31:30,198] [INFO] [controller] EPOCH 3 loss ppo:  -0.04436, loss val: 0.03342
[2022-12-07 09:31:30,242] [INFO] [controller] EPOCH 4 loss ppo:  -0.05254, loss val: 0.03689
[2022-12-07 09:31:30,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:31:30,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:31:30,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:31:36,523] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:31:42,469] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:31:48,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:31:54,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:31:59,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:32:05,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:32:11,053] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:32:17,109] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:32:22,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:32:28,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.1582263258826275
[2022-12-07 09:32:28,117] [INFO] [runner_train_mujoco] Average state value: 0.5270743059168259
[2022-12-07 09:32:28,117] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 09:32:28,171] [INFO] [controller] EPOCH 1 loss ppo:  -0.01566, loss val: 0.07384
[2022-12-07 09:32:28,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.02949, loss val: 0.07194
[2022-12-07 09:32:28,262] [INFO] [controller] EPOCH 3 loss ppo:  -0.03861, loss val: 0.07143
[2022-12-07 09:32:28,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.04463, loss val: 0.07251
[2022-12-07 09:32:28,315] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:32:28,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:32:28,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:32:34,418] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:32:40,349] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:32:45,655] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:32:51,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:32:56,880] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:33:03,165] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:33:10,655] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:33:15,959] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:33:21,504] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:33:27,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.32785732709692
[2022-12-07 09:33:27,231] [INFO] [runner_train_mujoco] Average state value: 0.5300650438716014
[2022-12-07 09:33:27,231] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 09:33:27,539] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.05056
[2022-12-07 09:33:27,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.02744, loss val: 0.05097
[2022-12-07 09:33:27,656] [INFO] [controller] EPOCH 3 loss ppo:  -0.03758, loss val: 0.05089
[2022-12-07 09:33:27,708] [INFO] [controller] EPOCH 4 loss ppo:  -0.04880, loss val: 0.05066
[2022-12-07 09:33:27,718] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:33:27,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:33:27,921] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:33:33,767] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:33:39,223] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:33:46,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:33:51,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:33:57,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:34:02,443] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:34:08,107] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:34:13,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:34:18,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:34:24,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.086484530920131
[2022-12-07 09:34:24,098] [INFO] [runner_train_mujoco] Average state value: 0.5418643081684907
[2022-12-07 09:34:24,098] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 09:34:24,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04966
[2022-12-07 09:34:24,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.02137, loss val: 0.04948
[2022-12-07 09:34:24,254] [INFO] [controller] EPOCH 3 loss ppo:  -0.03014, loss val: 0.04857
[2022-12-07 09:34:24,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.03924, loss val: 0.04776
[2022-12-07 09:34:24,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:34:24,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:34:24,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:34:30,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:34:35,961] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:34:41,089] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:34:46,690] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:34:52,547] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:34:58,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:35:03,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:35:09,355] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:35:14,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:35:19,737] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.15370718517505
[2022-12-07 09:35:19,737] [INFO] [runner_train_mujoco] Average state value: 0.5180687653298179
[2022-12-07 09:35:19,737] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 09:35:19,786] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.04337
[2022-12-07 09:35:19,827] [INFO] [controller] EPOCH 2 loss ppo:  -0.02468, loss val: 0.04365
[2022-12-07 09:35:19,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.03364, loss val: 0.04301
[2022-12-07 09:35:19,909] [INFO] [controller] EPOCH 4 loss ppo:  -0.04246, loss val: 0.04348
[2022-12-07 09:35:19,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:35:20,084] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:35:20,084] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:35:25,530] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:35:30,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:35:36,351] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:35:41,863] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:35:47,961] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:35:53,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:35:59,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:36:04,395] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:36:10,115] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:36:15,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.555225141185834
[2022-12-07 09:36:15,291] [INFO] [runner_train_mujoco] Average state value: 0.5106391501426698
[2022-12-07 09:36:15,292] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 09:36:15,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.05153
[2022-12-07 09:36:15,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.02130, loss val: 0.05093
[2022-12-07 09:36:15,491] [INFO] [controller] EPOCH 3 loss ppo:  -0.03145, loss val: 0.05040
[2022-12-07 09:36:15,537] [INFO] [controller] EPOCH 4 loss ppo:  -0.04133, loss val: 0.04981
[2022-12-07 09:36:15,547] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:36:15,761] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:36:15,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:36:21,685] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:36:27,113] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:36:32,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:36:38,457] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:36:43,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:36:48,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:36:53,918] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:36:59,134] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:37:05,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:37:10,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.008689572734763
[2022-12-07 09:37:10,913] [INFO] [runner_train_mujoco] Average state value: 0.47127288830031955
[2022-12-07 09:37:10,913] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 09:37:10,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.08423
[2022-12-07 09:37:11,011] [INFO] [controller] EPOCH 2 loss ppo:  -0.01986, loss val: 0.08576
[2022-12-07 09:37:11,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.02557, loss val: 0.08507
[2022-12-07 09:37:11,103] [INFO] [controller] EPOCH 4 loss ppo:  -0.03113, loss val: 0.08214
[2022-12-07 09:37:11,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:37:11,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:37:11,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:37:17,325] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:37:22,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:37:28,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:37:33,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:37:39,494] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:37:44,829] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:37:50,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:37:55,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:38:00,864] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:38:07,185] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.3902713557916915
[2022-12-07 09:38:07,186] [INFO] [runner_train_mujoco] Average state value: 0.4956735130151113
[2022-12-07 09:38:07,186] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 09:38:07,255] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.03775
[2022-12-07 09:38:07,303] [INFO] [controller] EPOCH 2 loss ppo:  -0.02367, loss val: 0.03736
[2022-12-07 09:38:07,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.03112, loss val: 0.03764
[2022-12-07 09:38:07,426] [INFO] [controller] EPOCH 4 loss ppo:  -0.03826, loss val: 0.03862
[2022-12-07 09:38:07,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:38:07,635] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:38:07,635] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:38:13,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:38:18,456] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:38:24,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:38:29,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:38:35,421] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:38:42,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:38:48,012] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:38:53,868] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:38:59,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:39:04,682] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.181301915241925
[2022-12-07 09:39:04,682] [INFO] [runner_train_mujoco] Average state value: 0.5082368289319177
[2022-12-07 09:39:04,682] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 09:39:04,740] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04947
[2022-12-07 09:39:04,785] [INFO] [controller] EPOCH 2 loss ppo:  -0.02123, loss val: 0.04867
[2022-12-07 09:39:04,827] [INFO] [controller] EPOCH 3 loss ppo:  -0.03035, loss val: 0.04700
[2022-12-07 09:39:04,872] [INFO] [controller] EPOCH 4 loss ppo:  -0.03711, loss val: 0.04565
[2022-12-07 09:39:04,882] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:39:05,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:39:05,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:39:10,555] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:39:16,221] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:39:21,268] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:39:26,578] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:39:31,798] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:39:37,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:39:42,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:39:47,941] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:39:53,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:39:59,301] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.365727038095316
[2022-12-07 09:39:59,301] [INFO] [runner_train_mujoco] Average state value: 0.47781933970128493
[2022-12-07 09:39:59,301] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 09:39:59,350] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.07710
[2022-12-07 09:39:59,393] [INFO] [controller] EPOCH 2 loss ppo:  -0.02337, loss val: 0.07681
[2022-12-07 09:39:59,435] [INFO] [controller] EPOCH 3 loss ppo:  -0.03239, loss val: 0.07788
[2022-12-07 09:39:59,477] [INFO] [controller] EPOCH 4 loss ppo:  -0.03927, loss val: 0.07685
[2022-12-07 09:39:59,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:39:59,672] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:39:59,672] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:40:05,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:40:11,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:40:16,856] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:40:22,597] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:40:28,521] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:40:34,222] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:40:39,742] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:40:51,345] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:41:02,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:41:10,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.805041699852729
[2022-12-07 09:41:10,635] [INFO] [runner_train_mujoco] Average state value: 0.54821861160174
[2022-12-07 09:41:10,635] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 09:41:10,692] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.04668
[2022-12-07 09:41:10,739] [INFO] [controller] EPOCH 2 loss ppo:  -0.01868, loss val: 0.04602
[2022-12-07 09:41:10,782] [INFO] [controller] EPOCH 3 loss ppo:  -0.02803, loss val: 0.04608
[2022-12-07 09:41:10,826] [INFO] [controller] EPOCH 4 loss ppo:  -0.03533, loss val: 0.04596
[2022-12-07 09:41:10,838] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:41:11,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:41:11,021] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:41:17,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:41:24,097] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:41:30,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:41:37,435] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:41:45,636] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:41:51,658] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:41:57,958] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:42:04,394] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:42:10,586] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:42:16,119] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.68074662437492
[2022-12-07 09:42:16,119] [INFO] [runner_train_mujoco] Average state value: 0.575740238547325
[2022-12-07 09:42:16,119] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 09:42:16,172] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.05141
[2022-12-07 09:42:16,225] [INFO] [controller] EPOCH 2 loss ppo:  -0.01945, loss val: 0.05141
[2022-12-07 09:42:16,274] [INFO] [controller] EPOCH 3 loss ppo:  -0.02723, loss val: 0.05121
[2022-12-07 09:42:16,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.03288, loss val: 0.05093
[2022-12-07 09:42:16,331] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:42:16,530] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:42:16,532] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:42:23,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:42:30,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:42:35,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:42:42,343] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:42:51,764] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:42:59,746] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:43:08,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:43:14,406] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:43:21,046] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:43:30,607] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.486913902153264
[2022-12-07 09:43:30,607] [INFO] [runner_train_mujoco] Average state value: 0.558424904572467
[2022-12-07 09:43:30,607] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 09:43:30,834] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.04947
[2022-12-07 09:43:30,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.01747, loss val: 0.04957
[2022-12-07 09:43:30,979] [INFO] [controller] EPOCH 3 loss ppo:  -0.02532, loss val: 0.04872
[2022-12-07 09:43:31,075] [INFO] [controller] EPOCH 4 loss ppo:  -0.03316, loss val: 0.04874
[2022-12-07 09:43:31,088] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:43:31,325] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:43:31,326] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:43:40,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:43:48,735] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:43:59,373] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:44:10,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:44:19,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:44:27,003] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:44:33,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:44:39,178] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:44:46,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:44:52,458] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.797277386745458
[2022-12-07 09:44:52,458] [INFO] [runner_train_mujoco] Average state value: 0.555741280257702
[2022-12-07 09:44:52,458] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 09:44:52,515] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.05289
[2022-12-07 09:44:52,564] [INFO] [controller] EPOCH 2 loss ppo:  -0.02028, loss val: 0.05286
[2022-12-07 09:44:52,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.02687, loss val: 0.05283
[2022-12-07 09:44:52,680] [INFO] [controller] EPOCH 4 loss ppo:  -0.03003, loss val: 0.05022
[2022-12-07 09:44:52,691] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:44:52,921] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:44:52,922] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:45:00,086] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:45:07,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:45:13,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:45:19,977] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:45:29,491] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:45:36,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:45:43,830] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:45:50,341] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:45:57,208] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:46:03,469] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.767918832111441
[2022-12-07 09:46:03,469] [INFO] [runner_train_mujoco] Average state value: 0.5234133460049828
[2022-12-07 09:46:03,469] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 09:46:03,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.04031
[2022-12-07 09:46:03,573] [INFO] [controller] EPOCH 2 loss ppo:  -0.01825, loss val: 0.04055
[2022-12-07 09:46:03,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.02523, loss val: 0.04054
[2022-12-07 09:46:03,668] [INFO] [controller] EPOCH 4 loss ppo:  -0.03104, loss val: 0.04081
[2022-12-07 09:46:03,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:46:03,885] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:46:03,885] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:46:10,012] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:46:16,046] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:46:22,077] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:46:29,842] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:46:37,573] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:46:44,204] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:46:50,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:46:56,278] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:47:02,366] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:47:08,383] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.986211063342666
[2022-12-07 09:47:08,383] [INFO] [runner_train_mujoco] Average state value: 0.5319847282369932
[2022-12-07 09:47:08,383] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 09:47:08,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.05470
[2022-12-07 09:47:08,495] [INFO] [controller] EPOCH 2 loss ppo:  -0.01655, loss val: 0.05314
[2022-12-07 09:47:08,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.02077, loss val: 0.05244
[2022-12-07 09:47:08,586] [INFO] [controller] EPOCH 4 loss ppo:  -0.02638, loss val: 0.05210
[2022-12-07 09:47:08,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:47:08,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:47:08,790] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:47:14,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:47:20,549] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:47:25,940] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:47:32,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:47:38,268] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:47:44,018] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:47:49,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:47:56,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:48:02,613] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:48:08,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.071416334818025
[2022-12-07 09:48:08,416] [INFO] [runner_train_mujoco] Average state value: 0.5019744726109008
[2022-12-07 09:48:08,416] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 09:48:08,480] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04843
[2022-12-07 09:48:08,528] [INFO] [controller] EPOCH 2 loss ppo:  -0.01600, loss val: 0.04856
[2022-12-07 09:48:08,568] [INFO] [controller] EPOCH 3 loss ppo:  -0.01948, loss val: 0.05329
[2022-12-07 09:48:08,614] [INFO] [controller] EPOCH 4 loss ppo:  -0.02409, loss val: 0.04831
[2022-12-07 09:48:08,624] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:48:08,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:48:08,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:48:15,061] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:48:20,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:48:26,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:48:32,607] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:48:38,115] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:48:43,474] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:48:48,463] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:48:53,952] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:48:59,570] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:49:05,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0380187135967445
[2022-12-07 09:49:05,165] [INFO] [runner_train_mujoco] Average state value: 0.5146268426875273
[2022-12-07 09:49:05,165] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 09:49:05,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.04570
[2022-12-07 09:49:05,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.01365, loss val: 0.04334
[2022-12-07 09:49:05,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.01444, loss val: 0.04457
[2022-12-07 09:49:05,319] [INFO] [controller] EPOCH 4 loss ppo:  -0.01574, loss val: 0.04672
[2022-12-07 09:49:05,328] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:49:05,444] [INFO] [optimize] Finished learning.
