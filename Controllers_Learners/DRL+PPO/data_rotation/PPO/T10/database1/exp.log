[2022-12-06 13:31:25,301] [INFO] [optimize] Starting learning
[2022-12-06 13:31:25,321] [INFO] [optimize] Starting learning process..
[2022-12-06 13:31:25,466] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:31:25,467] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:31:35,811] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:31:43,791] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:31:52,259] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:32:01,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:32:10,758] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:32:18,463] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:32:26,132] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:32:34,403] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:32:42,509] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:32:50,583] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4778913620364789
[2022-12-06 13:32:50,583] [INFO] [runner_train_mujoco] Average state value: -0.01989233919729789
[2022-12-06 13:32:50,584] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 13:32:50,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.48974
[2022-12-06 13:32:50,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.03829, loss val: 0.43196
[2022-12-06 13:32:50,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.05311, loss val: 0.37745
[2022-12-06 13:32:50,867] [INFO] [controller] EPOCH 4 loss ppo:  -0.05753, loss val: 0.35557
[2022-12-06 13:32:50,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:32:51,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:32:51,127] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:32:58,807] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:33:06,689] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:33:14,610] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:33:22,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:33:30,454] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:33:38,792] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:33:47,241] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:33:55,517] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:34:04,159] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:34:12,537] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4132023266521682
[2022-12-06 13:34:12,537] [INFO] [runner_train_mujoco] Average state value: 0.14169500270237526
[2022-12-06 13:34:12,537] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 13:34:12,612] [INFO] [controller] EPOCH 1 loss ppo:  -0.01513, loss val: 0.30841
[2022-12-06 13:34:12,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.03930, loss val: 0.28677
[2022-12-06 13:34:12,719] [INFO] [controller] EPOCH 3 loss ppo:  -0.05249, loss val: 0.25061
[2022-12-06 13:34:12,774] [INFO] [controller] EPOCH 4 loss ppo:  -0.06080, loss val: 0.21228
[2022-12-06 13:34:12,786] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:34:13,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:34:13,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:34:21,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:34:30,229] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:34:38,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:34:46,880] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:34:55,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:35:04,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:35:13,245] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:35:22,302] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:35:31,537] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:35:40,469] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37881773133198987
[2022-12-06 13:35:40,469] [INFO] [runner_train_mujoco] Average state value: 0.31284570273384454
[2022-12-06 13:35:40,469] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 13:35:40,556] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.16660
[2022-12-06 13:35:40,614] [INFO] [controller] EPOCH 2 loss ppo:  -0.04173, loss val: 0.14833
[2022-12-06 13:35:40,700] [INFO] [controller] EPOCH 3 loss ppo:  -0.05317, loss val: 0.13452
[2022-12-06 13:35:40,795] [INFO] [controller] EPOCH 4 loss ppo:  -0.05917, loss val: 0.12175
[2022-12-06 13:35:40,807] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:35:41,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:35:41,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:35:49,950] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:35:59,057] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:36:08,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:36:17,725] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:36:26,870] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:36:35,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:36:45,103] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:36:54,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:37:03,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:37:13,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42136349076117136
[2022-12-06 13:37:13,160] [INFO] [runner_train_mujoco] Average state value: 0.435600099404032
[2022-12-06 13:37:13,160] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 13:37:13,227] [INFO] [controller] EPOCH 1 loss ppo:  -0.01176, loss val: 0.11387
[2022-12-06 13:37:13,322] [INFO] [controller] EPOCH 2 loss ppo:  -0.03682, loss val: 0.10408
[2022-12-06 13:37:13,395] [INFO] [controller] EPOCH 3 loss ppo:  -0.05010, loss val: 0.09531
[2022-12-06 13:37:13,502] [INFO] [controller] EPOCH 4 loss ppo:  -0.05821, loss val: 0.09145
[2022-12-06 13:37:13,531] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:37:13,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:37:13,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:37:22,948] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:37:31,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:37:40,427] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:37:48,699] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:37:57,288] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:38:05,826] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:38:14,387] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:38:22,952] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:38:31,783] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:38:40,129] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.49609691828008257
[2022-12-06 13:38:40,130] [INFO] [runner_train_mujoco] Average state value: 0.540437431269015
[2022-12-06 13:38:40,130] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 13:38:40,466] [INFO] [controller] EPOCH 1 loss ppo:  -0.01201, loss val: 0.07994
[2022-12-06 13:38:40,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.03326, loss val: 0.07551
[2022-12-06 13:38:40,580] [INFO] [controller] EPOCH 3 loss ppo:  -0.04583, loss val: 0.07085
[2022-12-06 13:38:40,660] [INFO] [controller] EPOCH 4 loss ppo:  -0.05593, loss val: 0.06585
[2022-12-06 13:38:40,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:38:40,895] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:38:40,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:38:49,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:38:57,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:39:05,138] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:39:13,395] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:39:21,904] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:39:30,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:39:38,251] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:39:46,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:39:54,636] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:40:03,226] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46437373941048643
[2022-12-06 13:40:03,226] [INFO] [runner_train_mujoco] Average state value: 0.5284870791075129
[2022-12-06 13:40:03,227] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 13:40:03,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.07834
[2022-12-06 13:40:03,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.03690, loss val: 0.07533
[2022-12-06 13:40:03,440] [INFO] [controller] EPOCH 3 loss ppo:  -0.04850, loss val: 0.07165
[2022-12-06 13:40:03,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.05635, loss val: 0.06619
[2022-12-06 13:40:03,515] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:40:03,739] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:40:03,739] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:40:12,333] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:40:21,094] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:40:29,080] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:40:36,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:40:44,627] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:40:52,423] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:41:00,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:41:08,181] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:41:16,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:41:24,962] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48537202841965577
[2022-12-06 13:41:24,962] [INFO] [runner_train_mujoco] Average state value: 0.5450423749238252
[2022-12-06 13:41:24,962] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 13:41:25,036] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.05846
[2022-12-06 13:41:25,093] [INFO] [controller] EPOCH 2 loss ppo:  -0.02885, loss val: 0.05964
[2022-12-06 13:41:25,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.03896, loss val: 0.05370
[2022-12-06 13:41:25,239] [INFO] [controller] EPOCH 4 loss ppo:  -0.05029, loss val: 0.05043
[2022-12-06 13:41:25,254] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:41:25,481] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:41:25,481] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:41:33,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:41:41,790] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:41:49,999] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:41:58,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:42:06,440] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:42:14,719] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:42:23,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:42:31,627] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:42:40,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:42:48,238] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37183106819347433
[2022-12-06 13:42:48,238] [INFO] [runner_train_mujoco] Average state value: 0.5201617081264656
[2022-12-06 13:42:48,238] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 13:42:48,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.01070, loss val: 0.04600
[2022-12-06 13:42:48,376] [INFO] [controller] EPOCH 2 loss ppo:  -0.03600, loss val: 0.04508
[2022-12-06 13:42:48,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.04696, loss val: 0.04468
[2022-12-06 13:42:48,512] [INFO] [controller] EPOCH 4 loss ppo:  -0.05360, loss val: 0.04433
[2022-12-06 13:42:48,524] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:42:48,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:42:48,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:42:57,200] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:43:05,805] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:43:14,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:43:23,294] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:43:32,205] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:43:40,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:43:48,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:43:57,738] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:44:06,797] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:44:15,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6339857760730861
[2022-12-06 13:44:15,426] [INFO] [runner_train_mujoco] Average state value: 0.5033132165173688
[2022-12-06 13:44:15,426] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 13:44:15,503] [INFO] [controller] EPOCH 1 loss ppo:  -0.01051, loss val: 0.04813
[2022-12-06 13:44:15,557] [INFO] [controller] EPOCH 2 loss ppo:  -0.03462, loss val: 0.04571
[2022-12-06 13:44:15,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.04425, loss val: 0.04380
[2022-12-06 13:44:15,676] [INFO] [controller] EPOCH 4 loss ppo:  -0.05131, loss val: 0.04273
[2022-12-06 13:44:15,688] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:44:15,926] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:44:15,926] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:44:25,654] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:44:34,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:44:43,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:44:52,966] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:45:01,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:45:10,754] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:45:20,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:45:29,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:45:37,724] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:45:46,900] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5639590007887338
[2022-12-06 13:45:46,900] [INFO] [runner_train_mujoco] Average state value: 0.532216438361754
[2022-12-06 13:45:46,900] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 13:45:46,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.05114
[2022-12-06 13:45:47,055] [INFO] [controller] EPOCH 2 loss ppo:  -0.03402, loss val: 0.05152
[2022-12-06 13:45:47,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.04523, loss val: 0.04900
[2022-12-06 13:45:47,240] [INFO] [controller] EPOCH 4 loss ppo:  -0.05507, loss val: 0.04694
[2022-12-06 13:45:47,253] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:45:47,476] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:45:47,476] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:45:56,666] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:46:05,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:46:14,516] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:46:22,340] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:46:30,033] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:46:38,007] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:46:46,338] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:46:54,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:47:03,396] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:47:11,682] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41253916481745084
[2022-12-06 13:47:11,683] [INFO] [runner_train_mujoco] Average state value: 0.602167245666186
[2022-12-06 13:47:11,683] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 13:47:11,745] [INFO] [controller] EPOCH 1 loss ppo:  -0.00862, loss val: 0.04199
[2022-12-06 13:47:11,797] [INFO] [controller] EPOCH 2 loss ppo:  -0.02724, loss val: 0.04194
[2022-12-06 13:47:11,850] [INFO] [controller] EPOCH 3 loss ppo:  -0.04367, loss val: 0.04207
[2022-12-06 13:47:11,909] [INFO] [controller] EPOCH 4 loss ppo:  -0.05216, loss val: 0.04370
[2022-12-06 13:47:11,920] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:47:12,141] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:47:12,141] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:47:20,432] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:47:28,859] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:47:36,779] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:47:44,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:47:52,859] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:48:00,504] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:48:08,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:48:16,621] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:48:24,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:48:32,039] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6245813951625296
[2022-12-06 13:48:32,040] [INFO] [runner_train_mujoco] Average state value: 0.6146150128642718
[2022-12-06 13:48:32,040] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 13:48:32,110] [INFO] [controller] EPOCH 1 loss ppo:  -0.00956, loss val: 0.04243
[2022-12-06 13:48:32,162] [INFO] [controller] EPOCH 2 loss ppo:  -0.03050, loss val: 0.04162
[2022-12-06 13:48:32,295] [INFO] [controller] EPOCH 3 loss ppo:  -0.04714, loss val: 0.04093
[2022-12-06 13:48:32,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.05611, loss val: 0.03895
[2022-12-06 13:48:32,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:48:32,576] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:48:32,577] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:48:40,265] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:48:48,168] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:48:56,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:49:03,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:49:11,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:49:19,297] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:49:27,261] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:49:35,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:49:43,393] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:49:51,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4490302992884271
[2022-12-06 13:49:51,265] [INFO] [runner_train_mujoco] Average state value: 0.5650634980599085
[2022-12-06 13:49:51,265] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 13:49:51,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.00988, loss val: 0.04016
[2022-12-06 13:49:51,459] [INFO] [controller] EPOCH 2 loss ppo:  -0.03284, loss val: 0.04002
[2022-12-06 13:49:51,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.04838, loss val: 0.03998
[2022-12-06 13:49:51,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.05749, loss val: 0.04025
[2022-12-06 13:49:51,575] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:49:51,799] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:49:51,800] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:49:59,300] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:50:07,510] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:50:15,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:50:23,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:50:31,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:50:39,711] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:50:48,032] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:50:56,109] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:51:04,271] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:51:12,637] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4935217632988761
[2022-12-06 13:51:12,637] [INFO] [runner_train_mujoco] Average state value: 0.5313978644112745
[2022-12-06 13:51:12,637] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 13:51:12,707] [INFO] [controller] EPOCH 1 loss ppo:  -0.00908, loss val: 0.04206
[2022-12-06 13:51:12,772] [INFO] [controller] EPOCH 2 loss ppo:  -0.03051, loss val: 0.04280
[2022-12-06 13:51:12,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.04524, loss val: 0.03816
[2022-12-06 13:51:12,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.05377, loss val: 0.03783
[2022-12-06 13:51:12,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:51:13,154] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:51:13,155] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:51:21,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:51:29,935] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:51:37,953] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:51:46,383] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:51:54,813] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:52:03,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:52:11,832] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:52:20,761] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:52:29,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:52:37,204] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5789689995357198
[2022-12-06 13:52:37,204] [INFO] [runner_train_mujoco] Average state value: 0.5620536563495795
[2022-12-06 13:52:37,204] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 13:52:37,273] [INFO] [controller] EPOCH 1 loss ppo:  -0.01262, loss val: 0.04364
[2022-12-06 13:52:37,348] [INFO] [controller] EPOCH 2 loss ppo:  -0.03281, loss val: 0.04163
[2022-12-06 13:52:37,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.04178
[2022-12-06 13:52:37,491] [INFO] [controller] EPOCH 4 loss ppo:  -0.05444, loss val: 0.04075
[2022-12-06 13:52:37,504] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:52:37,756] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:52:37,757] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:52:46,500] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:52:55,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:53:03,925] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:53:12,918] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:53:22,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:53:31,375] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:53:40,036] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:53:49,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:53:57,935] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:54:06,545] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6019882536104778
[2022-12-06 13:54:06,545] [INFO] [runner_train_mujoco] Average state value: 0.6096120486954848
[2022-12-06 13:54:06,545] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 13:54:06,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.05539
[2022-12-06 13:54:06,680] [INFO] [controller] EPOCH 2 loss ppo:  -0.02479, loss val: 0.05518
[2022-12-06 13:54:06,734] [INFO] [controller] EPOCH 3 loss ppo:  -0.03343, loss val: 0.05231
[2022-12-06 13:54:06,825] [INFO] [controller] EPOCH 4 loss ppo:  -0.04340, loss val: 0.04918
[2022-12-06 13:54:06,837] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:54:07,065] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:54:07,065] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:54:15,632] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:54:23,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:54:32,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:54:40,380] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:54:48,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:54:57,349] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:55:05,927] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:55:14,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:55:22,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:55:30,753] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4845616589863436
[2022-12-06 13:55:30,754] [INFO] [runner_train_mujoco] Average state value: 0.5710170669953029
[2022-12-06 13:55:30,754] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 13:55:30,822] [INFO] [controller] EPOCH 1 loss ppo:  -0.00906, loss val: 0.03959
[2022-12-06 13:55:30,871] [INFO] [controller] EPOCH 2 loss ppo:  -0.03294, loss val: 0.03787
[2022-12-06 13:55:30,925] [INFO] [controller] EPOCH 3 loss ppo:  -0.04430, loss val: 0.03532
[2022-12-06 13:55:31,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.05212, loss val: 0.03584
[2022-12-06 13:55:31,040] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:55:31,264] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:55:31,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:55:39,238] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:55:47,337] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:55:55,593] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:56:03,334] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:56:11,608] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:56:19,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:56:28,312] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:56:36,349] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:56:44,765] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:56:52,646] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6580759377473413
[2022-12-06 13:56:52,647] [INFO] [runner_train_mujoco] Average state value: 0.4917668677171071
[2022-12-06 13:56:52,647] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 13:56:52,716] [INFO] [controller] EPOCH 1 loss ppo:  -0.00980, loss val: 0.04824
[2022-12-06 13:56:52,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.02973, loss val: 0.04949
[2022-12-06 13:56:52,841] [INFO] [controller] EPOCH 3 loss ppo:  -0.04237, loss val: 0.04415
[2022-12-06 13:56:52,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.05468, loss val: 0.04582
[2022-12-06 13:56:52,902] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:56:53,114] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:56:53,114] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:57:00,889] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:57:08,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:57:15,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:57:23,409] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:57:31,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:57:39,293] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:57:47,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:57:56,155] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:58:04,378] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:58:16,010] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7060816886866853
[2022-12-06 13:58:16,011] [INFO] [runner_train_mujoco] Average state value: 0.5069773711661499
[2022-12-06 13:58:16,011] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 13:58:16,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01105, loss val: 0.03707
[2022-12-06 13:58:16,322] [INFO] [controller] EPOCH 2 loss ppo:  -0.02924, loss val: 0.03536
[2022-12-06 13:58:16,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.04129, loss val: 0.03564
[2022-12-06 13:58:16,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.05215, loss val: 0.03601
[2022-12-06 13:58:16,571] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:58:16,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:58:16,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:58:27,788] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:58:36,782] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:58:47,383] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:58:59,570] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:59:11,187] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:59:21,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:59:32,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:59:43,803] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:59:54,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:00:04,196] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7631481531257582
[2022-12-06 14:00:04,196] [INFO] [runner_train_mujoco] Average state value: 0.5359181468188763
[2022-12-06 14:00:04,196] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 14:00:04,427] [INFO] [controller] EPOCH 1 loss ppo:  -0.01129, loss val: 0.04451
[2022-12-06 14:00:04,505] [INFO] [controller] EPOCH 2 loss ppo:  -0.03613, loss val: 0.03961
[2022-12-06 14:00:04,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.04850, loss val: 0.04003
[2022-12-06 14:00:04,781] [INFO] [controller] EPOCH 4 loss ppo:  -0.05485, loss val: 0.04473
[2022-12-06 14:00:04,802] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:00:05,072] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:00:05,073] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:00:14,308] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:00:23,891] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:00:33,420] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:00:44,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:00:58,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:01:11,574] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:01:24,825] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:01:38,425] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:01:53,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:02:03,992] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8053210552323234
[2022-12-06 14:02:03,993] [INFO] [runner_train_mujoco] Average state value: 0.5291025887926419
[2022-12-06 14:02:03,993] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 14:02:04,092] [INFO] [controller] EPOCH 1 loss ppo:  -0.01035, loss val: 0.04039
[2022-12-06 14:02:04,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.02490, loss val: 0.03721
[2022-12-06 14:02:04,214] [INFO] [controller] EPOCH 3 loss ppo:  -0.03925, loss val: 0.03506
[2022-12-06 14:02:04,295] [INFO] [controller] EPOCH 4 loss ppo:  -0.05389, loss val: 0.03585
[2022-12-06 14:02:04,309] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:02:04,556] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:02:04,556] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:02:14,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:02:24,130] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:02:34,865] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:02:44,627] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:02:53,864] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:03:03,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:03:13,440] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:03:24,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:03:33,591] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:03:42,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2281040389495428
[2022-12-06 14:03:42,781] [INFO] [runner_train_mujoco] Average state value: 0.48179437148571014
[2022-12-06 14:03:42,781] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 14:03:42,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.03950
[2022-12-06 14:03:42,923] [INFO] [controller] EPOCH 2 loss ppo:  -0.03487, loss val: 0.03989
[2022-12-06 14:03:42,979] [INFO] [controller] EPOCH 3 loss ppo:  -0.05006, loss val: 0.03917
[2022-12-06 14:03:43,050] [INFO] [controller] EPOCH 4 loss ppo:  -0.05668, loss val: 0.04023
[2022-12-06 14:03:43,063] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:03:43,317] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:03:43,318] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:03:52,310] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:04:01,133] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:04:10,132] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:04:18,988] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:04:28,278] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:04:36,790] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:04:45,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:04:53,063] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:05:01,834] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:05:10,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4029158877791557
[2022-12-06 14:05:10,172] [INFO] [runner_train_mujoco] Average state value: 0.4314170095324516
[2022-12-06 14:05:10,172] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 14:05:10,244] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.03560
[2022-12-06 14:05:10,298] [INFO] [controller] EPOCH 2 loss ppo:  -0.03841, loss val: 0.03872
[2022-12-06 14:05:10,349] [INFO] [controller] EPOCH 3 loss ppo:  -0.05080, loss val: 0.03627
[2022-12-06 14:05:10,402] [INFO] [controller] EPOCH 4 loss ppo:  -0.05638, loss val: 0.03620
[2022-12-06 14:05:10,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:05:10,667] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:05:10,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:05:18,874] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:05:27,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:05:37,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:05:45,874] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:05:53,491] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:06:01,320] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:06:09,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:06:18,512] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:06:29,859] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:06:41,289] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5876218022210329
[2022-12-06 14:06:41,289] [INFO] [runner_train_mujoco] Average state value: 0.4312823101629813
[2022-12-06 14:06:41,289] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 14:06:41,377] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.03838
[2022-12-06 14:06:41,476] [INFO] [controller] EPOCH 2 loss ppo:  -0.03440, loss val: 0.03758
[2022-12-06 14:06:41,600] [INFO] [controller] EPOCH 3 loss ppo:  -0.04426, loss val: 0.03667
[2022-12-06 14:06:41,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.05447, loss val: 0.03612
[2022-12-06 14:06:41,768] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:06:42,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:06:42,018] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:06:52,711] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:07:04,841] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:07:16,740] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:07:26,034] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:07:38,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:07:49,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:07:57,682] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:08:05,967] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:08:14,587] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:08:22,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6352473866688981
[2022-12-06 14:08:22,982] [INFO] [runner_train_mujoco] Average state value: 0.46009741905331614
[2022-12-06 14:08:22,982] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 14:08:23,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04208
[2022-12-06 14:08:23,149] [INFO] [controller] EPOCH 2 loss ppo:  -0.03509, loss val: 0.04320
[2022-12-06 14:08:23,333] [INFO] [controller] EPOCH 3 loss ppo:  -0.04827, loss val: 0.04136
[2022-12-06 14:08:23,410] [INFO] [controller] EPOCH 4 loss ppo:  -0.05787, loss val: 0.04077
[2022-12-06 14:08:23,421] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:08:23,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:08:23,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:08:32,430] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:08:41,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:08:49,725] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:08:57,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:09:06,317] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:09:15,580] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:09:24,317] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:09:33,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:09:41,192] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:09:49,796] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.149488014958945
[2022-12-06 14:09:49,796] [INFO] [runner_train_mujoco] Average state value: 0.4939839083602031
[2022-12-06 14:09:49,797] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 14:09:49,873] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04669
[2022-12-06 14:09:49,931] [INFO] [controller] EPOCH 2 loss ppo:  -0.03529, loss val: 0.04610
[2022-12-06 14:09:49,991] [INFO] [controller] EPOCH 3 loss ppo:  -0.04589, loss val: 0.04397
[2022-12-06 14:09:50,049] [INFO] [controller] EPOCH 4 loss ppo:  -0.05645, loss val: 0.04326
[2022-12-06 14:09:50,060] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:09:50,307] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:09:50,308] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:09:59,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:10:08,378] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:10:17,529] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:10:26,233] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:10:34,786] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:10:43,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:10:52,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:11:01,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:11:10,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:11:18,535] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1137921212584674
[2022-12-06 14:11:18,535] [INFO] [runner_train_mujoco] Average state value: 0.5483703413208325
[2022-12-06 14:11:18,535] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 14:11:18,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.05832
[2022-12-06 14:11:18,661] [INFO] [controller] EPOCH 2 loss ppo:  -0.02330, loss val: 0.05938
[2022-12-06 14:11:18,723] [INFO] [controller] EPOCH 3 loss ppo:  -0.03375, loss val: 0.05676
[2022-12-06 14:11:18,782] [INFO] [controller] EPOCH 4 loss ppo:  -0.04647, loss val: 0.05424
[2022-12-06 14:11:18,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:11:19,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:11:19,019] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:11:28,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:11:36,988] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:11:45,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:11:53,943] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:12:02,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:12:10,226] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:12:18,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:12:25,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:12:33,680] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:12:41,539] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5269428555821407
[2022-12-06 14:12:41,539] [INFO] [runner_train_mujoco] Average state value: 0.5222774446209271
[2022-12-06 14:12:41,539] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 14:12:41,615] [INFO] [controller] EPOCH 1 loss ppo:  -0.01692, loss val: 0.03695
[2022-12-06 14:12:41,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.02870, loss val: 0.03560
[2022-12-06 14:12:41,753] [INFO] [controller] EPOCH 3 loss ppo:  -0.04043, loss val: 0.03616
[2022-12-06 14:12:41,807] [INFO] [controller] EPOCH 4 loss ppo:  -0.05330, loss val: 0.03645
[2022-12-06 14:12:41,821] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:12:42,044] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:12:42,045] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:12:50,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:12:59,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:13:06,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:13:14,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:13:22,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:13:30,313] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:13:37,770] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:13:45,663] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:13:53,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:14:01,022] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7333755969985933
[2022-12-06 14:14:01,023] [INFO] [runner_train_mujoco] Average state value: 0.4913067952096462
[2022-12-06 14:14:01,023] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 14:14:01,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.04393
[2022-12-06 14:14:01,325] [INFO] [controller] EPOCH 2 loss ppo:  -0.03448, loss val: 0.04354
[2022-12-06 14:14:01,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.04650, loss val: 0.04472
[2022-12-06 14:14:01,432] [INFO] [controller] EPOCH 4 loss ppo:  -0.05405, loss val: 0.04353
[2022-12-06 14:14:01,442] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:14:01,654] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:14:01,655] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:14:09,778] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:14:18,733] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:14:27,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:14:35,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:14:43,925] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:14:51,971] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:15:00,403] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:15:08,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:15:17,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:15:26,662] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7005235448626843
[2022-12-06 14:15:26,663] [INFO] [runner_train_mujoco] Average state value: 0.4861659452021122
[2022-12-06 14:15:26,663] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 14:15:26,736] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.05270
[2022-12-06 14:15:26,786] [INFO] [controller] EPOCH 2 loss ppo:  -0.03286, loss val: 0.05181
[2022-12-06 14:15:26,839] [INFO] [controller] EPOCH 3 loss ppo:  -0.04404, loss val: 0.05005
[2022-12-06 14:15:26,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.05306, loss val: 0.04957
[2022-12-06 14:15:26,912] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:15:27,135] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:15:27,136] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:15:35,847] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:15:44,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:15:53,915] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:16:03,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:16:13,298] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:16:24,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:16:35,055] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:16:45,938] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:16:57,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:17:07,519] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.986060435761787
[2022-12-06 14:17:07,520] [INFO] [runner_train_mujoco] Average state value: 0.4476973345677058
[2022-12-06 14:17:07,520] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 14:17:07,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.03865
[2022-12-06 14:17:07,661] [INFO] [controller] EPOCH 2 loss ppo:  -0.03118, loss val: 0.03704
[2022-12-06 14:17:07,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.04472, loss val: 0.03671
[2022-12-06 14:17:07,775] [INFO] [controller] EPOCH 4 loss ppo:  -0.05694, loss val: 0.03552
[2022-12-06 14:17:07,796] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:17:08,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:17:08,052] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:17:17,217] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:17:26,384] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:17:35,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:17:44,639] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:17:54,786] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:18:04,114] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:18:12,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:18:22,520] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:18:31,802] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:18:41,861] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.251200504530172
[2022-12-06 14:18:41,861] [INFO] [runner_train_mujoco] Average state value: 0.3985475038588048
[2022-12-06 14:18:41,862] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 14:18:41,979] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.05318
[2022-12-06 14:18:42,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.03365, loss val: 0.05118
[2022-12-06 14:18:42,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.04248, loss val: 0.05329
[2022-12-06 14:18:42,250] [INFO] [controller] EPOCH 4 loss ppo:  -0.05422, loss val: 0.04992
[2022-12-06 14:18:42,272] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:18:42,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:18:42,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:18:51,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:19:01,449] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:19:10,913] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:19:20,055] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:19:28,762] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:19:37,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:19:46,885] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:19:55,505] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:20:04,051] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:20:13,303] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1902610517960843
[2022-12-06 14:20:13,304] [INFO] [runner_train_mujoco] Average state value: 0.4093795599440734
[2022-12-06 14:20:13,304] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 14:20:13,522] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.03286
[2022-12-06 14:20:13,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.03107, loss val: 0.03198
[2022-12-06 14:20:13,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.04189, loss val: 0.03089
[2022-12-06 14:20:13,756] [INFO] [controller] EPOCH 4 loss ppo:  -0.05280, loss val: 0.03035
[2022-12-06 14:20:13,768] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:20:14,013] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:20:14,014] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:20:23,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:20:32,428] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:20:41,140] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:20:49,961] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:20:58,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:21:08,143] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:21:18,090] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:21:28,546] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:21:37,982] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:21:49,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3173806550622933
[2022-12-06 14:21:49,469] [INFO] [runner_train_mujoco] Average state value: 0.44728085484355684
[2022-12-06 14:21:49,469] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 14:21:49,614] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04369
[2022-12-06 14:21:49,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.02695, loss val: 0.04402
[2022-12-06 14:21:49,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.04089, loss val: 0.04741
[2022-12-06 14:21:50,175] [INFO] [controller] EPOCH 4 loss ppo:  -0.05284, loss val: 0.04577
[2022-12-06 14:21:50,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:21:50,447] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:21:50,448] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:21:59,254] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:22:07,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:22:14,568] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:22:22,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:22:30,704] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:22:38,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:22:47,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:22:55,801] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:23:04,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:23:12,870] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6940631278031164
[2022-12-06 14:23:12,871] [INFO] [runner_train_mujoco] Average state value: 0.4576813290218512
[2022-12-06 14:23:12,871] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 14:23:12,987] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04448
[2022-12-06 14:23:13,060] [INFO] [controller] EPOCH 2 loss ppo:  -0.02466, loss val: 0.04438
[2022-12-06 14:23:13,159] [INFO] [controller] EPOCH 3 loss ppo:  -0.03486, loss val: 0.04421
[2022-12-06 14:23:13,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.04699, loss val: 0.04432
[2022-12-06 14:23:13,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:23:13,488] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:23:13,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:23:22,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:23:30,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:23:39,383] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:23:47,857] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:23:56,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:24:04,064] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:24:12,194] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:24:22,034] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:24:30,876] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:24:39,729] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8190763262325156
[2022-12-06 14:24:39,730] [INFO] [runner_train_mujoco] Average state value: 0.4647250395218531
[2022-12-06 14:24:39,730] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 14:24:39,820] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04657
[2022-12-06 14:24:39,884] [INFO] [controller] EPOCH 2 loss ppo:  -0.02871, loss val: 0.04690
[2022-12-06 14:24:39,961] [INFO] [controller] EPOCH 3 loss ppo:  -0.03531, loss val: 0.04560
[2022-12-06 14:24:40,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.04522, loss val: 0.04706
[2022-12-06 14:24:40,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:24:40,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:24:40,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:24:48,370] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:24:56,526] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:25:06,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:25:15,757] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:25:24,986] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:25:35,085] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:25:45,325] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:25:55,987] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:26:05,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:26:15,823] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.638391468747855
[2022-12-06 14:26:15,823] [INFO] [runner_train_mujoco] Average state value: 0.45100183669726057
[2022-12-06 14:26:15,823] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 14:26:15,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.03887
[2022-12-06 14:26:16,014] [INFO] [controller] EPOCH 2 loss ppo:  -0.02784, loss val: 0.04118
[2022-12-06 14:26:16,093] [INFO] [controller] EPOCH 3 loss ppo:  -0.03835, loss val: 0.04185
[2022-12-06 14:26:16,165] [INFO] [controller] EPOCH 4 loss ppo:  -0.04769, loss val: 0.03597
[2022-12-06 14:26:16,176] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:26:16,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:26:16,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:26:26,576] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:26:38,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:26:49,856] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:26:59,110] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:27:08,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:27:17,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:27:27,085] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:27:37,587] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:27:47,173] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:27:57,578] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.15080863143513
[2022-12-06 14:27:57,579] [INFO] [runner_train_mujoco] Average state value: 0.46259485222895946
[2022-12-06 14:27:57,579] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 14:27:57,686] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.03563
[2022-12-06 14:27:57,792] [INFO] [controller] EPOCH 2 loss ppo:  -0.02751, loss val: 0.03512
[2022-12-06 14:27:57,911] [INFO] [controller] EPOCH 3 loss ppo:  -0.04278, loss val: 0.03553
[2022-12-06 14:27:57,981] [INFO] [controller] EPOCH 4 loss ppo:  -0.05325, loss val: 0.03745
[2022-12-06 14:27:57,997] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:27:58,261] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:27:58,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:28:10,338] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:28:23,278] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:28:34,736] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:28:44,379] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:28:55,745] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:29:06,090] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:29:16,011] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:29:26,846] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:29:37,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:29:49,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6051495832315643
[2022-12-06 14:29:49,266] [INFO] [runner_train_mujoco] Average state value: 0.4819701568881671
[2022-12-06 14:29:49,266] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 14:29:49,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04402
[2022-12-06 14:29:49,768] [INFO] [controller] EPOCH 2 loss ppo:  -0.02532, loss val: 0.04456
[2022-12-06 14:29:50,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.03542, loss val: 0.04476
[2022-12-06 14:29:50,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.04654, loss val: 0.04302
[2022-12-06 14:29:50,664] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:29:50,994] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:29:50,994] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:30:01,954] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:30:13,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:30:24,836] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:30:36,324] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:30:49,086] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:31:00,827] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:31:12,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:31:22,532] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:31:32,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:31:44,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.076002915893264
[2022-12-06 14:31:44,986] [INFO] [runner_train_mujoco] Average state value: 0.5034187043209871
[2022-12-06 14:31:44,986] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 14:31:45,272] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04864
[2022-12-06 14:31:45,423] [INFO] [controller] EPOCH 2 loss ppo:  -0.02602, loss val: 0.04979
[2022-12-06 14:31:45,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.03618, loss val: 0.04889
[2022-12-06 14:31:45,788] [INFO] [controller] EPOCH 4 loss ppo:  -0.04418, loss val: 0.04946
[2022-12-06 14:31:45,821] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:31:46,166] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:31:46,167] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:31:56,412] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:32:06,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:32:17,156] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:32:26,508] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:32:36,332] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:32:46,053] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:32:55,852] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:33:05,177] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:33:14,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:33:23,151] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.188982004922756
[2022-12-06 14:33:23,151] [INFO] [runner_train_mujoco] Average state value: 0.5061323851148287
[2022-12-06 14:33:23,151] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 14:33:23,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.05722
[2022-12-06 14:33:23,749] [INFO] [controller] EPOCH 2 loss ppo:  -0.02429, loss val: 0.05705
[2022-12-06 14:33:23,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.03153, loss val: 0.05367
[2022-12-06 14:33:23,964] [INFO] [controller] EPOCH 4 loss ppo:  -0.04078, loss val: 0.05154
[2022-12-06 14:33:23,977] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:33:24,240] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:33:24,241] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:33:33,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:33:42,441] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:33:51,540] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:34:00,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:34:09,443] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:34:18,651] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:34:28,354] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:34:37,540] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:34:47,093] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:34:56,732] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.132139339865885
[2022-12-06 14:34:56,732] [INFO] [runner_train_mujoco] Average state value: 0.46805733829736706
[2022-12-06 14:34:56,733] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 14:34:56,865] [INFO] [controller] EPOCH 1 loss ppo:  -0.01385, loss val: 0.04021
[2022-12-06 14:34:56,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.02503, loss val: 0.04075
[2022-12-06 14:34:57,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.03196, loss val: 0.04153
[2022-12-06 14:34:57,183] [INFO] [controller] EPOCH 4 loss ppo:  -0.04455, loss val: 0.04402
[2022-12-06 14:34:57,196] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:34:57,461] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:34:57,461] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:35:07,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:35:17,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:35:26,783] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:35:36,405] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:35:45,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:35:53,528] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:36:01,324] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:36:09,230] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:36:18,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:36:28,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.323351155834771
[2022-12-06 14:36:28,375] [INFO] [runner_train_mujoco] Average state value: 0.45908630385001503
[2022-12-06 14:36:28,375] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 14:36:28,480] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04193
[2022-12-06 14:36:28,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.02077, loss val: 0.04190
[2022-12-06 14:36:28,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.03101, loss val: 0.04179
[2022-12-06 14:36:28,813] [INFO] [controller] EPOCH 4 loss ppo:  -0.04451, loss val: 0.04204
[2022-12-06 14:36:28,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:36:29,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:36:29,040] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:36:37,398] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:36:45,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:36:53,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:37:00,986] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:37:09,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:37:17,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:37:25,339] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:37:33,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:37:40,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:37:48,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.318049720257245
[2022-12-06 14:37:48,448] [INFO] [runner_train_mujoco] Average state value: 0.4592920672098796
[2022-12-06 14:37:48,448] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 14:37:48,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.03739
[2022-12-06 14:37:48,733] [INFO] [controller] EPOCH 2 loss ppo:  -0.02205, loss val: 0.03751
[2022-12-06 14:37:48,806] [INFO] [controller] EPOCH 3 loss ppo:  -0.03196, loss val: 0.03788
[2022-12-06 14:37:48,863] [INFO] [controller] EPOCH 4 loss ppo:  -0.04360, loss val: 0.03704
[2022-12-06 14:37:48,874] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:37:49,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:37:49,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:37:57,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:38:05,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:38:16,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:38:24,330] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:38:33,118] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:38:41,672] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:38:49,330] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:38:56,739] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:39:04,749] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:39:12,956] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.43971763901256
[2022-12-06 14:39:12,957] [INFO] [runner_train_mujoco] Average state value: 0.4665712476372718
[2022-12-06 14:39:12,957] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 14:39:13,057] [INFO] [controller] EPOCH 1 loss ppo:  -0.01318, loss val: 0.04434
[2022-12-06 14:39:13,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.02404, loss val: 0.04359
[2022-12-06 14:39:13,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.03122, loss val: 0.04344
[2022-12-06 14:39:13,245] [INFO] [controller] EPOCH 4 loss ppo:  -0.03854, loss val: 0.04198
[2022-12-06 14:39:13,257] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:39:13,482] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:39:13,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:39:22,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:39:30,991] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:39:39,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:39:48,305] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:39:57,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:40:06,448] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:40:15,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:40:24,190] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:40:33,072] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:40:41,770] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.4621610819388495
[2022-12-06 14:40:41,770] [INFO] [runner_train_mujoco] Average state value: 0.4871741910874844
[2022-12-06 14:40:41,770] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 14:40:41,854] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04942
[2022-12-06 14:40:41,919] [INFO] [controller] EPOCH 2 loss ppo:  -0.02385, loss val: 0.04910
[2022-12-06 14:40:42,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.03152, loss val: 0.04936
[2022-12-06 14:40:42,144] [INFO] [controller] EPOCH 4 loss ppo:  -0.04216, loss val: 0.04977
[2022-12-06 14:40:42,157] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:40:42,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:40:42,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:40:51,644] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:41:01,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:41:11,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:41:19,955] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:41:28,902] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:41:37,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:41:45,949] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:41:54,447] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:42:02,997] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:42:11,189] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.536693031591622
[2022-12-06 14:42:11,190] [INFO] [runner_train_mujoco] Average state value: 0.49636301781733827
[2022-12-06 14:42:11,190] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 14:42:11,274] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.04457
[2022-12-06 14:42:11,344] [INFO] [controller] EPOCH 2 loss ppo:  -0.02178, loss val: 0.04543
[2022-12-06 14:42:11,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.03211, loss val: 0.04447
[2022-12-06 14:42:11,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.04097, loss val: 0.04457
[2022-12-06 14:42:11,537] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:42:11,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:42:11,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:42:20,151] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:42:28,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:42:37,948] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:42:46,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:42:55,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:43:04,384] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:43:12,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:43:23,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:43:31,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:43:39,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.693515603931103
[2022-12-06 14:43:39,640] [INFO] [runner_train_mujoco] Average state value: 0.49230679868658384
[2022-12-06 14:43:39,641] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 14:43:39,714] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.05780
[2022-12-06 14:43:39,778] [INFO] [controller] EPOCH 2 loss ppo:  -0.01683, loss val: 0.05696
[2022-12-06 14:43:39,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.02417, loss val: 0.05439
[2022-12-06 14:43:39,888] [INFO] [controller] EPOCH 4 loss ppo:  -0.03005, loss val: 0.05385
[2022-12-06 14:43:39,900] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:43:40,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:43:40,109] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:43:47,996] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:43:55,842] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:44:04,126] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:44:11,947] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:44:19,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:44:27,718] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:44:35,479] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:44:43,095] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:44:51,038] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:44:59,576] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.665166881880618
[2022-12-06 14:44:59,577] [INFO] [runner_train_mujoco] Average state value: 0.46909361547231665
[2022-12-06 14:44:59,577] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 14:44:59,905] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04529
[2022-12-06 14:44:59,965] [INFO] [controller] EPOCH 2 loss ppo:  -0.01892, loss val: 0.04412
[2022-12-06 14:45:00,066] [INFO] [controller] EPOCH 3 loss ppo:  -0.02550, loss val: 0.04326
[2022-12-06 14:45:00,230] [INFO] [controller] EPOCH 4 loss ppo:  -0.03116, loss val: 0.04223
[2022-12-06 14:45:00,250] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:45:00,486] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:45:00,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:45:09,300] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:45:19,329] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:45:27,865] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:45:35,937] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:45:44,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:45:52,762] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:46:01,406] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:46:10,150] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:46:18,671] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:46:27,007] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.930122726699479
[2022-12-06 14:46:27,007] [INFO] [runner_train_mujoco] Average state value: 0.4348025458653768
[2022-12-06 14:46:27,007] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 14:46:27,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04082
[2022-12-06 14:46:27,221] [INFO] [controller] EPOCH 2 loss ppo:  -0.01825, loss val: 0.04387
[2022-12-06 14:46:27,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.02976, loss val: 0.04087
[2022-12-06 14:46:27,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.03607, loss val: 0.04160
[2022-12-06 14:46:27,467] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:46:27,719] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:46:27,722] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:46:36,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:46:45,071] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:46:53,669] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:47:02,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:47:11,493] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:47:20,437] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:47:29,741] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:47:38,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:47:46,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:47:55,314] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.194911850232514
[2022-12-06 14:47:55,315] [INFO] [runner_train_mujoco] Average state value: 0.42188878305753075
[2022-12-06 14:47:55,315] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 14:47:55,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01318, loss val: 0.04492
[2022-12-06 14:47:55,527] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.04508
[2022-12-06 14:47:55,635] [INFO] [controller] EPOCH 3 loss ppo:  -0.02687, loss val: 0.04424
[2022-12-06 14:47:55,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.03087, loss val: 0.04101
[2022-12-06 14:47:55,759] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:47:56,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:47:56,010] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:48:04,996] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:48:13,726] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:48:22,084] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:48:30,345] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:48:38,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:48:46,816] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:48:55,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:49:03,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:49:11,882] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:49:20,151] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.94410848506583
[2022-12-06 14:49:20,151] [INFO] [runner_train_mujoco] Average state value: 0.4145145895083745
[2022-12-06 14:49:20,151] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 14:49:20,235] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.04727
[2022-12-06 14:49:20,300] [INFO] [controller] EPOCH 2 loss ppo:  -0.02052, loss val: 0.04589
[2022-12-06 14:49:20,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.02900, loss val: 0.04586
[2022-12-06 14:49:20,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.03200, loss val: 0.04665
[2022-12-06 14:49:20,428] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:49:20,656] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:49:20,657] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:49:29,209] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:49:37,203] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:49:44,928] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:49:52,536] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:49:59,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:50:07,510] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:50:15,065] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:50:22,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:50:29,792] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:50:36,871] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.109127544934578
[2022-12-06 14:50:36,872] [INFO] [runner_train_mujoco] Average state value: 0.4154923467934132
[2022-12-06 14:50:36,872] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 14:50:36,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.01385, loss val: 0.04723
[2022-12-06 14:50:36,986] [INFO] [controller] EPOCH 2 loss ppo:  -0.01837, loss val: 0.04754
[2022-12-06 14:50:37,038] [INFO] [controller] EPOCH 3 loss ppo:  -0.02495, loss val: 0.04684
[2022-12-06 14:50:37,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.02977, loss val: 0.04696
[2022-12-06 14:50:37,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:50:37,325] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:50:37,326] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:50:45,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:50:53,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:51:01,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:51:10,178] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:51:17,973] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:51:25,867] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:51:33,721] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:51:40,991] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:51:48,664] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:51:56,393] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.933058403677396
[2022-12-06 14:51:56,394] [INFO] [runner_train_mujoco] Average state value: 0.42296805164217943
[2022-12-06 14:51:56,394] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 14:51:56,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.03753
[2022-12-06 14:51:56,608] [INFO] [controller] EPOCH 2 loss ppo:  -0.01727, loss val: 0.03626
[2022-12-06 14:51:56,701] [INFO] [controller] EPOCH 3 loss ppo:  -0.02319, loss val: 0.03620
[2022-12-06 14:51:56,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.02688, loss val: 0.03600
[2022-12-06 14:51:56,776] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:51:57,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:51:57,018] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:52:05,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:52:13,470] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:52:21,302] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:52:29,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:52:37,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:52:45,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:52:54,149] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:53:01,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:53:10,685] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:53:19,224] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.311439458502492
[2022-12-06 14:53:19,224] [INFO] [runner_train_mujoco] Average state value: 0.43006476773818336
[2022-12-06 14:53:19,224] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 14:53:19,304] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.03848
[2022-12-06 14:53:19,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.01784, loss val: 0.03724
[2022-12-06 14:53:19,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.02282, loss val: 0.03829
[2022-12-06 14:53:19,500] [INFO] [controller] EPOCH 4 loss ppo:  -0.02659, loss val: 0.03964
[2022-12-06 14:53:19,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:53:19,768] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:53:19,768] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:53:30,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:53:38,860] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:53:47,177] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:53:55,487] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:54:03,892] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:54:12,419] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:54:21,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:54:30,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:54:39,142] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:54:47,452] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.236853013837475
[2022-12-06 14:54:47,452] [INFO] [runner_train_mujoco] Average state value: 0.4331639673411846
[2022-12-06 14:54:47,452] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 14:54:47,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04959
[2022-12-06 14:54:47,587] [INFO] [controller] EPOCH 2 loss ppo:  -0.01640, loss val: 0.04960
[2022-12-06 14:54:47,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.02055, loss val: 0.05086
[2022-12-06 14:54:47,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.02386, loss val: 0.05136
[2022-12-06 14:54:47,720] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:54:47,962] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:54:47,962] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:54:56,703] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:55:05,807] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:55:13,988] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:55:22,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:55:29,757] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:55:37,089] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:55:43,565] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:55:49,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:55:56,075] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:56:02,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.2125576708078265
[2022-12-06 14:56:02,568] [INFO] [runner_train_mujoco] Average state value: 0.43420028467973076
[2022-12-06 14:56:02,568] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 14:56:02,636] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.03883
[2022-12-06 14:56:02,688] [INFO] [controller] EPOCH 2 loss ppo:  -0.01462, loss val: 0.03951
[2022-12-06 14:56:02,738] [INFO] [controller] EPOCH 3 loss ppo:  -0.01715, loss val: 0.04343
[2022-12-06 14:56:02,800] [INFO] [controller] EPOCH 4 loss ppo:  -0.02092, loss val: 0.03799
[2022-12-06 14:56:02,811] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:56:03,029] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:56:03,029] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:56:09,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:56:16,526] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:56:23,281] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:56:29,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:56:36,524] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:56:43,679] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:56:50,450] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:56:56,762] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:57:03,604] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:57:10,313] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.257202142863435
[2022-12-06 14:57:10,314] [INFO] [runner_train_mujoco] Average state value: 0.43383390674988426
[2022-12-06 14:57:10,314] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 14:57:10,380] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04256
[2022-12-06 14:57:10,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.01455, loss val: 0.04267
[2022-12-06 14:57:10,483] [INFO] [controller] EPOCH 3 loss ppo:  -0.01623, loss val: 0.04360
[2022-12-06 14:57:10,538] [INFO] [controller] EPOCH 4 loss ppo:  -0.01803, loss val: 0.04257
[2022-12-06 14:57:10,550] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:57:10,688] [INFO] [optimize] Finished learning.
