[2022-12-07 18:06:34,470] [INFO] [optimize] Starting learning
[2022-12-07 18:06:34,481] [INFO] [optimize] Starting learning process..
[2022-12-07 18:06:34,559] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:06:34,560] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:06:43,869] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:06:51,653] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:06:58,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:07:07,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:07:14,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:07:21,846] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:07:28,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:07:35,146] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:07:42,292] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:07:49,059] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7250755127942827
[2022-12-07 18:07:49,059] [INFO] [runner_train_mujoco] Average state value: 0.26382175062348445
[2022-12-07 18:07:49,060] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 18:07:49,113] [INFO] [controller] EPOCH 1 loss ppo:  -0.00945, loss val: 0.26633
[2022-12-07 18:07:49,156] [INFO] [controller] EPOCH 2 loss ppo:  -0.04480, loss val: 0.23789
[2022-12-07 18:07:49,196] [INFO] [controller] EPOCH 3 loss ppo:  -0.06458, loss val: 0.21276
[2022-12-07 18:07:49,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.07497, loss val: 0.19220
[2022-12-07 18:07:49,239] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:07:49,426] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:07:49,426] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:07:56,710] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:08:03,919] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:08:10,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:08:17,942] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:08:24,726] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:08:31,492] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:08:38,425] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:08:45,318] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:08:52,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:08:59,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5537343797089106
[2022-12-07 18:08:59,160] [INFO] [runner_train_mujoco] Average state value: 0.4314235396335523
[2022-12-07 18:08:59,160] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 18:08:59,206] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.20180
[2022-12-07 18:08:59,247] [INFO] [controller] EPOCH 2 loss ppo:  -0.04703, loss val: 0.18317
[2022-12-07 18:08:59,285] [INFO] [controller] EPOCH 3 loss ppo:  -0.06526, loss val: 0.16672
[2022-12-07 18:08:59,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.07878, loss val: 0.15354
[2022-12-07 18:08:59,336] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:08:59,554] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:08:59,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:09:07,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:09:14,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:09:21,674] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:09:29,058] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:09:36,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:09:42,840] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:09:49,673] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:09:56,436] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:10:03,151] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:10:09,924] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5540622131885244
[2022-12-07 18:10:09,925] [INFO] [runner_train_mujoco] Average state value: 0.5685310644910981
[2022-12-07 18:10:09,925] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 18:10:09,970] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.14027
[2022-12-07 18:10:10,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.04762, loss val: 0.13551
[2022-12-07 18:10:10,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.06472, loss val: 0.12054
[2022-12-07 18:10:10,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.07549, loss val: 0.11280
[2022-12-07 18:10:10,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:10:10,312] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:10:10,312] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:10:17,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:10:24,581] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:10:31,526] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:10:38,524] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:10:45,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:10:51,735] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:10:58,228] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:11:04,743] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:11:11,338] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:11:17,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6828937729657601
[2022-12-07 18:11:17,741] [INFO] [runner_train_mujoco] Average state value: 0.6155439135283232
[2022-12-07 18:11:17,741] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 18:11:17,791] [INFO] [controller] EPOCH 1 loss ppo:  -0.01052, loss val: 0.11052
[2022-12-07 18:11:17,825] [INFO] [controller] EPOCH 2 loss ppo:  -0.03986, loss val: 0.10441
[2022-12-07 18:11:17,866] [INFO] [controller] EPOCH 3 loss ppo:  -0.05735, loss val: 0.09905
[2022-12-07 18:11:17,909] [INFO] [controller] EPOCH 4 loss ppo:  -0.07086, loss val: 0.09326
[2022-12-07 18:11:17,918] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:11:18,108] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:11:18,109] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:11:24,931] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:11:31,970] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:11:38,727] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:11:45,923] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:11:52,709] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:11:59,330] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:12:05,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:12:12,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:12:19,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:12:26,113] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6377906492622022
[2022-12-07 18:12:26,113] [INFO] [runner_train_mujoco] Average state value: 0.5497856445933381
[2022-12-07 18:12:26,113] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 18:12:26,169] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.08968
[2022-12-07 18:12:26,212] [INFO] [controller] EPOCH 2 loss ppo:  -0.04250, loss val: 0.08469
[2022-12-07 18:12:26,253] [INFO] [controller] EPOCH 3 loss ppo:  -0.05849, loss val: 0.08014
[2022-12-07 18:12:26,291] [INFO] [controller] EPOCH 4 loss ppo:  -0.06866, loss val: 0.07738
[2022-12-07 18:12:26,298] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:12:26,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:12:26,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:12:33,357] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:12:40,798] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:12:47,739] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:12:54,742] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:13:04,017] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:13:10,647] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:13:17,280] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:13:24,141] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:13:30,907] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:13:37,518] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6159289128563581
[2022-12-07 18:13:37,519] [INFO] [runner_train_mujoco] Average state value: 0.5148317721411586
[2022-12-07 18:13:37,519] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 18:13:37,569] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.07073
[2022-12-07 18:13:37,610] [INFO] [controller] EPOCH 2 loss ppo:  -0.04408, loss val: 0.07117
[2022-12-07 18:13:37,652] [INFO] [controller] EPOCH 3 loss ppo:  -0.05946, loss val: 0.06681
[2022-12-07 18:13:37,694] [INFO] [controller] EPOCH 4 loss ppo:  -0.06906, loss val: 0.06764
[2022-12-07 18:13:37,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:13:37,926] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:13:37,927] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:13:45,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:13:52,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:13:59,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:14:06,895] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:14:13,832] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:14:20,711] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:14:27,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:14:34,935] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:14:42,103] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:14:48,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7939004145954168
[2022-12-07 18:14:48,906] [INFO] [runner_train_mujoco] Average state value: 0.49863854486495257
[2022-12-07 18:14:48,906] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 18:14:48,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01252, loss val: 0.05961
[2022-12-07 18:14:48,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.04164, loss val: 0.05724
[2022-12-07 18:14:49,028] [INFO] [controller] EPOCH 3 loss ppo:  -0.05627, loss val: 0.05678
[2022-12-07 18:14:49,069] [INFO] [controller] EPOCH 4 loss ppo:  -0.06832, loss val: 0.05447
[2022-12-07 18:14:49,077] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:14:49,280] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:14:49,280] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:14:57,178] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:15:04,122] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:15:10,973] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:15:18,040] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:15:24,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:15:31,623] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:15:38,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:15:45,083] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:15:51,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:15:58,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.756053059692129
[2022-12-07 18:15:58,273] [INFO] [runner_train_mujoco] Average state value: 0.5164739604167019
[2022-12-07 18:15:58,273] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 18:15:58,323] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.06496
[2022-12-07 18:15:58,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.04158, loss val: 0.06291
[2022-12-07 18:15:58,407] [INFO] [controller] EPOCH 3 loss ppo:  -0.06346, loss val: 0.06030
[2022-12-07 18:15:58,445] [INFO] [controller] EPOCH 4 loss ppo:  -0.07688, loss val: 0.05653
[2022-12-07 18:15:58,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:15:58,657] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:15:58,657] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:16:06,043] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:16:13,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:16:20,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:16:27,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:16:33,776] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:16:40,729] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:16:47,319] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:16:53,729] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:17:00,337] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:17:06,960] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0307736009535369
[2022-12-07 18:17:06,961] [INFO] [runner_train_mujoco] Average state value: 0.4654053851254285
[2022-12-07 18:17:06,961] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 18:17:07,014] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.04890
[2022-12-07 18:17:07,054] [INFO] [controller] EPOCH 2 loss ppo:  -0.04807, loss val: 0.04876
[2022-12-07 18:17:07,099] [INFO] [controller] EPOCH 3 loss ppo:  -0.06708, loss val: 0.04826
[2022-12-07 18:17:07,142] [INFO] [controller] EPOCH 4 loss ppo:  -0.07996, loss val: 0.05055
[2022-12-07 18:17:07,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:17:07,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:17:07,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:17:14,903] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:17:21,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:17:28,358] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:17:35,370] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:17:42,187] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:17:48,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:17:55,289] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:18:02,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:18:09,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:18:15,928] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7682037195993281
[2022-12-07 18:18:15,928] [INFO] [runner_train_mujoco] Average state value: 0.42960025621950626
[2022-12-07 18:18:15,928] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 18:18:15,984] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.05421
[2022-12-07 18:18:16,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.04370, loss val: 0.04913
[2022-12-07 18:18:16,072] [INFO] [controller] EPOCH 3 loss ppo:  -0.05998, loss val: 0.05158
[2022-12-07 18:18:16,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.07306, loss val: 0.05177
[2022-12-07 18:18:16,123] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:18:16,336] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:18:16,336] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:18:23,782] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:18:30,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:18:37,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:18:44,796] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:18:51,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:18:58,378] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:19:05,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:19:11,964] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:19:18,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:19:25,357] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6716787761657674
[2022-12-07 18:19:25,358] [INFO] [runner_train_mujoco] Average state value: 0.4603595365906756
[2022-12-07 18:19:25,358] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 18:19:25,412] [INFO] [controller] EPOCH 1 loss ppo:  -0.01003, loss val: 0.05447
[2022-12-07 18:19:25,456] [INFO] [controller] EPOCH 2 loss ppo:  -0.04000, loss val: 0.05316
[2022-12-07 18:19:25,502] [INFO] [controller] EPOCH 3 loss ppo:  -0.05566, loss val: 0.04962
[2022-12-07 18:19:25,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.06999, loss val: 0.04868
[2022-12-07 18:19:25,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:19:25,786] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:19:25,787] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:19:34,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:19:41,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:19:48,386] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:19:55,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:20:03,035] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:20:10,012] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:20:16,697] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:20:23,279] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:20:30,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:20:38,740] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9126246783309131
[2022-12-07 18:20:38,751] [INFO] [runner_train_mujoco] Average state value: 0.49166655870340764
[2022-12-07 18:20:38,751] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 18:20:38,877] [INFO] [controller] EPOCH 1 loss ppo:  -0.01233, loss val: 0.04635
[2022-12-07 18:20:38,941] [INFO] [controller] EPOCH 2 loss ppo:  -0.04222, loss val: 0.04661
[2022-12-07 18:20:39,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.05746, loss val: 0.04449
[2022-12-07 18:20:39,059] [INFO] [controller] EPOCH 4 loss ppo:  -0.06895, loss val: 0.04464
[2022-12-07 18:20:39,071] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:20:39,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:20:39,299] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:20:48,545] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:20:55,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:21:02,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:21:09,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:21:16,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:21:24,187] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:21:31,092] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:21:37,995] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:21:44,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:21:51,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0042856022416815
[2022-12-07 18:21:51,846] [INFO] [runner_train_mujoco] Average state value: 0.5306658066958189
[2022-12-07 18:21:51,846] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 18:21:51,892] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.05303
[2022-12-07 18:21:51,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.04340, loss val: 0.05083
[2022-12-07 18:21:51,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.06413, loss val: 0.05034
[2022-12-07 18:21:52,021] [INFO] [controller] EPOCH 4 loss ppo:  -0.07610, loss val: 0.05016
[2022-12-07 18:21:52,031] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:21:52,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:21:52,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:21:59,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:22:06,468] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:22:13,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:22:20,713] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:22:27,966] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:22:34,739] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:22:41,975] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:22:48,951] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:22:55,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:23:03,136] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9297018389747691
[2022-12-07 18:23:03,137] [INFO] [runner_train_mujoco] Average state value: 0.5421708948661884
[2022-12-07 18:23:03,137] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 18:23:03,185] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.04522
[2022-12-07 18:23:03,229] [INFO] [controller] EPOCH 2 loss ppo:  -0.04451, loss val: 0.04285
[2022-12-07 18:23:03,350] [INFO] [controller] EPOCH 3 loss ppo:  -0.06474, loss val: 0.04479
[2022-12-07 18:23:03,396] [INFO] [controller] EPOCH 4 loss ppo:  -0.07533, loss val: 0.04334
[2022-12-07 18:23:03,406] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:23:03,625] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:23:03,625] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:23:11,069] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:23:18,391] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:23:26,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:23:33,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:23:41,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:23:48,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:23:55,221] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:24:02,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:24:09,475] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:24:17,079] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.190252143555028
[2022-12-07 18:24:17,080] [INFO] [runner_train_mujoco] Average state value: 0.5359904745916525
[2022-12-07 18:24:17,080] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 18:24:17,134] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04702
[2022-12-07 18:24:17,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.04510, loss val: 0.04531
[2022-12-07 18:24:17,219] [INFO] [controller] EPOCH 3 loss ppo:  -0.06196, loss val: 0.04561
[2022-12-07 18:24:17,267] [INFO] [controller] EPOCH 4 loss ppo:  -0.07393, loss val: 0.04603
[2022-12-07 18:24:17,278] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:24:17,494] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:24:17,495] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:24:24,950] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:24:32,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:24:39,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:24:46,670] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:24:53,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:25:01,167] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:25:08,429] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:25:16,597] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:25:24,206] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:25:32,164] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.047418710236287
[2022-12-07 18:25:32,165] [INFO] [runner_train_mujoco] Average state value: 0.5127041266659896
[2022-12-07 18:25:32,165] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 18:25:32,216] [INFO] [controller] EPOCH 1 loss ppo:  -0.01009, loss val: 0.03360
[2022-12-07 18:25:32,265] [INFO] [controller] EPOCH 2 loss ppo:  -0.04021, loss val: 0.03397
[2022-12-07 18:25:32,309] [INFO] [controller] EPOCH 3 loss ppo:  -0.06171, loss val: 0.04049
[2022-12-07 18:25:32,356] [INFO] [controller] EPOCH 4 loss ppo:  -0.07351, loss val: 0.03332
[2022-12-07 18:25:32,366] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:25:32,562] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:25:32,563] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:25:39,809] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:25:47,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:25:55,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:26:03,557] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:26:10,470] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:26:17,312] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:26:23,966] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:26:30,608] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:26:37,123] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:26:44,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1716613730172456
[2022-12-07 18:26:44,447] [INFO] [runner_train_mujoco] Average state value: 0.5102320578694344
[2022-12-07 18:26:44,448] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 18:26:44,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.03001
[2022-12-07 18:26:44,536] [INFO] [controller] EPOCH 2 loss ppo:  -0.04494, loss val: 0.03067
[2022-12-07 18:26:44,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.06332, loss val: 0.03540
[2022-12-07 18:26:44,618] [INFO] [controller] EPOCH 4 loss ppo:  -0.07478, loss val: 0.02948
[2022-12-07 18:26:44,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:26:44,856] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:26:44,857] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:26:53,899] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:27:00,978] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:27:08,166] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:27:15,375] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:27:22,435] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:27:29,309] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:27:36,032] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:27:43,163] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:27:49,838] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:27:56,920] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4021909695413317
[2022-12-07 18:27:56,921] [INFO] [runner_train_mujoco] Average state value: 0.5124019875327747
[2022-12-07 18:27:56,921] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 18:27:56,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04902
[2022-12-07 18:27:57,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.03812, loss val: 0.05069
[2022-12-07 18:27:57,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.05824, loss val: 0.04685
[2022-12-07 18:27:57,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.07500, loss val: 0.04064
[2022-12-07 18:27:57,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:27:57,306] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:27:57,306] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:28:04,395] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:28:11,360] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:28:18,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:28:24,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:28:31,734] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:28:38,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:28:45,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:28:52,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:28:59,502] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:29:06,681] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2737249264287578
[2022-12-07 18:29:06,681] [INFO] [runner_train_mujoco] Average state value: 0.5856731745600701
[2022-12-07 18:29:06,681] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 18:29:06,729] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.04721
[2022-12-07 18:29:06,770] [INFO] [controller] EPOCH 2 loss ppo:  -0.04337, loss val: 0.04866
[2022-12-07 18:29:06,806] [INFO] [controller] EPOCH 3 loss ppo:  -0.06314, loss val: 0.04927
[2022-12-07 18:29:06,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.07667, loss val: 0.05059
[2022-12-07 18:29:06,851] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:29:07,044] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:29:07,044] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:29:14,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:29:20,714] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:29:28,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:29:36,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:29:43,645] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:29:50,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:29:57,378] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:30:04,180] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:30:11,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:30:18,574] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1988724421641546
[2022-12-07 18:30:18,575] [INFO] [runner_train_mujoco] Average state value: 0.5931907637218633
[2022-12-07 18:30:18,575] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 18:30:18,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.04146
[2022-12-07 18:30:18,667] [INFO] [controller] EPOCH 2 loss ppo:  -0.04466, loss val: 0.04062
[2022-12-07 18:30:18,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.06634, loss val: 0.03928
[2022-12-07 18:30:18,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.08140, loss val: 0.03747
[2022-12-07 18:30:18,756] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:30:18,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:30:18,969] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:30:25,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:30:32,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:30:39,771] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:30:47,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:30:54,590] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:31:01,509] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:31:08,533] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:31:15,737] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:31:22,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:31:30,474] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4239084694825677
[2022-12-07 18:31:30,474] [INFO] [runner_train_mujoco] Average state value: 0.5363043149113655
[2022-12-07 18:31:30,475] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 18:31:30,527] [INFO] [controller] EPOCH 1 loss ppo:  -0.01255, loss val: 0.04071
[2022-12-07 18:31:30,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.04153, loss val: 0.04252
[2022-12-07 18:31:30,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.06160, loss val: 0.04237
[2022-12-07 18:31:30,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.07640, loss val: 0.04282
[2022-12-07 18:31:30,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:31:30,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:31:30,880] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:31:38,613] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:31:45,907] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:31:52,825] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:31:59,716] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:32:06,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:32:14,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:32:21,980] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:32:30,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:32:36,888] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:32:44,616] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5248116980452502
[2022-12-07 18:32:44,616] [INFO] [runner_train_mujoco] Average state value: 0.5112625047465166
[2022-12-07 18:32:44,617] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 18:32:44,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01260, loss val: 0.04657
[2022-12-07 18:32:44,716] [INFO] [controller] EPOCH 2 loss ppo:  -0.03704, loss val: 0.04559
[2022-12-07 18:32:44,758] [INFO] [controller] EPOCH 3 loss ppo:  -0.05854, loss val: 0.04519
[2022-12-07 18:32:44,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.07435, loss val: 0.04285
[2022-12-07 18:32:44,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:32:45,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:32:45,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:32:52,391] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:32:59,325] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:33:06,145] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:33:13,719] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:33:20,269] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:33:27,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:33:33,866] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:33:40,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:33:46,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:33:53,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4007198152034377
[2022-12-07 18:33:53,505] [INFO] [runner_train_mujoco] Average state value: 0.5498707629938921
[2022-12-07 18:33:53,505] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 18:33:53,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01598, loss val: 0.04800
[2022-12-07 18:33:53,593] [INFO] [controller] EPOCH 2 loss ppo:  -0.04176, loss val: 0.04814
[2022-12-07 18:33:53,632] [INFO] [controller] EPOCH 3 loss ppo:  -0.05600, loss val: 0.04761
[2022-12-07 18:33:53,675] [INFO] [controller] EPOCH 4 loss ppo:  -0.06921, loss val: 0.04906
[2022-12-07 18:33:53,684] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:33:53,889] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:33:53,890] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:34:00,622] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:34:07,327] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:34:13,578] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:34:20,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:34:27,164] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:34:36,115] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:34:45,467] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:34:53,758] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:35:01,518] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:35:11,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.536053762989961
[2022-12-07 18:35:11,527] [INFO] [runner_train_mujoco] Average state value: 0.5462203610340755
[2022-12-07 18:35:11,528] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 18:35:11,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.03502
[2022-12-07 18:35:11,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.04100, loss val: 0.03335
[2022-12-07 18:35:11,658] [INFO] [controller] EPOCH 3 loss ppo:  -0.05930, loss val: 0.03376
[2022-12-07 18:35:11,704] [INFO] [controller] EPOCH 4 loss ppo:  -0.07564, loss val: 0.03496
[2022-12-07 18:35:11,713] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:35:11,931] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:35:11,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:35:18,688] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:35:25,300] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:35:32,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:35:39,024] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:35:45,929] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:35:52,685] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:35:59,514] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:36:06,289] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:36:13,193] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:36:20,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.842261171577776
[2022-12-07 18:36:20,219] [INFO] [runner_train_mujoco] Average state value: 0.48972115564346314
[2022-12-07 18:36:20,219] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 18:36:20,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.03957
[2022-12-07 18:36:20,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.04054, loss val: 0.04007
[2022-12-07 18:36:20,353] [INFO] [controller] EPOCH 3 loss ppo:  -0.05893, loss val: 0.04007
[2022-12-07 18:36:20,393] [INFO] [controller] EPOCH 4 loss ppo:  -0.07326, loss val: 0.04088
[2022-12-07 18:36:20,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:36:20,605] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:36:20,605] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:36:27,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:36:34,113] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:36:41,204] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:36:47,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:36:54,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:37:01,648] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:37:08,693] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:37:15,953] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:37:22,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:37:30,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6627298826583456
[2022-12-07 18:37:30,170] [INFO] [runner_train_mujoco] Average state value: 0.45844998275240256
[2022-12-07 18:37:30,170] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 18:37:30,224] [INFO] [controller] EPOCH 1 loss ppo:  -0.01521, loss val: 0.08130
[2022-12-07 18:37:30,266] [INFO] [controller] EPOCH 2 loss ppo:  -0.03464, loss val: 0.07479
[2022-12-07 18:37:30,303] [INFO] [controller] EPOCH 3 loss ppo:  -0.05215, loss val: 0.06624
[2022-12-07 18:37:30,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.06161, loss val: 0.05938
[2022-12-07 18:37:30,356] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:37:30,563] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:37:30,563] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:37:37,692] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:37:45,361] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:37:52,236] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:37:59,288] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:38:06,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:38:14,097] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:38:21,439] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:38:29,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:38:37,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:38:46,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9196032638939968
[2022-12-07 18:38:46,026] [INFO] [runner_train_mujoco] Average state value: 0.5355836169769367
[2022-12-07 18:38:46,026] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 18:38:46,079] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.03792
[2022-12-07 18:38:46,123] [INFO] [controller] EPOCH 2 loss ppo:  -0.04317, loss val: 0.04032
[2022-12-07 18:38:46,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.06182, loss val: 0.04398
[2022-12-07 18:38:46,207] [INFO] [controller] EPOCH 4 loss ppo:  -0.07318, loss val: 0.04539
[2022-12-07 18:38:46,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:38:46,430] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:38:46,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:38:54,075] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:39:02,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:39:10,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:39:18,076] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:39:25,306] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:39:28,182] [WARNING] [core] Too many contacts. Either the arena memory is full, or nconmax is specified and is exceeded. Increase arena memory allocation, or increase/remove nconmax. (ncon = 150) Time = 11.3740.
[2022-12-07 18:39:32,783] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:39:40,587] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:39:48,291] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:39:55,378] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:40:03,766] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7757253627785183
[2022-12-07 18:40:03,766] [INFO] [runner_train_mujoco] Average state value: 0.5544494616786639
[2022-12-07 18:40:03,767] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 18:40:03,816] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.05123
[2022-12-07 18:40:03,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.03951, loss val: 0.04867
[2022-12-07 18:40:03,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.05743, loss val: 0.04663
[2022-12-07 18:40:03,964] [INFO] [controller] EPOCH 4 loss ppo:  -0.07210, loss val: 0.04776
[2022-12-07 18:40:03,985] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:40:04,199] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:40:04,199] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:40:12,878] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:40:20,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:40:27,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:40:35,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:40:43,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:40:50,887] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:40:59,536] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:41:07,026] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:41:14,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:41:22,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8090884741247428
[2022-12-07 18:41:22,072] [INFO] [runner_train_mujoco] Average state value: 0.4999200245539347
[2022-12-07 18:41:22,072] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 18:41:22,121] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.05590
[2022-12-07 18:41:22,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.03392, loss val: 0.05318
[2022-12-07 18:41:22,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.05041, loss val: 0.05589
[2022-12-07 18:41:22,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.06104, loss val: 0.05310
[2022-12-07 18:41:22,265] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:41:22,486] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:41:22,486] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:41:30,311] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:41:38,055] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:41:45,809] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:41:54,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:42:02,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:42:10,295] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:42:18,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:42:27,412] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:42:35,044] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:42:42,128] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1288838669425365
[2022-12-07 18:42:42,129] [INFO] [runner_train_mujoco] Average state value: 0.45903231161460284
[2022-12-07 18:42:42,129] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 18:42:42,196] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.08053
[2022-12-07 18:42:42,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.04089, loss val: 0.08009
[2022-12-07 18:42:42,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.05874, loss val: 0.07798
[2022-12-07 18:42:42,372] [INFO] [controller] EPOCH 4 loss ppo:  -0.07284, loss val: 0.07837
[2022-12-07 18:42:42,383] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:42:42,628] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:42:42,628] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:42:50,441] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:42:57,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:43:05,050] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:43:12,444] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:43:20,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:43:29,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:43:37,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:43:45,220] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:43:54,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:44:03,716] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9330185903239545
[2022-12-07 18:44:03,717] [INFO] [runner_train_mujoco] Average state value: 0.5464219699005286
[2022-12-07 18:44:03,717] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 18:44:03,772] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.05073
[2022-12-07 18:44:03,819] [INFO] [controller] EPOCH 2 loss ppo:  -0.03517, loss val: 0.05075
[2022-12-07 18:44:03,946] [INFO] [controller] EPOCH 3 loss ppo:  -0.05190, loss val: 0.05137
[2022-12-07 18:44:03,993] [INFO] [controller] EPOCH 4 loss ppo:  -0.06374, loss val: 0.04971
[2022-12-07 18:44:04,002] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:44:04,225] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:44:04,225] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:44:13,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:44:23,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:44:33,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:44:44,138] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:44:53,424] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:45:03,121] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:45:13,586] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:45:23,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:45:33,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:45:43,607] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.082133570754544
[2022-12-07 18:45:43,607] [INFO] [runner_train_mujoco] Average state value: 0.539894377698501
[2022-12-07 18:45:43,608] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 18:45:43,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.04284
[2022-12-07 18:45:43,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.03998, loss val: 0.03963
[2022-12-07 18:45:43,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.05782, loss val: 0.03987
[2022-12-07 18:45:43,915] [INFO] [controller] EPOCH 4 loss ppo:  -0.07490, loss val: 0.03991
[2022-12-07 18:45:43,927] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:45:44,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:45:44,184] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:45:55,172] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:46:03,801] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:46:13,657] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:46:21,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:46:28,892] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:46:37,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:46:44,492] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:46:54,338] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:47:02,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:47:09,644] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4309626284515966
[2022-12-07 18:47:09,644] [INFO] [runner_train_mujoco] Average state value: 0.5056422045292954
[2022-12-07 18:47:09,645] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 18:47:09,732] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.03502
[2022-12-07 18:47:09,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.03487, loss val: 0.03363
[2022-12-07 18:47:10,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.05440, loss val: 0.03318
[2022-12-07 18:47:10,127] [INFO] [controller] EPOCH 4 loss ppo:  -0.07048, loss val: 0.03297
[2022-12-07 18:47:10,143] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:47:10,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:47:10,481] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:47:19,041] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:47:25,980] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:47:34,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:47:41,756] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:47:49,234] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:47:55,930] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:48:02,892] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:48:09,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:48:16,847] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:48:23,710] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.826286018101998
[2022-12-07 18:48:23,710] [INFO] [runner_train_mujoco] Average state value: 0.50670628580451
[2022-12-07 18:48:23,710] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 18:48:23,758] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.04258
[2022-12-07 18:48:23,799] [INFO] [controller] EPOCH 2 loss ppo:  -0.03698, loss val: 0.04234
[2022-12-07 18:48:23,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.05704, loss val: 0.04161
[2022-12-07 18:48:23,889] [INFO] [controller] EPOCH 4 loss ppo:  -0.07538, loss val: 0.04115
[2022-12-07 18:48:23,899] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:48:24,084] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:48:24,085] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:48:31,318] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:48:38,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:48:45,995] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:48:52,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:48:59,197] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:49:05,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:49:10,742] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:49:16,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:49:22,412] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:49:28,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6822188253608545
[2022-12-07 18:49:28,257] [INFO] [runner_train_mujoco] Average state value: 0.4770785630469521
[2022-12-07 18:49:28,257] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 18:49:28,292] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.04698
[2022-12-07 18:49:28,319] [INFO] [controller] EPOCH 2 loss ppo:  -0.03614, loss val: 0.04555
[2022-12-07 18:49:28,347] [INFO] [controller] EPOCH 3 loss ppo:  -0.05366, loss val: 0.04436
[2022-12-07 18:49:28,375] [INFO] [controller] EPOCH 4 loss ppo:  -0.06921, loss val: 0.04561
[2022-12-07 18:49:28,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:49:28,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:49:28,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:49:34,515] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:49:40,274] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:49:46,145] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:49:51,774] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:49:58,229] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:50:03,943] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:50:09,899] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:50:16,318] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:50:22,811] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:50:28,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.787200243244505
[2022-12-07 18:50:28,851] [INFO] [runner_train_mujoco] Average state value: 0.4541651610682408
[2022-12-07 18:50:28,851] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 18:50:28,891] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.05301
[2022-12-07 18:50:28,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.03175, loss val: 0.04649
[2022-12-07 18:50:28,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.05227, loss val: 0.04587
[2022-12-07 18:50:28,996] [INFO] [controller] EPOCH 4 loss ppo:  -0.06745, loss val: 0.04548
[2022-12-07 18:50:29,005] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:50:29,162] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:50:29,162] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:50:34,889] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:50:41,165] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:50:47,306] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:50:53,622] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:50:59,466] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:51:05,551] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:51:11,690] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:51:17,958] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:51:24,618] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:51:30,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9055108294439993
[2022-12-07 18:51:30,507] [INFO] [runner_train_mujoco] Average state value: 0.4452204213875035
[2022-12-07 18:51:30,507] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 18:51:30,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.05473
[2022-12-07 18:51:30,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.03711, loss val: 0.05213
[2022-12-07 18:51:30,611] [INFO] [controller] EPOCH 3 loss ppo:  -0.06018, loss val: 0.05150
[2022-12-07 18:51:30,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.07380, loss val: 0.05424
[2022-12-07 18:51:30,655] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:51:30,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:51:30,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:51:36,699] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:51:42,343] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:51:48,069] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:51:53,797] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:52:00,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:52:06,365] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:52:12,806] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:52:18,754] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:52:24,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:52:30,356] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1037001053015225
[2022-12-07 18:52:30,356] [INFO] [runner_train_mujoco] Average state value: 0.49072964580853784
[2022-12-07 18:52:30,356] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 18:52:30,406] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.03697
[2022-12-07 18:52:30,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.03419, loss val: 0.03938
[2022-12-07 18:52:30,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.05273, loss val: 0.03861
[2022-12-07 18:52:30,507] [INFO] [controller] EPOCH 4 loss ppo:  -0.06580, loss val: 0.03714
[2022-12-07 18:52:30,512] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:52:30,705] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:52:30,705] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:52:36,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:52:43,070] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:52:49,001] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:52:54,849] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:53:00,722] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:53:06,565] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:53:12,243] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:53:18,025] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:53:23,891] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:53:29,793] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1204617276886557
[2022-12-07 18:53:29,793] [INFO] [runner_train_mujoco] Average state value: 0.5074043099669119
[2022-12-07 18:53:29,793] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 18:53:29,830] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.04448
[2022-12-07 18:53:29,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.03594, loss val: 0.04435
[2022-12-07 18:53:29,908] [INFO] [controller] EPOCH 3 loss ppo:  -0.05357, loss val: 0.04469
[2022-12-07 18:53:29,948] [INFO] [controller] EPOCH 4 loss ppo:  -0.06892, loss val: 0.04467
[2022-12-07 18:53:29,958] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:53:30,121] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:53:30,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:53:36,004] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:53:41,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:53:47,639] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:53:53,357] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:53:59,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:54:04,765] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:54:10,393] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:54:16,094] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:54:21,704] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:54:27,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9161692043223058
[2022-12-07 18:54:27,297] [INFO] [runner_train_mujoco] Average state value: 0.5163063571254412
[2022-12-07 18:54:27,297] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 18:54:27,332] [INFO] [controller] EPOCH 1 loss ppo:  -0.01593, loss val: 0.04470
[2022-12-07 18:54:27,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.03960, loss val: 0.04286
[2022-12-07 18:54:27,399] [INFO] [controller] EPOCH 3 loss ppo:  -0.05558, loss val: 0.04253
[2022-12-07 18:54:27,431] [INFO] [controller] EPOCH 4 loss ppo:  -0.06792, loss val: 0.04252
[2022-12-07 18:54:27,437] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:54:27,566] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:54:27,566] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:54:33,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:54:39,710] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:54:45,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:54:51,149] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:54:56,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:55:02,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:55:07,905] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:55:13,484] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:55:18,961] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:55:24,522] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.319241442124438
[2022-12-07 18:55:24,522] [INFO] [runner_train_mujoco] Average state value: 0.4757866073896488
[2022-12-07 18:55:24,522] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 18:55:24,563] [INFO] [controller] EPOCH 1 loss ppo:  -0.01561, loss val: 0.07074
[2022-12-07 18:55:24,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.03386, loss val: 0.07000
[2022-12-07 18:55:24,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.04942, loss val: 0.06883
[2022-12-07 18:55:24,671] [INFO] [controller] EPOCH 4 loss ppo:  -0.06174, loss val: 0.06820
[2022-12-07 18:55:24,680] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:55:24,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:55:24,814] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:55:30,368] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:55:36,029] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:55:41,566] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:55:47,055] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:55:52,487] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:55:58,009] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:56:03,489] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:56:08,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:56:14,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:56:19,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.764906809523697
[2022-12-07 18:56:19,837] [INFO] [runner_train_mujoco] Average state value: 0.47722602395713337
[2022-12-07 18:56:19,837] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 18:56:19,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.05000
[2022-12-07 18:56:19,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.03356, loss val: 0.05053
[2022-12-07 18:56:19,940] [INFO] [controller] EPOCH 3 loss ppo:  -0.05124, loss val: 0.05006
[2022-12-07 18:56:19,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.06684, loss val: 0.04959
[2022-12-07 18:56:19,975] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:56:20,125] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:56:20,125] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:56:25,762] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:56:31,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:56:36,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:56:42,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:56:48,145] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:56:53,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:56:59,389] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:57:04,883] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:57:10,638] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:57:16,628] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6178949948778523
[2022-12-07 18:57:16,628] [INFO] [runner_train_mujoco] Average state value: 0.45692751666406795
[2022-12-07 18:57:16,628] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 18:57:16,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.06380
[2022-12-07 18:57:16,697] [INFO] [controller] EPOCH 2 loss ppo:  -0.03249, loss val: 0.06327
[2022-12-07 18:57:16,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.04852, loss val: 0.06601
[2022-12-07 18:57:16,764] [INFO] [controller] EPOCH 4 loss ppo:  -0.06217, loss val: 0.06427
[2022-12-07 18:57:16,770] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:57:16,908] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:57:16,909] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:57:22,472] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:57:28,074] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:57:33,595] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:57:39,676] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:57:45,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:57:50,770] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:57:56,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:58:01,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:58:07,439] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:58:12,959] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.383079728800228
[2022-12-07 18:58:12,960] [INFO] [runner_train_mujoco] Average state value: 0.46815903601050374
[2022-12-07 18:58:12,960] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 18:58:12,993] [INFO] [controller] EPOCH 1 loss ppo:  -0.01533, loss val: 0.03912
[2022-12-07 18:58:13,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.03243, loss val: 0.03932
[2022-12-07 18:58:13,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.04741, loss val: 0.03921
[2022-12-07 18:58:13,074] [INFO] [controller] EPOCH 4 loss ppo:  -0.05618, loss val: 0.03904
[2022-12-07 18:58:13,079] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:58:13,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:58:13,220] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:58:18,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:58:24,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:58:29,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:58:35,423] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:58:41,034] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:58:46,552] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:58:51,952] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:58:57,747] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:59:03,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:59:08,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.492093255615715
[2022-12-07 18:59:08,718] [INFO] [runner_train_mujoco] Average state value: 0.45650824197257556
[2022-12-07 18:59:08,719] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 18:59:08,754] [INFO] [controller] EPOCH 1 loss ppo:  -0.01575, loss val: 0.05084
[2022-12-07 18:59:08,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.03335, loss val: 0.05064
[2022-12-07 18:59:08,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.04916, loss val: 0.05079
[2022-12-07 18:59:08,841] [INFO] [controller] EPOCH 4 loss ppo:  -0.06181, loss val: 0.04993
[2022-12-07 18:59:08,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:59:08,995] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:59:08,996] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:59:14,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:59:20,320] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:59:25,895] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:59:31,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:59:37,205] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:59:42,681] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:59:48,165] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:59:53,629] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:59:59,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:00:04,716] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3582182547239947
[2022-12-07 19:00:04,716] [INFO] [runner_train_mujoco] Average state value: 0.48898202768961596
[2022-12-07 19:00:04,716] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 19:00:04,766] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.04321
[2022-12-07 19:00:04,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.02758, loss val: 0.04462
[2022-12-07 19:00:04,827] [INFO] [controller] EPOCH 3 loss ppo:  -0.04579, loss val: 0.04267
[2022-12-07 19:00:04,853] [INFO] [controller] EPOCH 4 loss ppo:  -0.05926, loss val: 0.04345
[2022-12-07 19:00:04,858] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:00:04,999] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:00:05,000] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:00:10,562] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:00:16,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:00:21,568] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:00:26,998] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:00:32,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:00:37,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:00:42,567] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:00:47,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:00:52,753] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:00:57,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2955805448039897
[2022-12-07 19:00:57,931] [INFO] [runner_train_mujoco] Average state value: 0.48484263133257627
[2022-12-07 19:00:57,931] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 19:00:57,963] [INFO] [controller] EPOCH 1 loss ppo:  -0.01489, loss val: 0.04946
[2022-12-07 19:00:57,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.02665, loss val: 0.04913
[2022-12-07 19:00:58,012] [INFO] [controller] EPOCH 3 loss ppo:  -0.04108, loss val: 0.04750
[2022-12-07 19:00:58,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.05183, loss val: 0.04543
[2022-12-07 19:00:58,040] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:00:58,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:00:58,149] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:01:03,408] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:01:08,531] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:01:13,730] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:01:18,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:01:24,073] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:01:29,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:01:34,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:01:39,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:01:44,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:01:49,890] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.011254593326813
[2022-12-07 19:01:49,890] [INFO] [runner_train_mujoco] Average state value: 0.516185899366935
[2022-12-07 19:01:49,890] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 19:01:49,922] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.03656
[2022-12-07 19:01:49,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.02627, loss val: 0.03621
[2022-12-07 19:01:50,037] [INFO] [controller] EPOCH 3 loss ppo:  -0.04036, loss val: 0.03631
[2022-12-07 19:01:50,070] [INFO] [controller] EPOCH 4 loss ppo:  -0.05051, loss val: 0.03595
[2022-12-07 19:01:50,078] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:01:50,175] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:01:50,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:01:55,372] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:02:00,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:02:05,889] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:02:10,878] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:02:15,862] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:02:21,032] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:02:26,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:02:31,101] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:02:36,122] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:02:41,222] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.229916169095153
[2022-12-07 19:02:41,222] [INFO] [runner_train_mujoco] Average state value: 0.5208591182231903
[2022-12-07 19:02:41,223] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 19:02:41,264] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04095
[2022-12-07 19:02:41,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.02641, loss val: 0.04059
[2022-12-07 19:02:41,322] [INFO] [controller] EPOCH 3 loss ppo:  -0.04007, loss val: 0.04205
[2022-12-07 19:02:41,347] [INFO] [controller] EPOCH 4 loss ppo:  -0.05191, loss val: 0.03964
[2022-12-07 19:02:41,352] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:02:41,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:02:41,455] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:02:46,639] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:02:51,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:02:56,859] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:03:02,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:03:07,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:03:12,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:03:17,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:03:22,184] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:03:27,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:03:32,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.490900928146728
[2022-12-07 19:03:32,459] [INFO] [runner_train_mujoco] Average state value: 0.5079128177165985
[2022-12-07 19:03:32,459] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 19:03:32,498] [INFO] [controller] EPOCH 1 loss ppo:  -0.01593, loss val: 0.03752
[2022-12-07 19:03:32,526] [INFO] [controller] EPOCH 2 loss ppo:  -0.03156, loss val: 0.03239
[2022-12-07 19:03:32,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.04316, loss val: 0.03203
[2022-12-07 19:03:32,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.05160, loss val: 0.03137
[2022-12-07 19:03:32,580] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:03:32,690] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:03:32,691] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:03:37,956] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:03:43,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:03:48,294] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:03:53,224] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:03:58,269] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:04:03,379] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:04:08,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:04:13,542] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:04:18,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:04:23,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.177558665436375
[2022-12-07 19:04:23,833] [INFO] [runner_train_mujoco] Average state value: 0.4852025038202603
[2022-12-07 19:04:23,833] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 19:04:23,865] [INFO] [controller] EPOCH 1 loss ppo:  -0.01498, loss val: 0.04226
[2022-12-07 19:04:23,890] [INFO] [controller] EPOCH 2 loss ppo:  -0.02604, loss val: 0.04467
[2022-12-07 19:04:23,917] [INFO] [controller] EPOCH 3 loss ppo:  -0.03897, loss val: 0.04397
[2022-12-07 19:04:23,956] [INFO] [controller] EPOCH 4 loss ppo:  -0.04994, loss val: 0.04243
[2022-12-07 19:04:23,964] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:04:24,102] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:04:24,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:04:29,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:04:34,727] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:04:39,812] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:04:45,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:04:50,201] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:04:56,010] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:05:01,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:05:06,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:05:11,654] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:05:16,749] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.226850263138689
[2022-12-07 19:05:16,750] [INFO] [runner_train_mujoco] Average state value: 0.33771829929202796
[2022-12-07 19:05:16,750] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 19:05:16,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.13587
[2022-12-07 19:05:16,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.01987, loss val: 0.13524
[2022-12-07 19:05:16,835] [INFO] [controller] EPOCH 3 loss ppo:  -0.02876, loss val: 0.13417
[2022-12-07 19:05:16,872] [INFO] [controller] EPOCH 4 loss ppo:  -0.03945, loss val: 0.13240
[2022-12-07 19:05:16,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:05:16,997] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:05:16,998] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:05:22,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:05:27,375] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:05:32,470] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:05:37,550] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:05:42,736] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:05:47,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:05:53,082] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:05:58,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:06:03,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:06:08,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.359176999302713
[2022-12-07 19:06:08,565] [INFO] [runner_train_mujoco] Average state value: 0.4697781727686524
[2022-12-07 19:06:08,565] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 19:06:08,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.03085
[2022-12-07 19:06:08,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.02181, loss val: 0.03222
[2022-12-07 19:06:08,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.03389, loss val: 0.03121
[2022-12-07 19:06:08,675] [INFO] [controller] EPOCH 4 loss ppo:  -0.04376, loss val: 0.03406
[2022-12-07 19:06:08,681] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:06:08,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:06:08,801] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:06:14,136] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:06:19,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:06:24,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:06:29,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:06:34,729] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:06:39,827] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:06:44,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:06:49,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:06:54,900] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:07:00,162] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.461154756794139
[2022-12-07 19:07:00,162] [INFO] [runner_train_mujoco] Average state value: 0.471038273682197
[2022-12-07 19:07:00,162] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 19:07:00,198] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04861
[2022-12-07 19:07:00,230] [INFO] [controller] EPOCH 2 loss ppo:  -0.02145, loss val: 0.04832
[2022-12-07 19:07:00,255] [INFO] [controller] EPOCH 3 loss ppo:  -0.03127, loss val: 0.04815
[2022-12-07 19:07:00,292] [INFO] [controller] EPOCH 4 loss ppo:  -0.04123, loss val: 0.04806
[2022-12-07 19:07:00,300] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:07:00,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:07:00,421] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:07:06,607] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:07:12,541] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:07:18,113] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:07:23,174] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:07:28,159] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:07:33,232] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:07:38,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:07:43,727] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:07:48,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:07:53,987] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.827613270851292
[2022-12-07 19:07:53,987] [INFO] [runner_train_mujoco] Average state value: 0.48181418949613963
[2022-12-07 19:07:53,987] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 19:07:54,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.03681
[2022-12-07 19:07:54,045] [INFO] [controller] EPOCH 2 loss ppo:  -0.02109, loss val: 0.03896
[2022-12-07 19:07:54,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.03075, loss val: 0.03673
[2022-12-07 19:07:54,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.03908, loss val: 0.03980
[2022-12-07 19:07:54,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:07:54,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:07:54,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:07:59,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:08:04,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:08:10,110] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:08:15,231] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:08:20,356] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:08:25,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:08:30,535] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:08:35,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:08:40,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:08:45,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.3574427344449855
[2022-12-07 19:08:45,979] [INFO] [runner_train_mujoco] Average state value: 0.4396563790539901
[2022-12-07 19:08:45,979] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 19:08:46,011] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.06515
[2022-12-07 19:08:46,036] [INFO] [controller] EPOCH 2 loss ppo:  -0.01716, loss val: 0.06497
[2022-12-07 19:08:46,062] [INFO] [controller] EPOCH 3 loss ppo:  -0.02327, loss val: 0.06471
[2022-12-07 19:08:46,089] [INFO] [controller] EPOCH 4 loss ppo:  -0.03079, loss val: 0.06537
[2022-12-07 19:08:46,094] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:08:46,213] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:08:46,213] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:08:51,601] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:08:56,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:09:02,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:09:07,353] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:09:12,673] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:09:17,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:09:22,916] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:09:28,152] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:09:33,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:09:38,539] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.751203950904789
[2022-12-07 19:09:38,539] [INFO] [runner_train_mujoco] Average state value: 0.46637399299442767
[2022-12-07 19:09:38,539] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 19:09:38,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.05443
[2022-12-07 19:09:38,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.01747, loss val: 0.05599
[2022-12-07 19:09:38,626] [INFO] [controller] EPOCH 3 loss ppo:  -0.02238, loss val: 0.05576
[2022-12-07 19:09:38,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.02858, loss val: 0.05535
[2022-12-07 19:09:38,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:09:38,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 19:09:38,772] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 19:09:44,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 19:09:49,441] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 19:09:54,603] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 19:09:59,682] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 19:10:05,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:10:10,355] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:10:15,461] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:10:20,729] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:10:25,927] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:10:31,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.457510692517905
[2022-12-07 19:10:31,256] [INFO] [runner_train_mujoco] Average state value: 0.39452837010224656
[2022-12-07 19:10:31,256] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 19:10:31,298] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.09327
[2022-12-07 19:10:31,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.01573, loss val: 0.09394
[2022-12-07 19:10:31,351] [INFO] [controller] EPOCH 3 loss ppo:  -0.01793, loss val: 0.09049
[2022-12-07 19:10:31,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.02041, loss val: 0.09405
[2022-12-07 19:10:31,382] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:10:31,448] [INFO] [optimize] Finished learning.
