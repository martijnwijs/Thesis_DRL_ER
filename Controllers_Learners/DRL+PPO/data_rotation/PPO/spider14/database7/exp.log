[2022-12-07 06:30:02,745] [INFO] [optimize] Starting learning
[2022-12-07 06:30:02,760] [INFO] [optimize] Starting learning process..
[2022-12-07 06:30:02,869] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:30:02,870] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:30:13,058] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:30:21,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:30:29,463] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:30:37,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:30:47,824] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:30:56,043] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:31:04,327] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:31:12,412] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:31:20,727] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:31:28,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4991745231487169
[2022-12-07 06:31:28,040] [INFO] [runner_train_mujoco] Average state value: 0.03374972731247544
[2022-12-07 06:31:28,040] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 06:31:28,097] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.49896
[2022-12-07 06:31:28,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.05835, loss val: 0.42434
[2022-12-07 06:31:28,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.07560, loss val: 0.38976
[2022-12-07 06:31:28,237] [INFO] [controller] EPOCH 4 loss ppo:  -0.08657, loss val: 0.34162
[2022-12-07 06:31:28,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:31:28,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:31:28,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:31:37,072] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:31:45,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:31:53,091] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:32:01,620] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:32:09,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:32:18,500] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:32:26,988] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:32:34,825] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:32:42,593] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:32:50,647] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.43053770645519396
[2022-12-07 06:32:50,647] [INFO] [runner_train_mujoco] Average state value: 0.1922748900093138
[2022-12-07 06:32:50,647] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 06:32:50,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.21245
[2022-12-07 06:32:50,745] [INFO] [controller] EPOCH 2 loss ppo:  -0.05773, loss val: 0.18473
[2022-12-07 06:32:50,796] [INFO] [controller] EPOCH 3 loss ppo:  -0.07867, loss val: 0.16042
[2022-12-07 06:32:50,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.08833, loss val: 0.13875
[2022-12-07 06:32:50,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:32:51,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:32:51,063] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:32:59,571] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:33:07,760] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:33:16,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:33:24,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:33:33,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:33:41,374] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:33:49,353] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:33:56,976] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:34:04,722] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:34:13,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.740689323297368
[2022-12-07 06:34:13,070] [INFO] [runner_train_mujoco] Average state value: 0.3616247916178157
[2022-12-07 06:34:13,070] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 06:34:13,123] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.12267
[2022-12-07 06:34:13,178] [INFO] [controller] EPOCH 2 loss ppo:  -0.04916, loss val: 0.11339
[2022-12-07 06:34:13,224] [INFO] [controller] EPOCH 3 loss ppo:  -0.06677, loss val: 0.09870
[2022-12-07 06:34:13,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.07897, loss val: 0.09667
[2022-12-07 06:34:13,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:34:13,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:34:13,493] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:34:22,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:34:30,184] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:34:38,223] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:34:46,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:34:54,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:35:02,529] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:35:10,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:35:18,910] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:35:26,969] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:35:34,678] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7194363726610444
[2022-12-07 06:35:34,678] [INFO] [runner_train_mujoco] Average state value: 0.49224571445087595
[2022-12-07 06:35:34,679] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 06:35:34,735] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.09459
[2022-12-07 06:35:34,780] [INFO] [controller] EPOCH 2 loss ppo:  -0.04784, loss val: 0.08933
[2022-12-07 06:35:34,828] [INFO] [controller] EPOCH 3 loss ppo:  -0.07050, loss val: 0.07700
[2022-12-07 06:35:34,875] [INFO] [controller] EPOCH 4 loss ppo:  -0.08050, loss val: 0.06924
[2022-12-07 06:35:34,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:35:35,095] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:35:35,095] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:35:43,389] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:35:51,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:35:58,874] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:36:07,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:36:16,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:36:24,531] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:36:32,192] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:36:40,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:36:48,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:36:56,048] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5631734755335613
[2022-12-07 06:36:56,048] [INFO] [runner_train_mujoco] Average state value: 0.6027371437121183
[2022-12-07 06:36:56,048] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 06:36:56,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.07898
[2022-12-07 06:36:56,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.04283, loss val: 0.07869
[2022-12-07 06:36:56,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.05522, loss val: 0.07435
[2022-12-07 06:36:56,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.06692, loss val: 0.07040
[2022-12-07 06:36:56,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:36:56,498] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:36:56,499] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:37:04,174] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:37:13,022] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:37:21,690] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:37:29,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:37:37,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:37:45,929] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:37:53,711] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:38:01,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:38:10,061] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:38:18,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6329217696333466
[2022-12-07 06:38:18,084] [INFO] [runner_train_mujoco] Average state value: 0.6032873030155897
[2022-12-07 06:38:18,084] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 06:38:18,136] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.06867
[2022-12-07 06:38:18,180] [INFO] [controller] EPOCH 2 loss ppo:  -0.04906, loss val: 0.06121
[2022-12-07 06:38:18,225] [INFO] [controller] EPOCH 3 loss ppo:  -0.06146, loss val: 0.05650
[2022-12-07 06:38:18,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.07091, loss val: 0.05399
[2022-12-07 06:38:18,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:38:18,497] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:38:18,497] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:38:26,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:38:34,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:38:43,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:38:52,078] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:39:00,506] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:39:08,012] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:39:15,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:39:23,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:39:30,325] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:39:37,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6940320987973723
[2022-12-07 06:39:37,108] [INFO] [runner_train_mujoco] Average state value: 0.5307678864002228
[2022-12-07 06:39:37,108] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 06:39:37,168] [INFO] [controller] EPOCH 1 loss ppo:  -0.01000, loss val: 0.05643
[2022-12-07 06:39:37,211] [INFO] [controller] EPOCH 2 loss ppo:  -0.04150, loss val: 0.05248
[2022-12-07 06:39:37,255] [INFO] [controller] EPOCH 3 loss ppo:  -0.05668, loss val: 0.04959
[2022-12-07 06:39:37,299] [INFO] [controller] EPOCH 4 loss ppo:  -0.07310, loss val: 0.04960
[2022-12-07 06:39:37,308] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:39:37,514] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:39:37,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:39:44,900] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:39:52,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:39:59,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:40:07,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:40:14,297] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:40:21,545] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:40:28,332] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:40:35,612] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:40:42,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:40:49,671] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5056149294367028
[2022-12-07 06:40:49,671] [INFO] [runner_train_mujoco] Average state value: 0.4660989321370919
[2022-12-07 06:40:49,671] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 06:40:49,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.04335
[2022-12-07 06:40:49,757] [INFO] [controller] EPOCH 2 loss ppo:  -0.04611, loss val: 0.04188
[2022-12-07 06:40:49,798] [INFO] [controller] EPOCH 3 loss ppo:  -0.06398, loss val: 0.04037
[2022-12-07 06:40:49,839] [INFO] [controller] EPOCH 4 loss ppo:  -0.07396, loss val: 0.04216
[2022-12-07 06:40:49,849] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:40:50,078] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:40:50,078] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:40:57,366] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:41:04,469] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:41:12,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:41:18,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:41:26,328] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:41:33,568] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:41:40,575] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:41:47,828] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:41:54,747] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:42:02,081] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.636172716637281
[2022-12-07 06:42:02,081] [INFO] [runner_train_mujoco] Average state value: 0.432435549557209
[2022-12-07 06:42:02,081] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 06:42:02,130] [INFO] [controller] EPOCH 1 loss ppo:  -0.01261, loss val: 0.04406
[2022-12-07 06:42:02,172] [INFO] [controller] EPOCH 2 loss ppo:  -0.04634, loss val: 0.04312
[2022-12-07 06:42:02,214] [INFO] [controller] EPOCH 3 loss ppo:  -0.06326, loss val: 0.04202
[2022-12-07 06:42:02,253] [INFO] [controller] EPOCH 4 loss ppo:  -0.07821, loss val: 0.04311
[2022-12-07 06:42:02,262] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:42:02,460] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:42:02,460] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:42:09,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:42:17,829] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:42:25,661] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:42:33,177] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:42:40,403] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:42:47,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:42:54,525] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:43:01,394] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:43:08,514] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:43:16,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.753356890315887
[2022-12-07 06:43:16,354] [INFO] [runner_train_mujoco] Average state value: 0.45189680133263266
[2022-12-07 06:43:16,355] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 06:43:16,415] [INFO] [controller] EPOCH 1 loss ppo:  -0.01232, loss val: 0.04171
[2022-12-07 06:43:16,461] [INFO] [controller] EPOCH 2 loss ppo:  -0.04369, loss val: 0.03952
[2022-12-07 06:43:16,502] [INFO] [controller] EPOCH 3 loss ppo:  -0.05970, loss val: 0.04034
[2022-12-07 06:43:16,556] [INFO] [controller] EPOCH 4 loss ppo:  -0.07375, loss val: 0.03860
[2022-12-07 06:43:16,567] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:43:16,793] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:43:16,794] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:43:25,756] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:43:32,799] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:43:39,569] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:43:46,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:43:54,081] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:44:02,162] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:44:09,516] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:44:16,461] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:44:23,854] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:44:30,853] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7900240888332476
[2022-12-07 06:44:30,854] [INFO] [runner_train_mujoco] Average state value: 0.47965778486927346
[2022-12-07 06:44:30,854] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 06:44:30,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01056, loss val: 0.03975
[2022-12-07 06:44:30,945] [INFO] [controller] EPOCH 2 loss ppo:  -0.03925, loss val: 0.04291
[2022-12-07 06:44:30,984] [INFO] [controller] EPOCH 3 loss ppo:  -0.05929, loss val: 0.03807
[2022-12-07 06:44:31,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.07312, loss val: 0.03772
[2022-12-07 06:44:31,038] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:44:31,245] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:44:31,246] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:44:39,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:44:46,225] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:44:53,720] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:45:00,886] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:45:09,894] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:45:18,739] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:45:26,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:45:34,805] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:45:43,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:45:51,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46707857130181385
[2022-12-07 06:45:51,778] [INFO] [runner_train_mujoco] Average state value: 0.5121863720764717
[2022-12-07 06:45:51,778] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 06:45:51,829] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.03689
[2022-12-07 06:45:51,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.04164, loss val: 0.03626
[2022-12-07 06:45:51,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.06161, loss val: 0.03834
[2022-12-07 06:45:51,957] [INFO] [controller] EPOCH 4 loss ppo:  -0.07159, loss val: 0.03639
[2022-12-07 06:45:51,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:45:52,180] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:45:52,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:46:00,816] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:46:09,141] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:46:17,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:46:26,389] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:46:34,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:46:42,801] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:46:51,249] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:47:00,079] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:47:10,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:47:20,134] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.664580804548337
[2022-12-07 06:47:20,134] [INFO] [runner_train_mujoco] Average state value: 0.5311393501659234
[2022-12-07 06:47:20,134] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 06:47:20,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.04889
[2022-12-07 06:47:20,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.04441, loss val: 0.04804
[2022-12-07 06:47:20,303] [INFO] [controller] EPOCH 3 loss ppo:  -0.06308, loss val: 0.04869
[2022-12-07 06:47:20,360] [INFO] [controller] EPOCH 4 loss ppo:  -0.07642, loss val: 0.04778
[2022-12-07 06:47:20,372] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:47:20,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:47:20,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:47:30,542] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:47:40,737] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:47:50,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:47:59,051] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:48:08,158] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:48:17,353] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:48:26,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:48:35,984] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:48:45,069] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:48:54,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.778843883049731
[2022-12-07 06:48:54,382] [INFO] [runner_train_mujoco] Average state value: 0.5103912420272827
[2022-12-07 06:48:54,382] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 06:48:54,447] [INFO] [controller] EPOCH 1 loss ppo:  -0.01267, loss val: 0.04272
[2022-12-07 06:48:54,505] [INFO] [controller] EPOCH 2 loss ppo:  -0.04110, loss val: 0.04239
[2022-12-07 06:48:54,634] [INFO] [controller] EPOCH 3 loss ppo:  -0.06029, loss val: 0.04022
[2022-12-07 06:48:54,694] [INFO] [controller] EPOCH 4 loss ppo:  -0.07363, loss val: 0.03894
[2022-12-07 06:48:54,705] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:48:54,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:48:54,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:49:04,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:49:13,413] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:49:22,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:49:31,856] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:49:41,259] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:49:51,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:50:01,295] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:50:10,192] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:50:19,042] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:50:27,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9324771153326843
[2022-12-07 06:50:27,931] [INFO] [runner_train_mujoco] Average state value: 0.4555976142485937
[2022-12-07 06:50:27,931] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 06:50:27,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.03868
[2022-12-07 06:50:28,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.04316, loss val: 0.04001
[2022-12-07 06:50:28,088] [INFO] [controller] EPOCH 3 loss ppo:  -0.06456, loss val: 0.03953
[2022-12-07 06:50:28,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.07779, loss val: 0.04353
[2022-12-07 06:50:28,146] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:50:28,362] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:50:28,362] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:50:37,972] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:50:47,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:50:55,991] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:51:04,795] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:51:14,231] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:51:23,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:51:32,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:51:42,038] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:51:51,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:52:02,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7293025916953522
[2022-12-07 06:52:02,040] [INFO] [runner_train_mujoco] Average state value: 0.4489930162231127
[2022-12-07 06:52:02,041] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 06:52:02,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.04074
[2022-12-07 06:52:02,168] [INFO] [controller] EPOCH 2 loss ppo:  -0.04082, loss val: 0.03950
[2022-12-07 06:52:02,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.06030, loss val: 0.03733
[2022-12-07 06:52:02,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.07360, loss val: 0.03560
[2022-12-07 06:52:02,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:52:02,508] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:52:02,509] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:52:12,258] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:52:21,851] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:52:31,957] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:52:40,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:52:50,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:52:59,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:53:08,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:53:18,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:53:27,119] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:53:35,999] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.745911392575101
[2022-12-07 06:53:35,999] [INFO] [runner_train_mujoco] Average state value: 0.5189535870949428
[2022-12-07 06:53:35,999] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 06:53:36,059] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04225
[2022-12-07 06:53:36,111] [INFO] [controller] EPOCH 2 loss ppo:  -0.04383, loss val: 0.04131
[2022-12-07 06:53:36,155] [INFO] [controller] EPOCH 3 loss ppo:  -0.06019, loss val: 0.04160
[2022-12-07 06:53:36,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.07477, loss val: 0.04202
[2022-12-07 06:53:36,210] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:53:36,427] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:53:36,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:53:45,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:53:55,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:54:04,246] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:54:13,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:54:22,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:54:31,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:54:40,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:54:49,825] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:54:59,033] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:55:08,096] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.818793054753114
[2022-12-07 06:55:08,096] [INFO] [runner_train_mujoco] Average state value: 0.585362109820048
[2022-12-07 06:55:08,096] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 06:55:08,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.05047
[2022-12-07 06:55:08,221] [INFO] [controller] EPOCH 2 loss ppo:  -0.04031, loss val: 0.04999
[2022-12-07 06:55:08,285] [INFO] [controller] EPOCH 3 loss ppo:  -0.05955, loss val: 0.04830
[2022-12-07 06:55:08,358] [INFO] [controller] EPOCH 4 loss ppo:  -0.07540, loss val: 0.04501
[2022-12-07 06:55:08,369] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:55:08,609] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:55:08,609] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:55:17,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:55:27,460] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:55:36,416] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:55:45,180] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:55:54,388] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:56:03,122] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:56:12,469] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:56:22,064] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:56:31,145] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:56:40,847] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.74904849777961
[2022-12-07 06:56:40,848] [INFO] [runner_train_mujoco] Average state value: 0.5500944141546886
[2022-12-07 06:56:40,848] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 06:56:40,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01152, loss val: 0.04776
[2022-12-07 06:56:40,955] [INFO] [controller] EPOCH 2 loss ppo:  -0.03945, loss val: 0.04526
[2022-12-07 06:56:41,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.06101, loss val: 0.04467
[2022-12-07 06:56:41,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.07618, loss val: 0.04469
[2022-12-07 06:56:41,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:56:41,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:56:41,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:56:52,079] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:57:01,834] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:57:10,846] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:57:19,820] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:57:28,742] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:57:37,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:57:47,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:57:56,159] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:58:05,005] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:58:13,781] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9652161049637416
[2022-12-07 06:58:13,781] [INFO] [runner_train_mujoco] Average state value: 0.48521764258543654
[2022-12-07 06:58:13,781] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 06:58:13,846] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.02887
[2022-12-07 06:58:13,901] [INFO] [controller] EPOCH 2 loss ppo:  -0.04461, loss val: 0.02625
[2022-12-07 06:58:13,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.06592, loss val: 0.02927
[2022-12-07 06:58:14,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.07985, loss val: 0.02804
[2022-12-07 06:58:14,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:58:14,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:58:14,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:58:23,471] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:58:33,297] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:58:42,582] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:58:51,314] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:59:00,223] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:59:09,043] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:59:18,050] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:59:27,158] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:59:36,376] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:59:45,433] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7229507489203623
[2022-12-07 06:59:45,434] [INFO] [runner_train_mujoco] Average state value: 0.4476628075242043
[2022-12-07 06:59:45,434] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 06:59:45,498] [INFO] [controller] EPOCH 1 loss ppo:  -0.01131, loss val: 0.04448
[2022-12-07 06:59:45,551] [INFO] [controller] EPOCH 2 loss ppo:  -0.03906, loss val: 0.04358
[2022-12-07 06:59:45,604] [INFO] [controller] EPOCH 3 loss ppo:  -0.05528, loss val: 0.04221
[2022-12-07 06:59:45,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.06727, loss val: 0.03986
[2022-12-07 06:59:45,662] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:59:45,884] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:59:45,884] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:59:55,548] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:00:04,773] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:00:13,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:00:22,045] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:00:30,821] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:00:39,941] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:00:49,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:00:57,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:01:07,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:01:16,385] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7374613776948283
[2022-12-07 07:01:16,385] [INFO] [runner_train_mujoco] Average state value: 0.4792180960178375
[2022-12-07 07:01:16,385] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 07:01:16,449] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.03375
[2022-12-07 07:01:16,506] [INFO] [controller] EPOCH 2 loss ppo:  -0.04051, loss val: 0.03300
[2022-12-07 07:01:16,580] [INFO] [controller] EPOCH 3 loss ppo:  -0.06455, loss val: 0.03351
[2022-12-07 07:01:16,635] [INFO] [controller] EPOCH 4 loss ppo:  -0.07797, loss val: 0.03454
[2022-12-07 07:01:16,645] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:01:16,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:01:16,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:01:26,150] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:01:35,340] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:01:44,732] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:01:54,158] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:02:02,863] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:02:11,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:02:21,009] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:02:30,488] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:02:39,909] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:02:48,876] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7240650840524293
[2022-12-07 07:02:48,876] [INFO] [runner_train_mujoco] Average state value: 0.5217972562437256
[2022-12-07 07:02:48,876] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 07:02:48,944] [INFO] [controller] EPOCH 1 loss ppo:  -0.01151, loss val: 0.03914
[2022-12-07 07:02:49,021] [INFO] [controller] EPOCH 2 loss ppo:  -0.04085, loss val: 0.03946
[2022-12-07 07:02:49,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.06298, loss val: 0.04017
[2022-12-07 07:02:49,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.07674, loss val: 0.03992
[2022-12-07 07:02:49,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:02:49,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:02:49,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:02:58,314] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:03:07,360] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:03:16,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:03:25,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:03:34,812] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:03:43,901] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:03:52,915] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:04:01,298] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:04:10,489] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:04:19,681] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.883628950593286
[2022-12-07 07:04:19,681] [INFO] [runner_train_mujoco] Average state value: 0.5303536934951941
[2022-12-07 07:04:19,681] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 07:04:19,752] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04137
[2022-12-07 07:04:19,802] [INFO] [controller] EPOCH 2 loss ppo:  -0.03639, loss val: 0.04098
[2022-12-07 07:04:19,849] [INFO] [controller] EPOCH 3 loss ppo:  -0.05602, loss val: 0.04235
[2022-12-07 07:04:19,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.06870, loss val: 0.04065
[2022-12-07 07:04:19,911] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:04:20,131] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:04:20,132] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:04:29,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:04:38,328] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:04:47,055] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:04:55,639] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:05:04,119] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:05:13,247] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:05:22,116] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:05:31,547] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:05:40,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:05:49,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9085251115489348
[2022-12-07 07:05:49,543] [INFO] [runner_train_mujoco] Average state value: 0.5158160588939984
[2022-12-07 07:05:49,543] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 07:05:49,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.04122
[2022-12-07 07:05:49,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.03355, loss val: 0.04268
[2022-12-07 07:05:49,721] [INFO] [controller] EPOCH 3 loss ppo:  -0.05721, loss val: 0.04212
[2022-12-07 07:05:49,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.07355, loss val: 0.04223
[2022-12-07 07:05:49,778] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:05:49,989] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:05:49,989] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:05:58,900] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:06:07,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:06:16,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:06:25,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:06:34,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:06:44,055] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:06:52,522] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:07:01,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:07:12,001] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:07:21,942] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.945374761992125
[2022-12-07 07:07:21,942] [INFO] [runner_train_mujoco] Average state value: 0.5076787813790143
[2022-12-07 07:07:21,942] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 07:07:22,009] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.04783
[2022-12-07 07:07:22,061] [INFO] [controller] EPOCH 2 loss ppo:  -0.03554, loss val: 0.04483
[2022-12-07 07:07:22,118] [INFO] [controller] EPOCH 3 loss ppo:  -0.05546, loss val: 0.04685
[2022-12-07 07:07:22,187] [INFO] [controller] EPOCH 4 loss ppo:  -0.07030, loss val: 0.04901
[2022-12-07 07:07:22,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:07:22,427] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:07:22,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:07:31,529] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:07:40,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:07:49,711] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:07:58,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:08:07,238] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:08:16,184] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:08:24,917] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:08:34,095] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:08:42,867] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:08:52,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1098932589861779
[2022-12-07 07:08:52,524] [INFO] [runner_train_mujoco] Average state value: 0.5221544755945604
[2022-12-07 07:08:52,524] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 07:08:52,582] [INFO] [controller] EPOCH 1 loss ppo:  -0.01260, loss val: 0.04014
[2022-12-07 07:08:52,624] [INFO] [controller] EPOCH 2 loss ppo:  -0.04023, loss val: 0.03959
[2022-12-07 07:08:52,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.05914, loss val: 0.04028
[2022-12-07 07:08:52,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.07311, loss val: 0.03943
[2022-12-07 07:08:52,712] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:08:52,918] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:08:52,919] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:09:01,148] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:09:08,997] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:09:16,868] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:09:24,749] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:09:32,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:09:40,860] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:09:49,181] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:09:57,605] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:10:05,189] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:10:12,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.209350178577579
[2022-12-07 07:10:12,828] [INFO] [runner_train_mujoco] Average state value: 0.5155893570780754
[2022-12-07 07:10:12,828] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 07:10:12,891] [INFO] [controller] EPOCH 1 loss ppo:  -0.01133, loss val: 0.03337
[2022-12-07 07:10:12,937] [INFO] [controller] EPOCH 2 loss ppo:  -0.03537, loss val: 0.03434
[2022-12-07 07:10:12,984] [INFO] [controller] EPOCH 3 loss ppo:  -0.05777, loss val: 0.03303
[2022-12-07 07:10:13,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.07679, loss val: 0.03681
[2022-12-07 07:10:13,040] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:10:13,290] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:10:13,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:10:21,255] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:10:29,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:10:37,387] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:10:45,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:10:53,366] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:11:01,553] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:11:09,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:11:17,158] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:11:25,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:11:32,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6520738810141633
[2022-12-07 07:11:32,813] [INFO] [runner_train_mujoco] Average state value: 0.4983373177349567
[2022-12-07 07:11:32,813] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 07:11:32,864] [INFO] [controller] EPOCH 1 loss ppo:  -0.01583, loss val: 0.03542
[2022-12-07 07:11:32,916] [INFO] [controller] EPOCH 2 loss ppo:  -0.04261, loss val: 0.03425
[2022-12-07 07:11:32,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.05792, loss val: 0.03324
[2022-12-07 07:11:33,005] [INFO] [controller] EPOCH 4 loss ppo:  -0.07156, loss val: 0.03261
[2022-12-07 07:11:33,015] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:11:33,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:11:33,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:11:41,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:11:49,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:11:57,965] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:12:05,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:12:13,484] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:12:21,203] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:12:29,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:12:37,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:12:45,570] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:12:53,901] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.36308741853671
[2022-12-07 07:12:53,901] [INFO] [runner_train_mujoco] Average state value: 0.4702430679798126
[2022-12-07 07:12:53,902] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 07:12:53,958] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.03674
[2022-12-07 07:12:54,004] [INFO] [controller] EPOCH 2 loss ppo:  -0.03866, loss val: 0.03621
[2022-12-07 07:12:54,058] [INFO] [controller] EPOCH 3 loss ppo:  -0.06016, loss val: 0.03667
[2022-12-07 07:12:54,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.07685, loss val: 0.03547
[2022-12-07 07:12:54,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:12:54,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:12:54,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:13:02,024] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:13:09,842] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:13:18,080] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:13:26,359] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:13:34,314] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:13:42,259] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:13:50,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:13:58,557] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:14:06,701] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:14:14,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3783438811169875
[2022-12-07 07:14:14,895] [INFO] [runner_train_mujoco] Average state value: 0.4409027306586504
[2022-12-07 07:14:14,895] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 07:14:14,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.03718
[2022-12-07 07:14:14,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.03633, loss val: 0.03919
[2022-12-07 07:14:15,103] [INFO] [controller] EPOCH 3 loss ppo:  -0.05444, loss val: 0.03726
[2022-12-07 07:14:15,147] [INFO] [controller] EPOCH 4 loss ppo:  -0.07139, loss val: 0.03838
[2022-12-07 07:14:15,156] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:14:15,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:14:15,367] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:14:23,160] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:14:31,642] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:14:39,377] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:14:47,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:14:55,156] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:15:03,177] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:15:10,553] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:15:18,542] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:15:26,625] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:15:34,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6993293219965704
[2022-12-07 07:15:34,507] [INFO] [runner_train_mujoco] Average state value: 0.4471757235129674
[2022-12-07 07:15:34,507] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 07:15:34,566] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.04621
[2022-12-07 07:15:34,612] [INFO] [controller] EPOCH 2 loss ppo:  -0.03827, loss val: 0.04405
[2022-12-07 07:15:34,662] [INFO] [controller] EPOCH 3 loss ppo:  -0.05956, loss val: 0.04272
[2022-12-07 07:15:34,710] [INFO] [controller] EPOCH 4 loss ppo:  -0.07481, loss val: 0.04107
[2022-12-07 07:15:34,720] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:15:34,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:15:34,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:15:43,394] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:15:51,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:16:00,204] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:16:08,147] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:16:16,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:16:24,546] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:16:32,699] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:16:40,421] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:16:48,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:16:55,928] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.711019372225375
[2022-12-07 07:16:55,928] [INFO] [runner_train_mujoco] Average state value: 0.49812795335054394
[2022-12-07 07:16:55,928] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 07:16:55,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.03212
[2022-12-07 07:16:56,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.03587, loss val: 0.03360
[2022-12-07 07:16:56,079] [INFO] [controller] EPOCH 3 loss ppo:  -0.05552, loss val: 0.03457
[2022-12-07 07:16:56,124] [INFO] [controller] EPOCH 4 loss ppo:  -0.06942, loss val: 0.03425
[2022-12-07 07:16:56,134] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:16:56,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:16:56,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:17:04,679] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:17:12,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:17:20,614] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:17:30,042] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:17:38,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:17:45,745] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:17:54,294] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:18:03,619] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:18:11,602] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:18:19,554] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.800038381979147
[2022-12-07 07:18:19,555] [INFO] [runner_train_mujoco] Average state value: 0.5127078575491906
[2022-12-07 07:18:19,555] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 07:18:19,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04460
[2022-12-07 07:18:19,647] [INFO] [controller] EPOCH 2 loss ppo:  -0.03390, loss val: 0.04729
[2022-12-07 07:18:19,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.05497, loss val: 0.04759
[2022-12-07 07:18:19,736] [INFO] [controller] EPOCH 4 loss ppo:  -0.07145, loss val: 0.04562
[2022-12-07 07:18:19,745] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:18:19,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:18:19,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:18:28,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:18:35,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:18:44,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:18:52,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:18:59,866] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:19:07,398] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:19:15,268] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:19:23,245] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:19:31,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:19:41,236] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7186352527122903
[2022-12-07 07:19:41,236] [INFO] [runner_train_mujoco] Average state value: 0.5219341390033563
[2022-12-07 07:19:41,237] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 07:19:41,301] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.03645
[2022-12-07 07:19:41,347] [INFO] [controller] EPOCH 2 loss ppo:  -0.03988, loss val: 0.03652
[2022-12-07 07:19:41,389] [INFO] [controller] EPOCH 3 loss ppo:  -0.05849, loss val: 0.03744
[2022-12-07 07:19:41,435] [INFO] [controller] EPOCH 4 loss ppo:  -0.07327, loss val: 0.03626
[2022-12-07 07:19:41,445] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:19:41,657] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:19:41,658] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:19:49,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:19:57,846] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:20:05,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:20:13,459] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:20:21,266] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:20:29,286] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:20:37,174] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:20:45,216] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:20:53,362] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:21:01,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0725104756759927
[2022-12-07 07:21:01,177] [INFO] [runner_train_mujoco] Average state value: 0.5485995411475499
[2022-12-07 07:21:01,177] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 07:21:01,227] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.05135
[2022-12-07 07:21:01,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.03539, loss val: 0.05117
[2022-12-07 07:21:01,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.05394, loss val: 0.04966
[2022-12-07 07:21:01,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.06833, loss val: 0.04775
[2022-12-07 07:21:01,371] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:21:01,590] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:21:01,591] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:21:10,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:21:18,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:21:26,587] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:21:34,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:21:43,126] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:21:50,781] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:21:58,898] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:22:06,732] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:22:14,641] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:22:22,893] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.038391261902133
[2022-12-07 07:22:22,893] [INFO] [runner_train_mujoco] Average state value: 0.5195269222855569
[2022-12-07 07:22:22,894] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 07:22:22,948] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.03666
[2022-12-07 07:22:22,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.03768, loss val: 0.03748
[2022-12-07 07:22:23,036] [INFO] [controller] EPOCH 3 loss ppo:  -0.05955, loss val: 0.03857
[2022-12-07 07:22:23,081] [INFO] [controller] EPOCH 4 loss ppo:  -0.07236, loss val: 0.03691
[2022-12-07 07:22:23,090] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:22:23,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:22:23,298] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:22:31,485] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:22:39,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:22:47,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:22:55,510] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:23:03,860] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:23:11,649] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:23:19,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:23:27,214] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:23:35,266] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:23:43,595] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9803231578391478
[2022-12-07 07:23:43,595] [INFO] [runner_train_mujoco] Average state value: 0.4867250309586525
[2022-12-07 07:23:43,595] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 07:23:43,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.03643
[2022-12-07 07:23:43,705] [INFO] [controller] EPOCH 2 loss ppo:  -0.03691, loss val: 0.04100
[2022-12-07 07:23:43,749] [INFO] [controller] EPOCH 3 loss ppo:  -0.05876, loss val: 0.04674
[2022-12-07 07:23:43,796] [INFO] [controller] EPOCH 4 loss ppo:  -0.07392, loss val: 0.03641
[2022-12-07 07:23:43,805] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:23:44,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:23:44,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:23:52,512] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:24:00,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:24:08,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:24:16,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:24:24,399] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:24:32,540] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:40,210] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:24:47,961] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:24:55,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:25:03,512] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.085098971653818
[2022-12-07 07:25:03,512] [INFO] [runner_train_mujoco] Average state value: 0.45289905596772834
[2022-12-07 07:25:03,512] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 07:25:03,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.05808
[2022-12-07 07:25:03,615] [INFO] [controller] EPOCH 2 loss ppo:  -0.03530, loss val: 0.05799
[2022-12-07 07:25:03,659] [INFO] [controller] EPOCH 3 loss ppo:  -0.05176, loss val: 0.05812
[2022-12-07 07:25:03,700] [INFO] [controller] EPOCH 4 loss ppo:  -0.06628, loss val: 0.05780
[2022-12-07 07:25:03,710] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:25:03,920] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:25:03,921] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:25:12,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:25:20,594] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:25:28,376] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:25:36,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:25:43,638] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:25:51,868] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:26:00,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:26:07,672] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:26:15,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:26:23,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.381716194531323
[2022-12-07 07:26:23,077] [INFO] [runner_train_mujoco] Average state value: 0.4821376487811406
[2022-12-07 07:26:23,077] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 07:26:23,133] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04074
[2022-12-07 07:26:23,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.03128, loss val: 0.04019
[2022-12-07 07:26:23,228] [INFO] [controller] EPOCH 3 loss ppo:  -0.04931, loss val: 0.03977
[2022-12-07 07:26:23,278] [INFO] [controller] EPOCH 4 loss ppo:  -0.06388, loss val: 0.03951
[2022-12-07 07:26:23,290] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:26:23,517] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:26:23,517] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:26:31,751] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:26:40,239] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:26:48,383] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:26:56,381] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:27:04,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:27:12,162] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:27:20,370] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:27:28,476] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:27:36,235] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:27:43,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.762231239205665
[2022-12-07 07:27:43,979] [INFO] [runner_train_mujoco] Average state value: 0.4946903843283653
[2022-12-07 07:27:43,979] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 07:27:44,029] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.03771
[2022-12-07 07:27:44,072] [INFO] [controller] EPOCH 2 loss ppo:  -0.03239, loss val: 0.03738
[2022-12-07 07:27:44,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.04906, loss val: 0.03699
[2022-12-07 07:27:44,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.06248, loss val: 0.03466
[2022-12-07 07:27:44,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:27:44,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:27:44,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:27:52,483] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:28:00,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:28:08,673] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:28:16,451] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:28:24,244] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:28:31,772] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:28:39,947] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:28:47,647] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:28:55,917] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:29:04,002] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6292632059470806
[2022-12-07 07:29:04,002] [INFO] [runner_train_mujoco] Average state value: 0.5221084929307303
[2022-12-07 07:29:04,002] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 07:29:04,055] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.04033
[2022-12-07 07:29:04,102] [INFO] [controller] EPOCH 2 loss ppo:  -0.03214, loss val: 0.04046
[2022-12-07 07:29:04,143] [INFO] [controller] EPOCH 3 loss ppo:  -0.04857, loss val: 0.04464
[2022-12-07 07:29:04,188] [INFO] [controller] EPOCH 4 loss ppo:  -0.06427, loss val: 0.04468
[2022-12-07 07:29:04,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:29:04,407] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:29:04,407] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:29:12,766] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:29:21,002] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:29:28,628] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:29:36,779] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:29:44,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:29:53,288] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:30:01,580] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:30:09,199] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:30:16,909] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:30:24,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.833206437376337
[2022-12-07 07:30:24,370] [INFO] [runner_train_mujoco] Average state value: 0.5349641801714897
[2022-12-07 07:30:24,370] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 07:30:24,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.05122
[2022-12-07 07:30:24,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.03072, loss val: 0.05162
[2022-12-07 07:30:24,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.04844, loss val: 0.05114
[2022-12-07 07:30:24,556] [INFO] [controller] EPOCH 4 loss ppo:  -0.06062, loss val: 0.04980
[2022-12-07 07:30:24,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:30:24,754] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:30:24,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:30:32,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:30:40,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:30:49,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:30:56,814] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:31:05,110] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:31:12,462] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:31:20,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:31:28,292] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:31:36,702] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:31:46,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2289159167483428
[2022-12-07 07:31:46,444] [INFO] [runner_train_mujoco] Average state value: 0.5239148624142012
[2022-12-07 07:31:46,444] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 07:31:46,502] [INFO] [controller] EPOCH 1 loss ppo:  -0.01500, loss val: 0.04851
[2022-12-07 07:31:46,551] [INFO] [controller] EPOCH 2 loss ppo:  -0.03202, loss val: 0.04809
[2022-12-07 07:31:46,596] [INFO] [controller] EPOCH 3 loss ppo:  -0.05096, loss val: 0.04614
[2022-12-07 07:31:46,642] [INFO] [controller] EPOCH 4 loss ppo:  -0.06372, loss val: 0.04647
[2022-12-07 07:31:46,648] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:31:46,850] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:31:46,851] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:31:54,399] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:32:02,737] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:32:10,725] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:32:18,234] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:32:25,985] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:32:33,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:32:41,345] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:32:49,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:32:57,480] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:33:07,051] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.843692823325811
[2022-12-07 07:33:07,051] [INFO] [runner_train_mujoco] Average state value: 0.45135633087158206
[2022-12-07 07:33:07,051] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 07:33:07,101] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.07361
[2022-12-07 07:33:07,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.02723, loss val: 0.07380
[2022-12-07 07:33:07,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.04523, loss val: 0.07472
[2022-12-07 07:33:07,231] [INFO] [controller] EPOCH 4 loss ppo:  -0.05753, loss val: 0.07407
[2022-12-07 07:33:07,240] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:33:07,449] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:33:07,449] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:33:15,079] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:33:23,093] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:33:31,355] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:33:39,489] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:33:47,009] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:33:54,434] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:34:02,147] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:34:09,233] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:34:17,322] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:34:25,713] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7134038096416306
[2022-12-07 07:34:25,713] [INFO] [runner_train_mujoco] Average state value: 0.46310000687340896
[2022-12-07 07:34:25,713] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 07:34:25,774] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.05250
[2022-12-07 07:34:25,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.03076, loss val: 0.05201
[2022-12-07 07:34:25,861] [INFO] [controller] EPOCH 3 loss ppo:  -0.04702, loss val: 0.05182
[2022-12-07 07:34:25,910] [INFO] [controller] EPOCH 4 loss ppo:  -0.05783, loss val: 0.04951
[2022-12-07 07:34:25,917] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:34:26,130] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:34:26,130] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:34:34,103] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:34:42,146] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:34:49,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:34:57,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:35:04,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:35:12,623] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:35:20,369] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:35:27,821] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:35:35,588] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:35:43,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1912992628248573
[2022-12-07 07:35:43,448] [INFO] [runner_train_mujoco] Average state value: 0.4934135656617582
[2022-12-07 07:35:43,448] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 07:35:43,506] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.04530
[2022-12-07 07:35:43,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.03022, loss val: 0.04550
[2022-12-07 07:35:43,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.04412, loss val: 0.04556
[2022-12-07 07:35:43,647] [INFO] [controller] EPOCH 4 loss ppo:  -0.05446, loss val: 0.04546
[2022-12-07 07:35:43,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:35:43,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:35:43,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:35:51,657] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:36:00,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:36:07,886] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:36:15,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:36:23,372] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:36:31,151] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:36:38,678] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:36:45,971] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:36:53,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:37:01,713] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2997139027127305
[2022-12-07 07:37:01,713] [INFO] [runner_train_mujoco] Average state value: 0.5108758579194546
[2022-12-07 07:37:01,713] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 07:37:01,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.03897
[2022-12-07 07:37:01,824] [INFO] [controller] EPOCH 2 loss ppo:  -0.02605, loss val: 0.03893
[2022-12-07 07:37:01,935] [INFO] [controller] EPOCH 3 loss ppo:  -0.04339, loss val: 0.03948
[2022-12-07 07:37:01,981] [INFO] [controller] EPOCH 4 loss ppo:  -0.05806, loss val: 0.03958
[2022-12-07 07:37:01,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:37:02,200] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:37:02,201] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:37:10,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:37:20,038] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:37:28,005] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:37:36,695] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:37:44,107] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:37:51,398] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:37:58,952] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:38:06,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:38:14,591] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:38:22,158] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.218856037551663
[2022-12-07 07:38:22,158] [INFO] [runner_train_mujoco] Average state value: 0.5220056723157566
[2022-12-07 07:38:22,158] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 07:38:22,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04369
[2022-12-07 07:38:22,252] [INFO] [controller] EPOCH 2 loss ppo:  -0.02444, loss val: 0.04372
[2022-12-07 07:38:22,297] [INFO] [controller] EPOCH 3 loss ppo:  -0.03994, loss val: 0.04381
[2022-12-07 07:38:22,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.05307, loss val: 0.04471
[2022-12-07 07:38:22,348] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:38:22,560] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:38:22,561] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:38:30,678] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:38:38,701] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:38:46,451] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:38:54,727] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:39:02,588] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:39:10,268] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:39:17,596] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:39:24,958] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:39:32,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:39:40,366] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3975035584604734
[2022-12-07 07:39:40,366] [INFO] [runner_train_mujoco] Average state value: 0.4952926455760996
[2022-12-07 07:39:40,366] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 07:39:40,422] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.06192
[2022-12-07 07:39:40,466] [INFO] [controller] EPOCH 2 loss ppo:  -0.02340, loss val: 0.06159
[2022-12-07 07:39:40,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.03633, loss val: 0.06222
[2022-12-07 07:39:40,545] [INFO] [controller] EPOCH 4 loss ppo:  -0.04736, loss val: 0.06162
[2022-12-07 07:39:40,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:39:40,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:39:40,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:39:49,413] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:39:57,579] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:40:05,705] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:40:13,412] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:40:21,084] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:40:28,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:40:36,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:40:44,228] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:40:52,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:40:59,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3278234874984456
[2022-12-07 07:40:59,835] [INFO] [runner_train_mujoco] Average state value: 0.5116329896176854
[2022-12-07 07:40:59,835] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 07:40:59,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.05093
[2022-12-07 07:40:59,935] [INFO] [controller] EPOCH 2 loss ppo:  -0.02183, loss val: 0.04903
[2022-12-07 07:41:00,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.03599, loss val: 0.04827
[2022-12-07 07:41:00,116] [INFO] [controller] EPOCH 4 loss ppo:  -0.04850, loss val: 0.04763
[2022-12-07 07:41:00,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:41:00,329] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:41:00,329] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:41:08,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:41:16,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:41:23,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:41:31,653] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:41:40,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:41:47,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:41:55,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:42:03,023] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:42:10,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:42:18,533] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2943955152424254
[2022-12-07 07:42:18,533] [INFO] [runner_train_mujoco] Average state value: 0.5404680922577778
[2022-12-07 07:42:18,533] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 07:42:18,586] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.04733
[2022-12-07 07:42:18,631] [INFO] [controller] EPOCH 2 loss ppo:  -0.02093, loss val: 0.04801
[2022-12-07 07:42:18,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.03368, loss val: 0.04817
[2022-12-07 07:42:18,724] [INFO] [controller] EPOCH 4 loss ppo:  -0.04590, loss val: 0.04885
[2022-12-07 07:42:18,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:42:18,946] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:42:18,947] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:42:27,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:42:35,525] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:42:43,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:42:51,464] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:42:59,094] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:43:06,670] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:43:13,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:43:22,557] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:43:29,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:43:37,320] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.927814570887071
[2022-12-07 07:43:37,321] [INFO] [runner_train_mujoco] Average state value: 0.5071569913725058
[2022-12-07 07:43:37,321] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 07:43:37,368] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.06554
[2022-12-07 07:43:37,409] [INFO] [controller] EPOCH 2 loss ppo:  -0.02079, loss val: 0.06559
[2022-12-07 07:43:37,451] [INFO] [controller] EPOCH 3 loss ppo:  -0.03284, loss val: 0.06591
[2022-12-07 07:43:37,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.04484, loss val: 0.06509
[2022-12-07 07:43:37,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:43:37,697] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:43:37,697] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:43:44,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:43:52,283] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:43:59,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:44:06,053] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:44:13,615] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:44:20,799] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:44:27,328] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:44:33,967] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:44:40,395] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:44:47,359] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.772535782195411
[2022-12-07 07:44:47,359] [INFO] [runner_train_mujoco] Average state value: 0.5398999584118526
[2022-12-07 07:44:47,360] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 07:44:47,406] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.03598
[2022-12-07 07:44:47,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.01964, loss val: 0.03736
[2022-12-07 07:44:47,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.03014, loss val: 0.03872
[2022-12-07 07:44:47,512] [INFO] [controller] EPOCH 4 loss ppo:  -0.04010, loss val: 0.03771
[2022-12-07 07:44:47,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:44:47,709] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:44:47,710] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:44:55,193] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:45:01,609] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:45:08,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:45:14,697] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:45:20,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:45:27,026] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:45:33,193] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:45:39,417] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:45:45,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:45:52,388] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.24651869585808
[2022-12-07 07:45:52,388] [INFO] [runner_train_mujoco] Average state value: 0.5358336901068688
[2022-12-07 07:45:52,389] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 07:45:52,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.04473
[2022-12-07 07:45:52,473] [INFO] [controller] EPOCH 2 loss ppo:  -0.01695, loss val: 0.04547
[2022-12-07 07:45:52,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.02304, loss val: 0.04385
[2022-12-07 07:45:52,555] [INFO] [controller] EPOCH 4 loss ppo:  -0.03197, loss val: 0.04376
[2022-12-07 07:45:52,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:45:52,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:45:52,738] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:45:59,364] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:46:06,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:46:12,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:46:18,633] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:46:25,336] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:46:31,625] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:46:37,862] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:46:44,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:46:50,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:46:56,408] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.749818796786248
[2022-12-07 07:46:56,408] [INFO] [runner_train_mujoco] Average state value: 0.5263727238724629
[2022-12-07 07:46:56,408] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 07:46:56,454] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.03879
[2022-12-07 07:46:56,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.01768, loss val: 0.03760
[2022-12-07 07:46:56,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.02381, loss val: 0.03770
[2022-12-07 07:46:56,566] [INFO] [controller] EPOCH 4 loss ppo:  -0.03171, loss val: 0.03890
[2022-12-07 07:46:56,575] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:46:56,746] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:46:56,746] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:47:03,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:47:10,085] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:47:16,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:47:22,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:47:28,494] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:47:34,687] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:47:41,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:47:47,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:47:53,322] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:47:59,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.009938493914947
[2022-12-07 07:47:59,459] [INFO] [runner_train_mujoco] Average state value: 0.5271223138769467
[2022-12-07 07:47:59,459] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 07:47:59,503] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.03952
[2022-12-07 07:47:59,542] [INFO] [controller] EPOCH 2 loss ppo:  -0.01731, loss val: 0.03965
[2022-12-07 07:47:59,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.02205, loss val: 0.03943
[2022-12-07 07:47:59,620] [INFO] [controller] EPOCH 4 loss ppo:  -0.02774, loss val: 0.04001
[2022-12-07 07:47:59,629] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:47:59,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:47:59,806] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:48:06,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:48:13,125] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:48:19,475] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:48:25,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:48:31,668] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:48:37,778] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:48:44,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:48:50,286] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:48:56,385] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:49:02,691] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.123122651904396
[2022-12-07 07:49:02,692] [INFO] [runner_train_mujoco] Average state value: 0.44683240879699593
[2022-12-07 07:49:02,692] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 07:49:02,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.08521
[2022-12-07 07:49:02,777] [INFO] [controller] EPOCH 2 loss ppo:  -0.01467, loss val: 0.08656
[2022-12-07 07:49:02,816] [INFO] [controller] EPOCH 3 loss ppo:  -0.01619, loss val: 0.08477
[2022-12-07 07:49:02,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.01854, loss val: 0.08485
[2022-12-07 07:49:02,863] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:49:02,956] [INFO] [optimize] Finished learning.
