[2022-12-06 14:53:21,028] [INFO] [optimize] Starting learning
[2022-12-06 14:53:21,043] [INFO] [optimize] Starting learning process..
[2022-12-06 14:53:21,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:53:21,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:53:35,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:53:47,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:53:59,930] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:54:12,133] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:54:25,465] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:54:38,818] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:54:51,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:55:04,901] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:55:16,765] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:55:28,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5505158523546031
[2022-12-06 14:55:28,328] [INFO] [runner_train_mujoco] Average state value: 0.08484613235915701
[2022-12-06 14:55:28,328] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 14:55:28,402] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.46907
[2022-12-06 14:55:28,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.05602, loss val: 0.42086
[2022-12-06 14:55:28,517] [INFO] [controller] EPOCH 3 loss ppo:  -0.07218, loss val: 0.37130
[2022-12-06 14:55:28,575] [INFO] [controller] EPOCH 4 loss ppo:  -0.08037, loss val: 0.32087
[2022-12-06 14:55:28,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:55:28,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:55:28,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:55:39,344] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:55:49,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:55:58,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:56:07,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:56:17,730] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:56:27,124] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:56:37,048] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:56:47,321] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:56:57,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:57:06,829] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6751085449495646
[2022-12-06 14:57:06,829] [INFO] [runner_train_mujoco] Average state value: 0.2695921818437055
[2022-12-06 14:57:06,829] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 14:57:06,910] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.22278
[2022-12-06 14:57:06,973] [INFO] [controller] EPOCH 2 loss ppo:  -0.05008, loss val: 0.19992
[2022-12-06 14:57:07,024] [INFO] [controller] EPOCH 3 loss ppo:  -0.07353, loss val: 0.18018
[2022-12-06 14:57:07,072] [INFO] [controller] EPOCH 4 loss ppo:  -0.08523, loss val: 0.16484
[2022-12-06 14:57:07,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:57:07,317] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:57:07,317] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:57:16,366] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:57:25,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:57:33,114] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:57:40,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:57:49,146] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:57:56,928] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:58:04,851] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:58:13,452] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:58:21,882] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:58:29,678] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7736119961491805
[2022-12-06 14:58:29,678] [INFO] [runner_train_mujoco] Average state value: 0.37579518441079807
[2022-12-06 14:58:29,678] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 14:58:29,733] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.16012
[2022-12-06 14:58:29,775] [INFO] [controller] EPOCH 2 loss ppo:  -0.05129, loss val: 0.14714
[2022-12-06 14:58:29,816] [INFO] [controller] EPOCH 3 loss ppo:  -0.07006, loss val: 0.13604
[2022-12-06 14:58:29,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.08122, loss val: 0.12687
[2022-12-06 14:58:29,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:58:30,075] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:58:30,075] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:58:38,040] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:58:46,547] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:58:54,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:59:02,555] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:59:10,832] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:59:18,918] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:59:27,319] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:59:35,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:59:44,304] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:59:52,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47890623903737695
[2022-12-06 14:59:52,448] [INFO] [runner_train_mujoco] Average state value: 0.47845217130209006
[2022-12-06 14:59:52,448] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 14:59:52,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.01112, loss val: 0.12238
[2022-12-06 14:59:52,549] [INFO] [controller] EPOCH 2 loss ppo:  -0.04337, loss val: 0.11440
[2022-12-06 14:59:52,599] [INFO] [controller] EPOCH 3 loss ppo:  -0.06363, loss val: 0.10561
[2022-12-06 14:59:52,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.07396, loss val: 0.09988
[2022-12-06 14:59:52,659] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:59:52,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:59:52,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:00:01,401] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:00:10,174] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:00:18,076] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:00:25,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:00:33,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:00:41,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:00:49,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:00:58,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:01:09,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:01:18,673] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6350916711114645
[2022-12-06 15:01:18,673] [INFO] [runner_train_mujoco] Average state value: 0.5632242466167858
[2022-12-06 15:01:18,673] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 15:01:18,750] [INFO] [controller] EPOCH 1 loss ppo:  -0.01209, loss val: 0.08976
[2022-12-06 15:01:18,817] [INFO] [controller] EPOCH 2 loss ppo:  -0.04481, loss val: 0.08659
[2022-12-06 15:01:18,875] [INFO] [controller] EPOCH 3 loss ppo:  -0.06263, loss val: 0.08199
[2022-12-06 15:01:18,939] [INFO] [controller] EPOCH 4 loss ppo:  -0.07402, loss val: 0.07702
[2022-12-06 15:01:18,951] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:01:19,215] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:01:19,215] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:01:28,415] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:01:36,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:01:43,405] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:01:50,928] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:01:58,339] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:02:09,151] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:02:19,490] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:02:27,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:02:36,547] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:02:44,313] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6250397871049695
[2022-12-06 15:02:44,314] [INFO] [runner_train_mujoco] Average state value: 0.5439244870413094
[2022-12-06 15:02:44,314] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 15:02:44,372] [INFO] [controller] EPOCH 1 loss ppo:  -0.01071, loss val: 0.08450
[2022-12-06 15:02:44,419] [INFO] [controller] EPOCH 2 loss ppo:  -0.04393, loss val: 0.08200
[2022-12-06 15:02:44,466] [INFO] [controller] EPOCH 3 loss ppo:  -0.06005, loss val: 0.07911
[2022-12-06 15:02:44,524] [INFO] [controller] EPOCH 4 loss ppo:  -0.07062, loss val: 0.07855
[2022-12-06 15:02:44,537] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:02:44,816] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:02:44,816] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:02:53,142] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:03:01,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:03:09,241] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:03:17,463] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:03:25,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:03:32,886] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:03:41,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:03:49,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:03:57,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:04:05,410] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6173875075787414
[2022-12-06 15:04:05,410] [INFO] [runner_train_mujoco] Average state value: 0.5160000466766457
[2022-12-06 15:04:05,410] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 15:04:05,466] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.07160
[2022-12-06 15:04:05,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.04402, loss val: 0.06789
[2022-12-06 15:04:05,546] [INFO] [controller] EPOCH 3 loss ppo:  -0.06354, loss val: 0.06662
[2022-12-06 15:04:05,593] [INFO] [controller] EPOCH 4 loss ppo:  -0.07364, loss val: 0.06221
[2022-12-06 15:04:05,604] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:04:05,827] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:04:05,828] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:04:16,680] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:04:24,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:04:31,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:04:38,451] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:04:46,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:04:54,571] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:05:05,087] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:05:13,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:05:21,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:05:28,351] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6601560689068815
[2022-12-06 15:05:28,351] [INFO] [runner_train_mujoco] Average state value: 0.5552654039810102
[2022-12-06 15:05:28,351] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 15:05:28,400] [INFO] [controller] EPOCH 1 loss ppo:  -0.01067, loss val: 0.06458
[2022-12-06 15:05:28,443] [INFO] [controller] EPOCH 2 loss ppo:  -0.04150, loss val: 0.06181
[2022-12-06 15:05:28,481] [INFO] [controller] EPOCH 3 loss ppo:  -0.05730, loss val: 0.06033
[2022-12-06 15:05:28,526] [INFO] [controller] EPOCH 4 loss ppo:  -0.07097, loss val: 0.06058
[2022-12-06 15:05:28,533] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:05:28,748] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:05:28,749] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:05:36,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:05:43,888] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:05:51,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:06:01,666] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:06:09,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:06:16,559] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:06:24,333] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:06:31,876] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:06:40,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:06:48,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7582340861305958
[2022-12-06 15:06:48,931] [INFO] [runner_train_mujoco] Average state value: 0.5617087104320526
[2022-12-06 15:06:48,931] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 15:06:48,981] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.04567
[2022-12-06 15:06:49,021] [INFO] [controller] EPOCH 2 loss ppo:  -0.04290, loss val: 0.04397
[2022-12-06 15:06:49,067] [INFO] [controller] EPOCH 3 loss ppo:  -0.05722, loss val: 0.04394
[2022-12-06 15:06:49,112] [INFO] [controller] EPOCH 4 loss ppo:  -0.06899, loss val: 0.04855
[2022-12-06 15:06:49,122] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:06:49,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:06:49,359] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:06:56,841] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:07:05,002] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:07:12,738] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:07:20,491] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:07:27,357] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:07:34,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:07:41,725] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:07:48,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:07:55,590] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:08:02,556] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6451756490255374
[2022-12-06 15:08:02,557] [INFO] [runner_train_mujoco] Average state value: 0.5213271126896144
[2022-12-06 15:08:02,557] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 15:08:02,610] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.04970
[2022-12-06 15:08:02,656] [INFO] [controller] EPOCH 2 loss ppo:  -0.04180, loss val: 0.04907
[2022-12-06 15:08:02,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.05932, loss val: 0.05134
[2022-12-06 15:08:02,744] [INFO] [controller] EPOCH 4 loss ppo:  -0.06985, loss val: 0.04735
[2022-12-06 15:08:02,754] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:08:02,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:08:02,966] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:08:10,349] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:08:17,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:08:24,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:08:32,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:08:39,313] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:08:46,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:08:54,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:09:02,757] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:09:10,148] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:09:16,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8132075382707878
[2022-12-06 15:09:16,958] [INFO] [runner_train_mujoco] Average state value: 0.5319638062020143
[2022-12-06 15:09:16,958] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 15:09:17,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.04737
[2022-12-06 15:09:17,044] [INFO] [controller] EPOCH 2 loss ppo:  -0.04645, loss val: 0.04871
[2022-12-06 15:09:17,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.06274, loss val: 0.04996
[2022-12-06 15:09:17,124] [INFO] [controller] EPOCH 4 loss ppo:  -0.07493, loss val: 0.04568
[2022-12-06 15:09:17,134] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:09:17,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:09:17,348] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:09:24,585] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:09:31,953] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:09:38,868] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:09:45,625] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:09:54,472] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:10:03,872] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:10:11,982] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:10:19,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:10:27,331] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:10:34,538] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9323515595251223
[2022-12-06 15:10:34,538] [INFO] [runner_train_mujoco] Average state value: 0.5316177011827627
[2022-12-06 15:10:34,538] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 15:10:34,601] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.04687
[2022-12-06 15:10:34,657] [INFO] [controller] EPOCH 2 loss ppo:  -0.04605, loss val: 0.04477
[2022-12-06 15:10:34,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.06128, loss val: 0.04483
[2022-12-06 15:10:34,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.07426, loss val: 0.04353
[2022-12-06 15:10:34,771] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:10:35,000] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:10:35,000] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:10:42,394] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:10:50,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:10:57,738] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:11:05,051] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:11:12,706] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:11:20,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:11:29,829] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:11:39,410] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:11:46,741] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:11:53,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1243396655738915
[2022-12-06 15:11:53,979] [INFO] [runner_train_mujoco] Average state value: 0.5551758239964644
[2022-12-06 15:11:53,979] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 15:11:54,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.05506
[2022-12-06 15:11:54,088] [INFO] [controller] EPOCH 2 loss ppo:  -0.04372, loss val: 0.05325
[2022-12-06 15:11:54,145] [INFO] [controller] EPOCH 3 loss ppo:  -0.06312, loss val: 0.04370
[2022-12-06 15:11:54,198] [INFO] [controller] EPOCH 4 loss ppo:  -0.07445, loss val: 0.04864
[2022-12-06 15:11:54,208] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:11:54,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:11:54,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:12:01,926] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:12:10,974] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:12:20,965] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:12:29,046] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:12:39,162] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:12:47,547] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:12:55,571] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:13:04,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:13:12,938] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:13:21,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3509772032774647
[2022-12-06 15:13:21,040] [INFO] [runner_train_mujoco] Average state value: 0.5367459959089756
[2022-12-06 15:13:21,040] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 15:13:21,091] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.04396
[2022-12-06 15:13:21,140] [INFO] [controller] EPOCH 2 loss ppo:  -0.04278, loss val: 0.04311
[2022-12-06 15:13:21,264] [INFO] [controller] EPOCH 3 loss ppo:  -0.06192, loss val: 0.04120
[2022-12-06 15:13:21,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.07451, loss val: 0.04145
[2022-12-06 15:13:21,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:13:21,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:13:21,597] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:13:29,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:13:37,278] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:13:44,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:13:52,732] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:14:00,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:14:08,744] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:14:16,549] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:14:24,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:14:32,656] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:14:40,408] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.090245317595956
[2022-12-06 15:14:40,408] [INFO] [runner_train_mujoco] Average state value: 0.49550389534235
[2022-12-06 15:14:40,409] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 15:14:40,465] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.04299
[2022-12-06 15:14:40,513] [INFO] [controller] EPOCH 2 loss ppo:  -0.05049, loss val: 0.04086
[2022-12-06 15:14:40,561] [INFO] [controller] EPOCH 3 loss ppo:  -0.06607, loss val: 0.04309
[2022-12-06 15:14:40,607] [INFO] [controller] EPOCH 4 loss ppo:  -0.07512, loss val: 0.03999
[2022-12-06 15:14:40,618] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:14:40,837] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:14:40,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:14:49,051] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:14:58,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:15:07,217] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:15:17,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:15:27,163] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:15:35,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:15:43,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:15:51,806] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:16:00,056] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:16:08,032] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5523883268033452
[2022-12-06 15:16:08,032] [INFO] [runner_train_mujoco] Average state value: 0.45189222541948154
[2022-12-06 15:16:08,032] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 15:16:08,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.04667
[2022-12-06 15:16:08,134] [INFO] [controller] EPOCH 2 loss ppo:  -0.04351, loss val: 0.04645
[2022-12-06 15:16:08,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.06224, loss val: 0.04483
[2022-12-06 15:16:08,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.07518, loss val: 0.04442
[2022-12-06 15:16:08,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:16:08,475] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:16:08,476] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:16:16,517] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:16:25,628] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:16:35,172] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:16:46,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:16:53,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:17:01,384] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:17:09,497] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:17:16,845] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:17:24,519] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:17:31,997] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7280132756968432
[2022-12-06 15:17:31,997] [INFO] [runner_train_mujoco] Average state value: 0.49185011563698444
[2022-12-06 15:17:31,997] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 15:17:32,051] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.04417
[2022-12-06 15:17:32,084] [INFO] [controller] EPOCH 2 loss ppo:  -0.04892, loss val: 0.04407
[2022-12-06 15:17:32,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.06853, loss val: 0.04316
[2022-12-06 15:17:32,168] [INFO] [controller] EPOCH 4 loss ppo:  -0.08136, loss val: 0.04364
[2022-12-06 15:17:32,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:17:32,386] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:17:32,386] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:17:39,723] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:17:46,817] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:17:54,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:18:02,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:18:09,903] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:18:16,963] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:18:24,249] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:18:31,325] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:18:38,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:18:45,130] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.935693742410097
[2022-12-06 15:18:45,130] [INFO] [runner_train_mujoco] Average state value: 0.5295652113258839
[2022-12-06 15:18:45,130] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 15:18:45,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.01277, loss val: 0.04024
[2022-12-06 15:18:45,206] [INFO] [controller] EPOCH 2 loss ppo:  -0.04207, loss val: 0.03970
[2022-12-06 15:18:45,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.06107, loss val: 0.04002
[2022-12-06 15:18:45,277] [INFO] [controller] EPOCH 4 loss ppo:  -0.07472, loss val: 0.03842
[2022-12-06 15:18:45,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:18:45,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:18:45,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:18:52,427] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:18:59,316] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:19:06,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:19:13,455] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:19:20,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:19:27,108] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:19:34,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:19:40,942] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:19:48,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:19:55,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0366661509214703
[2022-12-06 15:19:55,836] [INFO] [runner_train_mujoco] Average state value: 0.5575163143873215
[2022-12-06 15:19:55,836] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 15:19:55,883] [INFO] [controller] EPOCH 1 loss ppo:  -0.01540, loss val: 0.04592
[2022-12-06 15:19:55,918] [INFO] [controller] EPOCH 2 loss ppo:  -0.04347, loss val: 0.04835
[2022-12-06 15:19:55,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.06091, loss val: 0.04375
[2022-12-06 15:19:56,002] [INFO] [controller] EPOCH 4 loss ppo:  -0.07479, loss val: 0.04013
[2022-12-06 15:19:56,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:19:56,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:19:56,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:20:03,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:20:10,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:20:17,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:20:24,047] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:20:31,078] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:20:37,692] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:20:44,508] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:20:51,187] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:20:57,759] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:21:04,215] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.33109093056766
[2022-12-06 15:21:04,215] [INFO] [runner_train_mujoco] Average state value: 0.5159134435455004
[2022-12-06 15:21:04,215] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 15:21:04,265] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.05174
[2022-12-06 15:21:04,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.04354, loss val: 0.04751
[2022-12-06 15:21:04,349] [INFO] [controller] EPOCH 3 loss ppo:  -0.06472, loss val: 0.04763
[2022-12-06 15:21:04,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.07875, loss val: 0.04889
[2022-12-06 15:21:04,398] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:21:04,604] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:21:04,605] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:21:11,177] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:21:17,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:21:24,716] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:21:31,669] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:21:38,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:21:45,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:21:51,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:21:59,394] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:22:07,064] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:22:16,248] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.513085633603299
[2022-12-06 15:22:16,248] [INFO] [runner_train_mujoco] Average state value: 0.48236407438913975
[2022-12-06 15:22:16,248] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 15:22:16,298] [INFO] [controller] EPOCH 1 loss ppo:  -0.01605, loss val: 0.03720
[2022-12-06 15:22:16,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.04755, loss val: 0.03659
[2022-12-06 15:22:16,384] [INFO] [controller] EPOCH 3 loss ppo:  -0.06202, loss val: 0.03775
[2022-12-06 15:22:16,423] [INFO] [controller] EPOCH 4 loss ppo:  -0.07519, loss val: 0.03568
[2022-12-06 15:22:16,433] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:22:16,630] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:22:16,631] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:22:24,027] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:22:31,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:22:38,950] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:22:47,058] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:22:55,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:23:02,946] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:23:09,772] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:23:16,698] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:23:23,622] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:23:30,629] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6105251653278243
[2022-12-06 15:23:30,629] [INFO] [runner_train_mujoco] Average state value: 0.5052896540562312
[2022-12-06 15:23:30,629] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 15:23:30,679] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.04900
[2022-12-06 15:23:30,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.04728, loss val: 0.04580
[2022-12-06 15:23:30,764] [INFO] [controller] EPOCH 3 loss ppo:  -0.06483, loss val: 0.04536
[2022-12-06 15:23:30,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.07630, loss val: 0.04575
[2022-12-06 15:23:30,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:23:31,009] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:23:31,010] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:23:37,971] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:23:45,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:23:52,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:23:59,732] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:24:06,748] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:24:13,775] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:24:21,427] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:24:29,836] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:24:38,164] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:24:45,168] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5366708580559667
[2022-12-06 15:24:45,168] [INFO] [runner_train_mujoco] Average state value: 0.5343505888283253
[2022-12-06 15:24:45,168] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 15:24:45,219] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.05177
[2022-12-06 15:24:45,264] [INFO] [controller] EPOCH 2 loss ppo:  -0.03735, loss val: 0.05039
[2022-12-06 15:24:45,306] [INFO] [controller] EPOCH 3 loss ppo:  -0.05667, loss val: 0.04758
[2022-12-06 15:24:45,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.07264, loss val: 0.04615
[2022-12-06 15:24:45,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:24:45,570] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:24:45,570] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:24:52,971] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:25:00,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:25:08,025] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:25:15,378] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:25:23,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:25:30,786] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:25:37,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:25:44,982] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:25:52,349] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:25:59,424] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8884047756908493
[2022-12-06 15:25:59,425] [INFO] [runner_train_mujoco] Average state value: 0.6139884627262753
[2022-12-06 15:25:59,425] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 15:25:59,475] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.06114
[2022-12-06 15:25:59,518] [INFO] [controller] EPOCH 2 loss ppo:  -0.03740, loss val: 0.06168
[2022-12-06 15:25:59,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.05452, loss val: 0.06141
[2022-12-06 15:25:59,598] [INFO] [controller] EPOCH 4 loss ppo:  -0.06736, loss val: 0.05916
[2022-12-06 15:25:59,606] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:25:59,802] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:25:59,803] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:26:06,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:26:14,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:26:21,378] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:26:28,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:26:36,430] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:26:44,590] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:26:52,004] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:26:59,499] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:27:06,943] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:27:14,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9800792657646684
[2022-12-06 15:27:14,017] [INFO] [runner_train_mujoco] Average state value: 0.6002447466850281
[2022-12-06 15:27:14,017] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 15:27:14,075] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.06645
[2022-12-06 15:27:14,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.03441, loss val: 0.06215
[2022-12-06 15:27:14,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.05526, loss val: 0.05852
[2022-12-06 15:27:14,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.07172, loss val: 0.05599
[2022-12-06 15:27:14,224] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:27:14,442] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:27:14,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:27:21,819] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:27:28,856] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:27:36,134] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:27:43,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:27:50,218] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:27:57,464] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:28:04,673] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:28:11,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:28:18,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:28:25,797] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.045151846777114
[2022-12-06 15:28:25,797] [INFO] [runner_train_mujoco] Average state value: 0.5236142722566923
[2022-12-06 15:28:25,797] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 15:28:25,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.04261
[2022-12-06 15:28:25,875] [INFO] [controller] EPOCH 2 loss ppo:  -0.03955, loss val: 0.04206
[2022-12-06 15:28:25,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.05494, loss val: 0.04101
[2022-12-06 15:28:25,956] [INFO] [controller] EPOCH 4 loss ppo:  -0.07151, loss val: 0.04108
[2022-12-06 15:28:25,966] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:28:26,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:28:26,149] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:28:33,473] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:28:41,765] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:28:48,486] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:28:55,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:29:02,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:29:09,053] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:29:15,702] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:29:22,933] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:29:32,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:29:41,360] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9356873739861484
[2022-12-06 15:29:41,361] [INFO] [runner_train_mujoco] Average state value: 0.4523188827633858
[2022-12-06 15:29:41,361] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 15:29:41,526] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04168
[2022-12-06 15:29:41,654] [INFO] [controller] EPOCH 2 loss ppo:  -0.04550, loss val: 0.04206
[2022-12-06 15:29:41,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.06777, loss val: 0.04214
[2022-12-06 15:29:41,832] [INFO] [controller] EPOCH 4 loss ppo:  -0.08191, loss val: 0.04259
[2022-12-06 15:29:41,846] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:29:42,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:29:42,187] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:29:50,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:29:58,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:30:05,899] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:30:13,749] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:30:23,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:30:29,873] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:30:36,732] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:30:43,439] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:30:50,133] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:30:57,400] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4060170483691428
[2022-12-06 15:30:57,400] [INFO] [runner_train_mujoco] Average state value: 0.4312278645336628
[2022-12-06 15:30:57,400] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 15:30:57,455] [INFO] [controller] EPOCH 1 loss ppo:  -0.01522, loss val: 0.06722
[2022-12-06 15:30:57,498] [INFO] [controller] EPOCH 2 loss ppo:  -0.03489, loss val: 0.06727
[2022-12-06 15:30:57,540] [INFO] [controller] EPOCH 3 loss ppo:  -0.04862, loss val: 0.06323
[2022-12-06 15:30:57,589] [INFO] [controller] EPOCH 4 loss ppo:  -0.06488, loss val: 0.05920
[2022-12-06 15:30:57,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:30:57,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:30:57,814] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:31:05,265] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:31:12,513] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:31:19,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:31:29,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:31:37,306] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:31:45,107] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:31:53,228] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:32:02,405] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:32:10,434] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:32:18,747] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.027213157607037
[2022-12-06 15:32:18,747] [INFO] [runner_train_mujoco] Average state value: 0.47777768147985145
[2022-12-06 15:32:18,747] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 15:32:18,806] [INFO] [controller] EPOCH 1 loss ppo:  -0.01510, loss val: 0.04206
[2022-12-06 15:32:18,849] [INFO] [controller] EPOCH 2 loss ppo:  -0.04451, loss val: 0.04283
[2022-12-06 15:32:18,900] [INFO] [controller] EPOCH 3 loss ppo:  -0.06333, loss val: 0.04482
[2022-12-06 15:32:18,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.07633, loss val: 0.04381
[2022-12-06 15:32:18,956] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:32:19,179] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:32:19,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:32:29,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:32:36,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:32:43,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:32:51,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:32:58,686] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:33:06,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:33:15,012] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:33:23,088] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:33:32,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:33:40,852] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.62145974023869
[2022-12-06 15:33:40,852] [INFO] [runner_train_mujoco] Average state value: 0.5063473030924797
[2022-12-06 15:33:40,852] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 15:33:40,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.04040
[2022-12-06 15:33:40,955] [INFO] [controller] EPOCH 2 loss ppo:  -0.04089, loss val: 0.04020
[2022-12-06 15:33:41,000] [INFO] [controller] EPOCH 3 loss ppo:  -0.05641, loss val: 0.04331
[2022-12-06 15:33:41,043] [INFO] [controller] EPOCH 4 loss ppo:  -0.07161, loss val: 0.03986
[2022-12-06 15:33:41,054] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:33:41,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:33:41,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:33:51,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:34:02,060] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:34:11,313] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:34:19,564] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:34:29,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:34:39,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:34:50,397] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:34:58,724] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:35:06,803] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:35:15,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7366991295171927
[2022-12-06 15:35:15,389] [INFO] [runner_train_mujoco] Average state value: 0.4925272206316391
[2022-12-06 15:35:15,390] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 15:35:15,455] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04563
[2022-12-06 15:35:15,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.03313, loss val: 0.04569
[2022-12-06 15:35:15,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.05476, loss val: 0.05197
[2022-12-06 15:35:15,705] [INFO] [controller] EPOCH 4 loss ppo:  -0.06983, loss val: 0.04452
[2022-12-06 15:35:15,757] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:35:15,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:35:15,998] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:35:28,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:35:37,857] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:35:51,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:36:00,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:36:09,037] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:36:19,150] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:36:28,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:36:37,465] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:36:46,745] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:36:55,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.941642998109797
[2022-12-06 15:36:55,340] [INFO] [runner_train_mujoco] Average state value: 0.5099722731113434
[2022-12-06 15:36:55,340] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 15:36:55,400] [INFO] [controller] EPOCH 1 loss ppo:  -0.01767, loss val: 0.03028
[2022-12-06 15:36:55,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.04118, loss val: 0.03049
[2022-12-06 15:36:55,488] [INFO] [controller] EPOCH 3 loss ppo:  -0.05695, loss val: 0.02975
[2022-12-06 15:36:55,532] [INFO] [controller] EPOCH 4 loss ppo:  -0.07275, loss val: 0.02961
[2022-12-06 15:36:55,543] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:36:55,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:36:55,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:37:04,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:37:12,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:37:21,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:37:28,646] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:37:36,944] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:37:46,489] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:37:55,211] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:38:05,038] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:38:13,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:38:21,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.304551975608758
[2022-12-06 15:38:21,291] [INFO] [runner_train_mujoco] Average state value: 0.5299445380469163
[2022-12-06 15:38:21,292] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 15:38:21,346] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.03412
[2022-12-06 15:38:21,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.03735, loss val: 0.03443
[2022-12-06 15:38:21,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.05436, loss val: 0.03361
[2022-12-06 15:38:21,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.06933, loss val: 0.03373
[2022-12-06 15:38:21,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:38:21,689] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:38:21,689] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:38:29,600] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:38:37,828] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:38:45,403] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:38:52,847] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:38:59,830] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:39:07,040] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:39:14,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:39:22,445] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:39:30,671] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:39:41,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.256592736545233
[2022-12-06 15:39:41,486] [INFO] [runner_train_mujoco] Average state value: 0.5491323114434878
[2022-12-06 15:39:41,486] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 15:39:41,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.04466
[2022-12-06 15:39:41,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.03187, loss val: 0.04462
[2022-12-06 15:39:41,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.04775, loss val: 0.04335
[2022-12-06 15:39:41,826] [INFO] [controller] EPOCH 4 loss ppo:  -0.06324, loss val: 0.04232
[2022-12-06 15:39:41,839] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:39:42,120] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:39:42,120] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:39:50,295] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:39:58,231] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:40:06,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:40:14,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:40:20,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:40:27,750] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:40:34,997] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:40:42,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:40:49,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:40:56,234] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.342148025292786
[2022-12-06 15:40:56,234] [INFO] [runner_train_mujoco] Average state value: 0.5100558825458089
[2022-12-06 15:40:56,235] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 15:40:56,284] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04667
[2022-12-06 15:40:56,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.03438, loss val: 0.04651
[2022-12-06 15:40:56,370] [INFO] [controller] EPOCH 3 loss ppo:  -0.05195, loss val: 0.04718
[2022-12-06 15:40:56,410] [INFO] [controller] EPOCH 4 loss ppo:  -0.06804, loss val: 0.04880
[2022-12-06 15:40:56,419] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:40:56,628] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:40:56,629] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:41:03,538] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:41:11,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:41:19,232] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:41:31,366] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:41:39,368] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:41:49,155] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:41:57,920] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:42:06,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:42:14,595] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:42:22,461] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.79253809158192
[2022-12-06 15:42:22,461] [INFO] [runner_train_mujoco] Average state value: 0.519063479622205
[2022-12-06 15:42:22,461] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 15:42:22,527] [INFO] [controller] EPOCH 1 loss ppo:  -0.01575, loss val: 0.04839
[2022-12-06 15:42:22,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.03824, loss val: 0.04800
[2022-12-06 15:42:22,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.05371, loss val: 0.04716
[2022-12-06 15:42:22,717] [INFO] [controller] EPOCH 4 loss ppo:  -0.07032, loss val: 0.04695
[2022-12-06 15:42:22,727] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:42:22,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:42:22,958] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:42:30,464] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:42:38,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:42:47,102] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:42:55,779] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:43:04,512] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:43:12,974] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:43:22,316] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:43:30,910] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:43:38,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:43:46,830] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.400346311360415
[2022-12-06 15:43:46,830] [INFO] [runner_train_mujoco] Average state value: 0.49524150265256567
[2022-12-06 15:43:46,831] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 15:43:46,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.03192
[2022-12-06 15:43:46,936] [INFO] [controller] EPOCH 2 loss ppo:  -0.03628, loss val: 0.03198
[2022-12-06 15:43:46,991] [INFO] [controller] EPOCH 3 loss ppo:  -0.05334, loss val: 0.03406
[2022-12-06 15:43:47,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.06497, loss val: 0.03030
[2022-12-06 15:43:47,057] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:43:47,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:43:47,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:43:55,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:44:04,097] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:44:12,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:44:22,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:44:31,985] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:44:40,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:44:49,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:44:58,510] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:45:07,584] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:45:16,688] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.8154300689748855
[2022-12-06 15:45:16,688] [INFO] [runner_train_mujoco] Average state value: 0.48963466677069667
[2022-12-06 15:45:16,688] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 15:45:16,840] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.05565
[2022-12-06 15:45:16,951] [INFO] [controller] EPOCH 2 loss ppo:  -0.03747, loss val: 0.05502
[2022-12-06 15:45:17,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.05271, loss val: 0.05629
[2022-12-06 15:45:17,253] [INFO] [controller] EPOCH 4 loss ppo:  -0.06608, loss val: 0.05499
[2022-12-06 15:45:17,272] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:45:17,665] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:45:17,667] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:45:25,788] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:45:33,235] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:45:40,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:45:48,104] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:45:55,872] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:46:03,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:46:11,802] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:46:19,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:46:27,067] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:46:34,283] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.539758209062636
[2022-12-06 15:46:34,283] [INFO] [runner_train_mujoco] Average state value: 0.43365243811657034
[2022-12-06 15:46:34,283] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 15:46:34,332] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.08184
[2022-12-06 15:46:34,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.02989, loss val: 0.08104
[2022-12-06 15:46:34,407] [INFO] [controller] EPOCH 3 loss ppo:  -0.04762, loss val: 0.08058
[2022-12-06 15:46:34,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.06263, loss val: 0.07848
[2022-12-06 15:46:34,462] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:46:34,627] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:46:34,628] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:46:44,199] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:46:51,469] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:46:58,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:47:06,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:47:13,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:47:21,507] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:47:29,111] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:47:36,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:47:44,282] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:47:51,653] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.61414993836798
[2022-12-06 15:47:51,653] [INFO] [runner_train_mujoco] Average state value: 0.4671353240410487
[2022-12-06 15:47:51,653] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 15:47:51,718] [INFO] [controller] EPOCH 1 loss ppo:  -0.01249, loss val: 0.04827
[2022-12-06 15:47:51,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.02692, loss val: 0.04826
[2022-12-06 15:47:51,853] [INFO] [controller] EPOCH 3 loss ppo:  -0.04297, loss val: 0.04778
[2022-12-06 15:47:51,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.05820, loss val: 0.04751
[2022-12-06 15:47:51,924] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:47:52,146] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:47:52,146] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:47:59,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:48:06,192] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:48:13,603] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:48:20,571] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:48:27,558] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:48:34,505] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:48:41,357] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:48:48,483] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:48:55,734] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:49:03,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7101251846572705
[2022-12-06 15:49:03,111] [INFO] [runner_train_mujoco] Average state value: 0.4314335602025191
[2022-12-06 15:49:03,111] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 15:49:03,163] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.06088
[2022-12-06 15:49:03,205] [INFO] [controller] EPOCH 2 loss ppo:  -0.03459, loss val: 0.06256
[2022-12-06 15:49:03,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.05170, loss val: 0.06093
[2022-12-06 15:49:03,289] [INFO] [controller] EPOCH 4 loss ppo:  -0.06627, loss val: 0.06076
[2022-12-06 15:49:03,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:49:03,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:49:03,468] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:49:10,349] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:49:17,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:49:28,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:49:35,077] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:49:41,915] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:49:48,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:49:55,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:50:04,066] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:50:12,964] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:50:21,811] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.600782147182716
[2022-12-06 15:50:21,811] [INFO] [runner_train_mujoco] Average state value: 0.4702164642723898
[2022-12-06 15:50:21,812] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 15:50:21,908] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.05953
[2022-12-06 15:50:21,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.03113, loss val: 0.05939
[2022-12-06 15:50:22,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.05180, loss val: 0.05750
[2022-12-06 15:50:22,114] [INFO] [controller] EPOCH 4 loss ppo:  -0.06157, loss val: 0.05567
[2022-12-06 15:50:22,127] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:50:22,399] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:50:22,401] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:50:31,351] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:50:37,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:50:44,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:50:51,228] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:50:58,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:51:05,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:51:11,429] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:51:17,979] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:51:25,043] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:51:32,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.768978146428948
[2022-12-06 15:51:32,339] [INFO] [runner_train_mujoco] Average state value: 0.4480990823705991
[2022-12-06 15:51:32,339] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 15:51:32,394] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.04856
[2022-12-06 15:51:32,434] [INFO] [controller] EPOCH 2 loss ppo:  -0.03219, loss val: 0.04960
[2022-12-06 15:51:32,476] [INFO] [controller] EPOCH 3 loss ppo:  -0.04586, loss val: 0.04894
[2022-12-06 15:51:32,519] [INFO] [controller] EPOCH 4 loss ppo:  -0.05598, loss val: 0.04842
[2022-12-06 15:51:32,529] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:51:32,737] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:51:32,738] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:51:39,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:51:46,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:51:53,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:52:00,876] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:52:07,665] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:52:14,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:52:22,062] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:52:29,074] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:52:36,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:52:43,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.269498822796735
[2022-12-06 15:52:43,447] [INFO] [runner_train_mujoco] Average state value: 0.45295975112915043
[2022-12-06 15:52:43,447] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 15:52:43,495] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.04667
[2022-12-06 15:52:43,541] [INFO] [controller] EPOCH 2 loss ppo:  -0.03061, loss val: 0.04663
[2022-12-06 15:52:43,586] [INFO] [controller] EPOCH 3 loss ppo:  -0.04566, loss val: 0.04507
[2022-12-06 15:52:43,629] [INFO] [controller] EPOCH 4 loss ppo:  -0.05745, loss val: 0.04484
[2022-12-06 15:52:43,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:52:43,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:52:43,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:52:51,653] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:52:59,492] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:53:06,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:53:14,165] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:53:21,344] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:53:28,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:53:36,947] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:53:44,511] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:53:52,216] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:53:59,758] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.812109252651286
[2022-12-06 15:53:59,758] [INFO] [runner_train_mujoco] Average state value: 0.4260264454310139
[2022-12-06 15:53:59,758] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 15:53:59,813] [INFO] [controller] EPOCH 1 loss ppo:  -0.01568, loss val: 0.05488
[2022-12-06 15:53:59,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.03179, loss val: 0.05886
[2022-12-06 15:53:59,911] [INFO] [controller] EPOCH 3 loss ppo:  -0.04534, loss val: 0.05607
[2022-12-06 15:53:59,966] [INFO] [controller] EPOCH 4 loss ppo:  -0.05883, loss val: 0.05403
[2022-12-06 15:53:59,977] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:54:00,208] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:54:00,209] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:54:08,061] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:54:15,907] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:54:23,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:54:33,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:54:40,838] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:54:47,995] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:54:55,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:55:03,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:55:11,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:55:19,929] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.908251591453168
[2022-12-06 15:55:19,929] [INFO] [runner_train_mujoco] Average state value: 0.45650558106104533
[2022-12-06 15:55:19,929] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 15:55:19,995] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.05566
[2022-12-06 15:55:20,065] [INFO] [controller] EPOCH 2 loss ppo:  -0.03002, loss val: 0.05688
[2022-12-06 15:55:20,155] [INFO] [controller] EPOCH 3 loss ppo:  -0.04078, loss val: 0.05652
[2022-12-06 15:55:20,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.05046, loss val: 0.05507
[2022-12-06 15:55:20,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:55:20,498] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:55:20,498] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:55:29,778] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:55:41,082] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:55:49,796] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:55:58,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:56:06,248] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:56:14,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:56:23,326] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:56:31,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:56:39,865] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:56:50,653] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.740665403265174
[2022-12-06 15:56:50,654] [INFO] [runner_train_mujoco] Average state value: 0.4457909376422564
[2022-12-06 15:56:50,654] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 15:56:50,920] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.05455
[2022-12-06 15:56:51,335] [INFO] [controller] EPOCH 2 loss ppo:  -0.02715, loss val: 0.05475
[2022-12-06 15:56:51,788] [INFO] [controller] EPOCH 3 loss ppo:  -0.04392, loss val: 0.05328
[2022-12-06 15:56:52,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.05742, loss val: 0.05340
[2022-12-06 15:56:52,053] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:56:52,503] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:56:52,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:57:04,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:57:14,900] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:57:24,304] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:57:32,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:57:41,357] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:57:49,252] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:57:57,449] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:58:05,798] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:58:13,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:58:22,418] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7155325699380874
[2022-12-06 15:58:22,418] [INFO] [runner_train_mujoco] Average state value: 0.4865858864026765
[2022-12-06 15:58:22,418] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 15:58:22,474] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.04488
[2022-12-06 15:58:22,516] [INFO] [controller] EPOCH 2 loss ppo:  -0.02910, loss val: 0.04342
[2022-12-06 15:58:22,628] [INFO] [controller] EPOCH 3 loss ppo:  -0.04356, loss val: 0.04118
[2022-12-06 15:58:22,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.05454, loss val: 0.04069
[2022-12-06 15:58:22,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:58:22,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:58:22,862] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:58:30,583] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:58:38,527] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:58:46,262] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:58:54,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:59:02,197] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:59:09,965] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:59:19,178] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:59:28,144] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:59:36,386] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:59:44,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.109227797209262
[2022-12-06 15:59:44,272] [INFO] [runner_train_mujoco] Average state value: 0.5144148926312725
[2022-12-06 15:59:44,272] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 15:59:44,323] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.03321
[2022-12-06 15:59:44,363] [INFO] [controller] EPOCH 2 loss ppo:  -0.02379, loss val: 0.03333
[2022-12-06 15:59:44,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.03687, loss val: 0.03364
[2022-12-06 15:59:44,446] [INFO] [controller] EPOCH 4 loss ppo:  -0.04693, loss val: 0.03394
[2022-12-06 15:59:44,455] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:59:44,671] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:59:44,672] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:59:52,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:00:00,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:00:08,315] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:00:16,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:00:23,467] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:00:30,674] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:00:37,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:00:45,288] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:00:52,980] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:01:01,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.270478114625733
[2022-12-06 16:01:01,912] [INFO] [runner_train_mujoco] Average state value: 0.4841009286145369
[2022-12-06 16:01:01,912] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 16:01:01,981] [INFO] [controller] EPOCH 1 loss ppo:  -0.01548, loss val: 0.06347
[2022-12-06 16:01:02,052] [INFO] [controller] EPOCH 2 loss ppo:  -0.02831, loss val: 0.06564
[2022-12-06 16:01:02,125] [INFO] [controller] EPOCH 3 loss ppo:  -0.04031, loss val: 0.06286
[2022-12-06 16:01:02,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.05073, loss val: 0.06257
[2022-12-06 16:01:02,234] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:01:02,459] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:01:02,460] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:01:11,283] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:01:19,850] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:01:29,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:01:37,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:01:45,551] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:01:53,785] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:02:02,325] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:02:11,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:02:19,450] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:02:31,602] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.168437226896556
[2022-12-06 16:02:31,603] [INFO] [runner_train_mujoco] Average state value: 0.5225893327395121
[2022-12-06 16:02:31,603] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 16:02:31,969] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.04038
[2022-12-06 16:02:32,085] [INFO] [controller] EPOCH 2 loss ppo:  -0.02234, loss val: 0.03875
[2022-12-06 16:02:32,144] [INFO] [controller] EPOCH 3 loss ppo:  -0.03426, loss val: 0.04032
[2022-12-06 16:02:32,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.04389, loss val: 0.03821
[2022-12-06 16:02:32,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:02:32,466] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:02:32,466] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:02:42,561] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:02:55,527] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:03:06,191] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:03:16,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:03:27,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:03:38,462] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:03:49,085] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:04:00,358] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:04:11,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:04:23,972] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.537000286833193
[2022-12-06 16:04:23,973] [INFO] [runner_train_mujoco] Average state value: 0.48733935551593693
[2022-12-06 16:04:23,973] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 16:04:24,050] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.06718
[2022-12-06 16:04:24,112] [INFO] [controller] EPOCH 2 loss ppo:  -0.02185, loss val: 0.06794
[2022-12-06 16:04:24,190] [INFO] [controller] EPOCH 3 loss ppo:  -0.03454, loss val: 0.06811
[2022-12-06 16:04:24,262] [INFO] [controller] EPOCH 4 loss ppo:  -0.04479, loss val: 0.06626
[2022-12-06 16:04:24,275] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:04:24,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:04:24,562] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:04:36,124] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:04:47,370] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:05:00,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:05:12,232] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:05:22,861] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:05:35,353] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:05:47,189] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:05:58,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:06:08,574] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:06:18,675] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.963072642760861
[2022-12-06 16:06:18,675] [INFO] [runner_train_mujoco] Average state value: 0.5029534560069442
[2022-12-06 16:06:18,675] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 16:06:18,747] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.05228
[2022-12-06 16:06:18,814] [INFO] [controller] EPOCH 2 loss ppo:  -0.02308, loss val: 0.05150
[2022-12-06 16:06:18,883] [INFO] [controller] EPOCH 3 loss ppo:  -0.03532, loss val: 0.05094
[2022-12-06 16:06:18,947] [INFO] [controller] EPOCH 4 loss ppo:  -0.04420, loss val: 0.05241
[2022-12-06 16:06:18,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:06:19,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:06:19,243] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:06:30,002] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:06:40,753] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:06:51,720] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:07:02,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:07:14,561] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:07:25,435] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:07:35,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:07:44,939] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:07:54,685] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:08:04,643] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.918074482692843
[2022-12-06 16:08:04,644] [INFO] [runner_train_mujoco] Average state value: 0.4619902488986651
[2022-12-06 16:08:04,644] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 16:08:04,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.07336
[2022-12-06 16:08:04,759] [INFO] [controller] EPOCH 2 loss ppo:  -0.01931, loss val: 0.07517
[2022-12-06 16:08:04,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.02818, loss val: 0.07280
[2022-12-06 16:08:04,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.03751, loss val: 0.07708
[2022-12-06 16:08:04,871] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:08:05,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:08:05,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:08:15,564] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:08:25,503] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:08:35,478] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:08:44,868] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:08:53,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:09:03,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:09:12,579] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:09:22,102] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:09:31,989] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:09:41,056] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.9257788516626055
[2022-12-06 16:09:41,056] [INFO] [runner_train_mujoco] Average state value: 0.5022063701227306
[2022-12-06 16:09:41,056] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 16:09:41,130] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.04460
[2022-12-06 16:09:41,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.01827, loss val: 0.04517
[2022-12-06 16:09:41,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.02656, loss val: 0.04393
[2022-12-06 16:09:41,311] [INFO] [controller] EPOCH 4 loss ppo:  -0.03672, loss val: 0.04428
[2022-12-06 16:09:41,322] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:09:41,559] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:09:41,560] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:09:51,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:10:02,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:10:11,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:10:20,919] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:10:30,429] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:10:40,815] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:10:51,746] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:11:02,374] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:11:12,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:11:21,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.7356350037112005
[2022-12-06 16:11:21,651] [INFO] [runner_train_mujoco] Average state value: 0.5162333087821801
[2022-12-06 16:11:21,651] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 16:11:21,727] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.04320
[2022-12-06 16:11:21,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.01956, loss val: 0.04254
[2022-12-06 16:11:21,833] [INFO] [controller] EPOCH 3 loss ppo:  -0.02733, loss val: 0.04285
[2022-12-06 16:11:21,885] [INFO] [controller] EPOCH 4 loss ppo:  -0.03570, loss val: 0.04236
[2022-12-06 16:11:21,896] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:11:22,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:11:22,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:11:32,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:11:43,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:11:54,143] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:12:04,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:12:15,509] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:12:25,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:12:36,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:12:46,798] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:12:57,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:13:07,369] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.704233145916084
[2022-12-06 16:13:07,370] [INFO] [runner_train_mujoco] Average state value: 0.5306848170558611
[2022-12-06 16:13:07,370] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 16:13:07,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.03456
[2022-12-06 16:13:07,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.01800, loss val: 0.03510
[2022-12-06 16:13:07,535] [INFO] [controller] EPOCH 3 loss ppo:  -0.02408, loss val: 0.03443
[2022-12-06 16:13:07,585] [INFO] [controller] EPOCH 4 loss ppo:  -0.02994, loss val: 0.03471
[2022-12-06 16:13:07,597] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:13:07,844] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:13:07,844] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:13:18,591] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:13:29,231] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:13:39,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:13:49,559] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:13:59,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:14:09,543] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:14:19,417] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:14:28,853] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:14:38,587] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:14:48,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.478027577377799
[2022-12-06 16:14:48,173] [INFO] [runner_train_mujoco] Average state value: 0.5083978530156115
[2022-12-06 16:14:48,173] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 16:14:48,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.04693
[2022-12-06 16:14:48,321] [INFO] [controller] EPOCH 2 loss ppo:  -0.01535, loss val: 0.04731
[2022-12-06 16:14:48,396] [INFO] [controller] EPOCH 3 loss ppo:  -0.01761, loss val: 0.04681
[2022-12-06 16:14:48,457] [INFO] [controller] EPOCH 4 loss ppo:  -0.02103, loss val: 0.04679
[2022-12-06 16:14:48,470] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:14:48,625] [INFO] [optimize] Finished learning.
