[2022-12-07 08:38:20,325] [INFO] [optimize] Starting learning
[2022-12-07 08:38:20,345] [INFO] [optimize] Starting learning process..
[2022-12-07 08:38:20,451] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:38:20,451] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:38:30,086] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:38:38,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:38:46,767] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:38:56,582] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:39:05,052] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:39:13,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:39:21,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:39:29,575] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:39:37,821] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:39:45,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5007202147431289
[2022-12-07 08:39:45,505] [INFO] [runner_train_mujoco] Average state value: -0.14170188561206062
[2022-12-07 08:39:45,505] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:39:45,559] [INFO] [controller] EPOCH 1 loss ppo:  -0.01606, loss val: 0.72795
[2022-12-07 08:39:45,606] [INFO] [controller] EPOCH 2 loss ppo:  -0.05356, loss val: 0.66178
[2022-12-07 08:39:45,652] [INFO] [controller] EPOCH 3 loss ppo:  -0.07173, loss val: 0.60679
[2022-12-07 08:39:45,694] [INFO] [controller] EPOCH 4 loss ppo:  -0.08414, loss val: 0.53992
[2022-12-07 08:39:45,705] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:39:45,918] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:39:45,918] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:39:54,465] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:40:02,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:40:10,773] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:40:18,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:27,206] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:40:36,076] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:40:43,841] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:40:51,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:40:59,296] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:41:07,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7636542702631587
[2022-12-07 08:41:07,619] [INFO] [runner_train_mujoco] Average state value: 0.03598965504268805
[2022-12-07 08:41:07,619] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:41:07,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01635, loss val: 0.49920
[2022-12-07 08:41:07,723] [INFO] [controller] EPOCH 2 loss ppo:  -0.05472, loss val: 0.43722
[2022-12-07 08:41:07,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.07273, loss val: 0.39317
[2022-12-07 08:41:07,819] [INFO] [controller] EPOCH 4 loss ppo:  -0.08585, loss val: 0.37548
[2022-12-07 08:41:07,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:41:08,041] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:41:08,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:41:16,044] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:41:24,228] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:41:32,017] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:41:40,525] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:41:48,620] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:41:57,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:42:05,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:42:13,499] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:42:21,861] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:42:29,600] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5075042672125922
[2022-12-07 08:42:29,600] [INFO] [runner_train_mujoco] Average state value: 0.17851408574730157
[2022-12-07 08:42:29,600] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:42:29,651] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.29737
[2022-12-07 08:42:29,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.05154, loss val: 0.27192
[2022-12-07 08:42:29,739] [INFO] [controller] EPOCH 3 loss ppo:  -0.07374, loss val: 0.24300
[2022-12-07 08:42:29,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.08337, loss val: 0.20429
[2022-12-07 08:42:29,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:42:30,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:42:30,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:42:38,231] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:42:46,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:42:54,646] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:43:02,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:43:11,377] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:43:20,140] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:43:28,867] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:43:37,009] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:43:45,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:43:52,491] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4374181544925319
[2022-12-07 08:43:52,491] [INFO] [runner_train_mujoco] Average state value: 0.32877819491426147
[2022-12-07 08:43:52,491] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:43:52,541] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.16234
[2022-12-07 08:43:52,584] [INFO] [controller] EPOCH 2 loss ppo:  -0.05275, loss val: 0.14931
[2022-12-07 08:43:52,628] [INFO] [controller] EPOCH 3 loss ppo:  -0.07117, loss val: 0.13881
[2022-12-07 08:43:52,673] [INFO] [controller] EPOCH 4 loss ppo:  -0.08305, loss val: 0.13127
[2022-12-07 08:43:52,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:43:52,889] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:43:52,889] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:44:00,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:44:09,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:44:17,581] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:44:26,050] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:44:33,779] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:44:41,687] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:44:49,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:44:57,484] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:45:05,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:45:13,478] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.35116212670471925
[2022-12-07 08:45:13,479] [INFO] [runner_train_mujoco] Average state value: 0.4301135389295717
[2022-12-07 08:45:13,479] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:45:13,536] [INFO] [controller] EPOCH 1 loss ppo:  -0.01062, loss val: 0.14619
[2022-12-07 08:45:13,579] [INFO] [controller] EPOCH 2 loss ppo:  -0.03928, loss val: 0.13660
[2022-12-07 08:45:13,622] [INFO] [controller] EPOCH 3 loss ppo:  -0.05659, loss val: 0.12707
[2022-12-07 08:45:13,667] [INFO] [controller] EPOCH 4 loss ppo:  -0.06936, loss val: 0.11404
[2022-12-07 08:45:13,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:45:13,873] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:45:13,874] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:45:22,748] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:45:33,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:45:42,914] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:45:51,716] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:46:00,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:46:09,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:46:18,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:46:27,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:46:37,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:46:45,614] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5922291685108543
[2022-12-07 08:46:45,614] [INFO] [runner_train_mujoco] Average state value: 0.5207036812404792
[2022-12-07 08:46:45,614] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:46:45,674] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.10130
[2022-12-07 08:46:45,727] [INFO] [controller] EPOCH 2 loss ppo:  -0.05564, loss val: 0.09780
[2022-12-07 08:46:45,800] [INFO] [controller] EPOCH 3 loss ppo:  -0.07296, loss val: 0.09438
[2022-12-07 08:46:45,845] [INFO] [controller] EPOCH 4 loss ppo:  -0.08366, loss val: 0.08774
[2022-12-07 08:46:45,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:46:46,069] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:46:46,069] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:46:55,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:47:04,205] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:47:12,743] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:47:21,626] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:47:29,644] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:47:37,700] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:47:47,937] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:47:57,030] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:48:05,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:48:13,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.505256980866299
[2022-12-07 08:48:13,817] [INFO] [runner_train_mujoco] Average state value: 0.58096555527548
[2022-12-07 08:48:13,817] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:48:13,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.00866, loss val: 0.09389
[2022-12-07 08:48:13,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.03579, loss val: 0.08969
[2022-12-07 08:48:13,950] [INFO] [controller] EPOCH 3 loss ppo:  -0.05980, loss val: 0.08489
[2022-12-07 08:48:13,993] [INFO] [controller] EPOCH 4 loss ppo:  -0.07161, loss val: 0.08010
[2022-12-07 08:48:14,003] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:48:14,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:48:14,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:48:22,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:48:30,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:48:38,596] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:48:46,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:48:55,101] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:49:03,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:49:10,964] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:49:18,846] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:49:27,524] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:49:37,086] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.622502935888565
[2022-12-07 08:49:37,086] [INFO] [runner_train_mujoco] Average state value: 0.5647635205710928
[2022-12-07 08:49:37,087] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:49:37,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01097, loss val: 0.07350
[2022-12-07 08:49:37,995] [INFO] [controller] EPOCH 2 loss ppo:  -0.04446, loss val: 0.06941
[2022-12-07 08:49:38,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.06745, loss val: 0.06656
[2022-12-07 08:49:38,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.07878, loss val: 0.06501
[2022-12-07 08:49:38,120] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:49:38,343] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:49:38,344] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:49:47,620] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:49:57,300] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:50:06,972] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:50:16,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:50:25,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:50:34,713] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:50:44,123] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:50:53,013] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:51:02,362] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:51:11,747] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6564226112853231
[2022-12-07 08:51:11,747] [INFO] [runner_train_mujoco] Average state value: 0.5009987956136465
[2022-12-07 08:51:11,747] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:51:11,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.00963, loss val: 0.05890
[2022-12-07 08:51:11,869] [INFO] [controller] EPOCH 2 loss ppo:  -0.04531, loss val: 0.05730
[2022-12-07 08:51:11,922] [INFO] [controller] EPOCH 3 loss ppo:  -0.06241, loss val: 0.05563
[2022-12-07 08:51:11,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.07424, loss val: 0.05439
[2022-12-07 08:51:11,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:51:12,193] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:51:12,193] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:21,389] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:51:30,499] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:51:39,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:51:48,636] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:51:58,002] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:52:07,275] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:52:16,005] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:52:24,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:52:33,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:52:42,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8486762592717234
[2022-12-07 08:52:42,773] [INFO] [runner_train_mujoco] Average state value: 0.4759209334924817
[2022-12-07 08:52:42,774] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 08:52:42,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.05630
[2022-12-07 08:52:42,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.04356, loss val: 0.05554
[2022-12-07 08:52:42,912] [INFO] [controller] EPOCH 3 loss ppo:  -0.06014, loss val: 0.05411
[2022-12-07 08:52:42,955] [INFO] [controller] EPOCH 4 loss ppo:  -0.07478, loss val: 0.05278
[2022-12-07 08:52:42,965] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:52:43,179] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:52:43,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:52:52,449] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:53:01,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:10,610] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:20,054] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:53:29,293] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:38,455] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:53:47,370] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:53:56,619] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:54:05,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:54:14,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7933696673503077
[2022-12-07 08:54:14,829] [INFO] [runner_train_mujoco] Average state value: 0.47038964994996785
[2022-12-07 08:54:14,829] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 08:54:14,885] [INFO] [controller] EPOCH 1 loss ppo:  -0.01001, loss val: 0.05035
[2022-12-07 08:54:14,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.04053, loss val: 0.04918
[2022-12-07 08:54:14,985] [INFO] [controller] EPOCH 3 loss ppo:  -0.06401, loss val: 0.04998
[2022-12-07 08:54:15,033] [INFO] [controller] EPOCH 4 loss ppo:  -0.07546, loss val: 0.04767
[2022-12-07 08:54:15,045] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:54:15,267] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:54:15,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:54:24,881] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:54:34,328] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:54:43,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:54:52,760] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:55:01,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:55:09,851] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:18,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:55:28,304] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:55:37,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:55:47,032] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6092725388957096
[2022-12-07 08:55:47,032] [INFO] [runner_train_mujoco] Average state value: 0.46302406401435536
[2022-12-07 08:55:47,033] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 08:55:47,092] [INFO] [controller] EPOCH 1 loss ppo:  -0.01281, loss val: 0.05509
[2022-12-07 08:55:47,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.04551, loss val: 0.05296
[2022-12-07 08:55:47,184] [INFO] [controller] EPOCH 3 loss ppo:  -0.06725, loss val: 0.05392
[2022-12-07 08:55:47,229] [INFO] [controller] EPOCH 4 loss ppo:  -0.08077, loss val: 0.05099
[2022-12-07 08:55:47,239] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:55:47,456] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:55:47,457] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:55:56,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:56:04,915] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:56:14,331] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:56:24,197] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:56:33,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:56:42,883] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:56:52,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:57:01,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:10,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:19,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6361587104119371
[2022-12-07 08:57:19,931] [INFO] [runner_train_mujoco] Average state value: 0.4861462893982729
[2022-12-07 08:57:19,931] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 08:57:19,996] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.04669
[2022-12-07 08:57:20,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.04166, loss val: 0.04293
[2022-12-07 08:57:20,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.06121, loss val: 0.04176
[2022-12-07 08:57:20,176] [INFO] [controller] EPOCH 4 loss ppo:  -0.07752, loss val: 0.04668
[2022-12-07 08:57:20,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:20,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:20,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:57:29,712] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:57:39,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:57:48,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:57:57,786] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:58:06,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:58:15,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:58:24,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:33,787] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:58:43,222] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:58:52,789] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8852266467557761
[2022-12-07 08:58:52,789] [INFO] [runner_train_mujoco] Average state value: 0.5475845646510522
[2022-12-07 08:58:52,790] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 08:58:52,853] [INFO] [controller] EPOCH 1 loss ppo:  -0.01011, loss val: 0.04782
[2022-12-07 08:58:52,904] [INFO] [controller] EPOCH 2 loss ppo:  -0.03828, loss val: 0.04756
[2022-12-07 08:58:53,022] [INFO] [controller] EPOCH 3 loss ppo:  -0.05724, loss val: 0.04678
[2022-12-07 08:58:53,076] [INFO] [controller] EPOCH 4 loss ppo:  -0.07067, loss val: 0.04659
[2022-12-07 08:58:53,086] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:58:53,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:58:53,299] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:59:02,664] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:59:11,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:59:20,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:59:29,496] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:59:38,399] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:59:47,681] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:59:56,537] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:00:05,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:00:14,848] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:00:23,845] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6452749501821307
[2022-12-07 09:00:23,846] [INFO] [runner_train_mujoco] Average state value: 0.5338800784001748
[2022-12-07 09:00:23,846] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 09:00:23,895] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04956
[2022-12-07 09:00:23,937] [INFO] [controller] EPOCH 2 loss ppo:  -0.04419, loss val: 0.05053
[2022-12-07 09:00:23,981] [INFO] [controller] EPOCH 3 loss ppo:  -0.06562, loss val: 0.05172
[2022-12-07 09:00:24,023] [INFO] [controller] EPOCH 4 loss ppo:  -0.07731, loss val: 0.05128
[2022-12-07 09:00:24,035] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:00:24,252] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:00:24,253] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:00:33,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:00:42,274] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:00:51,533] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:01:00,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:01:09,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:18,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:28,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:01:36,904] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:01:46,184] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:01:55,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5176030286906178
[2022-12-07 09:01:55,508] [INFO] [runner_train_mujoco] Average state value: 0.5203769826889038
[2022-12-07 09:01:55,508] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 09:01:55,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.04735
[2022-12-07 09:01:55,613] [INFO] [controller] EPOCH 2 loss ppo:  -0.04440, loss val: 0.04629
[2022-12-07 09:01:55,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.06255, loss val: 0.04541
[2022-12-07 09:01:55,703] [INFO] [controller] EPOCH 4 loss ppo:  -0.07406, loss val: 0.04687
[2022-12-07 09:01:55,714] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:01:55,941] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:01:55,941] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:05,580] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:02:14,960] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:02:24,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:02:33,409] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:02:42,068] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:02:51,035] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:02:59,788] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:03:09,131] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:03:17,642] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:26,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8346561764845177
[2022-12-07 09:03:26,913] [INFO] [runner_train_mujoco] Average state value: 0.5545978251496951
[2022-12-07 09:03:26,913] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 09:03:26,977] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.04779
[2022-12-07 09:03:27,028] [INFO] [controller] EPOCH 2 loss ppo:  -0.04284, loss val: 0.04520
[2022-12-07 09:03:27,078] [INFO] [controller] EPOCH 3 loss ppo:  -0.06498, loss val: 0.04483
[2022-12-07 09:03:27,127] [INFO] [controller] EPOCH 4 loss ppo:  -0.07847, loss val: 0.04385
[2022-12-07 09:03:27,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:03:27,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:03:27,361] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:03:36,677] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:03:46,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:03:54,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:04:03,513] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:04:13,021] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:04:21,638] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:04:30,862] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:04:39,454] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:04:47,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:04:55,820] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9186343304721232
[2022-12-07 09:04:55,821] [INFO] [runner_train_mujoco] Average state value: 0.5396971860403816
[2022-12-07 09:04:55,821] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 09:04:55,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.04261
[2022-12-07 09:04:55,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.04017, loss val: 0.04460
[2022-12-07 09:04:55,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.05838, loss val: 0.04113
[2022-12-07 09:04:56,017] [INFO] [controller] EPOCH 4 loss ppo:  -0.07460, loss val: 0.03874
[2022-12-07 09:04:56,027] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:04:56,233] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:04:56,234] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:05:04,211] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:05:12,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:20,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:28,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:05:37,113] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:05:45,017] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:05:51,707] [WARNING] [core] Too many contacts. Either the arena memory is full, or nconmax is specified and is exceeded. Increase arena memory allocation, or increase/remove nconmax. (ncon = 150) Time = 23.9260.
[2022-12-07 09:05:53,618] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:06:01,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:06:09,148] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:06:17,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0912205797754007
[2022-12-07 09:06:17,389] [INFO] [runner_train_mujoco] Average state value: 0.5528566807508468
[2022-12-07 09:06:17,389] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 09:06:17,438] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.04302
[2022-12-07 09:06:17,480] [INFO] [controller] EPOCH 2 loss ppo:  -0.04301, loss val: 0.04303
[2022-12-07 09:06:17,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.06056, loss val: 0.04250
[2022-12-07 09:06:17,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.07388, loss val: 0.04159
[2022-12-07 09:06:17,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:06:17,791] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:06:17,791] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:06:25,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:06:34,006] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:06:42,290] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:06:50,121] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:06:57,680] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:07:06,368] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:07:15,045] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:07:24,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:07:32,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:07:40,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9429451008325538
[2022-12-07 09:07:40,543] [INFO] [runner_train_mujoco] Average state value: 0.4755667933051784
[2022-12-07 09:07:40,543] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 09:07:40,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.07328
[2022-12-07 09:07:40,632] [INFO] [controller] EPOCH 2 loss ppo:  -0.04079, loss val: 0.07234
[2022-12-07 09:07:40,675] [INFO] [controller] EPOCH 3 loss ppo:  -0.06020, loss val: 0.06966
[2022-12-07 09:07:40,715] [INFO] [controller] EPOCH 4 loss ppo:  -0.07585, loss val: 0.06826
[2022-12-07 09:07:40,725] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:07:40,944] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:07:40,944] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:07:48,833] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:07:56,675] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:08:04,891] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:08:13,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:08:21,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:08:30,170] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:08:37,936] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:08:45,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:08:53,817] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:09:01,687] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1643268010592043
[2022-12-07 09:09:01,687] [INFO] [runner_train_mujoco] Average state value: 0.4793296764940023
[2022-12-07 09:09:01,687] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 09:09:01,749] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.04876
[2022-12-07 09:09:01,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.03695, loss val: 0.05311
[2022-12-07 09:09:01,834] [INFO] [controller] EPOCH 3 loss ppo:  -0.05662, loss val: 0.04998
[2022-12-07 09:09:01,876] [INFO] [controller] EPOCH 4 loss ppo:  -0.07092, loss val: 0.05316
[2022-12-07 09:09:01,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:09:02,107] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:09:02,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:09:10,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:09:18,535] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:09:25,983] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:09:34,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:09:41,976] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:09:50,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:09:59,031] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:10:06,867] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:10:14,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:10:22,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9446939730197187
[2022-12-07 09:10:22,718] [INFO] [runner_train_mujoco] Average state value: 0.4693879627684752
[2022-12-07 09:10:22,718] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 09:10:22,771] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.05809
[2022-12-07 09:10:22,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.04519, loss val: 0.05794
[2022-12-07 09:10:22,864] [INFO] [controller] EPOCH 3 loss ppo:  -0.06158, loss val: 0.05501
[2022-12-07 09:10:22,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.07770, loss val: 0.05474
[2022-12-07 09:10:22,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:10:23,138] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:10:23,139] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:10:31,706] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:10:39,290] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:10:47,269] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:10:55,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:11:03,561] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:11:11,617] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:11:20,221] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:11:28,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:11:36,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:11:44,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3787333746107953
[2022-12-07 09:11:44,272] [INFO] [runner_train_mujoco] Average state value: 0.5318649921019872
[2022-12-07 09:11:44,272] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 09:11:44,342] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.04455
[2022-12-07 09:11:44,385] [INFO] [controller] EPOCH 2 loss ppo:  -0.03681, loss val: 0.05161
[2022-12-07 09:11:44,429] [INFO] [controller] EPOCH 3 loss ppo:  -0.05656, loss val: 0.04582
[2022-12-07 09:11:44,477] [INFO] [controller] EPOCH 4 loss ppo:  -0.07021, loss val: 0.04305
[2022-12-07 09:11:44,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:11:44,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:11:44,729] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:11:53,048] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:12:01,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:12:08,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:12:17,156] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:12:25,615] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:12:33,581] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:12:42,060] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:12:49,554] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:12:57,671] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:05,695] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2454906377239605
[2022-12-07 09:13:05,695] [INFO] [runner_train_mujoco] Average state value: 0.47020257131507004
[2022-12-07 09:13:05,695] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 09:13:05,744] [INFO] [controller] EPOCH 1 loss ppo:  -0.01537, loss val: 0.06323
[2022-12-07 09:13:05,786] [INFO] [controller] EPOCH 2 loss ppo:  -0.04279, loss val: 0.06279
[2022-12-07 09:13:05,829] [INFO] [controller] EPOCH 3 loss ppo:  -0.06202, loss val: 0.06250
[2022-12-07 09:13:05,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.07408, loss val: 0.06220
[2022-12-07 09:13:05,879] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:06,089] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:06,089] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:13:14,685] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:13:22,912] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:13:31,343] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:13:39,376] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:13:47,459] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:13:55,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:14:02,979] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:14:10,842] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:14:18,965] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:14:27,163] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6500365844469786
[2022-12-07 09:14:27,163] [INFO] [runner_train_mujoco] Average state value: 0.46497014170885087
[2022-12-07 09:14:27,163] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 09:14:27,219] [INFO] [controller] EPOCH 1 loss ppo:  -0.01582, loss val: 0.04769
[2022-12-07 09:14:27,264] [INFO] [controller] EPOCH 2 loss ppo:  -0.04459, loss val: 0.04778
[2022-12-07 09:14:27,304] [INFO] [controller] EPOCH 3 loss ppo:  -0.06453, loss val: 0.04650
[2022-12-07 09:14:27,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.07974, loss val: 0.04636
[2022-12-07 09:14:27,360] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:14:27,568] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:14:27,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:14:35,949] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:14:43,824] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:14:52,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:00,670] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:15:08,837] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:15:16,963] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:15:24,944] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:15:32,843] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:15:40,992] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:15:48,874] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.775399695580073
[2022-12-07 09:15:48,874] [INFO] [runner_train_mujoco] Average state value: 0.45540223896503457
[2022-12-07 09:15:48,875] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 09:15:48,927] [INFO] [controller] EPOCH 1 loss ppo:  -0.01544, loss val: 0.03214
[2022-12-07 09:15:48,971] [INFO] [controller] EPOCH 2 loss ppo:  -0.04246, loss val: 0.03673
[2022-12-07 09:15:49,174] [INFO] [controller] EPOCH 3 loss ppo:  -0.06031, loss val: 0.03244
[2022-12-07 09:15:49,259] [INFO] [controller] EPOCH 4 loss ppo:  -0.07770, loss val: 0.03675
[2022-12-07 09:15:49,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:15:49,488] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:15:49,488] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:15:57,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:16:05,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:16:13,740] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:16:22,276] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:16:30,824] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:16:39,213] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:16:47,150] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:16:54,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:17:02,935] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:17:11,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.79295630258237
[2022-12-07 09:17:11,088] [INFO] [runner_train_mujoco] Average state value: 0.4750889209707577
[2022-12-07 09:17:11,089] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 09:17:11,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.03631
[2022-12-07 09:17:11,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.04005, loss val: 0.03645
[2022-12-07 09:17:11,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.05856, loss val: 0.03761
[2022-12-07 09:17:11,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.07706, loss val: 0.03582
[2022-12-07 09:17:11,301] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:17:11,504] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:17:11,504] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:17:19,656] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:17:28,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:17:36,163] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:17:43,443] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:17:51,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:17:59,354] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:07,672] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:18:15,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:18:23,622] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:18:31,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7220998866854866
[2022-12-07 09:18:31,327] [INFO] [runner_train_mujoco] Average state value: 0.4727036968668302
[2022-12-07 09:18:31,327] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 09:18:31,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01515, loss val: 0.04138
[2022-12-07 09:18:31,416] [INFO] [controller] EPOCH 2 loss ppo:  -0.04245, loss val: 0.04304
[2022-12-07 09:18:31,454] [INFO] [controller] EPOCH 3 loss ppo:  -0.06239, loss val: 0.04507
[2022-12-07 09:18:31,500] [INFO] [controller] EPOCH 4 loss ppo:  -0.08040, loss val: 0.04400
[2022-12-07 09:18:31,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:18:31,743] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:18:31,744] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:18:39,562] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:18:47,464] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:18:55,462] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:19:03,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:19:11,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:19:19,722] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:19:28,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:19:36,239] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:19:44,200] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:19:52,511] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6045873700767266
[2022-12-07 09:19:52,512] [INFO] [runner_train_mujoco] Average state value: 0.46542184050877883
[2022-12-07 09:19:52,512] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 09:19:52,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.04079
[2022-12-07 09:19:52,607] [INFO] [controller] EPOCH 2 loss ppo:  -0.04146, loss val: 0.04186
[2022-12-07 09:19:52,650] [INFO] [controller] EPOCH 3 loss ppo:  -0.06483, loss val: 0.04063
[2022-12-07 09:19:52,693] [INFO] [controller] EPOCH 4 loss ppo:  -0.07851, loss val: 0.04071
[2022-12-07 09:19:52,702] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:19:52,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:19:52,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:20:00,926] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:20:09,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:20:17,281] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:20:25,309] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:20:32,977] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:20:41,708] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:20:49,666] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:20:57,954] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:21:05,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:21:13,748] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8015617779405635
[2022-12-07 09:21:13,748] [INFO] [runner_train_mujoco] Average state value: 0.43872039026518656
[2022-12-07 09:21:13,748] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 09:21:13,799] [INFO] [controller] EPOCH 1 loss ppo:  -0.01571, loss val: 0.07409
[2022-12-07 09:21:13,840] [INFO] [controller] EPOCH 2 loss ppo:  -0.03935, loss val: 0.07138
[2022-12-07 09:21:13,882] [INFO] [controller] EPOCH 3 loss ppo:  -0.05924, loss val: 0.06732
[2022-12-07 09:21:13,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.07082, loss val: 0.06555
[2022-12-07 09:21:13,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:21:14,225] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:21:14,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:21:22,501] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:21:29,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:21:38,156] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:21:46,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:21:54,110] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:22:02,244] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:22:10,210] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:22:18,286] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:22:26,569] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:22:34,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7311153569709896
[2022-12-07 09:22:34,545] [INFO] [runner_train_mujoco] Average state value: 0.4993661681711674
[2022-12-07 09:22:34,545] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 09:22:34,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01587, loss val: 0.04269
[2022-12-07 09:22:34,637] [INFO] [controller] EPOCH 2 loss ppo:  -0.03885, loss val: 0.04330
[2022-12-07 09:22:34,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.05563, loss val: 0.04368
[2022-12-07 09:22:34,793] [INFO] [controller] EPOCH 4 loss ppo:  -0.07181, loss val: 0.04454
[2022-12-07 09:22:34,805] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:22:35,025] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:22:35,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:22:43,476] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:22:51,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:23:00,254] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:23:08,629] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:23:16,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:23:24,938] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:23:32,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:23:40,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:23:48,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:23:56,766] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3485185772730177
[2022-12-07 09:23:56,766] [INFO] [runner_train_mujoco] Average state value: 0.5130609100461007
[2022-12-07 09:23:56,766] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 09:23:56,817] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.03103
[2022-12-07 09:23:56,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.03724, loss val: 0.03066
[2022-12-07 09:23:56,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.05985, loss val: 0.03557
[2022-12-07 09:23:56,946] [INFO] [controller] EPOCH 4 loss ppo:  -0.07712, loss val: 0.03044
[2022-12-07 09:23:56,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:23:57,163] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:23:57,163] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:24:05,464] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:24:13,529] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:24:21,551] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:24:29,408] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:24:37,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:24:45,494] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:24:53,680] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:25:01,656] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:25:09,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:25:17,573] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.424001298707659
[2022-12-07 09:25:17,573] [INFO] [runner_train_mujoco] Average state value: 0.5026147240648666
[2022-12-07 09:25:17,573] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 09:25:17,629] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04163
[2022-12-07 09:25:17,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.03611, loss val: 0.04068
[2022-12-07 09:25:17,721] [INFO] [controller] EPOCH 3 loss ppo:  -0.05222, loss val: 0.04231
[2022-12-07 09:25:17,766] [INFO] [controller] EPOCH 4 loss ppo:  -0.06838, loss val: 0.04047
[2022-12-07 09:25:17,776] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:25:17,989] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:25:17,990] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:25:26,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:25:34,554] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:25:42,419] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:25:50,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:25:58,254] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:26:06,697] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:26:14,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:26:22,667] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:26:30,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:38,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.210472675793286
[2022-12-07 09:26:38,048] [INFO] [runner_train_mujoco] Average state value: 0.47516444094975785
[2022-12-07 09:26:38,048] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 09:26:38,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01568, loss val: 0.03453
[2022-12-07 09:26:38,206] [INFO] [controller] EPOCH 2 loss ppo:  -0.03594, loss val: 0.03580
[2022-12-07 09:26:38,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.05537, loss val: 0.03353
[2022-12-07 09:26:38,296] [INFO] [controller] EPOCH 4 loss ppo:  -0.07092, loss val: 0.03453
[2022-12-07 09:26:38,305] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:38,505] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:38,505] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:26:46,997] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:26:55,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:03,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:27:11,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:27:19,399] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:27:27,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:27:35,633] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:27:43,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:27:51,099] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:27:59,262] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5057006681781844
[2022-12-07 09:27:59,262] [INFO] [runner_train_mujoco] Average state value: 0.45686127031842866
[2022-12-07 09:27:59,263] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 09:27:59,312] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.05003
[2022-12-07 09:27:59,356] [INFO] [controller] EPOCH 2 loss ppo:  -0.03408, loss val: 0.05002
[2022-12-07 09:27:59,396] [INFO] [controller] EPOCH 3 loss ppo:  -0.05438, loss val: 0.04879
[2022-12-07 09:27:59,437] [INFO] [controller] EPOCH 4 loss ppo:  -0.06645, loss val: 0.04476
[2022-12-07 09:27:59,446] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:27:59,673] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:27:59,673] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:28:07,421] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:28:15,653] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:28:23,295] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:28:30,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:28:38,784] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:28:47,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:28:55,949] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:03,916] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:29:11,848] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:29:19,771] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0335293281624933
[2022-12-07 09:29:19,771] [INFO] [runner_train_mujoco] Average state value: 0.435479779213667
[2022-12-07 09:29:19,771] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 09:29:19,839] [INFO] [controller] EPOCH 1 loss ppo:  -0.01526, loss val: 0.07231
[2022-12-07 09:29:19,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.04181, loss val: 0.07152
[2022-12-07 09:29:19,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.06017, loss val: 0.07020
[2022-12-07 09:29:19,981] [INFO] [controller] EPOCH 4 loss ppo:  -0.07217, loss val: 0.06968
[2022-12-07 09:29:19,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:29:20,198] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:29:20,198] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:29:28,271] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:29:36,228] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:29:43,848] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:51,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:29:59,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:30:08,401] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:30:16,334] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:30:24,314] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:32,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:40,061] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.041723872374016
[2022-12-07 09:30:40,061] [INFO] [runner_train_mujoco] Average state value: 0.464242319367826
[2022-12-07 09:30:40,061] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 09:30:40,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.05419
[2022-12-07 09:30:40,162] [INFO] [controller] EPOCH 2 loss ppo:  -0.03787, loss val: 0.05381
[2022-12-07 09:30:40,203] [INFO] [controller] EPOCH 3 loss ppo:  -0.05515, loss val: 0.05343
[2022-12-07 09:30:40,238] [INFO] [controller] EPOCH 4 loss ppo:  -0.06715, loss val: 0.05361
[2022-12-07 09:30:40,250] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:40,436] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:40,436] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:48,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:30:56,506] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:31:04,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:31:12,860] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:31:20,751] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:31:29,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:31:37,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:31:45,912] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:31:54,139] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:32:02,056] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7520005674130967
[2022-12-07 09:32:02,056] [INFO] [runner_train_mujoco] Average state value: 0.5306306767364343
[2022-12-07 09:32:02,056] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 09:32:02,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04126
[2022-12-07 09:32:02,156] [INFO] [controller] EPOCH 2 loss ppo:  -0.03343, loss val: 0.04260
[2022-12-07 09:32:02,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.05352, loss val: 0.04228
[2022-12-07 09:32:02,258] [INFO] [controller] EPOCH 4 loss ppo:  -0.06803, loss val: 0.04086
[2022-12-07 09:32:02,267] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:32:02,473] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:32:02,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:32:12,734] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:32:20,843] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:32:28,113] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:32:36,676] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:32:44,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:32:52,253] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:33:00,749] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:33:10,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:33:18,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:33:25,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2607437235298304
[2022-12-07 09:33:25,818] [INFO] [runner_train_mujoco] Average state value: 0.51311442921559
[2022-12-07 09:33:25,818] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 09:33:25,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.04714
[2022-12-07 09:33:25,919] [INFO] [controller] EPOCH 2 loss ppo:  -0.03376, loss val: 0.04613
[2022-12-07 09:33:25,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.05041, loss val: 0.04504
[2022-12-07 09:33:26,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.06192, loss val: 0.04438
[2022-12-07 09:33:26,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:33:26,255] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:33:26,256] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:33:34,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:33:42,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:33:51,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:33:59,337] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:34:07,434] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:34:14,767] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:34:21,870] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:34:30,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:34:38,549] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:34:46,233] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1051658986181394
[2022-12-07 09:34:46,233] [INFO] [runner_train_mujoco] Average state value: 0.46992801160613695
[2022-12-07 09:34:46,233] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 09:34:46,286] [INFO] [controller] EPOCH 1 loss ppo:  -0.01518, loss val: 0.04823
[2022-12-07 09:34:46,331] [INFO] [controller] EPOCH 2 loss ppo:  -0.03711, loss val: 0.04751
[2022-12-07 09:34:46,376] [INFO] [controller] EPOCH 3 loss ppo:  -0.05387, loss val: 0.04776
[2022-12-07 09:34:46,421] [INFO] [controller] EPOCH 4 loss ppo:  -0.06597, loss val: 0.04575
[2022-12-07 09:34:46,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:34:46,645] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:34:46,646] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:34:54,563] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:35:02,863] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:35:10,538] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:35:17,906] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:35:28,129] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:35:35,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:35:43,771] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:35:51,660] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:35:59,756] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:36:07,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2289997925457463
[2022-12-07 09:36:07,272] [INFO] [runner_train_mujoco] Average state value: 0.44076144346346463
[2022-12-07 09:36:07,272] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 09:36:07,329] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.05168
[2022-12-07 09:36:07,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.02974, loss val: 0.05015
[2022-12-07 09:36:07,415] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.04863
[2022-12-07 09:36:07,456] [INFO] [controller] EPOCH 4 loss ppo:  -0.05882, loss val: 0.05035
[2022-12-07 09:36:07,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:36:07,676] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:36:07,676] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:36:15,524] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:36:23,906] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:36:31,441] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:36:39,231] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:36:46,879] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:36:54,319] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:37:01,765] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:37:09,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:37:18,609] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:37:27,178] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1198677955532244
[2022-12-07 09:37:27,178] [INFO] [runner_train_mujoco] Average state value: 0.44088259147604303
[2022-12-07 09:37:27,178] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 09:37:27,229] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.04148
[2022-12-07 09:37:27,274] [INFO] [controller] EPOCH 2 loss ppo:  -0.03265, loss val: 0.04000
[2022-12-07 09:37:27,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.04939, loss val: 0.04021
[2022-12-07 09:37:27,371] [INFO] [controller] EPOCH 4 loss ppo:  -0.06521, loss val: 0.04050
[2022-12-07 09:37:27,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:37:27,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:37:27,584] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:37:35,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:37:43,641] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:37:51,364] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:37:58,584] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:38:06,690] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:38:15,054] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:38:23,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:38:31,321] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:38:39,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:38:48,874] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.466228708273975
[2022-12-07 09:38:48,875] [INFO] [runner_train_mujoco] Average state value: 0.47812446708480516
[2022-12-07 09:38:48,875] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 09:38:48,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.01570, loss val: 0.04282
[2022-12-07 09:38:48,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.02925, loss val: 0.04188
[2022-12-07 09:38:49,028] [INFO] [controller] EPOCH 3 loss ppo:  -0.04264, loss val: 0.03977
[2022-12-07 09:38:49,078] [INFO] [controller] EPOCH 4 loss ppo:  -0.05923, loss val: 0.03864
[2022-12-07 09:38:49,086] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:38:49,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:38:49,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:38:57,226] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:39:04,596] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:39:12,533] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:39:20,163] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:39:27,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:39:35,196] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:39:42,601] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:39:50,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:39:58,815] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:40:06,908] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.264086156085123
[2022-12-07 09:40:06,908] [INFO] [runner_train_mujoco] Average state value: 0.512095547258854
[2022-12-07 09:40:06,908] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 09:40:06,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04168
[2022-12-07 09:40:07,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.03063, loss val: 0.04252
[2022-12-07 09:40:07,065] [INFO] [controller] EPOCH 3 loss ppo:  -0.04666, loss val: 0.04354
[2022-12-07 09:40:07,116] [INFO] [controller] EPOCH 4 loss ppo:  -0.06070, loss val: 0.04286
[2022-12-07 09:40:07,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:40:07,356] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:40:07,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:40:15,286] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:40:23,524] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:40:31,644] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:40:39,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:40:55,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:41:09,242] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:41:18,705] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:41:27,887] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:41:37,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:41:47,745] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4845243130001706
[2022-12-07 09:41:47,745] [INFO] [runner_train_mujoco] Average state value: 0.4885327815959851
[2022-12-07 09:41:47,745] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 09:41:47,806] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.06348
[2022-12-07 09:41:47,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.03002, loss val: 0.06318
[2022-12-07 09:41:47,924] [INFO] [controller] EPOCH 3 loss ppo:  -0.04693, loss val: 0.06272
[2022-12-07 09:41:47,980] [INFO] [controller] EPOCH 4 loss ppo:  -0.06542, loss val: 0.06226
[2022-12-07 09:41:47,992] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:41:48,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:41:48,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:41:57,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:42:05,934] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:42:13,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:42:23,837] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:42:32,903] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:42:41,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:42:54,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:43:05,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:43:15,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:43:26,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5175063610736865
[2022-12-07 09:43:26,327] [INFO] [runner_train_mujoco] Average state value: 0.4964962779904406
[2022-12-07 09:43:26,328] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 09:43:26,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.06406
[2022-12-07 09:43:26,613] [INFO] [controller] EPOCH 2 loss ppo:  -0.02763, loss val: 0.06386
[2022-12-07 09:43:26,732] [INFO] [controller] EPOCH 3 loss ppo:  -0.04251, loss val: 0.06451
[2022-12-07 09:43:26,952] [INFO] [controller] EPOCH 4 loss ppo:  -0.05798, loss val: 0.06396
[2022-12-07 09:43:26,970] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:43:27,277] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:43:27,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:43:40,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:43:52,584] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:44:09,247] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:44:22,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:44:31,495] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:44:40,482] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:44:49,989] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:45:00,129] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:45:09,795] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:45:18,977] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5950789195544375
[2022-12-07 09:45:18,978] [INFO] [runner_train_mujoco] Average state value: 0.5126954755087694
[2022-12-07 09:45:18,978] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 09:45:19,042] [INFO] [controller] EPOCH 1 loss ppo:  -0.01486, loss val: 0.04854
[2022-12-07 09:45:19,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.03301, loss val: 0.04841
[2022-12-07 09:45:19,137] [INFO] [controller] EPOCH 3 loss ppo:  -0.04837, loss val: 0.04787
[2022-12-07 09:45:19,187] [INFO] [controller] EPOCH 4 loss ppo:  -0.06068, loss val: 0.04781
[2022-12-07 09:45:19,198] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:45:19,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:45:19,419] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:45:32,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:45:42,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:45:51,516] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:46:00,791] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:46:09,676] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:46:18,234] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:46:27,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:46:39,031] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:46:47,903] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:46:56,613] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3405507750811814
[2022-12-07 09:46:56,613] [INFO] [runner_train_mujoco] Average state value: 0.5193867112273971
[2022-12-07 09:46:56,613] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 09:46:56,669] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.04552
[2022-12-07 09:46:56,717] [INFO] [controller] EPOCH 2 loss ppo:  -0.02673, loss val: 0.04600
[2022-12-07 09:46:56,826] [INFO] [controller] EPOCH 3 loss ppo:  -0.04649, loss val: 0.04553
[2022-12-07 09:46:56,872] [INFO] [controller] EPOCH 4 loss ppo:  -0.05938, loss val: 0.04522
[2022-12-07 09:46:56,883] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:46:57,106] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:46:57,106] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:47:05,655] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:47:14,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:47:22,611] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:47:33,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:47:41,527] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:47:50,074] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:47:59,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:48:07,910] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:48:16,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:48:24,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6286153675777064
[2022-12-07 09:48:24,913] [INFO] [runner_train_mujoco] Average state value: 0.5209509777451554
[2022-12-07 09:48:24,914] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 09:48:24,973] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.04488
[2022-12-07 09:48:25,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.02719, loss val: 0.04537
[2022-12-07 09:48:25,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.04348, loss val: 0.04424
[2022-12-07 09:48:25,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.05722, loss val: 0.04311
[2022-12-07 09:48:25,120] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:48:25,333] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:48:25,333] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:48:33,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:48:41,271] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:48:48,555] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:48:56,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:49:03,629] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:49:11,675] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:49:19,280] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:49:26,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:49:34,524] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:49:41,621] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.138250976052824
[2022-12-07 09:49:41,621] [INFO] [runner_train_mujoco] Average state value: 0.5313936551014582
[2022-12-07 09:49:41,621] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 09:49:41,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.04314
[2022-12-07 09:49:41,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.02581, loss val: 0.04253
[2022-12-07 09:49:41,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.03745, loss val: 0.04160
[2022-12-07 09:49:41,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.04663, loss val: 0.03830
[2022-12-07 09:49:41,811] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:49:41,996] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:49:41,996] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:49:48,719] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:49:55,237] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:50:01,959] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:50:08,765] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:50:16,222] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:50:23,344] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:50:30,286] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:50:37,305] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:50:44,400] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:50:51,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6871129590241383
[2022-12-07 09:50:51,340] [INFO] [runner_train_mujoco] Average state value: 0.49567716547598445
[2022-12-07 09:50:51,340] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 09:50:51,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01540, loss val: 0.04520
[2022-12-07 09:50:51,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.02758, loss val: 0.04496
[2022-12-07 09:50:51,465] [INFO] [controller] EPOCH 3 loss ppo:  -0.04079, loss val: 0.04933
[2022-12-07 09:50:51,506] [INFO] [controller] EPOCH 4 loss ppo:  -0.04994, loss val: 0.04443
[2022-12-07 09:50:51,515] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:50:51,698] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:50:51,698] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:50:58,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:51:05,203] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:51:12,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:51:18,830] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:51:25,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:51:32,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:51:40,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:51:49,105] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:51:59,103] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:52:06,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.160929850489751
[2022-12-07 09:52:06,066] [INFO] [runner_train_mujoco] Average state value: 0.4773023765683174
[2022-12-07 09:52:06,066] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 09:52:06,112] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.05662
[2022-12-07 09:52:06,152] [INFO] [controller] EPOCH 2 loss ppo:  -0.02209, loss val: 0.05658
[2022-12-07 09:52:06,191] [INFO] [controller] EPOCH 3 loss ppo:  -0.03537, loss val: 0.05574
[2022-12-07 09:52:06,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.04773, loss val: 0.05564
[2022-12-07 09:52:06,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:52:06,437] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:52:06,438] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:52:12,934] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:52:20,417] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:52:27,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:52:34,520] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:52:41,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:52:48,293] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:52:55,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:53:03,121] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:53:10,372] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:53:17,608] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.759281410467601
[2022-12-07 09:53:17,608] [INFO] [runner_train_mujoco] Average state value: 0.504664243867
[2022-12-07 09:53:17,609] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 09:53:17,658] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.04002
[2022-12-07 09:53:17,698] [INFO] [controller] EPOCH 2 loss ppo:  -0.02184, loss val: 0.04068
[2022-12-07 09:53:17,737] [INFO] [controller] EPOCH 3 loss ppo:  -0.03520, loss val: 0.04049
[2022-12-07 09:53:17,777] [INFO] [controller] EPOCH 4 loss ppo:  -0.04629, loss val: 0.04057
[2022-12-07 09:53:17,784] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:53:17,961] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:53:17,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:53:25,461] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:53:32,750] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:53:39,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:53:46,578] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:53:54,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:54:01,010] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:54:09,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:54:16,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:54:24,353] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:54:32,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.16339984797255
[2022-12-07 09:54:32,702] [INFO] [runner_train_mujoco] Average state value: 0.4966305285990238
[2022-12-07 09:54:32,702] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 09:54:32,749] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.03777
[2022-12-07 09:54:32,790] [INFO] [controller] EPOCH 2 loss ppo:  -0.02207, loss val: 0.03561
[2022-12-07 09:54:32,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.03309, loss val: 0.03507
[2022-12-07 09:54:32,868] [INFO] [controller] EPOCH 4 loss ppo:  -0.04281, loss val: 0.03498
[2022-12-07 09:54:32,879] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:54:33,114] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:54:33,115] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:54:40,192] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:54:46,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:54:53,944] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:55:01,230] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:55:08,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:55:15,646] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:55:23,233] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:55:30,223] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:55:38,184] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:55:45,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.850804133879973
[2022-12-07 09:55:45,746] [INFO] [runner_train_mujoco] Average state value: 0.48559099700798597
[2022-12-07 09:55:45,746] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 09:55:45,793] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.05433
[2022-12-07 09:55:45,835] [INFO] [controller] EPOCH 2 loss ppo:  -0.01813, loss val: 0.05425
[2022-12-07 09:55:45,875] [INFO] [controller] EPOCH 3 loss ppo:  -0.02521, loss val: 0.05410
[2022-12-07 09:55:45,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.03394, loss val: 0.05372
[2022-12-07 09:55:45,931] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:55:46,128] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:55:46,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:55:53,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:55:59,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:56:06,670] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:56:14,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:56:22,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:56:30,543] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:56:38,558] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:56:46,043] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:56:52,704] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:56:59,908] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9598391013470113
[2022-12-07 09:56:59,909] [INFO] [runner_train_mujoco] Average state value: 0.49486077683170643
[2022-12-07 09:56:59,909] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 09:56:59,953] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.04447
[2022-12-07 09:56:59,991] [INFO] [controller] EPOCH 2 loss ppo:  -0.01882, loss val: 0.04336
[2022-12-07 09:57:00,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.02661, loss val: 0.04322
[2022-12-07 09:57:00,086] [INFO] [controller] EPOCH 4 loss ppo:  -0.03612, loss val: 0.04461
[2022-12-07 09:57:00,095] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:57:00,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:57:00,299] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:57:07,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:57:14,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:57:21,621] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:57:28,531] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:57:35,495] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:57:42,602] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:57:49,794] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:57:56,739] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:58:03,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:58:10,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.020309975923212
[2022-12-07 09:58:10,627] [INFO] [runner_train_mujoco] Average state value: 0.48491892098635436
[2022-12-07 09:58:10,627] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 09:58:10,672] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.04757
[2022-12-07 09:58:10,715] [INFO] [controller] EPOCH 2 loss ppo:  -0.01657, loss val: 0.04748
[2022-12-07 09:58:10,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.02055, loss val: 0.04764
[2022-12-07 09:58:10,800] [INFO] [controller] EPOCH 4 loss ppo:  -0.02605, loss val: 0.04734
[2022-12-07 09:58:10,809] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:58:11,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:58:11,011] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:58:18,071] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:58:25,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:58:31,760] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:58:38,252] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:58:44,802] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:58:51,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:58:58,314] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:59:05,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:59:12,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:59:19,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8482942108173623
[2022-12-07 09:59:19,460] [INFO] [runner_train_mujoco] Average state value: 0.4823853865340352
[2022-12-07 09:59:19,460] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 09:59:19,514] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.05149
[2022-12-07 09:59:19,560] [INFO] [controller] EPOCH 2 loss ppo:  -0.01562, loss val: 0.05144
[2022-12-07 09:59:19,606] [INFO] [controller] EPOCH 3 loss ppo:  -0.01804, loss val: 0.05111
[2022-12-07 09:59:19,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.02080, loss val: 0.05080
[2022-12-07 09:59:19,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:59:19,792] [INFO] [optimize] Finished learning.
