[2022-12-07 17:41:17,870] [INFO] [optimize] Starting learning
[2022-12-07 17:41:17,880] [INFO] [optimize] Starting learning process..
[2022-12-07 17:41:18,007] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:41:18,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:41:24,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:41:30,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:41:36,669] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:41:44,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:41:51,144] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:41:56,667] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:42:02,116] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:42:07,795] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:42:13,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:42:18,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4449033943235244
[2022-12-07 17:42:18,931] [INFO] [runner_train_mujoco] Average state value: 0.024492777432004613
[2022-12-07 17:42:18,931] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 17:42:19,008] [INFO] [controller] EPOCH 1 loss ppo:  -0.01145, loss val: 0.45714
[2022-12-07 17:42:19,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.05448, loss val: 0.38634
[2022-12-07 17:42:19,076] [INFO] [controller] EPOCH 3 loss ppo:  -0.07072, loss val: 0.34309
[2022-12-07 17:42:19,112] [INFO] [controller] EPOCH 4 loss ppo:  -0.08112, loss val: 0.29882
[2022-12-07 17:42:19,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:42:19,221] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:42:19,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:42:24,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:42:30,327] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:42:35,851] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:42:41,674] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:42:47,829] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:42:53,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:42:59,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:43:04,923] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:43:10,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:43:16,584] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44116002120451847
[2022-12-07 17:43:16,584] [INFO] [runner_train_mujoco] Average state value: 0.19721157081176835
[2022-12-07 17:43:16,584] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 17:43:16,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01173, loss val: 0.25571
[2022-12-07 17:43:16,658] [INFO] [controller] EPOCH 2 loss ppo:  -0.05010, loss val: 0.22046
[2022-12-07 17:43:16,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.06657, loss val: 0.19086
[2022-12-07 17:43:16,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.08015, loss val: 0.16650
[2022-12-07 17:43:16,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:43:16,873] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:43:16,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:43:24,830] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:43:33,644] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:43:43,071] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:43:49,238] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:43:55,584] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:44:02,105] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:44:08,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:44:14,790] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:44:21,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:44:27,478] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5533737276037891
[2022-12-07 17:44:27,478] [INFO] [runner_train_mujoco] Average state value: 0.3625028477888554
[2022-12-07 17:44:27,478] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 17:44:27,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.14187
[2022-12-07 17:44:27,571] [INFO] [controller] EPOCH 2 loss ppo:  -0.05143, loss val: 0.12894
[2022-12-07 17:44:27,608] [INFO] [controller] EPOCH 3 loss ppo:  -0.07232, loss val: 0.11718
[2022-12-07 17:44:27,651] [INFO] [controller] EPOCH 4 loss ppo:  -0.08387, loss val: 0.10638
[2022-12-07 17:44:27,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:44:27,821] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:44:27,821] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:44:34,204] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:44:40,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:44:47,046] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:44:53,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:44:59,496] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:45:05,792] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:45:11,465] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:45:17,916] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:45:23,921] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:45:30,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.542474187371877
[2022-12-07 17:45:30,013] [INFO] [runner_train_mujoco] Average state value: 0.49824692748735344
[2022-12-07 17:45:30,014] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 17:45:30,055] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.10121
[2022-12-07 17:45:30,087] [INFO] [controller] EPOCH 2 loss ppo:  -0.04752, loss val: 0.09695
[2022-12-07 17:45:30,124] [INFO] [controller] EPOCH 3 loss ppo:  -0.06671, loss val: 0.09355
[2022-12-07 17:45:30,156] [INFO] [controller] EPOCH 4 loss ppo:  -0.07457, loss val: 0.08429
[2022-12-07 17:45:30,162] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:45:30,307] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:45:30,308] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:45:36,865] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:45:42,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:45:48,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:45:55,412] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:46:01,463] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:46:07,369] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:46:15,053] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:46:20,716] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:46:27,380] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:46:33,947] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7711039988282078
[2022-12-07 17:46:33,948] [INFO] [runner_train_mujoco] Average state value: 0.5602159052391846
[2022-12-07 17:46:33,948] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 17:46:33,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.01114, loss val: 0.08477
[2022-12-07 17:46:34,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.04492, loss val: 0.08300
[2022-12-07 17:46:34,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.06431, loss val: 0.07804
[2022-12-07 17:46:34,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.07498, loss val: 0.06942
[2022-12-07 17:46:34,098] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:46:34,285] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:46:34,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:46:41,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:46:47,199] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:46:52,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:46:59,414] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:47:06,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:47:13,779] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:47:20,271] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:47:25,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:47:31,520] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:47:38,023] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7315987235060657
[2022-12-07 17:47:38,024] [INFO] [runner_train_mujoco] Average state value: 0.5135233327634634
[2022-12-07 17:47:38,024] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 17:47:38,060] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.06965
[2022-12-07 17:47:38,093] [INFO] [controller] EPOCH 2 loss ppo:  -0.05048, loss val: 0.06767
[2022-12-07 17:47:38,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.07056, loss val: 0.06652
[2022-12-07 17:47:38,150] [INFO] [controller] EPOCH 4 loss ppo:  -0.08100, loss val: 0.06675
[2022-12-07 17:47:38,158] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:47:38,276] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:47:38,276] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:47:43,867] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:47:50,388] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:47:57,267] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:48:05,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:48:11,477] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:48:17,523] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:48:23,136] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:48:28,814] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:48:35,880] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:48:43,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.691496453564923
[2022-12-07 17:48:43,527] [INFO] [runner_train_mujoco] Average state value: 0.5116288307818274
[2022-12-07 17:48:43,527] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 17:48:43,574] [INFO] [controller] EPOCH 1 loss ppo:  -0.01262, loss val: 0.06831
[2022-12-07 17:48:43,620] [INFO] [controller] EPOCH 2 loss ppo:  -0.04674, loss val: 0.06422
[2022-12-07 17:48:43,660] [INFO] [controller] EPOCH 3 loss ppo:  -0.06404, loss val: 0.06244
[2022-12-07 17:48:43,693] [INFO] [controller] EPOCH 4 loss ppo:  -0.07284, loss val: 0.06186
[2022-12-07 17:48:43,701] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:48:43,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:48:43,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:48:50,744] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:49:00,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:49:06,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:49:12,209] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:49:18,021] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:49:24,100] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:49:29,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:49:35,488] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:49:41,758] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:49:48,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7334180706483684
[2022-12-07 17:49:48,567] [INFO] [runner_train_mujoco] Average state value: 0.5479351901262999
[2022-12-07 17:49:48,568] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 17:49:48,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01125, loss val: 0.04903
[2022-12-07 17:49:48,674] [INFO] [controller] EPOCH 2 loss ppo:  -0.04170, loss val: 0.04818
[2022-12-07 17:49:48,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.05987, loss val: 0.04711
[2022-12-07 17:49:48,765] [INFO] [controller] EPOCH 4 loss ppo:  -0.07487, loss val: 0.04474
[2022-12-07 17:49:48,774] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:49:48,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:49:48,991] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:49:54,996] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:50:01,144] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:50:07,109] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:50:13,335] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:50:19,689] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:50:25,827] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:50:31,903] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:50:37,811] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:50:43,468] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:50:46,918] [WARNING] [core] Too many contacts. Either the arena memory is full, or nconmax is specified and is exceeded. Increase arena memory allocation, or increase/remove nconmax. (ncon = 150) Time = 18.0628.
[2022-12-07 17:50:49,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9469752304335076
[2022-12-07 17:50:49,045] [INFO] [runner_train_mujoco] Average state value: 0.5356239670614401
[2022-12-07 17:50:49,045] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 17:50:49,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04535
[2022-12-07 17:50:49,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.04957, loss val: 0.04721
[2022-12-07 17:50:49,147] [INFO] [controller] EPOCH 3 loss ppo:  -0.06524, loss val: 0.04502
[2022-12-07 17:50:49,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.07610, loss val: 0.04120
[2022-12-07 17:50:49,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:50:49,309] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:50:49,309] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:50:55,057] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:51:00,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:51:06,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:51:12,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:51:17,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:51:23,962] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:51:29,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:51:35,553] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:51:41,517] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:51:47,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.713460190206936
[2022-12-07 17:51:47,385] [INFO] [runner_train_mujoco] Average state value: 0.4760442133930822
[2022-12-07 17:51:47,385] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 17:51:47,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.04242
[2022-12-07 17:51:47,464] [INFO] [controller] EPOCH 2 loss ppo:  -0.04888, loss val: 0.04314
[2022-12-07 17:51:47,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.06587, loss val: 0.04131
[2022-12-07 17:51:47,546] [INFO] [controller] EPOCH 4 loss ppo:  -0.07554, loss val: 0.04220
[2022-12-07 17:51:47,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:51:47,737] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:51:47,737] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:51:55,396] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:52:01,555] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:52:07,870] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:52:15,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:52:21,663] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:52:27,212] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:52:32,640] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:52:38,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:52:43,647] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:52:50,785] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9727703027794258
[2022-12-07 17:52:50,786] [INFO] [runner_train_mujoco] Average state value: 0.45201997752487666
[2022-12-07 17:52:50,786] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 17:52:50,829] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.04593
[2022-12-07 17:52:50,862] [INFO] [controller] EPOCH 2 loss ppo:  -0.03960, loss val: 0.04394
[2022-12-07 17:52:50,895] [INFO] [controller] EPOCH 3 loss ppo:  -0.05825, loss val: 0.04497
[2022-12-07 17:52:50,928] [INFO] [controller] EPOCH 4 loss ppo:  -0.07311, loss val: 0.04370
[2022-12-07 17:52:50,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:52:51,085] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:52:51,086] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:52:56,868] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:53:04,483] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:53:10,746] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:53:17,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:53:24,396] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:53:31,052] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:53:38,186] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:53:44,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:53:51,263] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:53:57,873] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.978218729463005
[2022-12-07 17:53:57,873] [INFO] [runner_train_mujoco] Average state value: 0.4864909623811643
[2022-12-07 17:53:57,873] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 17:53:57,931] [INFO] [controller] EPOCH 1 loss ppo:  -0.01087, loss val: 0.04311
[2022-12-07 17:53:57,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.04429, loss val: 0.04375
[2022-12-07 17:53:58,021] [INFO] [controller] EPOCH 3 loss ppo:  -0.06714, loss val: 0.04670
[2022-12-07 17:53:58,069] [INFO] [controller] EPOCH 4 loss ppo:  -0.07930, loss val: 0.04323
[2022-12-07 17:53:58,078] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:53:58,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:53:58,263] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:54:05,275] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:54:12,085] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:54:18,385] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:54:24,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:54:30,854] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:54:37,077] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:54:42,919] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:54:48,849] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:54:54,751] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:55:00,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.182359812863866
[2022-12-07 17:55:00,642] [INFO] [runner_train_mujoco] Average state value: 0.5196541478137175
[2022-12-07 17:55:00,642] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 17:55:00,691] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.04329
[2022-12-07 17:55:00,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.04572, loss val: 0.04414
[2022-12-07 17:55:00,775] [INFO] [controller] EPOCH 3 loss ppo:  -0.06396, loss val: 0.04396
[2022-12-07 17:55:00,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.07980, loss val: 0.04323
[2022-12-07 17:55:00,821] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:55:01,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:55:01,016] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:55:07,539] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:55:14,092] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:55:20,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:55:26,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:55:32,613] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:55:38,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:55:44,775] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:55:50,939] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:55:57,142] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:56:03,159] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.178216617886979
[2022-12-07 17:56:03,159] [INFO] [runner_train_mujoco] Average state value: 0.5102335469524065
[2022-12-07 17:56:03,159] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 17:56:03,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.01156, loss val: 0.03818
[2022-12-07 17:56:03,238] [INFO] [controller] EPOCH 2 loss ppo:  -0.04136, loss val: 0.03837
[2022-12-07 17:56:03,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.06050, loss val: 0.03907
[2022-12-07 17:56:03,362] [INFO] [controller] EPOCH 4 loss ppo:  -0.07429, loss val: 0.03761
[2022-12-07 17:56:03,367] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:56:03,537] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:56:03,538] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:56:09,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:56:16,117] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:56:22,245] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:56:28,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:56:34,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:56:41,889] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:56:48,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:56:55,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:57:02,129] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:57:08,287] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.458706600747415
[2022-12-07 17:57:08,287] [INFO] [runner_train_mujoco] Average state value: 0.44392918958080313
[2022-12-07 17:57:08,287] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 17:57:08,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.08531
[2022-12-07 17:57:08,379] [INFO] [controller] EPOCH 2 loss ppo:  -0.04650, loss val: 0.08859
[2022-12-07 17:57:08,422] [INFO] [controller] EPOCH 3 loss ppo:  -0.06277, loss val: 0.08724
[2022-12-07 17:57:08,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.07680, loss val: 0.08137
[2022-12-07 17:57:08,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:57:08,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:57:08,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:57:15,185] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:57:21,591] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:57:28,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:57:34,552] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:57:40,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:57:47,066] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:57:53,469] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:57:59,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:58:05,986] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:58:12,766] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6318818508148734
[2022-12-07 17:58:12,766] [INFO] [runner_train_mujoco] Average state value: 0.5041721666604281
[2022-12-07 17:58:12,766] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 17:58:12,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.04370
[2022-12-07 17:58:12,851] [INFO] [controller] EPOCH 2 loss ppo:  -0.04116, loss val: 0.04350
[2022-12-07 17:58:12,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.06095, loss val: 0.04390
[2022-12-07 17:58:12,956] [INFO] [controller] EPOCH 4 loss ppo:  -0.07568, loss val: 0.04402
[2022-12-07 17:58:12,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:58:13,213] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:58:13,214] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:58:19,730] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:58:26,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:58:33,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:58:40,519] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:58:46,699] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:58:53,731] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:59:02,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:59:10,717] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:59:17,264] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:59:23,897] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8987330112281486
[2022-12-07 17:59:23,898] [INFO] [runner_train_mujoco] Average state value: 0.49884320906798046
[2022-12-07 17:59:23,898] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 17:59:23,947] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.04247
[2022-12-07 17:59:23,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.04543, loss val: 0.04131
[2022-12-07 17:59:24,036] [INFO] [controller] EPOCH 3 loss ppo:  -0.06167, loss val: 0.03878
[2022-12-07 17:59:24,077] [INFO] [controller] EPOCH 4 loss ppo:  -0.07291, loss val: 0.03716
[2022-12-07 17:59:24,084] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:59:24,270] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:59:24,271] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:59:30,916] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:59:37,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:59:43,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:59:50,200] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:59:57,456] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:00:04,416] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:00:10,637] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:00:16,711] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:00:22,794] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:00:28,881] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.86895601214926
[2022-12-07 18:00:28,882] [INFO] [runner_train_mujoco] Average state value: 0.4599318424661954
[2022-12-07 18:00:28,882] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 18:00:28,931] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04514
[2022-12-07 18:00:28,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.04455, loss val: 0.04621
[2022-12-07 18:00:29,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.06149, loss val: 0.04710
[2022-12-07 18:00:29,049] [INFO] [controller] EPOCH 4 loss ppo:  -0.07623, loss val: 0.04533
[2022-12-07 18:00:29,058] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:00:29,255] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:00:29,255] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:00:35,562] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:00:42,046] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:00:48,372] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:00:54,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:01:01,121] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:01:10,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:01:16,089] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:01:21,858] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:01:27,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:01:33,673] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.274810418732539
[2022-12-07 18:01:33,673] [INFO] [runner_train_mujoco] Average state value: 0.43810019853338594
[2022-12-07 18:01:33,673] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 18:01:33,715] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.03865
[2022-12-07 18:01:33,749] [INFO] [controller] EPOCH 2 loss ppo:  -0.04257, loss val: 0.03767
[2022-12-07 18:01:33,785] [INFO] [controller] EPOCH 3 loss ppo:  -0.05858, loss val: 0.03750
[2022-12-07 18:01:33,824] [INFO] [controller] EPOCH 4 loss ppo:  -0.07208, loss val: 0.03649
[2022-12-07 18:01:33,833] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:01:34,003] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:01:34,003] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:01:40,858] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:01:47,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:01:54,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:02:00,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:02:06,469] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:02:12,352] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:02:18,267] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:02:23,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:02:29,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:02:35,901] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4327388926667415
[2022-12-07 18:02:35,901] [INFO] [runner_train_mujoco] Average state value: 0.4686151227553685
[2022-12-07 18:02:35,901] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 18:02:35,944] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.03756
[2022-12-07 18:02:35,983] [INFO] [controller] EPOCH 2 loss ppo:  -0.04218, loss val: 0.03827
[2022-12-07 18:02:36,019] [INFO] [controller] EPOCH 3 loss ppo:  -0.05953, loss val: 0.03845
[2022-12-07 18:02:36,054] [INFO] [controller] EPOCH 4 loss ppo:  -0.07501, loss val: 0.03818
[2022-12-07 18:02:36,063] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:02:36,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:02:36,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:02:42,605] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:02:49,271] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:02:55,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:03:01,789] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:03:08,712] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:03:14,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:03:20,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:03:26,580] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:03:32,602] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:03:38,625] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3605305447349023
[2022-12-07 18:03:38,625] [INFO] [runner_train_mujoco] Average state value: 0.4681745993718505
[2022-12-07 18:03:38,625] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 18:03:38,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04694
[2022-12-07 18:03:38,711] [INFO] [controller] EPOCH 2 loss ppo:  -0.04165, loss val: 0.04454
[2022-12-07 18:03:38,747] [INFO] [controller] EPOCH 3 loss ppo:  -0.06025, loss val: 0.04507
[2022-12-07 18:03:38,783] [INFO] [controller] EPOCH 4 loss ppo:  -0.07379, loss val: 0.04209
[2022-12-07 18:03:38,791] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:03:38,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:03:38,960] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:03:45,473] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:03:52,197] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:03:58,356] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:04:04,656] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:04:10,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:04:16,774] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:04:22,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:04:29,303] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:04:35,819] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:04:42,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7046850080506406
[2022-12-07 18:04:42,284] [INFO] [runner_train_mujoco] Average state value: 0.49100729826092715
[2022-12-07 18:04:42,284] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 18:04:42,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01589, loss val: 0.03786
[2022-12-07 18:04:42,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.04263, loss val: 0.03884
[2022-12-07 18:04:42,488] [INFO] [controller] EPOCH 3 loss ppo:  -0.05835, loss val: 0.03836
[2022-12-07 18:04:42,555] [INFO] [controller] EPOCH 4 loss ppo:  -0.07611, loss val: 0.03777
[2022-12-07 18:04:42,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:04:42,776] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:04:42,777] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:04:49,399] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:04:55,922] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:05:02,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:05:08,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:05:14,298] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:05:20,111] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:05:25,967] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:05:31,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:05:38,324] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:05:44,298] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.73622589723571
[2022-12-07 18:05:44,299] [INFO] [runner_train_mujoco] Average state value: 0.4879713615278403
[2022-12-07 18:05:44,299] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 18:05:44,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.04857
[2022-12-07 18:05:44,385] [INFO] [controller] EPOCH 2 loss ppo:  -0.04030, loss val: 0.04762
[2022-12-07 18:05:44,426] [INFO] [controller] EPOCH 3 loss ppo:  -0.05436, loss val: 0.04852
[2022-12-07 18:05:44,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.06886, loss val: 0.04668
[2022-12-07 18:05:44,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:05:44,653] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:05:44,653] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:05:50,843] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:05:57,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:06:03,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:06:09,706] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:06:15,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:06:21,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:06:27,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:06:33,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:06:42,194] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:06:49,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.016269499480385
[2022-12-07 18:06:49,718] [INFO] [runner_train_mujoco] Average state value: 0.4991486609578132
[2022-12-07 18:06:49,719] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 18:06:49,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04557
[2022-12-07 18:06:49,831] [INFO] [controller] EPOCH 2 loss ppo:  -0.04114, loss val: 0.04552
[2022-12-07 18:06:49,887] [INFO] [controller] EPOCH 3 loss ppo:  -0.06158, loss val: 0.04618
[2022-12-07 18:06:49,947] [INFO] [controller] EPOCH 4 loss ppo:  -0.07803, loss val: 0.04586
[2022-12-07 18:06:49,956] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:06:50,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:06:50,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:06:57,227] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:07:04,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:07:12,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:07:20,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:07:26,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:07:33,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:07:40,278] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:07:47,100] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:07:54,261] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:08:01,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3988216474277566
[2022-12-07 18:08:01,115] [INFO] [runner_train_mujoco] Average state value: 0.5137880930900572
[2022-12-07 18:08:01,116] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 18:08:01,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03128
[2022-12-07 18:08:01,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.04067, loss val: 0.03161
[2022-12-07 18:08:01,242] [INFO] [controller] EPOCH 3 loss ppo:  -0.05640, loss val: 0.03285
[2022-12-07 18:08:01,277] [INFO] [controller] EPOCH 4 loss ppo:  -0.07204, loss val: 0.02954
[2022-12-07 18:08:01,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:08:01,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:08:01,515] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:08:08,410] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:08:15,116] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:08:22,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:08:29,101] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:08:36,003] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:08:42,902] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:08:49,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:08:56,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:09:03,723] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:09:10,839] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1843227038431716
[2022-12-07 18:09:10,839] [INFO] [runner_train_mujoco] Average state value: 0.47217555510997766
[2022-12-07 18:09:10,839] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 18:09:10,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.04435
[2022-12-07 18:09:10,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.03701, loss val: 0.04317
[2022-12-07 18:09:10,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.05034, loss val: 0.04357
[2022-12-07 18:09:11,013] [INFO] [controller] EPOCH 4 loss ppo:  -0.06885, loss val: 0.04287
[2022-12-07 18:09:11,019] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:09:11,213] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:09:11,213] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:09:18,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:09:25,391] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:09:32,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:09:39,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:09:46,355] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:09:52,875] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:09:59,624] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:10:06,472] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:10:13,490] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:10:20,102] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.692602949074561
[2022-12-07 18:10:20,102] [INFO] [runner_train_mujoco] Average state value: 0.4910165486435096
[2022-12-07 18:10:20,102] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 18:10:20,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.04618
[2022-12-07 18:10:20,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.03636, loss val: 0.04662
[2022-12-07 18:10:20,231] [INFO] [controller] EPOCH 3 loss ppo:  -0.05452, loss val: 0.04619
[2022-12-07 18:10:20,267] [INFO] [controller] EPOCH 4 loss ppo:  -0.07179, loss val: 0.04589
[2022-12-07 18:10:20,277] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:10:20,482] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:10:20,482] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:10:27,416] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:10:34,484] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:10:41,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:10:48,226] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:10:54,820] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:11:01,339] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:11:07,567] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:11:13,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:11:20,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:11:27,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.634885967817037
[2022-12-07 18:11:27,291] [INFO] [runner_train_mujoco] Average state value: 0.4634027039955059
[2022-12-07 18:11:27,291] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 18:11:27,336] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.03673
[2022-12-07 18:11:27,379] [INFO] [controller] EPOCH 2 loss ppo:  -0.03719, loss val: 0.03979
[2022-12-07 18:11:27,423] [INFO] [controller] EPOCH 3 loss ppo:  -0.06090, loss val: 0.03735
[2022-12-07 18:11:27,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.06958, loss val: 0.03731
[2022-12-07 18:11:27,469] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:11:27,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:11:27,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:11:34,415] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:11:41,352] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:11:48,440] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:11:55,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:12:01,579] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:12:07,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:12:14,575] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:12:21,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:12:27,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:12:34,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.153366338873589
[2022-12-07 18:12:34,524] [INFO] [runner_train_mujoco] Average state value: 0.46827047821879386
[2022-12-07 18:12:34,524] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 18:12:34,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.04390
[2022-12-07 18:12:34,609] [INFO] [controller] EPOCH 2 loss ppo:  -0.03934, loss val: 0.04340
[2022-12-07 18:12:34,655] [INFO] [controller] EPOCH 3 loss ppo:  -0.05876, loss val: 0.04310
[2022-12-07 18:12:34,701] [INFO] [controller] EPOCH 4 loss ppo:  -0.07434, loss val: 0.04488
[2022-12-07 18:12:34,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:12:34,926] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:12:34,926] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:12:42,005] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:12:48,514] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:12:55,538] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:13:02,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:13:09,008] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:13:15,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:13:22,127] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:13:28,777] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:13:35,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:13:42,781] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.418633717340802
[2022-12-07 18:13:42,781] [INFO] [runner_train_mujoco] Average state value: 0.46133619460463515
[2022-12-07 18:13:42,781] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 18:13:42,831] [INFO] [controller] EPOCH 1 loss ppo:  -0.01156, loss val: 0.04179
[2022-12-07 18:13:42,869] [INFO] [controller] EPOCH 2 loss ppo:  -0.03280, loss val: 0.04096
[2022-12-07 18:13:42,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.05039, loss val: 0.04032
[2022-12-07 18:13:42,959] [INFO] [controller] EPOCH 4 loss ppo:  -0.06694, loss val: 0.04086
[2022-12-07 18:13:42,969] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:13:43,175] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:13:43,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:13:50,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:13:57,351] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:14:04,667] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:14:11,590] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:14:18,369] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:14:24,978] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:14:31,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:14:39,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:14:45,857] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:14:52,885] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.531802469095513
[2022-12-07 18:14:52,886] [INFO] [runner_train_mujoco] Average state value: 0.4384113279283047
[2022-12-07 18:14:52,886] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 18:14:52,935] [INFO] [controller] EPOCH 1 loss ppo:  -0.01489, loss val: 0.04779
[2022-12-07 18:14:52,977] [INFO] [controller] EPOCH 2 loss ppo:  -0.03872, loss val: 0.04773
[2022-12-07 18:14:53,099] [INFO] [controller] EPOCH 3 loss ppo:  -0.05156, loss val: 0.04708
[2022-12-07 18:14:53,145] [INFO] [controller] EPOCH 4 loss ppo:  -0.06636, loss val: 0.04711
[2022-12-07 18:14:53,155] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:14:53,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:14:53,359] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:15:00,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:15:07,304] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:15:15,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:15:22,235] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:15:28,830] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:15:35,665] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:15:42,208] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:15:48,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:15:55,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:16:02,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.306640739793042
[2022-12-07 18:16:02,469] [INFO] [runner_train_mujoco] Average state value: 0.4349020262348155
[2022-12-07 18:16:02,469] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 18:16:02,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.06183
[2022-12-07 18:16:02,555] [INFO] [controller] EPOCH 2 loss ppo:  -0.03354, loss val: 0.06116
[2022-12-07 18:16:02,592] [INFO] [controller] EPOCH 3 loss ppo:  -0.04661, loss val: 0.05763
[2022-12-07 18:16:02,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.05693, loss val: 0.05306
[2022-12-07 18:16:02,638] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:16:02,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:16:02,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:16:10,511] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:16:17,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:16:24,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:16:30,770] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:16:37,145] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:16:44,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:16:50,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:16:57,012] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:17:03,538] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:17:10,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.593443421580095
[2022-12-07 18:17:10,468] [INFO] [runner_train_mujoco] Average state value: 0.48671802586317076
[2022-12-07 18:17:10,468] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 18:17:10,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.05265
[2022-12-07 18:17:10,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.03486, loss val: 0.05063
[2022-12-07 18:17:10,599] [INFO] [controller] EPOCH 3 loss ppo:  -0.05161, loss val: 0.05006
[2022-12-07 18:17:10,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.06779, loss val: 0.04928
[2022-12-07 18:17:10,648] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:17:10,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:17:10,851] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:17:17,710] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:17:24,338] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:17:31,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:17:37,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:17:44,369] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:17:50,868] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:17:57,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:18:04,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:18:10,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:18:17,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.934180920278114
[2022-12-07 18:18:17,931] [INFO] [runner_train_mujoco] Average state value: 0.5799592998226484
[2022-12-07 18:18:17,931] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 18:18:18,000] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.05524
[2022-12-07 18:18:18,051] [INFO] [controller] EPOCH 2 loss ppo:  -0.03041, loss val: 0.05836
[2022-12-07 18:18:18,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.04390, loss val: 0.05485
[2022-12-07 18:18:18,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.05898, loss val: 0.05270
[2022-12-07 18:18:18,146] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:18:18,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:18:18,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:18:25,489] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:18:32,271] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:18:39,441] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:18:46,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:18:52,881] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:18:59,390] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:19:06,102] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:19:12,891] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:19:19,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:19:26,614] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.630570224793129
[2022-12-07 18:19:26,614] [INFO] [runner_train_mujoco] Average state value: 0.5536802781249086
[2022-12-07 18:19:26,614] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 18:19:26,665] [INFO] [controller] EPOCH 1 loss ppo:  -0.01567, loss val: 0.05490
[2022-12-07 18:19:26,709] [INFO] [controller] EPOCH 2 loss ppo:  -0.03364, loss val: 0.05068
[2022-12-07 18:19:26,751] [INFO] [controller] EPOCH 3 loss ppo:  -0.04619, loss val: 0.04852
[2022-12-07 18:19:26,795] [INFO] [controller] EPOCH 4 loss ppo:  -0.06169, loss val: 0.04375
[2022-12-07 18:19:26,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:19:27,156] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:19:27,156] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:19:35,343] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:19:42,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:19:49,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:19:56,362] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:20:03,256] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:20:09,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:20:16,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:20:22,808] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:20:30,236] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:20:37,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.15977789355018
[2022-12-07 18:20:37,445] [INFO] [runner_train_mujoco] Average state value: 0.4581563560652236
[2022-12-07 18:20:37,445] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 18:20:37,494] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.05572
[2022-12-07 18:20:37,551] [INFO] [controller] EPOCH 2 loss ppo:  -0.02819, loss val: 0.05755
[2022-12-07 18:20:37,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.04084, loss val: 0.06242
[2022-12-07 18:20:37,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.05718, loss val: 0.06113
[2022-12-07 18:20:37,672] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:20:37,895] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:20:37,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:20:47,069] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:20:54,439] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:21:01,293] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:21:08,435] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:21:15,916] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:21:22,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:21:29,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:21:36,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:21:43,264] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:21:49,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.179720425048533
[2022-12-07 18:21:49,832] [INFO] [runner_train_mujoco] Average state value: 0.46742518791556364
[2022-12-07 18:21:49,832] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 18:21:49,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04600
[2022-12-07 18:21:49,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.03084, loss val: 0.04607
[2022-12-07 18:21:49,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.04209, loss val: 0.04598
[2022-12-07 18:21:50,000] [INFO] [controller] EPOCH 4 loss ppo:  -0.05997, loss val: 0.04598
[2022-12-07 18:21:50,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:21:50,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:21:50,189] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:21:57,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:22:04,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:22:11,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:22:18,586] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:22:25,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:22:32,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:22:39,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:22:46,414] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:22:53,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:23:00,219] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.606575446153206
[2022-12-07 18:23:00,219] [INFO] [runner_train_mujoco] Average state value: 0.46117057822148
[2022-12-07 18:23:00,219] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 18:23:00,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.04117
[2022-12-07 18:23:00,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.03197, loss val: 0.04125
[2022-12-07 18:23:00,386] [INFO] [controller] EPOCH 3 loss ppo:  -0.04640, loss val: 0.04318
[2022-12-07 18:23:00,442] [INFO] [controller] EPOCH 4 loss ppo:  -0.06104, loss val: 0.04121
[2022-12-07 18:23:00,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:23:00,675] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:23:00,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:23:08,265] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:23:15,670] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:23:23,338] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:23:30,579] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:23:38,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:23:45,448] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:23:52,365] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:23:59,253] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:24:06,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:24:13,565] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.77095345855475
[2022-12-07 18:24:13,565] [INFO] [runner_train_mujoco] Average state value: 0.4495112447775901
[2022-12-07 18:24:13,565] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 18:24:13,622] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.04801
[2022-12-07 18:24:13,669] [INFO] [controller] EPOCH 2 loss ppo:  -0.02997, loss val: 0.04815
[2022-12-07 18:24:13,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.03784, loss val: 0.04597
[2022-12-07 18:24:13,757] [INFO] [controller] EPOCH 4 loss ppo:  -0.05363, loss val: 0.04442
[2022-12-07 18:24:13,769] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:24:13,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:24:13,978] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:24:21,653] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:24:28,902] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:24:35,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:24:43,274] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:24:50,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:24:57,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:25:04,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:25:12,325] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:25:20,231] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:25:28,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.92782222173341
[2022-12-07 18:25:28,072] [INFO] [runner_train_mujoco] Average state value: 0.48389338508248336
[2022-12-07 18:25:28,072] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 18:25:28,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01496, loss val: 0.04722
[2022-12-07 18:25:28,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.02956, loss val: 0.04660
[2022-12-07 18:25:28,248] [INFO] [controller] EPOCH 3 loss ppo:  -0.03918, loss val: 0.04596
[2022-12-07 18:25:28,300] [INFO] [controller] EPOCH 4 loss ppo:  -0.05352, loss val: 0.04696
[2022-12-07 18:25:28,307] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:25:28,573] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:25:28,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:25:36,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:25:43,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:25:51,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:25:59,840] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:26:06,761] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:26:13,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:26:20,186] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:26:26,666] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:26:33,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:26:39,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.088488027178905
[2022-12-07 18:26:39,833] [INFO] [runner_train_mujoco] Average state value: 0.44662949764480186
[2022-12-07 18:26:39,833] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 18:26:39,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.07092
[2022-12-07 18:26:39,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.02330, loss val: 0.07063
[2022-12-07 18:26:39,968] [INFO] [controller] EPOCH 3 loss ppo:  -0.03871, loss val: 0.06811
[2022-12-07 18:26:40,010] [INFO] [controller] EPOCH 4 loss ppo:  -0.05531, loss val: 0.06850
[2022-12-07 18:26:40,021] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:26:40,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:26:40,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:26:48,564] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:26:56,991] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:27:03,821] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:27:11,050] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:27:17,970] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:27:24,861] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:27:31,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:27:38,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:27:45,216] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:27:51,758] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.725978366115676
[2022-12-07 18:27:51,759] [INFO] [runner_train_mujoco] Average state value: 0.4669677613178889
[2022-12-07 18:27:51,759] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 18:27:51,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01599, loss val: 0.05093
[2022-12-07 18:27:51,851] [INFO] [controller] EPOCH 2 loss ppo:  -0.02822, loss val: 0.05047
[2022-12-07 18:27:51,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.04015, loss val: 0.05014
[2022-12-07 18:27:51,945] [INFO] [controller] EPOCH 4 loss ppo:  -0.05856, loss val: 0.05027
[2022-12-07 18:27:51,956] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:27:52,177] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:27:52,178] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:27:59,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:28:06,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:28:12,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:28:19,211] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:28:25,975] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:28:33,912] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:28:41,143] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:28:47,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:28:54,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:29:01,484] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.804393388693195
[2022-12-07 18:29:01,484] [INFO] [runner_train_mujoco] Average state value: 0.4371003272732099
[2022-12-07 18:29:01,484] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 18:29:01,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04518
[2022-12-07 18:29:01,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.02775, loss val: 0.04485
[2022-12-07 18:29:01,615] [INFO] [controller] EPOCH 3 loss ppo:  -0.03811, loss val: 0.04397
[2022-12-07 18:29:01,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.05008, loss val: 0.04269
[2022-12-07 18:29:01,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:29:01,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:29:01,842] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:29:08,853] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:29:15,547] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:29:22,367] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:29:30,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:29:38,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:29:45,441] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:29:52,291] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:29:59,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:30:05,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:30:12,926] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.361661739227862
[2022-12-07 18:30:12,927] [INFO] [runner_train_mujoco] Average state value: 0.40508498355497913
[2022-12-07 18:30:12,927] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 18:30:12,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04961
[2022-12-07 18:30:13,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.02792, loss val: 0.04857
[2022-12-07 18:30:13,059] [INFO] [controller] EPOCH 3 loss ppo:  -0.03918, loss val: 0.04848
[2022-12-07 18:30:13,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.05060, loss val: 0.04993
[2022-12-07 18:30:13,109] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:30:13,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:30:13,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:30:20,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:30:27,394] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:30:34,225] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:30:41,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:30:48,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:30:55,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:31:02,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:31:09,539] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:31:16,716] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:31:23,498] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.727007669223057
[2022-12-07 18:31:23,498] [INFO] [runner_train_mujoco] Average state value: 0.38413713145256045
[2022-12-07 18:31:23,498] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 18:31:23,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.08456
[2022-12-07 18:31:23,592] [INFO] [controller] EPOCH 2 loss ppo:  -0.02473, loss val: 0.08218
[2022-12-07 18:31:23,634] [INFO] [controller] EPOCH 3 loss ppo:  -0.03495, loss val: 0.07978
[2022-12-07 18:31:23,676] [INFO] [controller] EPOCH 4 loss ppo:  -0.04520, loss val: 0.07806
[2022-12-07 18:31:23,686] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:31:23,925] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:31:23,926] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:31:34,949] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:31:42,304] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:31:49,299] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:31:56,222] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:32:03,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:32:11,354] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:32:18,529] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:32:26,258] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:32:33,990] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:32:40,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.665433335740767
[2022-12-07 18:32:40,986] [INFO] [runner_train_mujoco] Average state value: 0.44736638775467863
[2022-12-07 18:32:40,987] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 18:32:41,038] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.05023
[2022-12-07 18:32:41,075] [INFO] [controller] EPOCH 2 loss ppo:  -0.03122, loss val: 0.05118
[2022-12-07 18:32:41,120] [INFO] [controller] EPOCH 3 loss ppo:  -0.04119, loss val: 0.05104
[2022-12-07 18:32:41,165] [INFO] [controller] EPOCH 4 loss ppo:  -0.05166, loss val: 0.05166
[2022-12-07 18:32:41,174] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:32:41,356] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:32:41,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:32:49,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:32:56,176] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:33:03,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:33:09,732] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:33:16,970] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:33:23,818] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:33:30,564] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:33:36,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:33:43,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:33:49,876] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.909914494498461
[2022-12-07 18:33:49,876] [INFO] [runner_train_mujoco] Average state value: 0.44540356625989086
[2022-12-07 18:33:49,876] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 18:33:49,925] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.05206
[2022-12-07 18:33:49,960] [INFO] [controller] EPOCH 2 loss ppo:  -0.02369, loss val: 0.05015
[2022-12-07 18:33:50,000] [INFO] [controller] EPOCH 3 loss ppo:  -0.03812, loss val: 0.05164
[2022-12-07 18:33:50,037] [INFO] [controller] EPOCH 4 loss ppo:  -0.04818, loss val: 0.05132
[2022-12-07 18:33:50,046] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:33:50,238] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:33:50,238] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:33:57,050] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:34:03,683] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:34:10,050] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:34:16,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:34:23,378] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:34:30,848] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:34:41,127] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:34:50,541] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:34:57,483] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:35:07,669] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.131101250919262
[2022-12-07 18:35:07,670] [INFO] [runner_train_mujoco] Average state value: 0.4767370329896609
[2022-12-07 18:35:07,670] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 18:35:07,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.03357
[2022-12-07 18:35:07,836] [INFO] [controller] EPOCH 2 loss ppo:  -0.02564, loss val: 0.03347
[2022-12-07 18:35:07,998] [INFO] [controller] EPOCH 3 loss ppo:  -0.03781, loss val: 0.03343
[2022-12-07 18:35:08,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.04593, loss val: 0.03333
[2022-12-07 18:35:08,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:35:08,307] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:35:08,308] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:35:15,631] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:35:22,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:35:29,206] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:35:36,351] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:35:43,153] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:35:50,175] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:35:56,792] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:36:03,699] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:36:10,369] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:36:17,233] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.78513498622881
[2022-12-07 18:36:17,233] [INFO] [runner_train_mujoco] Average state value: 0.47065284527093165
[2022-12-07 18:36:17,233] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 18:36:17,280] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.04677
[2022-12-07 18:36:17,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.02248, loss val: 0.04351
[2022-12-07 18:36:17,362] [INFO] [controller] EPOCH 3 loss ppo:  -0.03235, loss val: 0.04607
[2022-12-07 18:36:17,414] [INFO] [controller] EPOCH 4 loss ppo:  -0.03862, loss val: 0.04291
[2022-12-07 18:36:17,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:36:17,625] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:36:17,625] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:36:24,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:36:31,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:36:38,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:36:45,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:36:52,424] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:36:59,258] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:37:06,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:37:13,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:37:20,601] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:37:27,458] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.448231949472958
[2022-12-07 18:37:27,458] [INFO] [runner_train_mujoco] Average state value: 0.5001847365697225
[2022-12-07 18:37:27,458] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 18:37:27,502] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.06892
[2022-12-07 18:37:27,539] [INFO] [controller] EPOCH 2 loss ppo:  -0.02054, loss val: 0.06992
[2022-12-07 18:37:27,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.03137, loss val: 0.07021
[2022-12-07 18:37:27,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.03826, loss val: 0.07234
[2022-12-07 18:37:27,629] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:37:27,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:37:27,834] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:37:35,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:37:42,629] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:37:49,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:37:56,705] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:38:03,582] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:38:11,058] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:38:18,387] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:38:25,758] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:38:33,014] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:38:42,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.572227872892432
[2022-12-07 18:38:42,760] [INFO] [runner_train_mujoco] Average state value: 0.5036790655454
[2022-12-07 18:38:42,760] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 18:38:42,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.01473, loss val: 0.05519
[2022-12-07 18:38:42,882] [INFO] [controller] EPOCH 2 loss ppo:  -0.02581, loss val: 0.05267
[2022-12-07 18:38:42,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.03704, loss val: 0.05191
[2022-12-07 18:38:42,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.04255, loss val: 0.05101
[2022-12-07 18:38:43,004] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:38:43,206] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:38:43,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:38:51,064] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:38:58,609] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:39:07,260] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:39:14,775] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:39:21,963] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:39:29,861] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:39:37,147] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:39:44,526] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:39:52,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:39:59,604] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.536401044250572
[2022-12-07 18:39:59,604] [INFO] [runner_train_mujoco] Average state value: 0.4865065962672233
[2022-12-07 18:39:59,604] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 18:39:59,657] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.03726
[2022-12-07 18:39:59,698] [INFO] [controller] EPOCH 2 loss ppo:  -0.01952, loss val: 0.03715
[2022-12-07 18:39:59,738] [INFO] [controller] EPOCH 3 loss ppo:  -0.03075, loss val: 0.03686
[2022-12-07 18:39:59,781] [INFO] [controller] EPOCH 4 loss ppo:  -0.03721, loss val: 0.03674
[2022-12-07 18:39:59,792] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:40:00,163] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:40:00,164] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:40:08,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:40:16,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:40:24,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:40:32,011] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:40:39,252] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:40:52,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:41:01,008] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:41:08,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:41:15,778] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:41:23,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.1893967104888485
[2022-12-07 18:41:23,515] [INFO] [runner_train_mujoco] Average state value: 0.4391755622302493
[2022-12-07 18:41:23,515] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 18:41:23,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04904
[2022-12-07 18:41:23,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.02189, loss val: 0.05566
[2022-12-07 18:41:23,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.03233, loss val: 0.04947
[2022-12-07 18:41:23,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.03865, loss val: 0.05042
[2022-12-07 18:41:23,717] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:41:23,934] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:41:23,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:41:31,348] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:41:39,409] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:41:46,893] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:41:55,884] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:42:04,322] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:42:11,935] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:42:20,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:42:32,750] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:42:39,714] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:42:47,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.412368311016638
[2022-12-07 18:42:47,325] [INFO] [runner_train_mujoco] Average state value: 0.46798084986209865
[2022-12-07 18:42:47,325] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 18:42:47,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04069
[2022-12-07 18:42:47,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.01922, loss val: 0.04071
[2022-12-07 18:42:47,452] [INFO] [controller] EPOCH 3 loss ppo:  -0.02760, loss val: 0.04020
[2022-12-07 18:42:47,497] [INFO] [controller] EPOCH 4 loss ppo:  -0.03228, loss val: 0.04089
[2022-12-07 18:42:47,507] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:42:47,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:42:47,722] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:42:55,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:43:02,755] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:43:09,953] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:43:17,190] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:43:26,651] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:43:35,088] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:43:42,782] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:43:51,913] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:44:01,213] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:44:09,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.446405938596122
[2022-12-07 18:44:09,364] [INFO] [runner_train_mujoco] Average state value: 0.46423188567161555
[2022-12-07 18:44:09,364] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 18:44:09,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.04013
[2022-12-07 18:44:09,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.01624, loss val: 0.04025
[2022-12-07 18:44:09,499] [INFO] [controller] EPOCH 3 loss ppo:  -0.02270, loss val: 0.04147
[2022-12-07 18:44:09,550] [INFO] [controller] EPOCH 4 loss ppo:  -0.02973, loss val: 0.04032
[2022-12-07 18:44:09,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:44:09,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:44:09,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:44:19,299] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:44:29,651] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:44:40,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:44:50,110] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:45:02,320] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:45:12,760] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:45:22,720] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:45:32,546] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:45:42,319] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:45:53,456] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.388384598750987
[2022-12-07 18:45:53,457] [INFO] [runner_train_mujoco] Average state value: 0.4456768997622033
[2022-12-07 18:45:53,457] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 18:45:53,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04328
[2022-12-07 18:45:53,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.01694, loss val: 0.04290
[2022-12-07 18:45:53,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.02296, loss val: 0.04304
[2022-12-07 18:45:53,699] [INFO] [controller] EPOCH 4 loss ppo:  -0.03034, loss val: 0.04278
[2022-12-07 18:45:53,711] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:45:53,955] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:45:53,956] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:46:02,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:46:12,717] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:46:20,210] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:46:28,199] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:46:37,478] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:46:44,493] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:46:51,789] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:46:59,648] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:47:06,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:47:15,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.455346324753981
[2022-12-07 18:47:15,328] [INFO] [runner_train_mujoco] Average state value: 0.4617367836833
[2022-12-07 18:47:15,329] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 18:47:15,392] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04230
[2022-12-07 18:47:15,439] [INFO] [controller] EPOCH 2 loss ppo:  -0.01437, loss val: 0.04334
[2022-12-07 18:47:15,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.01783, loss val: 0.04235
[2022-12-07 18:47:15,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.02334, loss val: 0.04287
[2022-12-07 18:47:15,545] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:47:15,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:47:15,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:47:23,416] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:47:30,975] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:47:39,117] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:47:46,960] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:47:53,560] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:48:00,783] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:48:07,466] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:48:16,960] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:48:23,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:48:30,831] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.748827536388441
[2022-12-07 18:48:30,831] [INFO] [runner_train_mujoco] Average state value: 0.45605046172936764
[2022-12-07 18:48:30,831] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 18:48:30,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.06656
[2022-12-07 18:48:30,919] [INFO] [controller] EPOCH 2 loss ppo:  -0.01420, loss val: 0.06975
[2022-12-07 18:48:30,963] [INFO] [controller] EPOCH 3 loss ppo:  -0.01571, loss val: 0.06947
[2022-12-07 18:48:31,010] [INFO] [controller] EPOCH 4 loss ppo:  -0.01779, loss val: 0.07043
[2022-12-07 18:48:31,020] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:48:31,137] [INFO] [optimize] Finished learning.
