[2022-12-07 17:52:57,349] [INFO] [optimize] Starting learning
[2022-12-07 17:52:57,359] [INFO] [optimize] Starting learning process..
[2022-12-07 17:52:57,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:52:57,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:53:05,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:53:11,383] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:53:17,457] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:53:25,034] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:53:31,865] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:53:38,848] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:53:45,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:53:51,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:53:58,686] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:54:05,755] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6515994447951566
[2022-12-07 17:54:05,756] [INFO] [runner_train_mujoco] Average state value: -0.1386824115477502
[2022-12-07 17:54:05,756] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 17:54:05,807] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.68012
[2022-12-07 17:54:05,854] [INFO] [controller] EPOCH 2 loss ppo:  -0.05298, loss val: 0.63102
[2022-12-07 17:54:05,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.06710, loss val: 0.57150
[2022-12-07 17:54:05,946] [INFO] [controller] EPOCH 4 loss ppo:  -0.07940, loss val: 0.53215
[2022-12-07 17:54:05,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:54:06,140] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:54:06,140] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:54:12,756] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:54:19,314] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:54:25,665] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:54:32,018] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:54:38,055] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:54:43,914] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:54:49,721] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:54:55,636] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:55:01,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:55:08,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5137200160857258
[2022-12-07 17:55:08,224] [INFO] [runner_train_mujoco] Average state value: 0.043963839230438076
[2022-12-07 17:55:08,224] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 17:55:08,267] [INFO] [controller] EPOCH 1 loss ppo:  -0.01539, loss val: 0.45375
[2022-12-07 17:55:08,300] [INFO] [controller] EPOCH 2 loss ppo:  -0.05266, loss val: 0.41415
[2022-12-07 17:55:08,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.07344, loss val: 0.36463
[2022-12-07 17:55:08,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.08154, loss val: 0.32542
[2022-12-07 17:55:08,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:55:08,553] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:55:08,553] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:55:15,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:55:21,184] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:55:27,320] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:55:33,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:55:40,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:55:46,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:55:52,421] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:55:58,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:56:04,984] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:56:11,008] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.501432476294209
[2022-12-07 17:56:11,008] [INFO] [runner_train_mujoco] Average state value: 0.20775919986950858
[2022-12-07 17:56:11,009] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 17:56:11,054] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.20336
[2022-12-07 17:56:11,090] [INFO] [controller] EPOCH 2 loss ppo:  -0.05154, loss val: 0.18500
[2022-12-07 17:56:11,130] [INFO] [controller] EPOCH 3 loss ppo:  -0.06888, loss val: 0.16514
[2022-12-07 17:56:11,169] [INFO] [controller] EPOCH 4 loss ppo:  -0.07944, loss val: 0.15142
[2022-12-07 17:56:11,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:56:11,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:56:11,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:56:17,534] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:56:23,598] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:56:30,040] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:56:36,339] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:56:43,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:56:50,145] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:56:57,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:57:03,589] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:57:10,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:57:16,441] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6655450475265574
[2022-12-07 17:57:16,441] [INFO] [runner_train_mujoco] Average state value: 0.34868008712617055
[2022-12-07 17:57:16,441] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 17:57:16,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.16772
[2022-12-07 17:57:16,513] [INFO] [controller] EPOCH 2 loss ppo:  -0.04123, loss val: 0.15187
[2022-12-07 17:57:16,543] [INFO] [controller] EPOCH 3 loss ppo:  -0.05845, loss val: 0.13248
[2022-12-07 17:57:16,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.07137, loss val: 0.12285
[2022-12-07 17:57:16,584] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:57:16,798] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:57:16,798] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:57:23,328] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:57:29,831] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:57:36,259] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:57:42,630] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:57:48,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:57:55,364] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:58:01,652] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:58:08,282] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:58:15,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:58:21,289] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5688968178444297
[2022-12-07 17:58:21,290] [INFO] [runner_train_mujoco] Average state value: 0.4481145369261504
[2022-12-07 17:58:21,290] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 17:58:21,335] [INFO] [controller] EPOCH 1 loss ppo:  -0.01204, loss val: 0.10913
[2022-12-07 17:58:21,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.04948, loss val: 0.10112
[2022-12-07 17:58:21,411] [INFO] [controller] EPOCH 3 loss ppo:  -0.06846, loss val: 0.09435
[2022-12-07 17:58:21,447] [INFO] [controller] EPOCH 4 loss ppo:  -0.07846, loss val: 0.08871
[2022-12-07 17:58:21,453] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:58:21,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:58:21,600] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:58:28,932] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:58:35,819] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:58:42,563] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 17:58:48,987] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 17:58:56,995] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 17:59:05,613] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 17:59:13,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 17:59:19,836] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 17:59:27,064] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 17:59:33,293] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.723234076565384
[2022-12-07 17:59:33,293] [INFO] [runner_train_mujoco] Average state value: 0.5334682261832059
[2022-12-07 17:59:33,293] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 17:59:33,342] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.08198
[2022-12-07 17:59:33,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.04415, loss val: 0.07686
[2022-12-07 17:59:33,426] [INFO] [controller] EPOCH 3 loss ppo:  -0.06501, loss val: 0.07522
[2022-12-07 17:59:33,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.07777, loss val: 0.07019
[2022-12-07 17:59:33,473] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 17:59:33,673] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 17:59:33,673] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 17:59:40,221] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 17:59:46,594] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 17:59:53,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:00:01,050] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:00:07,623] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:00:13,757] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:00:19,802] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:00:25,730] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:00:32,166] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:00:38,569] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7087564536419307
[2022-12-07 18:00:38,570] [INFO] [runner_train_mujoco] Average state value: 0.5846037548780441
[2022-12-07 18:00:38,570] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 18:00:38,612] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.06805
[2022-12-07 18:00:38,646] [INFO] [controller] EPOCH 2 loss ppo:  -0.05290, loss val: 0.06813
[2022-12-07 18:00:38,685] [INFO] [controller] EPOCH 3 loss ppo:  -0.06780, loss val: 0.06129
[2022-12-07 18:00:38,731] [INFO] [controller] EPOCH 4 loss ppo:  -0.07779, loss val: 0.05853
[2022-12-07 18:00:38,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:00:38,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:00:38,938] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:00:45,409] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:00:51,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:00:58,056] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:01:04,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:01:11,642] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:01:17,539] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:01:23,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:01:29,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:01:35,726] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:01:42,589] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7203220345144151
[2022-12-07 18:01:42,590] [INFO] [runner_train_mujoco] Average state value: 0.5325652727385363
[2022-12-07 18:01:42,590] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 18:01:42,642] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.06196
[2022-12-07 18:01:42,688] [INFO] [controller] EPOCH 2 loss ppo:  -0.03978, loss val: 0.05725
[2022-12-07 18:01:42,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.05990, loss val: 0.05231
[2022-12-07 18:01:42,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.07383, loss val: 0.04610
[2022-12-07 18:01:42,780] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:01:42,981] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:01:42,981] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:01:49,721] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:01:56,670] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:02:02,694] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:02:08,623] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:02:14,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:02:20,275] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:02:26,110] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:02:32,082] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:02:38,699] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:02:44,672] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7387426635332547
[2022-12-07 18:02:44,672] [INFO] [runner_train_mujoco] Average state value: 0.4629022487538556
[2022-12-07 18:02:44,672] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 18:02:44,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.01133, loss val: 0.06483
[2022-12-07 18:02:44,758] [INFO] [controller] EPOCH 2 loss ppo:  -0.04313, loss val: 0.06403
[2022-12-07 18:02:44,799] [INFO] [controller] EPOCH 3 loss ppo:  -0.06305, loss val: 0.06355
[2022-12-07 18:02:44,837] [INFO] [controller] EPOCH 4 loss ppo:  -0.07855, loss val: 0.06037
[2022-12-07 18:02:44,846] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:02:45,053] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:02:45,053] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:02:52,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:02:59,148] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:03:05,537] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:03:12,355] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:03:18,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:03:24,349] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:03:30,518] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:03:36,655] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:03:43,198] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:03:49,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7141808195091649
[2022-12-07 18:03:49,405] [INFO] [runner_train_mujoco] Average state value: 0.4374778241589666
[2022-12-07 18:03:49,405] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 18:03:49,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01160, loss val: 0.05083
[2022-12-07 18:03:49,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.04473, loss val: 0.05001
[2022-12-07 18:03:49,527] [INFO] [controller] EPOCH 3 loss ppo:  -0.06181, loss val: 0.05332
[2022-12-07 18:03:49,564] [INFO] [controller] EPOCH 4 loss ppo:  -0.07357, loss val: 0.04432
[2022-12-07 18:03:49,571] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:03:49,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:03:49,744] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:03:56,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:04:02,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:04:08,982] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:04:14,988] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:04:21,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:04:27,770] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:04:33,975] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:04:40,754] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:04:47,694] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:04:53,758] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6179329593266805
[2022-12-07 18:04:53,758] [INFO] [runner_train_mujoco] Average state value: 0.4938030475974083
[2022-12-07 18:04:53,759] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 18:04:53,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.04477
[2022-12-07 18:04:53,838] [INFO] [controller] EPOCH 2 loss ppo:  -0.04793, loss val: 0.04331
[2022-12-07 18:04:53,874] [INFO] [controller] EPOCH 3 loss ppo:  -0.06507, loss val: 0.04315
[2022-12-07 18:04:53,906] [INFO] [controller] EPOCH 4 loss ppo:  -0.07482, loss val: 0.04292
[2022-12-07 18:04:53,912] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:04:54,093] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:04:54,093] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:05:00,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:05:07,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:05:12,959] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:05:18,891] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:05:24,715] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:05:30,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:05:36,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:05:43,180] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:05:49,576] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:05:55,621] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8673183271198303
[2022-12-07 18:05:55,622] [INFO] [runner_train_mujoco] Average state value: 0.5101623067855835
[2022-12-07 18:05:55,622] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 18:05:55,667] [INFO] [controller] EPOCH 1 loss ppo:  -0.01007, loss val: 0.04349
[2022-12-07 18:05:55,708] [INFO] [controller] EPOCH 2 loss ppo:  -0.04467, loss val: 0.04291
[2022-12-07 18:05:55,744] [INFO] [controller] EPOCH 3 loss ppo:  -0.05735, loss val: 0.04186
[2022-12-07 18:05:55,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.07083, loss val: 0.04218
[2022-12-07 18:05:55,788] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:05:55,979] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:05:55,979] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:06:02,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:06:08,748] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:06:14,672] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:06:20,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:06:26,373] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:06:32,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:06:41,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:06:49,027] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:06:56,469] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:07:03,995] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.701954487076488
[2022-12-07 18:07:03,995] [INFO] [runner_train_mujoco] Average state value: 0.5125786566051342
[2022-12-07 18:07:03,995] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 18:07:04,064] [INFO] [controller] EPOCH 1 loss ppo:  -0.01138, loss val: 0.03937
[2022-12-07 18:07:04,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.04239, loss val: 0.03914
[2022-12-07 18:07:04,182] [INFO] [controller] EPOCH 3 loss ppo:  -0.06023, loss val: 0.04125
[2022-12-07 18:07:04,240] [INFO] [controller] EPOCH 4 loss ppo:  -0.07298, loss val: 0.03997
[2022-12-07 18:07:04,252] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:07:04,506] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:07:04,507] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:07:12,523] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:07:19,719] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:07:26,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:07:33,120] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:07:40,137] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:07:46,822] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:07:54,179] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:08:01,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:08:08,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:08:15,141] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7101052230589188
[2022-12-07 18:08:15,141] [INFO] [runner_train_mujoco] Average state value: 0.5093364622493585
[2022-12-07 18:08:15,141] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 18:08:15,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01346, loss val: 0.04498
[2022-12-07 18:08:15,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.03721, loss val: 0.04522
[2022-12-07 18:08:15,342] [INFO] [controller] EPOCH 3 loss ppo:  -0.05484, loss val: 0.04415
[2022-12-07 18:08:15,385] [INFO] [controller] EPOCH 4 loss ppo:  -0.06696, loss val: 0.04433
[2022-12-07 18:08:15,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:08:15,578] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:08:15,578] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:08:22,648] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:08:29,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:08:36,112] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:08:43,138] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:08:49,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:08:56,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:09:04,346] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:09:11,599] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:09:18,610] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:09:25,487] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8056813552972244
[2022-12-07 18:09:25,487] [INFO] [runner_train_mujoco] Average state value: 0.518120324452718
[2022-12-07 18:09:25,487] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 18:09:25,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04121
[2022-12-07 18:09:25,577] [INFO] [controller] EPOCH 2 loss ppo:  -0.03828, loss val: 0.04002
[2022-12-07 18:09:25,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.05955, loss val: 0.04023
[2022-12-07 18:09:25,657] [INFO] [controller] EPOCH 4 loss ppo:  -0.07206, loss val: 0.03884
[2022-12-07 18:09:25,667] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:09:25,888] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:09:25,889] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:09:33,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:09:40,074] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:09:46,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:09:53,623] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:10:00,278] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:10:07,038] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:10:14,032] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:10:21,012] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:10:27,970] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:10:34,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7896059905489462
[2022-12-07 18:10:34,832] [INFO] [runner_train_mujoco] Average state value: 0.5443113776445389
[2022-12-07 18:10:34,832] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 18:10:34,882] [INFO] [controller] EPOCH 1 loss ppo:  -0.01010, loss val: 0.04358
[2022-12-07 18:10:34,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.04072, loss val: 0.04351
[2022-12-07 18:10:34,966] [INFO] [controller] EPOCH 3 loss ppo:  -0.05896, loss val: 0.04436
[2022-12-07 18:10:35,007] [INFO] [controller] EPOCH 4 loss ppo:  -0.07381, loss val: 0.04264
[2022-12-07 18:10:35,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:10:35,201] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:10:35,201] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:10:42,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:10:49,001] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:10:55,542] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:11:02,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:11:08,687] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:11:15,232] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:11:22,055] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:11:29,071] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:11:35,783] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:11:42,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9250604975819368
[2022-12-07 18:11:42,812] [INFO] [runner_train_mujoco] Average state value: 0.5536490077972412
[2022-12-07 18:11:42,812] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 18:11:42,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04822
[2022-12-07 18:11:42,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.03781, loss val: 0.04583
[2022-12-07 18:11:42,949] [INFO] [controller] EPOCH 3 loss ppo:  -0.05337, loss val: 0.04310
[2022-12-07 18:11:42,981] [INFO] [controller] EPOCH 4 loss ppo:  -0.06952, loss val: 0.03875
[2022-12-07 18:11:42,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:11:43,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:11:43,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:11:50,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:11:56,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:12:03,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:12:09,793] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:12:16,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:12:22,883] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:12:29,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:12:37,072] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:12:43,838] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:12:50,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.759156168311793
[2022-12-07 18:12:50,446] [INFO] [runner_train_mujoco] Average state value: 0.4925212279160818
[2022-12-07 18:12:50,446] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 18:12:50,489] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04762
[2022-12-07 18:12:50,531] [INFO] [controller] EPOCH 2 loss ppo:  -0.03834, loss val: 0.04832
[2022-12-07 18:12:50,573] [INFO] [controller] EPOCH 3 loss ppo:  -0.05358, loss val: 0.04850
[2022-12-07 18:12:50,608] [INFO] [controller] EPOCH 4 loss ppo:  -0.06919, loss val: 0.04974
[2022-12-07 18:12:50,618] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:12:50,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:12:50,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:12:57,804] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:13:04,471] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:13:11,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:13:18,348] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:13:24,993] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:13:31,567] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:13:38,456] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:13:46,149] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:13:52,933] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:13:59,757] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.006549078090137
[2022-12-07 18:13:59,758] [INFO] [runner_train_mujoco] Average state value: 0.47042969413598373
[2022-12-07 18:13:59,758] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 18:13:59,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03429
[2022-12-07 18:13:59,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.04124, loss val: 0.03406
[2022-12-07 18:13:59,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.06051, loss val: 0.03577
[2022-12-07 18:13:59,930] [INFO] [controller] EPOCH 4 loss ppo:  -0.07537, loss val: 0.03490
[2022-12-07 18:13:59,939] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:14:00,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:14:00,148] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:14:07,340] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:14:14,344] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:14:21,056] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:14:27,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:14:35,101] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:14:42,435] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:14:49,253] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:14:56,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:15:04,050] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:15:10,875] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8969089405508885
[2022-12-07 18:15:10,875] [INFO] [runner_train_mujoco] Average state value: 0.48863179646929095
[2022-12-07 18:15:10,875] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 18:15:10,920] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.04029
[2022-12-07 18:15:10,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.04145, loss val: 0.03977
[2022-12-07 18:15:10,989] [INFO] [controller] EPOCH 3 loss ppo:  -0.05891, loss val: 0.03866
[2022-12-07 18:15:11,027] [INFO] [controller] EPOCH 4 loss ppo:  -0.07424, loss val: 0.04052
[2022-12-07 18:15:11,037] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:15:11,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:15:11,218] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:15:18,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:15:24,824] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:15:31,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:15:38,210] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:15:44,928] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:15:51,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:15:58,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:16:05,512] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:16:13,114] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:16:19,715] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.294149663746914
[2022-12-07 18:16:19,715] [INFO] [runner_train_mujoco] Average state value: 0.5174095190068086
[2022-12-07 18:16:19,716] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 18:16:19,768] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04434
[2022-12-07 18:16:19,811] [INFO] [controller] EPOCH 2 loss ppo:  -0.03792, loss val: 0.04478
[2022-12-07 18:16:19,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.05323, loss val: 0.04170
[2022-12-07 18:16:19,892] [INFO] [controller] EPOCH 4 loss ppo:  -0.06870, loss val: 0.03937
[2022-12-07 18:16:19,902] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:16:20,118] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:16:20,118] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:16:26,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:16:33,735] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:16:40,584] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:16:47,074] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:16:53,703] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:17:00,459] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:17:06,971] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:17:14,622] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:17:21,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:17:27,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5658550825206032
[2022-12-07 18:17:27,836] [INFO] [runner_train_mujoco] Average state value: 0.49825222682952874
[2022-12-07 18:17:27,836] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 18:17:27,885] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.03114
[2022-12-07 18:17:27,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.04308, loss val: 0.03118
[2022-12-07 18:17:27,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.06241, loss val: 0.03158
[2022-12-07 18:17:28,007] [INFO] [controller] EPOCH 4 loss ppo:  -0.07766, loss val: 0.03256
[2022-12-07 18:17:28,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:17:28,208] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:17:28,208] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:17:35,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:17:41,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:17:48,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:17:55,018] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:18:01,751] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:18:08,537] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:18:15,353] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:18:23,369] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:18:30,467] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:18:37,280] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7582030455716744
[2022-12-07 18:18:37,281] [INFO] [runner_train_mujoco] Average state value: 0.4807545038064321
[2022-12-07 18:18:37,281] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 18:18:37,338] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.04302
[2022-12-07 18:18:37,380] [INFO] [controller] EPOCH 2 loss ppo:  -0.04539, loss val: 0.04310
[2022-12-07 18:18:37,421] [INFO] [controller] EPOCH 3 loss ppo:  -0.06053, loss val: 0.04001
[2022-12-07 18:18:37,465] [INFO] [controller] EPOCH 4 loss ppo:  -0.07036, loss val: 0.03900
[2022-12-07 18:18:37,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:18:37,667] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:18:37,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:18:45,043] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:18:51,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:18:58,722] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:19:05,585] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:19:12,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:19:19,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:19:26,407] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:19:34,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:19:42,079] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:19:48,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1046888713926015
[2022-12-07 18:19:48,812] [INFO] [runner_train_mujoco] Average state value: 0.5293581574559212
[2022-12-07 18:19:48,813] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 18:19:48,861] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.05225
[2022-12-07 18:19:48,899] [INFO] [controller] EPOCH 2 loss ppo:  -0.04228, loss val: 0.05357
[2022-12-07 18:19:48,936] [INFO] [controller] EPOCH 3 loss ppo:  -0.06274, loss val: 0.05344
[2022-12-07 18:19:48,974] [INFO] [controller] EPOCH 4 loss ppo:  -0.07913, loss val: 0.05220
[2022-12-07 18:19:48,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:19:49,146] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:19:49,147] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:19:56,387] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:20:03,277] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:20:10,004] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:20:16,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:20:23,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:20:30,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:20:38,372] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:20:47,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:20:54,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:21:01,595] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.382718198383159
[2022-12-07 18:21:01,595] [INFO] [runner_train_mujoco] Average state value: 0.5311376439879337
[2022-12-07 18:21:01,595] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 18:21:01,673] [INFO] [controller] EPOCH 1 loss ppo:  -0.01721, loss val: 0.03669
[2022-12-07 18:21:01,714] [INFO] [controller] EPOCH 2 loss ppo:  -0.04451, loss val: 0.03770
[2022-12-07 18:21:01,760] [INFO] [controller] EPOCH 3 loss ppo:  -0.06310, loss val: 0.04005
[2022-12-07 18:21:01,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.07704, loss val: 0.03824
[2022-12-07 18:21:01,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:21:02,026] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:21:02,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:21:09,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:21:16,343] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:21:23,364] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:21:30,528] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:21:37,441] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:21:44,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:21:51,268] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:21:58,285] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:22:05,418] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:22:12,607] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.469819592567482
[2022-12-07 18:22:12,607] [INFO] [runner_train_mujoco] Average state value: 0.5131058474630118
[2022-12-07 18:22:12,607] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 18:22:12,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.01701, loss val: 0.04685
[2022-12-07 18:22:12,702] [INFO] [controller] EPOCH 2 loss ppo:  -0.04481, loss val: 0.04599
[2022-12-07 18:22:12,749] [INFO] [controller] EPOCH 3 loss ppo:  -0.05955, loss val: 0.04452
[2022-12-07 18:22:12,794] [INFO] [controller] EPOCH 4 loss ppo:  -0.07589, loss val: 0.04320
[2022-12-07 18:22:12,803] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:22:13,009] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:22:13,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:22:20,149] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:22:27,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:22:34,269] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:22:41,467] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:22:48,451] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:22:55,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:23:02,749] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:23:10,384] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:23:17,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:23:25,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9017893168375775
[2022-12-07 18:23:25,334] [INFO] [runner_train_mujoco] Average state value: 0.4793470559765895
[2022-12-07 18:23:25,334] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 18:23:25,403] [INFO] [controller] EPOCH 1 loss ppo:  -0.01510, loss val: 0.03615
[2022-12-07 18:23:25,455] [INFO] [controller] EPOCH 2 loss ppo:  -0.04146, loss val: 0.02981
[2022-12-07 18:23:25,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.05872, loss val: 0.02999
[2022-12-07 18:23:25,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.07514, loss val: 0.02996
[2022-12-07 18:23:25,562] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:23:25,773] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:23:25,773] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:23:32,747] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:23:40,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:23:47,937] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:23:54,837] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:24:01,889] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:24:09,081] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:24:16,957] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:24:24,638] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:24:31,746] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:24:39,130] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0028374467486003
[2022-12-07 18:24:39,131] [INFO] [runner_train_mujoco] Average state value: 0.4461071822295587
[2022-12-07 18:24:39,131] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 18:24:39,180] [INFO] [controller] EPOCH 1 loss ppo:  -0.01599, loss val: 0.03972
[2022-12-07 18:24:39,220] [INFO] [controller] EPOCH 2 loss ppo:  -0.04071, loss val: 0.03904
[2022-12-07 18:24:39,262] [INFO] [controller] EPOCH 3 loss ppo:  -0.05611, loss val: 0.03918
[2022-12-07 18:24:39,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.07298, loss val: 0.03895
[2022-12-07 18:24:39,317] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:24:39,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:24:39,526] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:24:46,880] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:24:54,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:25:01,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:25:08,666] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:25:17,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:25:24,624] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:25:32,825] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:25:40,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:25:48,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:25:56,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6969790804078815
[2022-12-07 18:25:56,214] [INFO] [runner_train_mujoco] Average state value: 0.4390806235248844
[2022-12-07 18:25:56,214] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 18:25:56,294] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.03742
[2022-12-07 18:25:56,358] [INFO] [controller] EPOCH 2 loss ppo:  -0.03652, loss val: 0.03718
[2022-12-07 18:25:56,422] [INFO] [controller] EPOCH 3 loss ppo:  -0.05369, loss val: 0.03706
[2022-12-07 18:25:56,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.07309, loss val: 0.03675
[2022-12-07 18:25:56,496] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:25:56,742] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:25:56,743] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:26:04,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:26:11,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:26:18,087] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:26:24,849] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:26:31,564] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:26:38,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:26:45,762] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:26:54,971] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:27:02,208] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:27:09,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0577068529495746
[2022-12-07 18:27:09,550] [INFO] [runner_train_mujoco] Average state value: 0.45256456103920933
[2022-12-07 18:27:09,550] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 18:27:09,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.03999
[2022-12-07 18:27:09,655] [INFO] [controller] EPOCH 2 loss ppo:  -0.03631, loss val: 0.04288
[2022-12-07 18:27:09,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.05204, loss val: 0.04135
[2022-12-07 18:27:09,755] [INFO] [controller] EPOCH 4 loss ppo:  -0.07018, loss val: 0.04057
[2022-12-07 18:27:09,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:27:09,989] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:27:09,989] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:27:16,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:27:24,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:27:30,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:27:37,658] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:27:44,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:27:52,000] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:27:59,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:28:06,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:28:13,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:28:20,020] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.426963298289384
[2022-12-07 18:28:20,020] [INFO] [runner_train_mujoco] Average state value: 0.4507051504949729
[2022-12-07 18:28:20,021] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 18:28:20,066] [INFO] [controller] EPOCH 1 loss ppo:  -0.01615, loss val: 0.04488
[2022-12-07 18:28:20,108] [INFO] [controller] EPOCH 2 loss ppo:  -0.03288, loss val: 0.04586
[2022-12-07 18:28:20,215] [INFO] [controller] EPOCH 3 loss ppo:  -0.04733, loss val: 0.04927
[2022-12-07 18:28:20,263] [INFO] [controller] EPOCH 4 loss ppo:  -0.06359, loss val: 0.04706
[2022-12-07 18:28:20,270] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:28:20,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:28:20,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:28:27,144] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:28:34,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:28:41,263] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:28:49,124] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:28:55,813] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:29:03,416] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:29:10,585] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:29:17,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:29:24,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:29:32,417] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3888699015289157
[2022-12-07 18:29:32,417] [INFO] [runner_train_mujoco] Average state value: 0.4357375231484572
[2022-12-07 18:29:32,417] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 18:29:32,472] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.04961
[2022-12-07 18:29:32,513] [INFO] [controller] EPOCH 2 loss ppo:  -0.03653, loss val: 0.04923
[2022-12-07 18:29:32,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.05555, loss val: 0.04899
[2022-12-07 18:29:32,595] [INFO] [controller] EPOCH 4 loss ppo:  -0.07261, loss val: 0.04890
[2022-12-07 18:29:32,603] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:29:32,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:29:32,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:29:40,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:29:47,603] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:29:54,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:30:01,722] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:30:08,716] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:30:15,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:30:23,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:30:30,106] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:30:37,014] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:30:44,295] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.907247765320025
[2022-12-07 18:30:44,295] [INFO] [runner_train_mujoco] Average state value: 0.45388829865058256
[2022-12-07 18:30:44,295] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 18:30:44,400] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.04753
[2022-12-07 18:30:44,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.03694, loss val: 0.04737
[2022-12-07 18:30:44,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.05354, loss val: 0.04579
[2022-12-07 18:30:44,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.06789, loss val: 0.04438
[2022-12-07 18:30:44,559] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:30:44,768] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:30:44,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:30:54,044] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:31:01,089] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:31:08,105] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:31:15,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:31:22,449] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:31:30,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:31:38,118] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:31:45,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:31:52,836] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:31:59,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.87243879987788
[2022-12-07 18:31:59,774] [INFO] [runner_train_mujoco] Average state value: 0.4334823999678095
[2022-12-07 18:31:59,774] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 18:31:59,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.01522, loss val: 0.07098
[2022-12-07 18:31:59,869] [INFO] [controller] EPOCH 2 loss ppo:  -0.03275, loss val: 0.07130
[2022-12-07 18:31:59,906] [INFO] [controller] EPOCH 3 loss ppo:  -0.05038, loss val: 0.07092
[2022-12-07 18:31:59,948] [INFO] [controller] EPOCH 4 loss ppo:  -0.06671, loss val: 0.07025
[2022-12-07 18:31:59,956] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:32:00,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:32:00,182] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:32:13,997] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:32:21,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:32:29,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:32:36,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:32:44,216] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:32:51,916] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:32:59,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:33:06,103] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:33:13,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:33:20,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7370513335015323
[2022-12-07 18:33:20,464] [INFO] [runner_train_mujoco] Average state value: 0.4955636988605062
[2022-12-07 18:33:20,464] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 18:33:20,511] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.03950
[2022-12-07 18:33:20,548] [INFO] [controller] EPOCH 2 loss ppo:  -0.03708, loss val: 0.04250
[2022-12-07 18:33:20,590] [INFO] [controller] EPOCH 3 loss ppo:  -0.05346, loss val: 0.03824
[2022-12-07 18:33:20,633] [INFO] [controller] EPOCH 4 loss ppo:  -0.06832, loss val: 0.04140
[2022-12-07 18:33:20,643] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:33:20,847] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:33:20,848] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:33:27,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:33:34,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:33:40,898] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:33:48,859] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:33:55,964] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:34:02,781] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:34:09,323] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:34:15,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:34:22,454] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:34:29,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8028402361978615
[2022-12-07 18:34:29,508] [INFO] [runner_train_mujoco] Average state value: 0.47365096703171733
[2022-12-07 18:34:29,508] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 18:34:29,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.04267
[2022-12-07 18:34:29,636] [INFO] [controller] EPOCH 2 loss ppo:  -0.03373, loss val: 0.04349
[2022-12-07 18:34:29,699] [INFO] [controller] EPOCH 3 loss ppo:  -0.05080, loss val: 0.04347
[2022-12-07 18:34:29,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.06620, loss val: 0.04308
[2022-12-07 18:34:29,759] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:34:29,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:34:29,978] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:34:39,275] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:34:49,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:34:56,254] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:35:05,411] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:35:14,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:35:21,028] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:35:27,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:35:34,918] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:35:41,536] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:35:48,438] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.370333871340618
[2022-12-07 18:35:48,438] [INFO] [runner_train_mujoco] Average state value: 0.46101291387279825
[2022-12-07 18:35:48,439] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 18:35:48,499] [INFO] [controller] EPOCH 1 loss ppo:  -0.01620, loss val: 0.04164
[2022-12-07 18:35:48,542] [INFO] [controller] EPOCH 2 loss ppo:  -0.04003, loss val: 0.04391
[2022-12-07 18:35:48,583] [INFO] [controller] EPOCH 3 loss ppo:  -0.05577, loss val: 0.04144
[2022-12-07 18:35:48,620] [INFO] [controller] EPOCH 4 loss ppo:  -0.07129, loss val: 0.04601
[2022-12-07 18:35:48,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:35:48,829] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:35:48,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:35:55,524] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:36:02,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:36:11,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:36:18,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:36:25,719] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:36:32,652] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:36:39,841] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:36:46,796] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:36:53,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:37:00,335] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.160360020358833
[2022-12-07 18:37:00,335] [INFO] [runner_train_mujoco] Average state value: 0.46907742935419083
[2022-12-07 18:37:00,335] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 18:37:00,386] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.05046
[2022-12-07 18:37:00,429] [INFO] [controller] EPOCH 2 loss ppo:  -0.03616, loss val: 0.04851
[2022-12-07 18:37:00,474] [INFO] [controller] EPOCH 3 loss ppo:  -0.04925, loss val: 0.04878
[2022-12-07 18:37:00,519] [INFO] [controller] EPOCH 4 loss ppo:  -0.06434, loss val: 0.04967
[2022-12-07 18:37:00,528] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:37:00,747] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:37:00,748] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:37:07,795] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:37:14,987] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:37:22,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:37:29,362] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:37:36,637] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:37:47,163] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:37:54,322] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:38:01,519] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:38:09,044] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:38:16,302] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.036857317489911
[2022-12-07 18:38:16,302] [INFO] [runner_train_mujoco] Average state value: 0.45787924630443255
[2022-12-07 18:38:16,302] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 18:38:16,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04937
[2022-12-07 18:38:16,423] [INFO] [controller] EPOCH 2 loss ppo:  -0.03181, loss val: 0.04961
[2022-12-07 18:38:16,467] [INFO] [controller] EPOCH 3 loss ppo:  -0.04979, loss val: 0.04789
[2022-12-07 18:38:16,510] [INFO] [controller] EPOCH 4 loss ppo:  -0.06793, loss val: 0.04860
[2022-12-07 18:38:16,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:38:16,729] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:38:16,730] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:38:24,154] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:38:31,581] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:38:40,321] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:38:48,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:38:55,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:39:04,680] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:39:12,461] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:39:19,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:39:27,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:39:34,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.505533126711839
[2022-12-07 18:39:34,747] [INFO] [runner_train_mujoco] Average state value: 0.4571343584756057
[2022-12-07 18:39:34,747] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 18:39:34,801] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.04038
[2022-12-07 18:39:34,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.03564, loss val: 0.03888
[2022-12-07 18:39:34,897] [INFO] [controller] EPOCH 3 loss ppo:  -0.05032, loss val: 0.03879
[2022-12-07 18:39:34,945] [INFO] [controller] EPOCH 4 loss ppo:  -0.06605, loss val: 0.03852
[2022-12-07 18:39:34,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:39:35,163] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:39:35,164] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:39:42,669] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:39:50,335] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:39:57,806] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:40:06,502] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:40:14,906] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:40:22,637] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:40:30,286] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:40:37,855] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:40:45,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:40:54,262] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.728739397768784
[2022-12-07 18:40:54,262] [INFO] [runner_train_mujoco] Average state value: 0.46142123248179756
[2022-12-07 18:40:54,263] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 18:40:54,321] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.04436
[2022-12-07 18:40:54,374] [INFO] [controller] EPOCH 2 loss ppo:  -0.03065, loss val: 0.04788
[2022-12-07 18:40:54,425] [INFO] [controller] EPOCH 3 loss ppo:  -0.04239, loss val: 0.04390
[2022-12-07 18:40:54,481] [INFO] [controller] EPOCH 4 loss ppo:  -0.05777, loss val: 0.04605
[2022-12-07 18:40:54,495] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:40:54,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:40:54,732] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:41:02,758] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:41:10,240] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:41:17,987] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:41:25,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:41:33,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:41:41,238] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:41:49,303] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:41:58,245] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:42:06,315] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:42:14,499] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.473311146037611
[2022-12-07 18:42:14,500] [INFO] [runner_train_mujoco] Average state value: 0.45203886766235035
[2022-12-07 18:42:14,500] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 18:42:14,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01497, loss val: 0.04602
[2022-12-07 18:42:14,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.02925, loss val: 0.04076
[2022-12-07 18:42:14,688] [INFO] [controller] EPOCH 3 loss ppo:  -0.04206, loss val: 0.04245
[2022-12-07 18:42:14,757] [INFO] [controller] EPOCH 4 loss ppo:  -0.05608, loss val: 0.03874
[2022-12-07 18:42:14,770] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:42:14,994] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:42:14,994] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:42:23,783] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:42:32,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:42:39,544] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:42:47,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:42:55,189] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:43:02,645] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:43:10,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:43:17,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:43:27,088] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:43:37,762] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.982015902196447
[2022-12-07 18:43:37,762] [INFO] [runner_train_mujoco] Average state value: 0.47354347487290704
[2022-12-07 18:43:37,762] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 18:43:37,813] [INFO] [controller] EPOCH 1 loss ppo:  -0.01489, loss val: 0.04995
[2022-12-07 18:43:37,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.02821, loss val: 0.05073
[2022-12-07 18:43:37,907] [INFO] [controller] EPOCH 3 loss ppo:  -0.03953, loss val: 0.05076
[2022-12-07 18:43:37,956] [INFO] [controller] EPOCH 4 loss ppo:  -0.05482, loss val: 0.05138
[2022-12-07 18:43:37,966] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:43:38,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:43:38,160] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:43:45,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:43:55,726] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:44:05,058] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:44:13,939] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:44:24,230] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:44:34,521] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:44:45,753] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:44:55,477] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:45:05,407] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:45:15,826] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.736539078789282
[2022-12-07 18:45:15,826] [INFO] [runner_train_mujoco] Average state value: 0.4783297421733538
[2022-12-07 18:45:15,826] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 18:45:15,898] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04867
[2022-12-07 18:45:15,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.02532, loss val: 0.04887
[2022-12-07 18:45:16,009] [INFO] [controller] EPOCH 3 loss ppo:  -0.03899, loss val: 0.04740
[2022-12-07 18:45:16,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.05116, loss val: 0.04691
[2022-12-07 18:45:16,110] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:45:16,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:45:16,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:45:26,438] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:45:36,387] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:45:47,896] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:45:57,651] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:46:06,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:46:16,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:46:24,162] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:46:32,171] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:46:40,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:46:47,761] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.59258952571881
[2022-12-07 18:46:47,761] [INFO] [runner_train_mujoco] Average state value: 0.4483092464506626
[2022-12-07 18:46:47,761] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 18:46:47,801] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.03318
[2022-12-07 18:46:47,841] [INFO] [controller] EPOCH 2 loss ppo:  -0.02899, loss val: 0.03313
[2022-12-07 18:46:47,882] [INFO] [controller] EPOCH 3 loss ppo:  -0.04519, loss val: 0.03304
[2022-12-07 18:46:47,925] [INFO] [controller] EPOCH 4 loss ppo:  -0.05435, loss val: 0.03264
[2022-12-07 18:46:47,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:46:48,102] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:46:48,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:46:56,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:47:03,798] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:47:12,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:47:20,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:47:27,528] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:47:40,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:47:47,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:47:54,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:48:03,601] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:48:10,479] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.900032508147992
[2022-12-07 18:48:10,479] [INFO] [runner_train_mujoco] Average state value: 0.4349315267999968
[2022-12-07 18:48:10,479] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 18:48:10,537] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.05423
[2022-12-07 18:48:10,582] [INFO] [controller] EPOCH 2 loss ppo:  -0.02377, loss val: 0.05403
[2022-12-07 18:48:10,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.03463, loss val: 0.05467
[2022-12-07 18:48:10,675] [INFO] [controller] EPOCH 4 loss ppo:  -0.04666, loss val: 0.04973
[2022-12-07 18:48:10,686] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:48:10,916] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:48:10,917] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:48:18,095] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:48:25,529] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:48:32,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:48:41,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:48:47,955] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:48:54,887] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:49:01,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:49:06,958] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:49:12,783] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:49:18,708] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.148791414587162
[2022-12-07 18:49:18,708] [INFO] [runner_train_mujoco] Average state value: 0.4481414962212244
[2022-12-07 18:49:18,708] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 18:49:18,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.04152
[2022-12-07 18:49:18,778] [INFO] [controller] EPOCH 2 loss ppo:  -0.02616, loss val: 0.04216
[2022-12-07 18:49:18,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.03547, loss val: 0.04315
[2022-12-07 18:49:18,858] [INFO] [controller] EPOCH 4 loss ppo:  -0.04869, loss val: 0.04206
[2022-12-07 18:49:18,867] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:49:19,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:49:19,010] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:49:25,246] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:49:31,610] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:49:37,341] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:49:43,478] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:49:49,417] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:49:55,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:50:01,850] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:50:07,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:50:14,432] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:50:20,907] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.26891506470511
[2022-12-07 18:50:20,907] [INFO] [runner_train_mujoco] Average state value: 0.4516308259566625
[2022-12-07 18:50:20,907] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 18:50:20,955] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04190
[2022-12-07 18:50:21,004] [INFO] [controller] EPOCH 2 loss ppo:  -0.02544, loss val: 0.04200
[2022-12-07 18:50:21,099] [INFO] [controller] EPOCH 3 loss ppo:  -0.03613, loss val: 0.04187
[2022-12-07 18:50:21,135] [INFO] [controller] EPOCH 4 loss ppo:  -0.04483, loss val: 0.04031
[2022-12-07 18:50:21,141] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:50:21,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:50:21,306] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:50:27,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:50:33,813] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:50:40,163] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:50:46,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:50:52,940] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:50:59,105] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:51:05,220] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:51:11,759] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:51:18,094] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:51:24,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.629698779316123
[2022-12-07 18:51:24,894] [INFO] [runner_train_mujoco] Average state value: 0.45460637107491497
[2022-12-07 18:51:24,895] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 18:51:24,932] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.06790
[2022-12-07 18:51:24,966] [INFO] [controller] EPOCH 2 loss ppo:  -0.01881, loss val: 0.06627
[2022-12-07 18:51:24,993] [INFO] [controller] EPOCH 3 loss ppo:  -0.02862, loss val: 0.06281
[2022-12-07 18:51:25,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.03826, loss val: 0.06088
[2022-12-07 18:51:25,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:51:25,152] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:51:25,153] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:51:31,348] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:51:37,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:51:42,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:51:48,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:51:54,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:52:01,444] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:52:07,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:52:14,392] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:52:20,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:52:26,106] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.173627035362268
[2022-12-07 18:52:26,107] [INFO] [runner_train_mujoco] Average state value: 0.48743430509169894
[2022-12-07 18:52:26,107] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 18:52:26,148] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04689
[2022-12-07 18:52:26,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.02516, loss val: 0.04800
[2022-12-07 18:52:26,210] [INFO] [controller] EPOCH 3 loss ppo:  -0.03869, loss val: 0.04807
[2022-12-07 18:52:26,246] [INFO] [controller] EPOCH 4 loss ppo:  -0.04850, loss val: 0.04694
[2022-12-07 18:52:26,252] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:52:26,384] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:52:26,384] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:52:32,489] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:52:40,812] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:52:47,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:52:53,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:52:59,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:53:05,037] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:53:11,047] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:53:16,953] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:53:22,910] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:53:28,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.236490998021127
[2022-12-07 18:53:28,799] [INFO] [runner_train_mujoco] Average state value: 0.5039994709044696
[2022-12-07 18:53:28,799] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 18:53:28,835] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.04315
[2022-12-07 18:53:28,862] [INFO] [controller] EPOCH 2 loss ppo:  -0.02344, loss val: 0.04056
[2022-12-07 18:53:28,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.03421, loss val: 0.04045
[2022-12-07 18:53:28,928] [INFO] [controller] EPOCH 4 loss ppo:  -0.04336, loss val: 0.04119
[2022-12-07 18:53:28,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:53:29,086] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:53:29,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:53:35,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:53:41,527] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:53:49,533] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:53:55,368] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:54:01,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:54:07,107] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:54:12,917] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:54:18,727] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:54:24,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:54:30,745] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.662085284359799
[2022-12-07 18:54:30,745] [INFO] [runner_train_mujoco] Average state value: 0.44626142067710556
[2022-12-07 18:54:30,745] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 18:54:30,786] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.07592
[2022-12-07 18:54:30,824] [INFO] [controller] EPOCH 2 loss ppo:  -0.02161, loss val: 0.07594
[2022-12-07 18:54:30,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.03151, loss val: 0.07574
[2022-12-07 18:54:30,892] [INFO] [controller] EPOCH 4 loss ppo:  -0.04117, loss val: 0.07556
[2022-12-07 18:54:30,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:54:31,064] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:54:31,064] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:54:38,463] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:54:44,376] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:54:50,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:54:56,469] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:55:02,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:55:07,908] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:55:13,693] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:55:19,345] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:55:25,101] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:55:30,976] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5852157343262565
[2022-12-07 18:55:30,976] [INFO] [runner_train_mujoco] Average state value: 0.5030153932770093
[2022-12-07 18:55:30,976] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 18:55:31,009] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04420
[2022-12-07 18:55:31,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.01862, loss val: 0.04470
[2022-12-07 18:55:31,066] [INFO] [controller] EPOCH 3 loss ppo:  -0.02820, loss val: 0.04430
[2022-12-07 18:55:31,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.03868, loss val: 0.04377
[2022-12-07 18:55:31,099] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:55:31,233] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:55:31,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:55:37,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:55:43,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:55:48,857] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:55:54,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:56:00,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:56:05,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:56:11,098] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:56:16,666] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:56:26,887] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:56:32,536] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.02552199015631
[2022-12-07 18:56:32,537] [INFO] [runner_train_mujoco] Average state value: 0.4890455158775051
[2022-12-07 18:56:32,537] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 18:56:32,574] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04048
[2022-12-07 18:56:32,602] [INFO] [controller] EPOCH 2 loss ppo:  -0.02204, loss val: 0.04051
[2022-12-07 18:56:32,629] [INFO] [controller] EPOCH 3 loss ppo:  -0.03302, loss val: 0.04046
[2022-12-07 18:56:32,663] [INFO] [controller] EPOCH 4 loss ppo:  -0.04204, loss val: 0.04028
[2022-12-07 18:56:32,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:56:32,827] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:56:32,828] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:56:38,664] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:56:44,299] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:56:50,090] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:56:56,120] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:57:01,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:57:07,404] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:57:13,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:57:19,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:57:25,420] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:57:31,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.635414317794055
[2022-12-07 18:57:31,126] [INFO] [runner_train_mujoco] Average state value: 0.4926746269861857
[2022-12-07 18:57:31,126] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 18:57:31,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04930
[2022-12-07 18:57:31,187] [INFO] [controller] EPOCH 2 loss ppo:  -0.02130, loss val: 0.04804
[2022-12-07 18:57:31,218] [INFO] [controller] EPOCH 3 loss ppo:  -0.03068, loss val: 0.04927
[2022-12-07 18:57:31,243] [INFO] [controller] EPOCH 4 loss ppo:  -0.03813, loss val: 0.04769
[2022-12-07 18:57:31,248] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:57:31,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:57:31,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:57:37,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:57:42,948] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:57:48,758] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:57:54,529] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:58:00,190] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:58:05,912] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:58:11,546] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:58:17,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:58:23,052] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:58:28,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.49532613806779
[2022-12-07 18:58:28,846] [INFO] [runner_train_mujoco] Average state value: 0.4884193173448244
[2022-12-07 18:58:28,846] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 18:58:28,882] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.03854
[2022-12-07 18:58:28,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.01841, loss val: 0.03842
[2022-12-07 18:58:28,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.02454, loss val: 0.03848
[2022-12-07 18:58:28,989] [INFO] [controller] EPOCH 4 loss ppo:  -0.03074, loss val: 0.03799
[2022-12-07 18:58:28,995] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:58:29,146] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:58:29,146] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:58:34,903] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:58:40,791] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:58:46,504] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:58:52,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:58:57,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 18:59:03,527] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 18:59:09,381] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 18:59:14,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 18:59:20,830] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 18:59:26,625] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.8294612742334255
[2022-12-07 18:59:26,625] [INFO] [runner_train_mujoco] Average state value: 0.48837562553087865
[2022-12-07 18:59:26,625] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 18:59:26,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04229
[2022-12-07 18:59:26,711] [INFO] [controller] EPOCH 2 loss ppo:  -0.01682, loss val: 0.04266
[2022-12-07 18:59:26,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.02115, loss val: 0.04331
[2022-12-07 18:59:26,775] [INFO] [controller] EPOCH 4 loss ppo:  -0.02671, loss val: 0.04269
[2022-12-07 18:59:26,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 18:59:26,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 18:59:26,951] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 18:59:32,674] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 18:59:38,515] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 18:59:44,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 18:59:49,737] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 18:59:55,451] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 19:00:01,150] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 19:00:07,030] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 19:00:12,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 19:00:18,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 19:00:24,220] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.164399489112048
[2022-12-07 19:00:24,220] [INFO] [runner_train_mujoco] Average state value: 0.49064455521106715
[2022-12-07 19:00:24,220] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 19:00:24,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04704
[2022-12-07 19:00:24,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.01586, loss val: 0.04703
[2022-12-07 19:00:24,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.01861, loss val: 0.04703
[2022-12-07 19:00:24,351] [INFO] [controller] EPOCH 4 loss ppo:  -0.02174, loss val: 0.04775
[2022-12-07 19:00:24,356] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 19:00:24,424] [INFO] [optimize] Finished learning.
