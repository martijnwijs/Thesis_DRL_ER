[2022-12-06 20:13:56,783] [INFO] [optimize] Starting learning
[2022-12-06 20:13:56,795] [INFO] [optimize] Starting learning process..
[2022-12-06 20:13:56,892] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:13:56,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:14:04,696] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:14:13,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:14:21,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:14:29,006] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:14:36,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:14:43,321] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:14:50,930] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:14:57,938] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:15:04,866] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:15:12,433] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5446828950990662
[2022-12-06 20:15:12,433] [INFO] [runner_train_mujoco] Average state value: 0.172309895247221
[2022-12-06 20:15:12,434] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 20:15:12,480] [INFO] [controller] EPOCH 1 loss ppo:  -0.00701, loss val: 0.37642
[2022-12-06 20:15:12,532] [INFO] [controller] EPOCH 2 loss ppo:  -0.04670, loss val: 0.32199
[2022-12-06 20:15:12,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.06851, loss val: 0.29202
[2022-12-06 20:15:12,625] [INFO] [controller] EPOCH 4 loss ppo:  -0.07993, loss val: 0.24964
[2022-12-06 20:15:12,635] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:15:12,845] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:15:12,845] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:15:20,853] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:15:29,164] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:15:36,374] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:15:43,299] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:15:50,359] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:15:58,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:16:05,915] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:16:13,182] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:16:20,576] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:16:28,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5025219474519873
[2022-12-06 20:16:28,237] [INFO] [runner_train_mujoco] Average state value: 0.33073220517889906
[2022-12-06 20:16:28,237] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 20:16:28,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01125, loss val: 0.19085
[2022-12-06 20:16:28,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.04785, loss val: 0.17019
[2022-12-06 20:16:28,384] [INFO] [controller] EPOCH 3 loss ppo:  -0.06672, loss val: 0.15478
[2022-12-06 20:16:28,429] [INFO] [controller] EPOCH 4 loss ppo:  -0.07972, loss val: 0.14275
[2022-12-06 20:16:28,438] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:16:28,632] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:16:28,632] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:16:36,226] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:16:44,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:16:51,469] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:16:59,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:17:06,449] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:17:14,037] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:17:21,644] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:17:28,980] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:17:36,545] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:17:44,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6045462380939414
[2022-12-06 20:17:44,214] [INFO] [runner_train_mujoco] Average state value: 0.4673129803330327
[2022-12-06 20:17:44,215] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 20:17:44,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.13221
[2022-12-06 20:17:44,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.04663, loss val: 0.12387
[2022-12-06 20:17:44,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.06158, loss val: 0.11470
[2022-12-06 20:17:44,430] [INFO] [controller] EPOCH 4 loss ppo:  -0.07308, loss val: 0.10899
[2022-12-06 20:17:44,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:17:44,665] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:17:44,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:17:53,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:18:01,439] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:18:08,785] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:18:16,317] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:18:24,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:18:31,624] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:18:39,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:18:46,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:18:54,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:19:02,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6083117448266628
[2022-12-06 20:19:02,769] [INFO] [runner_train_mujoco] Average state value: 0.5329659695482503
[2022-12-06 20:19:02,769] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 20:19:02,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.10079
[2022-12-06 20:19:02,861] [INFO] [controller] EPOCH 2 loss ppo:  -0.04567, loss val: 0.09338
[2022-12-06 20:19:02,905] [INFO] [controller] EPOCH 3 loss ppo:  -0.06254, loss val: 0.08881
[2022-12-06 20:19:02,953] [INFO] [controller] EPOCH 4 loss ppo:  -0.07463, loss val: 0.08315
[2022-12-06 20:19:02,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:19:03,173] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:19:03,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:19:11,405] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:19:19,961] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:19:27,941] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:19:35,589] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:19:43,388] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:19:50,631] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:19:57,621] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:20:04,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:20:11,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:20:18,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47341709549050115
[2022-12-06 20:20:18,670] [INFO] [runner_train_mujoco] Average state value: 0.5357974403345336
[2022-12-06 20:20:18,670] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 20:20:18,722] [INFO] [controller] EPOCH 1 loss ppo:  -0.00996, loss val: 0.07993
[2022-12-06 20:20:18,759] [INFO] [controller] EPOCH 2 loss ppo:  -0.04132, loss val: 0.07494
[2022-12-06 20:20:18,803] [INFO] [controller] EPOCH 3 loss ppo:  -0.06078, loss val: 0.07065
[2022-12-06 20:20:18,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.07597, loss val: 0.06505
[2022-12-06 20:20:18,850] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:20:19,048] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:20:19,048] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:20:25,847] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:20:32,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:20:39,558] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:20:46,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:20:53,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:20:59,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:21:06,260] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:21:12,858] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:21:19,741] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:21:26,749] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7987793153861845
[2022-12-06 20:21:26,749] [INFO] [runner_train_mujoco] Average state value: 0.4781608080118894
[2022-12-06 20:21:26,749] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 20:21:26,796] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.06999
[2022-12-06 20:21:26,838] [INFO] [controller] EPOCH 2 loss ppo:  -0.04231, loss val: 0.06916
[2022-12-06 20:21:26,879] [INFO] [controller] EPOCH 3 loss ppo:  -0.05977, loss val: 0.06537
[2022-12-06 20:21:26,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.07037, loss val: 0.06179
[2022-12-06 20:21:26,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:21:27,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:21:27,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:21:33,758] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:21:40,575] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:21:47,250] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:21:54,098] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:22:00,767] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:22:07,645] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:22:14,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:22:20,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:22:27,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:22:34,242] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5487307956689739
[2022-12-06 20:22:34,242] [INFO] [runner_train_mujoco] Average state value: 0.5038523224368691
[2022-12-06 20:22:34,242] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 20:22:34,290] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.06057
[2022-12-06 20:22:34,319] [INFO] [controller] EPOCH 2 loss ppo:  -0.04192, loss val: 0.06059
[2022-12-06 20:22:34,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.06079, loss val: 0.05985
[2022-12-06 20:22:34,394] [INFO] [controller] EPOCH 4 loss ppo:  -0.07545, loss val: 0.05666
[2022-12-06 20:22:34,404] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:22:34,588] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:22:34,589] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:22:41,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:22:47,703] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:22:54,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:23:01,005] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:23:07,663] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:23:14,137] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:23:20,739] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:23:27,703] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:23:34,222] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:23:40,827] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6428827070531307
[2022-12-06 20:23:40,828] [INFO] [runner_train_mujoco] Average state value: 0.5710792025725048
[2022-12-06 20:23:40,828] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 20:23:40,877] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.05829
[2022-12-06 20:23:40,916] [INFO] [controller] EPOCH 2 loss ppo:  -0.04473, loss val: 0.05932
[2022-12-06 20:23:40,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.06197, loss val: 0.05669
[2022-12-06 20:23:40,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.07080, loss val: 0.05827
[2022-12-06 20:23:41,003] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:23:41,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:23:41,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:23:48,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:23:54,884] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:24:01,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:24:08,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:24:15,046] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:24:21,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:24:28,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:24:35,766] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:24:42,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:24:49,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6742952082196099
[2022-12-06 20:24:49,389] [INFO] [runner_train_mujoco] Average state value: 0.5852489632566771
[2022-12-06 20:24:49,389] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 20:24:49,439] [INFO] [controller] EPOCH 1 loss ppo:  -0.01014, loss val: 0.06307
[2022-12-06 20:24:49,478] [INFO] [controller] EPOCH 2 loss ppo:  -0.03464, loss val: 0.05857
[2022-12-06 20:24:49,521] [INFO] [controller] EPOCH 3 loss ppo:  -0.05107, loss val: 0.05492
[2022-12-06 20:24:49,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.06910, loss val: 0.05096
[2022-12-06 20:24:49,577] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:24:49,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:24:49,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:24:56,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:25:04,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:25:11,139] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:25:17,871] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:25:24,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:25:31,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:25:38,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:25:45,033] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:25:51,757] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:25:58,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.667440256314889
[2022-12-06 20:25:58,444] [INFO] [runner_train_mujoco] Average state value: 0.5160783337329824
[2022-12-06 20:25:58,444] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 20:25:58,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01137, loss val: 0.04640
[2022-12-06 20:25:58,517] [INFO] [controller] EPOCH 2 loss ppo:  -0.04362, loss val: 0.04612
[2022-12-06 20:25:58,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.06463, loss val: 0.04638
[2022-12-06 20:25:58,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.07522, loss val: 0.04660
[2022-12-06 20:25:58,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:25:58,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:25:58,782] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:26:05,647] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:26:12,460] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:26:19,276] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:26:26,004] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:26:32,694] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:26:39,208] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:26:45,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:26:52,468] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:26:58,984] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:27:05,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8273684725190114
[2022-12-06 20:27:05,543] [INFO] [runner_train_mujoco] Average state value: 0.47692582052946086
[2022-12-06 20:27:05,543] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 20:27:05,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.01258, loss val: 0.04744
[2022-12-06 20:27:05,634] [INFO] [controller] EPOCH 2 loss ppo:  -0.04142, loss val: 0.04623
[2022-12-06 20:27:05,673] [INFO] [controller] EPOCH 3 loss ppo:  -0.06085, loss val: 0.04591
[2022-12-06 20:27:05,705] [INFO] [controller] EPOCH 4 loss ppo:  -0.07499, loss val: 0.04595
[2022-12-06 20:27:05,711] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:27:05,908] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:27:05,908] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:27:12,880] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:27:19,529] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:27:26,579] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:27:32,995] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:27:39,457] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:27:45,782] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:27:52,281] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:27:58,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:28:08,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:28:14,407] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8044133952777697
[2022-12-06 20:28:14,407] [INFO] [runner_train_mujoco] Average state value: 0.47520573757092155
[2022-12-06 20:28:14,407] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 20:28:14,456] [INFO] [controller] EPOCH 1 loss ppo:  -0.01136, loss val: 0.04239
[2022-12-06 20:28:14,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.04230, loss val: 0.04164
[2022-12-06 20:28:14,538] [INFO] [controller] EPOCH 3 loss ppo:  -0.06419, loss val: 0.04049
[2022-12-06 20:28:14,570] [INFO] [controller] EPOCH 4 loss ppo:  -0.07725, loss val: 0.03965
[2022-12-06 20:28:14,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:28:14,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:28:14,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:28:21,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:28:28,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:28:34,893] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:28:41,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:28:47,676] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:28:54,438] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:29:00,987] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:29:07,475] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:29:14,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:29:20,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.729357575538226
[2022-12-06 20:29:20,837] [INFO] [runner_train_mujoco] Average state value: 0.5069337357978025
[2022-12-06 20:29:20,838] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 20:29:20,884] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.05101
[2022-12-06 20:29:20,933] [INFO] [controller] EPOCH 2 loss ppo:  -0.03808, loss val: 0.04830
[2022-12-06 20:29:20,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.05556, loss val: 0.04685
[2022-12-06 20:29:21,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.06920, loss val: 0.04310
[2022-12-06 20:29:21,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:29:21,257] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:29:21,257] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:29:28,122] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:29:35,058] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:29:41,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:29:47,991] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:29:54,544] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:30:01,238] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:30:07,892] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:30:14,377] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:30:21,015] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:30:27,720] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7684992481896211
[2022-12-06 20:30:27,720] [INFO] [runner_train_mujoco] Average state value: 0.5780773172080518
[2022-12-06 20:30:27,720] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 20:30:27,769] [INFO] [controller] EPOCH 1 loss ppo:  -0.01170, loss val: 0.05605
[2022-12-06 20:30:27,805] [INFO] [controller] EPOCH 2 loss ppo:  -0.03665, loss val: 0.05440
[2022-12-06 20:30:27,910] [INFO] [controller] EPOCH 3 loss ppo:  -0.05457, loss val: 0.05668
[2022-12-06 20:30:27,954] [INFO] [controller] EPOCH 4 loss ppo:  -0.06702, loss val: 0.05165
[2022-12-06 20:30:27,964] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:30:28,171] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:30:28,171] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:30:35,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:30:42,335] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:30:49,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:30:56,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:31:03,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:31:10,005] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:31:16,770] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:31:23,650] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:31:30,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:31:36,777] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9040694484948419
[2022-12-06 20:31:36,777] [INFO] [runner_train_mujoco] Average state value: 0.5707025990684828
[2022-12-06 20:31:36,777] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 20:31:36,828] [INFO] [controller] EPOCH 1 loss ppo:  -0.01022, loss val: 0.04460
[2022-12-06 20:31:36,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.03799, loss val: 0.04138
[2022-12-06 20:31:36,906] [INFO] [controller] EPOCH 3 loss ppo:  -0.05442, loss val: 0.04346
[2022-12-06 20:31:36,948] [INFO] [controller] EPOCH 4 loss ppo:  -0.06844, loss val: 0.04029
[2022-12-06 20:31:36,957] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:31:37,130] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:31:37,130] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:31:44,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:31:51,670] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:31:58,302] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:32:04,887] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:32:11,560] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:32:18,176] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:32:24,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:32:31,417] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:32:38,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:32:44,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9849171314627381
[2022-12-06 20:32:44,514] [INFO] [runner_train_mujoco] Average state value: 0.5203715454538664
[2022-12-06 20:32:44,514] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 20:32:44,563] [INFO] [controller] EPOCH 1 loss ppo:  -0.01173, loss val: 0.04148
[2022-12-06 20:32:44,607] [INFO] [controller] EPOCH 2 loss ppo:  -0.04025, loss val: 0.03920
[2022-12-06 20:32:44,647] [INFO] [controller] EPOCH 3 loss ppo:  -0.06084, loss val: 0.03778
[2022-12-06 20:32:44,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.07277, loss val: 0.03921
[2022-12-06 20:32:44,699] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:32:44,904] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:32:44,904] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:32:51,724] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:32:58,826] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:33:05,453] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:33:12,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:33:18,749] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:33:25,627] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:33:32,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:33:38,798] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:33:45,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:33:51,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7716966164444728
[2022-12-06 20:33:51,530] [INFO] [runner_train_mujoco] Average state value: 0.44856816588838894
[2022-12-06 20:33:51,530] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 20:33:51,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.04844
[2022-12-06 20:33:51,619] [INFO] [controller] EPOCH 2 loss ppo:  -0.04000, loss val: 0.05155
[2022-12-06 20:33:51,653] [INFO] [controller] EPOCH 3 loss ppo:  -0.06063, loss val: 0.04486
[2022-12-06 20:33:51,691] [INFO] [controller] EPOCH 4 loss ppo:  -0.07689, loss val: 0.04732
[2022-12-06 20:33:51,700] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:33:51,878] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:33:51,878] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:33:58,691] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:34:05,198] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:34:11,930] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:34:18,516] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:34:25,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:34:31,446] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:34:37,646] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:34:43,923] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:34:50,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:34:56,942] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2976622883477344
[2022-12-06 20:34:56,942] [INFO] [runner_train_mujoco] Average state value: 0.4596213403244813
[2022-12-06 20:34:56,942] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 20:34:56,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.03953
[2022-12-06 20:34:57,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.04032, loss val: 0.03529
[2022-12-06 20:34:57,066] [INFO] [controller] EPOCH 3 loss ppo:  -0.06096, loss val: 0.03531
[2022-12-06 20:34:57,107] [INFO] [controller] EPOCH 4 loss ppo:  -0.07595, loss val: 0.03483
[2022-12-06 20:34:57,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:34:57,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:34:57,289] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:35:04,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:35:11,117] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:35:17,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:35:24,243] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:35:30,824] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:35:37,293] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:35:43,728] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:35:50,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:35:56,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:36:03,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2599583013242621
[2022-12-06 20:36:03,304] [INFO] [runner_train_mujoco] Average state value: 0.46135740221540134
[2022-12-06 20:36:03,305] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 20:36:03,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04805
[2022-12-06 20:36:03,416] [INFO] [controller] EPOCH 2 loss ppo:  -0.04263, loss val: 0.04725
[2022-12-06 20:36:03,463] [INFO] [controller] EPOCH 3 loss ppo:  -0.06070, loss val: 0.04472
[2022-12-06 20:36:03,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.07567, loss val: 0.04396
[2022-12-06 20:36:03,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:36:03,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:36:03,741] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:36:10,428] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:36:17,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:36:24,360] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:36:31,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:36:38,059] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:36:44,744] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:36:51,407] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:36:57,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:37:04,586] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:37:11,439] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.17779326938712
[2022-12-06 20:37:11,440] [INFO] [runner_train_mujoco] Average state value: 0.4714895749886831
[2022-12-06 20:37:11,440] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 20:37:11,489] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04398
[2022-12-06 20:37:11,535] [INFO] [controller] EPOCH 2 loss ppo:  -0.03991, loss val: 0.04210
[2022-12-06 20:37:11,577] [INFO] [controller] EPOCH 3 loss ppo:  -0.05382, loss val: 0.04064
[2022-12-06 20:37:11,619] [INFO] [controller] EPOCH 4 loss ppo:  -0.06943, loss val: 0.03830
[2022-12-06 20:37:11,625] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:37:11,833] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:37:11,834] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:37:18,788] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:37:25,821] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:37:32,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:37:39,735] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:37:46,512] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:37:53,330] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:38:00,133] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:38:06,833] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:38:13,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:38:20,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3677826707175735
[2022-12-06 20:38:20,508] [INFO] [runner_train_mujoco] Average state value: 0.5311304440895717
[2022-12-06 20:38:20,508] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 20:38:20,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04336
[2022-12-06 20:38:20,591] [INFO] [controller] EPOCH 2 loss ppo:  -0.03939, loss val: 0.04425
[2022-12-06 20:38:20,632] [INFO] [controller] EPOCH 3 loss ppo:  -0.05486, loss val: 0.04490
[2022-12-06 20:38:20,677] [INFO] [controller] EPOCH 4 loss ppo:  -0.06965, loss val: 0.04565
[2022-12-06 20:38:20,686] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:38:20,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:38:20,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:38:27,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:38:34,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:38:41,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:38:48,388] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:38:54,883] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:39:01,429] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:39:07,971] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:39:14,623] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:39:21,004] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:39:27,909] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5018805264355857
[2022-12-06 20:39:27,909] [INFO] [runner_train_mujoco] Average state value: 0.5376649548808732
[2022-12-06 20:39:27,909] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 20:39:27,954] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.03500
[2022-12-06 20:39:27,991] [INFO] [controller] EPOCH 2 loss ppo:  -0.03841, loss val: 0.03486
[2022-12-06 20:39:28,027] [INFO] [controller] EPOCH 3 loss ppo:  -0.05900, loss val: 0.03486
[2022-12-06 20:39:28,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.07396, loss val: 0.03470
[2022-12-06 20:39:28,071] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:39:28,275] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:39:28,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:39:35,054] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:39:42,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:39:48,995] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:39:55,964] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:40:02,396] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:40:08,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:40:15,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:40:21,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:40:28,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:40:35,220] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.646210178866888
[2022-12-06 20:40:35,220] [INFO] [runner_train_mujoco] Average state value: 0.5424942706425984
[2022-12-06 20:40:35,220] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 20:40:35,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.03198
[2022-12-06 20:40:35,306] [INFO] [controller] EPOCH 2 loss ppo:  -0.04152, loss val: 0.03274
[2022-12-06 20:40:35,349] [INFO] [controller] EPOCH 3 loss ppo:  -0.05911, loss val: 0.03218
[2022-12-06 20:40:35,391] [INFO] [controller] EPOCH 4 loss ppo:  -0.07327, loss val: 0.03244
[2022-12-06 20:40:35,400] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:40:35,577] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:40:35,578] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:40:42,299] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:40:49,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:40:55,786] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:41:02,318] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:41:08,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:41:15,085] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:41:21,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:41:27,744] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:41:34,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:41:41,279] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0483322539037205
[2022-12-06 20:41:41,279] [INFO] [runner_train_mujoco] Average state value: 0.5613097020785014
[2022-12-06 20:41:41,279] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 20:41:41,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.04025
[2022-12-06 20:41:41,366] [INFO] [controller] EPOCH 2 loss ppo:  -0.04380, loss val: 0.04402
[2022-12-06 20:41:41,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.06276, loss val: 0.04002
[2022-12-06 20:41:41,449] [INFO] [controller] EPOCH 4 loss ppo:  -0.07885, loss val: 0.04003
[2022-12-06 20:41:41,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:41:41,654] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:41:41,654] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:41:48,203] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:41:54,547] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:42:01,193] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:42:07,646] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:42:14,043] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:42:20,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:42:26,654] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:42:33,320] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:42:39,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:42:46,405] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.840524224834708
[2022-12-06 20:42:46,405] [INFO] [runner_train_mujoco] Average state value: 0.48385120970259105
[2022-12-06 20:42:46,405] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 20:42:46,454] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.12417
[2022-12-06 20:42:46,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.03756, loss val: 0.12173
[2022-12-06 20:42:46,540] [INFO] [controller] EPOCH 3 loss ppo:  -0.05286, loss val: 0.12135
[2022-12-06 20:42:46,582] [INFO] [controller] EPOCH 4 loss ppo:  -0.06867, loss val: 0.11823
[2022-12-06 20:42:46,591] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:42:46,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:42:46,776] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:42:53,573] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:43:00,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:43:07,018] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:43:13,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:43:20,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:43:27,253] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:43:33,873] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:43:40,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:43:47,226] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:43:53,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1231459293788615
[2022-12-06 20:43:53,917] [INFO] [runner_train_mujoco] Average state value: 0.573771553337574
[2022-12-06 20:43:53,917] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 20:43:53,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.04316
[2022-12-06 20:43:54,016] [INFO] [controller] EPOCH 2 loss ppo:  -0.04285, loss val: 0.04358
[2022-12-06 20:43:54,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.06439, loss val: 0.04337
[2022-12-06 20:43:54,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.07683, loss val: 0.04280
[2022-12-06 20:43:54,116] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:43:54,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:43:54,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:44:01,389] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:44:08,314] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:44:15,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:44:23,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:44:31,563] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:44:39,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:44:47,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:44:55,031] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:45:02,895] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:45:12,182] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.247814837333862
[2022-12-06 20:45:12,182] [INFO] [runner_train_mujoco] Average state value: 0.5735521488289038
[2022-12-06 20:45:12,183] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 20:45:12,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.04548
[2022-12-06 20:45:12,312] [INFO] [controller] EPOCH 2 loss ppo:  -0.03485, loss val: 0.04317
[2022-12-06 20:45:12,382] [INFO] [controller] EPOCH 3 loss ppo:  -0.05615, loss val: 0.04391
[2022-12-06 20:45:12,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.07212, loss val: 0.04215
[2022-12-06 20:45:12,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:45:12,700] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:45:12,700] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:45:20,844] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:45:30,338] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:45:38,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:45:47,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:45:55,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:46:04,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:46:12,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:46:21,608] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:46:30,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:46:38,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.562824554017968
[2022-12-06 20:46:38,819] [INFO] [runner_train_mujoco] Average state value: 0.5306681067546208
[2022-12-06 20:46:38,820] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 20:46:38,872] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.04172
[2022-12-06 20:46:38,931] [INFO] [controller] EPOCH 2 loss ppo:  -0.04472, loss val: 0.04083
[2022-12-06 20:46:38,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.06379, loss val: 0.04158
[2022-12-06 20:46:39,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.07743, loss val: 0.04120
[2022-12-06 20:46:39,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:46:39,241] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:46:39,241] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:46:46,562] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:46:53,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:47:01,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:47:08,761] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:47:16,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:47:23,355] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:47:30,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:47:38,359] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:47:45,784] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:47:53,441] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.70447714789097
[2022-12-06 20:47:53,441] [INFO] [runner_train_mujoco] Average state value: 0.5096413673559825
[2022-12-06 20:47:53,441] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 20:47:53,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04014
[2022-12-06 20:47:53,546] [INFO] [controller] EPOCH 2 loss ppo:  -0.04029, loss val: 0.03901
[2022-12-06 20:47:53,593] [INFO] [controller] EPOCH 3 loss ppo:  -0.06067, loss val: 0.03875
[2022-12-06 20:47:53,641] [INFO] [controller] EPOCH 4 loss ppo:  -0.07767, loss val: 0.03695
[2022-12-06 20:47:53,652] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:47:53,895] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:47:53,896] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:48:01,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:48:09,299] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:48:16,755] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:48:24,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:48:32,269] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:48:39,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:48:47,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:48:54,835] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:49:02,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:49:10,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4020224740252205
[2022-12-06 20:49:10,930] [INFO] [runner_train_mujoco] Average state value: 0.45247683940579486
[2022-12-06 20:49:10,930] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 20:49:10,987] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.03378
[2022-12-06 20:49:11,037] [INFO] [controller] EPOCH 2 loss ppo:  -0.04492, loss val: 0.03465
[2022-12-06 20:49:11,085] [INFO] [controller] EPOCH 3 loss ppo:  -0.06524, loss val: 0.03750
[2022-12-06 20:49:11,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.07692, loss val: 0.03436
[2022-12-06 20:49:11,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:49:11,363] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:49:11,363] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:49:19,393] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:49:27,249] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:49:35,165] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:49:42,653] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:49:49,760] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:49:57,373] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:50:06,758] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:50:14,386] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:50:22,136] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:50:29,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.555231669624235
[2022-12-06 20:50:29,696] [INFO] [runner_train_mujoco] Average state value: 0.4020710975453257
[2022-12-06 20:50:29,696] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 20:50:29,749] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.08928
[2022-12-06 20:50:29,794] [INFO] [controller] EPOCH 2 loss ppo:  -0.03710, loss val: 0.08875
[2022-12-06 20:50:29,915] [INFO] [controller] EPOCH 3 loss ppo:  -0.05567, loss val: 0.08831
[2022-12-06 20:50:29,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.07280, loss val: 0.08688
[2022-12-06 20:50:29,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:50:30,197] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:50:30,198] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:50:37,791] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:50:44,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:50:52,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:50:59,467] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:51:06,710] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:51:14,273] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:51:21,402] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:51:28,754] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:51:36,168] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:51:44,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.555737212029302
[2022-12-06 20:51:44,034] [INFO] [runner_train_mujoco] Average state value: 0.4768809877485037
[2022-12-06 20:51:44,034] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 20:51:44,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.04253
[2022-12-06 20:51:44,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.03766, loss val: 0.04093
[2022-12-06 20:51:44,176] [INFO] [controller] EPOCH 3 loss ppo:  -0.05531, loss val: 0.03894
[2022-12-06 20:51:44,218] [INFO] [controller] EPOCH 4 loss ppo:  -0.07128, loss val: 0.03710
[2022-12-06 20:51:44,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:51:44,440] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:51:44,441] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:51:52,035] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:51:59,104] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:52:06,140] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:52:13,172] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:52:20,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:52:27,125] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:52:34,099] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:52:41,580] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:52:48,759] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:52:56,476] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6896564400908627
[2022-12-06 20:52:56,476] [INFO] [runner_train_mujoco] Average state value: 0.5193716329981883
[2022-12-06 20:52:56,476] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 20:52:56,526] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.04007
[2022-12-06 20:52:56,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.04097, loss val: 0.04039
[2022-12-06 20:52:56,615] [INFO] [controller] EPOCH 3 loss ppo:  -0.06080, loss val: 0.04007
[2022-12-06 20:52:56,658] [INFO] [controller] EPOCH 4 loss ppo:  -0.07751, loss val: 0.04012
[2022-12-06 20:52:56,668] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:52:56,888] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:52:56,888] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:53:04,200] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:53:11,746] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:53:18,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:53:26,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:53:33,111] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:53:40,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:53:47,995] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:53:55,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:54:02,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:54:10,380] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.833635222179004
[2022-12-06 20:54:10,380] [INFO] [runner_train_mujoco] Average state value: 0.5624124868114789
[2022-12-06 20:54:10,380] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 20:54:10,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.05411
[2022-12-06 20:54:10,475] [INFO] [controller] EPOCH 2 loss ppo:  -0.03476, loss val: 0.05365
[2022-12-06 20:54:10,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.05220, loss val: 0.05257
[2022-12-06 20:54:10,561] [INFO] [controller] EPOCH 4 loss ppo:  -0.07013, loss val: 0.05218
[2022-12-06 20:54:10,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:54:10,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:54:10,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:54:18,031] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:54:25,459] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:54:33,007] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:54:40,745] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:54:48,346] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:54:56,086] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:55:03,548] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:55:11,092] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:55:19,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:55:27,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.41189696819364
[2022-12-06 20:55:27,301] [INFO] [runner_train_mujoco] Average state value: 0.5406082095007102
[2022-12-06 20:55:27,301] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 20:55:27,356] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03416
[2022-12-06 20:55:27,399] [INFO] [controller] EPOCH 2 loss ppo:  -0.03544, loss val: 0.03212
[2022-12-06 20:55:27,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.05530, loss val: 0.03387
[2022-12-06 20:55:27,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.07025, loss val: 0.03315
[2022-12-06 20:55:27,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:55:27,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:55:27,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:55:35,549] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:55:43,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:55:50,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:55:58,874] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:56:06,420] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:56:15,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:56:24,507] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:56:33,088] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:56:41,928] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:56:50,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3993269410759277
[2022-12-06 20:56:50,334] [INFO] [runner_train_mujoco] Average state value: 0.4915909645557404
[2022-12-06 20:56:50,334] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 20:56:50,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.03806
[2022-12-06 20:56:50,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.03813, loss val: 0.03857
[2022-12-06 20:56:50,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.05966, loss val: 0.03907
[2022-12-06 20:56:50,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.07238, loss val: 0.03899
[2022-12-06 20:56:50,545] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:56:50,756] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:56:50,756] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:56:59,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:57:09,832] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:57:19,635] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:57:28,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:57:36,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:57:45,138] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:57:54,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:58:04,340] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:58:14,842] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:58:23,842] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0488517936565085
[2022-12-06 20:58:23,843] [INFO] [runner_train_mujoco] Average state value: 0.4668179073631763
[2022-12-06 20:58:23,843] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 20:58:23,912] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.04047
[2022-12-06 20:58:23,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.03926, loss val: 0.04051
[2022-12-06 20:58:24,015] [INFO] [controller] EPOCH 3 loss ppo:  -0.05821, loss val: 0.04280
[2022-12-06 20:58:24,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.07047, loss val: 0.04073
[2022-12-06 20:58:24,074] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:58:24,303] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:58:24,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:58:33,426] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:58:43,191] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:58:52,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:59:02,651] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:59:12,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:59:21,475] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:59:31,010] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:59:40,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:59:51,009] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:00:00,856] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.173468655343521
[2022-12-06 21:00:00,857] [INFO] [runner_train_mujoco] Average state value: 0.4220508954028288
[2022-12-06 21:00:00,857] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 21:00:00,942] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.07981
[2022-12-06 21:00:01,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.03648, loss val: 0.07728
[2022-12-06 21:00:01,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.05441, loss val: 0.07321
[2022-12-06 21:00:01,122] [INFO] [controller] EPOCH 4 loss ppo:  -0.06831, loss val: 0.07229
[2022-12-06 21:00:01,133] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:00:01,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:00:01,361] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:00:10,882] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:00:20,762] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:00:30,920] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:00:40,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:00:50,760] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:01:01,128] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:01:11,314] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:01:21,427] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:01:31,112] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:01:41,419] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5649239834965547
[2022-12-06 21:01:41,420] [INFO] [runner_train_mujoco] Average state value: 0.4953072441319625
[2022-12-06 21:01:41,420] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 21:01:41,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.02972
[2022-12-06 21:01:41,558] [INFO] [controller] EPOCH 2 loss ppo:  -0.03894, loss val: 0.03259
[2022-12-06 21:01:41,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.05515, loss val: 0.02904
[2022-12-06 21:01:41,663] [INFO] [controller] EPOCH 4 loss ppo:  -0.06751, loss val: 0.02934
[2022-12-06 21:01:41,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:01:41,917] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:01:41,917] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:01:52,170] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:02:01,770] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:02:11,789] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:02:21,774] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:02:31,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:02:41,174] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:02:50,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:03:01,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:03:11,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:03:21,176] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.380600214846917
[2022-12-06 21:03:21,177] [INFO] [runner_train_mujoco] Average state value: 0.4997423942623039
[2022-12-06 21:03:21,178] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 21:03:21,267] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.06203
[2022-12-06 21:03:21,338] [INFO] [controller] EPOCH 2 loss ppo:  -0.03202, loss val: 0.06081
[2022-12-06 21:03:21,392] [INFO] [controller] EPOCH 3 loss ppo:  -0.05200, loss val: 0.06037
[2022-12-06 21:03:21,447] [INFO] [controller] EPOCH 4 loss ppo:  -0.06705, loss val: 0.05841
[2022-12-06 21:03:21,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:03:21,676] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:03:21,676] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:03:31,278] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:03:40,689] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:03:50,071] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:03:58,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:04:08,462] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:04:17,479] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:04:26,339] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:04:35,465] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:04:44,766] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:04:54,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.616308954507106
[2022-12-06 21:04:54,273] [INFO] [runner_train_mujoco] Average state value: 0.49488890783985456
[2022-12-06 21:04:54,273] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 21:04:54,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04008
[2022-12-06 21:04:54,409] [INFO] [controller] EPOCH 2 loss ppo:  -0.03612, loss val: 0.04068
[2022-12-06 21:04:54,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.05605, loss val: 0.04135
[2022-12-06 21:04:54,549] [INFO] [controller] EPOCH 4 loss ppo:  -0.06819, loss val: 0.04126
[2022-12-06 21:04:54,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:04:54,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:04:54,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:05:04,245] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:05:14,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:05:23,679] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:05:32,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:05:42,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:05:51,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:06:01,115] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:06:10,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:06:20,342] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:06:30,439] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7124831785801113
[2022-12-06 21:06:30,439] [INFO] [runner_train_mujoco] Average state value: 0.4909639327327411
[2022-12-06 21:06:30,439] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 21:06:30,499] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.03944
[2022-12-06 21:06:30,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.03269, loss val: 0.03746
[2022-12-06 21:06:30,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.04990, loss val: 0.03744
[2022-12-06 21:06:30,686] [INFO] [controller] EPOCH 4 loss ppo:  -0.06264, loss val: 0.03631
[2022-12-06 21:06:30,697] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:06:30,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:06:30,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:06:40,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:06:51,173] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:07:00,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:07:12,803] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:07:24,096] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:07:33,915] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:07:44,004] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:07:53,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:08:03,958] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:08:14,329] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8804118720643737
[2022-12-06 21:08:14,330] [INFO] [runner_train_mujoco] Average state value: 0.5269898789127667
[2022-12-06 21:08:14,330] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 21:08:14,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.03917
[2022-12-06 21:08:14,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.03288, loss val: 0.03960
[2022-12-06 21:08:14,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.05383, loss val: 0.03834
[2022-12-06 21:08:14,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.06748, loss val: 0.03843
[2022-12-06 21:08:14,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:08:14,878] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:08:14,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:08:25,476] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:08:35,787] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:08:45,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:08:54,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:09:04,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:09:13,935] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:09:23,483] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:09:33,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:09:43,622] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:09:53,212] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9983335516401737
[2022-12-06 21:09:53,213] [INFO] [runner_train_mujoco] Average state value: 0.5423805965185166
[2022-12-06 21:09:53,213] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 21:09:53,286] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.05638
[2022-12-06 21:09:53,345] [INFO] [controller] EPOCH 2 loss ppo:  -0.03151, loss val: 0.05601
[2022-12-06 21:09:53,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.05068, loss val: 0.05601
[2022-12-06 21:09:53,498] [INFO] [controller] EPOCH 4 loss ppo:  -0.06475, loss val: 0.05459
[2022-12-06 21:09:53,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:09:53,741] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:09:53,741] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:10:03,206] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:10:13,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:10:22,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:10:32,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:10:41,693] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:10:50,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:11:00,135] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:11:09,581] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:11:18,979] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:11:30,321] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9213895100019194
[2022-12-06 21:11:30,321] [INFO] [runner_train_mujoco] Average state value: 0.5169194050431252
[2022-12-06 21:11:30,322] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 21:11:30,406] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.04446
[2022-12-06 21:11:30,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.02746, loss val: 0.04316
[2022-12-06 21:11:30,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.04266, loss val: 0.04135
[2022-12-06 21:11:30,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.05404, loss val: 0.03949
[2022-12-06 21:11:30,595] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:11:30,846] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:11:30,846] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:11:40,617] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:11:50,043] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:11:59,026] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:12:07,960] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:12:17,468] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:12:27,074] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:12:41,150] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:12:50,594] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:12:59,649] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:13:08,783] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.157206084386586
[2022-12-06 21:13:08,783] [INFO] [runner_train_mujoco] Average state value: 0.4802209387818972
[2022-12-06 21:13:08,783] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 21:13:08,844] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.03990
[2022-12-06 21:13:08,889] [INFO] [controller] EPOCH 2 loss ppo:  -0.03003, loss val: 0.04172
[2022-12-06 21:13:08,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.04914, loss val: 0.04633
[2022-12-06 21:13:08,986] [INFO] [controller] EPOCH 4 loss ppo:  -0.06305, loss val: 0.04028
[2022-12-06 21:13:08,996] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:13:09,236] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:13:09,237] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:13:19,233] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:13:28,448] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:13:37,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:13:47,440] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:13:57,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:14:07,980] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:14:17,382] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:14:27,181] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:14:36,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:14:46,076] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9453538635980565
[2022-12-06 21:14:46,076] [INFO] [runner_train_mujoco] Average state value: 0.4455260508681337
[2022-12-06 21:14:46,076] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 21:14:46,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01551, loss val: 0.04842
[2022-12-06 21:14:46,192] [INFO] [controller] EPOCH 2 loss ppo:  -0.03183, loss val: 0.04683
[2022-12-06 21:14:46,252] [INFO] [controller] EPOCH 3 loss ppo:  -0.04866, loss val: 0.04564
[2022-12-06 21:14:46,300] [INFO] [controller] EPOCH 4 loss ppo:  -0.05941, loss val: 0.04504
[2022-12-06 21:14:46,311] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:14:46,538] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:14:46,538] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:14:56,609] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:15:07,225] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:15:17,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:15:27,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:15:37,812] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:15:47,638] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:15:57,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:16:07,673] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:16:17,581] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:16:27,074] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.116028888247831
[2022-12-06 21:16:27,075] [INFO] [runner_train_mujoco] Average state value: 0.4582655002474785
[2022-12-06 21:16:27,075] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 21:16:27,150] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04717
[2022-12-06 21:16:27,203] [INFO] [controller] EPOCH 2 loss ppo:  -0.02865, loss val: 0.04686
[2022-12-06 21:16:27,327] [INFO] [controller] EPOCH 3 loss ppo:  -0.04436, loss val: 0.04708
[2022-12-06 21:16:27,382] [INFO] [controller] EPOCH 4 loss ppo:  -0.05582, loss val: 0.04695
[2022-12-06 21:16:27,393] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:16:27,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:16:27,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:16:37,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:16:47,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:16:57,389] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:17:06,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:17:16,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:17:25,383] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:17:35,008] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:17:44,608] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:17:53,608] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:18:02,754] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.305546717936657
[2022-12-06 21:18:02,754] [INFO] [runner_train_mujoco] Average state value: 0.46445727355281513
[2022-12-06 21:18:02,754] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 21:18:02,821] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.04383
[2022-12-06 21:18:02,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.02657, loss val: 0.04425
[2022-12-06 21:18:02,926] [INFO] [controller] EPOCH 3 loss ppo:  -0.04261, loss val: 0.04465
[2022-12-06 21:18:02,980] [INFO] [controller] EPOCH 4 loss ppo:  -0.05481, loss val: 0.04595
[2022-12-06 21:18:02,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:18:03,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:18:03,214] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:18:12,615] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:18:22,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:18:31,400] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:18:40,691] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:18:49,987] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:18:58,865] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:19:08,274] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:19:17,747] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:19:27,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:19:36,417] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.053891945782998
[2022-12-06 21:19:36,417] [INFO] [runner_train_mujoco] Average state value: 0.4523531379153331
[2022-12-06 21:19:36,417] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 21:19:36,472] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04519
[2022-12-06 21:19:36,519] [INFO] [controller] EPOCH 2 loss ppo:  -0.02326, loss val: 0.04279
[2022-12-06 21:19:36,584] [INFO] [controller] EPOCH 3 loss ppo:  -0.03585, loss val: 0.04560
[2022-12-06 21:19:36,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.04709, loss val: 0.04478
[2022-12-06 21:19:36,653] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:19:36,884] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:19:36,885] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:19:46,593] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:19:56,595] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:20:05,645] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:20:15,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:20:24,859] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:20:34,749] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:20:44,314] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:20:53,921] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:21:03,811] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:21:14,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.083986838186574
[2022-12-06 21:21:14,090] [INFO] [runner_train_mujoco] Average state value: 0.46595293336113286
[2022-12-06 21:21:14,090] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 21:21:14,160] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.04277
[2022-12-06 21:21:14,219] [INFO] [controller] EPOCH 2 loss ppo:  -0.02666, loss val: 0.04343
[2022-12-06 21:21:14,274] [INFO] [controller] EPOCH 3 loss ppo:  -0.04284, loss val: 0.04188
[2022-12-06 21:21:14,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.05489, loss val: 0.04244
[2022-12-06 21:21:14,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:21:14,588] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:21:14,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:21:24,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:21:34,681] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:21:44,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:21:54,603] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:22:04,797] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:22:14,825] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:22:25,261] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:22:35,224] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:22:45,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:22:55,357] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0239389607318365
[2022-12-06 21:22:55,358] [INFO] [runner_train_mujoco] Average state value: 0.46677692823608713
[2022-12-06 21:22:55,358] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 21:22:55,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04520
[2022-12-06 21:22:55,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.02328, loss val: 0.05055
[2022-12-06 21:22:55,592] [INFO] [controller] EPOCH 3 loss ppo:  -0.03633, loss val: 0.04449
[2022-12-06 21:22:55,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.04843, loss val: 0.04418
[2022-12-06 21:22:55,681] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:22:55,922] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:22:55,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:23:06,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:23:16,831] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:23:29,395] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:23:38,915] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:23:48,636] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:23:58,181] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:24:07,952] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:24:18,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:24:27,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:24:37,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.749605018768905
[2022-12-06 21:24:37,332] [INFO] [runner_train_mujoco] Average state value: 0.48620990373690925
[2022-12-06 21:24:37,332] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 21:24:37,428] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.03793
[2022-12-06 21:24:37,491] [INFO] [controller] EPOCH 2 loss ppo:  -0.02124, loss val: 0.03973
[2022-12-06 21:24:37,546] [INFO] [controller] EPOCH 3 loss ppo:  -0.03259, loss val: 0.03837
[2022-12-06 21:24:37,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.04430, loss val: 0.04217
[2022-12-06 21:24:37,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:24:37,828] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:24:37,829] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:24:47,830] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:24:57,097] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:25:06,593] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:25:15,831] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:25:25,062] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:25:34,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:25:43,824] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:25:52,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:26:02,068] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:26:12,944] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.504462296547212
[2022-12-06 21:26:12,944] [INFO] [runner_train_mujoco] Average state value: 0.49614071739713345
[2022-12-06 21:26:12,944] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 21:26:13,017] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04129
[2022-12-06 21:26:13,071] [INFO] [controller] EPOCH 2 loss ppo:  -0.02065, loss val: 0.04169
[2022-12-06 21:26:13,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.03138, loss val: 0.04137
[2022-12-06 21:26:13,170] [INFO] [controller] EPOCH 4 loss ppo:  -0.04145, loss val: 0.04139
[2022-12-06 21:26:13,181] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:26:13,406] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:26:13,407] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:26:24,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:26:33,534] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:26:42,782] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:26:52,030] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:27:01,152] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:27:11,019] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:27:20,479] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:27:30,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:27:39,606] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:27:49,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.462327594455937
[2022-12-06 21:27:49,375] [INFO] [runner_train_mujoco] Average state value: 0.5027213243246078
[2022-12-06 21:27:49,375] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 21:27:49,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.04504
[2022-12-06 21:27:49,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.01866, loss val: 0.04511
[2022-12-06 21:27:49,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.02584, loss val: 0.04501
[2022-12-06 21:27:49,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.03451, loss val: 0.04488
[2022-12-06 21:27:49,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:27:49,845] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:27:49,846] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:27:59,827] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:28:09,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:28:18,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:28:27,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:28:36,547] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:28:46,079] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:28:55,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:29:06,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:29:15,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:29:25,592] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.675604080172519
[2022-12-06 21:29:25,593] [INFO] [runner_train_mujoco] Average state value: 0.4968502406279246
[2022-12-06 21:29:25,593] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 21:29:25,663] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.03973
[2022-12-06 21:29:25,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.01862, loss val: 0.03975
[2022-12-06 21:29:25,776] [INFO] [controller] EPOCH 3 loss ppo:  -0.02605, loss val: 0.04139
[2022-12-06 21:29:25,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.03509, loss val: 0.04239
[2022-12-06 21:29:25,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:29:26,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:29:26,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:29:35,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:29:45,719] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:29:55,727] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:30:06,231] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:30:16,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:30:26,682] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:30:36,770] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:30:47,045] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:30:57,081] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:31:06,910] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.644589349269059
[2022-12-06 21:31:06,910] [INFO] [runner_train_mujoco] Average state value: 0.4943821912308534
[2022-12-06 21:31:06,910] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 21:31:06,994] [INFO] [controller] EPOCH 1 loss ppo:  -0.01385, loss val: 0.04953
[2022-12-06 21:31:07,068] [INFO] [controller] EPOCH 2 loss ppo:  -0.01611, loss val: 0.04484
[2022-12-06 21:31:07,124] [INFO] [controller] EPOCH 3 loss ppo:  -0.02036, loss val: 0.04881
[2022-12-06 21:31:07,177] [INFO] [controller] EPOCH 4 loss ppo:  -0.02644, loss val: 0.04701
[2022-12-06 21:31:07,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:31:07,420] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:31:07,420] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:31:17,495] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:31:27,080] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:31:36,679] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:31:46,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:31:56,019] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:32:05,997] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:32:15,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:32:25,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:32:35,480] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:32:45,001] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.65210919907835
[2022-12-06 21:32:45,001] [INFO] [runner_train_mujoco] Average state value: 0.47700844402611253
[2022-12-06 21:32:45,001] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 21:32:45,072] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.06861
[2022-12-06 21:32:45,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.01478, loss val: 0.06802
[2022-12-06 21:32:45,199] [INFO] [controller] EPOCH 3 loss ppo:  -0.01632, loss val: 0.06868
[2022-12-06 21:32:45,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.01838, loss val: 0.06776
[2022-12-06 21:32:45,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:32:45,403] [INFO] [optimize] Finished learning.
