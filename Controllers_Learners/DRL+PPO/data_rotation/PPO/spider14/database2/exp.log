[2022-12-06 17:33:37,236] [INFO] [optimize] Starting learning
[2022-12-06 17:33:37,248] [INFO] [optimize] Starting learning process..
[2022-12-06 17:33:37,352] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:33:37,353] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:33:46,862] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:33:54,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:34:03,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:34:11,655] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:34:19,575] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:34:27,413] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:34:35,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:34:42,780] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:34:50,206] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:34:57,903] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5306762873845134
[2022-12-06 17:34:57,903] [INFO] [runner_train_mujoco] Average state value: -0.07530784400055805
[2022-12-06 17:34:57,903] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 17:34:57,960] [INFO] [controller] EPOCH 1 loss ppo:  -0.01573, loss val: 0.61649
[2022-12-06 17:34:58,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.05609, loss val: 0.54441
[2022-12-06 17:34:58,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.07166, loss val: 0.48369
[2022-12-06 17:34:58,095] [INFO] [controller] EPOCH 4 loss ppo:  -0.08293, loss val: 0.42169
[2022-12-06 17:34:58,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:34:58,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:34:58,323] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:35:06,318] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:35:14,263] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:35:22,358] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:35:30,264] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:35:37,943] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:35:45,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:35:53,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:36:01,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:36:10,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:36:17,571] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6435146076004069
[2022-12-06 17:36:17,571] [INFO] [runner_train_mujoco] Average state value: 0.10910280954372138
[2022-12-06 17:36:17,571] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 17:36:17,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.37762
[2022-12-06 17:36:17,674] [INFO] [controller] EPOCH 2 loss ppo:  -0.04412, loss val: 0.32332
[2022-12-06 17:36:17,725] [INFO] [controller] EPOCH 3 loss ppo:  -0.06533, loss val: 0.28860
[2022-12-06 17:36:17,778] [INFO] [controller] EPOCH 4 loss ppo:  -0.07949, loss val: 0.25190
[2022-12-06 17:36:17,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:36:18,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:36:18,011] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:36:26,098] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:36:34,275] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:36:43,166] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:36:51,446] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:36:59,657] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:37:08,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:37:16,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:37:24,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:37:32,760] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:37:40,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6321086877597615
[2022-12-06 17:37:40,930] [INFO] [runner_train_mujoco] Average state value: 0.2696617156341672
[2022-12-06 17:37:40,930] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 17:37:40,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.19668
[2022-12-06 17:37:41,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.04872, loss val: 0.17316
[2022-12-06 17:37:41,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.06755, loss val: 0.15483
[2022-12-06 17:37:41,129] [INFO] [controller] EPOCH 4 loss ppo:  -0.07954, loss val: 0.13953
[2022-12-06 17:37:41,140] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:37:41,374] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:37:41,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:37:49,845] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:37:58,283] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:38:06,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:38:15,127] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:38:22,822] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:38:30,774] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:38:38,989] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:38:46,724] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:38:54,652] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:39:02,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39445672711585295
[2022-12-06 17:39:02,339] [INFO] [runner_train_mujoco] Average state value: 0.424653067385157
[2022-12-06 17:39:02,339] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 17:39:02,392] [INFO] [controller] EPOCH 1 loss ppo:  -0.01121, loss val: 0.15052
[2022-12-06 17:39:02,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.04268, loss val: 0.12724
[2022-12-06 17:39:02,482] [INFO] [controller] EPOCH 3 loss ppo:  -0.06523, loss val: 0.11913
[2022-12-06 17:39:02,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.07689, loss val: 0.10356
[2022-12-06 17:39:02,538] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:39:02,746] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:39:02,747] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:39:11,233] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:39:19,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:39:27,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:39:35,436] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:39:43,133] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:39:50,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:39:57,626] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:40:04,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:40:11,811] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:40:18,537] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5311002342922541
[2022-12-06 17:40:18,538] [INFO] [runner_train_mujoco] Average state value: 0.5652983159143478
[2022-12-06 17:40:18,538] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 17:40:18,589] [INFO] [controller] EPOCH 1 loss ppo:  -0.01037, loss val: 0.10601
[2022-12-06 17:40:18,630] [INFO] [controller] EPOCH 2 loss ppo:  -0.04474, loss val: 0.10202
[2022-12-06 17:40:18,674] [INFO] [controller] EPOCH 3 loss ppo:  -0.06057, loss val: 0.09992
[2022-12-06 17:40:18,716] [INFO] [controller] EPOCH 4 loss ppo:  -0.07198, loss val: 0.09185
[2022-12-06 17:40:18,725] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:40:18,922] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:40:18,922] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:40:26,101] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:40:32,863] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:40:39,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:40:46,500] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:40:53,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:41:00,480] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:41:07,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:41:14,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:41:21,280] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:41:28,035] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6130914941087682
[2022-12-06 17:41:28,035] [INFO] [runner_train_mujoco] Average state value: 0.5972939223771293
[2022-12-06 17:41:28,035] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 17:41:28,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.07131
[2022-12-06 17:41:28,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.04846, loss val: 0.06882
[2022-12-06 17:41:28,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.06549, loss val: 0.06435
[2022-12-06 17:41:28,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.07696, loss val: 0.05920
[2022-12-06 17:41:28,218] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:41:28,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:41:28,418] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:41:35,704] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:41:42,979] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:41:49,722] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:41:57,475] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:42:04,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:42:11,831] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:42:18,612] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:42:25,506] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:42:32,361] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:42:39,373] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6309586039709337
[2022-12-06 17:42:39,373] [INFO] [runner_train_mujoco] Average state value: 0.590085655843218
[2022-12-06 17:42:39,374] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 17:42:39,422] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.07419
[2022-12-06 17:42:39,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.03986, loss val: 0.07193
[2022-12-06 17:42:39,503] [INFO] [controller] EPOCH 3 loss ppo:  -0.05357, loss val: 0.06442
[2022-12-06 17:42:39,545] [INFO] [controller] EPOCH 4 loss ppo:  -0.06697, loss val: 0.05980
[2022-12-06 17:42:39,555] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:42:39,755] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:42:39,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:42:47,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:42:54,570] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:43:01,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:43:09,362] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:43:17,786] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:43:25,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:43:32,968] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:43:39,966] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:43:46,925] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:43:54,282] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6585748478434474
[2022-12-06 17:43:54,282] [INFO] [runner_train_mujoco] Average state value: 0.5416873610255619
[2022-12-06 17:43:54,282] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 17:43:54,336] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.06519
[2022-12-06 17:43:54,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.04442, loss val: 0.06381
[2022-12-06 17:43:54,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.06265, loss val: 0.06280
[2022-12-06 17:43:54,464] [INFO] [controller] EPOCH 4 loss ppo:  -0.07288, loss val: 0.06110
[2022-12-06 17:43:54,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:43:54,690] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:43:54,691] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:44:02,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:44:10,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:44:17,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:44:25,255] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:44:32,547] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:44:39,669] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:44:46,663] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:44:53,470] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:45:00,273] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:45:07,336] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7402079797472862
[2022-12-06 17:45:07,336] [INFO] [runner_train_mujoco] Average state value: 0.4876738787442445
[2022-12-06 17:45:07,336] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 17:45:07,382] [INFO] [controller] EPOCH 1 loss ppo:  -0.01253, loss val: 0.05254
[2022-12-06 17:45:07,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.04337, loss val: 0.05010
[2022-12-06 17:45:07,467] [INFO] [controller] EPOCH 3 loss ppo:  -0.06136, loss val: 0.04849
[2022-12-06 17:45:07,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.07574, loss val: 0.04731
[2022-12-06 17:45:07,509] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:45:07,712] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:45:07,713] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:45:15,290] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:45:22,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:45:29,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:45:37,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:45:44,286] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:45:51,092] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:45:57,920] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:46:04,763] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:46:11,654] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:46:18,587] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7981400597550142
[2022-12-06 17:46:18,587] [INFO] [runner_train_mujoco] Average state value: 0.4654399890986582
[2022-12-06 17:46:18,587] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 17:46:18,636] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.04899
[2022-12-06 17:46:18,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.04144, loss val: 0.04891
[2022-12-06 17:46:18,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.05923, loss val: 0.04677
[2022-12-06 17:46:18,745] [INFO] [controller] EPOCH 4 loss ppo:  -0.07143, loss val: 0.04498
[2022-12-06 17:46:18,755] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:46:18,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:46:18,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:46:25,894] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:46:32,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:46:39,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:46:46,982] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:46:53,751] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:47:00,389] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:47:07,217] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:47:13,874] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:47:20,375] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:47:27,298] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7296738908403733
[2022-12-06 17:47:27,298] [INFO] [runner_train_mujoco] Average state value: 0.48141132176915813
[2022-12-06 17:47:27,298] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 17:47:27,347] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.04515
[2022-12-06 17:47:27,388] [INFO] [controller] EPOCH 2 loss ppo:  -0.05127, loss val: 0.04224
[2022-12-06 17:47:27,428] [INFO] [controller] EPOCH 3 loss ppo:  -0.06616, loss val: 0.04117
[2022-12-06 17:47:27,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.07631, loss val: 0.04080
[2022-12-06 17:47:27,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:47:27,665] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:47:27,666] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:47:34,723] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:47:41,869] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:47:48,797] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:47:55,937] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:48:02,998] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:48:09,653] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:48:16,532] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:48:23,301] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:48:30,192] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:48:37,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6262338342530434
[2022-12-06 17:48:37,085] [INFO] [runner_train_mujoco] Average state value: 0.5380766519556442
[2022-12-06 17:48:37,085] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 17:48:37,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.05255
[2022-12-06 17:48:37,185] [INFO] [controller] EPOCH 2 loss ppo:  -0.04295, loss val: 0.05393
[2022-12-06 17:48:37,229] [INFO] [controller] EPOCH 3 loss ppo:  -0.06080, loss val: 0.05074
[2022-12-06 17:48:37,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.07869, loss val: 0.04805
[2022-12-06 17:48:37,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:48:37,493] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:48:37,493] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:48:44,906] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:48:52,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:49:00,263] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:49:07,680] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:49:14,855] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:49:21,963] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:49:29,022] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:49:35,889] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:49:43,369] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:49:50,795] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7734177268290316
[2022-12-06 17:49:50,796] [INFO] [runner_train_mujoco] Average state value: 0.5140196275015672
[2022-12-06 17:49:50,796] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 17:49:50,853] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.04084
[2022-12-06 17:49:50,905] [INFO] [controller] EPOCH 2 loss ppo:  -0.04207, loss val: 0.03956
[2022-12-06 17:49:50,949] [INFO] [controller] EPOCH 3 loss ppo:  -0.05798, loss val: 0.04284
[2022-12-06 17:49:50,999] [INFO] [controller] EPOCH 4 loss ppo:  -0.07159, loss val: 0.03882
[2022-12-06 17:49:51,010] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:49:51,239] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:49:51,240] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:49:58,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:50:06,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:50:13,423] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:50:20,810] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:50:28,312] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:50:35,624] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:50:42,757] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:50:49,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:50:57,264] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:51:04,509] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7675208475285854
[2022-12-06 17:51:04,510] [INFO] [runner_train_mujoco] Average state value: 0.49126665991544727
[2022-12-06 17:51:04,510] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 17:51:04,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.04003
[2022-12-06 17:51:04,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.04745, loss val: 0.03979
[2022-12-06 17:51:04,702] [INFO] [controller] EPOCH 3 loss ppo:  -0.06664, loss val: 0.03956
[2022-12-06 17:51:04,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.07959, loss val: 0.03843
[2022-12-06 17:51:04,757] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:51:04,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:51:04,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:51:12,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:51:19,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:51:26,618] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:51:33,824] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:51:41,173] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:51:48,148] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:51:55,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:52:01,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:52:09,062] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:52:16,438] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8727957312149375
[2022-12-06 17:52:16,438] [INFO] [runner_train_mujoco] Average state value: 0.45051074228311583
[2022-12-06 17:52:16,438] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 17:52:16,485] [INFO] [controller] EPOCH 1 loss ppo:  -0.01182, loss val: 0.08423
[2022-12-06 17:52:16,522] [INFO] [controller] EPOCH 2 loss ppo:  -0.04004, loss val: 0.08193
[2022-12-06 17:52:16,558] [INFO] [controller] EPOCH 3 loss ppo:  -0.05862, loss val: 0.07981
[2022-12-06 17:52:16,591] [INFO] [controller] EPOCH 4 loss ppo:  -0.07208, loss val: 0.07903
[2022-12-06 17:52:16,598] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:52:16,747] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:52:16,747] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:52:23,927] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:52:30,981] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:52:37,668] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:52:44,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:52:51,697] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:52:58,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:53:05,199] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:53:12,183] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:53:19,005] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:53:25,965] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9466625827638016
[2022-12-06 17:53:25,965] [INFO] [runner_train_mujoco] Average state value: 0.5320549058616162
[2022-12-06 17:53:25,965] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 17:53:26,008] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.04531
[2022-12-06 17:53:26,043] [INFO] [controller] EPOCH 2 loss ppo:  -0.04052, loss val: 0.04649
[2022-12-06 17:53:26,082] [INFO] [controller] EPOCH 3 loss ppo:  -0.05780, loss val: 0.04629
[2022-12-06 17:53:26,123] [INFO] [controller] EPOCH 4 loss ppo:  -0.07325, loss val: 0.04657
[2022-12-06 17:53:26,132] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:53:26,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:53:26,312] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:53:33,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:53:40,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:53:46,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:53:53,857] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:54:00,724] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:54:07,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:54:14,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:54:21,168] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:54:30,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:54:36,960] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7680166113914694
[2022-12-06 17:54:36,960] [INFO] [runner_train_mujoco] Average state value: 0.5468899188041687
[2022-12-06 17:54:36,960] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 17:54:37,010] [INFO] [controller] EPOCH 1 loss ppo:  -0.01237, loss val: 0.04818
[2022-12-06 17:54:37,053] [INFO] [controller] EPOCH 2 loss ppo:  -0.03766, loss val: 0.04728
[2022-12-06 17:54:37,095] [INFO] [controller] EPOCH 3 loss ppo:  -0.05472, loss val: 0.04661
[2022-12-06 17:54:37,135] [INFO] [controller] EPOCH 4 loss ppo:  -0.06583, loss val: 0.04514
[2022-12-06 17:54:37,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:54:37,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:54:37,349] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:54:44,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:54:51,019] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:54:57,967] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:55:05,115] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:55:12,350] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:55:19,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:55:26,522] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:55:33,500] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:55:40,646] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:55:47,840] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9725477207364162
[2022-12-06 17:55:47,840] [INFO] [runner_train_mujoco] Average state value: 0.5121175837318102
[2022-12-06 17:55:47,840] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 17:55:47,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04269
[2022-12-06 17:55:47,931] [INFO] [controller] EPOCH 2 loss ppo:  -0.04484, loss val: 0.04420
[2022-12-06 17:55:47,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.06342, loss val: 0.04493
[2022-12-06 17:55:48,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.07702, loss val: 0.04301
[2022-12-06 17:55:48,024] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:55:48,224] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:55:48,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:55:55,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:56:02,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:56:09,217] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:56:16,423] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:56:23,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:56:31,259] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:56:39,555] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:56:47,235] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:56:54,637] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:57:01,828] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8813580913101117
[2022-12-06 17:57:01,829] [INFO] [runner_train_mujoco] Average state value: 0.49360288865367574
[2022-12-06 17:57:01,829] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 17:57:01,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01016, loss val: 0.03995
[2022-12-06 17:57:01,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.03728, loss val: 0.03868
[2022-12-06 17:57:01,963] [INFO] [controller] EPOCH 3 loss ppo:  -0.05559, loss val: 0.03630
[2022-12-06 17:57:02,008] [INFO] [controller] EPOCH 4 loss ppo:  -0.07141, loss val: 0.03802
[2022-12-06 17:57:02,018] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:57:02,208] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:57:02,209] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:57:09,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:57:16,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:57:23,979] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:57:31,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:57:38,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:57:45,530] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:57:52,796] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:57:59,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:58:07,139] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:58:13,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4745163354094735
[2022-12-06 17:58:13,974] [INFO] [runner_train_mujoco] Average state value: 0.4605529797871907
[2022-12-06 17:58:13,974] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 17:58:14,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.04458
[2022-12-06 17:58:14,069] [INFO] [controller] EPOCH 2 loss ppo:  -0.03951, loss val: 0.04612
[2022-12-06 17:58:14,106] [INFO] [controller] EPOCH 3 loss ppo:  -0.06094, loss val: 0.04545
[2022-12-06 17:58:14,151] [INFO] [controller] EPOCH 4 loss ppo:  -0.07538, loss val: 0.04632
[2022-12-06 17:58:14,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:58:14,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:58:14,331] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:58:21,406] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:58:28,516] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:58:35,366] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:58:42,317] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:58:49,142] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:58:56,164] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:59:03,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:59:10,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:59:17,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:59:24,100] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.168157003803534
[2022-12-06 17:59:24,100] [INFO] [runner_train_mujoco] Average state value: 0.42042490507910646
[2022-12-06 17:59:24,100] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 17:59:24,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.08812
[2022-12-06 17:59:24,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.03240, loss val: 0.08182
[2022-12-06 17:59:24,219] [INFO] [controller] EPOCH 3 loss ppo:  -0.05016, loss val: 0.07742
[2022-12-06 17:59:24,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.06543, loss val: 0.07702
[2022-12-06 17:59:24,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:59:24,453] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:59:24,453] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:59:31,229] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:59:38,370] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:59:45,058] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:59:51,934] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:59:58,699] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:00:05,504] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:00:12,604] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:00:19,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:00:25,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:00:32,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2935628849422436
[2022-12-06 18:00:32,404] [INFO] [runner_train_mujoco] Average state value: 0.49343837392330164
[2022-12-06 18:00:32,404] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 18:00:32,453] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04231
[2022-12-06 18:00:32,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.03989, loss val: 0.04420
[2022-12-06 18:00:32,521] [INFO] [controller] EPOCH 3 loss ppo:  -0.06088, loss val: 0.03973
[2022-12-06 18:00:32,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.07683, loss val: 0.04042
[2022-12-06 18:00:32,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:00:32,777] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:00:32,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:00:39,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:00:46,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:00:52,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:00:59,389] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:01:06,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:01:13,481] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:01:20,529] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:01:27,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:01:34,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:01:40,737] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4346853301017335
[2022-12-06 18:01:40,737] [INFO] [runner_train_mujoco] Average state value: 0.5612778206169605
[2022-12-06 18:01:40,737] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 18:01:40,786] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.05141
[2022-12-06 18:01:40,830] [INFO] [controller] EPOCH 2 loss ppo:  -0.03997, loss val: 0.05247
[2022-12-06 18:01:40,875] [INFO] [controller] EPOCH 3 loss ppo:  -0.05555, loss val: 0.05304
[2022-12-06 18:01:40,920] [INFO] [controller] EPOCH 4 loss ppo:  -0.06915, loss val: 0.05182
[2022-12-06 18:01:40,929] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:01:41,092] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:01:41,092] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:01:47,886] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:01:54,798] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:02:01,600] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:02:08,545] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:02:15,726] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:02:23,000] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:02:30,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:02:37,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:02:44,226] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:02:51,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5433883017687926
[2022-12-06 18:02:51,091] [INFO] [runner_train_mujoco] Average state value: 0.5589364222586154
[2022-12-06 18:02:51,091] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 18:02:51,139] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.03934
[2022-12-06 18:02:51,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.04443, loss val: 0.03879
[2022-12-06 18:02:51,224] [INFO] [controller] EPOCH 3 loss ppo:  -0.05826, loss val: 0.03867
[2022-12-06 18:02:51,270] [INFO] [controller] EPOCH 4 loss ppo:  -0.07263, loss val: 0.03774
[2022-12-06 18:02:51,279] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:02:51,482] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:02:51,483] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:02:58,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:03:05,494] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:03:12,339] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:03:19,489] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:03:27,245] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:03:34,406] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:03:41,436] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:03:48,362] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:03:55,404] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:04:02,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6856145423537854
[2022-12-06 18:04:02,325] [INFO] [runner_train_mujoco] Average state value: 0.5194843440552553
[2022-12-06 18:04:02,325] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 18:04:02,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.02856
[2022-12-06 18:04:02,412] [INFO] [controller] EPOCH 2 loss ppo:  -0.04196, loss val: 0.03095
[2022-12-06 18:04:02,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.05886, loss val: 0.03261
[2022-12-06 18:04:02,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.07503, loss val: 0.03006
[2022-12-06 18:04:02,504] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:04:02,694] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:04:02,695] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:04:10,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:04:17,127] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:04:24,396] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:04:31,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:04:39,465] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:04:47,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:04:54,067] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:05:01,218] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:05:08,176] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:05:14,990] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6862558956712164
[2022-12-06 18:05:14,990] [INFO] [runner_train_mujoco] Average state value: 0.5151219850778579
[2022-12-06 18:05:14,990] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 18:05:15,034] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.05103
[2022-12-06 18:05:15,075] [INFO] [controller] EPOCH 2 loss ppo:  -0.04081, loss val: 0.04936
[2022-12-06 18:05:15,109] [INFO] [controller] EPOCH 3 loss ppo:  -0.05266, loss val: 0.04569
[2022-12-06 18:05:15,152] [INFO] [controller] EPOCH 4 loss ppo:  -0.06577, loss val: 0.04436
[2022-12-06 18:05:15,163] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:05:15,376] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:05:15,376] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:05:22,579] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:05:29,406] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:05:36,425] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:05:43,854] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:05:51,258] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:05:58,226] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:06:07,722] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:06:14,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:06:21,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:06:28,337] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8945168037286106
[2022-12-06 18:06:28,337] [INFO] [runner_train_mujoco] Average state value: 0.5634523135821026
[2022-12-06 18:06:28,338] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 18:06:28,385] [INFO] [controller] EPOCH 1 loss ppo:  -0.01607, loss val: 0.03482
[2022-12-06 18:06:28,427] [INFO] [controller] EPOCH 2 loss ppo:  -0.04195, loss val: 0.03452
[2022-12-06 18:06:28,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.05947, loss val: 0.03692
[2022-12-06 18:06:28,508] [INFO] [controller] EPOCH 4 loss ppo:  -0.07544, loss val: 0.03577
[2022-12-06 18:06:28,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:06:28,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:06:28,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:06:35,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:06:42,746] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:06:49,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:06:56,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:07:04,575] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:07:13,335] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:07:22,167] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:07:29,126] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:07:35,727] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:07:42,302] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.242344860947798
[2022-12-06 18:07:42,302] [INFO] [runner_train_mujoco] Average state value: 0.6001639110843341
[2022-12-06 18:07:42,302] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 18:07:42,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.03448
[2022-12-06 18:07:42,383] [INFO] [controller] EPOCH 2 loss ppo:  -0.03655, loss val: 0.03621
[2022-12-06 18:07:42,424] [INFO] [controller] EPOCH 3 loss ppo:  -0.05840, loss val: 0.03438
[2022-12-06 18:07:42,461] [INFO] [controller] EPOCH 4 loss ppo:  -0.07293, loss val: 0.03420
[2022-12-06 18:07:42,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:07:42,659] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:07:42,659] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:07:49,361] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:07:56,344] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:08:03,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:08:10,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:08:18,722] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:08:25,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:08:32,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:08:39,001] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:08:45,699] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:08:52,414] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8422085177055507
[2022-12-06 18:08:52,414] [INFO] [runner_train_mujoco] Average state value: 0.6101419163346291
[2022-12-06 18:08:52,414] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 18:08:52,455] [INFO] [controller] EPOCH 1 loss ppo:  -0.01537, loss val: 0.04304
[2022-12-06 18:08:52,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.03915, loss val: 0.04263
[2022-12-06 18:08:52,537] [INFO] [controller] EPOCH 3 loss ppo:  -0.05642, loss val: 0.04283
[2022-12-06 18:08:52,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.07086, loss val: 0.04047
[2022-12-06 18:08:52,587] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:08:52,793] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:08:52,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:08:59,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:09:06,696] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:09:13,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:09:21,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:09:28,257] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:09:35,300] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:09:42,101] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:09:48,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:09:55,825] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:10:02,790] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3315858744213607
[2022-12-06 18:10:02,790] [INFO] [runner_train_mujoco] Average state value: 0.5763431179126103
[2022-12-06 18:10:02,791] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 18:10:02,837] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.04551
[2022-12-06 18:10:02,881] [INFO] [controller] EPOCH 2 loss ppo:  -0.03482, loss val: 0.04400
[2022-12-06 18:10:02,925] [INFO] [controller] EPOCH 3 loss ppo:  -0.05090, loss val: 0.04130
[2022-12-06 18:10:02,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.06752, loss val: 0.03938
[2022-12-06 18:10:02,978] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:10:03,199] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:10:03,200] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:10:10,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:10:17,911] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:10:25,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:10:32,576] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:10:39,739] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:10:46,765] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:10:53,531] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:11:00,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:11:07,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:11:14,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1789146304734692
[2022-12-06 18:11:14,072] [INFO] [runner_train_mujoco] Average state value: 0.5128592904011409
[2022-12-06 18:11:14,072] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 18:11:14,123] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.03897
[2022-12-06 18:11:14,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.03617, loss val: 0.03938
[2022-12-06 18:11:14,277] [INFO] [controller] EPOCH 3 loss ppo:  -0.05605, loss val: 0.03910
[2022-12-06 18:11:14,320] [INFO] [controller] EPOCH 4 loss ppo:  -0.07216, loss val: 0.03927
[2022-12-06 18:11:14,330] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:11:14,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:11:14,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:11:21,348] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:11:29,033] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:11:36,249] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:11:46,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:11:53,815] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:12:00,567] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:12:07,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:12:14,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:12:20,706] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:12:27,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4653870541262823
[2022-12-06 18:12:27,446] [INFO] [runner_train_mujoco] Average state value: 0.4648226207097371
[2022-12-06 18:12:27,446] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 18:12:27,490] [INFO] [controller] EPOCH 1 loss ppo:  -0.01556, loss val: 0.05438
[2022-12-06 18:12:27,532] [INFO] [controller] EPOCH 2 loss ppo:  -0.03586, loss val: 0.05407
[2022-12-06 18:12:27,573] [INFO] [controller] EPOCH 3 loss ppo:  -0.05287, loss val: 0.05433
[2022-12-06 18:12:27,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.06884, loss val: 0.05248
[2022-12-06 18:12:27,620] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:12:27,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:12:27,823] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:12:35,843] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:12:43,221] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:12:50,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:12:56,956] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:13:04,089] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:13:10,832] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:13:17,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:13:24,283] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:13:31,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:13:37,950] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8237485670844817
[2022-12-06 18:13:37,950] [INFO] [runner_train_mujoco] Average state value: 0.4918384384115537
[2022-12-06 18:13:37,950] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 18:13:37,996] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.03823
[2022-12-06 18:13:38,038] [INFO] [controller] EPOCH 2 loss ppo:  -0.03955, loss val: 0.03928
[2022-12-06 18:13:38,080] [INFO] [controller] EPOCH 3 loss ppo:  -0.05735, loss val: 0.03964
[2022-12-06 18:13:38,117] [INFO] [controller] EPOCH 4 loss ppo:  -0.07081, loss val: 0.03811
[2022-12-06 18:13:38,123] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:13:38,328] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:13:38,328] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:13:45,261] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:13:52,443] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:13:59,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:14:06,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:14:13,174] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:14:20,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:14:26,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:14:33,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:14:41,205] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:14:48,232] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6273713665353284
[2022-12-06 18:14:48,232] [INFO] [runner_train_mujoco] Average state value: 0.5260509352187315
[2022-12-06 18:14:48,232] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 18:14:48,284] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.04276
[2022-12-06 18:14:48,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.03611, loss val: 0.04226
[2022-12-06 18:14:48,369] [INFO] [controller] EPOCH 3 loss ppo:  -0.05498, loss val: 0.04169
[2022-12-06 18:14:48,408] [INFO] [controller] EPOCH 4 loss ppo:  -0.06886, loss val: 0.04089
[2022-12-06 18:14:48,418] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:14:48,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:14:48,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:14:56,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:15:03,305] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:15:10,333] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:15:17,458] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:15:25,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:15:32,428] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:15:39,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:15:46,324] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:15:57,125] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:16:04,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.637712400357498
[2022-12-06 18:16:04,364] [INFO] [runner_train_mujoco] Average state value: 0.5151291909019152
[2022-12-06 18:16:04,364] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 18:16:04,418] [INFO] [controller] EPOCH 1 loss ppo:  -0.01587, loss val: 0.03983
[2022-12-06 18:16:04,450] [INFO] [controller] EPOCH 2 loss ppo:  -0.04104, loss val: 0.04192
[2022-12-06 18:16:04,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.05977, loss val: 0.03814
[2022-12-06 18:16:04,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.07394, loss val: 0.03968
[2022-12-06 18:16:04,542] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:16:04,751] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:16:04,752] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:16:12,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:16:19,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:16:26,701] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:16:34,048] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:16:41,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:16:48,903] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:16:55,808] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:17:03,088] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:17:10,132] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:17:17,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6842061563233224
[2022-12-06 18:17:17,401] [INFO] [runner_train_mujoco] Average state value: 0.4835555871526401
[2022-12-06 18:17:17,401] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 18:17:17,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.04285
[2022-12-06 18:17:17,492] [INFO] [controller] EPOCH 2 loss ppo:  -0.03162, loss val: 0.04156
[2022-12-06 18:17:17,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.05101, loss val: 0.04126
[2022-12-06 18:17:17,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.06521, loss val: 0.03955
[2022-12-06 18:17:17,587] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:17:17,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:17:17,801] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:17:24,946] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:17:34,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:17:42,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:17:52,084] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:17:59,725] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:18:07,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:18:15,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:18:23,362] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:18:31,310] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:18:39,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.031947342359311
[2022-12-06 18:18:39,273] [INFO] [runner_train_mujoco] Average state value: 0.5017657532691956
[2022-12-06 18:18:39,273] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 18:18:39,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.01544, loss val: 0.04143
[2022-12-06 18:18:39,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.03930, loss val: 0.04189
[2022-12-06 18:18:39,416] [INFO] [controller] EPOCH 3 loss ppo:  -0.05557, loss val: 0.04317
[2022-12-06 18:18:39,465] [INFO] [controller] EPOCH 4 loss ppo:  -0.06919, loss val: 0.04368
[2022-12-06 18:18:39,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:18:39,688] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:18:39,688] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:18:48,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:18:56,151] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:19:03,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:19:11,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:19:18,434] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:19:26,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:19:34,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:19:42,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:19:50,024] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:19:57,280] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.181111588213983
[2022-12-06 18:19:57,280] [INFO] [runner_train_mujoco] Average state value: 0.5035990355312825
[2022-12-06 18:19:57,280] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 18:19:57,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.04785
[2022-12-06 18:19:57,373] [INFO] [controller] EPOCH 2 loss ppo:  -0.03451, loss val: 0.04561
[2022-12-06 18:19:57,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.05404, loss val: 0.04533
[2022-12-06 18:19:57,464] [INFO] [controller] EPOCH 4 loss ppo:  -0.06613, loss val: 0.04416
[2022-12-06 18:19:57,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:19:57,699] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:19:57,699] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:20:05,597] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:20:13,114] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:20:20,730] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:20:28,569] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:20:36,800] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:20:44,680] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:20:52,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:21:00,345] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:21:08,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:21:16,678] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1776883014460378
[2022-12-06 18:21:16,678] [INFO] [runner_train_mujoco] Average state value: 0.472403281490008
[2022-12-06 18:21:16,678] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 18:21:16,736] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.04130
[2022-12-06 18:21:16,785] [INFO] [controller] EPOCH 2 loss ppo:  -0.03087, loss val: 0.04218
[2022-12-06 18:21:16,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.05003, loss val: 0.04309
[2022-12-06 18:21:16,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.06316, loss val: 0.04365
[2022-12-06 18:21:16,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:21:17,107] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:21:17,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:21:24,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:21:33,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:21:41,224] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:21:49,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:21:57,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:22:05,772] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:22:13,987] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:22:22,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:22:30,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:22:39,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1941180935974502
[2022-12-06 18:22:39,545] [INFO] [runner_train_mujoco] Average state value: 0.4648044606347879
[2022-12-06 18:22:39,545] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 18:22:39,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.05451
[2022-12-06 18:22:39,652] [INFO] [controller] EPOCH 2 loss ppo:  -0.03612, loss val: 0.05633
[2022-12-06 18:22:39,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.05394, loss val: 0.05360
[2022-12-06 18:22:39,745] [INFO] [controller] EPOCH 4 loss ppo:  -0.06779, loss val: 0.05469
[2022-12-06 18:22:39,756] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:22:39,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:22:39,972] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:22:48,081] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:22:57,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:23:08,904] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:23:18,918] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:23:29,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:23:39,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:23:48,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:23:57,695] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:24:06,782] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:24:15,444] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6365833985548237
[2022-12-06 18:24:15,444] [INFO] [runner_train_mujoco] Average state value: 0.45870817632476485
[2022-12-06 18:24:15,445] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 18:24:15,519] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04867
[2022-12-06 18:24:15,569] [INFO] [controller] EPOCH 2 loss ppo:  -0.03244, loss val: 0.04719
[2022-12-06 18:24:15,699] [INFO] [controller] EPOCH 3 loss ppo:  -0.04945, loss val: 0.04804
[2022-12-06 18:24:15,755] [INFO] [controller] EPOCH 4 loss ppo:  -0.06289, loss val: 0.04756
[2022-12-06 18:24:15,767] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:24:16,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:24:16,002] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:24:24,653] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:24:33,305] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:24:40,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:24:51,530] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:24:59,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:25:08,242] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:25:16,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:25:24,951] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:25:33,356] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:25:41,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8139332289141983
[2022-12-06 18:25:41,703] [INFO] [runner_train_mujoco] Average state value: 0.45286655381321916
[2022-12-06 18:25:41,703] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 18:25:41,752] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.03530
[2022-12-06 18:25:41,787] [INFO] [controller] EPOCH 2 loss ppo:  -0.03078, loss val: 0.03668
[2022-12-06 18:25:41,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.04586, loss val: 0.03829
[2022-12-06 18:25:41,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.06215, loss val: 0.03729
[2022-12-06 18:25:41,887] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:25:42,116] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:25:42,117] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:25:50,347] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:25:58,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:26:06,297] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:26:14,824] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:26:23,226] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:26:30,658] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:26:39,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:26:51,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:27:00,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:27:09,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.651522292386506
[2022-12-06 18:27:09,751] [INFO] [runner_train_mujoco] Average state value: 0.42044644741962356
[2022-12-06 18:27:09,751] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 18:27:09,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.05042
[2022-12-06 18:27:09,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.03061, loss val: 0.05085
[2022-12-06 18:27:09,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.04726, loss val: 0.04906
[2022-12-06 18:27:09,948] [INFO] [controller] EPOCH 4 loss ppo:  -0.06121, loss val: 0.04877
[2022-12-06 18:27:09,958] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:27:10,191] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:27:10,191] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:27:19,383] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:27:28,532] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:27:39,810] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:27:51,452] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:28:02,935] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:28:14,054] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:28:24,820] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:28:35,857] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:28:47,429] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:28:57,988] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5189590293018767
[2022-12-06 18:28:57,989] [INFO] [runner_train_mujoco] Average state value: 0.42756714559098086
[2022-12-06 18:28:57,989] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 18:28:58,058] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.05873
[2022-12-06 18:28:58,112] [INFO] [controller] EPOCH 2 loss ppo:  -0.02860, loss val: 0.05548
[2022-12-06 18:28:58,168] [INFO] [controller] EPOCH 3 loss ppo:  -0.04253, loss val: 0.05402
[2022-12-06 18:28:58,228] [INFO] [controller] EPOCH 4 loss ppo:  -0.05544, loss val: 0.05340
[2022-12-06 18:28:58,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:28:58,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:28:58,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:29:09,582] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:29:20,960] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:29:32,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:29:44,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:29:55,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:30:07,263] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:30:18,795] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:30:30,705] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:30:41,917] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:30:53,244] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.019034078048702
[2022-12-06 18:30:53,244] [INFO] [runner_train_mujoco] Average state value: 0.4487371401637792
[2022-12-06 18:30:53,245] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 18:30:53,327] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.07037
[2022-12-06 18:30:53,421] [INFO] [controller] EPOCH 2 loss ppo:  -0.02470, loss val: 0.06901
[2022-12-06 18:30:53,493] [INFO] [controller] EPOCH 3 loss ppo:  -0.03920, loss val: 0.05956
[2022-12-06 18:30:53,549] [INFO] [controller] EPOCH 4 loss ppo:  -0.05177, loss val: 0.06240
[2022-12-06 18:30:53,562] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:30:53,963] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:30:53,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:31:05,235] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:31:16,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:31:27,237] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:31:37,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:31:48,513] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:31:59,474] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:32:10,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:32:20,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:32:31,188] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:32:41,613] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.039905580737548
[2022-12-06 18:32:41,613] [INFO] [runner_train_mujoco] Average state value: 0.5000178099473318
[2022-12-06 18:32:41,614] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 18:32:41,675] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04671
[2022-12-06 18:32:41,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.02899, loss val: 0.04549
[2022-12-06 18:32:41,781] [INFO] [controller] EPOCH 3 loss ppo:  -0.04480, loss val: 0.04534
[2022-12-06 18:32:41,836] [INFO] [controller] EPOCH 4 loss ppo:  -0.05842, loss val: 0.04642
[2022-12-06 18:32:41,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:32:42,094] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:32:42,094] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:32:52,117] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:33:02,393] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:33:12,819] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:33:23,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:33:33,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:33:43,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:33:53,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:34:03,318] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:34:13,454] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:34:23,944] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.019638764978623
[2022-12-06 18:34:23,944] [INFO] [runner_train_mujoco] Average state value: 0.5310905413925647
[2022-12-06 18:34:23,944] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 18:34:24,014] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.04014
[2022-12-06 18:34:24,062] [INFO] [controller] EPOCH 2 loss ppo:  -0.02768, loss val: 0.04027
[2022-12-06 18:34:24,111] [INFO] [controller] EPOCH 3 loss ppo:  -0.04246, loss val: 0.03950
[2022-12-06 18:34:24,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.05518, loss val: 0.03946
[2022-12-06 18:34:24,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:34:24,433] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:34:24,433] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:34:35,110] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:34:45,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:35:00,081] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:35:11,215] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:35:20,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:35:30,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:35:41,550] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:35:52,473] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:36:02,778] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:36:13,305] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.005504686261889
[2022-12-06 18:36:13,305] [INFO] [runner_train_mujoco] Average state value: 0.5424085350433985
[2022-12-06 18:36:13,305] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 18:36:13,382] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04099
[2022-12-06 18:36:13,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.02814, loss val: 0.04098
[2022-12-06 18:36:13,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.04187, loss val: 0.04183
[2022-12-06 18:36:13,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.05444, loss val: 0.04133
[2022-12-06 18:36:13,669] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:36:13,927] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:36:13,927] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:36:27,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:36:42,588] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:36:58,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:37:16,399] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:37:32,455] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:37:45,697] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:38:02,898] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:38:17,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:38:30,547] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:38:45,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.134132316252937
[2022-12-06 18:38:45,893] [INFO] [runner_train_mujoco] Average state value: 0.5338573515216509
[2022-12-06 18:38:45,893] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 18:38:46,047] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.04184
[2022-12-06 18:38:46,139] [INFO] [controller] EPOCH 2 loss ppo:  -0.02837, loss val: 0.04144
[2022-12-06 18:38:46,292] [INFO] [controller] EPOCH 3 loss ppo:  -0.04292, loss val: 0.04077
[2022-12-06 18:38:46,550] [INFO] [controller] EPOCH 4 loss ppo:  -0.05379, loss val: 0.03999
[2022-12-06 18:38:46,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:38:46,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:38:46,930] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:39:03,094] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:39:16,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:39:32,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:39:46,829] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:40:00,245] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:40:15,354] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:40:30,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:40:45,911] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:41:09,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:41:23,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.580324667477382
[2022-12-06 18:41:23,328] [INFO] [runner_train_mujoco] Average state value: 0.5127395847638448
[2022-12-06 18:41:23,329] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 18:41:23,436] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.04328
[2022-12-06 18:41:23,506] [INFO] [controller] EPOCH 2 loss ppo:  -0.02550, loss val: 0.04267
[2022-12-06 18:41:23,688] [INFO] [controller] EPOCH 3 loss ppo:  -0.03866, loss val: 0.04233
[2022-12-06 18:41:23,826] [INFO] [controller] EPOCH 4 loss ppo:  -0.04859, loss val: 0.04206
[2022-12-06 18:41:23,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:41:24,184] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:41:24,185] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:41:36,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:41:49,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:42:01,869] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:42:13,789] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:42:26,264] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:42:40,357] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:42:56,078] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:43:09,920] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:43:24,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:43:37,679] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.504608407670168
[2022-12-06 18:43:37,679] [INFO] [runner_train_mujoco] Average state value: 0.4879983997046947
[2022-12-06 18:43:37,679] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 18:43:37,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.04089
[2022-12-06 18:43:37,867] [INFO] [controller] EPOCH 2 loss ppo:  -0.02345, loss val: 0.04194
[2022-12-06 18:43:37,935] [INFO] [controller] EPOCH 3 loss ppo:  -0.03608, loss val: 0.04245
[2022-12-06 18:43:38,027] [INFO] [controller] EPOCH 4 loss ppo:  -0.04607, loss val: 0.04366
[2022-12-06 18:43:38,041] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:43:38,343] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:43:38,344] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:43:53,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:44:07,244] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:44:21,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:44:35,672] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:44:49,415] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:45:03,241] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:45:16,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:45:30,925] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:45:44,926] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:45:59,216] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.19432619957139
[2022-12-06 18:45:59,216] [INFO] [runner_train_mujoco] Average state value: 0.48713699970642727
[2022-12-06 18:45:59,216] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 18:45:59,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.03745
[2022-12-06 18:45:59,483] [INFO] [controller] EPOCH 2 loss ppo:  -0.02325, loss val: 0.03685
[2022-12-06 18:45:59,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.03491, loss val: 0.03631
[2022-12-06 18:45:59,660] [INFO] [controller] EPOCH 4 loss ppo:  -0.04519, loss val: 0.03563
[2022-12-06 18:45:59,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:45:59,963] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:45:59,964] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:46:14,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:46:28,244] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:46:41,859] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:46:55,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:47:09,699] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:47:23,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:47:38,139] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:47:51,747] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:48:05,785] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:48:19,586] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.582038161083938
[2022-12-06 18:48:19,586] [INFO] [runner_train_mujoco] Average state value: 0.5029153533478578
[2022-12-06 18:48:19,586] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 18:48:19,683] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04310
[2022-12-06 18:48:19,760] [INFO] [controller] EPOCH 2 loss ppo:  -0.02109, loss val: 0.04538
[2022-12-06 18:48:19,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.03203, loss val: 0.04332
[2022-12-06 18:48:19,932] [INFO] [controller] EPOCH 4 loss ppo:  -0.04430, loss val: 0.04330
[2022-12-06 18:48:19,945] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:48:20,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:48:20,218] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:48:34,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:48:47,941] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:49:01,370] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:49:15,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:49:28,970] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:49:42,957] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:49:56,429] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:50:10,109] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:50:23,480] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:50:37,537] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.380722551575315
[2022-12-06 18:50:37,538] [INFO] [runner_train_mujoco] Average state value: 0.49729864662885664
[2022-12-06 18:50:37,538] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 18:50:37,636] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04710
[2022-12-06 18:50:37,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.01966, loss val: 0.04874
[2022-12-06 18:50:37,811] [INFO] [controller] EPOCH 3 loss ppo:  -0.03013, loss val: 0.04807
[2022-12-06 18:50:37,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.03996, loss val: 0.04696
[2022-12-06 18:50:37,892] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:50:38,193] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:50:38,194] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:50:52,386] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:51:05,954] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:51:19,458] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:51:32,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:51:46,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:52:00,072] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:52:13,944] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:52:27,828] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:52:41,101] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:52:54,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.557934725576052
[2022-12-06 18:52:54,636] [INFO] [runner_train_mujoco] Average state value: 0.5098468220333258
[2022-12-06 18:52:54,650] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 18:52:54,791] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.02924
[2022-12-06 18:52:54,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.01861, loss val: 0.02916
[2022-12-06 18:52:54,961] [INFO] [controller] EPOCH 3 loss ppo:  -0.02689, loss val: 0.02892
[2022-12-06 18:52:55,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.03569, loss val: 0.02906
[2022-12-06 18:52:55,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:52:55,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:52:55,398] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:53:08,961] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:53:22,202] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:53:36,206] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:53:49,749] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:54:03,504] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:54:16,993] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:54:30,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:54:43,826] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:54:57,465] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:55:11,095] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.211635778575561
[2022-12-06 18:55:11,096] [INFO] [runner_train_mujoco] Average state value: 0.4856094643274943
[2022-12-06 18:55:11,096] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 18:55:11,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.06542
[2022-12-06 18:55:11,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.01730, loss val: 0.06605
[2022-12-06 18:55:11,340] [INFO] [controller] EPOCH 3 loss ppo:  -0.02325, loss val: 0.06563
[2022-12-06 18:55:11,406] [INFO] [controller] EPOCH 4 loss ppo:  -0.03034, loss val: 0.06788
[2022-12-06 18:55:11,422] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:55:11,742] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:55:11,742] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:55:25,838] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:55:39,585] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:55:52,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:56:06,784] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:56:19,839] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:56:33,395] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:56:46,775] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:57:01,220] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:57:13,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:57:24,941] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.509643024110073
[2022-12-06 18:57:24,941] [INFO] [runner_train_mujoco] Average state value: 0.5105233531494935
[2022-12-06 18:57:24,941] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 18:57:25,023] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.05002
[2022-12-06 18:57:25,080] [INFO] [controller] EPOCH 2 loss ppo:  -0.01628, loss val: 0.05013
[2022-12-06 18:57:25,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.02005, loss val: 0.05139
[2022-12-06 18:57:25,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.02569, loss val: 0.05007
[2022-12-06 18:57:25,246] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:57:25,489] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:57:25,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:57:39,217] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:57:52,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:58:06,976] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:58:20,656] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:58:34,314] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:58:47,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:59:00,954] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:59:14,686] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:59:28,106] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:59:42,585] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.984131893939619
[2022-12-06 18:59:42,585] [INFO] [runner_train_mujoco] Average state value: 0.5120706327656905
[2022-12-06 18:59:42,586] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 18:59:42,704] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.03822
[2022-12-06 18:59:42,808] [INFO] [controller] EPOCH 2 loss ppo:  -0.01566, loss val: 0.03821
[2022-12-06 18:59:42,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.01768, loss val: 0.04037
[2022-12-06 18:59:43,021] [INFO] [controller] EPOCH 4 loss ppo:  -0.02033, loss val: 0.03824
[2022-12-06 18:59:43,037] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:59:43,231] [INFO] [optimize] Finished learning.
