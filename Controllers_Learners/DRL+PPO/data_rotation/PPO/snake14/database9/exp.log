[2022-12-07 08:45:25,470] [INFO] [optimize] Starting learning
[2022-12-07 08:45:25,485] [INFO] [optimize] Starting learning process..
[2022-12-07 08:45:25,612] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:45:25,612] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:45:36,876] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:45:45,599] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:45:55,016] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:46:03,523] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:46:13,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:46:22,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:46:32,658] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:46:41,078] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:46:49,932] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:46:59,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5450033907098888
[2022-12-07 08:46:59,215] [INFO] [runner_train_mujoco] Average state value: 0.08168971826136114
[2022-12-07 08:46:59,215] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:46:59,271] [INFO] [controller] EPOCH 1 loss ppo:  -0.01022, loss val: 0.42483
[2022-12-07 08:46:59,321] [INFO] [controller] EPOCH 2 loss ppo:  -0.05310, loss val: 0.38034
[2022-12-07 08:46:59,371] [INFO] [controller] EPOCH 3 loss ppo:  -0.06661, loss val: 0.33631
[2022-12-07 08:46:59,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.07929, loss val: 0.31084
[2022-12-07 08:46:59,432] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:46:59,640] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:46:59,640] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:47:08,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:47:17,629] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:47:25,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:47:33,778] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:47:43,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:47:53,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:48:02,305] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:48:10,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:48:19,338] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:48:27,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3718939940004622
[2022-12-07 08:48:27,508] [INFO] [runner_train_mujoco] Average state value: 0.2590075425133109
[2022-12-07 08:48:27,508] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:48:27,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.23446
[2022-12-07 08:48:27,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.05174, loss val: 0.21151
[2022-12-07 08:48:27,664] [INFO] [controller] EPOCH 3 loss ppo:  -0.07077, loss val: 0.18704
[2022-12-07 08:48:27,708] [INFO] [controller] EPOCH 4 loss ppo:  -0.08344, loss val: 0.16936
[2022-12-07 08:48:27,717] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:48:27,923] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:48:27,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:48:36,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:48:44,752] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:48:53,146] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:49:01,220] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:49:09,040] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:49:17,343] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:49:25,807] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:49:34,476] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:49:45,063] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:49:54,500] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6284284708531822
[2022-12-07 08:49:54,500] [INFO] [runner_train_mujoco] Average state value: 0.3344057195050021
[2022-12-07 08:49:54,500] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:49:54,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.22770
[2022-12-07 08:49:54,603] [INFO] [controller] EPOCH 2 loss ppo:  -0.05474, loss val: 0.21173
[2022-12-07 08:49:54,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.07460, loss val: 0.19823
[2022-12-07 08:49:54,708] [INFO] [controller] EPOCH 4 loss ppo:  -0.08547, loss val: 0.18603
[2022-12-07 08:49:54,718] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:49:54,934] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:49:54,935] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:50:04,714] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:50:14,186] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:50:23,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:50:32,901] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:50:42,041] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:50:51,315] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:51:00,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:51:10,145] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:51:19,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:51:28,629] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5987930350158368
[2022-12-07 08:51:28,629] [INFO] [runner_train_mujoco] Average state value: 0.4652289421136181
[2022-12-07 08:51:28,629] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:51:28,736] [INFO] [controller] EPOCH 1 loss ppo:  -0.01578, loss val: 0.14025
[2022-12-07 08:51:28,781] [INFO] [controller] EPOCH 2 loss ppo:  -0.05452, loss val: 0.13369
[2022-12-07 08:51:28,828] [INFO] [controller] EPOCH 3 loss ppo:  -0.07437, loss val: 0.12725
[2022-12-07 08:51:28,877] [INFO] [controller] EPOCH 4 loss ppo:  -0.08619, loss val: 0.12085
[2022-12-07 08:51:28,887] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:51:29,107] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:51:29,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:38,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:51:47,658] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:51:57,247] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:52:06,184] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:52:15,459] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:52:24,784] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:52:34,331] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:52:43,262] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:52:52,787] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:53:01,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6070859065266387
[2022-12-07 08:53:01,914] [INFO] [runner_train_mujoco] Average state value: 0.46633163382795945
[2022-12-07 08:53:01,914] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:53:01,971] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.14724
[2022-12-07 08:53:02,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.05092, loss val: 0.14187
[2022-12-07 08:53:02,077] [INFO] [controller] EPOCH 3 loss ppo:  -0.07038, loss val: 0.14557
[2022-12-07 08:53:02,129] [INFO] [controller] EPOCH 4 loss ppo:  -0.08141, loss val: 0.12875
[2022-12-07 08:53:02,139] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:53:02,348] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:53:02,348] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:53:10,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:53:20,630] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:29,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:38,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:53:47,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:56,919] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:54:05,682] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:54:14,819] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:54:24,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:54:34,560] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6523275348594684
[2022-12-07 08:54:34,561] [INFO] [runner_train_mujoco] Average state value: 0.44037102012087903
[2022-12-07 08:54:34,561] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:54:34,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.13190
[2022-12-07 08:54:34,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.04599, loss val: 0.12983
[2022-12-07 08:54:34,734] [INFO] [controller] EPOCH 3 loss ppo:  -0.06426, loss val: 0.12422
[2022-12-07 08:54:34,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.08027, loss val: 0.11421
[2022-12-07 08:54:34,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:54:35,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:54:35,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:54:44,840] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:54:53,540] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:55:02,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:55:11,367] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:55:20,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:55:30,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:39,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:55:48,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:55:57,694] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:56:06,775] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.573371474125036
[2022-12-07 08:56:06,775] [INFO] [runner_train_mujoco] Average state value: 0.5019667747467758
[2022-12-07 08:56:06,775] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:56:06,832] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.08739
[2022-12-07 08:56:06,875] [INFO] [controller] EPOCH 2 loss ppo:  -0.04764, loss val: 0.08832
[2022-12-07 08:56:06,918] [INFO] [controller] EPOCH 3 loss ppo:  -0.06284, loss val: 0.08656
[2022-12-07 08:56:06,965] [INFO] [controller] EPOCH 4 loss ppo:  -0.07516, loss val: 0.07989
[2022-12-07 08:56:06,976] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:56:07,193] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:56:07,194] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:56:16,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:56:25,973] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:56:35,559] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:56:45,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:56:54,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:57:03,154] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:57:12,692] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:57:22,328] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:31,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:40,774] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2620585645836313
[2022-12-07 08:57:40,775] [INFO] [runner_train_mujoco] Average state value: 0.45864800185337656
[2022-12-07 08:57:40,775] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:57:40,834] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.11454
[2022-12-07 08:57:40,876] [INFO] [controller] EPOCH 2 loss ppo:  -0.04850, loss val: 0.11064
[2022-12-07 08:57:40,920] [INFO] [controller] EPOCH 3 loss ppo:  -0.06596, loss val: 0.10795
[2022-12-07 08:57:40,963] [INFO] [controller] EPOCH 4 loss ppo:  -0.08160, loss val: 0.10405
[2022-12-07 08:57:40,972] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:41,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:41,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:57:50,527] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:57:59,813] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:58:08,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:58:17,681] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:58:27,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:58:36,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:58:45,429] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:55,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:59:04,548] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:59:13,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3867459383563632
[2022-12-07 08:59:13,651] [INFO] [runner_train_mujoco] Average state value: 0.47597550433004887
[2022-12-07 08:59:13,652] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:59:13,712] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.11272
[2022-12-07 08:59:13,755] [INFO] [controller] EPOCH 2 loss ppo:  -0.04874, loss val: 0.10913
[2022-12-07 08:59:13,800] [INFO] [controller] EPOCH 3 loss ppo:  -0.06821, loss val: 0.10693
[2022-12-07 08:59:13,845] [INFO] [controller] EPOCH 4 loss ppo:  -0.08228, loss val: 0.10201
[2022-12-07 08:59:13,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:59:14,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:59:14,074] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:59:23,423] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:59:32,355] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:59:41,846] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:59:50,925] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:00:00,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:00:09,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:00:18,607] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:00:27,695] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:00:36,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:00:45,852] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.423120313538809
[2022-12-07 09:00:45,852] [INFO] [runner_train_mujoco] Average state value: 0.5661720340549946
[2022-12-07 09:00:45,852] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 09:00:45,911] [INFO] [controller] EPOCH 1 loss ppo:  -0.01537, loss val: 0.05836
[2022-12-07 09:00:45,955] [INFO] [controller] EPOCH 2 loss ppo:  -0.04979, loss val: 0.05677
[2022-12-07 09:00:46,019] [INFO] [controller] EPOCH 3 loss ppo:  -0.06754, loss val: 0.05481
[2022-12-07 09:00:46,092] [INFO] [controller] EPOCH 4 loss ppo:  -0.07914, loss val: 0.05400
[2022-12-07 09:00:46,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:00:46,328] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:00:46,328] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:00:55,925] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:01:04,982] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:01:14,039] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:01:23,348] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:01:32,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:41,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:50,755] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:01:59,779] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:02:09,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:02:18,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.782600931533199
[2022-12-07 09:02:18,477] [INFO] [runner_train_mujoco] Average state value: 0.6076527115553617
[2022-12-07 09:02:18,477] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 09:02:18,527] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.07110
[2022-12-07 09:02:18,571] [INFO] [controller] EPOCH 2 loss ppo:  -0.04750, loss val: 0.06736
[2022-12-07 09:02:18,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.06621, loss val: 0.06552
[2022-12-07 09:02:18,674] [INFO] [controller] EPOCH 4 loss ppo:  -0.08164, loss val: 0.06348
[2022-12-07 09:02:18,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:02:18,913] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:02:18,913] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:28,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:02:37,609] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:02:46,581] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:02:55,704] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:03:04,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:03:13,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:03:22,933] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:03:32,253] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:03:41,595] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:51,044] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5280599342301742
[2022-12-07 09:03:51,044] [INFO] [runner_train_mujoco] Average state value: 0.5973934387465318
[2022-12-07 09:03:51,045] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 09:03:51,103] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04892
[2022-12-07 09:03:51,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.04194, loss val: 0.04849
[2022-12-07 09:03:51,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.05662, loss val: 0.04072
[2022-12-07 09:03:51,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.07373, loss val: 0.03722
[2022-12-07 09:03:51,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:03:51,506] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:03:51,506] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:04:00,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:04:09,819] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:04:18,718] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:04:27,865] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:04:36,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:04:45,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:04:53,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:05:01,727] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:05:09,945] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:05:18,286] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5156072217512069
[2022-12-07 09:05:18,286] [INFO] [runner_train_mujoco] Average state value: 0.4770256965259711
[2022-12-07 09:05:18,286] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 09:05:18,335] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.06569
[2022-12-07 09:05:18,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.04703, loss val: 0.06838
[2022-12-07 09:05:18,425] [INFO] [controller] EPOCH 3 loss ppo:  -0.06599, loss val: 0.06601
[2022-12-07 09:05:18,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.08074, loss val: 0.06941
[2022-12-07 09:05:18,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:05:18,685] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:05:18,685] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:05:26,523] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:05:35,007] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:42,877] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:51,177] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:05:59,326] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:06:07,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:06:15,242] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:06:23,701] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:06:32,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:06:40,473] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4343771913522623
[2022-12-07 09:06:40,473] [INFO] [runner_train_mujoco] Average state value: 0.43398837696760895
[2022-12-07 09:06:40,473] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 09:06:40,528] [INFO] [controller] EPOCH 1 loss ppo:  -0.01733, loss val: 0.06851
[2022-12-07 09:06:40,584] [INFO] [controller] EPOCH 2 loss ppo:  -0.05154, loss val: 0.07121
[2022-12-07 09:06:40,633] [INFO] [controller] EPOCH 3 loss ppo:  -0.06858, loss val: 0.06687
[2022-12-07 09:06:40,676] [INFO] [controller] EPOCH 4 loss ppo:  -0.08262, loss val: 0.06510
[2022-12-07 09:06:40,686] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:06:40,902] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:06:40,902] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:06:48,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:06:56,845] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:07:05,538] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:07:14,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:07:24,398] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:07:33,068] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:07:41,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:07:49,732] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:07:58,079] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:08:06,022] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4505565787387058
[2022-12-07 09:08:06,022] [INFO] [runner_train_mujoco] Average state value: 0.45054395113885404
[2022-12-07 09:08:06,022] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 09:08:06,131] [INFO] [controller] EPOCH 1 loss ppo:  -0.01495, loss val: 0.05150
[2022-12-07 09:08:06,177] [INFO] [controller] EPOCH 2 loss ppo:  -0.04867, loss val: 0.05082
[2022-12-07 09:08:06,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.06507, loss val: 0.04958
[2022-12-07 09:08:06,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.07954, loss val: 0.04798
[2022-12-07 09:08:06,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:08:06,503] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:08:06,503] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:08:14,525] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:08:22,699] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:08:31,100] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:08:39,053] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:08:46,975] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:08:55,204] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:09:03,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:09:11,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:09:20,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:09:27,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6789755350612499
[2022-12-07 09:09:27,846] [INFO] [runner_train_mujoco] Average state value: 0.4917397060145935
[2022-12-07 09:09:27,846] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 09:09:27,904] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04396
[2022-12-07 09:09:27,952] [INFO] [controller] EPOCH 2 loss ppo:  -0.04532, loss val: 0.04356
[2022-12-07 09:09:28,000] [INFO] [controller] EPOCH 3 loss ppo:  -0.06703, loss val: 0.04671
[2022-12-07 09:09:28,043] [INFO] [controller] EPOCH 4 loss ppo:  -0.08204, loss val: 0.04261
[2022-12-07 09:09:28,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:09:28,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:09:28,289] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:09:36,768] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:09:44,730] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:09:53,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:10:01,640] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:10:09,637] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:10:18,076] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:10:26,867] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:10:35,340] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:10:43,510] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:10:51,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3173064983263252
[2022-12-07 09:10:51,267] [INFO] [runner_train_mujoco] Average state value: 0.5044953950047493
[2022-12-07 09:10:51,267] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 09:10:51,328] [INFO] [controller] EPOCH 1 loss ppo:  -0.01015, loss val: 0.04721
[2022-12-07 09:10:51,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.03898, loss val: 0.04659
[2022-12-07 09:10:51,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.06053, loss val: 0.04631
[2022-12-07 09:10:51,458] [INFO] [controller] EPOCH 4 loss ppo:  -0.07477, loss val: 0.04555
[2022-12-07 09:10:51,466] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:10:51,673] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:10:51,674] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:10:59,815] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:11:08,402] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:11:16,303] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:11:24,059] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:11:32,590] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:11:41,207] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:11:49,401] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:11:57,598] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:12:05,875] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:12:13,921] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.648020892863721
[2022-12-07 09:12:13,921] [INFO] [runner_train_mujoco] Average state value: 0.505559146453937
[2022-12-07 09:12:13,921] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 09:12:14,021] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04704
[2022-12-07 09:12:14,078] [INFO] [controller] EPOCH 2 loss ppo:  -0.04604, loss val: 0.04547
[2022-12-07 09:12:14,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.06746, loss val: 0.04419
[2022-12-07 09:12:14,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.08297, loss val: 0.04482
[2022-12-07 09:12:14,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:12:14,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:12:14,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:12:22,816] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:12:31,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:12:39,598] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:12:47,536] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:12:55,409] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:13:03,480] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:13:12,016] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:13:20,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:13:29,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:37,316] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4330152118613029
[2022-12-07 09:13:37,316] [INFO] [runner_train_mujoco] Average state value: 0.536600726644198
[2022-12-07 09:13:37,316] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 09:13:37,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01259, loss val: 0.04103
[2022-12-07 09:13:37,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.04546, loss val: 0.04097
[2022-12-07 09:13:37,464] [INFO] [controller] EPOCH 3 loss ppo:  -0.06700, loss val: 0.04011
[2022-12-07 09:13:37,506] [INFO] [controller] EPOCH 4 loss ppo:  -0.07973, loss val: 0.03854
[2022-12-07 09:13:37,517] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:37,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:37,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:13:45,598] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:13:53,531] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:14:02,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:14:10,289] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:14:18,671] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:14:26,890] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:14:35,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:14:43,427] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:14:51,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:15:00,209] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6843984066519984
[2022-12-07 09:15:00,209] [INFO] [runner_train_mujoco] Average state value: 0.4990847299396991
[2022-12-07 09:15:00,209] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 09:15:00,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.03160
[2022-12-07 09:15:00,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.04329, loss val: 0.03896
[2022-12-07 09:15:00,371] [INFO] [controller] EPOCH 3 loss ppo:  -0.06262, loss val: 0.03774
[2022-12-07 09:15:00,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.07936, loss val: 0.03461
[2022-12-07 09:15:00,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:15:00,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:15:00,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:15:08,927] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:15:17,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:15:25,481] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:33,497] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:15:41,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:15:50,418] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:15:58,859] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:16:06,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:16:15,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:16:23,658] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3675520328179438
[2022-12-07 09:16:23,658] [INFO] [runner_train_mujoco] Average state value: 0.47453669118136166
[2022-12-07 09:16:23,658] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 09:16:23,711] [INFO] [controller] EPOCH 1 loss ppo:  -0.01214, loss val: 0.04032
[2022-12-07 09:16:23,756] [INFO] [controller] EPOCH 2 loss ppo:  -0.04197, loss val: 0.03958
[2022-12-07 09:16:23,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.06696, loss val: 0.03844
[2022-12-07 09:16:23,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.08256, loss val: 0.03962
[2022-12-07 09:16:23,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:16:24,070] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:16:24,071] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:16:32,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:16:40,879] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:16:48,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:16:56,764] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:17:04,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:17:13,310] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:17:21,844] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:17:30,106] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:17:38,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:17:46,030] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6051175979763666
[2022-12-07 09:17:46,030] [INFO] [runner_train_mujoco] Average state value: 0.5210122412443161
[2022-12-07 09:17:46,030] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 09:17:46,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.03805
[2022-12-07 09:17:46,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.04585, loss val: 0.03808
[2022-12-07 09:17:46,177] [INFO] [controller] EPOCH 3 loss ppo:  -0.06513, loss val: 0.03613
[2022-12-07 09:17:46,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.07836, loss val: 0.03720
[2022-12-07 09:17:46,228] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:17:46,438] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:17:46,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:17:54,909] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:18:03,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:18:11,407] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:18:19,876] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:18:27,607] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:18:36,270] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:44,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:18:51,822] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:18:59,962] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:19:08,326] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7277061308638946
[2022-12-07 09:19:08,326] [INFO] [runner_train_mujoco] Average state value: 0.5534519770542781
[2022-12-07 09:19:08,326] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 09:19:08,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.04739
[2022-12-07 09:19:08,417] [INFO] [controller] EPOCH 2 loss ppo:  -0.04044, loss val: 0.04747
[2022-12-07 09:19:08,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.05910, loss val: 0.04637
[2022-12-07 09:19:08,504] [INFO] [controller] EPOCH 4 loss ppo:  -0.07637, loss val: 0.04623
[2022-12-07 09:19:08,513] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:19:08,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:19:08,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:19:17,534] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:19:26,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:19:34,272] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:19:42,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:19:50,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:19:59,181] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:20:07,381] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:20:15,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:20:23,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:20:31,644] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.502434913971641
[2022-12-07 09:20:31,644] [INFO] [runner_train_mujoco] Average state value: 0.5283242623259624
[2022-12-07 09:20:31,644] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 09:20:31,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04645
[2022-12-07 09:20:31,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.03676, loss val: 0.04109
[2022-12-07 09:20:31,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.05729, loss val: 0.03722
[2022-12-07 09:20:31,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.07255, loss val: 0.03404
[2022-12-07 09:20:31,817] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:20:32,029] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:20:32,029] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:20:40,431] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:20:48,615] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:20:56,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:21:04,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:21:12,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:21:21,245] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:21:29,440] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:21:37,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:21:46,221] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:21:53,645] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4693297856864203
[2022-12-07 09:21:53,645] [INFO] [runner_train_mujoco] Average state value: 0.4610647479593754
[2022-12-07 09:21:53,645] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 09:21:53,695] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.04533
[2022-12-07 09:21:53,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.04190, loss val: 0.04658
[2022-12-07 09:21:53,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.06099, loss val: 0.04727
[2022-12-07 09:21:53,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.07485, loss val: 0.04776
[2022-12-07 09:21:53,811] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:21:54,022] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:21:54,022] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:22:02,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:22:11,164] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:22:19,220] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:22:27,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:22:36,571] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:22:44,712] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:22:52,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:23:01,333] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:23:09,521] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:23:17,520] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6373481375951175
[2022-12-07 09:23:17,520] [INFO] [runner_train_mujoco] Average state value: 0.4378140275379022
[2022-12-07 09:23:17,520] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 09:23:17,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.05374
[2022-12-07 09:23:17,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.03655, loss val: 0.05144
[2022-12-07 09:23:17,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.05593, loss val: 0.04983
[2022-12-07 09:23:17,755] [INFO] [controller] EPOCH 4 loss ppo:  -0.07064, loss val: 0.04719
[2022-12-07 09:23:17,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:23:17,969] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:23:17,970] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:25,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:23:34,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:23:41,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:23:50,251] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:23:59,050] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:24:07,429] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:24:15,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:24:23,890] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:24:31,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:24:40,020] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7499349296843605
[2022-12-07 09:24:40,020] [INFO] [runner_train_mujoco] Average state value: 0.46948937755823134
[2022-12-07 09:24:40,021] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 09:24:40,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.05831
[2022-12-07 09:24:40,123] [INFO] [controller] EPOCH 2 loss ppo:  -0.03755, loss val: 0.05508
[2022-12-07 09:24:40,164] [INFO] [controller] EPOCH 3 loss ppo:  -0.05447, loss val: 0.05112
[2022-12-07 09:24:40,206] [INFO] [controller] EPOCH 4 loss ppo:  -0.07151, loss val: 0.04853
[2022-12-07 09:24:40,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:24:40,400] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:24:40,401] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:24:48,614] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:24:56,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:25:05,237] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:25:13,337] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:25:21,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:25:30,193] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:25:37,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:25:45,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:25:54,222] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:02,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6425387132765294
[2022-12-07 09:26:02,923] [INFO] [runner_train_mujoco] Average state value: 0.5527156637012958
[2022-12-07 09:26:02,923] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 09:26:02,978] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04356
[2022-12-07 09:26:03,023] [INFO] [controller] EPOCH 2 loss ppo:  -0.04171, loss val: 0.04464
[2022-12-07 09:26:03,067] [INFO] [controller] EPOCH 3 loss ppo:  -0.05910, loss val: 0.04601
[2022-12-07 09:26:03,113] [INFO] [controller] EPOCH 4 loss ppo:  -0.07607, loss val: 0.04776
[2022-12-07 09:26:03,123] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:03,335] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:03,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:26:11,811] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:26:20,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:26:28,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:26:36,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:26:45,017] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:26:53,640] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:27:02,254] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:27:10,362] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:27:18,564] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:27:26,713] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5164328569478112
[2022-12-07 09:27:26,714] [INFO] [runner_train_mujoco] Average state value: 0.582721509416898
[2022-12-07 09:27:26,714] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 09:27:26,763] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03851
[2022-12-07 09:27:26,803] [INFO] [controller] EPOCH 2 loss ppo:  -0.03949, loss val: 0.03901
[2022-12-07 09:27:26,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.05960, loss val: 0.03820
[2022-12-07 09:27:26,886] [INFO] [controller] EPOCH 4 loss ppo:  -0.07384, loss val: 0.03829
[2022-12-07 09:27:26,895] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:27:27,113] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:27:27,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:27:35,555] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:27:43,422] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:51,613] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:28:00,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:28:07,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:28:16,270] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:28:24,010] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:28:31,919] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:28:39,986] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:28:48,356] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7355192048406383
[2022-12-07 09:28:48,357] [INFO] [runner_train_mujoco] Average state value: 0.597104667186737
[2022-12-07 09:28:48,357] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 09:28:48,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.04382
[2022-12-07 09:28:48,690] [INFO] [controller] EPOCH 2 loss ppo:  -0.03779, loss val: 0.04542
[2022-12-07 09:28:48,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.05748, loss val: 0.04330
[2022-12-07 09:28:48,792] [INFO] [controller] EPOCH 4 loss ppo:  -0.07132, loss val: 0.04290
[2022-12-07 09:28:48,800] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:28:49,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:28:49,018] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:28:57,698] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:29:06,147] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:29:13,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:22,142] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:29:30,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:29:38,389] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:29:46,370] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:54,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:02,656] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:11,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3423191522700115
[2022-12-07 09:30:11,171] [INFO] [runner_train_mujoco] Average state value: 0.571489418104291
[2022-12-07 09:30:11,171] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 09:30:11,227] [INFO] [controller] EPOCH 1 loss ppo:  -0.01165, loss val: 0.04743
[2022-12-07 09:30:11,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.03596, loss val: 0.04653
[2022-12-07 09:30:11,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.05756, loss val: 0.04514
[2022-12-07 09:30:11,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.07125, loss val: 0.04370
[2022-12-07 09:30:11,360] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:11,549] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:11,549] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:20,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:30:27,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:30:35,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:30:43,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:30:52,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:31:00,940] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:31:09,489] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:31:17,646] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:31:26,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:31:34,599] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5487211274480428
[2022-12-07 09:31:34,599] [INFO] [runner_train_mujoco] Average state value: 0.5380797076026599
[2022-12-07 09:31:34,599] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 09:31:34,656] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.03848
[2022-12-07 09:31:34,702] [INFO] [controller] EPOCH 2 loss ppo:  -0.04179, loss val: 0.03607
[2022-12-07 09:31:34,746] [INFO] [controller] EPOCH 3 loss ppo:  -0.06113, loss val: 0.03729
[2022-12-07 09:31:34,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.07709, loss val: 0.04028
[2022-12-07 09:31:34,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:31:35,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:31:35,020] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:31:43,659] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:31:52,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:32:00,068] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:32:07,982] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:32:16,467] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:32:24,510] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:32:32,921] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:32:41,151] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:32:49,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:32:57,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.584694207226479
[2022-12-07 09:32:57,264] [INFO] [runner_train_mujoco] Average state value: 0.5135732888082664
[2022-12-07 09:32:57,264] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 09:32:57,315] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04359
[2022-12-07 09:32:57,357] [INFO] [controller] EPOCH 2 loss ppo:  -0.03577, loss val: 0.04295
[2022-12-07 09:32:57,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.05643, loss val: 0.04362
[2022-12-07 09:32:57,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.07323, loss val: 0.04281
[2022-12-07 09:32:57,463] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:32:57,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:32:57,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:33:08,026] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:33:16,172] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:33:24,146] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:33:32,311] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:33:40,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:33:50,398] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:33:58,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:34:06,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:34:13,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:34:21,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4851385544129936
[2022-12-07 09:34:21,783] [INFO] [runner_train_mujoco] Average state value: 0.4983632741073767
[2022-12-07 09:34:21,783] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 09:34:21,839] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.03930
[2022-12-07 09:34:21,888] [INFO] [controller] EPOCH 2 loss ppo:  -0.03538, loss val: 0.03932
[2022-12-07 09:34:21,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.05500, loss val: 0.04154
[2022-12-07 09:34:21,986] [INFO] [controller] EPOCH 4 loss ppo:  -0.06738, loss val: 0.03723
[2022-12-07 09:34:21,996] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:34:22,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:34:22,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:34:31,214] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:34:39,070] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:34:47,146] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:34:55,815] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:35:03,805] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:35:11,232] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:35:18,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:35:26,445] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:35:34,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:35:42,566] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6194334092794502
[2022-12-07 09:35:42,566] [INFO] [runner_train_mujoco] Average state value: 0.4973809678355853
[2022-12-07 09:35:42,566] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 09:35:42,615] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.04924
[2022-12-07 09:35:42,655] [INFO] [controller] EPOCH 2 loss ppo:  -0.03245, loss val: 0.04764
[2022-12-07 09:35:42,698] [INFO] [controller] EPOCH 3 loss ppo:  -0.05231, loss val: 0.04670
[2022-12-07 09:35:42,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.06808, loss val: 0.04515
[2022-12-07 09:35:42,749] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:35:42,955] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:35:42,956] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:35:50,966] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:35:59,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:36:06,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:36:14,434] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:36:23,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:36:30,714] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:36:38,820] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:36:46,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:36:53,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:37:01,289] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.870296262848979
[2022-12-07 09:37:01,289] [INFO] [runner_train_mujoco] Average state value: 0.5592291619777681
[2022-12-07 09:37:01,289] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 09:37:01,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.04444
[2022-12-07 09:37:01,396] [INFO] [controller] EPOCH 2 loss ppo:  -0.03948, loss val: 0.04272
[2022-12-07 09:37:01,443] [INFO] [controller] EPOCH 3 loss ppo:  -0.06095, loss val: 0.04165
[2022-12-07 09:37:01,496] [INFO] [controller] EPOCH 4 loss ppo:  -0.07763, loss val: 0.04079
[2022-12-07 09:37:01,506] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:37:01,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:37:01,736] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:37:10,555] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:37:18,857] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:37:26,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:37:35,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:37:42,878] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:37:50,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:37:58,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:38:06,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:38:14,818] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:38:22,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6543238743370074
[2022-12-07 09:38:22,836] [INFO] [runner_train_mujoco] Average state value: 0.580097892721494
[2022-12-07 09:38:22,836] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 09:38:22,932] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04958
[2022-12-07 09:38:23,022] [INFO] [controller] EPOCH 2 loss ppo:  -0.03500, loss val: 0.04738
[2022-12-07 09:38:23,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.05261, loss val: 0.04670
[2022-12-07 09:38:23,283] [INFO] [controller] EPOCH 4 loss ppo:  -0.06578, loss val: 0.04527
[2022-12-07 09:38:23,294] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:38:23,522] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:38:23,523] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:38:31,421] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:38:39,960] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:38:49,000] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:38:57,301] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:39:05,003] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:39:13,115] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:39:21,073] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:39:28,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:39:36,331] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:39:44,150] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6034671566246543
[2022-12-07 09:39:44,150] [INFO] [runner_train_mujoco] Average state value: 0.5599660195509593
[2022-12-07 09:39:44,150] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 09:39:44,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.03645
[2022-12-07 09:39:44,284] [INFO] [controller] EPOCH 2 loss ppo:  -0.03219, loss val: 0.03498
[2022-12-07 09:39:44,331] [INFO] [controller] EPOCH 3 loss ppo:  -0.05139, loss val: 0.03438
[2022-12-07 09:39:44,433] [INFO] [controller] EPOCH 4 loss ppo:  -0.06778, loss val: 0.03257
[2022-12-07 09:39:44,442] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:39:44,656] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:39:44,656] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:39:52,663] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:40:00,852] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:40:09,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:40:17,548] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:40:25,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:40:34,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:40:43,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:41:00,785] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:41:12,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:41:21,771] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7024483668066164
[2022-12-07 09:41:21,772] [INFO] [runner_train_mujoco] Average state value: 0.5059935383001963
[2022-12-07 09:41:21,772] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 09:41:21,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.01233, loss val: 0.03920
[2022-12-07 09:41:21,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.03617, loss val: 0.03950
[2022-12-07 09:41:21,909] [INFO] [controller] EPOCH 3 loss ppo:  -0.05511, loss val: 0.04006
[2022-12-07 09:41:21,956] [INFO] [controller] EPOCH 4 loss ppo:  -0.07068, loss val: 0.03891
[2022-12-07 09:41:21,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:41:22,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:41:22,187] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:41:31,122] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:41:42,406] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:41:51,391] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:42:00,215] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:42:09,494] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:42:17,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:42:28,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:42:36,668] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:42:46,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:42:59,490] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.468356890057191
[2022-12-07 09:42:59,490] [INFO] [runner_train_mujoco] Average state value: 0.48588944190740585
[2022-12-07 09:42:59,490] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 09:42:59,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.04073
[2022-12-07 09:42:59,620] [INFO] [controller] EPOCH 2 loss ppo:  -0.03577, loss val: 0.04429
[2022-12-07 09:42:59,679] [INFO] [controller] EPOCH 3 loss ppo:  -0.05493, loss val: 0.03946
[2022-12-07 09:42:59,733] [INFO] [controller] EPOCH 4 loss ppo:  -0.06663, loss val: 0.04108
[2022-12-07 09:42:59,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:42:59,967] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:42:59,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:43:11,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:43:19,798] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:43:33,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:43:45,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:44:00,539] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:44:15,994] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:44:27,102] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:44:36,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:44:45,467] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:44:55,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7449696927717497
[2022-12-07 09:44:55,427] [INFO] [runner_train_mujoco] Average state value: 0.48555194034179056
[2022-12-07 09:44:55,427] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 09:44:55,504] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.04798
[2022-12-07 09:44:55,579] [INFO] [controller] EPOCH 2 loss ppo:  -0.02962, loss val: 0.04661
[2022-12-07 09:44:55,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.04765, loss val: 0.04201
[2022-12-07 09:44:55,739] [INFO] [controller] EPOCH 4 loss ppo:  -0.06067, loss val: 0.04039
[2022-12-07 09:44:55,750] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:44:55,985] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:44:55,986] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:45:05,879] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:45:15,078] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:45:26,924] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:45:38,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:45:48,381] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:45:58,138] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:46:07,177] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:46:16,369] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:46:26,522] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:46:37,580] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7449608930776375
[2022-12-07 09:46:37,580] [INFO] [runner_train_mujoco] Average state value: 0.5073453535238902
[2022-12-07 09:46:37,580] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 09:46:37,647] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.04366
[2022-12-07 09:46:37,704] [INFO] [controller] EPOCH 2 loss ppo:  -0.03416, loss val: 0.04463
[2022-12-07 09:46:37,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.05334, loss val: 0.04412
[2022-12-07 09:46:37,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.06746, loss val: 0.04374
[2022-12-07 09:46:37,828] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:46:38,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:46:38,129] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:46:47,616] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:46:56,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:47:05,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:47:13,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:47:22,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:47:31,259] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:47:39,918] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:47:48,408] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:47:57,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:48:06,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7138910177636268
[2022-12-07 09:48:06,148] [INFO] [runner_train_mujoco] Average state value: 0.5297905058860779
[2022-12-07 09:48:06,148] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 09:48:06,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.04160
[2022-12-07 09:48:06,257] [INFO] [controller] EPOCH 2 loss ppo:  -0.03488, loss val: 0.03859
[2022-12-07 09:48:06,312] [INFO] [controller] EPOCH 3 loss ppo:  -0.05245, loss val: 0.03864
[2022-12-07 09:48:06,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.06761, loss val: 0.03998
[2022-12-07 09:48:06,375] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:48:06,589] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:48:06,590] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:48:15,497] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:48:23,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:48:32,734] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:48:40,427] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:48:48,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:48:55,920] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:49:03,568] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:49:11,830] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:49:19,495] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:49:27,203] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9618002556609988
[2022-12-07 09:49:27,203] [INFO] [runner_train_mujoco] Average state value: 0.5321325226624806
[2022-12-07 09:49:27,203] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 09:49:27,274] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.03526
[2022-12-07 09:49:27,323] [INFO] [controller] EPOCH 2 loss ppo:  -0.03011, loss val: 0.04172
[2022-12-07 09:49:27,360] [INFO] [controller] EPOCH 3 loss ppo:  -0.04453, loss val: 0.03895
[2022-12-07 09:49:27,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.05836, loss val: 0.03524
[2022-12-07 09:49:27,408] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:49:27,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:49:27,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:49:35,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:49:42,757] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:49:49,287] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:49:55,911] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:50:02,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:50:09,552] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:50:17,015] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:50:24,027] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:50:31,034] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:50:38,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5426126066717658
[2022-12-07 09:50:38,530] [INFO] [runner_train_mujoco] Average state value: 0.5199261224071184
[2022-12-07 09:50:38,530] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 09:50:38,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04485
[2022-12-07 09:50:38,620] [INFO] [controller] EPOCH 2 loss ppo:  -0.02820, loss val: 0.04690
[2022-12-07 09:50:38,659] [INFO] [controller] EPOCH 3 loss ppo:  -0.04395, loss val: 0.04591
[2022-12-07 09:50:38,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.05728, loss val: 0.04337
[2022-12-07 09:50:38,716] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:50:38,903] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:50:38,904] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:50:45,544] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:50:52,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:50:59,603] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:51:06,839] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:51:13,814] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:51:20,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:51:27,920] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:51:34,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:51:43,291] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:51:53,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.590696028008224
[2022-12-07 09:51:53,752] [INFO] [runner_train_mujoco] Average state value: 0.5037361010213692
[2022-12-07 09:51:53,752] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 09:51:53,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.04229
[2022-12-07 09:51:53,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.03331, loss val: 0.04152
[2022-12-07 09:51:54,022] [INFO] [controller] EPOCH 3 loss ppo:  -0.05081, loss val: 0.04148
[2022-12-07 09:51:54,095] [INFO] [controller] EPOCH 4 loss ppo:  -0.06251, loss val: 0.04148
[2022-12-07 09:51:54,109] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:51:54,380] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:51:54,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:52:02,631] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:52:09,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:52:16,772] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:52:24,145] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:52:31,231] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:52:38,247] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:52:45,031] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:52:51,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:52:58,990] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:53:06,859] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6726050082526958
[2022-12-07 09:53:06,859] [INFO] [runner_train_mujoco] Average state value: 0.5210065193374952
[2022-12-07 09:53:06,859] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 09:53:06,911] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.03515
[2022-12-07 09:53:06,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.02722, loss val: 0.03151
[2022-12-07 09:53:06,996] [INFO] [controller] EPOCH 3 loss ppo:  -0.04631, loss val: 0.03048
[2022-12-07 09:53:07,037] [INFO] [controller] EPOCH 4 loss ppo:  -0.05863, loss val: 0.03117
[2022-12-07 09:53:07,047] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:53:07,260] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:53:07,260] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:53:14,472] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:53:22,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:53:29,722] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:53:36,681] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:53:43,849] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:53:51,504] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:53:58,373] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:54:05,328] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:54:12,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:54:19,984] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5766259137977403
[2022-12-07 09:54:19,984] [INFO] [runner_train_mujoco] Average state value: 0.5140906226436297
[2022-12-07 09:54:19,984] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 09:54:20,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.03912
[2022-12-07 09:54:20,138] [INFO] [controller] EPOCH 2 loss ppo:  -0.02893, loss val: 0.03904
[2022-12-07 09:54:20,191] [INFO] [controller] EPOCH 3 loss ppo:  -0.04488, loss val: 0.03776
[2022-12-07 09:54:20,234] [INFO] [controller] EPOCH 4 loss ppo:  -0.05603, loss val: 0.04000
[2022-12-07 09:54:20,244] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:54:20,450] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:54:20,450] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:54:28,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:54:36,374] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:54:43,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:54:50,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:54:57,996] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:55:05,217] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:55:12,591] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:55:20,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:55:27,985] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:55:35,985] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.09637982639969
[2022-12-07 09:55:35,985] [INFO] [runner_train_mujoco] Average state value: 0.5132314436833064
[2022-12-07 09:55:35,985] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 09:55:36,035] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04545
[2022-12-07 09:55:36,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.02418, loss val: 0.04152
[2022-12-07 09:55:36,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.04176, loss val: 0.04152
[2022-12-07 09:55:36,162] [INFO] [controller] EPOCH 4 loss ppo:  -0.05772, loss val: 0.04132
[2022-12-07 09:55:36,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:55:36,377] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:55:36,377] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:55:44,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:55:51,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:55:58,656] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:56:05,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:56:12,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:56:21,725] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:56:29,461] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:56:37,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:56:45,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:56:52,604] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7851077715018728
[2022-12-07 09:56:52,604] [INFO] [runner_train_mujoco] Average state value: 0.5308368271191914
[2022-12-07 09:56:52,604] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 09:56:52,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04023
[2022-12-07 09:56:52,689] [INFO] [controller] EPOCH 2 loss ppo:  -0.02446, loss val: 0.04323
[2022-12-07 09:56:52,732] [INFO] [controller] EPOCH 3 loss ppo:  -0.03888, loss val: 0.04282
[2022-12-07 09:56:52,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.05115, loss val: 0.03989
[2022-12-07 09:56:52,780] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:56:52,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:56:52,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:57:00,562] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:57:07,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:57:14,832] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:57:21,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:57:28,935] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:57:35,788] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:57:42,870] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:57:50,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:57:57,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:58:04,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.829928945946497
[2022-12-07 09:58:04,173] [INFO] [runner_train_mujoco] Average state value: 0.5433454598585764
[2022-12-07 09:58:04,173] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 09:58:04,223] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04813
[2022-12-07 09:58:04,266] [INFO] [controller] EPOCH 2 loss ppo:  -0.02297, loss val: 0.04822
[2022-12-07 09:58:04,309] [INFO] [controller] EPOCH 3 loss ppo:  -0.03713, loss val: 0.04890
[2022-12-07 09:58:04,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.04985, loss val: 0.04878
[2022-12-07 09:58:04,359] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:58:04,564] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:58:04,564] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:58:11,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:58:18,862] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:58:25,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:58:32,524] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:58:39,367] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:58:46,227] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:58:53,353] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:59:00,331] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:59:07,234] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:59:14,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.750603468318014
[2022-12-07 09:59:14,005] [INFO] [runner_train_mujoco] Average state value: 0.532301977833112
[2022-12-07 09:59:14,005] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 09:59:14,060] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.03445
[2022-12-07 09:59:14,103] [INFO] [controller] EPOCH 2 loss ppo:  -0.02267, loss val: 0.03281
[2022-12-07 09:59:14,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.03782, loss val: 0.03243
[2022-12-07 09:59:14,185] [INFO] [controller] EPOCH 4 loss ppo:  -0.05056, loss val: 0.03382
[2022-12-07 09:59:14,196] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:59:14,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:59:14,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:59:22,195] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:59:31,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:59:39,433] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:59:46,644] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:59:54,227] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:00:02,335] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:00:10,510] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:00:19,300] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:00:27,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:00:35,504] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.952898954153626
[2022-12-07 10:00:35,504] [INFO] [runner_train_mujoco] Average state value: 0.5317115347385407
[2022-12-07 10:00:35,504] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 10:00:35,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.04391
[2022-12-07 10:00:35,613] [INFO] [controller] EPOCH 2 loss ppo:  -0.01804, loss val: 0.04385
[2022-12-07 10:00:35,656] [INFO] [controller] EPOCH 3 loss ppo:  -0.02915, loss val: 0.04365
[2022-12-07 10:00:35,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.04328, loss val: 0.04430
[2022-12-07 10:00:35,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:00:35,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:00:35,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:00:43,940] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:00:51,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:00:59,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:01:06,897] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:01:14,452] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:01:22,745] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:01:31,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:01:39,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:01:48,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:01:56,442] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9712989008014195
[2022-12-07 10:01:56,442] [INFO] [runner_train_mujoco] Average state value: 0.5300217341581981
[2022-12-07 10:01:56,443] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 10:01:56,496] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.03635
[2022-12-07 10:01:56,540] [INFO] [controller] EPOCH 2 loss ppo:  -0.01992, loss val: 0.03737
[2022-12-07 10:01:56,582] [INFO] [controller] EPOCH 3 loss ppo:  -0.03108, loss val: 0.03641
[2022-12-07 10:01:56,627] [INFO] [controller] EPOCH 4 loss ppo:  -0.04251, loss val: 0.03639
[2022-12-07 10:01:56,637] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:01:56,854] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:01:56,854] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:02:05,548] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:02:14,488] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:02:23,164] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:02:31,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:02:39,509] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:02:47,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:02:56,497] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:03:04,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:03:12,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:03:21,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.832312384926857
[2022-12-07 10:03:21,124] [INFO] [runner_train_mujoco] Average state value: 0.5265428776144983
[2022-12-07 10:03:21,124] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 10:03:21,189] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.04326
[2022-12-07 10:03:21,239] [INFO] [controller] EPOCH 2 loss ppo:  -0.01748, loss val: 0.04260
[2022-12-07 10:03:21,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.02440, loss val: 0.04282
[2022-12-07 10:03:21,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.03273, loss val: 0.04284
[2022-12-07 10:03:21,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:03:21,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:03:21,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:03:30,126] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:03:38,954] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:03:46,994] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:03:55,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:04:04,233] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:04:12,775] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:04:20,606] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:04:28,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:04:36,483] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:04:44,682] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9631618826746142
[2022-12-07 10:04:44,683] [INFO] [runner_train_mujoco] Average state value: 0.5164704433083535
[2022-12-07 10:04:44,683] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 10:04:44,735] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.04224
[2022-12-07 10:04:44,780] [INFO] [controller] EPOCH 2 loss ppo:  -0.01849, loss val: 0.04433
[2022-12-07 10:04:44,826] [INFO] [controller] EPOCH 3 loss ppo:  -0.02603, loss val: 0.04434
[2022-12-07 10:04:44,874] [INFO] [controller] EPOCH 4 loss ppo:  -0.03603, loss val: 0.04414
[2022-12-07 10:04:44,884] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:04:45,083] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:04:45,084] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:04:53,149] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:05:00,625] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:05:08,014] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:05:15,327] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:05:22,773] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:05:30,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:05:38,543] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:05:45,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:05:53,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:06:01,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6316487063184397
[2022-12-07 10:06:01,958] [INFO] [runner_train_mujoco] Average state value: 0.5070139667391776
[2022-12-07 10:06:01,958] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 10:06:02,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.03399
[2022-12-07 10:06:02,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.01583, loss val: 0.03409
[2022-12-07 10:06:02,114] [INFO] [controller] EPOCH 3 loss ppo:  -0.01994, loss val: 0.03514
[2022-12-07 10:06:02,157] [INFO] [controller] EPOCH 4 loss ppo:  -0.02555, loss val: 0.03831
[2022-12-07 10:06:02,167] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:06:02,372] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:06:02,373] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:06:11,178] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:06:19,082] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:06:27,183] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:06:34,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:06:42,658] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:06:50,970] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:06:59,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:07:08,486] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:07:17,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:07:26,938] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.049706465476365
[2022-12-07 10:07:26,939] [INFO] [runner_train_mujoco] Average state value: 0.5152249881823858
[2022-12-07 10:07:26,939] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 10:07:26,998] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.03351
[2022-12-07 10:07:27,048] [INFO] [controller] EPOCH 2 loss ppo:  -0.01563, loss val: 0.03365
[2022-12-07 10:07:27,100] [INFO] [controller] EPOCH 3 loss ppo:  -0.01816, loss val: 0.03349
[2022-12-07 10:07:27,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.02178, loss val: 0.03351
[2022-12-07 10:07:27,194] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:07:27,339] [INFO] [optimize] Finished learning.
