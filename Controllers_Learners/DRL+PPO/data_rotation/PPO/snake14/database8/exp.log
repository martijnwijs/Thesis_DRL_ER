[2022-12-07 06:49:46,699] [INFO] [optimize] Starting learning
[2022-12-07 06:49:46,721] [INFO] [optimize] Starting learning process..
[2022-12-07 06:49:46,887] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:49:46,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:49:57,553] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:50:06,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:50:16,061] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:50:25,127] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:50:35,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:50:44,107] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:50:53,774] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:51:03,113] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:51:12,785] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:51:21,810] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.485620534114911
[2022-12-07 06:51:21,811] [INFO] [runner_train_mujoco] Average state value: -0.14874023515979448
[2022-12-07 06:51:21,811] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 06:51:21,877] [INFO] [controller] EPOCH 1 loss ppo:  -0.01654, loss val: 0.62467
[2022-12-07 06:51:21,926] [INFO] [controller] EPOCH 2 loss ppo:  -0.05418, loss val: 0.56443
[2022-12-07 06:51:21,972] [INFO] [controller] EPOCH 3 loss ppo:  -0.07117, loss val: 0.52884
[2022-12-07 06:51:22,016] [INFO] [controller] EPOCH 4 loss ppo:  -0.08265, loss val: 0.46798
[2022-12-07 06:51:22,026] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:51:22,235] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:51:22,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:51:31,804] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:51:40,673] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:51:50,018] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:52:00,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:52:10,499] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:52:20,701] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:52:30,382] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:52:39,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:52:48,601] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:52:57,708] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3725377745702014
[2022-12-07 06:52:57,708] [INFO] [runner_train_mujoco] Average state value: -0.04863772756326944
[2022-12-07 06:52:57,708] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 06:52:57,786] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.45275
[2022-12-07 06:52:57,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.04975, loss val: 0.39237
[2022-12-07 06:52:57,907] [INFO] [controller] EPOCH 3 loss ppo:  -0.06881, loss val: 0.35454
[2022-12-07 06:52:57,957] [INFO] [controller] EPOCH 4 loss ppo:  -0.08225, loss val: 0.33149
[2022-12-07 06:52:57,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:52:58,181] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:52:58,181] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:53:07,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:53:17,509] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:53:26,476] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:53:35,703] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:53:45,229] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:53:54,628] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:54:03,788] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:54:13,554] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:54:22,578] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:54:31,729] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.497636828275827
[2022-12-07 06:54:31,729] [INFO] [runner_train_mujoco] Average state value: 0.09730587625689804
[2022-12-07 06:54:31,730] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 06:54:31,792] [INFO] [controller] EPOCH 1 loss ppo:  -0.01211, loss val: 0.31480
[2022-12-07 06:54:31,841] [INFO] [controller] EPOCH 2 loss ppo:  -0.05315, loss val: 0.28308
[2022-12-07 06:54:31,897] [INFO] [controller] EPOCH 3 loss ppo:  -0.07336, loss val: 0.26047
[2022-12-07 06:54:31,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.08446, loss val: 0.23114
[2022-12-07 06:54:31,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:54:32,174] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:54:32,174] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:54:41,111] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:54:50,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:55:00,356] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:55:10,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:55:19,557] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:55:29,368] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:55:38,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:55:47,338] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:55:56,592] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:56:05,747] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.600173697952626
[2022-12-07 06:56:05,747] [INFO] [runner_train_mujoco] Average state value: 0.2745238471676906
[2022-12-07 06:56:05,747] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 06:56:05,856] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.17769
[2022-12-07 06:56:05,933] [INFO] [controller] EPOCH 2 loss ppo:  -0.05150, loss val: 0.15765
[2022-12-07 06:56:06,004] [INFO] [controller] EPOCH 3 loss ppo:  -0.07082, loss val: 0.14344
[2022-12-07 06:56:06,072] [INFO] [controller] EPOCH 4 loss ppo:  -0.08352, loss val: 0.13213
[2022-12-07 06:56:06,097] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:56:06,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:56:06,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:56:15,602] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:56:24,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:56:34,139] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:56:43,619] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:56:54,704] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:57:04,376] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:57:13,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:57:22,383] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:57:31,861] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:57:41,559] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5610261567448909
[2022-12-07 06:57:41,560] [INFO] [runner_train_mujoco] Average state value: 0.3638641230203212
[2022-12-07 06:57:41,560] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 06:57:41,616] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.13003
[2022-12-07 06:57:41,669] [INFO] [controller] EPOCH 2 loss ppo:  -0.04961, loss val: 0.11937
[2022-12-07 06:57:41,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.06752, loss val: 0.11135
[2022-12-07 06:57:41,789] [INFO] [controller] EPOCH 4 loss ppo:  -0.08045, loss val: 0.10048
[2022-12-07 06:57:41,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:57:42,019] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:57:42,020] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:57:51,301] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:57:59,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:58:08,859] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:58:18,044] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:58:27,583] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:58:36,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:58:46,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:58:55,033] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:59:04,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:59:13,361] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4957497617750493
[2022-12-07 06:59:13,361] [INFO] [runner_train_mujoco] Average state value: 0.48758846037089826
[2022-12-07 06:59:13,361] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 06:59:13,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.09574
[2022-12-07 06:59:13,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.04934, loss val: 0.09192
[2022-12-07 06:59:13,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.06437, loss val: 0.08621
[2022-12-07 06:59:13,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.07342, loss val: 0.08197
[2022-12-07 06:59:13,562] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:59:13,774] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:59:13,774] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:59:23,075] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:59:32,255] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:59:41,451] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:59:51,062] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:00:00,561] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:00:09,505] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:00:18,581] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:00:27,524] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:00:36,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:00:46,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6204471330132797
[2022-12-07 07:00:46,050] [INFO] [runner_train_mujoco] Average state value: 0.491023746351401
[2022-12-07 07:00:46,050] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 07:00:46,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.14303
[2022-12-07 07:00:46,181] [INFO] [controller] EPOCH 2 loss ppo:  -0.05268, loss val: 0.13966
[2022-12-07 07:00:46,247] [INFO] [controller] EPOCH 3 loss ppo:  -0.06683, loss val: 0.13726
[2022-12-07 07:00:46,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.08079, loss val: 0.13208
[2022-12-07 07:00:46,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:00:46,553] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:00:46,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:00:55,635] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:01:05,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:01:14,479] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:01:23,629] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:01:32,622] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:01:41,877] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:01:50,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:02:00,307] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:02:09,461] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:02:18,400] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5185562700102355
[2022-12-07 07:02:18,400] [INFO] [runner_train_mujoco] Average state value: 0.5403131332099438
[2022-12-07 07:02:18,400] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 07:02:18,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.10910
[2022-12-07 07:02:18,510] [INFO] [controller] EPOCH 2 loss ppo:  -0.05080, loss val: 0.10253
[2022-12-07 07:02:18,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.06800, loss val: 0.09830
[2022-12-07 07:02:18,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.07965, loss val: 0.09450
[2022-12-07 07:02:18,633] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:02:18,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:02:18,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:02:27,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:02:37,007] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:02:46,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:02:55,640] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:03:04,812] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:03:14,087] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:03:23,179] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:03:32,738] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:03:41,988] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:03:50,896] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6478471088069846
[2022-12-07 07:03:50,896] [INFO] [runner_train_mujoco] Average state value: 0.3895954368884365
[2022-12-07 07:03:50,896] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 07:03:50,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01575, loss val: 0.13821
[2022-12-07 07:03:51,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.04691, loss val: 0.12977
[2022-12-07 07:03:51,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.06691, loss val: 0.12305
[2022-12-07 07:03:51,127] [INFO] [controller] EPOCH 4 loss ppo:  -0.08213, loss val: 0.11598
[2022-12-07 07:03:51,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:03:51,356] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:03:51,357] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:03:59,889] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:04:08,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:04:17,738] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:04:27,075] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:04:36,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:04:45,743] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:04:54,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:05:03,340] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:05:12,200] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:05:21,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7909798998760766
[2022-12-07 07:05:21,256] [INFO] [runner_train_mujoco] Average state value: 0.4473952084605893
[2022-12-07 07:05:21,256] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 07:05:21,332] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.07743
[2022-12-07 07:05:21,383] [INFO] [controller] EPOCH 2 loss ppo:  -0.04813, loss val: 0.07356
[2022-12-07 07:05:21,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.06810, loss val: 0.07173
[2022-12-07 07:05:21,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.08342, loss val: 0.07013
[2022-12-07 07:05:21,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:05:21,717] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:05:21,717] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:05:31,043] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:05:40,534] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:05:49,282] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:05:58,255] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:06:07,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:06:16,262] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:06:25,477] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:06:34,870] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:06:44,409] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:06:53,142] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.665743153187492
[2022-12-07 07:06:53,142] [INFO] [runner_train_mujoco] Average state value: 0.36040310439715784
[2022-12-07 07:06:53,142] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 07:06:53,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.09200
[2022-12-07 07:06:53,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.04687, loss val: 0.08710
[2022-12-07 07:06:53,301] [INFO] [controller] EPOCH 3 loss ppo:  -0.06457, loss val: 0.08652
[2022-12-07 07:06:53,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.07956, loss val: 0.08211
[2022-12-07 07:06:53,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:06:53,608] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:06:53,609] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:07:02,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:07:13,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:07:23,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:07:32,756] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:07:42,147] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:07:51,409] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:07:59,857] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:08:08,728] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:08:17,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:08:26,618] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7505124988161274
[2022-12-07 07:08:26,618] [INFO] [runner_train_mujoco] Average state value: 0.4311609104747574
[2022-12-07 07:08:26,618] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 07:08:26,674] [INFO] [controller] EPOCH 1 loss ppo:  -0.01505, loss val: 0.06025
[2022-12-07 07:08:26,724] [INFO] [controller] EPOCH 2 loss ppo:  -0.05080, loss val: 0.05843
[2022-12-07 07:08:26,772] [INFO] [controller] EPOCH 3 loss ppo:  -0.06991, loss val: 0.06187
[2022-12-07 07:08:26,828] [INFO] [controller] EPOCH 4 loss ppo:  -0.08314, loss val: 0.05640
[2022-12-07 07:08:26,839] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:08:27,070] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:08:27,071] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:08:36,364] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:08:45,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:08:54,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:09:03,325] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:09:11,288] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:09:19,385] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:09:27,323] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:09:35,532] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:09:43,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:09:51,362] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5948480449268774
[2022-12-07 07:09:51,362] [INFO] [runner_train_mujoco] Average state value: 0.4271973306114475
[2022-12-07 07:09:51,363] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 07:09:51,419] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.06997
[2022-12-07 07:09:51,457] [INFO] [controller] EPOCH 2 loss ppo:  -0.05047, loss val: 0.06839
[2022-12-07 07:09:51,496] [INFO] [controller] EPOCH 3 loss ppo:  -0.06897, loss val: 0.06778
[2022-12-07 07:09:51,546] [INFO] [controller] EPOCH 4 loss ppo:  -0.08487, loss val: 0.06360
[2022-12-07 07:09:51,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:09:51,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:09:51,763] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:09:59,998] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:10:08,042] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:10:16,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:10:24,689] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:10:33,465] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:10:41,331] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:10:49,807] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:10:57,792] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:11:05,910] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:11:14,308] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4848943884572177
[2022-12-07 07:11:14,309] [INFO] [runner_train_mujoco] Average state value: 0.48458252581954
[2022-12-07 07:11:14,309] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 07:11:14,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.06051
[2022-12-07 07:11:14,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.04605, loss val: 0.05870
[2022-12-07 07:11:14,459] [INFO] [controller] EPOCH 3 loss ppo:  -0.06678, loss val: 0.05719
[2022-12-07 07:11:14,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.08207, loss val: 0.05522
[2022-12-07 07:11:14,512] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:11:14,714] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:11:14,714] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:11:22,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:11:30,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:11:39,389] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:11:47,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:11:56,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:12:04,658] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:12:12,391] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:12:20,249] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:12:28,590] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:12:36,358] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7638399161737426
[2022-12-07 07:12:36,358] [INFO] [runner_train_mujoco] Average state value: 0.5116156440898777
[2022-12-07 07:12:36,358] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 07:12:36,462] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.05409
[2022-12-07 07:12:36,519] [INFO] [controller] EPOCH 2 loss ppo:  -0.05024, loss val: 0.05106
[2022-12-07 07:12:36,564] [INFO] [controller] EPOCH 3 loss ppo:  -0.07224, loss val: 0.05275
[2022-12-07 07:12:36,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.08480, loss val: 0.04926
[2022-12-07 07:12:36,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:12:36,826] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:12:36,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:12:45,637] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:12:54,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:13:02,204] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:13:10,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:13:18,347] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:13:26,844] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:13:35,190] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:13:43,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:13:51,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:13:59,879] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.980641523527345
[2022-12-07 07:13:59,879] [INFO] [runner_train_mujoco] Average state value: 0.5354581611603498
[2022-12-07 07:13:59,880] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 07:13:59,937] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.05564
[2022-12-07 07:13:59,978] [INFO] [controller] EPOCH 2 loss ppo:  -0.04879, loss val: 0.05468
[2022-12-07 07:14:00,039] [INFO] [controller] EPOCH 3 loss ppo:  -0.06736, loss val: 0.05345
[2022-12-07 07:14:00,089] [INFO] [controller] EPOCH 4 loss ppo:  -0.07785, loss val: 0.05498
[2022-12-07 07:14:00,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:14:00,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:14:00,311] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:14:08,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:14:16,659] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:14:24,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:14:32,669] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:14:40,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:14:49,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:14:57,568] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:15:05,759] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:15:13,625] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:15:21,871] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7107514200432679
[2022-12-07 07:15:21,872] [INFO] [runner_train_mujoco] Average state value: 0.5592717632402977
[2022-12-07 07:15:21,872] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 07:15:21,921] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.05757
[2022-12-07 07:15:21,960] [INFO] [controller] EPOCH 2 loss ppo:  -0.04949, loss val: 0.05508
[2022-12-07 07:15:22,004] [INFO] [controller] EPOCH 3 loss ppo:  -0.06970, loss val: 0.05407
[2022-12-07 07:15:22,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.08419, loss val: 0.05242
[2022-12-07 07:15:22,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:15:22,280] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:15:22,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:15:30,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:15:39,251] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:15:47,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:15:56,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:16:03,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:16:11,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:16:20,434] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:16:28,286] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:16:36,371] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:16:44,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5874476010065104
[2022-12-07 07:16:44,640] [INFO] [runner_train_mujoco] Average state value: 0.5834440227746963
[2022-12-07 07:16:44,641] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 07:16:44,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04971
[2022-12-07 07:16:44,744] [INFO] [controller] EPOCH 2 loss ppo:  -0.03993, loss val: 0.04869
[2022-12-07 07:16:44,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.05833, loss val: 0.05001
[2022-12-07 07:16:44,841] [INFO] [controller] EPOCH 4 loss ppo:  -0.07295, loss val: 0.04426
[2022-12-07 07:16:44,850] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:16:45,066] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:16:45,067] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:16:53,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:17:01,785] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:17:10,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:17:18,257] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:17:25,992] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:17:34,224] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:17:42,401] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:17:50,786] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:17:59,699] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:18:08,531] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6533711234960524
[2022-12-07 07:18:08,531] [INFO] [runner_train_mujoco] Average state value: 0.5387024845381577
[2022-12-07 07:18:08,531] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 07:18:08,582] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.05211
[2022-12-07 07:18:08,624] [INFO] [controller] EPOCH 2 loss ppo:  -0.04671, loss val: 0.05271
[2022-12-07 07:18:08,668] [INFO] [controller] EPOCH 3 loss ppo:  -0.07092, loss val: 0.05513
[2022-12-07 07:18:08,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.08588, loss val: 0.05499
[2022-12-07 07:18:08,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:18:08,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:18:08,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:18:17,361] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:18:25,596] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:18:33,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:18:41,957] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:18:50,420] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:18:58,428] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:19:06,189] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:19:14,309] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:19:22,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:19:30,924] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5103307039200589
[2022-12-07 07:19:30,924] [INFO] [runner_train_mujoco] Average state value: 0.5253565103511015
[2022-12-07 07:19:30,924] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 07:19:30,987] [INFO] [controller] EPOCH 1 loss ppo:  -0.01236, loss val: 0.03808
[2022-12-07 07:19:31,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.04321, loss val: 0.04065
[2022-12-07 07:19:31,069] [INFO] [controller] EPOCH 3 loss ppo:  -0.06576, loss val: 0.03970
[2022-12-07 07:19:31,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.07910, loss val: 0.03718
[2022-12-07 07:19:31,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:19:31,321] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:19:31,321] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:19:39,450] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:19:48,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:19:56,378] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:20:04,438] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:20:12,261] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:20:20,447] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:20:28,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:20:37,168] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:20:45,503] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:20:53,868] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.625449427610419
[2022-12-07 07:20:53,868] [INFO] [runner_train_mujoco] Average state value: 0.5512171752154827
[2022-12-07 07:20:53,868] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 07:20:53,922] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.04382
[2022-12-07 07:20:53,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.03922, loss val: 0.04107
[2022-12-07 07:20:54,009] [INFO] [controller] EPOCH 3 loss ppo:  -0.05792, loss val: 0.03817
[2022-12-07 07:20:54,052] [INFO] [controller] EPOCH 4 loss ppo:  -0.07033, loss val: 0.03500
[2022-12-07 07:20:54,061] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:20:54,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:20:54,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:21:02,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:21:11,444] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:21:19,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:21:27,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:21:35,966] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:21:44,541] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:21:52,414] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:22:00,305] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:22:08,507] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:22:17,063] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7548624252574871
[2022-12-07 07:22:17,063] [INFO] [runner_train_mujoco] Average state value: 0.6164228207767009
[2022-12-07 07:22:17,063] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 07:22:17,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.06656
[2022-12-07 07:22:17,161] [INFO] [controller] EPOCH 2 loss ppo:  -0.03825, loss val: 0.06368
[2022-12-07 07:22:17,196] [INFO] [controller] EPOCH 3 loss ppo:  -0.05823, loss val: 0.06447
[2022-12-07 07:22:17,241] [INFO] [controller] EPOCH 4 loss ppo:  -0.07480, loss val: 0.06231
[2022-12-07 07:22:17,254] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:22:17,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:22:17,480] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:22:25,983] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:22:34,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:22:42,520] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:22:50,614] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:22:58,933] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:23:07,121] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:23:15,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:23:23,024] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:23:30,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:23:39,313] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4407633354594502
[2022-12-07 07:23:39,314] [INFO] [runner_train_mujoco] Average state value: 0.602995863387982
[2022-12-07 07:23:39,314] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 07:23:39,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01201, loss val: 0.06363
[2022-12-07 07:23:39,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.04056, loss val: 0.06006
[2022-12-07 07:23:39,466] [INFO] [controller] EPOCH 3 loss ppo:  -0.06233, loss val: 0.05601
[2022-12-07 07:23:39,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.07772, loss val: 0.04905
[2022-12-07 07:23:39,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:23:39,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:23:39,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:23:48,066] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:23:56,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:24:04,859] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:24:13,249] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:24:21,595] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:24:29,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:37,853] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:24:45,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:24:53,419] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:25:01,497] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6699199147553518
[2022-12-07 07:25:01,498] [INFO] [runner_train_mujoco] Average state value: 0.5050577979485195
[2022-12-07 07:25:01,498] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 07:25:01,546] [INFO] [controller] EPOCH 1 loss ppo:  -0.01614, loss val: 0.03931
[2022-12-07 07:25:01,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.04967, loss val: 0.04223
[2022-12-07 07:25:01,642] [INFO] [controller] EPOCH 3 loss ppo:  -0.06923, loss val: 0.03616
[2022-12-07 07:25:01,682] [INFO] [controller] EPOCH 4 loss ppo:  -0.08273, loss val: 0.03565
[2022-12-07 07:25:01,690] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:25:01,885] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:25:01,885] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:25:10,412] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:25:19,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:25:27,067] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:25:34,826] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:25:42,653] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:25:51,077] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:25:59,502] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:26:07,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:26:15,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:26:23,217] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8304793521096283
[2022-12-07 07:26:23,217] [INFO] [runner_train_mujoco] Average state value: 0.4659651058912277
[2022-12-07 07:26:23,217] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 07:26:23,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.04971
[2022-12-07 07:26:23,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.04469, loss val: 0.04836
[2022-12-07 07:26:23,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.06487, loss val: 0.04435
[2022-12-07 07:26:23,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.07852, loss val: 0.04171
[2022-12-07 07:26:23,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:26:23,715] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:26:23,715] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:26:32,031] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:26:40,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:26:49,338] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:26:57,498] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:27:05,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:27:13,811] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:27:22,449] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:27:30,469] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:27:38,517] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:27:46,511] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4181721796654982
[2022-12-07 07:27:46,511] [INFO] [runner_train_mujoco] Average state value: 0.5164359858234724
[2022-12-07 07:27:46,511] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 07:27:46,610] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.04509
[2022-12-07 07:27:46,654] [INFO] [controller] EPOCH 2 loss ppo:  -0.04739, loss val: 0.04264
[2022-12-07 07:27:46,700] [INFO] [controller] EPOCH 3 loss ppo:  -0.07033, loss val: 0.04227
[2022-12-07 07:27:46,744] [INFO] [controller] EPOCH 4 loss ppo:  -0.08755, loss val: 0.04081
[2022-12-07 07:27:46,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:27:46,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:27:46,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:27:55,620] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:28:04,098] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:28:12,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:28:20,523] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:28:28,383] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:28:36,336] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:28:44,324] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:28:52,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:29:01,001] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:29:09,664] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8377324850605963
[2022-12-07 07:29:09,664] [INFO] [runner_train_mujoco] Average state value: 0.5620393995046615
[2022-12-07 07:29:09,664] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 07:29:09,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.03771
[2022-12-07 07:29:09,767] [INFO] [controller] EPOCH 2 loss ppo:  -0.04654, loss val: 0.04111
[2022-12-07 07:29:09,812] [INFO] [controller] EPOCH 3 loss ppo:  -0.06581, loss val: 0.03833
[2022-12-07 07:29:09,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.08021, loss val: 0.03895
[2022-12-07 07:29:09,871] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:29:10,085] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:29:10,086] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:29:18,449] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:29:26,472] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:29:34,766] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:29:42,844] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:29:51,155] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:29:59,086] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:30:07,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:30:14,932] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:30:23,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:30:31,359] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6478563765115564
[2022-12-07 07:30:31,359] [INFO] [runner_train_mujoco] Average state value: 0.5855783284107844
[2022-12-07 07:30:31,359] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 07:30:31,418] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.05132
[2022-12-07 07:30:31,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.04133, loss val: 0.05114
[2022-12-07 07:30:31,505] [INFO] [controller] EPOCH 3 loss ppo:  -0.05959, loss val: 0.04992
[2022-12-07 07:30:31,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.07309, loss val: 0.04848
[2022-12-07 07:30:31,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:30:31,783] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:30:31,783] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:30:40,293] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:30:48,931] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:30:56,885] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:31:05,334] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:31:13,261] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:31:21,384] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:31:29,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:31:39,927] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:31:48,500] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:31:56,569] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8028797718611187
[2022-12-07 07:31:56,570] [INFO] [runner_train_mujoco] Average state value: 0.5528666204611461
[2022-12-07 07:31:56,570] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 07:31:56,632] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.04473
[2022-12-07 07:31:56,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.03989, loss val: 0.04315
[2022-12-07 07:31:56,727] [INFO] [controller] EPOCH 3 loss ppo:  -0.06442, loss val: 0.04219
[2022-12-07 07:31:56,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.08048, loss val: 0.04030
[2022-12-07 07:31:56,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:31:56,986] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:31:56,986] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:32:05,407] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:32:13,387] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:32:21,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:32:28,649] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:32:36,572] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:32:44,546] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:32:52,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:33:01,410] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:33:10,356] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:33:18,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.837888497617702
[2022-12-07 07:33:18,521] [INFO] [runner_train_mujoco] Average state value: 0.504731312473615
[2022-12-07 07:33:18,521] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 07:33:18,581] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.03595
[2022-12-07 07:33:18,628] [INFO] [controller] EPOCH 2 loss ppo:  -0.04016, loss val: 0.03510
[2022-12-07 07:33:18,673] [INFO] [controller] EPOCH 3 loss ppo:  -0.05988, loss val: 0.03712
[2022-12-07 07:33:18,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.07315, loss val: 0.03462
[2022-12-07 07:33:18,723] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:33:18,932] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:33:18,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:33:26,667] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:33:34,941] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:33:43,074] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:33:50,977] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:33:58,597] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:34:05,997] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:34:13,708] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:34:22,283] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:34:31,001] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:34:39,383] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6937088681771642
[2022-12-07 07:34:39,383] [INFO] [runner_train_mujoco] Average state value: 0.49558176176746693
[2022-12-07 07:34:39,383] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 07:34:39,439] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.03529
[2022-12-07 07:34:39,483] [INFO] [controller] EPOCH 2 loss ppo:  -0.03975, loss val: 0.03859
[2022-12-07 07:34:39,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.05930, loss val: 0.03272
[2022-12-07 07:34:39,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.07631, loss val: 0.03172
[2022-12-07 07:34:39,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:34:39,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:34:39,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:34:47,618] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:34:55,340] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:35:03,351] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:35:11,554] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:35:19,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:35:27,292] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:35:34,895] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:35:42,783] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:35:50,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:35:59,303] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.957325556968422
[2022-12-07 07:35:59,303] [INFO] [runner_train_mujoco] Average state value: 0.5374279243350029
[2022-12-07 07:35:59,303] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 07:35:59,355] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.03555
[2022-12-07 07:35:59,411] [INFO] [controller] EPOCH 2 loss ppo:  -0.04495, loss val: 0.03416
[2022-12-07 07:35:59,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.06792, loss val: 0.03266
[2022-12-07 07:35:59,497] [INFO] [controller] EPOCH 4 loss ppo:  -0.08414, loss val: 0.03359
[2022-12-07 07:35:59,507] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:35:59,707] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:35:59,708] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:36:08,057] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:36:15,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:36:23,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:36:31,638] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:36:39,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:36:47,286] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:36:55,149] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:37:03,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:37:12,000] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:37:22,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.887545676335937
[2022-12-07 07:37:22,077] [INFO] [runner_train_mujoco] Average state value: 0.5785463405251503
[2022-12-07 07:37:22,077] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 07:37:22,134] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.03549
[2022-12-07 07:37:22,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.04131, loss val: 0.03714
[2022-12-07 07:37:22,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.06047, loss val: 0.03489
[2022-12-07 07:37:22,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.07689, loss val: 0.03783
[2022-12-07 07:37:22,281] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:37:22,489] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:37:22,490] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:37:30,642] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:37:38,498] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:37:46,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:37:53,940] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:38:01,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:38:09,887] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:38:17,766] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:38:25,728] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:38:33,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:38:41,615] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8641849106206938
[2022-12-07 07:38:41,616] [INFO] [runner_train_mujoco] Average state value: 0.57847458811601
[2022-12-07 07:38:41,616] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 07:38:41,673] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04137
[2022-12-07 07:38:41,717] [INFO] [controller] EPOCH 2 loss ppo:  -0.04031, loss val: 0.04094
[2022-12-07 07:38:41,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.06208, loss val: 0.04055
[2022-12-07 07:38:41,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.07976, loss val: 0.04132
[2022-12-07 07:38:41,812] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:38:42,021] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:38:42,021] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:38:50,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:38:58,776] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:39:06,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:39:14,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:39:21,739] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:39:29,417] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:39:37,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:39:45,793] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:39:54,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:40:02,861] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9184401137409295
[2022-12-07 07:40:02,862] [INFO] [runner_train_mujoco] Average state value: 0.5617323770721753
[2022-12-07 07:40:02,862] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 07:40:02,912] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.03864
[2022-12-07 07:40:02,956] [INFO] [controller] EPOCH 2 loss ppo:  -0.03968, loss val: 0.03946
[2022-12-07 07:40:02,997] [INFO] [controller] EPOCH 3 loss ppo:  -0.05877, loss val: 0.03956
[2022-12-07 07:40:03,035] [INFO] [controller] EPOCH 4 loss ppo:  -0.07741, loss val: 0.03949
[2022-12-07 07:40:03,044] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:40:03,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:40:03,247] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:40:11,203] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:40:18,906] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:40:26,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:40:34,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:40:42,763] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:40:50,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:40:58,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:41:07,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:41:15,303] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:41:23,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9986225372026933
[2022-12-07 07:41:23,171] [INFO] [runner_train_mujoco] Average state value: 0.5394159451325734
[2022-12-07 07:41:23,171] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 07:41:23,224] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.03868
[2022-12-07 07:41:23,265] [INFO] [controller] EPOCH 2 loss ppo:  -0.03576, loss val: 0.03862
[2022-12-07 07:41:23,306] [INFO] [controller] EPOCH 3 loss ppo:  -0.05650, loss val: 0.03937
[2022-12-07 07:41:23,349] [INFO] [controller] EPOCH 4 loss ppo:  -0.07291, loss val: 0.03986
[2022-12-07 07:41:23,359] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:41:23,563] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:41:23,564] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:41:31,402] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:41:40,003] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:41:48,026] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:41:55,839] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:42:03,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:42:11,631] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:42:19,537] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:42:28,225] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:42:36,723] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:42:45,038] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.724953771485287
[2022-12-07 07:42:45,038] [INFO] [runner_train_mujoco] Average state value: 0.5291380430459977
[2022-12-07 07:42:45,038] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 07:42:45,155] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.03455
[2022-12-07 07:42:45,199] [INFO] [controller] EPOCH 2 loss ppo:  -0.03608, loss val: 0.03409
[2022-12-07 07:42:45,240] [INFO] [controller] EPOCH 3 loss ppo:  -0.05741, loss val: 0.03512
[2022-12-07 07:42:45,284] [INFO] [controller] EPOCH 4 loss ppo:  -0.07365, loss val: 0.03431
[2022-12-07 07:42:45,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:42:45,498] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:42:45,499] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:42:53,216] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:43:01,218] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:43:08,852] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:43:16,928] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:43:25,970] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:43:33,568] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:43:41,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:43:48,899] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:43:56,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:44:03,351] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6288478330174623
[2022-12-07 07:44:03,351] [INFO] [runner_train_mujoco] Average state value: 0.5479628421068192
[2022-12-07 07:44:03,351] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 07:44:03,400] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.03789
[2022-12-07 07:44:03,434] [INFO] [controller] EPOCH 2 loss ppo:  -0.03897, loss val: 0.04243
[2022-12-07 07:44:03,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.06055, loss val: 0.03547
[2022-12-07 07:44:03,508] [INFO] [controller] EPOCH 4 loss ppo:  -0.07673, loss val: 0.03671
[2022-12-07 07:44:03,517] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:44:03,721] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:44:03,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:44:11,189] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:44:18,661] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:44:25,404] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:44:32,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:44:38,870] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:44:45,874] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:44:53,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:45:00,345] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:45:07,167] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:45:13,704] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.869993806390782
[2022-12-07 07:45:13,704] [INFO] [runner_train_mujoco] Average state value: 0.5698366459012032
[2022-12-07 07:45:13,704] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 07:45:13,750] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.03901
[2022-12-07 07:45:13,784] [INFO] [controller] EPOCH 2 loss ppo:  -0.03357, loss val: 0.03752
[2022-12-07 07:45:13,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.05352, loss val: 0.03947
[2022-12-07 07:45:13,856] [INFO] [controller] EPOCH 4 loss ppo:  -0.06956, loss val: 0.03711
[2022-12-07 07:45:13,865] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:45:14,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:45:14,032] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:45:20,538] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:45:26,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:45:33,161] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:45:39,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:45:45,752] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:45:52,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:45:59,623] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:46:06,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:46:12,995] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:46:19,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9779108599628703
[2022-12-07 07:46:19,341] [INFO] [runner_train_mujoco] Average state value: 0.5604999572932721
[2022-12-07 07:46:19,341] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 07:46:19,386] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.03879
[2022-12-07 07:46:19,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.03783, loss val: 0.03978
[2022-12-07 07:46:19,459] [INFO] [controller] EPOCH 3 loss ppo:  -0.06044, loss val: 0.03834
[2022-12-07 07:46:19,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.07392, loss val: 0.03825
[2022-12-07 07:46:19,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:46:19,705] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:46:19,706] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:46:26,152] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:46:32,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:46:39,021] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:46:45,536] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:46:51,919] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:46:58,820] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:47:05,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:47:12,307] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:47:18,540] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:47:24,940] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8419163013633078
[2022-12-07 07:47:24,940] [INFO] [runner_train_mujoco] Average state value: 0.5512465807596842
[2022-12-07 07:47:24,940] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 07:47:24,984] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.03771
[2022-12-07 07:47:25,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.03441, loss val: 0.03814
[2022-12-07 07:47:25,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.05375, loss val: 0.03670
[2022-12-07 07:47:25,103] [INFO] [controller] EPOCH 4 loss ppo:  -0.06909, loss val: 0.03645
[2022-12-07 07:47:25,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:47:25,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:47:25,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:47:31,747] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:47:38,389] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:47:44,771] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:47:51,213] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:47:57,495] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:48:04,541] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:48:11,126] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:48:17,785] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:48:24,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:48:30,500] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7944879369923967
[2022-12-07 07:48:30,501] [INFO] [runner_train_mujoco] Average state value: 0.5415335399111113
[2022-12-07 07:48:30,501] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 07:48:30,543] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.04490
[2022-12-07 07:48:30,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.03737, loss val: 0.04607
[2022-12-07 07:48:30,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.05762, loss val: 0.04520
[2022-12-07 07:48:30,658] [INFO] [controller] EPOCH 4 loss ppo:  -0.07462, loss val: 0.04410
[2022-12-07 07:48:30,667] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:48:30,845] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:48:30,845] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:48:37,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:48:43,885] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:48:50,692] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:48:57,078] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:49:03,907] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:49:12,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:49:19,978] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:49:27,527] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:49:34,710] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:49:41,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8817909434217728
[2022-12-07 07:49:41,832] [INFO] [runner_train_mujoco] Average state value: 0.5238686374823252
[2022-12-07 07:49:41,832] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 07:49:41,884] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.04471
[2022-12-07 07:49:41,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.03179, loss val: 0.04377
[2022-12-07 07:49:41,971] [INFO] [controller] EPOCH 3 loss ppo:  -0.05346, loss val: 0.04675
[2022-12-07 07:49:42,017] [INFO] [controller] EPOCH 4 loss ppo:  -0.06954, loss val: 0.04470
[2022-12-07 07:49:42,024] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:49:42,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:49:42,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:49:49,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:49:57,266] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:50:04,769] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:50:11,941] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:50:19,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:50:26,195] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:50:33,680] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:50:41,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:50:48,266] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:50:55,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.803799345131237
[2022-12-07 07:50:55,784] [INFO] [runner_train_mujoco] Average state value: 0.5134522748788198
[2022-12-07 07:50:55,784] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 07:50:55,838] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.03576
[2022-12-07 07:50:55,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.03382, loss val: 0.03579
[2022-12-07 07:50:55,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.05020, loss val: 0.03581
[2022-12-07 07:50:55,966] [INFO] [controller] EPOCH 4 loss ppo:  -0.06376, loss val: 0.03562
[2022-12-07 07:50:55,976] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:50:56,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:50:56,184] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:51:03,624] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:51:11,105] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:51:18,102] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:51:25,314] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:51:32,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:51:40,290] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:51:47,533] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:51:54,586] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:52:01,836] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:52:09,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9259731728882605
[2022-12-07 07:52:09,124] [INFO] [runner_train_mujoco] Average state value: 0.5189233762423198
[2022-12-07 07:52:09,124] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 07:52:09,172] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.03901
[2022-12-07 07:52:09,214] [INFO] [controller] EPOCH 2 loss ppo:  -0.03141, loss val: 0.04084
[2022-12-07 07:52:09,257] [INFO] [controller] EPOCH 3 loss ppo:  -0.05144, loss val: 0.03788
[2022-12-07 07:52:09,299] [INFO] [controller] EPOCH 4 loss ppo:  -0.06420, loss val: 0.03725
[2022-12-07 07:52:09,308] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:52:09,512] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:52:09,512] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:52:16,476] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:52:23,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:52:30,833] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:52:38,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:52:45,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:52:52,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:53:00,389] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:53:07,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:53:14,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:53:21,770] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7507364755002572
[2022-12-07 07:53:21,770] [INFO] [runner_train_mujoco] Average state value: 0.5278513744870822
[2022-12-07 07:53:21,771] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 07:53:21,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.04173
[2022-12-07 07:53:21,873] [INFO] [controller] EPOCH 2 loss ppo:  -0.02854, loss val: 0.04003
[2022-12-07 07:53:21,919] [INFO] [controller] EPOCH 3 loss ppo:  -0.04862, loss val: 0.03940
[2022-12-07 07:53:21,957] [INFO] [controller] EPOCH 4 loss ppo:  -0.06291, loss val: 0.03966
[2022-12-07 07:53:21,964] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:53:22,150] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:53:22,151] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:53:29,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:53:36,831] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:53:43,820] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:53:51,330] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:53:59,159] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:54:06,978] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:54:14,462] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:54:21,642] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:54:28,650] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:54:35,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7675333990473532
[2022-12-07 07:54:35,468] [INFO] [runner_train_mujoco] Average state value: 0.5493775955239932
[2022-12-07 07:54:35,468] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 07:54:35,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.04674
[2022-12-07 07:54:35,560] [INFO] [controller] EPOCH 2 loss ppo:  -0.02701, loss val: 0.04620
[2022-12-07 07:54:35,603] [INFO] [controller] EPOCH 3 loss ppo:  -0.04446, loss val: 0.04678
[2022-12-07 07:54:35,644] [INFO] [controller] EPOCH 4 loss ppo:  -0.05885, loss val: 0.04695
[2022-12-07 07:54:35,653] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:54:35,861] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:54:35,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:54:42,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:54:50,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:54:57,353] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:55:05,090] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:55:12,758] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:55:19,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:55:27,206] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:55:34,069] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:55:41,239] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:55:48,547] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8474451810637678
[2022-12-07 07:55:48,547] [INFO] [runner_train_mujoco] Average state value: 0.5515315385659536
[2022-12-07 07:55:48,547] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 07:55:48,646] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.04518
[2022-12-07 07:55:48,691] [INFO] [controller] EPOCH 2 loss ppo:  -0.02671, loss val: 0.04444
[2022-12-07 07:55:48,733] [INFO] [controller] EPOCH 3 loss ppo:  -0.04333, loss val: 0.04455
[2022-12-07 07:55:48,775] [INFO] [controller] EPOCH 4 loss ppo:  -0.05677, loss val: 0.04387
[2022-12-07 07:55:48,785] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:55:48,987] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:55:48,987] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:55:55,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:56:03,513] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:56:10,655] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:56:17,731] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:56:25,044] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:56:32,458] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:56:39,688] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:56:46,955] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:56:54,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:57:01,630] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7293213267198808
[2022-12-07 07:57:01,630] [INFO] [runner_train_mujoco] Average state value: 0.5351169343590736
[2022-12-07 07:57:01,630] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 07:57:01,679] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04030
[2022-12-07 07:57:01,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.02628, loss val: 0.04316
[2022-12-07 07:57:01,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.04384, loss val: 0.04127
[2022-12-07 07:57:01,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.05784, loss val: 0.04034
[2022-12-07 07:57:01,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:57:02,014] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:57:02,014] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:57:09,305] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:57:16,636] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:57:24,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:57:31,503] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:57:38,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:57:46,506] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:57:54,146] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:58:01,153] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:58:08,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:58:15,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8222433032295633
[2022-12-07 07:58:15,054] [INFO] [runner_train_mujoco] Average state value: 0.5274953934550285
[2022-12-07 07:58:15,054] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 07:58:15,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.03718
[2022-12-07 07:58:15,152] [INFO] [controller] EPOCH 2 loss ppo:  -0.02677, loss val: 0.03715
[2022-12-07 07:58:15,196] [INFO] [controller] EPOCH 3 loss ppo:  -0.04374, loss val: 0.03669
[2022-12-07 07:58:15,238] [INFO] [controller] EPOCH 4 loss ppo:  -0.05624, loss val: 0.03758
[2022-12-07 07:58:15,248] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:58:15,448] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:58:15,448] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:58:23,335] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:58:30,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:58:38,068] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:58:45,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:58:52,635] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:58:59,806] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:59:07,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:59:14,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:59:21,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:59:28,750] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8336386886730593
[2022-12-07 07:59:28,750] [INFO] [runner_train_mujoco] Average state value: 0.5340646589100361
[2022-12-07 07:59:28,750] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 07:59:28,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.03597
[2022-12-07 07:59:28,838] [INFO] [controller] EPOCH 2 loss ppo:  -0.02467, loss val: 0.03522
[2022-12-07 07:59:28,880] [INFO] [controller] EPOCH 3 loss ppo:  -0.04049, loss val: 0.03503
[2022-12-07 07:59:28,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.05496, loss val: 0.03457
[2022-12-07 07:59:28,931] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:59:29,129] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:59:29,129] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:59:36,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:59:44,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:59:51,971] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:59:59,245] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:00:06,735] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:00:14,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:00:21,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:00:28,842] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:00:36,447] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:00:44,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.867893765774578
[2022-12-07 08:00:44,042] [INFO] [runner_train_mujoco] Average state value: 0.5422280763387679
[2022-12-07 08:00:44,042] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 08:00:44,092] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03741
[2022-12-07 08:00:44,135] [INFO] [controller] EPOCH 2 loss ppo:  -0.02500, loss val: 0.03604
[2022-12-07 08:00:44,177] [INFO] [controller] EPOCH 3 loss ppo:  -0.04173, loss val: 0.03761
[2022-12-07 08:00:44,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.05568, loss val: 0.03546
[2022-12-07 08:00:44,229] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:00:44,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:00:44,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:00:51,930] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:00:59,524] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:01:06,750] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:01:14,156] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:01:21,746] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:01:29,202] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:01:36,184] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:01:43,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:01:50,942] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:01:57,932] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.041648807924524
[2022-12-07 08:01:57,933] [INFO] [runner_train_mujoco] Average state value: 0.5555074024001758
[2022-12-07 08:01:57,933] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 08:01:58,002] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.03884
[2022-12-07 08:01:58,043] [INFO] [controller] EPOCH 2 loss ppo:  -0.02089, loss val: 0.03679
[2022-12-07 08:01:58,084] [INFO] [controller] EPOCH 3 loss ppo:  -0.03398, loss val: 0.03624
[2022-12-07 08:01:58,125] [INFO] [controller] EPOCH 4 loss ppo:  -0.04705, loss val: 0.03618
[2022-12-07 08:01:58,134] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:01:58,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:01:58,331] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:02:05,899] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:02:13,322] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:02:20,587] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:02:28,204] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:02:35,513] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:02:42,941] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:02:50,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:02:57,243] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:03:04,491] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:03:11,598] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8475223550221074
[2022-12-07 08:03:11,598] [INFO] [runner_train_mujoco] Average state value: 0.5556845018068949
[2022-12-07 08:03:11,599] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 08:03:11,653] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.03892
[2022-12-07 08:03:11,695] [INFO] [controller] EPOCH 2 loss ppo:  -0.02220, loss val: 0.03895
[2022-12-07 08:03:11,737] [INFO] [controller] EPOCH 3 loss ppo:  -0.03488, loss val: 0.03872
[2022-12-07 08:03:11,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.04714, loss val: 0.03864
[2022-12-07 08:03:11,788] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:03:11,999] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:03:12,000] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:03:19,623] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:03:27,241] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:03:34,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:03:42,167] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:03:49,914] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:03:57,700] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:04:04,830] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:04:11,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:04:19,227] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:04:26,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9575989350069556
[2022-12-07 08:04:26,886] [INFO] [runner_train_mujoco] Average state value: 0.5516442510883014
[2022-12-07 08:04:26,886] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 08:04:26,934] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04329
[2022-12-07 08:04:26,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.01733, loss val: 0.04328
[2022-12-07 08:04:27,018] [INFO] [controller] EPOCH 3 loss ppo:  -0.02607, loss val: 0.04387
[2022-12-07 08:04:27,061] [INFO] [controller] EPOCH 4 loss ppo:  -0.03653, loss val: 0.04309
[2022-12-07 08:04:27,070] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:04:27,271] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:04:27,271] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:04:34,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:04:41,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:04:49,147] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:04:56,065] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:05:03,310] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:05:10,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:05:17,697] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:05:25,026] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:05:32,052] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:05:39,208] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9752178754809038
[2022-12-07 08:05:39,209] [INFO] [runner_train_mujoco] Average state value: 0.5390896268288294
[2022-12-07 08:05:39,209] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 08:05:39,253] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.04318
[2022-12-07 08:05:39,290] [INFO] [controller] EPOCH 2 loss ppo:  -0.01840, loss val: 0.04147
[2022-12-07 08:05:39,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.02620, loss val: 0.04274
[2022-12-07 08:05:39,371] [INFO] [controller] EPOCH 4 loss ppo:  -0.03621, loss val: 0.04158
[2022-12-07 08:05:39,379] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:05:39,556] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:05:39,556] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:05:47,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:05:54,286] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:06:01,589] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:06:08,898] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:06:16,460] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:06:23,785] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:06:30,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:06:37,897] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:06:45,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:06:52,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8322008898759505
[2022-12-07 08:06:52,603] [INFO] [runner_train_mujoco] Average state value: 0.5371741862098377
[2022-12-07 08:06:52,603] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 08:06:52,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.03234
[2022-12-07 08:06:52,700] [INFO] [controller] EPOCH 2 loss ppo:  -0.01633, loss val: 0.03224
[2022-12-07 08:06:52,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.02141, loss val: 0.03301
[2022-12-07 08:06:52,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.02791, loss val: 0.03234
[2022-12-07 08:06:52,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:06:52,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:06:52,998] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:07:00,339] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:07:08,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:07:17,424] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:07:25,208] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:07:32,241] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:07:39,636] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:07:46,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:07:53,970] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:08:01,317] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:08:08,850] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9875728176757002
[2022-12-07 08:08:08,850] [INFO] [runner_train_mujoco] Average state value: 0.5306846231023472
[2022-12-07 08:08:08,850] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 08:08:08,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03625
[2022-12-07 08:08:08,942] [INFO] [controller] EPOCH 2 loss ppo:  -0.01511, loss val: 0.03676
[2022-12-07 08:08:08,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.01726, loss val: 0.03663
[2022-12-07 08:08:09,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.02018, loss val: 0.03693
[2022-12-07 08:08:09,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:08:09,148] [INFO] [optimize] Finished learning.
