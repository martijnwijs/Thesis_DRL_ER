[2022-12-06 16:50:20,687] [INFO] [optimize] Starting learning
[2022-12-06 16:50:20,708] [INFO] [optimize] Starting learning process..
[2022-12-06 16:50:20,861] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:50:20,862] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:50:36,040] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:50:48,952] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:51:02,293] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:51:16,090] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:51:29,911] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:51:44,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:51:56,844] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:52:10,130] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:52:23,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:52:35,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.291032026878073
[2022-12-06 16:52:35,300] [INFO] [runner_train_mujoco] Average state value: -0.01953432361284892
[2022-12-06 16:52:35,300] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 16:52:35,451] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.50193
[2022-12-06 16:52:35,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.05790, loss val: 0.45897
[2022-12-06 16:52:35,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.07461, loss val: 0.42823
[2022-12-06 16:52:35,722] [INFO] [controller] EPOCH 4 loss ppo:  -0.08455, loss val: 0.37675
[2022-12-06 16:52:35,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:52:36,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:52:36,041] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:52:48,542] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:53:00,592] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:53:13,145] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:53:25,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:53:37,417] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:53:49,386] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:54:01,633] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:54:13,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:54:25,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:54:37,618] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6534307636092698
[2022-12-06 16:54:37,619] [INFO] [runner_train_mujoco] Average state value: 0.12490968417593588
[2022-12-06 16:54:37,619] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 16:54:37,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.36091
[2022-12-06 16:54:37,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.05391, loss val: 0.32503
[2022-12-06 16:54:37,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.07506, loss val: 0.29175
[2022-12-06 16:54:37,910] [INFO] [controller] EPOCH 4 loss ppo:  -0.08687, loss val: 0.26092
[2022-12-06 16:54:37,921] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:54:38,176] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:54:38,177] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:54:49,607] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:55:00,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:55:12,315] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:55:24,131] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:55:35,714] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:55:47,050] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:55:58,507] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:56:09,777] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:56:20,885] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:56:32,707] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4910590335996126
[2022-12-06 16:56:32,708] [INFO] [runner_train_mujoco] Average state value: 0.26254356499326725
[2022-12-06 16:56:32,708] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 16:56:32,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01579, loss val: 0.21660
[2022-12-06 16:56:33,117] [INFO] [controller] EPOCH 2 loss ppo:  -0.05527, loss val: 0.18453
[2022-12-06 16:56:33,200] [INFO] [controller] EPOCH 3 loss ppo:  -0.07470, loss val: 0.17666
[2022-12-06 16:56:33,258] [INFO] [controller] EPOCH 4 loss ppo:  -0.08580, loss val: 0.14137
[2022-12-06 16:56:33,270] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:56:33,519] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:56:33,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:56:45,820] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:56:57,504] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:57:09,939] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:57:21,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:57:33,803] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:57:46,292] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:57:58,865] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:58:11,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:58:24,182] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:58:36,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5242923535952237
[2022-12-06 16:58:36,884] [INFO] [runner_train_mujoco] Average state value: 0.42020565029295787
[2022-12-06 16:58:36,885] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 16:58:37,076] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.13071
[2022-12-06 16:58:37,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.05451, loss val: 0.11994
[2022-12-06 16:58:37,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.07421, loss val: 0.10320
[2022-12-06 16:58:37,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.08499, loss val: 0.09083
[2022-12-06 16:58:37,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:58:37,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:58:37,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:58:51,072] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:59:04,524] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:59:18,136] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:59:30,701] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:59:44,320] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:59:57,930] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:00:11,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:00:24,424] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:00:37,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:00:50,243] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.383471009833254
[2022-12-06 17:00:50,244] [INFO] [runner_train_mujoco] Average state value: 0.49482954222895204
[2022-12-06 17:00:50,244] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 17:00:50,331] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.14780
[2022-12-06 17:00:50,434] [INFO] [controller] EPOCH 2 loss ppo:  -0.04835, loss val: 0.14505
[2022-12-06 17:00:50,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.06982, loss val: 0.14137
[2022-12-06 17:00:51,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.08411, loss val: 0.13454
[2022-12-06 17:00:51,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:00:51,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:00:51,724] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:01:04,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:01:17,388] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:01:30,155] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:01:43,739] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:01:56,617] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:02:10,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:02:23,320] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:02:35,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:02:47,795] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:02:59,555] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6622241576136798
[2022-12-06 17:02:59,555] [INFO] [runner_train_mujoco] Average state value: 0.5850218809470535
[2022-12-06 17:02:59,555] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 17:02:59,701] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.09149
[2022-12-06 17:02:59,875] [INFO] [controller] EPOCH 2 loss ppo:  -0.04261, loss val: 0.08360
[2022-12-06 17:02:59,953] [INFO] [controller] EPOCH 3 loss ppo:  -0.06067, loss val: 0.07976
[2022-12-06 17:03:00,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.07396, loss val: 0.07293
[2022-12-06 17:03:00,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:03:00,291] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:03:00,291] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:03:12,902] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:03:25,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:03:36,821] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:03:48,703] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:04:00,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:04:12,162] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:04:23,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:04:35,719] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:04:47,785] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:05:00,402] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5237825726521013
[2022-12-06 17:05:00,402] [INFO] [runner_train_mujoco] Average state value: 0.5357167669857542
[2022-12-06 17:05:00,403] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 17:05:00,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.06431
[2022-12-06 17:05:00,557] [INFO] [controller] EPOCH 2 loss ppo:  -0.05172, loss val: 0.06175
[2022-12-06 17:05:00,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.06872, loss val: 0.06298
[2022-12-06 17:05:00,677] [INFO] [controller] EPOCH 4 loss ppo:  -0.08116, loss val: 0.05864
[2022-12-06 17:05:00,689] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:05:00,939] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:05:00,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:05:12,235] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:05:23,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:05:36,146] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:05:48,957] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:06:01,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:06:14,541] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:06:28,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:06:41,472] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:06:54,838] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:07:11,229] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6669480111340989
[2022-12-06 17:07:11,229] [INFO] [runner_train_mujoco] Average state value: 0.5256907559484243
[2022-12-06 17:07:11,229] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 17:07:11,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01088, loss val: 0.06387
[2022-12-06 17:07:11,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.04471, loss val: 0.06038
[2022-12-06 17:07:11,694] [INFO] [controller] EPOCH 3 loss ppo:  -0.06420, loss val: 0.06117
[2022-12-06 17:07:11,796] [INFO] [controller] EPOCH 4 loss ppo:  -0.07473, loss val: 0.05601
[2022-12-06 17:07:11,809] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:07:12,103] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:07:12,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:07:25,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:07:44,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:08:00,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:08:16,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:08:32,433] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:08:47,058] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:09:02,569] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:09:20,233] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:09:34,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:09:50,078] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5064651283162398
[2022-12-06 17:09:50,079] [INFO] [runner_train_mujoco] Average state value: 0.4813183344242473
[2022-12-06 17:09:50,079] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 17:09:50,262] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.12813
[2022-12-06 17:09:50,403] [INFO] [controller] EPOCH 2 loss ppo:  -0.04861, loss val: 0.12481
[2022-12-06 17:09:50,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.06388, loss val: 0.12283
[2022-12-06 17:09:50,851] [INFO] [controller] EPOCH 4 loss ppo:  -0.07467, loss val: 0.12036
[2022-12-06 17:09:50,866] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:09:51,290] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:09:51,291] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:10:09,137] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:10:25,793] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:10:41,954] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:11:00,472] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:11:16,988] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:11:34,849] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:11:52,565] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:12:09,978] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:12:26,677] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:12:42,726] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.820783651893952
[2022-12-06 17:12:42,726] [INFO] [runner_train_mujoco] Average state value: 0.5664731515397629
[2022-12-06 17:12:42,726] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 17:12:42,842] [INFO] [controller] EPOCH 1 loss ppo:  -0.01572, loss val: 0.06320
[2022-12-06 17:12:42,932] [INFO] [controller] EPOCH 2 loss ppo:  -0.05114, loss val: 0.06288
[2022-12-06 17:12:43,017] [INFO] [controller] EPOCH 3 loss ppo:  -0.07142, loss val: 0.06335
[2022-12-06 17:12:43,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.08306, loss val: 0.06108
[2022-12-06 17:12:43,109] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:12:43,460] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:12:43,482] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:13:03,145] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:13:18,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:13:35,377] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:13:50,300] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:14:05,048] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:14:20,095] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:14:35,428] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:14:48,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:15:01,343] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:15:17,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6117543723251935
[2022-12-06 17:15:17,760] [INFO] [runner_train_mujoco] Average state value: 0.565604922965169
[2022-12-06 17:15:17,760] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 17:15:17,884] [INFO] [controller] EPOCH 1 loss ppo:  -0.01259, loss val: 0.07643
[2022-12-06 17:15:18,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.04471, loss val: 0.07954
[2022-12-06 17:15:18,079] [INFO] [controller] EPOCH 3 loss ppo:  -0.06252, loss val: 0.07400
[2022-12-06 17:15:18,323] [INFO] [controller] EPOCH 4 loss ppo:  -0.07437, loss val: 0.07230
[2022-12-06 17:15:18,350] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:15:18,761] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:15:18,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:15:31,724] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:15:44,254] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:15:56,535] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:16:09,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:16:22,349] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:16:34,628] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:16:47,581] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:17:00,521] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:17:12,896] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:17:25,553] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4155098547855272
[2022-12-06 17:17:25,553] [INFO] [runner_train_mujoco] Average state value: 0.4636640944480896
[2022-12-06 17:17:25,553] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 17:17:25,652] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.12708
[2022-12-06 17:17:25,777] [INFO] [controller] EPOCH 2 loss ppo:  -0.04367, loss val: 0.12562
[2022-12-06 17:17:25,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.06270, loss val: 0.12064
[2022-12-06 17:17:25,937] [INFO] [controller] EPOCH 4 loss ppo:  -0.07387, loss val: 0.11764
[2022-12-06 17:17:25,953] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:17:26,219] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:17:26,219] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:17:40,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:17:51,687] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:18:02,807] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:18:13,663] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:18:25,147] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:18:35,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:18:46,248] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:18:57,057] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:19:08,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:19:18,551] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5467348632622502
[2022-12-06 17:19:18,551] [INFO] [runner_train_mujoco] Average state value: 0.4452709641357263
[2022-12-06 17:19:18,551] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 17:19:18,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.10873
[2022-12-06 17:19:18,707] [INFO] [controller] EPOCH 2 loss ppo:  -0.04687, loss val: 0.10815
[2022-12-06 17:19:18,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.06358, loss val: 0.10148
[2022-12-06 17:19:18,845] [INFO] [controller] EPOCH 4 loss ppo:  -0.07561, loss val: 0.09467
[2022-12-06 17:19:18,858] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:19:19,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:19:19,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:19:31,356] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:19:41,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:19:51,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:20:03,130] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:20:14,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:20:24,537] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:20:38,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:20:50,910] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:21:04,411] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:21:16,661] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6114492873578379
[2022-12-06 17:21:16,662] [INFO] [runner_train_mujoco] Average state value: 0.542689973719418
[2022-12-06 17:21:16,662] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 17:21:16,756] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.05253
[2022-12-06 17:21:16,851] [INFO] [controller] EPOCH 2 loss ppo:  -0.04952, loss val: 0.05252
[2022-12-06 17:21:16,960] [INFO] [controller] EPOCH 3 loss ppo:  -0.07125, loss val: 0.05181
[2022-12-06 17:21:17,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.08344, loss val: 0.05129
[2022-12-06 17:21:17,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:21:17,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:21:17,359] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:21:29,369] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:21:39,869] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:21:50,097] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:22:00,741] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:22:11,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:22:21,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:22:32,320] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:22:42,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:22:53,902] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:23:04,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6547706103052147
[2022-12-06 17:23:04,825] [INFO] [runner_train_mujoco] Average state value: 0.44881039973100023
[2022-12-06 17:23:04,825] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 17:23:04,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.09223
[2022-12-06 17:23:05,025] [INFO] [controller] EPOCH 2 loss ppo:  -0.04487, loss val: 0.08982
[2022-12-06 17:23:05,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.06616, loss val: 0.08706
[2022-12-06 17:23:05,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.08051, loss val: 0.08577
[2022-12-06 17:23:05,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:23:05,427] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:23:05,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:23:16,352] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:23:28,294] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:23:39,481] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:23:50,313] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:24:00,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:24:11,344] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:24:22,311] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:24:32,493] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:24:43,269] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:24:53,697] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7875763420272848
[2022-12-06 17:24:53,697] [INFO] [runner_train_mujoco] Average state value: 0.5045581144094468
[2022-12-06 17:24:53,697] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 17:24:53,758] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.03930
[2022-12-06 17:24:53,820] [INFO] [controller] EPOCH 2 loss ppo:  -0.04806, loss val: 0.03763
[2022-12-06 17:24:53,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.06751, loss val: 0.03790
[2022-12-06 17:24:53,924] [INFO] [controller] EPOCH 4 loss ppo:  -0.07892, loss val: 0.03699
[2022-12-06 17:24:53,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:24:54,189] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:24:54,190] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:25:05,291] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:25:15,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:25:25,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:25:35,554] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:25:45,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:25:55,875] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:26:06,280] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:26:16,709] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:26:26,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:26:36,421] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7612962769092662
[2022-12-06 17:26:36,421] [INFO] [runner_train_mujoco] Average state value: 0.4753254513144494
[2022-12-06 17:26:36,421] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 17:26:36,482] [INFO] [controller] EPOCH 1 loss ppo:  -0.01599, loss val: 0.04775
[2022-12-06 17:26:36,531] [INFO] [controller] EPOCH 2 loss ppo:  -0.04688, loss val: 0.04858
[2022-12-06 17:26:36,580] [INFO] [controller] EPOCH 3 loss ppo:  -0.05932, loss val: 0.04247
[2022-12-06 17:26:36,631] [INFO] [controller] EPOCH 4 loss ppo:  -0.07369, loss val: 0.04482
[2022-12-06 17:26:36,657] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:26:36,882] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:26:36,882] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:26:47,131] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:26:56,652] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:27:06,741] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:27:15,759] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:27:24,192] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:27:32,286] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:27:40,450] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:27:48,903] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:27:57,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:28:06,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7971313130471558
[2022-12-06 17:28:06,568] [INFO] [runner_train_mujoco] Average state value: 0.47111116656661034
[2022-12-06 17:28:06,568] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 17:28:06,689] [INFO] [controller] EPOCH 1 loss ppo:  -0.01601, loss val: 0.05660
[2022-12-06 17:28:06,770] [INFO] [controller] EPOCH 2 loss ppo:  -0.04861, loss val: 0.05658
[2022-12-06 17:28:06,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.07128, loss val: 0.05583
[2022-12-06 17:28:07,142] [INFO] [controller] EPOCH 4 loss ppo:  -0.08608, loss val: 0.05750
[2022-12-06 17:28:07,160] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:28:07,490] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:28:07,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:28:22,795] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:28:30,912] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:28:39,655] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:28:51,579] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:29:02,342] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:29:10,448] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:29:19,190] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:29:27,576] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:29:35,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:29:43,793] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7240497404989799
[2022-12-06 17:29:43,793] [INFO] [runner_train_mujoco] Average state value: 0.46698133627076943
[2022-12-06 17:29:43,793] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 17:29:43,843] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.07307
[2022-12-06 17:29:43,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.04084, loss val: 0.07196
[2022-12-06 17:29:43,929] [INFO] [controller] EPOCH 3 loss ppo:  -0.06096, loss val: 0.07002
[2022-12-06 17:29:43,973] [INFO] [controller] EPOCH 4 loss ppo:  -0.07621, loss val: 0.06815
[2022-12-06 17:29:43,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:29:44,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:29:44,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:29:52,487] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:30:01,201] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:30:09,598] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:30:17,852] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:30:26,081] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:30:34,437] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:30:42,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:30:51,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:30:59,504] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:31:08,834] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4275834207246987
[2022-12-06 17:31:08,834] [INFO] [runner_train_mujoco] Average state value: 0.5157495252514879
[2022-12-06 17:31:08,834] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 17:31:08,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04697
[2022-12-06 17:31:08,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.04836, loss val: 0.04189
[2022-12-06 17:31:09,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.06849, loss val: 0.04236
[2022-12-06 17:31:09,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.08379, loss val: 0.04104
[2022-12-06 17:31:09,061] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:31:09,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:31:09,284] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:31:18,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:31:26,735] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:31:35,188] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:31:43,961] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:31:52,568] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:32:01,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:32:09,917] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:32:18,306] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:32:26,373] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:32:34,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.360712360749308
[2022-12-06 17:32:34,892] [INFO] [runner_train_mujoco] Average state value: 0.5082325148185094
[2022-12-06 17:32:34,892] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 17:32:34,946] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04440
[2022-12-06 17:32:34,992] [INFO] [controller] EPOCH 2 loss ppo:  -0.04961, loss val: 0.04443
[2022-12-06 17:32:35,039] [INFO] [controller] EPOCH 3 loss ppo:  -0.06969, loss val: 0.04446
[2022-12-06 17:32:35,085] [INFO] [controller] EPOCH 4 loss ppo:  -0.08429, loss val: 0.04716
[2022-12-06 17:32:35,093] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:32:35,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:32:35,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:32:43,520] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:32:51,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:33:00,128] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:33:08,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:33:16,358] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:33:24,347] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:33:32,303] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:33:41,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:33:50,015] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:33:58,099] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6781312026289672
[2022-12-06 17:33:58,099] [INFO] [runner_train_mujoco] Average state value: 0.5066220389405887
[2022-12-06 17:33:58,099] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 17:33:58,156] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.03312
[2022-12-06 17:33:58,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.04546, loss val: 0.03271
[2022-12-06 17:33:58,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.06526, loss val: 0.03377
[2022-12-06 17:33:58,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.07975, loss val: 0.03159
[2022-12-06 17:33:58,296] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:33:58,505] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:33:58,505] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:34:06,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:34:15,224] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:34:23,332] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:34:31,085] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:34:38,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:34:46,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:34:54,291] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:35:02,395] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:35:10,827] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:35:18,743] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6008305087061072
[2022-12-06 17:35:18,744] [INFO] [runner_train_mujoco] Average state value: 0.4880486064553261
[2022-12-06 17:35:18,744] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 17:35:18,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.01504, loss val: 0.03212
[2022-12-06 17:35:18,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.04607, loss val: 0.03196
[2022-12-06 17:35:18,884] [INFO] [controller] EPOCH 3 loss ppo:  -0.06729, loss val: 0.03521
[2022-12-06 17:35:18,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.08292, loss val: 0.03185
[2022-12-06 17:35:18,937] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:35:19,139] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:35:19,140] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:35:26,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:35:34,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:35:42,578] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:35:50,602] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:35:58,986] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:36:07,431] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:36:15,143] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:36:23,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:36:31,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:36:40,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.624288601736535
[2022-12-06 17:36:40,004] [INFO] [runner_train_mujoco] Average state value: 0.4328574592123429
[2022-12-06 17:36:40,004] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 17:36:40,067] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.05044
[2022-12-06 17:36:40,120] [INFO] [controller] EPOCH 2 loss ppo:  -0.04648, loss val: 0.05143
[2022-12-06 17:36:40,178] [INFO] [controller] EPOCH 3 loss ppo:  -0.06388, loss val: 0.05164
[2022-12-06 17:36:40,231] [INFO] [controller] EPOCH 4 loss ppo:  -0.07871, loss val: 0.05194
[2022-12-06 17:36:40,243] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:36:40,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:36:40,472] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:36:48,665] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:36:57,054] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:37:05,514] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:37:14,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:37:22,508] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:37:30,683] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:37:38,846] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:37:47,296] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:37:56,074] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:38:04,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5140341577103098
[2022-12-06 17:38:04,402] [INFO] [runner_train_mujoco] Average state value: 0.45051311194896704
[2022-12-06 17:38:04,402] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 17:38:04,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.04438
[2022-12-06 17:38:04,507] [INFO] [controller] EPOCH 2 loss ppo:  -0.04986, loss val: 0.04167
[2022-12-06 17:38:04,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.07160, loss val: 0.04136
[2022-12-06 17:38:04,596] [INFO] [controller] EPOCH 4 loss ppo:  -0.08391, loss val: 0.04135
[2022-12-06 17:38:04,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:38:04,827] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:38:04,828] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:38:13,138] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:38:21,035] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:38:28,893] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:38:37,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:38:45,003] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:38:53,164] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:39:01,220] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:39:09,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:39:17,663] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:39:25,681] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8325052511945146
[2022-12-06 17:39:25,681] [INFO] [runner_train_mujoco] Average state value: 0.46937701165676116
[2022-12-06 17:39:25,681] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 17:39:25,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.03045
[2022-12-06 17:39:25,822] [INFO] [controller] EPOCH 2 loss ppo:  -0.04506, loss val: 0.03035
[2022-12-06 17:39:25,863] [INFO] [controller] EPOCH 3 loss ppo:  -0.06351, loss val: 0.03029
[2022-12-06 17:39:25,908] [INFO] [controller] EPOCH 4 loss ppo:  -0.07597, loss val: 0.03017
[2022-12-06 17:39:25,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:39:26,133] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:39:26,133] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:39:33,961] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:39:41,698] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:39:49,595] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:39:56,519] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:40:03,862] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:40:10,809] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:40:17,722] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:40:25,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:40:32,110] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:40:38,882] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8192792177128485
[2022-12-06 17:40:38,883] [INFO] [runner_train_mujoco] Average state value: 0.4637627889215946
[2022-12-06 17:40:38,883] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 17:40:38,931] [INFO] [controller] EPOCH 1 loss ppo:  -0.01255, loss val: 0.05868
[2022-12-06 17:40:38,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.03486, loss val: 0.05491
[2022-12-06 17:40:39,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.05677, loss val: 0.05395
[2022-12-06 17:40:39,053] [INFO] [controller] EPOCH 4 loss ppo:  -0.07249, loss val: 0.05091
[2022-12-06 17:40:39,062] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:40:39,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:40:39,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:40:46,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:40:53,292] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:41:00,366] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:41:07,187] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:41:14,132] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:41:21,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:41:28,025] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:41:35,497] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:41:42,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:41:49,807] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5922713283228902
[2022-12-06 17:41:49,808] [INFO] [runner_train_mujoco] Average state value: 0.49534061400095625
[2022-12-06 17:41:49,808] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 17:41:49,859] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.04620
[2022-12-06 17:41:49,903] [INFO] [controller] EPOCH 2 loss ppo:  -0.04593, loss val: 0.04587
[2022-12-06 17:41:49,945] [INFO] [controller] EPOCH 3 loss ppo:  -0.06714, loss val: 0.04686
[2022-12-06 17:41:49,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.08411, loss val: 0.04710
[2022-12-06 17:41:49,989] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:41:50,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:41:50,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:41:57,858] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:42:05,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:42:12,090] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:42:19,034] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:42:25,966] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:42:32,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:42:40,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:42:47,399] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:42:55,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:43:02,144] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8669408969644117
[2022-12-06 17:43:02,145] [INFO] [runner_train_mujoco] Average state value: 0.5376837058564027
[2022-12-06 17:43:02,145] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 17:43:02,192] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.03429
[2022-12-06 17:43:02,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.04602, loss val: 0.03312
[2022-12-06 17:43:02,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.06550, loss val: 0.03288
[2022-12-06 17:43:02,336] [INFO] [controller] EPOCH 4 loss ppo:  -0.08253, loss val: 0.03374
[2022-12-06 17:43:02,346] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:43:02,570] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:43:02,571] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:43:10,382] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:43:18,581] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:43:26,718] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:43:33,715] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:43:40,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:43:48,053] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:43:55,800] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:44:03,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:44:10,900] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:44:18,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.762926798045686
[2022-12-06 17:44:18,505] [INFO] [runner_train_mujoco] Average state value: 0.5466357006430627
[2022-12-06 17:44:18,505] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 17:44:18,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01533, loss val: 0.04885
[2022-12-06 17:44:18,598] [INFO] [controller] EPOCH 2 loss ppo:  -0.04129, loss val: 0.04271
[2022-12-06 17:44:18,641] [INFO] [controller] EPOCH 3 loss ppo:  -0.05761, loss val: 0.04426
[2022-12-06 17:44:18,685] [INFO] [controller] EPOCH 4 loss ppo:  -0.07291, loss val: 0.04130
[2022-12-06 17:44:18,696] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:44:18,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:44:18,905] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:44:26,300] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:44:33,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:44:40,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:44:47,934] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:44:55,058] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:45:02,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:45:09,616] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:45:17,417] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:45:25,078] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:45:32,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7208538572007648
[2022-12-06 17:45:32,191] [INFO] [runner_train_mujoco] Average state value: 0.5432919994393983
[2022-12-06 17:45:32,191] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 17:45:32,242] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.03645
[2022-12-06 17:45:32,278] [INFO] [controller] EPOCH 2 loss ppo:  -0.04124, loss val: 0.03835
[2022-12-06 17:45:32,315] [INFO] [controller] EPOCH 3 loss ppo:  -0.06329, loss val: 0.03570
[2022-12-06 17:45:32,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.08171, loss val: 0.03578
[2022-12-06 17:45:32,366] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:45:32,558] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:45:32,559] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:45:39,817] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:45:46,819] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:45:53,820] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:46:00,731] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:46:07,836] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:46:14,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:46:22,141] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:46:29,463] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:46:36,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:46:43,239] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7807497284497658
[2022-12-06 17:46:43,239] [INFO] [runner_train_mujoco] Average state value: 0.512748681957523
[2022-12-06 17:46:43,239] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 17:46:43,291] [INFO] [controller] EPOCH 1 loss ppo:  -0.01658, loss val: 0.03711
[2022-12-06 17:46:43,332] [INFO] [controller] EPOCH 2 loss ppo:  -0.04051, loss val: 0.03751
[2022-12-06 17:46:43,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.05753, loss val: 0.03816
[2022-12-06 17:46:43,417] [INFO] [controller] EPOCH 4 loss ppo:  -0.07430, loss val: 0.03712
[2022-12-06 17:46:43,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:46:43,632] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:46:43,632] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:46:50,578] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:46:57,360] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:47:04,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:47:10,825] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:47:17,646] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:47:24,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:47:31,563] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:47:39,027] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:47:45,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:47:52,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8031294941293372
[2022-12-06 17:47:52,832] [INFO] [runner_train_mujoco] Average state value: 0.49582675354679423
[2022-12-06 17:47:52,832] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 17:47:52,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.04636
[2022-12-06 17:47:52,921] [INFO] [controller] EPOCH 2 loss ppo:  -0.04135, loss val: 0.04867
[2022-12-06 17:47:52,960] [INFO] [controller] EPOCH 3 loss ppo:  -0.06332, loss val: 0.04592
[2022-12-06 17:47:53,000] [INFO] [controller] EPOCH 4 loss ppo:  -0.07730, loss val: 0.04622
[2022-12-06 17:47:53,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:47:53,205] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:47:53,206] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:48:00,027] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:48:07,111] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:48:13,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:48:20,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:48:27,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:48:34,339] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:48:41,715] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:48:49,285] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:48:56,572] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:49:03,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7943053258297172
[2022-12-06 17:49:03,603] [INFO] [runner_train_mujoco] Average state value: 0.5001669189830621
[2022-12-06 17:49:03,604] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 17:49:03,654] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.03157
[2022-12-06 17:49:03,698] [INFO] [controller] EPOCH 2 loss ppo:  -0.04028, loss val: 0.03063
[2022-12-06 17:49:03,742] [INFO] [controller] EPOCH 3 loss ppo:  -0.05998, loss val: 0.03352
[2022-12-06 17:49:03,787] [INFO] [controller] EPOCH 4 loss ppo:  -0.07543, loss val: 0.03253
[2022-12-06 17:49:03,796] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:49:04,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:49:04,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:49:11,185] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:49:18,252] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:49:25,960] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:49:32,940] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:49:40,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:49:47,773] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:49:55,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:50:02,750] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:50:09,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:50:17,104] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.792406955775559
[2022-12-06 17:50:17,104] [INFO] [runner_train_mujoco] Average state value: 0.48945162670811015
[2022-12-06 17:50:17,104] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 17:50:17,155] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.03883
[2022-12-06 17:50:17,197] [INFO] [controller] EPOCH 2 loss ppo:  -0.03650, loss val: 0.03866
[2022-12-06 17:50:17,237] [INFO] [controller] EPOCH 3 loss ppo:  -0.05431, loss val: 0.04002
[2022-12-06 17:50:17,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.06905, loss val: 0.03698
[2022-12-06 17:50:17,290] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:50:17,493] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:50:17,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:50:24,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:50:32,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:50:39,710] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:50:46,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:50:54,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:51:01,535] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:51:09,241] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:51:16,628] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:51:23,921] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:51:30,942] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7228240880012495
[2022-12-06 17:51:30,942] [INFO] [runner_train_mujoco] Average state value: 0.5167402591109276
[2022-12-06 17:51:30,942] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 17:51:30,988] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04777
[2022-12-06 17:51:31,031] [INFO] [controller] EPOCH 2 loss ppo:  -0.03637, loss val: 0.04726
[2022-12-06 17:51:31,074] [INFO] [controller] EPOCH 3 loss ppo:  -0.05943, loss val: 0.04833
[2022-12-06 17:51:31,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.07623, loss val: 0.04811
[2022-12-06 17:51:31,124] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:51:31,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:51:31,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:51:38,414] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:51:45,389] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:51:52,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:51:59,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:52:07,032] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:52:14,270] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:52:21,574] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:52:28,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:52:35,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:52:42,316] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.855565376481853
[2022-12-06 17:52:42,317] [INFO] [runner_train_mujoco] Average state value: 0.5320953517357508
[2022-12-06 17:52:42,317] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 17:52:42,411] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04194
[2022-12-06 17:52:42,454] [INFO] [controller] EPOCH 2 loss ppo:  -0.03367, loss val: 0.04157
[2022-12-06 17:52:42,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.05301, loss val: 0.04124
[2022-12-06 17:52:42,530] [INFO] [controller] EPOCH 4 loss ppo:  -0.06952, loss val: 0.04077
[2022-12-06 17:52:42,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:52:42,741] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:52:42,742] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:52:49,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:52:56,295] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:53:02,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:53:09,782] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:53:16,733] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:53:23,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:53:31,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:53:38,423] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:53:45,132] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:53:51,869] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.415093138496669
[2022-12-06 17:53:51,869] [INFO] [runner_train_mujoco] Average state value: 0.5385596564213435
[2022-12-06 17:53:51,870] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 17:53:51,919] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.04940
[2022-12-06 17:53:51,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.03695, loss val: 0.04969
[2022-12-06 17:53:51,993] [INFO] [controller] EPOCH 3 loss ppo:  -0.05554, loss val: 0.04968
[2022-12-06 17:53:52,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.06936, loss val: 0.04881
[2022-12-06 17:53:52,046] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:53:52,224] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:53:52,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:53:59,132] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:54:06,031] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:54:12,825] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:54:19,818] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:54:26,930] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:54:33,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:54:41,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:54:47,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:54:54,801] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:55:01,609] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.840986292651547
[2022-12-06 17:55:01,609] [INFO] [runner_train_mujoco] Average state value: 0.5439986374378203
[2022-12-06 17:55:01,609] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 17:55:01,658] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04014
[2022-12-06 17:55:01,693] [INFO] [controller] EPOCH 2 loss ppo:  -0.03478, loss val: 0.03917
[2022-12-06 17:55:01,730] [INFO] [controller] EPOCH 3 loss ppo:  -0.05502, loss val: 0.03925
[2022-12-06 17:55:01,770] [INFO] [controller] EPOCH 4 loss ppo:  -0.07187, loss val: 0.03821
[2022-12-06 17:55:01,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:55:01,981] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:55:01,981] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:55:09,187] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:55:16,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:55:23,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:55:30,356] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:55:37,685] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:55:44,692] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:55:51,757] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:55:59,036] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:56:05,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:56:12,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.814447133360569
[2022-12-06 17:56:12,915] [INFO] [runner_train_mujoco] Average state value: 0.5259920056462287
[2022-12-06 17:56:12,915] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 17:56:12,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.04382
[2022-12-06 17:56:13,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.03201, loss val: 0.04104
[2022-12-06 17:56:13,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.04739, loss val: 0.04203
[2022-12-06 17:56:13,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.05948, loss val: 0.03941
[2022-12-06 17:56:13,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:56:13,308] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:56:13,309] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:56:20,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:56:28,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:56:35,486] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:56:43,097] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:56:50,689] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:56:58,146] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:57:05,659] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:57:13,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:57:20,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:57:27,390] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.615076078863476
[2022-12-06 17:57:27,390] [INFO] [runner_train_mujoco] Average state value: 0.5376322101553281
[2022-12-06 17:57:27,390] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 17:57:27,439] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.03130
[2022-12-06 17:57:27,481] [INFO] [controller] EPOCH 2 loss ppo:  -0.03568, loss val: 0.03004
[2022-12-06 17:57:27,521] [INFO] [controller] EPOCH 3 loss ppo:  -0.05413, loss val: 0.03047
[2022-12-06 17:57:27,562] [INFO] [controller] EPOCH 4 loss ppo:  -0.06875, loss val: 0.03016
[2022-12-06 17:57:27,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:57:27,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:57:27,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:57:34,790] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:57:42,057] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:57:49,248] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:57:56,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:58:03,920] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:58:11,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:58:18,417] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:58:25,659] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:58:32,506] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:58:39,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.592131313258107
[2022-12-06 17:58:39,309] [INFO] [runner_train_mujoco] Average state value: 0.5667689233819644
[2022-12-06 17:58:39,309] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 17:58:39,359] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.03585
[2022-12-06 17:58:39,396] [INFO] [controller] EPOCH 2 loss ppo:  -0.03997, loss val: 0.03620
[2022-12-06 17:58:39,439] [INFO] [controller] EPOCH 3 loss ppo:  -0.05666, loss val: 0.03846
[2022-12-06 17:58:39,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.06992, loss val: 0.03606
[2022-12-06 17:58:39,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:58:39,705] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:58:39,705] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:58:46,711] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:58:53,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:59:01,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:59:08,235] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:59:15,234] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:59:22,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:59:28,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:59:36,245] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:59:42,976] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:59:49,697] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8932997051551994
[2022-12-06 17:59:49,697] [INFO] [runner_train_mujoco] Average state value: 0.5606146084070206
[2022-12-06 17:59:49,697] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 17:59:49,738] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.03688
[2022-12-06 17:59:49,776] [INFO] [controller] EPOCH 2 loss ppo:  -0.03226, loss val: 0.03678
[2022-12-06 17:59:49,815] [INFO] [controller] EPOCH 3 loss ppo:  -0.04926, loss val: 0.03672
[2022-12-06 17:59:49,853] [INFO] [controller] EPOCH 4 loss ppo:  -0.06632, loss val: 0.03800
[2022-12-06 17:59:49,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:59:50,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:59:50,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:59:56,870] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:00:03,859] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:00:11,027] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:00:17,828] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:00:25,007] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:00:31,504] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:00:38,300] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:00:45,003] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:00:51,510] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:00:58,135] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8427555038084993
[2022-12-06 18:00:58,135] [INFO] [runner_train_mujoco] Average state value: 0.5348712799747786
[2022-12-06 18:00:58,135] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 18:00:58,184] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04893
[2022-12-06 18:00:58,218] [INFO] [controller] EPOCH 2 loss ppo:  -0.02929, loss val: 0.04541
[2022-12-06 18:00:58,254] [INFO] [controller] EPOCH 3 loss ppo:  -0.04270, loss val: 0.04451
[2022-12-06 18:00:58,289] [INFO] [controller] EPOCH 4 loss ppo:  -0.05808, loss val: 0.04410
[2022-12-06 18:00:58,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:00:58,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:00:58,501] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:01:05,384] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:01:12,565] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:01:19,460] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:01:26,330] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:01:32,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:01:39,665] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:01:46,570] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:01:53,594] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:02:00,387] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:02:07,220] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9484274131015815
[2022-12-06 18:02:07,220] [INFO] [runner_train_mujoco] Average state value: 0.5337465067307154
[2022-12-06 18:02:07,220] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 18:02:07,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01546, loss val: 0.03884
[2022-12-06 18:02:07,310] [INFO] [controller] EPOCH 2 loss ppo:  -0.03288, loss val: 0.03799
[2022-12-06 18:02:07,353] [INFO] [controller] EPOCH 3 loss ppo:  -0.05135, loss val: 0.03780
[2022-12-06 18:02:07,397] [INFO] [controller] EPOCH 4 loss ppo:  -0.06737, loss val: 0.03651
[2022-12-06 18:02:07,407] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:02:07,598] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:02:07,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:02:14,750] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:02:22,080] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:02:29,232] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:02:36,277] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:02:43,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:02:49,961] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:02:57,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:03:04,143] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:03:11,083] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:03:18,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.934267477352288
[2022-12-06 18:03:18,055] [INFO] [runner_train_mujoco] Average state value: 0.5051694834828377
[2022-12-06 18:03:18,055] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 18:03:18,104] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.03779
[2022-12-06 18:03:18,148] [INFO] [controller] EPOCH 2 loss ppo:  -0.02978, loss val: 0.04369
[2022-12-06 18:03:18,185] [INFO] [controller] EPOCH 3 loss ppo:  -0.04359, loss val: 0.04373
[2022-12-06 18:03:18,228] [INFO] [controller] EPOCH 4 loss ppo:  -0.05497, loss val: 0.04446
[2022-12-06 18:03:18,238] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:03:18,440] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:03:18,441] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:03:26,138] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:03:33,257] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:03:40,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:03:47,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:03:54,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:04:01,562] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:04:09,085] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:04:16,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:04:23,618] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:04:31,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8963064591802585
[2022-12-06 18:04:31,124] [INFO] [runner_train_mujoco] Average state value: 0.4976952947974205
[2022-12-06 18:04:31,124] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 18:04:31,176] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.03856
[2022-12-06 18:04:31,220] [INFO] [controller] EPOCH 2 loss ppo:  -0.02659, loss val: 0.03537
[2022-12-06 18:04:31,266] [INFO] [controller] EPOCH 3 loss ppo:  -0.04331, loss val: 0.03381
[2022-12-06 18:04:31,320] [INFO] [controller] EPOCH 4 loss ppo:  -0.05597, loss val: 0.03349
[2022-12-06 18:04:31,331] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:04:31,548] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:04:31,548] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:04:39,265] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:04:46,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:04:54,049] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:05:01,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:05:08,701] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:05:15,789] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:05:23,095] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:05:30,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:05:37,555] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:05:45,010] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.929831236481381
[2022-12-06 18:05:45,010] [INFO] [runner_train_mujoco] Average state value: 0.4876602285901706
[2022-12-06 18:05:45,010] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 18:05:45,103] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.03758
[2022-12-06 18:05:45,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.03018, loss val: 0.03541
[2022-12-06 18:05:45,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.04726, loss val: 0.03556
[2022-12-06 18:05:45,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.06155, loss val: 0.03542
[2022-12-06 18:05:45,218] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:05:45,426] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:05:45,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:05:52,641] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:05:59,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:06:06,585] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:06:13,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:06:20,107] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:06:27,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:06:34,130] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:06:41,245] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:06:48,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:06:55,320] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6293168205274224
[2022-12-06 18:06:55,320] [INFO] [runner_train_mujoco] Average state value: 0.49013564517100655
[2022-12-06 18:06:55,320] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 18:06:55,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03104
[2022-12-06 18:06:55,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.02590, loss val: 0.03110
[2022-12-06 18:06:55,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.04137, loss val: 0.03086
[2022-12-06 18:06:55,496] [INFO] [controller] EPOCH 4 loss ppo:  -0.05323, loss val: 0.03359
[2022-12-06 18:06:55,506] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:06:55,713] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:06:55,713] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:07:03,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:07:12,650] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:07:21,652] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:07:28,709] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:07:35,367] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:07:42,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:07:48,942] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:07:55,868] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:08:03,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:08:10,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0852976844775104
[2022-12-06 18:08:10,091] [INFO] [runner_train_mujoco] Average state value: 0.5001249759991964
[2022-12-06 18:08:10,091] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 18:08:10,140] [INFO] [controller] EPOCH 1 loss ppo:  -0.01522, loss val: 0.04717
[2022-12-06 18:08:10,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.02640, loss val: 0.04788
[2022-12-06 18:08:10,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.04201, loss val: 0.04684
[2022-12-06 18:08:10,261] [INFO] [controller] EPOCH 4 loss ppo:  -0.05531, loss val: 0.04820
[2022-12-06 18:08:10,275] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:08:10,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:08:10,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:08:17,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:08:24,506] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:08:31,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:08:38,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:08:44,944] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:08:51,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:08:58,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:09:05,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:09:13,132] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:09:20,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0597602762105276
[2022-12-06 18:09:20,300] [INFO] [runner_train_mujoco] Average state value: 0.5154356231689452
[2022-12-06 18:09:20,300] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 18:09:20,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.03951
[2022-12-06 18:09:20,390] [INFO] [controller] EPOCH 2 loss ppo:  -0.02113, loss val: 0.03969
[2022-12-06 18:09:20,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.03394, loss val: 0.04047
[2022-12-06 18:09:20,471] [INFO] [controller] EPOCH 4 loss ppo:  -0.04751, loss val: 0.04312
[2022-12-06 18:09:20,480] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:09:20,683] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:09:20,684] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:09:27,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:09:35,050] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:09:41,855] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:09:48,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:09:55,752] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:10:02,746] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:10:10,252] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:10:17,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:10:25,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:10:32,675] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.936342201865718
[2022-12-06 18:10:32,676] [INFO] [runner_train_mujoco] Average state value: 0.5170727565288544
[2022-12-06 18:10:32,676] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 18:10:32,726] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.03437
[2022-12-06 18:10:32,762] [INFO] [controller] EPOCH 2 loss ppo:  -0.02521, loss val: 0.03611
[2022-12-06 18:10:32,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.04104, loss val: 0.03844
[2022-12-06 18:10:32,845] [INFO] [controller] EPOCH 4 loss ppo:  -0.05213, loss val: 0.03438
[2022-12-06 18:10:32,854] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:10:33,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:10:33,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:10:40,024] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:10:47,235] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:10:54,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:11:01,177] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:11:08,048] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:11:15,187] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:11:21,968] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:11:29,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:11:37,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:11:44,282] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9768708095993237
[2022-12-06 18:11:44,282] [INFO] [runner_train_mujoco] Average state value: 0.5107681475281715
[2022-12-06 18:11:44,282] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 18:11:44,332] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04521
[2022-12-06 18:11:44,372] [INFO] [controller] EPOCH 2 loss ppo:  -0.02155, loss val: 0.04552
[2022-12-06 18:11:44,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.03371, loss val: 0.04416
[2022-12-06 18:11:44,445] [INFO] [controller] EPOCH 4 loss ppo:  -0.04644, loss val: 0.04528
[2022-12-06 18:11:44,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:11:44,650] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:11:44,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:11:51,613] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:11:58,666] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:12:05,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:12:12,371] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:12:19,115] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:12:25,953] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:12:33,068] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:12:40,428] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:12:47,278] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:12:53,922] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9293042917293703
[2022-12-06 18:12:53,922] [INFO] [runner_train_mujoco] Average state value: 0.49591620934009556
[2022-12-06 18:12:53,922] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 18:12:53,973] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.03587
[2022-12-06 18:12:54,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.01918, loss val: 0.03509
[2022-12-06 18:12:54,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.02938, loss val: 0.03626
[2022-12-06 18:12:54,095] [INFO] [controller] EPOCH 4 loss ppo:  -0.04199, loss val: 0.03578
[2022-12-06 18:12:54,105] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:12:54,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:12:54,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:13:01,051] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:13:08,070] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:13:14,769] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:13:21,462] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:13:28,226] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:13:35,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:13:42,262] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:13:49,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:13:56,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:14:03,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.036338247629431
[2022-12-06 18:14:03,273] [INFO] [runner_train_mujoco] Average state value: 0.4906491285860538
[2022-12-06 18:14:03,273] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 18:14:03,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.04983
[2022-12-06 18:14:03,366] [INFO] [controller] EPOCH 2 loss ppo:  -0.01900, loss val: 0.04566
[2022-12-06 18:14:03,403] [INFO] [controller] EPOCH 3 loss ppo:  -0.02743, loss val: 0.04569
[2022-12-06 18:14:03,441] [INFO] [controller] EPOCH 4 loss ppo:  -0.03733, loss val: 0.04544
[2022-12-06 18:14:03,449] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:14:03,631] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:14:03,631] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:14:10,539] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:14:17,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:14:24,230] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:14:31,255] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:14:38,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:14:45,297] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:14:52,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:14:59,911] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:15:07,180] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:15:14,151] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8692920183478523
[2022-12-06 18:15:14,151] [INFO] [runner_train_mujoco] Average state value: 0.4986353961626688
[2022-12-06 18:15:14,151] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 18:15:14,201] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.04589
[2022-12-06 18:15:14,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.01824, loss val: 0.04346
[2022-12-06 18:15:14,272] [INFO] [controller] EPOCH 3 loss ppo:  -0.02397, loss val: 0.04274
[2022-12-06 18:15:14,312] [INFO] [controller] EPOCH 4 loss ppo:  -0.03165, loss val: 0.04216
[2022-12-06 18:15:14,322] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:15:14,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:15:14,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:15:21,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:15:29,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:15:36,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:15:43,514] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:15:50,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:15:58,029] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:16:05,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:16:12,978] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:16:20,353] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:16:27,593] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0131484466520755
[2022-12-06 18:16:27,593] [INFO] [runner_train_mujoco] Average state value: 0.502658256729444
[2022-12-06 18:16:27,593] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 18:16:27,653] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03924
[2022-12-06 18:16:27,697] [INFO] [controller] EPOCH 2 loss ppo:  -0.01610, loss val: 0.03958
[2022-12-06 18:16:27,742] [INFO] [controller] EPOCH 3 loss ppo:  -0.02005, loss val: 0.03892
[2022-12-06 18:16:27,787] [INFO] [controller] EPOCH 4 loss ppo:  -0.02532, loss val: 0.03843
[2022-12-06 18:16:27,797] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:16:27,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:16:27,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:16:35,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:16:42,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:16:50,099] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:16:57,276] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:17:04,432] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:17:11,480] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:17:18,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:17:26,072] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:17:33,393] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:17:40,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8462357829567768
[2022-12-06 18:17:40,505] [INFO] [runner_train_mujoco] Average state value: 0.5067921795149644
[2022-12-06 18:17:40,505] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 18:17:40,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.03637
[2022-12-06 18:17:40,597] [INFO] [controller] EPOCH 2 loss ppo:  -0.01548, loss val: 0.03734
[2022-12-06 18:17:40,633] [INFO] [controller] EPOCH 3 loss ppo:  -0.01767, loss val: 0.03894
[2022-12-06 18:17:40,672] [INFO] [controller] EPOCH 4 loss ppo:  -0.02046, loss val: 0.03717
[2022-12-06 18:17:40,681] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:17:40,796] [INFO] [optimize] Finished learning.
