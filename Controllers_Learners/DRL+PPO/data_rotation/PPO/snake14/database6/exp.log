[2022-12-07 02:56:26,402] [INFO] [optimize] Starting learning
[2022-12-07 02:56:26,417] [INFO] [optimize] Starting learning process..
[2022-12-07 02:56:26,543] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:56:26,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:56:37,571] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:56:47,100] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:56:56,698] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:57:06,252] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:57:15,888] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:57:26,207] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:57:35,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:57:45,470] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:57:54,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:58:03,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.59805303034182
[2022-12-07 02:58:03,721] [INFO] [runner_train_mujoco] Average state value: 0.15229267729570467
[2022-12-07 02:58:03,722] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 02:58:03,792] [INFO] [controller] EPOCH 1 loss ppo:  -0.00759, loss val: 0.35787
[2022-12-07 02:58:03,843] [INFO] [controller] EPOCH 2 loss ppo:  -0.05425, loss val: 0.31925
[2022-12-07 02:58:03,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.07321, loss val: 0.28551
[2022-12-07 02:58:03,960] [INFO] [controller] EPOCH 4 loss ppo:  -0.08273, loss val: 0.25079
[2022-12-07 02:58:03,971] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:58:04,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:58:04,187] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:58:13,961] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:58:23,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:58:32,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:58:42,311] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:58:51,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:59:00,571] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:59:09,624] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:59:18,967] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:59:28,668] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:59:37,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6224323036341357
[2022-12-07 02:59:37,838] [INFO] [runner_train_mujoco] Average state value: 0.22320459903248896
[2022-12-07 02:59:37,838] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 02:59:37,896] [INFO] [controller] EPOCH 1 loss ppo:  -0.01631, loss val: 0.34239
[2022-12-07 02:59:37,959] [INFO] [controller] EPOCH 2 loss ppo:  -0.05805, loss val: 0.31311
[2022-12-07 02:59:38,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.07833, loss val: 0.30225
[2022-12-07 02:59:38,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.09141, loss val: 0.28655
[2022-12-07 02:59:38,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:59:38,290] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:59:38,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:59:47,973] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:59:57,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:00:06,409] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:00:15,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:00:25,161] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:00:34,500] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:00:43,921] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:00:52,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:01:01,966] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:01:11,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.444206142117219
[2022-12-07 03:01:11,275] [INFO] [runner_train_mujoco] Average state value: 0.4157556496715794
[2022-12-07 03:01:11,275] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 03:01:11,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.19568
[2022-12-07 03:01:11,396] [INFO] [controller] EPOCH 2 loss ppo:  -0.05246, loss val: 0.17983
[2022-12-07 03:01:11,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.07280, loss val: 0.16742
[2022-12-07 03:01:11,524] [INFO] [controller] EPOCH 4 loss ppo:  -0.08376, loss val: 0.15433
[2022-12-07 03:01:11,534] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:01:11,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:01:11,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:01:21,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:01:30,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:01:39,962] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:01:49,415] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:01:58,284] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:02:07,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:02:16,747] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:02:25,947] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:02:35,316] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:02:44,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4543563823021226
[2022-12-07 03:02:44,760] [INFO] [runner_train_mujoco] Average state value: 0.4948628683537245
[2022-12-07 03:02:44,761] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 03:02:44,879] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.17664
[2022-12-07 03:02:44,935] [INFO] [controller] EPOCH 2 loss ppo:  -0.05027, loss val: 0.17082
[2022-12-07 03:02:44,993] [INFO] [controller] EPOCH 3 loss ppo:  -0.06864, loss val: 0.16379
[2022-12-07 03:02:45,064] [INFO] [controller] EPOCH 4 loss ppo:  -0.08316, loss val: 0.15783
[2022-12-07 03:02:45,074] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:02:45,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:02:45,306] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:02:54,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:03:04,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:03:13,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:03:23,580] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:03:33,455] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:03:42,454] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:03:51,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:04:01,287] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:04:10,353] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:04:19,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.763845301576152
[2022-12-07 03:04:19,237] [INFO] [runner_train_mujoco] Average state value: 0.5865936647082368
[2022-12-07 03:04:19,237] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 03:04:19,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.09684
[2022-12-07 03:04:19,431] [INFO] [controller] EPOCH 2 loss ppo:  -0.04531, loss val: 0.09164
[2022-12-07 03:04:19,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.06422, loss val: 0.08623
[2022-12-07 03:04:19,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.07510, loss val: 0.08180
[2022-12-07 03:04:19,563] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:04:19,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:04:19,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:04:29,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:04:39,149] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:04:48,603] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:04:57,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:05:06,957] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:05:16,417] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:05:25,080] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:05:34,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:05:43,919] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:05:53,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.454353630343777
[2022-12-07 03:05:53,177] [INFO] [runner_train_mujoco] Average state value: 0.5659646996061006
[2022-12-07 03:05:53,177] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 03:05:53,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.08906
[2022-12-07 03:05:53,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.04524, loss val: 0.08412
[2022-12-07 03:05:53,366] [INFO] [controller] EPOCH 3 loss ppo:  -0.06230, loss val: 0.08023
[2022-12-07 03:05:53,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.07481, loss val: 0.07536
[2022-12-07 03:05:53,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:05:53,658] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:05:53,658] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:06:02,493] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:06:12,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:06:21,164] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:06:30,994] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:06:40,539] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:06:49,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:06:59,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:07:10,147] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:07:20,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:07:30,125] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6170488921502213
[2022-12-07 03:07:30,126] [INFO] [runner_train_mujoco] Average state value: 0.4387390671881537
[2022-12-07 03:07:30,126] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 03:07:30,192] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.13990
[2022-12-07 03:07:30,254] [INFO] [controller] EPOCH 2 loss ppo:  -0.04593, loss val: 0.13815
[2022-12-07 03:07:30,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.06347, loss val: 0.13554
[2022-12-07 03:07:30,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.07556, loss val: 0.13000
[2022-12-07 03:07:30,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:07:30,602] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:07:30,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:07:39,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:07:49,295] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:07:58,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:08:08,472] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:08:17,699] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:08:27,228] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:08:36,321] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:08:45,209] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:08:54,506] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:09:04,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.427978452654862
[2022-12-07 03:09:04,033] [INFO] [runner_train_mujoco] Average state value: 0.3909009301240246
[2022-12-07 03:09:04,033] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 03:09:04,101] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.16720
[2022-12-07 03:09:04,158] [INFO] [controller] EPOCH 2 loss ppo:  -0.03780, loss val: 0.16600
[2022-12-07 03:09:04,209] [INFO] [controller] EPOCH 3 loss ppo:  -0.05583, loss val: 0.16459
[2022-12-07 03:09:04,271] [INFO] [controller] EPOCH 4 loss ppo:  -0.06832, loss val: 0.15265
[2022-12-07 03:09:04,288] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:09:04,519] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:09:04,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:09:14,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:09:23,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:09:32,996] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:09:41,914] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:09:50,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:10:00,504] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:10:10,172] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:10:19,217] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:10:28,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:10:37,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6245185452891193
[2022-12-07 03:10:37,660] [INFO] [runner_train_mujoco] Average state value: 0.5110011571496724
[2022-12-07 03:10:37,660] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 03:10:37,721] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.07165
[2022-12-07 03:10:37,774] [INFO] [controller] EPOCH 2 loss ppo:  -0.04986, loss val: 0.07000
[2022-12-07 03:10:37,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.07201, loss val: 0.07121
[2022-12-07 03:10:37,882] [INFO] [controller] EPOCH 4 loss ppo:  -0.08564, loss val: 0.07066
[2022-12-07 03:10:37,893] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:10:38,119] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:10:38,119] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:10:47,449] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:57,005] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:06,200] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:11:15,510] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:11:23,987] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:11:33,302] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:11:42,872] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:11:52,143] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:12:01,377] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:12:10,196] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5862132685128874
[2022-12-07 03:12:10,196] [INFO] [runner_train_mujoco] Average state value: 0.55651147501419
[2022-12-07 03:12:10,196] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 03:12:10,254] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.06157
[2022-12-07 03:12:10,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.04984, loss val: 0.06078
[2022-12-07 03:12:10,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.07024, loss val: 0.05862
[2022-12-07 03:12:10,424] [INFO] [controller] EPOCH 4 loss ppo:  -0.08253, loss val: 0.05787
[2022-12-07 03:12:10,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:12:10,650] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:12:10,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:12:19,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:12:29,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:12:39,331] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:12:48,705] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:57,712] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:13:06,852] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:13:16,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:13:25,062] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:13:34,802] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:13:43,697] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.490484585387393
[2022-12-07 03:13:43,698] [INFO] [runner_train_mujoco] Average state value: 0.5354285215313236
[2022-12-07 03:13:43,698] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 03:13:43,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.06151
[2022-12-07 03:13:43,878] [INFO] [controller] EPOCH 2 loss ppo:  -0.04941, loss val: 0.06244
[2022-12-07 03:13:43,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.06708, loss val: 0.05936
[2022-12-07 03:13:44,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.07866, loss val: 0.06252
[2022-12-07 03:13:44,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:13:44,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:13:44,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:13:53,037] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:14:02,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:14:11,672] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:14:21,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:14:29,534] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:14:38,726] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:14:47,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:14:56,836] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:15:06,060] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:15:15,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6358603009390305
[2022-12-07 03:15:15,328] [INFO] [runner_train_mujoco] Average state value: 0.5691225338565806
[2022-12-07 03:15:15,328] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 03:15:15,403] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.04949
[2022-12-07 03:15:15,453] [INFO] [controller] EPOCH 2 loss ppo:  -0.04865, loss val: 0.04972
[2022-12-07 03:15:15,501] [INFO] [controller] EPOCH 3 loss ppo:  -0.06599, loss val: 0.04915
[2022-12-07 03:15:15,576] [INFO] [controller] EPOCH 4 loss ppo:  -0.07786, loss val: 0.04717
[2022-12-07 03:15:15,585] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:15:15,808] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:15:15,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:15:25,267] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:15:34,778] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:15:44,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:15:53,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:16:03,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:16:12,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:16:21,146] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:16:29,120] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:16:37,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:16:45,611] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.46253365083115
[2022-12-07 03:16:45,611] [INFO] [runner_train_mujoco] Average state value: 0.5674582277660568
[2022-12-07 03:16:45,611] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 03:16:45,661] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.05258
[2022-12-07 03:16:45,705] [INFO] [controller] EPOCH 2 loss ppo:  -0.04570, loss val: 0.05177
[2022-12-07 03:16:45,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.06382, loss val: 0.04970
[2022-12-07 03:16:45,786] [INFO] [controller] EPOCH 4 loss ppo:  -0.07584, loss val: 0.05002
[2022-12-07 03:16:45,795] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:16:46,003] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:16:46,003] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:16:54,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:17:03,151] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:17:11,654] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:17:19,696] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:17:27,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:17:35,946] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:17:44,005] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:17:52,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:18:00,822] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:18:09,307] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6984006837956105
[2022-12-07 03:18:09,307] [INFO] [runner_train_mujoco] Average state value: 0.5465240762482086
[2022-12-07 03:18:09,307] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 03:18:09,359] [INFO] [controller] EPOCH 1 loss ppo:  -0.01514, loss val: 0.04912
[2022-12-07 03:18:09,405] [INFO] [controller] EPOCH 2 loss ppo:  -0.05019, loss val: 0.04888
[2022-12-07 03:18:09,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.06951, loss val: 0.04764
[2022-12-07 03:18:09,493] [INFO] [controller] EPOCH 4 loss ppo:  -0.08206, loss val: 0.04719
[2022-12-07 03:18:09,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:18:09,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:18:09,708] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:18:17,952] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:18:26,661] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:18:34,887] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:18:42,994] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:18:51,313] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:18:59,713] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:19:08,391] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:19:16,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:19:25,600] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:19:34,074] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4536466864673983
[2022-12-07 03:19:34,074] [INFO] [runner_train_mujoco] Average state value: 0.4914516205489635
[2022-12-07 03:19:34,075] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 03:19:34,177] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04950
[2022-12-07 03:19:34,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.04703, loss val: 0.04933
[2022-12-07 03:19:34,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.06397, loss val: 0.04855
[2022-12-07 03:19:34,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.07832, loss val: 0.04770
[2022-12-07 03:19:34,312] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:19:34,518] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:19:34,518] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:19:43,078] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:19:51,751] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:20:00,282] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:20:08,479] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:20:16,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:20:24,680] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:20:32,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:20:40,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:20:49,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:20:57,622] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4725116733478856
[2022-12-07 03:20:57,623] [INFO] [runner_train_mujoco] Average state value: 0.48040240180244054
[2022-12-07 03:20:57,623] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 03:20:57,680] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.07669
[2022-12-07 03:20:57,727] [INFO] [controller] EPOCH 2 loss ppo:  -0.04306, loss val: 0.07525
[2022-12-07 03:20:57,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.06325, loss val: 0.07343
[2022-12-07 03:20:57,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.07671, loss val: 0.07167
[2022-12-07 03:20:57,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:20:58,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:20:58,041] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:21:07,203] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:21:15,542] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:21:23,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:21:31,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:21:39,717] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:21:47,710] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:21:56,132] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:22:04,328] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:22:12,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:22:20,647] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.494606077176649
[2022-12-07 03:22:20,647] [INFO] [runner_train_mujoco] Average state value: 0.4738947410794597
[2022-12-07 03:22:20,647] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 03:22:20,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.09705
[2022-12-07 03:22:20,743] [INFO] [controller] EPOCH 2 loss ppo:  -0.04742, loss val: 0.09568
[2022-12-07 03:22:20,786] [INFO] [controller] EPOCH 3 loss ppo:  -0.06476, loss val: 0.09524
[2022-12-07 03:22:20,829] [INFO] [controller] EPOCH 4 loss ppo:  -0.07903, loss val: 0.08949
[2022-12-07 03:22:20,838] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:22:21,049] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:22:21,049] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:22:29,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:22:38,100] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:22:46,584] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:22:54,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:23:03,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:23:11,542] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:23:19,481] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:23:27,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:23:35,704] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:23:44,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.764260332397964
[2022-12-07 03:23:44,507] [INFO] [runner_train_mujoco] Average state value: 0.5717553060452144
[2022-12-07 03:23:44,507] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 03:23:44,563] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.05408
[2022-12-07 03:23:44,614] [INFO] [controller] EPOCH 2 loss ppo:  -0.04894, loss val: 0.05175
[2022-12-07 03:23:44,658] [INFO] [controller] EPOCH 3 loss ppo:  -0.06744, loss val: 0.05247
[2022-12-07 03:23:44,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.07925, loss val: 0.05135
[2022-12-07 03:23:44,711] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:23:44,922] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:23:44,923] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:23:53,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:24:01,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:24:10,211] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:24:18,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:24:26,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:24:34,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:24:42,846] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:24:50,996] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:24:59,329] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:25:07,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.379164917630177
[2022-12-07 03:25:07,660] [INFO] [runner_train_mujoco] Average state value: 0.5479342185457547
[2022-12-07 03:25:07,660] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 03:25:07,728] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.05107
[2022-12-07 03:25:07,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.04382, loss val: 0.05118
[2022-12-07 03:25:07,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.06370, loss val: 0.05111
[2022-12-07 03:25:07,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.07969, loss val: 0.04958
[2022-12-07 03:25:07,928] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:25:08,152] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:25:08,152] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:25:16,527] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:25:25,223] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:33,046] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:25:41,421] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:25:49,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:25:58,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:26:05,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:26:13,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:26:22,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:26:30,417] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7035211832923456
[2022-12-07 03:26:30,417] [INFO] [runner_train_mujoco] Average state value: 0.5051456840808193
[2022-12-07 03:26:30,418] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 03:26:30,492] [INFO] [controller] EPOCH 1 loss ppo:  -0.01506, loss val: 0.04425
[2022-12-07 03:26:30,647] [INFO] [controller] EPOCH 2 loss ppo:  -0.04429, loss val: 0.04654
[2022-12-07 03:26:30,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.06011, loss val: 0.04528
[2022-12-07 03:26:30,766] [INFO] [controller] EPOCH 4 loss ppo:  -0.07579, loss val: 0.04159
[2022-12-07 03:26:30,775] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:26:30,966] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:26:30,967] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:26:39,981] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:26:49,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:26:57,272] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:27:05,432] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:27:13,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:27:21,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:27:29,750] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:27:37,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:27:46,634] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:27:55,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5697935197533133
[2022-12-07 03:27:55,018] [INFO] [runner_train_mujoco] Average state value: 0.5149250082398454
[2022-12-07 03:27:55,018] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 03:27:55,076] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.05190
[2022-12-07 03:27:55,120] [INFO] [controller] EPOCH 2 loss ppo:  -0.04414, loss val: 0.05121
[2022-12-07 03:27:55,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.06406, loss val: 0.05058
[2022-12-07 03:27:55,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.07605, loss val: 0.05051
[2022-12-07 03:27:55,220] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:27:55,425] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:27:55,426] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:28:03,252] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:28:11,880] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:28:20,311] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:28:28,202] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:28:36,151] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:28:44,593] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:28:53,195] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:29:01,604] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:29:09,965] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:29:18,143] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8282284603958747
[2022-12-07 03:29:18,143] [INFO] [runner_train_mujoco] Average state value: 0.5688863900353511
[2022-12-07 03:29:18,143] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 03:29:18,198] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.03916
[2022-12-07 03:29:18,243] [INFO] [controller] EPOCH 2 loss ppo:  -0.04230, loss val: 0.03922
[2022-12-07 03:29:18,288] [INFO] [controller] EPOCH 3 loss ppo:  -0.06245, loss val: 0.03878
[2022-12-07 03:29:18,332] [INFO] [controller] EPOCH 4 loss ppo:  -0.07652, loss val: 0.03790
[2022-12-07 03:29:18,341] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:29:18,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:29:18,550] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:29:27,157] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:29:35,594] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:29:45,687] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:29:54,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:30:02,278] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:30:10,299] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:30:18,172] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:30:26,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:30:34,745] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:30:43,583] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7733820402081863
[2022-12-07 03:30:43,584] [INFO] [runner_train_mujoco] Average state value: 0.5190952108105024
[2022-12-07 03:30:43,584] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 03:30:43,641] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.05143
[2022-12-07 03:30:43,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.03915, loss val: 0.04899
[2022-12-07 03:30:43,734] [INFO] [controller] EPOCH 3 loss ppo:  -0.05861, loss val: 0.04344
[2022-12-07 03:30:43,780] [INFO] [controller] EPOCH 4 loss ppo:  -0.07523, loss val: 0.04348
[2022-12-07 03:30:43,792] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:30:44,004] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:30:44,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:30:52,832] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:31:01,383] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:31:09,407] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:31:17,875] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:31:25,843] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:31:33,906] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:31:42,265] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:31:50,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:31:58,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:32:06,972] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.768353145531475
[2022-12-07 03:32:06,973] [INFO] [runner_train_mujoco] Average state value: 0.5013943841954072
[2022-12-07 03:32:06,973] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 03:32:07,026] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.05333
[2022-12-07 03:32:07,071] [INFO] [controller] EPOCH 2 loss ppo:  -0.04301, loss val: 0.05494
[2022-12-07 03:32:07,127] [INFO] [controller] EPOCH 3 loss ppo:  -0.06050, loss val: 0.05406
[2022-12-07 03:32:07,175] [INFO] [controller] EPOCH 4 loss ppo:  -0.07398, loss val: 0.04977
[2022-12-07 03:32:07,185] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:32:07,412] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:32:07,412] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:32:15,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:32:24,060] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:32:32,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:32:41,344] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:32:49,539] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:32:57,155] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:33:05,065] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:33:12,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:33:22,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:33:33,322] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5119921069580944
[2022-12-07 03:33:33,322] [INFO] [runner_train_mujoco] Average state value: 0.5059303376177946
[2022-12-07 03:33:33,322] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 03:33:33,394] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04946
[2022-12-07 03:33:33,451] [INFO] [controller] EPOCH 2 loss ppo:  -0.04533, loss val: 0.04714
[2022-12-07 03:33:33,529] [INFO] [controller] EPOCH 3 loss ppo:  -0.06870, loss val: 0.04826
[2022-12-07 03:33:33,600] [INFO] [controller] EPOCH 4 loss ppo:  -0.08469, loss val: 0.04707
[2022-12-07 03:33:33,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:33:33,840] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:33:33,841] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:33:43,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:33:52,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:34:01,595] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:34:10,444] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:34:19,988] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:34:29,373] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:34:39,001] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:34:48,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:34:58,184] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:35:07,231] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6489523819437835
[2022-12-07 03:35:07,231] [INFO] [runner_train_mujoco] Average state value: 0.5734494656423728
[2022-12-07 03:35:07,231] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 03:35:07,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01505, loss val: 0.05160
[2022-12-07 03:35:07,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.04121, loss val: 0.05140
[2022-12-07 03:35:07,488] [INFO] [controller] EPOCH 3 loss ppo:  -0.05900, loss val: 0.05141
[2022-12-07 03:35:07,556] [INFO] [controller] EPOCH 4 loss ppo:  -0.07420, loss val: 0.04802
[2022-12-07 03:35:07,566] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:35:07,793] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:35:07,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:35:16,702] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:35:25,858] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:35:34,809] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:35:44,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:35:53,562] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:36:02,391] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:36:11,314] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:36:20,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:36:29,475] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:36:38,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.619037862939487
[2022-12-07 03:36:38,468] [INFO] [runner_train_mujoco] Average state value: 0.5488633192876975
[2022-12-07 03:36:38,468] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 03:36:38,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.04220
[2022-12-07 03:36:38,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.04268, loss val: 0.04401
[2022-12-07 03:36:38,619] [INFO] [controller] EPOCH 3 loss ppo:  -0.06255, loss val: 0.04430
[2022-12-07 03:36:38,673] [INFO] [controller] EPOCH 4 loss ppo:  -0.07940, loss val: 0.04438
[2022-12-07 03:36:38,684] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:36:38,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:36:38,899] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:36:48,370] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:36:57,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:37:06,296] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:37:15,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:37:24,634] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:37:33,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:37:41,923] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:37:51,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:38:00,998] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:38:09,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4665350379162996
[2022-12-07 03:38:09,636] [INFO] [runner_train_mujoco] Average state value: 0.5314645552039147
[2022-12-07 03:38:09,636] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 03:38:09,690] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.04567
[2022-12-07 03:38:09,735] [INFO] [controller] EPOCH 2 loss ppo:  -0.04561, loss val: 0.04402
[2022-12-07 03:38:09,787] [INFO] [controller] EPOCH 3 loss ppo:  -0.06542, loss val: 0.04559
[2022-12-07 03:38:09,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.08093, loss val: 0.04409
[2022-12-07 03:38:09,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:38:10,061] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:38:10,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:38:19,543] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:38:28,882] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:38:37,562] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:38:46,491] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:38:55,570] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:39:04,362] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:39:13,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:39:21,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:39:30,868] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:39:40,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5772859442595628
[2022-12-07 03:39:40,108] [INFO] [runner_train_mujoco] Average state value: 0.5559952767491341
[2022-12-07 03:39:40,109] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 03:39:40,167] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.04175
[2022-12-07 03:39:40,221] [INFO] [controller] EPOCH 2 loss ppo:  -0.03876, loss val: 0.04362
[2022-12-07 03:39:40,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.05930, loss val: 0.04080
[2022-12-07 03:39:40,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.07688, loss val: 0.03900
[2022-12-07 03:39:40,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:39:40,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:39:40,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:39:49,640] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:39:58,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:40:07,580] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:40:16,599] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:40:24,792] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:40:33,740] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:40:42,948] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:40:52,258] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:41:01,311] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:41:10,226] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5933866201561113
[2022-12-07 03:41:10,226] [INFO] [runner_train_mujoco] Average state value: 0.5267161657214163
[2022-12-07 03:41:10,226] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 03:41:10,297] [INFO] [controller] EPOCH 1 loss ppo:  -0.01571, loss val: 0.03976
[2022-12-07 03:41:10,352] [INFO] [controller] EPOCH 2 loss ppo:  -0.04036, loss val: 0.03973
[2022-12-07 03:41:10,398] [INFO] [controller] EPOCH 3 loss ppo:  -0.06106, loss val: 0.03812
[2022-12-07 03:41:10,446] [INFO] [controller] EPOCH 4 loss ppo:  -0.07778, loss val: 0.04014
[2022-12-07 03:41:10,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:41:10,675] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:41:10,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:41:19,723] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:41:28,771] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:41:37,804] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:41:47,195] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:41:56,127] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:42:05,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:42:14,675] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:42:23,641] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:42:31,933] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:42:40,243] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4703329929011208
[2022-12-07 03:42:40,243] [INFO] [runner_train_mujoco] Average state value: 0.47473394836982086
[2022-12-07 03:42:40,243] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 03:42:40,297] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04233
[2022-12-07 03:42:40,345] [INFO] [controller] EPOCH 2 loss ppo:  -0.03401, loss val: 0.04313
[2022-12-07 03:42:40,387] [INFO] [controller] EPOCH 3 loss ppo:  -0.05628, loss val: 0.04096
[2022-12-07 03:42:40,438] [INFO] [controller] EPOCH 4 loss ppo:  -0.07293, loss val: 0.04096
[2022-12-07 03:42:40,448] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:42:40,669] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:42:40,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:42:49,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:42:57,347] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:43:05,820] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:43:14,129] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:43:22,722] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:43:30,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:43:38,935] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:43:46,748] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:43:54,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:44:03,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.725933015477242
[2022-12-07 03:44:03,173] [INFO] [runner_train_mujoco] Average state value: 0.4802733755310376
[2022-12-07 03:44:03,173] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 03:44:03,226] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04283
[2022-12-07 03:44:03,274] [INFO] [controller] EPOCH 2 loss ppo:  -0.04023, loss val: 0.04651
[2022-12-07 03:44:03,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.06247, loss val: 0.04045
[2022-12-07 03:44:03,375] [INFO] [controller] EPOCH 4 loss ppo:  -0.08136, loss val: 0.04034
[2022-12-07 03:44:03,385] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:44:03,604] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:44:03,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:44:12,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:44:20,605] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:44:28,310] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:44:35,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:44:43,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:44:52,387] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:45:00,180] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:45:07,232] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:45:14,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:45:21,680] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6565394894533891
[2022-12-07 03:45:21,680] [INFO] [runner_train_mujoco] Average state value: 0.519221864109238
[2022-12-07 03:45:21,680] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 03:45:21,729] [INFO] [controller] EPOCH 1 loss ppo:  -0.01609, loss val: 0.04465
[2022-12-07 03:45:21,764] [INFO] [controller] EPOCH 2 loss ppo:  -0.03903, loss val: 0.04465
[2022-12-07 03:45:21,803] [INFO] [controller] EPOCH 3 loss ppo:  -0.05651, loss val: 0.04443
[2022-12-07 03:45:21,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.06902, loss val: 0.04285
[2022-12-07 03:45:21,851] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:45:22,055] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:45:22,055] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:45:29,410] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:45:36,718] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:45:44,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:45:51,688] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:45:59,054] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:46:06,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:46:13,696] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:46:20,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:46:27,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:46:35,157] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7086935290075806
[2022-12-07 03:46:35,157] [INFO] [runner_train_mujoco] Average state value: 0.509532740910848
[2022-12-07 03:46:35,157] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 03:46:35,206] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.03808
[2022-12-07 03:46:35,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.03840, loss val: 0.03843
[2022-12-07 03:46:35,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.05837, loss val: 0.03888
[2022-12-07 03:46:35,331] [INFO] [controller] EPOCH 4 loss ppo:  -0.07541, loss val: 0.03740
[2022-12-07 03:46:35,340] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:46:35,543] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:46:35,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:46:43,498] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:46:52,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:46:59,267] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:47:06,602] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:47:14,041] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:47:21,243] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:47:28,268] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:47:35,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:47:42,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:47:50,225] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7439827164818227
[2022-12-07 03:47:50,225] [INFO] [runner_train_mujoco] Average state value: 0.47781621060768764
[2022-12-07 03:47:50,225] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 03:47:50,284] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.04467
[2022-12-07 03:47:50,327] [INFO] [controller] EPOCH 2 loss ppo:  -0.04057, loss val: 0.04467
[2022-12-07 03:47:50,370] [INFO] [controller] EPOCH 3 loss ppo:  -0.06140, loss val: 0.04345
[2022-12-07 03:47:50,411] [INFO] [controller] EPOCH 4 loss ppo:  -0.07702, loss val: 0.04518
[2022-12-07 03:47:50,421] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:47:50,636] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:47:50,637] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:47:57,807] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:48:05,635] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:48:12,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:48:20,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:48:27,358] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:48:34,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:48:41,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:48:48,302] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:48:55,993] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:49:03,227] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0063596949548748
[2022-12-07 03:49:03,227] [INFO] [runner_train_mujoco] Average state value: 0.48695105453332266
[2022-12-07 03:49:03,227] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 03:49:03,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.05994
[2022-12-07 03:49:03,320] [INFO] [controller] EPOCH 2 loss ppo:  -0.03229, loss val: 0.05956
[2022-12-07 03:49:03,366] [INFO] [controller] EPOCH 3 loss ppo:  -0.05075, loss val: 0.05257
[2022-12-07 03:49:03,408] [INFO] [controller] EPOCH 4 loss ppo:  -0.06492, loss val: 0.05012
[2022-12-07 03:49:03,417] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:49:03,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:49:03,606] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:49:11,200] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:49:18,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:49:25,421] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:49:32,482] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:49:39,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:49:47,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:49:54,501] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:50:01,526] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:50:08,751] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:50:15,891] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9826890367666863
[2022-12-07 03:50:15,891] [INFO] [runner_train_mujoco] Average state value: 0.4939209390729665
[2022-12-07 03:50:15,891] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 03:50:15,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.04271
[2022-12-07 03:50:16,029] [INFO] [controller] EPOCH 2 loss ppo:  -0.03745, loss val: 0.04183
[2022-12-07 03:50:16,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.05841, loss val: 0.04049
[2022-12-07 03:50:16,110] [INFO] [controller] EPOCH 4 loss ppo:  -0.07497, loss val: 0.03964
[2022-12-07 03:50:16,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:50:16,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:50:16,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:50:23,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:50:30,651] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:50:38,154] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:50:45,366] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:50:52,804] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:50:59,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:51:06,938] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:51:13,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:51:21,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:51:28,772] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5197639413742252
[2022-12-07 03:51:28,772] [INFO] [runner_train_mujoco] Average state value: 0.5323244223296641
[2022-12-07 03:51:28,772] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 03:51:28,825] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.03912
[2022-12-07 03:51:28,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.03426, loss val: 0.03922
[2022-12-07 03:51:28,907] [INFO] [controller] EPOCH 3 loss ppo:  -0.05455, loss val: 0.03787
[2022-12-07 03:51:28,952] [INFO] [controller] EPOCH 4 loss ppo:  -0.06713, loss val: 0.03697
[2022-12-07 03:51:28,962] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:51:29,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:51:29,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:51:36,698] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:51:44,155] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:51:51,395] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:51:58,638] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:52:05,942] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:52:13,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:52:20,520] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:52:28,086] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:52:35,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:52:42,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6724671104689004
[2022-12-07 03:52:42,660] [INFO] [runner_train_mujoco] Average state value: 0.5592470715939999
[2022-12-07 03:52:42,660] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 03:52:42,707] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.03453
[2022-12-07 03:52:42,747] [INFO] [controller] EPOCH 2 loss ppo:  -0.03439, loss val: 0.03264
[2022-12-07 03:52:42,782] [INFO] [controller] EPOCH 3 loss ppo:  -0.05444, loss val: 0.03143
[2022-12-07 03:52:42,822] [INFO] [controller] EPOCH 4 loss ppo:  -0.06751, loss val: 0.03035
[2022-12-07 03:52:42,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:52:43,035] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:52:43,036] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:52:49,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:52:57,659] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:53:05,340] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:53:12,270] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:53:19,223] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:53:26,435] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:53:33,449] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:53:40,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:53:47,902] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:53:55,219] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8418831551992625
[2022-12-07 03:53:55,220] [INFO] [runner_train_mujoco] Average state value: 0.6027754983703295
[2022-12-07 03:53:55,220] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 03:53:55,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.04447
[2022-12-07 03:53:55,316] [INFO] [controller] EPOCH 2 loss ppo:  -0.03129, loss val: 0.04476
[2022-12-07 03:53:55,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.05060, loss val: 0.04680
[2022-12-07 03:53:55,396] [INFO] [controller] EPOCH 4 loss ppo:  -0.06616, loss val: 0.04498
[2022-12-07 03:53:55,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:53:55,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:53:55,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:54:02,674] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:54:10,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:54:17,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:54:24,294] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:54:31,851] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:54:39,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:54:45,930] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:54:53,016] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:55:00,263] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:55:07,268] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5623038385132424
[2022-12-07 03:55:07,268] [INFO] [runner_train_mujoco] Average state value: 0.5974581071535747
[2022-12-07 03:55:07,268] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 03:55:07,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04690
[2022-12-07 03:55:07,359] [INFO] [controller] EPOCH 2 loss ppo:  -0.02838, loss val: 0.04489
[2022-12-07 03:55:07,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.04730, loss val: 0.04407
[2022-12-07 03:55:07,441] [INFO] [controller] EPOCH 4 loss ppo:  -0.06304, loss val: 0.04203
[2022-12-07 03:55:07,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:55:07,650] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:55:07,651] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:55:15,291] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:55:23,107] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:55:30,544] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:55:37,712] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:55:44,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:55:51,566] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:55:58,655] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:56:06,323] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:56:14,174] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:56:21,145] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4083357491000075
[2022-12-07 03:56:21,145] [INFO] [runner_train_mujoco] Average state value: 0.5617587907115618
[2022-12-07 03:56:21,145] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 03:56:21,193] [INFO] [controller] EPOCH 1 loss ppo:  -0.01279, loss val: 0.03604
[2022-12-07 03:56:21,232] [INFO] [controller] EPOCH 2 loss ppo:  -0.03243, loss val: 0.03561
[2022-12-07 03:56:21,271] [INFO] [controller] EPOCH 3 loss ppo:  -0.05207, loss val: 0.03513
[2022-12-07 03:56:21,312] [INFO] [controller] EPOCH 4 loss ppo:  -0.06554, loss val: 0.03549
[2022-12-07 03:56:21,321] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:56:21,512] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:56:21,512] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:56:28,916] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:56:36,218] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:56:43,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:56:50,459] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:56:57,710] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:57:05,199] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:57:12,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:57:19,530] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:57:26,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:57:33,610] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.93118618860601
[2022-12-07 03:57:33,610] [INFO] [runner_train_mujoco] Average state value: 0.5325910313526789
[2022-12-07 03:57:33,610] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 03:57:33,655] [INFO] [controller] EPOCH 1 loss ppo:  -0.01518, loss val: 0.03416
[2022-12-07 03:57:33,689] [INFO] [controller] EPOCH 2 loss ppo:  -0.03408, loss val: 0.03384
[2022-12-07 03:57:33,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.05136, loss val: 0.03397
[2022-12-07 03:57:33,761] [INFO] [controller] EPOCH 4 loss ppo:  -0.06402, loss val: 0.03424
[2022-12-07 03:57:33,770] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:57:33,951] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:57:33,951] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:57:41,889] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:57:50,225] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:57:57,610] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:58:04,549] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:58:11,845] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:58:19,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:58:26,743] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:58:33,868] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:58:41,285] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:58:48,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6515128837448927
[2022-12-07 03:58:48,344] [INFO] [runner_train_mujoco] Average state value: 0.519375453352928
[2022-12-07 03:58:48,344] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 03:58:48,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.04281
[2022-12-07 03:58:48,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.02900, loss val: 0.04273
[2022-12-07 03:58:48,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.04719, loss val: 0.04421
[2022-12-07 03:58:48,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.06130, loss val: 0.04108
[2022-12-07 03:58:48,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:58:48,721] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:58:48,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:58:56,192] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:59:03,635] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:59:10,750] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:59:17,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:59:25,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:59:32,029] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:59:39,293] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:59:47,013] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:59:54,304] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:00:01,929] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9456984535104618
[2022-12-07 04:00:01,929] [INFO] [runner_train_mujoco] Average state value: 0.5063382610678673
[2022-12-07 04:00:01,929] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 04:00:01,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.04488
[2022-12-07 04:00:02,016] [INFO] [controller] EPOCH 2 loss ppo:  -0.03337, loss val: 0.04232
[2022-12-07 04:00:02,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.05318, loss val: 0.04747
[2022-12-07 04:00:02,094] [INFO] [controller] EPOCH 4 loss ppo:  -0.06668, loss val: 0.04612
[2022-12-07 04:00:02,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:00:02,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:00:02,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:00:10,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:00:17,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:00:24,313] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:00:30,990] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:00:37,901] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:00:45,088] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:00:52,506] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:00:59,786] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:01:07,101] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:01:14,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.755353238088902
[2022-12-07 04:01:14,365] [INFO] [runner_train_mujoco] Average state value: 0.4880849057336648
[2022-12-07 04:01:14,365] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 04:01:14,421] [INFO] [controller] EPOCH 1 loss ppo:  -0.01498, loss val: 0.05770
[2022-12-07 04:01:14,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.02629, loss val: 0.05728
[2022-12-07 04:01:14,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.04226, loss val: 0.05660
[2022-12-07 04:01:14,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.05622, loss val: 0.05547
[2022-12-07 04:01:14,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:01:14,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:01:14,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:01:22,046] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:01:29,282] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:01:36,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:01:44,328] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:01:51,463] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:01:58,372] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:02:05,554] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:02:12,692] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:02:19,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:02:27,554] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6752083446681894
[2022-12-07 04:02:27,555] [INFO] [runner_train_mujoco] Average state value: 0.5008343791067601
[2022-12-07 04:02:27,555] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 04:02:27,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.01571, loss val: 0.03928
[2022-12-07 04:02:27,647] [INFO] [controller] EPOCH 2 loss ppo:  -0.03268, loss val: 0.03939
[2022-12-07 04:02:27,691] [INFO] [controller] EPOCH 3 loss ppo:  -0.05257, loss val: 0.03880
[2022-12-07 04:02:27,734] [INFO] [controller] EPOCH 4 loss ppo:  -0.06840, loss val: 0.04182
[2022-12-07 04:02:27,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:02:27,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:02:27,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:02:35,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:02:42,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:02:49,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:02:56,512] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:03:03,647] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:03:10,966] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:03:18,133] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:03:25,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:03:32,839] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:03:40,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.556124703589556
[2022-12-07 04:03:40,219] [INFO] [runner_train_mujoco] Average state value: 0.5234478008945783
[2022-12-07 04:03:40,219] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 04:03:40,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.03858
[2022-12-07 04:03:40,355] [INFO] [controller] EPOCH 2 loss ppo:  -0.02652, loss val: 0.03928
[2022-12-07 04:03:40,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.03857
[2022-12-07 04:03:40,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.05862, loss val: 0.03825
[2022-12-07 04:03:40,461] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:03:40,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:03:40,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:03:47,938] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:03:55,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:04:02,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:04:10,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:04:17,418] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:04:24,974] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:04:32,042] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:04:39,789] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:04:47,206] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:04:54,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.722128470953513
[2022-12-07 04:04:54,384] [INFO] [runner_train_mujoco] Average state value: 0.521582781692346
[2022-12-07 04:04:54,384] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 04:04:54,436] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.04197
[2022-12-07 04:04:54,478] [INFO] [controller] EPOCH 2 loss ppo:  -0.02934, loss val: 0.04009
[2022-12-07 04:04:54,520] [INFO] [controller] EPOCH 3 loss ppo:  -0.04704, loss val: 0.04128
[2022-12-07 04:04:54,564] [INFO] [controller] EPOCH 4 loss ppo:  -0.06068, loss val: 0.04046
[2022-12-07 04:04:54,573] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:04:54,778] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:04:54,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:05:02,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:05:09,600] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:05:16,736] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:05:23,873] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:05:31,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:05:38,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:05:45,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:05:52,808] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:06:00,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:06:07,763] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5340600247952614
[2022-12-07 04:06:07,763] [INFO] [runner_train_mujoco] Average state value: 0.5294619746406873
[2022-12-07 04:06:07,763] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 04:06:07,807] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.04362
[2022-12-07 04:06:07,858] [INFO] [controller] EPOCH 2 loss ppo:  -0.02444, loss val: 0.04320
[2022-12-07 04:06:07,903] [INFO] [controller] EPOCH 3 loss ppo:  -0.04113, loss val: 0.04500
[2022-12-07 04:06:07,947] [INFO] [controller] EPOCH 4 loss ppo:  -0.05539, loss val: 0.04312
[2022-12-07 04:06:07,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:06:08,156] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:06:08,157] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:06:15,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:06:22,835] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:06:29,815] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:06:36,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:06:44,012] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:06:51,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:06:58,723] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:07:08,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:07:16,108] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:07:23,428] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5546462250849455
[2022-12-07 04:07:23,428] [INFO] [runner_train_mujoco] Average state value: 0.536869286775589
[2022-12-07 04:07:23,428] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 04:07:23,475] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.05231
[2022-12-07 04:07:23,512] [INFO] [controller] EPOCH 2 loss ppo:  -0.02348, loss val: 0.05166
[2022-12-07 04:07:23,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.03733, loss val: 0.05113
[2022-12-07 04:07:23,591] [INFO] [controller] EPOCH 4 loss ppo:  -0.04967, loss val: 0.05102
[2022-12-07 04:07:23,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:07:23,777] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:07:23,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:07:30,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:07:37,709] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:07:44,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:07:52,231] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:07:59,493] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:08:07,200] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:08:14,344] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:08:21,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:08:28,584] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:08:35,761] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0463511481580254
[2022-12-07 04:08:35,761] [INFO] [runner_train_mujoco] Average state value: 0.5257920349041622
[2022-12-07 04:08:35,761] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 04:08:35,810] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.03523
[2022-12-07 04:08:35,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.02129, loss val: 0.03601
[2022-12-07 04:08:35,885] [INFO] [controller] EPOCH 3 loss ppo:  -0.03520, loss val: 0.03640
[2022-12-07 04:08:35,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.04843, loss val: 0.03627
[2022-12-07 04:08:35,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:08:36,130] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:08:36,130] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:08:43,446] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:08:50,796] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:08:57,999] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:09:04,854] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:09:12,268] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:09:19,957] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:09:27,053] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:09:34,240] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:09:41,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:09:48,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7506714194419317
[2022-12-07 04:09:48,440] [INFO] [runner_train_mujoco] Average state value: 0.5158682807087898
[2022-12-07 04:09:48,441] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 04:09:48,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.02774
[2022-12-07 04:09:48,533] [INFO] [controller] EPOCH 2 loss ppo:  -0.02073, loss val: 0.02799
[2022-12-07 04:09:48,573] [INFO] [controller] EPOCH 3 loss ppo:  -0.03253, loss val: 0.03027
[2022-12-07 04:09:48,609] [INFO] [controller] EPOCH 4 loss ppo:  -0.04522, loss val: 0.03056
[2022-12-07 04:09:48,618] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:09:48,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:09:48,814] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:09:56,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:10:03,544] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:10:10,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:10:17,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:10:24,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:10:32,198] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:10:39,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:10:46,833] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:10:53,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:11:00,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8096962014932263
[2022-12-07 04:11:00,847] [INFO] [runner_train_mujoco] Average state value: 0.5127091319958368
[2022-12-07 04:11:00,847] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 04:11:00,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.02676
[2022-12-07 04:11:00,935] [INFO] [controller] EPOCH 2 loss ppo:  -0.02243, loss val: 0.02903
[2022-12-07 04:11:00,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.03455, loss val: 0.02762
[2022-12-07 04:11:01,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.04708, loss val: 0.03042
[2022-12-07 04:11:01,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:11:01,253] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:11:01,253] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:11:08,390] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:11:15,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:11:22,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:11:29,540] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:11:37,452] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:11:45,073] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:11:51,868] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:11:58,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:12:06,046] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:12:13,402] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7251829192151706
[2022-12-07 04:12:13,402] [INFO] [runner_train_mujoco] Average state value: 0.5151318202813467
[2022-12-07 04:12:13,403] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 04:12:13,449] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.03331
[2022-12-07 04:12:13,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.01948, loss val: 0.03200
[2022-12-07 04:12:13,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.02860, loss val: 0.03241
[2022-12-07 04:12:13,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.03984, loss val: 0.03211
[2022-12-07 04:12:13,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:12:13,757] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:12:13,757] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:12:21,248] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:12:28,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:12:35,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:12:42,666] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:12:49,902] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:12:57,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:13:04,428] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:13:11,402] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:13:18,577] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:13:25,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9710810732765378
[2022-12-07 04:13:25,515] [INFO] [runner_train_mujoco] Average state value: 0.5166248918573062
[2022-12-07 04:13:25,515] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 04:13:25,576] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.02863
[2022-12-07 04:13:25,620] [INFO] [controller] EPOCH 2 loss ppo:  -0.01910, loss val: 0.02840
[2022-12-07 04:13:25,662] [INFO] [controller] EPOCH 3 loss ppo:  -0.02642, loss val: 0.02840
[2022-12-07 04:13:25,705] [INFO] [controller] EPOCH 4 loss ppo:  -0.03639, loss val: 0.02896
[2022-12-07 04:13:25,713] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:13:25,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:13:25,899] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:13:32,847] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:13:40,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:13:47,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:13:54,646] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:14:02,023] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:14:09,486] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:14:16,563] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:14:23,743] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:14:31,025] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:14:38,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7951044659510444
[2022-12-07 04:14:38,727] [INFO] [runner_train_mujoco] Average state value: 0.5202359414895376
[2022-12-07 04:14:38,727] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 04:14:38,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.03829
[2022-12-07 04:14:38,818] [INFO] [controller] EPOCH 2 loss ppo:  -0.01791, loss val: 0.03718
[2022-12-07 04:14:38,861] [INFO] [controller] EPOCH 3 loss ppo:  -0.02338, loss val: 0.03801
[2022-12-07 04:14:38,904] [INFO] [controller] EPOCH 4 loss ppo:  -0.03008, loss val: 0.03946
[2022-12-07 04:14:38,912] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:14:39,113] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:14:39,113] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:14:46,221] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:14:53,443] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:15:00,854] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:15:08,592] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:15:16,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:15:23,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:15:30,051] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:15:37,039] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:15:44,624] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:15:51,771] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8391314815401791
[2022-12-07 04:15:51,771] [INFO] [runner_train_mujoco] Average state value: 0.5180602323710918
[2022-12-07 04:15:51,771] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 04:15:51,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.02701
[2022-12-07 04:15:51,874] [INFO] [controller] EPOCH 2 loss ppo:  -0.01545, loss val: 0.02878
[2022-12-07 04:15:51,922] [INFO] [controller] EPOCH 3 loss ppo:  -0.01759, loss val: 0.02682
[2022-12-07 04:15:51,965] [INFO] [controller] EPOCH 4 loss ppo:  -0.02054, loss val: 0.02702
[2022-12-07 04:15:51,974] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:15:52,087] [INFO] [optimize] Finished learning.
