[2022-12-07 10:49:47,727] [INFO] [optimize] Starting learning
[2022-12-07 10:49:47,740] [INFO] [optimize] Starting learning process..
[2022-12-07 10:49:47,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:49:47,867] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:50:00,167] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:50:09,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:50:17,970] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:50:27,275] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:50:37,145] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:50:50,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:51:00,278] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:51:09,866] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:51:19,146] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:51:28,874] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5139356083390554
[2022-12-07 10:51:28,874] [INFO] [runner_train_mujoco] Average state value: -0.22414594893654188
[2022-12-07 10:51:28,874] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 10:51:28,946] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.62405
[2022-12-07 10:51:29,000] [INFO] [controller] EPOCH 2 loss ppo:  -0.05690, loss val: 0.55895
[2022-12-07 10:51:29,070] [INFO] [controller] EPOCH 3 loss ppo:  -0.07652, loss val: 0.51691
[2022-12-07 10:51:29,126] [INFO] [controller] EPOCH 4 loss ppo:  -0.08956, loss val: 0.44537
[2022-12-07 10:51:29,140] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:51:29,362] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:51:29,363] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:51:39,392] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:51:48,954] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:51:57,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:52:06,640] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:52:16,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:52:26,690] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:52:37,370] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:52:47,816] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:52:57,301] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:53:06,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4747223407951824
[2022-12-07 10:53:06,331] [INFO] [runner_train_mujoco] Average state value: -0.055873352135221155
[2022-12-07 10:53:06,331] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 10:53:06,396] [INFO] [controller] EPOCH 1 loss ppo:  -0.01550, loss val: 0.49990
[2022-12-07 10:53:06,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.05307, loss val: 0.45587
[2022-12-07 10:53:06,516] [INFO] [controller] EPOCH 3 loss ppo:  -0.07535, loss val: 0.40560
[2022-12-07 10:53:06,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.08935, loss val: 0.37993
[2022-12-07 10:53:06,602] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:53:06,824] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:53:06,825] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:53:16,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:53:25,665] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:53:35,665] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:53:45,998] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:53:55,580] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:54:04,275] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:54:12,978] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:54:21,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:54:30,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:54:40,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4351689293493144
[2022-12-07 10:54:40,014] [INFO] [runner_train_mujoco] Average state value: 0.057998489286750554
[2022-12-07 10:54:40,014] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 10:54:40,077] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.26054
[2022-12-07 10:54:40,125] [INFO] [controller] EPOCH 2 loss ppo:  -0.05229, loss val: 0.23260
[2022-12-07 10:54:40,171] [INFO] [controller] EPOCH 3 loss ppo:  -0.07110, loss val: 0.20442
[2022-12-07 10:54:40,218] [INFO] [controller] EPOCH 4 loss ppo:  -0.08516, loss val: 0.17636
[2022-12-07 10:54:40,230] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:54:40,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:54:40,455] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:54:49,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:54:58,642] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:55:07,033] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:55:15,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:55:24,664] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:55:33,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:55:42,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:55:51,600] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:56:00,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:56:09,051] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4116215848584406
[2022-12-07 10:56:09,052] [INFO] [runner_train_mujoco] Average state value: 0.1832911733041207
[2022-12-07 10:56:09,052] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 10:56:09,170] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.20634
[2022-12-07 10:56:09,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.04704, loss val: 0.19023
[2022-12-07 10:56:09,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.06665, loss val: 0.16831
[2022-12-07 10:56:09,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.07938, loss val: 0.15504
[2022-12-07 10:56:09,321] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:56:09,547] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:56:09,547] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:56:19,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:56:30,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:56:39,515] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:56:48,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:56:57,418] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:57:06,383] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:57:14,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:57:23,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:57:31,695] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:57:41,800] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6306894409680481
[2022-12-07 10:57:41,800] [INFO] [runner_train_mujoco] Average state value: 0.29139334237451353
[2022-12-07 10:57:41,800] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 10:57:41,872] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.09351
[2022-12-07 10:57:41,946] [INFO] [controller] EPOCH 2 loss ppo:  -0.05062, loss val: 0.08052
[2022-12-07 10:57:42,016] [INFO] [controller] EPOCH 3 loss ppo:  -0.07280, loss val: 0.06968
[2022-12-07 10:57:42,075] [INFO] [controller] EPOCH 4 loss ppo:  -0.08232, loss val: 0.06360
[2022-12-07 10:57:42,087] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:57:42,330] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:57:42,331] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:57:51,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:58:01,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:58:13,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:58:22,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:58:31,480] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:58:40,329] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:58:50,875] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:59:00,332] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:59:10,413] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:59:22,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4914304983135964
[2022-12-07 10:59:22,676] [INFO] [runner_train_mujoco] Average state value: 0.43975460294137403
[2022-12-07 10:59:22,676] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 10:59:22,751] [INFO] [controller] EPOCH 1 loss ppo:  -0.01658, loss val: 0.06580
[2022-12-07 10:59:22,804] [INFO] [controller] EPOCH 2 loss ppo:  -0.05805, loss val: 0.06204
[2022-12-07 10:59:22,888] [INFO] [controller] EPOCH 3 loss ppo:  -0.07637, loss val: 0.05494
[2022-12-07 10:59:22,955] [INFO] [controller] EPOCH 4 loss ppo:  -0.08832, loss val: 0.05293
[2022-12-07 10:59:22,966] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:59:23,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:59:23,215] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:59:35,276] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:59:46,306] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:59:57,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:00:08,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:00:20,217] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:00:32,233] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:00:44,071] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:00:55,861] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:01:07,330] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:01:18,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4356764714203252
[2022-12-07 11:01:18,426] [INFO] [runner_train_mujoco] Average state value: 0.47453439150253923
[2022-12-07 11:01:18,426] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 11:01:18,503] [INFO] [controller] EPOCH 1 loss ppo:  -0.01214, loss val: 0.07794
[2022-12-07 11:01:18,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.05108, loss val: 0.07643
[2022-12-07 11:01:18,643] [INFO] [controller] EPOCH 3 loss ppo:  -0.07020, loss val: 0.07530
[2022-12-07 11:01:18,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.08032, loss val: 0.07324
[2022-12-07 11:01:18,727] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:01:18,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:01:18,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:01:31,153] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:01:44,700] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:01:56,759] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:02:09,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:02:21,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:02:33,950] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:02:45,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:02:57,374] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:03:09,209] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:03:20,779] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6631716711127915
[2022-12-07 11:03:20,779] [INFO] [runner_train_mujoco] Average state value: 0.5525445120769242
[2022-12-07 11:03:20,779] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 11:03:20,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.05643
[2022-12-07 11:03:20,950] [INFO] [controller] EPOCH 2 loss ppo:  -0.05499, loss val: 0.05588
[2022-12-07 11:03:21,016] [INFO] [controller] EPOCH 3 loss ppo:  -0.07189, loss val: 0.05472
[2022-12-07 11:03:21,080] [INFO] [controller] EPOCH 4 loss ppo:  -0.08246, loss val: 0.05305
[2022-12-07 11:03:21,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:03:21,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:03:21,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:03:32,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:03:44,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:03:56,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:04:08,341] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:04:19,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:04:30,887] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:04:41,896] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:04:52,463] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:05:03,200] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:05:13,855] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3490455632606857
[2022-12-07 11:05:13,855] [INFO] [runner_train_mujoco] Average state value: 0.5439160257900755
[2022-12-07 11:05:13,856] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 11:05:13,918] [INFO] [controller] EPOCH 1 loss ppo:  -0.01500, loss val: 0.05002
[2022-12-07 11:05:13,980] [INFO] [controller] EPOCH 2 loss ppo:  -0.05111, loss val: 0.04783
[2022-12-07 11:05:14,032] [INFO] [controller] EPOCH 3 loss ppo:  -0.07038, loss val: 0.04706
[2022-12-07 11:05:14,085] [INFO] [controller] EPOCH 4 loss ppo:  -0.08247, loss val: 0.04787
[2022-12-07 11:05:14,097] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:05:14,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:05:14,342] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:05:25,926] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:05:36,995] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:05:46,885] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:05:57,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:06:08,418] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:06:19,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:06:30,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:06:41,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:06:52,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:07:04,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3364964025621127
[2022-12-07 11:07:04,483] [INFO] [runner_train_mujoco] Average state value: 0.5103607541508973
[2022-12-07 11:07:04,484] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 11:07:04,793] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.07793
[2022-12-07 11:07:05,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.04156, loss val: 0.07536
[2022-12-07 11:07:05,394] [INFO] [controller] EPOCH 3 loss ppo:  -0.05878, loss val: 0.07271
[2022-12-07 11:07:05,663] [INFO] [controller] EPOCH 4 loss ppo:  -0.07143, loss val: 0.06604
[2022-12-07 11:07:05,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:07:05,947] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:07:05,948] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:07:20,254] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:07:34,471] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:07:46,871] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:07:58,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:08:10,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:08:22,602] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:08:35,047] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:08:47,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:09:00,048] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:09:12,049] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.625372335001133
[2022-12-07 11:09:12,050] [INFO] [runner_train_mujoco] Average state value: 0.543252506395181
[2022-12-07 11:09:12,050] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 11:09:12,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.06849
[2022-12-07 11:09:12,215] [INFO] [controller] EPOCH 2 loss ppo:  -0.04635, loss val: 0.07158
[2022-12-07 11:09:12,273] [INFO] [controller] EPOCH 3 loss ppo:  -0.07108, loss val: 0.06950
[2022-12-07 11:09:12,365] [INFO] [controller] EPOCH 4 loss ppo:  -0.08360, loss val: 0.06770
[2022-12-07 11:09:12,382] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:09:12,684] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:09:12,684] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:09:25,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:09:39,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:09:51,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:10:03,204] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:10:14,601] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:10:25,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:10:37,084] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:10:48,347] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:10:59,176] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:11:11,712] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.453180055979572
[2022-12-07 11:11:11,712] [INFO] [runner_train_mujoco] Average state value: 0.563064560033381
[2022-12-07 11:11:11,712] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 11:11:11,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.05367
[2022-12-07 11:11:11,907] [INFO] [controller] EPOCH 2 loss ppo:  -0.05233, loss val: 0.05223
[2022-12-07 11:11:12,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.07067, loss val: 0.05174
[2022-12-07 11:11:12,258] [INFO] [controller] EPOCH 4 loss ppo:  -0.08392, loss val: 0.05173
[2022-12-07 11:11:12,276] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:11:12,604] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:11:12,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:11:24,756] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:11:35,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:11:47,003] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:11:58,496] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:12:09,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:12:18,518] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:12:27,440] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:12:36,517] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:12:45,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:12:55,398] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6707215924115704
[2022-12-07 11:12:55,398] [INFO] [runner_train_mujoco] Average state value: 0.4662966490934292
[2022-12-07 11:12:55,398] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 11:12:55,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.08947
[2022-12-07 11:12:55,508] [INFO] [controller] EPOCH 2 loss ppo:  -0.04943, loss val: 0.08818
[2022-12-07 11:12:55,568] [INFO] [controller] EPOCH 3 loss ppo:  -0.07098, loss val: 0.08348
[2022-12-07 11:12:55,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.08137, loss val: 0.07997
[2022-12-07 11:12:55,626] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:12:55,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:12:55,866] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:13:05,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:13:13,734] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:13:22,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:13:31,891] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:13:40,545] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:13:48,796] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:13:57,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:14:05,974] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:14:14,952] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:14:24,397] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.709802955870087
[2022-12-07 11:14:24,397] [INFO] [runner_train_mujoco] Average state value: 0.5019979926173885
[2022-12-07 11:14:24,398] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 11:14:24,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.06666
[2022-12-07 11:14:24,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.04558, loss val: 0.06373
[2022-12-07 11:14:24,558] [INFO] [controller] EPOCH 3 loss ppo:  -0.06968, loss val: 0.06449
[2022-12-07 11:14:24,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.08116, loss val: 0.06107
[2022-12-07 11:14:24,622] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:14:24,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:14:24,837] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:14:33,530] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:14:42,531] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:14:50,893] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:15:00,159] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:15:11,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:15:21,221] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:15:30,583] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:15:40,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:15:51,331] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:16:03,216] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6413776944151155
[2022-12-07 11:16:03,216] [INFO] [runner_train_mujoco] Average state value: 0.4701661154900988
[2022-12-07 11:16:03,216] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 11:16:03,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01261, loss val: 0.05818
[2022-12-07 11:16:03,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.04729, loss val: 0.05738
[2022-12-07 11:16:03,451] [INFO] [controller] EPOCH 3 loss ppo:  -0.06797, loss val: 0.05631
[2022-12-07 11:16:03,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.08250, loss val: 0.05534
[2022-12-07 11:16:03,506] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:16:03,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:16:03,745] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:16:13,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:16:23,602] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:16:32,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:16:42,098] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:16:53,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:17:03,446] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:17:13,102] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:17:21,847] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:17:31,959] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:17:42,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4117840709028546
[2022-12-07 11:17:42,807] [INFO] [runner_train_mujoco] Average state value: 0.4927743849108617
[2022-12-07 11:17:42,807] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 11:17:42,866] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.06803
[2022-12-07 11:17:42,913] [INFO] [controller] EPOCH 2 loss ppo:  -0.04399, loss val: 0.06022
[2022-12-07 11:17:42,961] [INFO] [controller] EPOCH 3 loss ppo:  -0.06255, loss val: 0.05713
[2022-12-07 11:17:43,011] [INFO] [controller] EPOCH 4 loss ppo:  -0.07654, loss val: 0.05449
[2022-12-07 11:17:43,022] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:17:43,263] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:17:43,263] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:17:54,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:18:05,149] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:18:15,176] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:18:24,688] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:18:33,844] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:18:43,378] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:18:53,238] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:19:02,379] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:19:12,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:19:22,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6588273856850602
[2022-12-07 11:19:22,028] [INFO] [runner_train_mujoco] Average state value: 0.5600344844063123
[2022-12-07 11:19:22,028] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 11:19:22,087] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04135
[2022-12-07 11:19:22,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.04732, loss val: 0.04148
[2022-12-07 11:19:22,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.06748, loss val: 0.04140
[2022-12-07 11:19:22,228] [INFO] [controller] EPOCH 4 loss ppo:  -0.07869, loss val: 0.04010
[2022-12-07 11:19:22,239] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:19:22,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:19:22,483] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:19:32,637] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:19:42,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:19:53,031] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:20:03,555] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:20:13,321] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:20:22,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:20:32,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:20:42,147] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:20:51,740] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:21:01,677] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8610782378079507
[2022-12-07 11:21:01,677] [INFO] [runner_train_mujoco] Average state value: 0.56828395930926
[2022-12-07 11:21:01,677] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 11:21:01,735] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.04473
[2022-12-07 11:21:01,799] [INFO] [controller] EPOCH 2 loss ppo:  -0.04694, loss val: 0.04215
[2022-12-07 11:21:01,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.06538, loss val: 0.04115
[2022-12-07 11:21:01,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.08118, loss val: 0.04227
[2022-12-07 11:21:01,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:21:02,174] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:21:02,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:21:13,027] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:21:23,112] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:21:33,268] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:21:43,541] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:21:53,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:22:01,397] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:22:10,287] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:22:19,240] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:22:28,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:22:37,655] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.846268638643097
[2022-12-07 11:22:37,655] [INFO] [runner_train_mujoco] Average state value: 0.5475249376992385
[2022-12-07 11:22:37,655] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 11:22:37,744] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.03874
[2022-12-07 11:22:37,796] [INFO] [controller] EPOCH 2 loss ppo:  -0.04841, loss val: 0.04002
[2022-12-07 11:22:37,847] [INFO] [controller] EPOCH 3 loss ppo:  -0.07202, loss val: 0.03851
[2022-12-07 11:22:37,896] [INFO] [controller] EPOCH 4 loss ppo:  -0.08357, loss val: 0.03770
[2022-12-07 11:22:37,908] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:22:38,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:22:38,147] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:22:47,917] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:22:57,040] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:23:05,831] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:23:14,636] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:23:24,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:23:34,373] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:23:43,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:23:52,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:24:02,845] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:24:13,205] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3754779235748205
[2022-12-07 11:24:13,205] [INFO] [runner_train_mujoco] Average state value: 0.5320966917127371
[2022-12-07 11:24:13,205] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 11:24:13,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.04796
[2022-12-07 11:24:13,305] [INFO] [controller] EPOCH 2 loss ppo:  -0.04589, loss val: 0.04723
[2022-12-07 11:24:13,353] [INFO] [controller] EPOCH 3 loss ppo:  -0.06456, loss val: 0.04838
[2022-12-07 11:24:13,402] [INFO] [controller] EPOCH 4 loss ppo:  -0.07699, loss val: 0.04752
[2022-12-07 11:24:13,414] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:24:13,660] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:24:13,661] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:24:22,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:24:32,241] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:24:41,896] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:24:52,064] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:25:01,612] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:25:10,894] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:25:20,017] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:25:29,739] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:25:39,804] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:25:50,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5888111701530827
[2022-12-07 11:25:50,316] [INFO] [runner_train_mujoco] Average state value: 0.545625241731604
[2022-12-07 11:25:50,316] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 11:25:50,385] [INFO] [controller] EPOCH 1 loss ppo:  -0.01519, loss val: 0.04342
[2022-12-07 11:25:50,464] [INFO] [controller] EPOCH 2 loss ppo:  -0.05070, loss val: 0.04239
[2022-12-07 11:25:50,532] [INFO] [controller] EPOCH 3 loss ppo:  -0.07025, loss val: 0.04263
[2022-12-07 11:25:50,596] [INFO] [controller] EPOCH 4 loss ppo:  -0.08472, loss val: 0.04518
[2022-12-07 11:25:50,605] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:25:50,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:25:50,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:26:00,661] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:26:10,085] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:26:20,653] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:26:30,690] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:26:40,259] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:26:51,225] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:27:01,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:27:10,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:27:20,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:27:29,392] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4104082347311189
[2022-12-07 11:27:29,393] [INFO] [runner_train_mujoco] Average state value: 0.5167419982502859
[2022-12-07 11:27:29,393] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 11:27:29,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.04105
[2022-12-07 11:27:29,502] [INFO] [controller] EPOCH 2 loss ppo:  -0.04473, loss val: 0.04224
[2022-12-07 11:27:29,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.06245, loss val: 0.04105
[2022-12-07 11:27:29,600] [INFO] [controller] EPOCH 4 loss ppo:  -0.07802, loss val: 0.04003
[2022-12-07 11:27:29,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:27:29,852] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:27:29,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:27:40,612] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:27:49,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:27:59,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:28:08,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:28:16,838] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:28:25,742] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:28:35,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:28:45,271] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:28:55,194] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:29:04,650] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5609936624865766
[2022-12-07 11:29:04,650] [INFO] [runner_train_mujoco] Average state value: 0.4976635931233565
[2022-12-07 11:29:04,650] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 11:29:04,722] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.05945
[2022-12-07 11:29:04,769] [INFO] [controller] EPOCH 2 loss ppo:  -0.04600, loss val: 0.05835
[2022-12-07 11:29:04,818] [INFO] [controller] EPOCH 3 loss ppo:  -0.06482, loss val: 0.05791
[2022-12-07 11:29:04,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.07689, loss val: 0.05643
[2022-12-07 11:29:04,872] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:29:05,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:29:05,100] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:29:14,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:29:23,414] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:29:33,667] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:29:45,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:29:55,779] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:30:04,268] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:30:15,558] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:30:24,488] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:30:32,815] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:30:42,037] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8180055704484421
[2022-12-07 11:30:42,038] [INFO] [runner_train_mujoco] Average state value: 0.5410248578563331
[2022-12-07 11:30:42,038] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 11:30:42,104] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.04871
[2022-12-07 11:30:42,146] [INFO] [controller] EPOCH 2 loss ppo:  -0.04344, loss val: 0.04392
[2022-12-07 11:30:42,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.06418, loss val: 0.04324
[2022-12-07 11:30:42,239] [INFO] [controller] EPOCH 4 loss ppo:  -0.07804, loss val: 0.04380
[2022-12-07 11:30:42,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:30:42,497] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:30:42,498] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:30:50,862] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:30:59,333] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:31:08,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:31:16,874] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:31:25,918] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:31:34,748] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:31:44,478] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:31:57,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:32:07,090] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:32:16,325] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7324817747835763
[2022-12-07 11:32:16,326] [INFO] [runner_train_mujoco] Average state value: 0.556080792327722
[2022-12-07 11:32:16,326] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 11:32:16,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.03502
[2022-12-07 11:32:16,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.04262, loss val: 0.03343
[2022-12-07 11:32:16,474] [INFO] [controller] EPOCH 3 loss ppo:  -0.05939, loss val: 0.03146
[2022-12-07 11:32:16,521] [INFO] [controller] EPOCH 4 loss ppo:  -0.07500, loss val: 0.03018
[2022-12-07 11:32:16,532] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:32:16,751] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:32:16,752] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:32:26,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:32:36,570] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:32:45,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:32:56,216] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:33:06,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:33:16,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:33:25,751] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:33:35,076] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:33:44,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:33:55,074] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5234882351735282
[2022-12-07 11:33:55,074] [INFO] [runner_train_mujoco] Average state value: 0.5067647049278021
[2022-12-07 11:33:55,074] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 11:33:55,302] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.03418
[2022-12-07 11:33:55,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.04052, loss val: 0.03529
[2022-12-07 11:33:55,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.06413, loss val: 0.03561
[2022-12-07 11:33:55,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.07954, loss val: 0.03102
[2022-12-07 11:33:55,687] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:33:56,057] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:33:56,061] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:34:08,741] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:34:19,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:34:30,808] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:34:41,378] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:34:51,199] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:35:00,665] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:35:10,347] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:35:24,645] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:35:38,668] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:35:50,031] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.427725358663898
[2022-12-07 11:35:50,032] [INFO] [runner_train_mujoco] Average state value: 0.4953569550638397
[2022-12-07 11:35:50,032] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 11:35:50,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01486, loss val: 0.02988
[2022-12-07 11:35:50,295] [INFO] [controller] EPOCH 2 loss ppo:  -0.04256, loss val: 0.02975
[2022-12-07 11:35:50,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.05900, loss val: 0.03706
[2022-12-07 11:35:50,519] [INFO] [controller] EPOCH 4 loss ppo:  -0.07491, loss val: 0.03321
[2022-12-07 11:35:50,538] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:35:50,858] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:35:50,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:36:02,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:36:11,617] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:36:25,990] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:36:38,656] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:36:50,698] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:37:01,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:37:10,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:37:19,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:37:28,610] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:37:38,246] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6009923515579214
[2022-12-07 11:37:38,246] [INFO] [runner_train_mujoco] Average state value: 0.5309696446259816
[2022-12-07 11:37:38,247] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 11:37:38,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.04460
[2022-12-07 11:37:38,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.04311, loss val: 0.04489
[2022-12-07 11:37:38,427] [INFO] [controller] EPOCH 3 loss ppo:  -0.06508, loss val: 0.04662
[2022-12-07 11:37:38,480] [INFO] [controller] EPOCH 4 loss ppo:  -0.07946, loss val: 0.04369
[2022-12-07 11:37:38,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:37:38,732] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:37:38,732] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:37:48,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:37:57,238] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:38:08,297] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:38:18,908] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:38:30,470] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:38:44,209] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:38:54,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:39:03,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:39:16,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:39:27,053] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6125746538876005
[2022-12-07 11:39:27,054] [INFO] [runner_train_mujoco] Average state value: 0.5183595297535261
[2022-12-07 11:39:27,054] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 11:39:27,160] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.03023
[2022-12-07 11:39:27,243] [INFO] [controller] EPOCH 2 loss ppo:  -0.04334, loss val: 0.03024
[2022-12-07 11:39:27,327] [INFO] [controller] EPOCH 3 loss ppo:  -0.06451, loss val: 0.03121
[2022-12-07 11:39:27,410] [INFO] [controller] EPOCH 4 loss ppo:  -0.08050, loss val: 0.02944
[2022-12-07 11:39:27,423] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:39:27,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:39:27,680] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:39:38,446] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:39:49,183] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:39:59,456] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:40:10,821] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:40:20,487] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:40:30,666] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:40:40,673] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:40:50,575] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:41:00,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:41:10,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7273998958084409
[2022-12-07 11:41:10,570] [INFO] [runner_train_mujoco] Average state value: 0.4925403260290623
[2022-12-07 11:41:10,570] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 11:41:10,642] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.03714
[2022-12-07 11:41:10,708] [INFO] [controller] EPOCH 2 loss ppo:  -0.04152, loss val: 0.03708
[2022-12-07 11:41:10,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.05989, loss val: 0.03933
[2022-12-07 11:41:10,827] [INFO] [controller] EPOCH 4 loss ppo:  -0.07131, loss val: 0.03542
[2022-12-07 11:41:10,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:41:11,082] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:41:11,083] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:41:21,310] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:41:30,444] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:41:39,739] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:41:48,834] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:41:57,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:42:07,212] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:42:16,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:42:25,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:42:35,306] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:42:44,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8226007392984376
[2022-12-07 11:42:44,090] [INFO] [runner_train_mujoco] Average state value: 0.5153692237933477
[2022-12-07 11:42:44,090] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 11:42:44,150] [INFO] [controller] EPOCH 1 loss ppo:  -0.01523, loss val: 0.04201
[2022-12-07 11:42:44,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.04461, loss val: 0.04357
[2022-12-07 11:42:44,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.06404, loss val: 0.04163
[2022-12-07 11:42:44,292] [INFO] [controller] EPOCH 4 loss ppo:  -0.07936, loss val: 0.04324
[2022-12-07 11:42:44,302] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:42:44,564] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:42:44,564] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:42:53,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:43:02,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:43:12,193] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:43:21,919] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:43:32,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:43:40,667] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:43:49,060] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:43:57,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:44:06,185] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:44:16,822] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.73703904047014
[2022-12-07 11:44:16,823] [INFO] [runner_train_mujoco] Average state value: 0.5282447258532047
[2022-12-07 11:44:16,823] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 11:44:16,955] [INFO] [controller] EPOCH 1 loss ppo:  -0.01494, loss val: 0.03493
[2022-12-07 11:44:17,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.04397, loss val: 0.03574
[2022-12-07 11:44:17,149] [INFO] [controller] EPOCH 3 loss ppo:  -0.06571, loss val: 0.03521
[2022-12-07 11:44:17,234] [INFO] [controller] EPOCH 4 loss ppo:  -0.07915, loss val: 0.03640
[2022-12-07 11:44:17,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:44:17,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:44:17,532] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:44:30,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:44:41,599] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:44:50,662] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:45:00,099] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:45:09,813] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:45:18,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:45:28,277] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:45:39,294] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:45:50,710] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:46:02,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7108260180830002
[2022-12-07 11:46:02,670] [INFO] [runner_train_mujoco] Average state value: 0.5301081871390342
[2022-12-07 11:46:02,671] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 11:46:02,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.04156
[2022-12-07 11:46:02,830] [INFO] [controller] EPOCH 2 loss ppo:  -0.04369, loss val: 0.04288
[2022-12-07 11:46:02,886] [INFO] [controller] EPOCH 3 loss ppo:  -0.06652, loss val: 0.04094
[2022-12-07 11:46:02,945] [INFO] [controller] EPOCH 4 loss ppo:  -0.08250, loss val: 0.04266
[2022-12-07 11:46:02,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:46:03,234] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:46:03,235] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:46:14,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:46:25,100] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:46:35,672] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:46:45,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:46:56,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:47:07,109] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:47:17,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:47:27,619] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:47:37,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:47:47,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.417806953746856
[2022-12-07 11:47:47,111] [INFO] [runner_train_mujoco] Average state value: 0.5216695710420609
[2022-12-07 11:47:47,111] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 11:47:47,178] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.03613
[2022-12-07 11:47:47,231] [INFO] [controller] EPOCH 2 loss ppo:  -0.04189, loss val: 0.03680
[2022-12-07 11:47:47,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.06132, loss val: 0.03635
[2022-12-07 11:47:47,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.07234, loss val: 0.03647
[2022-12-07 11:47:47,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:47:47,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:47:47,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:47:58,045] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:48:08,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:48:18,396] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:48:27,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:48:37,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:48:45,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:48:55,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:49:05,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:49:15,939] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:49:25,408] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5387273644327177
[2022-12-07 11:49:25,409] [INFO] [runner_train_mujoco] Average state value: 0.5057219950755438
[2022-12-07 11:49:25,409] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 11:49:25,466] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.03411
[2022-12-07 11:49:25,518] [INFO] [controller] EPOCH 2 loss ppo:  -0.03669, loss val: 0.03015
[2022-12-07 11:49:25,588] [INFO] [controller] EPOCH 3 loss ppo:  -0.05717, loss val: 0.02928
[2022-12-07 11:49:25,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.07301, loss val: 0.03396
[2022-12-07 11:49:25,648] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:49:25,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:49:25,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:49:36,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:49:45,552] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:49:54,642] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:50:04,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:50:13,792] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:50:23,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:50:31,410] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:50:40,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:50:49,743] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:50:58,674] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6358801409816675
[2022-12-07 11:50:58,674] [INFO] [runner_train_mujoco] Average state value: 0.5015646607279778
[2022-12-07 11:50:58,674] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 11:50:58,737] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04345
[2022-12-07 11:50:58,783] [INFO] [controller] EPOCH 2 loss ppo:  -0.03595, loss val: 0.04299
[2022-12-07 11:50:58,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.05434, loss val: 0.04126
[2022-12-07 11:50:58,896] [INFO] [controller] EPOCH 4 loss ppo:  -0.06698, loss val: 0.04031
[2022-12-07 11:50:58,907] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:50:59,138] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:50:59,139] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:51:08,264] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:51:17,169] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:51:25,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:51:33,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:51:42,710] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:51:51,170] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:51:59,624] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:52:08,200] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:52:17,205] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:52:26,119] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.858322217214686
[2022-12-07 11:52:26,120] [INFO] [runner_train_mujoco] Average state value: 0.5100992653767269
[2022-12-07 11:52:26,120] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 11:52:26,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.04478
[2022-12-07 11:52:26,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.03656, loss val: 0.04436
[2022-12-07 11:52:26,360] [INFO] [controller] EPOCH 3 loss ppo:  -0.05962, loss val: 0.04372
[2022-12-07 11:52:26,413] [INFO] [controller] EPOCH 4 loss ppo:  -0.07542, loss val: 0.04230
[2022-12-07 11:52:26,422] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:52:26,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:52:26,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:52:36,315] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:52:45,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:52:53,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:53:02,339] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:53:11,265] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:53:20,749] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:53:30,115] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:53:39,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:53:48,176] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:53:56,861] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.642593624536124
[2022-12-07 11:53:56,861] [INFO] [runner_train_mujoco] Average state value: 0.5439868835012118
[2022-12-07 11:53:56,861] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 11:53:56,917] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.03315
[2022-12-07 11:53:56,966] [INFO] [controller] EPOCH 2 loss ppo:  -0.03594, loss val: 0.03290
[2022-12-07 11:53:57,032] [INFO] [controller] EPOCH 3 loss ppo:  -0.05656, loss val: 0.03706
[2022-12-07 11:53:57,090] [INFO] [controller] EPOCH 4 loss ppo:  -0.06902, loss val: 0.03205
[2022-12-07 11:53:57,101] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:53:57,370] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:53:57,371] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:54:08,921] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:54:20,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:54:30,367] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:54:44,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:54:56,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:55:09,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:55:25,666] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:55:39,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:55:49,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:55:58,987] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.922436681254453
[2022-12-07 11:55:58,987] [INFO] [runner_train_mujoco] Average state value: 0.5661278356909751
[2022-12-07 11:55:58,987] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 11:55:59,050] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.04619
[2022-12-07 11:55:59,107] [INFO] [controller] EPOCH 2 loss ppo:  -0.03531, loss val: 0.04691
[2022-12-07 11:55:59,153] [INFO] [controller] EPOCH 3 loss ppo:  -0.05715, loss val: 0.04440
[2022-12-07 11:55:59,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.07226, loss val: 0.04386
[2022-12-07 11:55:59,210] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:55:59,451] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:55:59,451] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:56:10,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:56:19,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:56:29,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:56:38,969] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:56:48,302] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:56:58,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:57:08,767] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:57:18,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:57:28,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:57:37,952] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7035466679587477
[2022-12-07 11:57:37,952] [INFO] [runner_train_mujoco] Average state value: 0.5632930621703466
[2022-12-07 11:57:37,952] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 11:57:38,013] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.03076
[2022-12-07 11:57:38,065] [INFO] [controller] EPOCH 2 loss ppo:  -0.03519, loss val: 0.03297
[2022-12-07 11:57:38,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.05621, loss val: 0.03356
[2022-12-07 11:57:38,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.06878, loss val: 0.03165
[2022-12-07 11:57:38,193] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:57:38,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:57:38,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:57:48,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:57:57,740] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:58:08,982] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:58:20,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:58:30,878] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:58:40,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:58:49,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:58:58,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:59:10,956] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:59:27,000] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9257243805730018
[2022-12-07 11:59:27,000] [INFO] [runner_train_mujoco] Average state value: 0.5309590699474016
[2022-12-07 11:59:27,001] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 11:59:27,082] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.03116
[2022-12-07 11:59:27,144] [INFO] [controller] EPOCH 2 loss ppo:  -0.03748, loss val: 0.03112
[2022-12-07 11:59:27,206] [INFO] [controller] EPOCH 3 loss ppo:  -0.05875, loss val: 0.03118
[2022-12-07 11:59:27,271] [INFO] [controller] EPOCH 4 loss ppo:  -0.07163, loss val: 0.03392
[2022-12-07 11:59:27,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:59:27,548] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:59:27,549] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:59:39,124] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:59:49,726] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:59:58,316] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:00:07,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:00:16,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:00:24,835] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:00:36,188] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:00:45,909] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:00:54,767] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:01:03,865] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9783902776662956
[2022-12-07 12:01:03,866] [INFO] [runner_train_mujoco] Average state value: 0.5261013061602909
[2022-12-07 12:01:03,866] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 12:01:03,916] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.04422
[2022-12-07 12:01:03,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.03556, loss val: 0.04609
[2022-12-07 12:01:04,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.05421, loss val: 0.04627
[2022-12-07 12:01:04,049] [INFO] [controller] EPOCH 4 loss ppo:  -0.06801, loss val: 0.04391
[2022-12-07 12:01:04,060] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:01:04,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:01:04,298] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:01:13,969] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:01:22,130] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:01:30,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:01:39,829] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:01:48,613] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:01:57,316] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:02:07,388] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:02:19,396] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:02:29,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:02:39,143] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.784687474950672
[2022-12-07 12:02:39,144] [INFO] [runner_train_mujoco] Average state value: 0.5192653786738712
[2022-12-07 12:02:39,144] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 12:02:39,204] [INFO] [controller] EPOCH 1 loss ppo:  -0.01470, loss val: 0.03771
[2022-12-07 12:02:39,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.03162, loss val: 0.03753
[2022-12-07 12:02:39,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.05257, loss val: 0.03876
[2022-12-07 12:02:39,360] [INFO] [controller] EPOCH 4 loss ppo:  -0.06670, loss val: 0.03657
[2022-12-07 12:02:39,371] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:02:39,635] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:02:39,636] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:02:49,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:02:58,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:03:12,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:03:25,446] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:03:38,319] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:03:50,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:04:08,688] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:04:24,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:04:37,174] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:04:49,183] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7331883466165798
[2022-12-07 12:04:49,184] [INFO] [runner_train_mujoco] Average state value: 0.502091644614935
[2022-12-07 12:04:49,184] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 12:04:49,273] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.03598
[2022-12-07 12:04:49,403] [INFO] [controller] EPOCH 2 loss ppo:  -0.03102, loss val: 0.03922
[2022-12-07 12:04:49,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.05129, loss val: 0.03644
[2022-12-07 12:04:49,548] [INFO] [controller] EPOCH 4 loss ppo:  -0.06421, loss val: 0.03560
[2022-12-07 12:04:49,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:04:49,865] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:04:49,866] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:04:59,514] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:05:09,034] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:05:19,049] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:05:28,622] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:05:38,182] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:05:48,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:05:57,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:06:07,960] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:06:17,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:06:28,625] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6612748312300685
[2022-12-07 12:06:28,626] [INFO] [runner_train_mujoco] Average state value: 0.5000293772319953
[2022-12-07 12:06:28,626] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 12:06:28,688] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.03960
[2022-12-07 12:06:28,740] [INFO] [controller] EPOCH 2 loss ppo:  -0.02875, loss val: 0.03980
[2022-12-07 12:06:28,793] [INFO] [controller] EPOCH 3 loss ppo:  -0.04768, loss val: 0.03718
[2022-12-07 12:06:28,849] [INFO] [controller] EPOCH 4 loss ppo:  -0.06228, loss val: 0.03668
[2022-12-07 12:06:28,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:06:29,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:06:29,147] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:06:41,665] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:06:53,174] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:07:04,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:07:16,075] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:07:27,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:07:36,732] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:07:46,864] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:07:56,909] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:08:06,822] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:08:15,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.019887772727224
[2022-12-07 12:08:15,619] [INFO] [runner_train_mujoco] Average state value: 0.525173920015494
[2022-12-07 12:08:15,619] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 12:08:15,679] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.03242
[2022-12-07 12:08:15,731] [INFO] [controller] EPOCH 2 loss ppo:  -0.03032, loss val: 0.03362
[2022-12-07 12:08:15,782] [INFO] [controller] EPOCH 3 loss ppo:  -0.05037, loss val: 0.03221
[2022-12-07 12:08:15,833] [INFO] [controller] EPOCH 4 loss ppo:  -0.06537, loss val: 0.03422
[2022-12-07 12:08:15,844] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:08:16,094] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:08:16,095] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:08:25,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:08:35,237] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:08:44,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:08:53,097] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:09:02,559] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:09:11,978] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:09:21,164] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:09:29,912] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:09:38,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:09:47,062] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.215628296918145
[2022-12-07 12:09:47,062] [INFO] [runner_train_mujoco] Average state value: 0.5501257286568483
[2022-12-07 12:09:47,062] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 12:09:47,188] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04375
[2022-12-07 12:09:47,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.02897, loss val: 0.04278
[2022-12-07 12:09:47,304] [INFO] [controller] EPOCH 3 loss ppo:  -0.04536, loss val: 0.04493
[2022-12-07 12:09:47,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.05771, loss val: 0.04290
[2022-12-07 12:09:47,371] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:09:47,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:09:47,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:09:56,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:10:05,151] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:10:13,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:10:21,794] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:10:30,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:10:38,598] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:10:47,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:10:55,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:11:03,026] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:11:09,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6612102007807779
[2022-12-07 12:11:09,986] [INFO] [runner_train_mujoco] Average state value: 0.5438707632025083
[2022-12-07 12:11:09,986] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 12:11:10,081] [INFO] [controller] EPOCH 1 loss ppo:  -0.01427, loss val: 0.03149
[2022-12-07 12:11:10,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.02806, loss val: 0.03240
[2022-12-07 12:11:10,159] [INFO] [controller] EPOCH 3 loss ppo:  -0.04724, loss val: 0.03128
[2022-12-07 12:11:10,204] [INFO] [controller] EPOCH 4 loss ppo:  -0.06259, loss val: 0.03485
[2022-12-07 12:11:10,214] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:11:10,428] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:11:10,429] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:11:17,580] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:11:24,818] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:11:33,201] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:11:40,875] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:11:47,778] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:11:56,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:12:04,465] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:12:11,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:12:19,003] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:12:25,869] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8574162781137649
[2022-12-07 12:12:25,869] [INFO] [runner_train_mujoco] Average state value: 0.5418134868939718
[2022-12-07 12:12:25,869] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 12:12:25,913] [INFO] [controller] EPOCH 1 loss ppo:  -0.01513, loss val: 0.03358
[2022-12-07 12:12:25,950] [INFO] [controller] EPOCH 2 loss ppo:  -0.02889, loss val: 0.03365
[2022-12-07 12:12:25,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.04573, loss val: 0.03413
[2022-12-07 12:12:26,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.05880, loss val: 0.03357
[2022-12-07 12:12:26,038] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:12:26,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:12:26,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:12:33,415] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:12:40,660] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:12:47,794] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:12:55,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:13:02,509] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:13:10,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:13:18,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:13:26,379] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:13:34,665] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:13:42,119] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.966670142928816
[2022-12-07 12:13:42,119] [INFO] [runner_train_mujoco] Average state value: 0.5384875359634559
[2022-12-07 12:13:42,119] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 12:13:42,170] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.03144
[2022-12-07 12:13:42,214] [INFO] [controller] EPOCH 2 loss ppo:  -0.02566, loss val: 0.03133
[2022-12-07 12:13:42,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.04209, loss val: 0.03179
[2022-12-07 12:13:42,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.05729, loss val: 0.03612
[2022-12-07 12:13:42,303] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:13:42,536] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:13:42,537] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:13:51,644] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:13:59,548] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:14:07,475] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:14:15,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:14:22,510] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:14:30,520] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:14:38,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:14:47,084] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:14:55,042] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:15:02,625] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7376580722062525
[2022-12-07 12:15:02,626] [INFO] [runner_train_mujoco] Average state value: 0.5416564979652564
[2022-12-07 12:15:02,626] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 12:15:02,680] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.03964
[2022-12-07 12:15:02,722] [INFO] [controller] EPOCH 2 loss ppo:  -0.02343, loss val: 0.03814
[2022-12-07 12:15:02,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.03876, loss val: 0.03847
[2022-12-07 12:15:02,819] [INFO] [controller] EPOCH 4 loss ppo:  -0.05303, loss val: 0.03983
[2022-12-07 12:15:02,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:15:03,073] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:15:03,074] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:15:11,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:15:19,117] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:15:26,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:15:34,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:15:42,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:15:50,447] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:15:59,011] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:16:06,786] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:16:14,006] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:16:20,954] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8207808660502345
[2022-12-07 12:16:20,954] [INFO] [runner_train_mujoco] Average state value: 0.5494865465164184
[2022-12-07 12:16:20,954] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 12:16:21,006] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.03369
[2022-12-07 12:16:21,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.02175, loss val: 0.03350
[2022-12-07 12:16:21,086] [INFO] [controller] EPOCH 3 loss ppo:  -0.03536, loss val: 0.03296
[2022-12-07 12:16:21,126] [INFO] [controller] EPOCH 4 loss ppo:  -0.04786, loss val: 0.03199
[2022-12-07 12:16:21,136] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:16:21,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:16:21,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:16:28,528] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:16:35,797] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:16:44,064] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:16:51,948] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:17:00,218] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:17:08,935] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:17:16,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:17:24,031] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:17:30,936] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:17:37,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8380814241355554
[2022-12-07 12:17:37,550] [INFO] [runner_train_mujoco] Average state value: 0.5456312594413758
[2022-12-07 12:17:37,550] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 12:17:37,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.03641
[2022-12-07 12:17:37,625] [INFO] [controller] EPOCH 2 loss ppo:  -0.02117, loss val: 0.03606
[2022-12-07 12:17:37,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.03262, loss val: 0.03615
[2022-12-07 12:17:37,694] [INFO] [controller] EPOCH 4 loss ppo:  -0.04590, loss val: 0.03796
[2022-12-07 12:17:37,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:17:37,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:17:37,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:17:45,020] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:17:51,769] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:17:58,644] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:18:05,880] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:18:13,557] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:18:20,791] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:18:28,125] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:18:35,871] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:18:43,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:18:50,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.063479047000399
[2022-12-07 12:18:50,264] [INFO] [runner_train_mujoco] Average state value: 0.5418384230136871
[2022-12-07 12:18:50,264] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 12:18:50,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.03589
[2022-12-07 12:18:50,359] [INFO] [controller] EPOCH 2 loss ppo:  -0.02035, loss val: 0.03280
[2022-12-07 12:18:50,400] [INFO] [controller] EPOCH 3 loss ppo:  -0.03181, loss val: 0.03269
[2022-12-07 12:18:50,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.04445, loss val: 0.03261
[2022-12-07 12:18:50,446] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:18:50,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:18:50,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:18:58,128] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:19:05,392] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:19:12,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:19:19,714] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:19:27,361] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:19:34,904] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:19:42,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:19:50,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:19:58,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:20:05,301] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6573851625226197
[2022-12-07 12:20:05,301] [INFO] [runner_train_mujoco] Average state value: 0.5412651138901711
[2022-12-07 12:20:05,301] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 12:20:05,356] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04680
[2022-12-07 12:20:05,399] [INFO] [controller] EPOCH 2 loss ppo:  -0.02001, loss val: 0.04715
[2022-12-07 12:20:05,437] [INFO] [controller] EPOCH 3 loss ppo:  -0.02936, loss val: 0.04960
[2022-12-07 12:20:05,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.03968, loss val: 0.04589
[2022-12-07 12:20:05,484] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:20:05,677] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:20:05,677] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:20:12,805] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:20:19,965] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:20:26,846] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:20:34,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:20:41,635] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:20:48,567] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:20:55,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:21:03,074] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:21:10,395] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:21:17,412] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.739418438198101
[2022-12-07 12:21:17,412] [INFO] [runner_train_mujoco] Average state value: 0.5324251283208529
[2022-12-07 12:21:17,413] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 12:21:17,463] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.03218
[2022-12-07 12:21:17,507] [INFO] [controller] EPOCH 2 loss ppo:  -0.01869, loss val: 0.03404
[2022-12-07 12:21:17,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.02540, loss val: 0.03326
[2022-12-07 12:21:17,592] [INFO] [controller] EPOCH 4 loss ppo:  -0.03414, loss val: 0.03550
[2022-12-07 12:21:17,599] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:21:17,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:21:17,803] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:21:25,132] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:21:32,223] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:21:40,051] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:21:47,472] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:21:55,159] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:22:02,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:22:10,706] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:22:18,110] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:22:25,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:22:32,577] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9002025499296482
[2022-12-07 12:22:32,578] [INFO] [runner_train_mujoco] Average state value: 0.5481354425152143
[2022-12-07 12:22:32,578] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 12:22:32,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04099
[2022-12-07 12:22:32,679] [INFO] [controller] EPOCH 2 loss ppo:  -0.01725, loss val: 0.04125
[2022-12-07 12:22:32,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.02212, loss val: 0.04119
[2022-12-07 12:22:32,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.02831, loss val: 0.04206
[2022-12-07 12:22:32,775] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:22:32,977] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:22:32,977] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:22:40,317] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:22:47,269] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:22:54,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:23:01,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:23:09,114] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:23:16,054] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:23:22,872] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:23:30,098] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:23:36,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:23:43,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9034969676084739
[2022-12-07 12:23:43,667] [INFO] [runner_train_mujoco] Average state value: 0.5384571673075358
[2022-12-07 12:23:43,667] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 12:23:43,719] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.03087
[2022-12-07 12:23:43,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.01584, loss val: 0.03337
[2022-12-07 12:23:43,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.01834, loss val: 0.03088
[2022-12-07 12:23:43,855] [INFO] [controller] EPOCH 4 loss ppo:  -0.02185, loss val: 0.03332
[2022-12-07 12:23:43,866] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:23:43,987] [INFO] [optimize] Finished learning.
