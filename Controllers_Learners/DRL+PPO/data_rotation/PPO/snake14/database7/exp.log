[2022-12-07 04:53:08,902] [INFO] [optimize] Starting learning
[2022-12-07 04:53:08,919] [INFO] [optimize] Starting learning process..
[2022-12-07 04:53:09,044] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:53:09,045] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:19,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:53:29,058] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:53:37,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:53:47,215] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:53:56,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:54:05,838] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:54:15,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:54:24,191] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:54:33,331] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:54:42,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.64230940621127
[2022-12-07 04:54:42,564] [INFO] [runner_train_mujoco] Average state value: -0.19440593150878946
[2022-12-07 04:54:42,564] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 04:54:42,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.60125
[2022-12-07 04:54:42,668] [INFO] [controller] EPOCH 2 loss ppo:  -0.05505, loss val: 0.54353
[2022-12-07 04:54:42,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.07337, loss val: 0.49017
[2022-12-07 04:54:42,765] [INFO] [controller] EPOCH 4 loss ppo:  -0.08288, loss val: 0.44061
[2022-12-07 04:54:42,776] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:54:42,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:54:42,993] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:54:52,525] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:55:01,970] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:55:11,476] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:55:20,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:55:30,079] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:55:39,009] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:55:48,318] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:55:57,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:56:06,664] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:56:15,920] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.378773186930156
[2022-12-07 04:56:15,920] [INFO] [runner_train_mujoco] Average state value: -0.04821929966596265
[2022-12-07 04:56:15,920] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 04:56:15,974] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.46975
[2022-12-07 04:56:16,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.05585, loss val: 0.42458
[2022-12-07 04:56:16,079] [INFO] [controller] EPOCH 3 loss ppo:  -0.07408, loss val: 0.40068
[2022-12-07 04:56:16,128] [INFO] [controller] EPOCH 4 loss ppo:  -0.08500, loss val: 0.34230
[2022-12-07 04:56:16,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:56:16,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:56:16,350] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:56:26,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:56:35,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:56:45,234] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:56:54,588] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:57:03,706] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:57:12,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:57:22,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:57:31,319] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:57:40,223] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:57:50,433] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1882697049824489
[2022-12-07 04:57:50,433] [INFO] [runner_train_mujoco] Average state value: 0.0745897129625082
[2022-12-07 04:57:50,433] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 04:57:50,495] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.31718
[2022-12-07 04:57:50,550] [INFO] [controller] EPOCH 2 loss ppo:  -0.05344, loss val: 0.27820
[2022-12-07 04:57:50,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.07518, loss val: 0.26037
[2022-12-07 04:57:50,664] [INFO] [controller] EPOCH 4 loss ppo:  -0.08573, loss val: 0.21713
[2022-12-07 04:57:50,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:57:50,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:57:50,912] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:58:01,046] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:58:10,496] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:58:20,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:58:29,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:58:38,906] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:58:48,062] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:58:57,105] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:59:06,268] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:59:15,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:59:24,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6075422268728108
[2022-12-07 04:59:24,671] [INFO] [runner_train_mujoco] Average state value: 0.21765168558185297
[2022-12-07 04:59:24,671] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 04:59:24,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.16730
[2022-12-07 04:59:24,876] [INFO] [controller] EPOCH 2 loss ppo:  -0.05188, loss val: 0.15377
[2022-12-07 04:59:24,930] [INFO] [controller] EPOCH 3 loss ppo:  -0.07120, loss val: 0.13298
[2022-12-07 04:59:24,981] [INFO] [controller] EPOCH 4 loss ppo:  -0.08679, loss val: 0.12734
[2022-12-07 04:59:24,991] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:59:25,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:59:25,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:59:34,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:59:43,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:59:52,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:00:02,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:00:11,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:00:20,097] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:00:29,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:00:38,505] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:00:47,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:00:56,557] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6147636459746475
[2022-12-07 05:00:56,557] [INFO] [runner_train_mujoco] Average state value: 0.3791148507023851
[2022-12-07 05:00:56,557] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 05:00:56,642] [INFO] [controller] EPOCH 1 loss ppo:  -0.01619, loss val: 0.10747
[2022-12-07 05:00:56,694] [INFO] [controller] EPOCH 2 loss ppo:  -0.05071, loss val: 0.09647
[2022-12-07 05:00:56,746] [INFO] [controller] EPOCH 3 loss ppo:  -0.07053, loss val: 0.08822
[2022-12-07 05:00:56,797] [INFO] [controller] EPOCH 4 loss ppo:  -0.08614, loss val: 0.08153
[2022-12-07 05:00:56,808] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:00:57,030] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:00:57,030] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:01:06,642] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:01:15,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:01:24,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:01:34,247] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:01:43,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:01:52,317] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:02:01,467] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:02:10,320] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:02:19,819] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:02:29,379] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4407199954361265
[2022-12-07 05:02:29,379] [INFO] [runner_train_mujoco] Average state value: 0.49902787813916805
[2022-12-07 05:02:29,379] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 05:02:29,451] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.07075
[2022-12-07 05:02:29,515] [INFO] [controller] EPOCH 2 loss ppo:  -0.05134, loss val: 0.06794
[2022-12-07 05:02:29,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.07354, loss val: 0.06210
[2022-12-07 05:02:29,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.08640, loss val: 0.06100
[2022-12-07 05:02:29,633] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:02:29,855] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:02:29,855] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:02:39,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:02:48,564] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:02:57,555] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:03:06,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:03:16,301] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:03:25,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:03:34,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:03:44,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:03:53,194] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:04:02,600] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.510106660335517
[2022-12-07 05:04:02,601] [INFO] [runner_train_mujoco] Average state value: 0.5770046836622059
[2022-12-07 05:04:02,601] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 05:04:02,653] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.06450
[2022-12-07 05:04:02,705] [INFO] [controller] EPOCH 2 loss ppo:  -0.05302, loss val: 0.06264
[2022-12-07 05:04:02,789] [INFO] [controller] EPOCH 3 loss ppo:  -0.06989, loss val: 0.06058
[2022-12-07 05:04:02,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.07856, loss val: 0.06145
[2022-12-07 05:04:02,852] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:03,070] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:03,070] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:04:12,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:04:22,227] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:04:31,409] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:04:40,294] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:04:49,254] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:04:58,465] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:05:07,577] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:05:16,768] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:05:25,936] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:05:35,130] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.722955974369492
[2022-12-07 05:05:35,130] [INFO] [runner_train_mujoco] Average state value: 0.5750285846541325
[2022-12-07 05:05:35,130] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 05:05:35,191] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.08153
[2022-12-07 05:05:35,245] [INFO] [controller] EPOCH 2 loss ppo:  -0.04739, loss val: 0.07822
[2022-12-07 05:05:35,295] [INFO] [controller] EPOCH 3 loss ppo:  -0.06540, loss val: 0.07533
[2022-12-07 05:05:35,358] [INFO] [controller] EPOCH 4 loss ppo:  -0.08067, loss val: 0.07178
[2022-12-07 05:05:35,369] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:05:35,594] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:05:35,595] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:05:44,823] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:05:54,195] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:06:03,566] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:06:12,227] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:06:20,881] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:06:30,264] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:06:39,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:06:48,986] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:06:57,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:07:08,006] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4582794477867345
[2022-12-07 05:07:08,007] [INFO] [runner_train_mujoco] Average state value: 0.5135023354999722
[2022-12-07 05:07:08,007] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 05:07:08,085] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.09004
[2022-12-07 05:07:08,141] [INFO] [controller] EPOCH 2 loss ppo:  -0.04628, loss val: 0.08801
[2022-12-07 05:07:08,193] [INFO] [controller] EPOCH 3 loss ppo:  -0.06477, loss val: 0.08731
[2022-12-07 05:07:08,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.07840, loss val: 0.08472
[2022-12-07 05:07:08,271] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:07:08,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:07:08,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:07:18,820] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:07:28,769] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:07:38,648] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:07:47,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:07:57,001] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:08:05,808] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:08:14,437] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:08:23,937] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:08:33,353] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:08:42,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7043683455209233
[2022-12-07 05:08:42,542] [INFO] [runner_train_mujoco] Average state value: 0.5151801373101771
[2022-12-07 05:08:42,542] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 05:08:42,605] [INFO] [controller] EPOCH 1 loss ppo:  -0.01671, loss val: 0.05123
[2022-12-07 05:08:42,653] [INFO] [controller] EPOCH 2 loss ppo:  -0.05241, loss val: 0.05243
[2022-12-07 05:08:42,700] [INFO] [controller] EPOCH 3 loss ppo:  -0.07003, loss val: 0.05002
[2022-12-07 05:08:42,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.08392, loss val: 0.04915
[2022-12-07 05:08:42,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:08:42,980] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:08:42,981] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:08:52,555] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:09:01,955] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:09:10,890] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:09:19,502] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:09:28,604] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:09:37,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:09:47,401] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:09:56,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:10:06,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:10:15,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7542024120765176
[2022-12-07 05:10:15,328] [INFO] [runner_train_mujoco] Average state value: 0.4075761097706854
[2022-12-07 05:10:15,328] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 05:10:15,386] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.09541
[2022-12-07 05:10:15,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.04598, loss val: 0.08996
[2022-12-07 05:10:15,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.06281, loss val: 0.08496
[2022-12-07 05:10:15,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.07555, loss val: 0.08186
[2022-12-07 05:10:15,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:10:15,794] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:10:15,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:10:25,004] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:10:34,409] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:10:43,681] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:10:52,751] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:11:01,972] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:11:11,027] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:11:19,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:11:28,925] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:11:38,586] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:11:48,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.444298714852079
[2022-12-07 05:11:48,191] [INFO] [runner_train_mujoco] Average state value: 0.4490324542211989
[2022-12-07 05:11:48,191] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 05:11:48,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.05578
[2022-12-07 05:11:48,298] [INFO] [controller] EPOCH 2 loss ppo:  -0.04554, loss val: 0.05370
[2022-12-07 05:11:48,345] [INFO] [controller] EPOCH 3 loss ppo:  -0.06709, loss val: 0.05509
[2022-12-07 05:11:48,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.07909, loss val: 0.05106
[2022-12-07 05:11:48,408] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:11:48,637] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:11:48,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:11:57,407] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:12:06,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:12:15,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:12:24,500] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:12:33,862] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:12:43,151] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:12:52,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:13:00,586] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:13:08,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:13:17,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5290334932091398
[2022-12-07 05:13:17,392] [INFO] [runner_train_mujoco] Average state value: 0.461913284217318
[2022-12-07 05:13:17,392] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 05:13:17,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.01540, loss val: 0.06263
[2022-12-07 05:13:17,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.04533, loss val: 0.06477
[2022-12-07 05:13:17,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.06598, loss val: 0.06255
[2022-12-07 05:13:17,586] [INFO] [controller] EPOCH 4 loss ppo:  -0.08222, loss val: 0.05453
[2022-12-07 05:13:17,599] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:13:17,812] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:13:17,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:13:25,928] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:13:34,263] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:13:42,584] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:13:50,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:13:58,566] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:14:07,096] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:14:15,549] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:14:23,706] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:14:31,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:14:40,031] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4645273088443944
[2022-12-07 05:14:40,031] [INFO] [runner_train_mujoco] Average state value: 0.5170335012276968
[2022-12-07 05:14:40,031] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 05:14:40,081] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04011
[2022-12-07 05:14:40,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.04828, loss val: 0.04084
[2022-12-07 05:14:40,168] [INFO] [controller] EPOCH 3 loss ppo:  -0.06591, loss val: 0.04106
[2022-12-07 05:14:40,213] [INFO] [controller] EPOCH 4 loss ppo:  -0.07971, loss val: 0.03908
[2022-12-07 05:14:40,223] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:14:40,430] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:14:40,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:14:49,059] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:57,323] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:15:05,385] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:15:13,358] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:15:21,854] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:15:30,054] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:15:38,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:15:47,580] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:15:55,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:16:03,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6052579217306928
[2022-12-07 05:16:03,426] [INFO] [runner_train_mujoco] Average state value: 0.5629424763992429
[2022-12-07 05:16:03,426] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 05:16:03,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.04092
[2022-12-07 05:16:03,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.04907, loss val: 0.04043
[2022-12-07 05:16:03,603] [INFO] [controller] EPOCH 3 loss ppo:  -0.06797, loss val: 0.03981
[2022-12-07 05:16:03,643] [INFO] [controller] EPOCH 4 loss ppo:  -0.08085, loss val: 0.03950
[2022-12-07 05:16:03,652] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:16:03,840] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:16:03,841] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:16:12,082] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:16:20,824] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:16:28,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:16:36,796] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:16:45,226] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:16:53,847] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:17:02,147] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:17:10,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:17:18,344] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:17:26,228] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6307551373030182
[2022-12-07 05:17:26,229] [INFO] [runner_train_mujoco] Average state value: 0.5407407131493092
[2022-12-07 05:17:26,229] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 05:17:26,290] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.04770
[2022-12-07 05:17:26,353] [INFO] [controller] EPOCH 2 loss ppo:  -0.05277, loss val: 0.04662
[2022-12-07 05:17:26,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.07343, loss val: 0.04407
[2022-12-07 05:17:26,449] [INFO] [controller] EPOCH 4 loss ppo:  -0.08582, loss val: 0.04479
[2022-12-07 05:17:26,457] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:17:26,660] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:17:26,661] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:17:34,728] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:17:43,180] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:17:51,904] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:18:00,014] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:18:08,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:18:16,448] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:18:24,595] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:18:33,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:18:41,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:18:50,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5545382475808263
[2022-12-07 05:18:50,370] [INFO] [runner_train_mujoco] Average state value: 0.5151678680926561
[2022-12-07 05:18:50,370] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 05:18:50,422] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.05474
[2022-12-07 05:18:50,471] [INFO] [controller] EPOCH 2 loss ppo:  -0.04827, loss val: 0.05446
[2022-12-07 05:18:50,527] [INFO] [controller] EPOCH 3 loss ppo:  -0.06793, loss val: 0.05364
[2022-12-07 05:18:50,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.08321, loss val: 0.05420
[2022-12-07 05:18:50,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:18:50,783] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:18:50,783] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:18:59,006] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:19:07,121] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:19:15,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:19:22,831] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:19:31,276] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:19:39,561] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:19:47,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:19:56,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:20:03,783] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:20:11,663] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4151317785544395
[2022-12-07 05:20:11,663] [INFO] [runner_train_mujoco] Average state value: 0.46727887746691704
[2022-12-07 05:20:11,663] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 05:20:11,718] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04831
[2022-12-07 05:20:11,760] [INFO] [controller] EPOCH 2 loss ppo:  -0.04851, loss val: 0.04782
[2022-12-07 05:20:11,805] [INFO] [controller] EPOCH 3 loss ppo:  -0.06623, loss val: 0.04751
[2022-12-07 05:20:11,851] [INFO] [controller] EPOCH 4 loss ppo:  -0.07591, loss val: 0.04689
[2022-12-07 05:20:11,861] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:20:12,076] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:20:12,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:20:20,492] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:20:29,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:20:38,033] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:20:46,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:20:54,482] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:21:02,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:21:11,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:21:19,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:21:27,420] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:21:35,692] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6436095862331483
[2022-12-07 05:21:35,692] [INFO] [runner_train_mujoco] Average state value: 0.49241015654802317
[2022-12-07 05:21:35,693] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 05:21:35,748] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.04330
[2022-12-07 05:21:35,796] [INFO] [controller] EPOCH 2 loss ppo:  -0.04086, loss val: 0.04128
[2022-12-07 05:21:35,843] [INFO] [controller] EPOCH 3 loss ppo:  -0.06001, loss val: 0.04153
[2022-12-07 05:21:35,889] [INFO] [controller] EPOCH 4 loss ppo:  -0.07542, loss val: 0.03704
[2022-12-07 05:21:35,899] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:21:36,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:21:36,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:21:44,673] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:21:52,930] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:22:01,282] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:22:09,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:22:17,736] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:22:25,929] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:22:34,398] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:22:43,073] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:22:51,247] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:22:58,950] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4970029777726466
[2022-12-07 05:22:58,950] [INFO] [runner_train_mujoco] Average state value: 0.5167577186127504
[2022-12-07 05:22:58,950] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:22:59,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.05131
[2022-12-07 05:22:59,044] [INFO] [controller] EPOCH 2 loss ppo:  -0.04434, loss val: 0.05004
[2022-12-07 05:22:59,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.06516, loss val: 0.05183
[2022-12-07 05:22:59,119] [INFO] [controller] EPOCH 4 loss ppo:  -0.07967, loss val: 0.04912
[2022-12-07 05:22:59,128] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:22:59,319] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:22:59,319] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:23:07,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:23:15,582] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:23:24,577] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:23:33,090] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:23:41,794] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:23:50,081] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:23:57,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:24:05,632] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:24:13,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:24:22,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.489113522320686
[2022-12-07 05:24:22,256] [INFO] [runner_train_mujoco] Average state value: 0.5440004023512206
[2022-12-07 05:24:22,256] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 05:24:22,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.00809, loss val: 0.05529
[2022-12-07 05:24:22,362] [INFO] [controller] EPOCH 2 loss ppo:  -0.04104, loss val: 0.05554
[2022-12-07 05:24:22,411] [INFO] [controller] EPOCH 3 loss ppo:  -0.06201, loss val: 0.05608
[2022-12-07 05:24:22,455] [INFO] [controller] EPOCH 4 loss ppo:  -0.07788, loss val: 0.05289
[2022-12-07 05:24:22,464] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:24:22,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:24:22,674] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:24:30,522] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:24:38,917] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:24:47,230] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:24:55,311] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:25:03,851] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:25:11,911] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:25:20,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:25:28,801] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:25:36,884] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:25:45,147] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4624931030904522
[2022-12-07 05:25:45,147] [INFO] [runner_train_mujoco] Average state value: 0.5708696341911952
[2022-12-07 05:25:45,148] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 05:25:45,195] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.03824
[2022-12-07 05:25:45,238] [INFO] [controller] EPOCH 2 loss ppo:  -0.04615, loss val: 0.03747
[2022-12-07 05:25:45,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.06448, loss val: 0.03606
[2022-12-07 05:25:45,325] [INFO] [controller] EPOCH 4 loss ppo:  -0.07667, loss val: 0.03719
[2022-12-07 05:25:45,335] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:25:45,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:25:45,535] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:25:54,008] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:26:01,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:26:09,379] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:26:17,885] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:26:26,567] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:26:35,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:26:43,529] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:26:51,932] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:26:59,855] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:27:07,756] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5112852020461707
[2022-12-07 05:27:07,756] [INFO] [runner_train_mujoco] Average state value: 0.5510660091042519
[2022-12-07 05:27:07,756] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 05:27:07,816] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.04060
[2022-12-07 05:27:07,863] [INFO] [controller] EPOCH 2 loss ppo:  -0.04545, loss val: 0.04032
[2022-12-07 05:27:07,911] [INFO] [controller] EPOCH 3 loss ppo:  -0.06482, loss val: 0.04338
[2022-12-07 05:27:07,958] [INFO] [controller] EPOCH 4 loss ppo:  -0.07662, loss val: 0.04095
[2022-12-07 05:27:07,968] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:27:08,177] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:27:08,178] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:27:16,775] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:27:25,285] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:27:33,919] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:27:41,653] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:27:49,893] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:27:58,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:28:06,161] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:28:14,366] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:28:22,865] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:28:30,995] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7943422882571216
[2022-12-07 05:28:30,995] [INFO] [runner_train_mujoco] Average state value: 0.5173480505272746
[2022-12-07 05:28:30,995] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 05:28:31,050] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.04967
[2022-12-07 05:28:31,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.04082, loss val: 0.04884
[2022-12-07 05:28:31,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.06175, loss val: 0.04885
[2022-12-07 05:28:31,183] [INFO] [controller] EPOCH 4 loss ppo:  -0.07871, loss val: 0.04914
[2022-12-07 05:28:31,194] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:28:31,405] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:28:31,405] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:28:39,539] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:28:48,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:28:55,931] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:29:04,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:29:12,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:29:21,553] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:29:29,469] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:29:37,409] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:29:45,709] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:29:54,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.552404878351333
[2022-12-07 05:29:54,274] [INFO] [runner_train_mujoco] Average state value: 0.5181828347096841
[2022-12-07 05:29:54,274] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 05:29:54,358] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04820
[2022-12-07 05:29:54,411] [INFO] [controller] EPOCH 2 loss ppo:  -0.04403, loss val: 0.04565
[2022-12-07 05:29:54,464] [INFO] [controller] EPOCH 3 loss ppo:  -0.06523, loss val: 0.04610
[2022-12-07 05:29:54,548] [INFO] [controller] EPOCH 4 loss ppo:  -0.08069, loss val: 0.04353
[2022-12-07 05:29:54,559] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:29:54,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:29:54,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:30:04,704] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:30:12,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:30:20,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:30:28,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:30:37,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:30:45,102] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:30:53,041] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:31:01,268] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:31:09,879] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:31:18,152] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.86323148496684
[2022-12-07 05:31:18,152] [INFO] [runner_train_mujoco] Average state value: 0.4949811130215724
[2022-12-07 05:31:18,152] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 05:31:18,248] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.03745
[2022-12-07 05:31:18,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.04870, loss val: 0.03916
[2022-12-07 05:31:18,340] [INFO] [controller] EPOCH 3 loss ppo:  -0.06899, loss val: 0.03870
[2022-12-07 05:31:18,384] [INFO] [controller] EPOCH 4 loss ppo:  -0.08194, loss val: 0.03988
[2022-12-07 05:31:18,393] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:31:18,602] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:31:18,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:31:26,706] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:31:34,207] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:31:41,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:31:50,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:31:58,646] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:32:06,619] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:32:14,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:32:22,048] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:32:29,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:32:38,089] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5387759874641058
[2022-12-07 05:32:38,089] [INFO] [runner_train_mujoco] Average state value: 0.4620769256552061
[2022-12-07 05:32:38,089] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 05:32:38,150] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.05349
[2022-12-07 05:32:38,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.03892, loss val: 0.05557
[2022-12-07 05:32:38,247] [INFO] [controller] EPOCH 3 loss ppo:  -0.05776, loss val: 0.05138
[2022-12-07 05:32:38,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.07156, loss val: 0.05046
[2022-12-07 05:32:38,303] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:32:38,514] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:32:38,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:32:47,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:32:55,660] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:33:04,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:33:11,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:33:19,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:33:27,338] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:33:34,810] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:33:42,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:33:50,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:33:58,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7431013832056457
[2022-12-07 05:33:58,820] [INFO] [runner_train_mujoco] Average state value: 0.4926779690384865
[2022-12-07 05:33:58,820] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 05:33:58,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.04038
[2022-12-07 05:33:58,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.04517, loss val: 0.03611
[2022-12-07 05:33:58,990] [INFO] [controller] EPOCH 3 loss ppo:  -0.06481, loss val: 0.03579
[2022-12-07 05:33:59,052] [INFO] [controller] EPOCH 4 loss ppo:  -0.07763, loss val: 0.03935
[2022-12-07 05:33:59,062] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:33:59,297] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:33:59,297] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:34:07,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:34:15,652] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:34:24,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:34:31,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:34:39,708] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:34:49,044] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:34:58,154] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:35:05,725] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:35:13,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:35:21,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5368047049804052
[2022-12-07 05:35:21,340] [INFO] [runner_train_mujoco] Average state value: 0.5153096569180489
[2022-12-07 05:35:21,340] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 05:35:21,398] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.03802
[2022-12-07 05:35:21,443] [INFO] [controller] EPOCH 2 loss ppo:  -0.04461, loss val: 0.04009
[2022-12-07 05:35:21,493] [INFO] [controller] EPOCH 3 loss ppo:  -0.06488, loss val: 0.03904
[2022-12-07 05:35:21,541] [INFO] [controller] EPOCH 4 loss ppo:  -0.07928, loss val: 0.03803
[2022-12-07 05:35:21,550] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:35:21,754] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:35:21,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:35:29,376] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:35:38,179] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:35:46,565] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:35:54,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:36:02,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:36:09,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:36:17,612] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:36:25,347] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:36:33,591] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:36:42,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7731528015465146
[2022-12-07 05:36:42,224] [INFO] [runner_train_mujoco] Average state value: 0.5386805290381113
[2022-12-07 05:36:42,224] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 05:36:42,292] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.03661
[2022-12-07 05:36:42,338] [INFO] [controller] EPOCH 2 loss ppo:  -0.04014, loss val: 0.03643
[2022-12-07 05:36:42,391] [INFO] [controller] EPOCH 3 loss ppo:  -0.05903, loss val: 0.03613
[2022-12-07 05:36:42,440] [INFO] [controller] EPOCH 4 loss ppo:  -0.07404, loss val: 0.03505
[2022-12-07 05:36:42,450] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:36:42,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:36:42,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:36:51,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:36:58,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:37:06,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:37:14,264] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:37:22,228] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:37:30,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:37:39,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:37:47,054] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:37:54,802] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:38:02,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7155610628038989
[2022-12-07 05:38:02,704] [INFO] [runner_train_mujoco] Average state value: 0.5105318102637926
[2022-12-07 05:38:02,704] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 05:38:02,757] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.03732
[2022-12-07 05:38:02,800] [INFO] [controller] EPOCH 2 loss ppo:  -0.03731, loss val: 0.03829
[2022-12-07 05:38:02,847] [INFO] [controller] EPOCH 3 loss ppo:  -0.05619, loss val: 0.03674
[2022-12-07 05:38:02,889] [INFO] [controller] EPOCH 4 loss ppo:  -0.06984, loss val: 0.03762
[2022-12-07 05:38:02,899] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:38:03,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:38:03,112] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:38:11,314] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:38:19,736] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:38:28,055] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:38:35,674] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:38:43,558] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:38:51,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:38:59,306] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:39:07,139] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:39:14,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:39:23,343] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5138211548819953
[2022-12-07 05:39:23,343] [INFO] [runner_train_mujoco] Average state value: 0.5233027266065279
[2022-12-07 05:39:23,344] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 05:39:23,395] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.04125
[2022-12-07 05:39:23,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.04178, loss val: 0.04063
[2022-12-07 05:39:23,480] [INFO] [controller] EPOCH 3 loss ppo:  -0.06113, loss val: 0.04007
[2022-12-07 05:39:23,524] [INFO] [controller] EPOCH 4 loss ppo:  -0.07863, loss val: 0.04130
[2022-12-07 05:39:23,533] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:39:23,767] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:39:23,767] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:39:32,144] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:39:40,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:39:47,771] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:39:55,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:40:03,137] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:40:11,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:40:19,358] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:40:27,390] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:40:35,293] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:40:43,368] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8508853342883413
[2022-12-07 05:40:43,369] [INFO] [runner_train_mujoco] Average state value: 0.5300441915988923
[2022-12-07 05:40:43,369] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 05:40:43,428] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04655
[2022-12-07 05:40:43,479] [INFO] [controller] EPOCH 2 loss ppo:  -0.03975, loss val: 0.04597
[2022-12-07 05:40:43,547] [INFO] [controller] EPOCH 3 loss ppo:  -0.05876, loss val: 0.04652
[2022-12-07 05:40:43,596] [INFO] [controller] EPOCH 4 loss ppo:  -0.07399, loss val: 0.04543
[2022-12-07 05:40:43,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:40:43,821] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:40:43,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:40:51,771] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:40:59,798] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:41:07,374] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:41:15,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:41:23,469] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:41:31,073] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:41:38,626] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:41:46,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:41:54,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:42:04,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.721166768197543
[2022-12-07 05:42:04,841] [INFO] [runner_train_mujoco] Average state value: 0.520549400617679
[2022-12-07 05:42:04,841] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 05:42:04,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01499, loss val: 0.03076
[2022-12-07 05:42:04,967] [INFO] [controller] EPOCH 2 loss ppo:  -0.03775, loss val: 0.03166
[2022-12-07 05:42:05,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.05611, loss val: 0.03046
[2022-12-07 05:42:05,085] [INFO] [controller] EPOCH 4 loss ppo:  -0.07153, loss val: 0.02982
[2022-12-07 05:42:05,095] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:42:05,312] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:42:05,312] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:42:14,744] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:42:23,770] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:42:32,467] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:42:41,256] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:42:50,348] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:42:58,946] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:43:07,076] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:43:15,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:43:25,098] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:43:32,870] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.824192417651717
[2022-12-07 05:43:32,870] [INFO] [runner_train_mujoco] Average state value: 0.48455808093150454
[2022-12-07 05:43:32,870] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 05:43:32,921] [INFO] [controller] EPOCH 1 loss ppo:  -0.01637, loss val: 0.04198
[2022-12-07 05:43:32,958] [INFO] [controller] EPOCH 2 loss ppo:  -0.04276, loss val: 0.04325
[2022-12-07 05:43:33,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.06373, loss val: 0.04084
[2022-12-07 05:43:33,048] [INFO] [controller] EPOCH 4 loss ppo:  -0.07837, loss val: 0.04184
[2022-12-07 05:43:33,057] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:43:33,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:43:33,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:43:41,390] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:43:49,650] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:43:57,453] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:44:05,643] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:44:13,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:44:21,320] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:44:28,577] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:44:35,734] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:44:42,943] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:44:50,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4236305897509334
[2022-12-07 05:44:50,190] [INFO] [runner_train_mujoco] Average state value: 0.5088922260502974
[2022-12-07 05:44:50,190] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 05:44:50,242] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.05100
[2022-12-07 05:44:50,281] [INFO] [controller] EPOCH 2 loss ppo:  -0.03248, loss val: 0.05114
[2022-12-07 05:44:50,323] [INFO] [controller] EPOCH 3 loss ppo:  -0.05046, loss val: 0.05027
[2022-12-07 05:44:50,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.06504, loss val: 0.04901
[2022-12-07 05:44:50,373] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:44:50,577] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:44:50,577] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:44:57,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:45:05,255] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:45:12,584] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:45:19,709] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:45:26,765] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:45:33,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:45:40,778] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:45:48,941] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:45:55,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:46:03,145] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5776123472387518
[2022-12-07 05:46:03,146] [INFO] [runner_train_mujoco] Average state value: 0.5246514865557352
[2022-12-07 05:46:03,146] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 05:46:03,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04467
[2022-12-07 05:46:03,285] [INFO] [controller] EPOCH 2 loss ppo:  -0.03743, loss val: 0.04060
[2022-12-07 05:46:03,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.05939, loss val: 0.03975
[2022-12-07 05:46:03,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.07463, loss val: 0.04058
[2022-12-07 05:46:03,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:46:03,579] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:46:03,579] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:46:10,983] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:46:18,576] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:46:25,786] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:46:33,448] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:46:41,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:46:48,373] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:46:55,499] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:47:02,433] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:47:09,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:47:17,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8300302884720936
[2022-12-07 05:47:17,273] [INFO] [runner_train_mujoco] Average state value: 0.5373674013912677
[2022-12-07 05:47:17,273] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 05:47:17,324] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.03546
[2022-12-07 05:47:17,370] [INFO] [controller] EPOCH 2 loss ppo:  -0.03925, loss val: 0.03374
[2022-12-07 05:47:17,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.05652, loss val: 0.03440
[2022-12-07 05:47:17,472] [INFO] [controller] EPOCH 4 loss ppo:  -0.06912, loss val: 0.03859
[2022-12-07 05:47:17,479] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:47:17,677] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:47:17,677] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:47:24,752] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:47:32,271] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:47:39,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:47:46,646] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:47:53,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:48:01,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:48:08,606] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:48:16,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:48:24,349] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:48:31,359] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4825197244385753
[2022-12-07 05:48:31,359] [INFO] [runner_train_mujoco] Average state value: 0.5381077417731285
[2022-12-07 05:48:31,359] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 05:48:31,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.03543
[2022-12-07 05:48:31,456] [INFO] [controller] EPOCH 2 loss ppo:  -0.03091, loss val: 0.03514
[2022-12-07 05:48:31,501] [INFO] [controller] EPOCH 3 loss ppo:  -0.05312, loss val: 0.03563
[2022-12-07 05:48:31,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.06956, loss val: 0.03537
[2022-12-07 05:48:31,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:48:31,758] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:48:31,758] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:48:38,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:48:46,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:48:53,807] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:49:01,367] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:49:08,820] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:49:16,043] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:49:23,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:49:30,838] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:49:37,878] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:49:45,080] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.418652936902316
[2022-12-07 05:49:45,080] [INFO] [runner_train_mujoco] Average state value: 0.5329411578873794
[2022-12-07 05:49:45,080] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 05:49:45,133] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.03813
[2022-12-07 05:49:45,178] [INFO] [controller] EPOCH 2 loss ppo:  -0.03530, loss val: 0.03833
[2022-12-07 05:49:45,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.05579, loss val: 0.03910
[2022-12-07 05:49:45,266] [INFO] [controller] EPOCH 4 loss ppo:  -0.06929, loss val: 0.03798
[2022-12-07 05:49:45,274] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:49:45,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:49:45,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:49:52,846] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:50:00,967] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:50:08,374] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:50:15,220] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:50:22,177] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:50:29,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:50:36,518] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:50:43,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:50:50,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:50:58,030] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.726261571663572
[2022-12-07 05:50:58,030] [INFO] [runner_train_mujoco] Average state value: 0.5352427568236987
[2022-12-07 05:50:58,030] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 05:50:58,081] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.04052
[2022-12-07 05:50:58,123] [INFO] [controller] EPOCH 2 loss ppo:  -0.03255, loss val: 0.04449
[2022-12-07 05:50:58,164] [INFO] [controller] EPOCH 3 loss ppo:  -0.05228, loss val: 0.04245
[2022-12-07 05:50:58,208] [INFO] [controller] EPOCH 4 loss ppo:  -0.06801, loss val: 0.03389
[2022-12-07 05:50:58,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:50:58,403] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:50:58,403] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:51:05,781] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:51:13,025] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:51:20,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:51:27,104] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:51:34,441] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:51:41,744] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:51:49,081] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:51:55,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:52:03,146] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:52:10,232] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6624050780999522
[2022-12-07 05:52:10,232] [INFO] [runner_train_mujoco] Average state value: 0.5392609498997529
[2022-12-07 05:52:10,232] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 05:52:10,284] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04221
[2022-12-07 05:52:10,322] [INFO] [controller] EPOCH 2 loss ppo:  -0.03156, loss val: 0.04176
[2022-12-07 05:52:10,363] [INFO] [controller] EPOCH 3 loss ppo:  -0.05397, loss val: 0.03977
[2022-12-07 05:52:10,405] [INFO] [controller] EPOCH 4 loss ppo:  -0.06878, loss val: 0.03994
[2022-12-07 05:52:10,414] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:52:10,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:52:10,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:52:18,153] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:52:26,171] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:52:33,331] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:52:40,233] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:52:47,207] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:52:54,515] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:53:01,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:53:08,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:53:15,758] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:53:22,673] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5882318918869622
[2022-12-07 05:53:22,673] [INFO] [runner_train_mujoco] Average state value: 0.5367551664710045
[2022-12-07 05:53:22,673] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 05:53:22,721] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.03612
[2022-12-07 05:53:22,769] [INFO] [controller] EPOCH 2 loss ppo:  -0.03196, loss val: 0.03893
[2022-12-07 05:53:22,810] [INFO] [controller] EPOCH 3 loss ppo:  -0.05321, loss val: 0.03476
[2022-12-07 05:53:22,853] [INFO] [controller] EPOCH 4 loss ppo:  -0.06921, loss val: 0.03463
[2022-12-07 05:53:22,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:53:23,067] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:53:23,067] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:53:30,622] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:53:37,802] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:53:44,834] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:53:52,350] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:53:59,587] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:54:06,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:54:13,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:54:20,706] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:54:27,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:54:35,219] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.809471906358318
[2022-12-07 05:54:35,219] [INFO] [runner_train_mujoco] Average state value: 0.5129220136801402
[2022-12-07 05:54:35,220] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 05:54:35,266] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04091
[2022-12-07 05:54:35,306] [INFO] [controller] EPOCH 2 loss ppo:  -0.03193, loss val: 0.04018
[2022-12-07 05:54:35,347] [INFO] [controller] EPOCH 3 loss ppo:  -0.05076, loss val: 0.03847
[2022-12-07 05:54:35,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.06589, loss val: 0.03955
[2022-12-07 05:54:35,398] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:54:35,601] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:54:35,601] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:54:43,283] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:54:50,852] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:54:57,705] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:55:04,925] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:55:11,857] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:55:18,865] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:55:26,232] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:55:33,509] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:55:40,639] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:55:48,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8610264187420777
[2022-12-07 05:55:48,028] [INFO] [runner_train_mujoco] Average state value: 0.5051730301181475
[2022-12-07 05:55:48,028] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 05:55:48,081] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.03566
[2022-12-07 05:55:48,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.03077, loss val: 0.03276
[2022-12-07 05:55:48,170] [INFO] [controller] EPOCH 3 loss ppo:  -0.05018, loss val: 0.03261
[2022-12-07 05:55:48,215] [INFO] [controller] EPOCH 4 loss ppo:  -0.06462, loss val: 0.03669
[2022-12-07 05:55:48,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:55:48,433] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:55:48,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:55:55,573] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:56:02,836] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:56:09,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:56:16,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:56:24,046] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:56:31,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:56:38,650] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:56:45,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:56:52,997] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:57:00,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.010961478313326
[2022-12-07 05:57:00,378] [INFO] [runner_train_mujoco] Average state value: 0.5144835134545962
[2022-12-07 05:57:00,378] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 05:57:00,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04753
[2022-12-07 05:57:00,483] [INFO] [controller] EPOCH 2 loss ppo:  -0.03047, loss val: 0.04654
[2022-12-07 05:57:00,532] [INFO] [controller] EPOCH 3 loss ppo:  -0.04780, loss val: 0.04683
[2022-12-07 05:57:00,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.06241, loss val: 0.04561
[2022-12-07 05:57:00,587] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:57:00,825] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:57:00,826] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:57:08,033] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:57:15,707] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:57:22,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:57:29,773] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:57:37,209] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:57:44,294] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:57:51,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:57:58,548] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:58:05,897] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:58:14,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7874149637899641
[2022-12-07 05:58:14,309] [INFO] [runner_train_mujoco] Average state value: 0.5200903321901957
[2022-12-07 05:58:14,309] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 05:58:14,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.03525
[2022-12-07 05:58:14,409] [INFO] [controller] EPOCH 2 loss ppo:  -0.02732, loss val: 0.03441
[2022-12-07 05:58:14,457] [INFO] [controller] EPOCH 3 loss ppo:  -0.04744, loss val: 0.03412
[2022-12-07 05:58:14,508] [INFO] [controller] EPOCH 4 loss ppo:  -0.06276, loss val: 0.03528
[2022-12-07 05:58:14,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:58:14,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:58:14,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:58:22,090] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:58:29,110] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:58:36,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:58:43,580] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:58:51,004] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:58:58,047] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:59:05,253] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:59:12,443] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:59:19,570] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:59:26,353] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6722745325497996
[2022-12-07 05:59:26,353] [INFO] [runner_train_mujoco] Average state value: 0.5139365240732829
[2022-12-07 05:59:26,353] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 05:59:26,454] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.03782
[2022-12-07 05:59:26,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.02836, loss val: 0.03208
[2022-12-07 05:59:26,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.04591, loss val: 0.03195
[2022-12-07 05:59:26,573] [INFO] [controller] EPOCH 4 loss ppo:  -0.05976, loss val: 0.03195
[2022-12-07 05:59:26,581] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:59:26,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:59:26,776] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:59:34,271] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:59:41,479] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:59:49,063] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:59:56,427] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:00:03,555] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:00:10,939] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:00:18,082] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:00:25,829] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:00:32,964] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:00:40,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7224872230519561
[2022-12-07 06:00:40,149] [INFO] [runner_train_mujoco] Average state value: 0.5287587664524713
[2022-12-07 06:00:40,149] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 06:00:40,195] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04183
[2022-12-07 06:00:40,234] [INFO] [controller] EPOCH 2 loss ppo:  -0.02628, loss val: 0.04191
[2022-12-07 06:00:40,274] [INFO] [controller] EPOCH 3 loss ppo:  -0.04391, loss val: 0.04027
[2022-12-07 06:00:40,315] [INFO] [controller] EPOCH 4 loss ppo:  -0.05743, loss val: 0.03949
[2022-12-07 06:00:40,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:00:40,512] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:00:40,512] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:00:47,660] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:00:54,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:01:01,664] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:01:09,196] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:01:16,953] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:01:24,013] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:01:31,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:01:38,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:01:45,587] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:01:52,927] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8715675374326275
[2022-12-07 06:01:52,928] [INFO] [runner_train_mujoco] Average state value: 0.5361787642637889
[2022-12-07 06:01:52,928] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 06:01:52,977] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.03514
[2022-12-07 06:01:53,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.02753, loss val: 0.03524
[2022-12-07 06:01:53,058] [INFO] [controller] EPOCH 3 loss ppo:  -0.04524, loss val: 0.03789
[2022-12-07 06:01:53,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.05799, loss val: 0.03520
[2022-12-07 06:01:53,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:01:53,314] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:01:53,314] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:02:00,878] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:02:08,591] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:02:15,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:02:23,123] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:02:30,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:02:37,395] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:02:44,715] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:02:52,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:02:59,943] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:03:07,466] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9271205847197042
[2022-12-07 06:03:07,482] [INFO] [runner_train_mujoco] Average state value: 0.5424651726086934
[2022-12-07 06:03:07,483] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 06:03:07,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.03936
[2022-12-07 06:03:07,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.02633, loss val: 0.03878
[2022-12-07 06:03:07,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.04419, loss val: 0.03804
[2022-12-07 06:03:07,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.05966, loss val: 0.03907
[2022-12-07 06:03:07,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:03:07,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:03:07,909] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:03:15,215] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:03:22,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:03:29,485] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:03:36,433] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:03:43,828] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:03:51,090] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:03:58,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:04:05,954] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:04:13,010] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:04:19,964] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.877093572429193
[2022-12-07 06:04:19,964] [INFO] [runner_train_mujoco] Average state value: 0.5497974403103192
[2022-12-07 06:04:19,964] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 06:04:20,016] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.04411
[2022-12-07 06:04:20,056] [INFO] [controller] EPOCH 2 loss ppo:  -0.02464, loss val: 0.04451
[2022-12-07 06:04:20,098] [INFO] [controller] EPOCH 3 loss ppo:  -0.04057, loss val: 0.04338
[2022-12-07 06:04:20,141] [INFO] [controller] EPOCH 4 loss ppo:  -0.05424, loss val: 0.04465
[2022-12-07 06:04:20,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:04:20,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:04:20,348] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:04:27,734] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:04:35,200] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:04:42,080] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:04:49,424] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:04:56,326] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:05:04,159] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:05:11,641] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:05:18,749] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:05:25,650] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:05:32,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9260801697074357
[2022-12-07 06:05:32,332] [INFO] [runner_train_mujoco] Average state value: 0.5458160738150278
[2022-12-07 06:05:32,332] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 06:05:32,382] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.04353
[2022-12-07 06:05:32,429] [INFO] [controller] EPOCH 2 loss ppo:  -0.01801, loss val: 0.04397
[2022-12-07 06:05:32,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.02824, loss val: 0.04357
[2022-12-07 06:05:32,518] [INFO] [controller] EPOCH 4 loss ppo:  -0.03952, loss val: 0.04476
[2022-12-07 06:05:32,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:05:32,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:05:32,739] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:05:39,838] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:05:47,679] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:05:54,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:06:02,246] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:06:09,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:06:16,972] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:06:24,160] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:06:31,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:06:38,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:06:45,895] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0182782277909306
[2022-12-07 06:06:45,895] [INFO] [runner_train_mujoco] Average state value: 0.5469968520800272
[2022-12-07 06:06:45,895] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 06:06:45,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01387, loss val: 0.04469
[2022-12-07 06:06:46,001] [INFO] [controller] EPOCH 2 loss ppo:  -0.02013, loss val: 0.04788
[2022-12-07 06:06:46,046] [INFO] [controller] EPOCH 3 loss ppo:  -0.03109, loss val: 0.04478
[2022-12-07 06:06:46,090] [INFO] [controller] EPOCH 4 loss ppo:  -0.04252, loss val: 0.04469
[2022-12-07 06:06:46,096] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:06:46,298] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:06:46,299] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:06:53,422] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:07:00,553] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:07:09,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:07:17,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:07:24,896] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:07:32,745] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:07:40,116] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:07:47,088] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:07:54,048] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:08:00,954] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8450785487206436
[2022-12-07 06:08:00,954] [INFO] [runner_train_mujoco] Average state value: 0.5525370200673739
[2022-12-07 06:08:00,954] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 06:08:01,006] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04831
[2022-12-07 06:08:01,050] [INFO] [controller] EPOCH 2 loss ppo:  -0.01746, loss val: 0.03960
[2022-12-07 06:08:01,094] [INFO] [controller] EPOCH 3 loss ppo:  -0.02506, loss val: 0.04698
[2022-12-07 06:08:01,137] [INFO] [controller] EPOCH 4 loss ppo:  -0.03496, loss val: 0.04718
[2022-12-07 06:08:01,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:08:01,344] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:08:01,345] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:08:09,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:08:16,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:08:23,877] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:08:31,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:08:38,635] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:08:46,445] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:08:53,974] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:09:00,990] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:09:08,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:09:15,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.776055343561951
[2022-12-07 06:09:15,013] [INFO] [runner_train_mujoco] Average state value: 0.5548445544640224
[2022-12-07 06:09:15,013] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 06:09:15,063] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.03001
[2022-12-07 06:09:15,102] [INFO] [controller] EPOCH 2 loss ppo:  -0.01691, loss val: 0.03506
[2022-12-07 06:09:15,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.02305, loss val: 0.02981
[2022-12-07 06:09:15,181] [INFO] [controller] EPOCH 4 loss ppo:  -0.03136, loss val: 0.03022
[2022-12-07 06:09:15,189] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:09:15,391] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:09:15,392] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:09:22,509] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:09:29,834] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:09:36,868] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:09:44,258] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:09:51,952] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:09:59,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:10:06,590] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:10:13,574] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:10:20,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:10:27,910] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.895866701678037
[2022-12-07 06:10:27,911] [INFO] [runner_train_mujoco] Average state value: 0.5438655044436455
[2022-12-07 06:10:27,911] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 06:10:27,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.03721
[2022-12-07 06:10:28,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.01669, loss val: 0.03803
[2022-12-07 06:10:28,049] [INFO] [controller] EPOCH 3 loss ppo:  -0.02148, loss val: 0.03680
[2022-12-07 06:10:28,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.02758, loss val: 0.03659
[2022-12-07 06:10:28,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:10:28,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:10:28,302] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:10:36,137] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:10:43,524] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:10:50,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:10:57,510] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:11:05,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:11:12,274] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:11:19,787] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:11:26,432] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:11:33,722] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:11:40,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.927746764347105
[2022-12-07 06:11:40,634] [INFO] [runner_train_mujoco] Average state value: 0.5578741545279821
[2022-12-07 06:11:40,634] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 06:11:40,684] [INFO] [controller] EPOCH 1 loss ppo:  -0.01401, loss val: 0.03609
[2022-12-07 06:11:40,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.01535, loss val: 0.03559
[2022-12-07 06:11:40,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.01786, loss val: 0.03611
[2022-12-07 06:11:40,807] [INFO] [controller] EPOCH 4 loss ppo:  -0.02109, loss val: 0.03608
[2022-12-07 06:11:40,815] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:11:40,912] [INFO] [optimize] Finished learning.
