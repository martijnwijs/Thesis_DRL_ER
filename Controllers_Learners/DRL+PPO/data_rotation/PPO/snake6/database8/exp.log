[2022-12-07 06:11:44,170] [INFO] [optimize] Starting learning
[2022-12-07 06:11:44,175] [INFO] [optimize] Starting learning process..
[2022-12-07 06:11:44,234] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:11:44,234] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:11:50,136] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:11:54,189] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:11:58,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:12:02,454] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:12:06,886] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:12:10,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:12:14,874] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:12:19,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:12:23,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:12:27,800] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47140258111586436
[2022-12-07 06:12:27,801] [INFO] [runner_train_mujoco] Average state value: -0.2772798516352971
[2022-12-07 06:12:27,801] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 06:12:27,860] [INFO] [controller] EPOCH 1 loss ppo:  -0.01586, loss val: 0.74499
[2022-12-07 06:12:27,908] [INFO] [controller] EPOCH 2 loss ppo:  -0.03008, loss val: 0.67518
[2022-12-07 06:12:27,956] [INFO] [controller] EPOCH 3 loss ppo:  -0.03831, loss val: 0.59379
[2022-12-07 06:12:28,013] [INFO] [controller] EPOCH 4 loss ppo:  -0.04016, loss val: 0.52539
[2022-12-07 06:12:28,029] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:12:28,192] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:12:28,193] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:12:32,508] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:12:36,572] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:12:40,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:12:44,720] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:12:49,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:12:53,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:12:57,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:13:01,840] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:13:05,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:13:10,059] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4709606011561968
[2022-12-07 06:13:10,059] [INFO] [runner_train_mujoco] Average state value: -0.08916034657756486
[2022-12-07 06:13:10,059] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 06:13:10,115] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.35595
[2022-12-07 06:13:10,159] [INFO] [controller] EPOCH 2 loss ppo:  -0.02874, loss val: 0.30716
[2022-12-07 06:13:10,205] [INFO] [controller] EPOCH 3 loss ppo:  -0.03391, loss val: 0.25817
[2022-12-07 06:13:10,253] [INFO] [controller] EPOCH 4 loss ppo:  -0.03689, loss val: 0.22006
[2022-12-07 06:13:10,264] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:13:10,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:13:10,421] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:13:14,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:13:18,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:13:23,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:13:27,362] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:13:31,580] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:13:35,698] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:13:39,684] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:13:43,677] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:13:47,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:13:51,679] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42070534959325967
[2022-12-07 06:13:51,679] [INFO] [runner_train_mujoco] Average state value: 0.10294498958314457
[2022-12-07 06:13:51,679] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 06:13:51,728] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.24201
[2022-12-07 06:13:51,774] [INFO] [controller] EPOCH 2 loss ppo:  -0.02771, loss val: 0.21080
[2022-12-07 06:13:51,819] [INFO] [controller] EPOCH 3 loss ppo:  -0.02929, loss val: 0.17157
[2022-12-07 06:13:51,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.03390, loss val: 0.14678
[2022-12-07 06:13:51,872] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:13:52,026] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:13:52,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:13:56,157] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:14:00,604] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:14:04,858] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:14:09,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:14:12,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:14:16,627] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:14:20,908] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:14:24,768] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:14:28,538] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:14:32,592] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.553658807335015
[2022-12-07 06:14:32,593] [INFO] [runner_train_mujoco] Average state value: 0.2820697785889109
[2022-12-07 06:14:32,593] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 06:14:32,653] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.12013
[2022-12-07 06:14:32,702] [INFO] [controller] EPOCH 2 loss ppo:  -0.02690, loss val: 0.10647
[2022-12-07 06:14:32,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.03276, loss val: 0.08276
[2022-12-07 06:14:32,799] [INFO] [controller] EPOCH 4 loss ppo:  -0.03596, loss val: 0.07302
[2022-12-07 06:14:32,807] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:14:32,962] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:14:32,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:14:37,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:14:40,999] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:14:45,624] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:14:49,753] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:14:53,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:14:58,275] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:15:02,281] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:15:06,228] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:15:10,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:15:14,186] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5324442902943873
[2022-12-07 06:15:14,187] [INFO] [runner_train_mujoco] Average state value: 0.4472631809736292
[2022-12-07 06:15:14,187] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 06:15:14,253] [INFO] [controller] EPOCH 1 loss ppo:  -0.01049, loss val: 0.05203
[2022-12-07 06:15:14,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.02738, loss val: 0.04713
[2022-12-07 06:15:14,366] [INFO] [controller] EPOCH 3 loss ppo:  -0.03078, loss val: 0.04348
[2022-12-07 06:15:14,426] [INFO] [controller] EPOCH 4 loss ppo:  -0.03450, loss val: 0.04052
[2022-12-07 06:15:14,436] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:15:14,588] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:15:14,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:15:18,787] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:15:22,664] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:15:26,872] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:15:31,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:15:35,212] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:15:39,202] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:15:43,591] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:15:48,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:15:52,137] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:15:56,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6296134388451381
[2022-12-07 06:15:56,066] [INFO] [runner_train_mujoco] Average state value: 0.5219808877110481
[2022-12-07 06:15:56,066] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 06:15:56,119] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.03882
[2022-12-07 06:15:56,163] [INFO] [controller] EPOCH 2 loss ppo:  -0.02575, loss val: 0.03397
[2022-12-07 06:15:56,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.02791, loss val: 0.03344
[2022-12-07 06:15:56,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.03089, loss val: 0.03143
[2022-12-07 06:15:56,279] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:15:56,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:15:56,446] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:16:00,133] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:16:04,181] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:16:08,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:16:12,805] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:16:16,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:16:20,838] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:16:24,643] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:16:28,547] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:16:33,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:16:36,955] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5530188773679156
[2022-12-07 06:16:36,955] [INFO] [runner_train_mujoco] Average state value: 0.5018524799744288
[2022-12-07 06:16:36,956] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 06:16:37,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.04660
[2022-12-07 06:16:37,075] [INFO] [controller] EPOCH 2 loss ppo:  -0.02672, loss val: 0.04631
[2022-12-07 06:16:37,133] [INFO] [controller] EPOCH 3 loss ppo:  -0.02953, loss val: 0.04493
[2022-12-07 06:16:37,188] [INFO] [controller] EPOCH 4 loss ppo:  -0.02990, loss val: 0.04425
[2022-12-07 06:16:37,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:16:37,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:16:37,361] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:16:41,861] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:16:45,983] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:16:50,168] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:16:53,922] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:16:57,792] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:17:01,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:17:05,594] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:17:09,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:17:13,706] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:17:17,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5727125330519244
[2022-12-07 06:17:17,780] [INFO] [runner_train_mujoco] Average state value: 0.5322721018989881
[2022-12-07 06:17:17,781] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 06:17:17,845] [INFO] [controller] EPOCH 1 loss ppo:  -0.01170, loss val: 0.03765
[2022-12-07 06:17:17,892] [INFO] [controller] EPOCH 2 loss ppo:  -0.02800, loss val: 0.03639
[2022-12-07 06:17:17,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.03229, loss val: 0.03524
[2022-12-07 06:17:17,987] [INFO] [controller] EPOCH 4 loss ppo:  -0.03584, loss val: 0.03514
[2022-12-07 06:17:17,996] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:17:18,150] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:17:18,150] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:17:22,289] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:17:26,579] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:17:30,932] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:17:35,245] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:17:39,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:17:43,623] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:17:47,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:17:51,852] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:17:55,750] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:17:59,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9265087534347177
[2022-12-07 06:17:59,813] [INFO] [runner_train_mujoco] Average state value: 0.6009880373279254
[2022-12-07 06:17:59,813] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 06:17:59,865] [INFO] [controller] EPOCH 1 loss ppo:  -0.01133, loss val: 0.04463
[2022-12-07 06:17:59,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.01913, loss val: 0.04450
[2022-12-07 06:17:59,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.02169, loss val: 0.04062
[2022-12-07 06:18:00,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.02725, loss val: 0.03637
[2022-12-07 06:18:00,040] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:18:00,201] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:18:00,201] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:18:04,367] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:18:08,199] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:18:12,341] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:18:16,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:18:20,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:18:24,261] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:18:28,161] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:18:32,026] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:18:36,279] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:18:39,915] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.025743600782662
[2022-12-07 06:18:39,915] [INFO] [runner_train_mujoco] Average state value: 0.5453611600597699
[2022-12-07 06:18:39,915] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 06:18:39,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.03918
[2022-12-07 06:18:40,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.02229, loss val: 0.04143
[2022-12-07 06:18:40,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.02309, loss val: 0.04124
[2022-12-07 06:18:40,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.02855, loss val: 0.03942
[2022-12-07 06:18:40,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:18:40,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:18:40,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:18:44,591] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:18:48,845] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:18:52,960] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:18:56,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:19:01,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:19:05,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:19:09,361] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:19:13,124] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:19:16,830] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:19:21,199] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0693862734383235
[2022-12-07 06:19:21,199] [INFO] [runner_train_mujoco] Average state value: 0.5533223174611728
[2022-12-07 06:19:21,199] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 06:19:21,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04565
[2022-12-07 06:19:21,304] [INFO] [controller] EPOCH 2 loss ppo:  -0.02365, loss val: 0.04138
[2022-12-07 06:19:21,354] [INFO] [controller] EPOCH 3 loss ppo:  -0.02979, loss val: 0.03859
[2022-12-07 06:19:21,401] [INFO] [controller] EPOCH 4 loss ppo:  -0.03463, loss val: 0.03695
[2022-12-07 06:19:21,410] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:19:21,573] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:19:21,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:19:25,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:19:30,179] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:19:34,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:19:38,822] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:19:43,205] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:19:47,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:19:51,720] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:19:55,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:19:59,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:20:03,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6112765511338896
[2022-12-07 06:20:03,509] [INFO] [runner_train_mujoco] Average state value: 0.6522137989203135
[2022-12-07 06:20:03,509] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 06:20:03,567] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.05542
[2022-12-07 06:20:03,612] [INFO] [controller] EPOCH 2 loss ppo:  -0.02735, loss val: 0.05981
[2022-12-07 06:20:03,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.02854, loss val: 0.05788
[2022-12-07 06:20:03,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.03130, loss val: 0.05544
[2022-12-07 06:20:03,716] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:20:03,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:20:03,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:20:08,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:20:11,905] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:20:16,109] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:20:20,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:20:24,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:20:27,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:20:31,706] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:20:35,984] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:20:39,823] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:20:43,927] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7987888500842104
[2022-12-07 06:20:43,928] [INFO] [runner_train_mujoco] Average state value: 0.6304502047101657
[2022-12-07 06:20:43,928] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 06:20:43,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.04475
[2022-12-07 06:20:44,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.03071, loss val: 0.04381
[2022-12-07 06:20:44,093] [INFO] [controller] EPOCH 3 loss ppo:  -0.03134, loss val: 0.04291
[2022-12-07 06:20:44,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.03844, loss val: 0.04457
[2022-12-07 06:20:44,169] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:20:44,339] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:20:44,340] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:20:48,880] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:20:52,619] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:20:56,746] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:21:00,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:21:04,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:21:08,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:21:12,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:21:16,271] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:21:20,244] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:21:24,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.886845067418669
[2022-12-07 06:21:24,214] [INFO] [runner_train_mujoco] Average state value: 0.5667197205622991
[2022-12-07 06:21:24,214] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 06:21:24,306] [INFO] [controller] EPOCH 1 loss ppo:  -0.01055, loss val: 0.03898
[2022-12-07 06:21:24,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.02101, loss val: 0.03789
[2022-12-07 06:21:24,388] [INFO] [controller] EPOCH 3 loss ppo:  -0.02798, loss val: 0.03839
[2022-12-07 06:21:24,429] [INFO] [controller] EPOCH 4 loss ppo:  -0.03479, loss val: 0.03789
[2022-12-07 06:21:24,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:21:24,591] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:21:24,591] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:21:28,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:21:33,360] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:21:37,714] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:21:42,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:21:46,144] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:21:50,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:21:54,171] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:21:57,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:22:01,751] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:22:05,849] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8714748568538453
[2022-12-07 06:22:05,849] [INFO] [runner_train_mujoco] Average state value: 0.5257621609369914
[2022-12-07 06:22:05,849] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 06:22:05,909] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.03572
[2022-12-07 06:22:05,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.02663, loss val: 0.03563
[2022-12-07 06:22:06,074] [INFO] [controller] EPOCH 3 loss ppo:  -0.03076, loss val: 0.03487
[2022-12-07 06:22:06,122] [INFO] [controller] EPOCH 4 loss ppo:  -0.03517, loss val: 0.03499
[2022-12-07 06:22:06,132] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:22:06,286] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:22:06,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:22:10,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:22:14,216] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:22:18,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:22:23,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:22:27,100] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:22:31,104] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:22:34,942] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:22:38,638] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:22:42,859] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:22:47,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.399473784049029
[2022-12-07 06:22:47,045] [INFO] [runner_train_mujoco] Average state value: 0.4938749684294065
[2022-12-07 06:22:47,045] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 06:22:47,097] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.04340
[2022-12-07 06:22:47,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.02782, loss val: 0.04471
[2022-12-07 06:22:47,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.03387, loss val: 0.04470
[2022-12-07 06:22:47,230] [INFO] [controller] EPOCH 4 loss ppo:  -0.03794, loss val: 0.04327
[2022-12-07 06:22:47,239] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:22:47,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:22:47,398] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:22:51,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:22:55,890] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:22:59,970] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:23:03,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:23:07,212] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:23:11,273] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:23:15,289] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:23:19,367] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:23:23,314] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:23:26,902] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.504198950381368
[2022-12-07 06:23:26,902] [INFO] [runner_train_mujoco] Average state value: 0.4910855252146721
[2022-12-07 06:23:26,902] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 06:23:26,962] [INFO] [controller] EPOCH 1 loss ppo:  -0.01724, loss val: 0.03607
[2022-12-07 06:23:27,004] [INFO] [controller] EPOCH 2 loss ppo:  -0.02544, loss val: 0.03184
[2022-12-07 06:23:27,072] [INFO] [controller] EPOCH 3 loss ppo:  -0.03384, loss val: 0.03617
[2022-12-07 06:23:27,120] [INFO] [controller] EPOCH 4 loss ppo:  -0.03441, loss val: 0.03149
[2022-12-07 06:23:27,130] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:23:27,280] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:23:27,280] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:23:31,712] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:23:35,828] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:23:39,642] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:23:43,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:23:48,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:23:52,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:23:56,275] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:24:00,304] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:24:04,163] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:24:08,295] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6155133099361727
[2022-12-07 06:24:08,295] [INFO] [runner_train_mujoco] Average state value: 0.47163207314411804
[2022-12-07 06:24:08,295] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 06:24:08,345] [INFO] [controller] EPOCH 1 loss ppo:  -0.01770, loss val: 0.03086
[2022-12-07 06:24:08,391] [INFO] [controller] EPOCH 2 loss ppo:  -0.02442, loss val: 0.02899
[2022-12-07 06:24:08,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.03006, loss val: 0.02688
[2022-12-07 06:24:08,481] [INFO] [controller] EPOCH 4 loss ppo:  -0.03378, loss val: 0.02607
[2022-12-07 06:24:08,491] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:24:08,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:24:08,643] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:24:12,769] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:24:16,665] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:24:20,771] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:24:24,569] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:24:28,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:24:32,663] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:24:36,485] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:24:40,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:24:44,469] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:24:48,282] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.738427413439053
[2022-12-07 06:24:48,283] [INFO] [runner_train_mujoco] Average state value: 0.4079253380695979
[2022-12-07 06:24:48,283] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 06:24:48,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.01458, loss val: 0.04476
[2022-12-07 06:24:48,391] [INFO] [controller] EPOCH 2 loss ppo:  -0.02530, loss val: 0.04604
[2022-12-07 06:24:48,439] [INFO] [controller] EPOCH 3 loss ppo:  -0.03240, loss val: 0.04530
[2022-12-07 06:24:48,481] [INFO] [controller] EPOCH 4 loss ppo:  -0.03525, loss val: 0.04575
[2022-12-07 06:24:48,491] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:24:48,642] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:24:48,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:24:52,808] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:24:57,085] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:25:01,189] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:25:05,275] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:25:09,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:25:13,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:25:17,312] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:25:21,315] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:25:25,172] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:25:29,310] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.02215159088395
[2022-12-07 06:25:29,310] [INFO] [runner_train_mujoco] Average state value: 0.42724650170405704
[2022-12-07 06:25:29,310] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 06:25:29,371] [INFO] [controller] EPOCH 1 loss ppo:  -0.01618, loss val: 0.05505
[2022-12-07 06:25:29,416] [INFO] [controller] EPOCH 2 loss ppo:  -0.02178, loss val: 0.05756
[2022-12-07 06:25:29,463] [INFO] [controller] EPOCH 3 loss ppo:  -0.02958, loss val: 0.05252
[2022-12-07 06:25:29,507] [INFO] [controller] EPOCH 4 loss ppo:  -0.03243, loss val: 0.05061
[2022-12-07 06:25:29,517] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:25:29,669] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:25:29,670] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:25:33,799] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:25:37,720] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:25:41,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:25:45,882] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:25:49,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:25:54,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:25:57,680] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:26:01,674] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:26:05,738] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:26:09,714] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9568119466766163
[2022-12-07 06:26:09,715] [INFO] [runner_train_mujoco] Average state value: 0.5085279117822646
[2022-12-07 06:26:09,715] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 06:26:09,768] [INFO] [controller] EPOCH 1 loss ppo:  -0.01537, loss val: 0.04439
[2022-12-07 06:26:09,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.02291, loss val: 0.04454
[2022-12-07 06:26:09,849] [INFO] [controller] EPOCH 3 loss ppo:  -0.02811, loss val: 0.04543
[2022-12-07 06:26:09,892] [INFO] [controller] EPOCH 4 loss ppo:  -0.03394, loss val: 0.04505
[2022-12-07 06:26:09,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:26:10,058] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:26:10,058] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:26:14,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:26:17,755] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:26:21,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:26:26,046] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:26:30,113] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:26:34,240] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:26:38,583] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:26:42,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:26:47,027] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:26:51,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1969242987674695
[2022-12-07 06:26:51,468] [INFO] [runner_train_mujoco] Average state value: 0.5381470451354982
[2022-12-07 06:26:51,468] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 06:26:51,521] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.03867
[2022-12-07 06:26:51,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.02110, loss val: 0.03894
[2022-12-07 06:26:51,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.02778, loss val: 0.03881
[2022-12-07 06:26:51,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.03487, loss val: 0.03833
[2022-12-07 06:26:51,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:26:51,846] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:26:51,847] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:26:55,547] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:26:59,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:27:03,625] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:27:07,743] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:27:11,506] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:15,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:27:19,265] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:27:23,116] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:27:27,183] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:27:30,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.400103606390155
[2022-12-07 06:27:30,932] [INFO] [runner_train_mujoco] Average state value: 0.5080062823891639
[2022-12-07 06:27:30,932] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 06:27:30,995] [INFO] [controller] EPOCH 1 loss ppo:  -0.01606, loss val: 0.04211
[2022-12-07 06:27:31,041] [INFO] [controller] EPOCH 2 loss ppo:  -0.02065, loss val: 0.04177
[2022-12-07 06:27:31,097] [INFO] [controller] EPOCH 3 loss ppo:  -0.03223, loss val: 0.04141
[2022-12-07 06:27:31,143] [INFO] [controller] EPOCH 4 loss ppo:  -0.03691, loss val: 0.04204
[2022-12-07 06:27:31,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:27:31,306] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:27:31,306] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:27:35,509] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:27:39,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:27:43,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:27:47,329] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:27:51,244] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:27:55,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:27:59,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:28:03,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:28:06,933] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:28:10,920] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5094846556114256
[2022-12-07 06:28:10,921] [INFO] [runner_train_mujoco] Average state value: 0.473852856596311
[2022-12-07 06:28:10,921] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 06:28:10,976] [INFO] [controller] EPOCH 1 loss ppo:  -0.01457, loss val: 0.03983
[2022-12-07 06:28:11,024] [INFO] [controller] EPOCH 2 loss ppo:  -0.02392, loss val: 0.03792
[2022-12-07 06:28:11,097] [INFO] [controller] EPOCH 3 loss ppo:  -0.03074, loss val: 0.03782
[2022-12-07 06:28:11,154] [INFO] [controller] EPOCH 4 loss ppo:  -0.03882, loss val: 0.03904
[2022-12-07 06:28:11,166] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:28:11,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:28:11,323] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:28:15,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:28:19,288] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:28:23,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:28:27,104] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:28:31,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:28:35,107] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:28:38,749] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:28:42,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:28:46,148] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:28:49,843] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5726689646027374
[2022-12-07 06:28:49,843] [INFO] [runner_train_mujoco] Average state value: 0.49034583147366834
[2022-12-07 06:28:49,843] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 06:28:49,896] [INFO] [controller] EPOCH 1 loss ppo:  -0.01099, loss val: 0.03633
[2022-12-07 06:28:49,937] [INFO] [controller] EPOCH 2 loss ppo:  -0.01416, loss val: 0.03609
[2022-12-07 06:28:49,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.02812, loss val: 0.03986
[2022-12-07 06:28:50,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.02828, loss val: 0.03594
[2022-12-07 06:28:50,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:28:50,173] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:28:50,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:28:54,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:28:58,040] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:29:02,053] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:29:05,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:29:10,140] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:29:14,180] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:29:18,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:29:22,502] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:29:26,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:29:30,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.766058708006758
[2022-12-07 06:29:30,214] [INFO] [runner_train_mujoco] Average state value: 0.5178051138122877
[2022-12-07 06:29:30,214] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 06:29:30,263] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.05031
[2022-12-07 06:29:30,304] [INFO] [controller] EPOCH 2 loss ppo:  -0.01685, loss val: 0.05136
[2022-12-07 06:29:30,357] [INFO] [controller] EPOCH 3 loss ppo:  -0.02474, loss val: 0.04836
[2022-12-07 06:29:30,401] [INFO] [controller] EPOCH 4 loss ppo:  -0.02993, loss val: 0.04657
[2022-12-07 06:29:30,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:29:30,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:29:30,561] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:29:34,481] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:29:38,552] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:29:42,372] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:29:45,835] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:29:49,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:29:53,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:29:57,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:30:01,878] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:30:07,480] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:30:11,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0499441393728315
[2022-12-07 06:30:11,565] [INFO] [runner_train_mujoco] Average state value: 0.47026668826738993
[2022-12-07 06:30:11,565] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 06:30:11,618] [INFO] [controller] EPOCH 1 loss ppo:  -0.01698, loss val: 0.04307
[2022-12-07 06:30:11,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.02220, loss val: 0.04328
[2022-12-07 06:30:11,715] [INFO] [controller] EPOCH 3 loss ppo:  -0.03044, loss val: 0.04591
[2022-12-07 06:30:11,762] [INFO] [controller] EPOCH 4 loss ppo:  -0.03394, loss val: 0.04362
[2022-12-07 06:30:11,772] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:30:11,926] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:30:11,927] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:30:16,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:30:20,277] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:30:24,407] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:30:27,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:30:31,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:30:35,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:30:39,819] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:30:45,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:30:49,034] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:30:52,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5790735866559915
[2022-12-07 06:30:52,979] [INFO] [runner_train_mujoco] Average state value: 0.4682409663399061
[2022-12-07 06:30:52,979] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 06:30:53,031] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.03752
[2022-12-07 06:30:53,088] [INFO] [controller] EPOCH 2 loss ppo:  -0.02511, loss val: 0.03659
[2022-12-07 06:30:53,136] [INFO] [controller] EPOCH 3 loss ppo:  -0.03191, loss val: 0.03742
[2022-12-07 06:30:53,185] [INFO] [controller] EPOCH 4 loss ppo:  -0.03776, loss val: 0.04015
[2022-12-07 06:30:53,194] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:30:53,352] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:30:53,353] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:30:57,232] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:31:01,161] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:31:05,191] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:31:09,038] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:31:12,948] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:31:16,640] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:31:20,791] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:31:24,347] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:31:27,801] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:31:31,982] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.845974903802862
[2022-12-07 06:31:31,982] [INFO] [runner_train_mujoco] Average state value: 0.5062305668989817
[2022-12-07 06:31:31,982] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 06:31:32,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.04776
[2022-12-07 06:31:32,086] [INFO] [controller] EPOCH 2 loss ppo:  -0.01892, loss val: 0.04626
[2022-12-07 06:31:32,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.02799, loss val: 0.04863
[2022-12-07 06:31:32,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.03435, loss val: 0.04505
[2022-12-07 06:31:32,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:31:32,327] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:31:32,327] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:31:36,427] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:31:40,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:31:44,022] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:31:47,908] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:31:51,443] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:31:54,981] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:31:58,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:32:02,877] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:32:06,312] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:32:09,955] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.944663313077357
[2022-12-07 06:32:09,955] [INFO] [runner_train_mujoco] Average state value: 0.492385294119517
[2022-12-07 06:32:09,955] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 06:32:10,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.01512, loss val: 0.04297
[2022-12-07 06:32:10,075] [INFO] [controller] EPOCH 2 loss ppo:  -0.02161, loss val: 0.04270
[2022-12-07 06:32:10,124] [INFO] [controller] EPOCH 3 loss ppo:  -0.02856, loss val: 0.04111
[2022-12-07 06:32:10,167] [INFO] [controller] EPOCH 4 loss ppo:  -0.03461, loss val: 0.04112
[2022-12-07 06:32:10,173] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:32:10,331] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:32:10,331] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:32:14,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:32:18,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:32:22,757] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:32:26,710] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:32:30,365] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:32:34,028] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:32:37,487] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:32:41,256] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:32:44,822] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:32:48,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9909112101694477
[2022-12-07 06:32:48,760] [INFO] [runner_train_mujoco] Average state value: 0.4456872905095418
[2022-12-07 06:32:48,760] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 06:32:48,815] [INFO] [controller] EPOCH 1 loss ppo:  -0.01252, loss val: 0.04853
[2022-12-07 06:32:48,862] [INFO] [controller] EPOCH 2 loss ppo:  -0.01871, loss val: 0.04755
[2022-12-07 06:32:48,925] [INFO] [controller] EPOCH 3 loss ppo:  -0.03289, loss val: 0.04859
[2022-12-07 06:32:48,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.03016, loss val: 0.04817
[2022-12-07 06:32:48,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:32:49,126] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:32:49,126] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:32:53,156] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:32:57,015] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:33:00,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:33:04,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:33:08,356] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:33:12,339] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:33:16,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:33:20,291] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:33:24,359] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:33:28,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.195962320990371
[2022-12-07 06:33:28,028] [INFO] [runner_train_mujoco] Average state value: 0.42014682708183926
[2022-12-07 06:33:28,028] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 06:33:28,086] [INFO] [controller] EPOCH 1 loss ppo:  -0.00993, loss val: 0.03641
[2022-12-07 06:33:28,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.01634, loss val: 0.03562
[2022-12-07 06:33:28,186] [INFO] [controller] EPOCH 3 loss ppo:  -0.02507, loss val: 0.03555
[2022-12-07 06:33:28,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.02983, loss val: 0.03550
[2022-12-07 06:33:28,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:33:28,397] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:33:28,397] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:33:32,320] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:33:36,342] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:33:40,294] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:33:44,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:33:47,788] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:33:51,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:33:54,958] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:33:58,354] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:34:02,214] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:34:05,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.356587051829001
[2022-12-07 06:34:05,676] [INFO] [runner_train_mujoco] Average state value: 0.4061759963432948
[2022-12-07 06:34:05,676] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 06:34:05,732] [INFO] [controller] EPOCH 1 loss ppo:  -0.01497, loss val: 0.03482
[2022-12-07 06:34:05,775] [INFO] [controller] EPOCH 2 loss ppo:  -0.02250, loss val: 0.03552
[2022-12-07 06:34:05,819] [INFO] [controller] EPOCH 3 loss ppo:  -0.02542, loss val: 0.03423
[2022-12-07 06:34:05,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.03285, loss val: 0.03272
[2022-12-07 06:34:05,871] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:34:06,042] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:34:06,043] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:34:09,850] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:34:14,161] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:34:18,111] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:34:22,345] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:34:26,374] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:34:30,045] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:34:33,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:34:37,643] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:34:41,206] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:34:45,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.397259400764744
[2022-12-07 06:34:45,286] [INFO] [runner_train_mujoco] Average state value: 0.422760028163592
[2022-12-07 06:34:45,286] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 06:34:45,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01117, loss val: 0.05431
[2022-12-07 06:34:45,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.01732, loss val: 0.05357
[2022-12-07 06:34:45,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.02524, loss val: 0.05371
[2022-12-07 06:34:45,478] [INFO] [controller] EPOCH 4 loss ppo:  -0.03126, loss val: 0.05303
[2022-12-07 06:34:45,485] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:34:45,640] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:34:45,641] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:34:49,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:34:53,227] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:34:56,973] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:35:00,778] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:35:04,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:35:08,551] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:35:12,012] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:35:15,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:35:19,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:35:23,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5166010531811125
[2022-12-07 06:35:23,774] [INFO] [runner_train_mujoco] Average state value: 0.46011809810002646
[2022-12-07 06:35:23,774] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 06:35:23,828] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04762
[2022-12-07 06:35:23,876] [INFO] [controller] EPOCH 2 loss ppo:  -0.02219, loss val: 0.04754
[2022-12-07 06:35:23,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.02423, loss val: 0.04860
[2022-12-07 06:35:23,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.03201, loss val: 0.04776
[2022-12-07 06:35:23,976] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:35:24,141] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:35:24,141] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:35:27,641] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:35:31,148] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:35:34,600] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:35:38,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:35:42,571] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:35:46,156] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:35:50,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:35:53,775] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:35:57,230] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:36:01,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.6646799197052795
[2022-12-07 06:36:01,190] [INFO] [runner_train_mujoco] Average state value: 0.4635535372893016
[2022-12-07 06:36:01,191] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 06:36:01,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.04457
[2022-12-07 06:36:01,307] [INFO] [controller] EPOCH 2 loss ppo:  -0.01749, loss val: 0.04433
[2022-12-07 06:36:01,354] [INFO] [controller] EPOCH 3 loss ppo:  -0.02391, loss val: 0.04350
[2022-12-07 06:36:01,407] [INFO] [controller] EPOCH 4 loss ppo:  -0.03250, loss val: 0.04277
[2022-12-07 06:36:01,418] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:36:01,590] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:36:01,590] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:36:05,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:36:09,554] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:36:13,577] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:36:17,637] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:36:21,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:36:25,076] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:36:28,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:36:32,041] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:36:35,772] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:36:39,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.536724809839042
[2022-12-07 06:36:39,310] [INFO] [runner_train_mujoco] Average state value: 0.43215168497959777
[2022-12-07 06:36:39,310] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 06:36:39,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.04496
[2022-12-07 06:36:39,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.01817, loss val: 0.04780
[2022-12-07 06:36:39,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.02232, loss val: 0.04295
[2022-12-07 06:36:39,555] [INFO] [controller] EPOCH 4 loss ppo:  -0.02867, loss val: 0.04372
[2022-12-07 06:36:39,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:36:39,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:36:39,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:36:43,559] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:36:47,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:36:51,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:36:54,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:36:58,624] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:37:02,164] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:37:05,916] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:37:10,076] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:37:14,142] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:37:17,822] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.594764006682773
[2022-12-07 06:37:17,822] [INFO] [runner_train_mujoco] Average state value: 0.45287918561697016
[2022-12-07 06:37:17,822] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 06:37:17,883] [INFO] [controller] EPOCH 1 loss ppo:  -0.01208, loss val: 0.04975
[2022-12-07 06:37:17,929] [INFO] [controller] EPOCH 2 loss ppo:  -0.01737, loss val: 0.05055
[2022-12-07 06:37:17,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.01981, loss val: 0.05000
[2022-12-07 06:37:18,040] [INFO] [controller] EPOCH 4 loss ppo:  -0.03047, loss val: 0.05072
[2022-12-07 06:37:18,051] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:37:18,242] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:37:18,243] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:37:22,035] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:37:26,218] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:37:29,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:37:33,610] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:37:37,354] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:37:40,783] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:37:44,266] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:37:47,774] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:37:51,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:37:55,135] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.772771011130052
[2022-12-07 06:37:55,135] [INFO] [runner_train_mujoco] Average state value: 0.46950308704376215
[2022-12-07 06:37:55,135] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 06:37:55,185] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.04237
[2022-12-07 06:37:55,232] [INFO] [controller] EPOCH 2 loss ppo:  -0.01587, loss val: 0.04141
[2022-12-07 06:37:55,277] [INFO] [controller] EPOCH 3 loss ppo:  -0.02112, loss val: 0.04080
[2022-12-07 06:37:55,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.03013, loss val: 0.03984
[2022-12-07 06:37:55,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:37:55,475] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:37:55,475] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:37:58,901] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:38:02,658] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:38:06,779] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:38:10,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:38:14,443] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:38:18,205] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:38:21,995] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:38:25,829] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:38:30,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:38:33,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.680230193402343
[2022-12-07 06:38:33,572] [INFO] [runner_train_mujoco] Average state value: 0.4405108421047529
[2022-12-07 06:38:33,572] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 06:38:33,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01214, loss val: 0.05484
[2022-12-07 06:38:33,673] [INFO] [controller] EPOCH 2 loss ppo:  -0.02317, loss val: 0.05439
[2022-12-07 06:38:33,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.02989, loss val: 0.05446
[2022-12-07 06:38:33,766] [INFO] [controller] EPOCH 4 loss ppo:  -0.03287, loss val: 0.05418
[2022-12-07 06:38:33,775] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:38:33,928] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:38:33,928] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:38:37,897] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:38:42,033] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:38:45,824] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:38:49,796] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:38:53,832] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:38:57,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:39:01,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:39:05,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:39:08,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:39:12,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7837353126213635
[2022-12-07 06:39:12,089] [INFO] [runner_train_mujoco] Average state value: 0.43255850418408714
[2022-12-07 06:39:12,089] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 06:39:12,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.04692
[2022-12-07 06:39:12,174] [INFO] [controller] EPOCH 2 loss ppo:  -0.01928, loss val: 0.04732
[2022-12-07 06:39:12,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.02383, loss val: 0.04682
[2022-12-07 06:39:12,250] [INFO] [controller] EPOCH 4 loss ppo:  -0.02597, loss val: 0.04633
[2022-12-07 06:39:12,259] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:39:12,403] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:39:12,404] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:39:15,865] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:39:19,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:39:22,985] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:39:26,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:39:29,765] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:39:32,868] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:39:36,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:39:39,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:39:43,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:39:46,335] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.802136328731373
[2022-12-07 06:39:46,335] [INFO] [runner_train_mujoco] Average state value: 0.4572011749148369
[2022-12-07 06:39:46,335] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 06:39:46,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04223
[2022-12-07 06:39:46,422] [INFO] [controller] EPOCH 2 loss ppo:  -0.02414, loss val: 0.04591
[2022-12-07 06:39:46,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.02485, loss val: 0.04247
[2022-12-07 06:39:46,499] [INFO] [controller] EPOCH 4 loss ppo:  -0.02684, loss val: 0.04246
[2022-12-07 06:39:46,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:39:46,661] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:39:46,661] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:39:50,204] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:39:53,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:39:57,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:40:00,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:40:03,640] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:40:06,808] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:40:10,242] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:40:13,494] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:40:16,656] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:40:20,209] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.586427007135102
[2022-12-07 06:40:20,210] [INFO] [runner_train_mujoco] Average state value: 0.46619638446966805
[2022-12-07 06:40:20,210] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 06:40:20,263] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04850
[2022-12-07 06:40:20,304] [INFO] [controller] EPOCH 2 loss ppo:  -0.01645, loss val: 0.04827
[2022-12-07 06:40:20,345] [INFO] [controller] EPOCH 3 loss ppo:  -0.02057, loss val: 0.04872
[2022-12-07 06:40:20,384] [INFO] [controller] EPOCH 4 loss ppo:  -0.02648, loss val: 0.04849
[2022-12-07 06:40:20,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:40:20,537] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:40:20,537] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:40:23,774] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:40:27,004] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:40:30,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:40:33,869] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:40:36,989] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:40:40,151] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:40:43,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:40:46,929] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:40:50,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:40:53,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7351711254775
[2022-12-07 06:40:53,958] [INFO] [runner_train_mujoco] Average state value: 0.44634456817309065
[2022-12-07 06:40:53,959] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 06:40:54,005] [INFO] [controller] EPOCH 1 loss ppo:  -0.01143, loss val: 0.03574
[2022-12-07 06:40:54,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.01676, loss val: 0.03614
[2022-12-07 06:40:54,081] [INFO] [controller] EPOCH 3 loss ppo:  -0.02289, loss val: 0.03571
[2022-12-07 06:40:54,121] [INFO] [controller] EPOCH 4 loss ppo:  -0.02874, loss val: 0.03569
[2022-12-07 06:40:54,127] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:40:54,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:40:54,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:40:57,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:41:00,487] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:41:03,830] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:41:07,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:41:11,062] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:41:14,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:41:17,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:41:20,678] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:41:24,136] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:41:27,825] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.719897367289507
[2022-12-07 06:41:27,826] [INFO] [runner_train_mujoco] Average state value: 0.4227562207182249
[2022-12-07 06:41:27,826] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 06:41:27,882] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04366
[2022-12-07 06:41:27,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.01820, loss val: 0.04675
[2022-12-07 06:41:27,965] [INFO] [controller] EPOCH 3 loss ppo:  -0.02487, loss val: 0.04441
[2022-12-07 06:41:28,002] [INFO] [controller] EPOCH 4 loss ppo:  -0.02864, loss val: 0.04587
[2022-12-07 06:41:28,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:41:28,154] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:41:28,154] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:41:31,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:41:34,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:41:37,968] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:41:41,434] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:41:44,936] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:41:48,293] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:41:51,581] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:41:54,584] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:41:57,979] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:42:01,282] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.060687980276322
[2022-12-07 06:42:01,282] [INFO] [runner_train_mujoco] Average state value: 0.42501617544889453
[2022-12-07 06:42:01,282] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 06:42:01,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01108, loss val: 0.04621
[2022-12-07 06:42:01,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.01580, loss val: 0.04593
[2022-12-07 06:42:01,411] [INFO] [controller] EPOCH 3 loss ppo:  -0.02150, loss val: 0.04637
[2022-12-07 06:42:01,450] [INFO] [controller] EPOCH 4 loss ppo:  -0.02329, loss val: 0.04581
[2022-12-07 06:42:01,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:42:01,607] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:42:01,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:42:04,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:42:08,206] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:42:11,661] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:42:15,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:42:19,126] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:42:22,690] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:42:26,189] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:42:29,619] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:42:32,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:42:36,095] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.148592710494611
[2022-12-07 06:42:36,095] [INFO] [runner_train_mujoco] Average state value: 0.4310660996437073
[2022-12-07 06:42:36,095] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 06:42:36,143] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.04148
[2022-12-07 06:42:36,184] [INFO] [controller] EPOCH 2 loss ppo:  -0.01691, loss val: 0.04139
[2022-12-07 06:42:36,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.02012, loss val: 0.04091
[2022-12-07 06:42:36,264] [INFO] [controller] EPOCH 4 loss ppo:  -0.02088, loss val: 0.04005
[2022-12-07 06:42:36,273] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:42:36,399] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:42:36,400] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:42:39,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:42:43,253] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:42:46,637] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:42:49,812] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:42:52,845] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:42:56,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:42:59,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:43:02,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:43:05,941] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:43:09,416] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.945034081784987
[2022-12-07 06:43:09,417] [INFO] [runner_train_mujoco] Average state value: 0.4233496798872947
[2022-12-07 06:43:09,417] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 06:43:09,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.04296
[2022-12-07 06:43:09,517] [INFO] [controller] EPOCH 2 loss ppo:  -0.01850, loss val: 0.04226
[2022-12-07 06:43:09,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.02504, loss val: 0.04219
[2022-12-07 06:43:09,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.02899, loss val: 0.04190
[2022-12-07 06:43:09,606] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:43:09,753] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:43:09,753] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:43:13,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:43:16,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:43:20,934] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:43:25,277] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:43:28,611] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:43:31,654] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:43:34,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:43:38,044] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:43:41,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:43:44,343] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.8645115577765194
[2022-12-07 06:43:44,343] [INFO] [runner_train_mujoco] Average state value: 0.4055433064103126
[2022-12-07 06:43:44,343] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 06:43:44,391] [INFO] [controller] EPOCH 1 loss ppo:  -0.01182, loss val: 0.04488
[2022-12-07 06:43:44,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.01681, loss val: 0.04503
[2022-12-07 06:43:44,481] [INFO] [controller] EPOCH 3 loss ppo:  -0.02134, loss val: 0.04489
[2022-12-07 06:43:44,532] [INFO] [controller] EPOCH 4 loss ppo:  -0.02453, loss val: 0.04571
[2022-12-07 06:43:44,541] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:43:44,686] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:43:44,686] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:43:48,270] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:43:51,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:43:54,847] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:43:58,567] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:44:02,062] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:44:05,590] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:44:08,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:44:11,799] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:44:15,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:44:18,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.004565275871312
[2022-12-07 06:44:18,286] [INFO] [runner_train_mujoco] Average state value: 0.4120460247198741
[2022-12-07 06:44:18,286] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 06:44:18,334] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.05497
[2022-12-07 06:44:18,376] [INFO] [controller] EPOCH 2 loss ppo:  -0.01746, loss val: 0.05370
[2022-12-07 06:44:18,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.02182, loss val: 0.05399
[2022-12-07 06:44:18,457] [INFO] [controller] EPOCH 4 loss ppo:  -0.02502, loss val: 0.05319
[2022-12-07 06:44:18,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:44:18,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:44:18,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:44:22,173] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:44:25,398] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:44:28,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:44:32,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:44:35,780] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:44:39,390] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:44:42,556] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:44:45,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:44:49,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:44:52,500] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.143910648141928
[2022-12-07 06:44:52,500] [INFO] [runner_train_mujoco] Average state value: 0.41998494791984564
[2022-12-07 06:44:52,500] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 06:44:52,549] [INFO] [controller] EPOCH 1 loss ppo:  -0.01129, loss val: 0.04443
[2022-12-07 06:44:52,595] [INFO] [controller] EPOCH 2 loss ppo:  -0.01533, loss val: 0.04389
[2022-12-07 06:44:52,638] [INFO] [controller] EPOCH 3 loss ppo:  -0.02020, loss val: 0.04332
[2022-12-07 06:44:52,682] [INFO] [controller] EPOCH 4 loss ppo:  -0.02476, loss val: 0.04314
[2022-12-07 06:44:52,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:44:52,845] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:44:52,845] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:44:56,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:44:59,672] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:45:02,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:45:06,851] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:45:11,970] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:45:15,741] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:45:19,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:45:23,672] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:45:27,063] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:45:30,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.039760737734504
[2022-12-07 06:45:30,818] [INFO] [runner_train_mujoco] Average state value: 0.436440337518851
[2022-12-07 06:45:30,818] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 06:45:30,870] [INFO] [controller] EPOCH 1 loss ppo:  -0.01154, loss val: 0.04659
[2022-12-07 06:45:30,918] [INFO] [controller] EPOCH 2 loss ppo:  -0.01456, loss val: 0.04715
[2022-12-07 06:45:30,960] [INFO] [controller] EPOCH 3 loss ppo:  -0.01821, loss val: 0.04687
[2022-12-07 06:45:31,009] [INFO] [controller] EPOCH 4 loss ppo:  -0.02138, loss val: 0.04159
[2022-12-07 06:45:31,019] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:45:31,177] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:45:31,178] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:45:34,951] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:45:38,694] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:45:42,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:45:47,059] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:45:50,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:45:54,778] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:45:58,832] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:46:02,777] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:46:06,690] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:46:10,349] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.150238942116949
[2022-12-07 06:46:10,350] [INFO] [runner_train_mujoco] Average state value: 0.4633249751925468
[2022-12-07 06:46:10,350] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 06:46:10,407] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.04022
[2022-12-07 06:46:10,454] [INFO] [controller] EPOCH 2 loss ppo:  -0.01703, loss val: 0.04081
[2022-12-07 06:46:10,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.02022, loss val: 0.04209
[2022-12-07 06:46:10,546] [INFO] [controller] EPOCH 4 loss ppo:  -0.02506, loss val: 0.04108
[2022-12-07 06:46:10,557] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:46:10,710] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:46:10,710] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:46:14,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:46:18,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:46:22,276] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:46:26,043] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:46:29,837] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:46:33,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:46:36,802] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:46:41,243] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:46:44,847] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:46:48,729] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.087100620402869
[2022-12-07 06:46:48,730] [INFO] [runner_train_mujoco] Average state value: 0.47141297868887583
[2022-12-07 06:46:48,730] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 06:46:48,784] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.02992
[2022-12-07 06:46:48,831] [INFO] [controller] EPOCH 2 loss ppo:  -0.01367, loss val: 0.03144
[2022-12-07 06:46:48,878] [INFO] [controller] EPOCH 3 loss ppo:  -0.01884, loss val: 0.03035
[2022-12-07 06:46:48,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.02376, loss val: 0.03024
[2022-12-07 06:46:48,933] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:46:49,101] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:46:49,102] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:46:53,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:46:57,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:47:02,126] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:47:07,434] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:47:11,790] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:47:16,145] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:47:20,433] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:47:24,804] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:47:29,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:47:33,606] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.065414304569616
[2022-12-07 06:47:33,606] [INFO] [runner_train_mujoco] Average state value: 0.4688248008489609
[2022-12-07 06:47:33,606] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 06:47:33,666] [INFO] [controller] EPOCH 1 loss ppo:  -0.01121, loss val: 0.03665
[2022-12-07 06:47:33,715] [INFO] [controller] EPOCH 2 loss ppo:  -0.01248, loss val: 0.03635
[2022-12-07 06:47:33,789] [INFO] [controller] EPOCH 3 loss ppo:  -0.01587, loss val: 0.03927
[2022-12-07 06:47:33,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.01870, loss val: 0.03666
[2022-12-07 06:47:33,848] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:47:34,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:47:34,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:47:38,596] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:47:43,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:47:47,853] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:47:52,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:47:56,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:48:00,713] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:48:04,847] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:48:08,518] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:48:12,691] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:48:16,936] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.240247841650327
[2022-12-07 06:48:16,936] [INFO] [runner_train_mujoco] Average state value: 0.46677384040753045
[2022-12-07 06:48:16,936] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 06:48:17,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.04204
[2022-12-07 06:48:17,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.01442, loss val: 0.04190
[2022-12-07 06:48:17,116] [INFO] [controller] EPOCH 3 loss ppo:  -0.01821, loss val: 0.04210
[2022-12-07 06:48:17,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.02275, loss val: 0.04202
[2022-12-07 06:48:17,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:48:17,353] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:48:17,354] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:48:21,777] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:48:25,676] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:48:30,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:48:34,494] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:48:38,655] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:48:42,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:48:46,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:48:51,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:48:55,587] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:49:00,024] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.134473002975904
[2022-12-07 06:49:00,024] [INFO] [runner_train_mujoco] Average state value: 0.4648246238032977
[2022-12-07 06:49:00,024] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 06:49:00,090] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.04686
[2022-12-07 06:49:00,139] [INFO] [controller] EPOCH 2 loss ppo:  -0.01333, loss val: 0.04591
[2022-12-07 06:49:00,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.01509, loss val: 0.04751
[2022-12-07 06:49:00,246] [INFO] [controller] EPOCH 4 loss ppo:  -0.01731, loss val: 0.04676
[2022-12-07 06:49:00,256] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:49:00,440] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:49:00,440] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:49:04,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:49:08,968] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:49:13,243] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:49:17,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:49:22,093] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:49:26,301] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:49:30,618] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:49:34,981] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:49:39,427] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:49:43,379] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.219061756730428
[2022-12-07 06:49:43,379] [INFO] [runner_train_mujoco] Average state value: 0.4616088439027468
[2022-12-07 06:49:43,379] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 06:49:43,462] [INFO] [controller] EPOCH 1 loss ppo:  -0.01190, loss val: 0.04197
[2022-12-07 06:49:43,531] [INFO] [controller] EPOCH 2 loss ppo:  -0.01284, loss val: 0.04322
[2022-12-07 06:49:43,582] [INFO] [controller] EPOCH 3 loss ppo:  -0.01418, loss val: 0.04316
[2022-12-07 06:49:43,632] [INFO] [controller] EPOCH 4 loss ppo:  -0.01587, loss val: 0.05068
[2022-12-07 06:49:43,642] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:49:43,789] [INFO] [optimize] Finished learning.
