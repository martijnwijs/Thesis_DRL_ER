[2022-12-07 10:07:31,162] [INFO] [optimize] Starting learning
[2022-12-07 10:07:31,169] [INFO] [optimize] Starting learning process..
[2022-12-07 10:07:31,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:07:31,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:07:38,429] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:07:43,735] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:07:48,404] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:07:52,859] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:07:57,704] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:08:02,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:08:07,533] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:08:12,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:08:17,022] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:08:21,829] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4811998337484245
[2022-12-07 10:08:21,829] [INFO] [runner_train_mujoco] Average state value: -0.08642155998200178
[2022-12-07 10:08:21,829] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 10:08:21,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.01691, loss val: 0.54567
[2022-12-07 10:08:21,933] [INFO] [controller] EPOCH 2 loss ppo:  -0.03408, loss val: 0.48225
[2022-12-07 10:08:21,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.04008, loss val: 0.42912
[2022-12-07 10:08:22,023] [INFO] [controller] EPOCH 4 loss ppo:  -0.04362, loss val: 0.36112
[2022-12-07 10:08:22,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:08:22,206] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:08:22,206] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:08:26,770] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:08:31,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:08:35,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:08:40,137] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:08:44,622] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:08:49,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:08:53,921] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:08:58,822] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:09:03,925] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:09:11,373] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5312129691000066
[2022-12-07 10:09:11,374] [INFO] [runner_train_mujoco] Average state value: 0.10354735266106825
[2022-12-07 10:09:11,374] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 10:09:11,556] [INFO] [controller] EPOCH 1 loss ppo:  -0.01613, loss val: 0.27025
[2022-12-07 10:09:11,701] [INFO] [controller] EPOCH 2 loss ppo:  -0.02852, loss val: 0.23533
[2022-12-07 10:09:11,781] [INFO] [controller] EPOCH 3 loss ppo:  -0.03084, loss val: 0.21062
[2022-12-07 10:09:11,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.03599, loss val: 0.18210
[2022-12-07 10:09:11,924] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:09:12,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:09:12,170] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:09:20,000] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:09:29,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:09:35,093] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:09:40,033] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:09:44,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:09:50,162] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:09:56,497] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:10:01,796] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:10:06,957] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:10:12,498] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5125115924692432
[2022-12-07 10:10:12,498] [INFO] [runner_train_mujoco] Average state value: 0.29131321066183347
[2022-12-07 10:10:12,499] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 10:10:12,554] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.16629
[2022-12-07 10:10:12,609] [INFO] [controller] EPOCH 2 loss ppo:  -0.03079, loss val: 0.13831
[2022-12-07 10:10:12,676] [INFO] [controller] EPOCH 3 loss ppo:  -0.03549, loss val: 0.11660
[2022-12-07 10:10:12,745] [INFO] [controller] EPOCH 4 loss ppo:  -0.03869, loss val: 0.10065
[2022-12-07 10:10:12,761] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:10:12,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:10:12,951] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:10:17,845] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:10:23,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:10:29,112] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:10:34,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:10:38,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:10:42,908] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:10:48,652] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:10:55,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:11:02,359] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:11:06,954] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5532862873079113
[2022-12-07 10:11:06,955] [INFO] [runner_train_mujoco] Average state value: 0.44511776222288607
[2022-12-07 10:11:06,955] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 10:11:07,007] [INFO] [controller] EPOCH 1 loss ppo:  -0.01220, loss val: 0.08147
[2022-12-07 10:11:07,061] [INFO] [controller] EPOCH 2 loss ppo:  -0.02599, loss val: 0.07162
[2022-12-07 10:11:07,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.02990, loss val: 0.06525
[2022-12-07 10:11:07,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.02950, loss val: 0.06147
[2022-12-07 10:11:07,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:11:07,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:11:07,349] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:11:11,776] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:11:17,178] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:11:21,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:11:26,445] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:11:31,405] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:11:35,659] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:11:43,130] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:11:49,239] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:11:54,185] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:11:58,353] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4826930317846285
[2022-12-07 10:11:58,353] [INFO] [runner_train_mujoco] Average state value: 0.5498775705446799
[2022-12-07 10:11:58,354] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 10:11:58,406] [INFO] [controller] EPOCH 1 loss ppo:  -0.01020, loss val: 0.05381
[2022-12-07 10:11:58,448] [INFO] [controller] EPOCH 2 loss ppo:  -0.02003, loss val: 0.05055
[2022-12-07 10:11:58,491] [INFO] [controller] EPOCH 3 loss ppo:  -0.02163, loss val: 0.04653
[2022-12-07 10:11:58,529] [INFO] [controller] EPOCH 4 loss ppo:  -0.02704, loss val: 0.04262
[2022-12-07 10:11:58,540] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:11:58,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:11:58,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:12:02,777] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:12:07,009] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:12:11,369] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:12:15,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:12:19,877] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:12:24,368] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:12:28,707] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:12:33,349] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:12:38,628] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:12:44,598] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6778187581890613
[2022-12-07 10:12:44,599] [INFO] [runner_train_mujoco] Average state value: 0.5209066987037658
[2022-12-07 10:12:44,599] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 10:12:44,692] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.04513
[2022-12-07 10:12:44,755] [INFO] [controller] EPOCH 2 loss ppo:  -0.02413, loss val: 0.04492
[2022-12-07 10:12:44,838] [INFO] [controller] EPOCH 3 loss ppo:  -0.02843, loss val: 0.04198
[2022-12-07 10:12:44,901] [INFO] [controller] EPOCH 4 loss ppo:  -0.03229, loss val: 0.04023
[2022-12-07 10:12:44,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:12:45,097] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:12:45,097] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:12:50,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:12:55,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:13:00,286] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:13:04,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:13:08,428] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:13:12,374] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:13:16,322] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:13:20,357] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:13:24,862] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:13:29,200] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6130260142656357
[2022-12-07 10:13:29,200] [INFO] [runner_train_mujoco] Average state value: 0.5220935965975125
[2022-12-07 10:13:29,200] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 10:13:29,253] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.04679
[2022-12-07 10:13:29,306] [INFO] [controller] EPOCH 2 loss ppo:  -0.02795, loss val: 0.04351
[2022-12-07 10:13:29,348] [INFO] [controller] EPOCH 3 loss ppo:  -0.02794, loss val: 0.04248
[2022-12-07 10:13:29,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.03179, loss val: 0.04121
[2022-12-07 10:13:29,397] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:13:29,560] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:13:29,561] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:13:33,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:13:37,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:13:42,013] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:13:46,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:13:50,197] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:13:54,109] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:13:58,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:14:02,182] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:14:06,298] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:14:10,270] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6789772288906182
[2022-12-07 10:14:10,271] [INFO] [runner_train_mujoco] Average state value: 0.5943775590658188
[2022-12-07 10:14:10,271] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 10:14:10,336] [INFO] [controller] EPOCH 1 loss ppo:  -0.01214, loss val: 0.03408
[2022-12-07 10:14:10,377] [INFO] [controller] EPOCH 2 loss ppo:  -0.02505, loss val: 0.03484
[2022-12-07 10:14:10,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.03041, loss val: 0.03643
[2022-12-07 10:14:10,466] [INFO] [controller] EPOCH 4 loss ppo:  -0.03353, loss val: 0.03363
[2022-12-07 10:14:10,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:14:10,640] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:14:10,640] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:14:14,525] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:14:18,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:14:22,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:14:27,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:14:31,525] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:14:35,928] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:14:40,291] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:14:44,144] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:14:48,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:14:52,038] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5795569504587711
[2022-12-07 10:14:52,038] [INFO] [runner_train_mujoco] Average state value: 0.5921063624024392
[2022-12-07 10:14:52,038] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 10:14:52,095] [INFO] [controller] EPOCH 1 loss ppo:  -0.00988, loss val: 0.03655
[2022-12-07 10:14:52,138] [INFO] [controller] EPOCH 2 loss ppo:  -0.02451, loss val: 0.03795
[2022-12-07 10:14:52,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.02687, loss val: 0.03681
[2022-12-07 10:14:52,234] [INFO] [controller] EPOCH 4 loss ppo:  -0.03294, loss val: 0.03640
[2022-12-07 10:14:52,244] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:14:52,403] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:14:52,403] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:14:56,596] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:15:00,828] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:15:04,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:15:08,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:15:12,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:15:16,670] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:15:21,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:15:26,146] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:15:31,214] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:15:35,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8503045389053815
[2022-12-07 10:15:35,887] [INFO] [runner_train_mujoco] Average state value: 0.5958125489354134
[2022-12-07 10:15:35,888] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 10:15:35,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.03140
[2022-12-07 10:15:36,000] [INFO] [controller] EPOCH 2 loss ppo:  -0.02869, loss val: 0.02906
[2022-12-07 10:15:36,046] [INFO] [controller] EPOCH 3 loss ppo:  -0.03431, loss val: 0.03180
[2022-12-07 10:15:36,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.03766, loss val: 0.02897
[2022-12-07 10:15:36,116] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:15:36,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:15:36,288] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:15:41,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:15:47,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:15:51,924] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:15:57,040] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:16:01,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:16:05,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:16:09,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:16:13,477] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:16:17,509] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:16:21,694] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0083404621962495
[2022-12-07 10:16:21,694] [INFO] [runner_train_mujoco] Average state value: 0.6011703634063402
[2022-12-07 10:16:21,694] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 10:16:21,746] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04515
[2022-12-07 10:16:21,787] [INFO] [controller] EPOCH 2 loss ppo:  -0.03025, loss val: 0.04322
[2022-12-07 10:16:21,832] [INFO] [controller] EPOCH 3 loss ppo:  -0.03306, loss val: 0.04054
[2022-12-07 10:16:21,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.03893, loss val: 0.03858
[2022-12-07 10:16:21,888] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:16:22,048] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:16:22,048] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:16:26,669] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:16:31,448] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:16:36,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:16:41,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:16:46,036] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:16:50,553] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:16:55,067] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:16:59,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:17:04,401] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:17:09,136] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.275642564607478
[2022-12-07 10:17:09,137] [INFO] [runner_train_mujoco] Average state value: 0.5324367430210113
[2022-12-07 10:17:09,137] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 10:17:09,196] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.03680
[2022-12-07 10:17:09,244] [INFO] [controller] EPOCH 2 loss ppo:  -0.02777, loss val: 0.03721
[2022-12-07 10:17:09,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.03202, loss val: 0.03774
[2022-12-07 10:17:09,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.03277, loss val: 0.03849
[2022-12-07 10:17:09,348] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:17:09,524] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:17:09,524] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:17:13,998] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:17:18,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:17:23,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:17:27,585] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:17:32,462] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:17:37,265] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:17:42,542] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:17:47,503] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:17:52,644] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:17:58,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4761655451441384
[2022-12-07 10:17:58,839] [INFO] [runner_train_mujoco] Average state value: 0.4906170991261801
[2022-12-07 10:17:58,839] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 10:17:58,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.03442
[2022-12-07 10:17:59,144] [INFO] [controller] EPOCH 2 loss ppo:  -0.02984, loss val: 0.03534
[2022-12-07 10:17:59,243] [INFO] [controller] EPOCH 3 loss ppo:  -0.03158, loss val: 0.03391
[2022-12-07 10:17:59,350] [INFO] [controller] EPOCH 4 loss ppo:  -0.03745, loss val: 0.03511
[2022-12-07 10:17:59,365] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:17:59,581] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:17:59,581] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:18:06,801] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:18:11,312] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:18:16,068] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:18:20,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:18:25,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:18:29,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:18:34,085] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:18:38,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:18:43,317] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:18:47,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7543922732286332
[2022-12-07 10:18:47,809] [INFO] [runner_train_mujoco] Average state value: 0.49993475937843324
[2022-12-07 10:18:47,809] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 10:18:47,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.03860
[2022-12-07 10:18:47,962] [INFO] [controller] EPOCH 2 loss ppo:  -0.02781, loss val: 0.03659
[2022-12-07 10:18:48,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.03208, loss val: 0.03631
[2022-12-07 10:18:48,065] [INFO] [controller] EPOCH 4 loss ppo:  -0.03911, loss val: 0.03832
[2022-12-07 10:18:48,075] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:18:48,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:18:48,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:18:53,213] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:18:58,656] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:19:03,693] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:19:08,439] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:19:12,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:19:16,911] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:19:21,297] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:19:25,948] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:19:30,197] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:19:34,674] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0824747205187637
[2022-12-07 10:19:34,674] [INFO] [runner_train_mujoco] Average state value: 0.4788502242962519
[2022-12-07 10:19:34,674] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 10:19:34,728] [INFO] [controller] EPOCH 1 loss ppo:  -0.01573, loss val: 0.04088
[2022-12-07 10:19:34,774] [INFO] [controller] EPOCH 2 loss ppo:  -0.03114, loss val: 0.04034
[2022-12-07 10:19:34,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.03410, loss val: 0.04301
[2022-12-07 10:19:34,940] [INFO] [controller] EPOCH 4 loss ppo:  -0.03841, loss val: 0.04037
[2022-12-07 10:19:34,953] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:19:35,126] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:19:35,127] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:19:39,506] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:19:43,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:19:48,010] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:19:52,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:19:56,517] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:20:00,695] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:20:04,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:20:08,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:20:13,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:20:17,956] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1939447152172886
[2022-12-07 10:20:17,956] [INFO] [runner_train_mujoco] Average state value: 0.49116700877745945
[2022-12-07 10:20:17,956] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 10:20:18,007] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.03170
[2022-12-07 10:20:18,052] [INFO] [controller] EPOCH 2 loss ppo:  -0.02249, loss val: 0.03212
[2022-12-07 10:20:18,098] [INFO] [controller] EPOCH 3 loss ppo:  -0.02700, loss val: 0.03566
[2022-12-07 10:20:18,149] [INFO] [controller] EPOCH 4 loss ppo:  -0.03255, loss val: 0.03097
[2022-12-07 10:20:18,158] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:20:18,312] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:20:18,313] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:20:22,584] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:20:26,710] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:20:31,109] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:20:35,516] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:20:39,664] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:20:43,547] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:20:47,419] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:20:51,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:20:55,425] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:20:59,628] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4795458447550276
[2022-12-07 10:20:59,628] [INFO] [runner_train_mujoco] Average state value: 0.47606935246785487
[2022-12-07 10:20:59,628] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 10:20:59,682] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.05438
[2022-12-07 10:20:59,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.02790, loss val: 0.05359
[2022-12-07 10:20:59,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.03014, loss val: 0.05142
[2022-12-07 10:20:59,818] [INFO] [controller] EPOCH 4 loss ppo:  -0.03800, loss val: 0.05123
[2022-12-07 10:20:59,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:20:59,980] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:20:59,981] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:21:03,998] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:21:08,146] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:21:12,106] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:21:16,053] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:21:19,911] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:21:23,974] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:21:27,693] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:21:32,098] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:21:36,495] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:21:40,984] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.462140219948508
[2022-12-07 10:21:40,985] [INFO] [runner_train_mujoco] Average state value: 0.5240080037315688
[2022-12-07 10:21:40,985] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 10:21:41,056] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.03461
[2022-12-07 10:21:41,138] [INFO] [controller] EPOCH 2 loss ppo:  -0.02863, loss val: 0.03425
[2022-12-07 10:21:41,224] [INFO] [controller] EPOCH 3 loss ppo:  -0.03227, loss val: 0.03375
[2022-12-07 10:21:41,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.03842, loss val: 0.03812
[2022-12-07 10:21:41,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:21:41,485] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:21:41,485] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:21:45,653] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:21:49,895] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:21:53,919] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:21:58,754] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:22:03,454] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:22:07,506] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:22:11,268] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:22:15,059] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:22:19,012] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:22:22,785] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.871844467972683
[2022-12-07 10:22:22,785] [INFO] [runner_train_mujoco] Average state value: 0.5362151244481405
[2022-12-07 10:22:22,785] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 10:22:22,836] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.03916
[2022-12-07 10:22:22,878] [INFO] [controller] EPOCH 2 loss ppo:  -0.02372, loss val: 0.03904
[2022-12-07 10:22:22,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.02859, loss val: 0.03797
[2022-12-07 10:22:22,965] [INFO] [controller] EPOCH 4 loss ppo:  -0.03615, loss val: 0.03716
[2022-12-07 10:22:22,976] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:22:23,143] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:22:23,144] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:22:27,267] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:22:31,058] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:22:34,949] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:22:38,876] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:22:42,858] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:22:46,683] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:22:50,511] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:22:54,440] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:22:58,882] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:23:02,948] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.948981963666922
[2022-12-07 10:23:02,948] [INFO] [runner_train_mujoco] Average state value: 0.4897664996385574
[2022-12-07 10:23:02,949] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 10:23:03,009] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.03584
[2022-12-07 10:23:03,058] [INFO] [controller] EPOCH 2 loss ppo:  -0.02407, loss val: 0.03604
[2022-12-07 10:23:03,106] [INFO] [controller] EPOCH 3 loss ppo:  -0.02753, loss val: 0.03685
[2022-12-07 10:23:03,154] [INFO] [controller] EPOCH 4 loss ppo:  -0.03482, loss val: 0.03764
[2022-12-07 10:23:03,164] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:23:03,336] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:23:03,337] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:23:08,145] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:23:14,452] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:23:19,548] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:23:25,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:23:29,249] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:23:33,176] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:23:37,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:23:41,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:23:45,839] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:23:49,848] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0595372569644295
[2022-12-07 10:23:49,848] [INFO] [runner_train_mujoco] Average state value: 0.4796706370910009
[2022-12-07 10:23:49,848] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 10:23:49,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01594, loss val: 0.03462
[2022-12-07 10:23:49,955] [INFO] [controller] EPOCH 2 loss ppo:  -0.02387, loss val: 0.03429
[2022-12-07 10:23:50,008] [INFO] [controller] EPOCH 3 loss ppo:  -0.02927, loss val: 0.03525
[2022-12-07 10:23:50,057] [INFO] [controller] EPOCH 4 loss ppo:  -0.03664, loss val: 0.03548
[2022-12-07 10:23:50,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:23:50,254] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:23:50,255] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:23:55,173] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:23:59,387] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:24:03,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:24:08,050] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:24:12,216] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:24:16,290] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:24:20,499] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:24:25,045] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:24:29,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:24:33,803] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4849664616863643
[2022-12-07 10:24:33,804] [INFO] [runner_train_mujoco] Average state value: 0.4626747900048892
[2022-12-07 10:24:33,804] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 10:24:33,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.03367
[2022-12-07 10:24:33,918] [INFO] [controller] EPOCH 2 loss ppo:  -0.02546, loss val: 0.02913
[2022-12-07 10:24:33,969] [INFO] [controller] EPOCH 3 loss ppo:  -0.02876, loss val: 0.02805
[2022-12-07 10:24:34,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.03489, loss val: 0.02920
[2022-12-07 10:24:34,043] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:24:34,221] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:24:34,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:24:38,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:24:42,793] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:24:47,325] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:24:51,437] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:24:55,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:24:59,682] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:25:03,976] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:25:08,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:25:12,750] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:25:17,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.261443269923286
[2022-12-07 10:25:17,196] [INFO] [runner_train_mujoco] Average state value: 0.4074555592735608
[2022-12-07 10:25:17,196] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 10:25:17,260] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.03901
[2022-12-07 10:25:17,312] [INFO] [controller] EPOCH 2 loss ppo:  -0.02321, loss val: 0.03947
[2022-12-07 10:25:17,364] [INFO] [controller] EPOCH 3 loss ppo:  -0.03147, loss val: 0.03841
[2022-12-07 10:25:17,409] [INFO] [controller] EPOCH 4 loss ppo:  -0.03726, loss val: 0.03795
[2022-12-07 10:25:17,419] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:25:17,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:25:17,587] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:25:21,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:25:26,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:25:30,234] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:25:34,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:25:38,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:25:42,569] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:25:46,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:25:50,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:25:55,343] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:25:59,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5462117783003135
[2022-12-07 10:25:59,342] [INFO] [runner_train_mujoco] Average state value: 0.4042632649143537
[2022-12-07 10:25:59,342] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 10:25:59,407] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.03826
[2022-12-07 10:25:59,455] [INFO] [controller] EPOCH 2 loss ppo:  -0.01997, loss val: 0.03451
[2022-12-07 10:25:59,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.03147, loss val: 0.03500
[2022-12-07 10:25:59,565] [INFO] [controller] EPOCH 4 loss ppo:  -0.02944, loss val: 0.03456
[2022-12-07 10:25:59,575] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:25:59,767] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:25:59,768] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:26:04,475] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:26:09,073] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:26:13,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:26:18,067] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:26:22,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:26:26,899] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:26:31,079] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:26:35,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:26:39,547] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:26:43,668] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5421793326841042
[2022-12-07 10:26:43,668] [INFO] [runner_train_mujoco] Average state value: 0.45781807603438696
[2022-12-07 10:26:43,668] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 10:26:43,719] [INFO] [controller] EPOCH 1 loss ppo:  -0.01162, loss val: 0.04752
[2022-12-07 10:26:43,762] [INFO] [controller] EPOCH 2 loss ppo:  -0.02095, loss val: 0.04783
[2022-12-07 10:26:43,807] [INFO] [controller] EPOCH 3 loss ppo:  -0.03004, loss val: 0.04794
[2022-12-07 10:26:43,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.03561, loss val: 0.04934
[2022-12-07 10:26:43,861] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:26:44,004] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:26:44,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:26:47,917] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:26:52,069] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:26:56,330] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:27:00,453] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:27:04,465] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:27:08,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:27:12,937] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:27:17,249] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:27:21,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:27:26,215] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8838905105771686
[2022-12-07 10:27:26,216] [INFO] [runner_train_mujoco] Average state value: 0.46468840163946157
[2022-12-07 10:27:26,216] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 10:27:26,291] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.04611
[2022-12-07 10:27:26,361] [INFO] [controller] EPOCH 2 loss ppo:  -0.02138, loss val: 0.04434
[2022-12-07 10:27:26,411] [INFO] [controller] EPOCH 3 loss ppo:  -0.02755, loss val: 0.04377
[2022-12-07 10:27:26,459] [INFO] [controller] EPOCH 4 loss ppo:  -0.03138, loss val: 0.04544
[2022-12-07 10:27:26,470] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:27:26,639] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:27:26,639] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:27:31,304] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:27:35,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:27:40,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:27:44,396] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:27:48,454] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:27:52,434] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:27:56,570] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:28:00,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:28:04,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:28:09,657] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.133560419315927
[2022-12-07 10:28:09,658] [INFO] [runner_train_mujoco] Average state value: 0.4935650528271992
[2022-12-07 10:28:09,658] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 10:28:09,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04553
[2022-12-07 10:28:09,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.02205, loss val: 0.04603
[2022-12-07 10:28:09,826] [INFO] [controller] EPOCH 3 loss ppo:  -0.02777, loss val: 0.04422
[2022-12-07 10:28:09,888] [INFO] [controller] EPOCH 4 loss ppo:  -0.03399, loss val: 0.04163
[2022-12-07 10:28:09,898] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:28:10,080] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:28:10,080] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:28:14,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:28:19,408] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:28:23,810] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:28:28,234] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:28:32,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:28:36,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:28:41,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:28:45,368] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:28:49,601] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:28:53,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9997202655101676
[2022-12-07 10:28:53,543] [INFO] [runner_train_mujoco] Average state value: 0.46315608594814933
[2022-12-07 10:28:53,544] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 10:28:53,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01486, loss val: 0.04726
[2022-12-07 10:28:53,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.02367, loss val: 0.04886
[2022-12-07 10:28:53,682] [INFO] [controller] EPOCH 3 loss ppo:  -0.02993, loss val: 0.04851
[2022-12-07 10:28:53,725] [INFO] [controller] EPOCH 4 loss ppo:  -0.03636, loss val: 0.04768
[2022-12-07 10:28:53,735] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:28:53,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:28:53,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:28:58,174] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:29:02,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:29:06,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:29:10,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:29:14,550] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:29:18,718] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:29:22,830] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:29:26,780] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:29:30,809] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:29:34,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.448396612646588
[2022-12-07 10:29:34,814] [INFO] [runner_train_mujoco] Average state value: 0.4582369157671929
[2022-12-07 10:29:34,814] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 10:29:34,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.03519
[2022-12-07 10:29:34,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.01992, loss val: 0.03588
[2022-12-07 10:29:34,965] [INFO] [controller] EPOCH 3 loss ppo:  -0.02301, loss val: 0.03569
[2022-12-07 10:29:35,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.03165, loss val: 0.03555
[2022-12-07 10:29:35,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:29:35,198] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:29:35,198] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:29:39,215] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:29:43,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:29:48,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:29:52,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:29:57,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:30:01,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:30:06,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:30:10,289] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:30:14,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:30:18,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.350888921056933
[2022-12-07 10:30:18,368] [INFO] [runner_train_mujoco] Average state value: 0.47471200458208723
[2022-12-07 10:30:18,368] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 10:30:18,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04624
[2022-12-07 10:30:18,467] [INFO] [controller] EPOCH 2 loss ppo:  -0.01866, loss val: 0.04490
[2022-12-07 10:30:18,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.02620, loss val: 0.04542
[2022-12-07 10:30:18,550] [INFO] [controller] EPOCH 4 loss ppo:  -0.03268, loss val: 0.04433
[2022-12-07 10:30:18,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:30:18,717] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:30:18,718] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:30:22,999] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:30:26,928] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:30:31,567] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:30:35,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:30:39,530] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:30:43,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:30:47,942] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:30:52,894] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:30:57,252] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:31:02,076] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.46144476529862
[2022-12-07 10:31:02,077] [INFO] [runner_train_mujoco] Average state value: 0.443838363289833
[2022-12-07 10:31:02,077] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 10:31:02,171] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04356
[2022-12-07 10:31:02,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.02098, loss val: 0.04423
[2022-12-07 10:31:02,295] [INFO] [controller] EPOCH 3 loss ppo:  -0.02635, loss val: 0.04289
[2022-12-07 10:31:02,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.03193, loss val: 0.04140
[2022-12-07 10:31:02,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:31:02,552] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:31:02,553] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:31:06,810] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:31:10,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:31:15,149] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:31:18,985] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:31:23,021] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:31:27,443] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:31:31,509] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:31:36,099] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:31:41,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:31:45,964] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.472507629666373
[2022-12-07 10:31:45,965] [INFO] [runner_train_mujoco] Average state value: 0.4686693281928698
[2022-12-07 10:31:45,965] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 10:31:46,023] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.04330
[2022-12-07 10:31:46,068] [INFO] [controller] EPOCH 2 loss ppo:  -0.02130, loss val: 0.04360
[2022-12-07 10:31:46,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.02995, loss val: 0.04483
[2022-12-07 10:31:46,169] [INFO] [controller] EPOCH 4 loss ppo:  -0.03412, loss val: 0.04376
[2022-12-07 10:31:46,180] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:31:46,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:31:46,361] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:31:51,332] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:31:56,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:32:00,497] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:32:05,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:32:09,976] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:32:14,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:32:18,476] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:32:22,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:32:27,004] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:32:31,744] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.944374516352769
[2022-12-07 10:32:31,745] [INFO] [runner_train_mujoco] Average state value: 0.48139091344674423
[2022-12-07 10:32:31,745] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 10:32:31,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.04883
[2022-12-07 10:32:31,863] [INFO] [controller] EPOCH 2 loss ppo:  -0.01894, loss val: 0.04723
[2022-12-07 10:32:31,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.02286, loss val: 0.04563
[2022-12-07 10:32:31,987] [INFO] [controller] EPOCH 4 loss ppo:  -0.02906, loss val: 0.04549
[2022-12-07 10:32:32,000] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:32:32,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:32:32,189] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:32:36,910] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:32:41,429] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:32:46,086] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:32:50,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:32:55,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:33:00,302] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:33:04,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:33:09,095] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:33:13,330] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:33:17,857] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.631499195870083
[2022-12-07 10:33:17,857] [INFO] [runner_train_mujoco] Average state value: 0.44526512350638703
[2022-12-07 10:33:17,857] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 10:33:17,920] [INFO] [controller] EPOCH 1 loss ppo:  -0.01237, loss val: 0.04281
[2022-12-07 10:33:17,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.01543, loss val: 0.04021
[2022-12-07 10:33:18,023] [INFO] [controller] EPOCH 3 loss ppo:  -0.01970, loss val: 0.04278
[2022-12-07 10:33:18,084] [INFO] [controller] EPOCH 4 loss ppo:  -0.02693, loss val: 0.04255
[2022-12-07 10:33:18,096] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:33:18,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:33:18,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:33:22,623] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:33:27,066] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:33:31,339] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:33:35,210] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:33:38,977] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:33:43,533] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:33:47,978] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:33:52,340] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:33:56,719] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:34:01,248] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.570381424394416
[2022-12-07 10:34:01,248] [INFO] [runner_train_mujoco] Average state value: 0.40906898812452946
[2022-12-07 10:34:01,248] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 10:34:01,333] [INFO] [controller] EPOCH 1 loss ppo:  -0.01130, loss val: 0.04496
[2022-12-07 10:34:01,386] [INFO] [controller] EPOCH 2 loss ppo:  -0.02049, loss val: 0.04757
[2022-12-07 10:34:01,447] [INFO] [controller] EPOCH 3 loss ppo:  -0.02583, loss val: 0.04731
[2022-12-07 10:34:01,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.02781, loss val: 0.04538
[2022-12-07 10:34:01,524] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:34:01,703] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:34:01,703] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:34:06,512] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:34:10,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:34:14,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:34:19,097] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:34:23,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:34:28,019] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:34:31,878] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:34:35,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:34:39,692] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:34:43,964] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.800292479471642
[2022-12-07 10:34:43,965] [INFO] [runner_train_mujoco] Average state value: 0.42414918631315235
[2022-12-07 10:34:43,965] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 10:34:44,100] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.04007
[2022-12-07 10:34:44,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.02048, loss val: 0.03789
[2022-12-07 10:34:44,387] [INFO] [controller] EPOCH 3 loss ppo:  -0.02743, loss val: 0.03996
[2022-12-07 10:34:44,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.03043, loss val: 0.03316
[2022-12-07 10:34:44,499] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:34:44,699] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:34:44,699] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:34:49,583] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:34:53,822] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:34:58,434] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:35:02,453] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:35:06,294] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:35:10,458] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:35:14,494] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:35:18,642] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:35:22,777] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:35:26,662] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.977428543547423
[2022-12-07 10:35:26,662] [INFO] [runner_train_mujoco] Average state value: 0.4916753265062968
[2022-12-07 10:35:26,662] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 10:35:26,714] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04382
[2022-12-07 10:35:26,756] [INFO] [controller] EPOCH 2 loss ppo:  -0.02207, loss val: 0.04498
[2022-12-07 10:35:26,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.02309, loss val: 0.04555
[2022-12-07 10:35:26,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.02796, loss val: 0.04685
[2022-12-07 10:35:26,856] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:35:27,004] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:35:27,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:35:30,709] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:35:34,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:35:38,931] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:35:43,176] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:35:47,702] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:35:52,803] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:35:57,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:36:01,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:36:05,989] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:36:10,254] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.96888801523428
[2022-12-07 10:36:10,254] [INFO] [runner_train_mujoco] Average state value: 0.5056096567908923
[2022-12-07 10:36:10,255] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 10:36:10,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.06357
[2022-12-07 10:36:10,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.02030, loss val: 0.05990
[2022-12-07 10:36:10,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.02495, loss val: 0.05682
[2022-12-07 10:36:10,591] [INFO] [controller] EPOCH 4 loss ppo:  -0.03044, loss val: 0.05444
[2022-12-07 10:36:10,601] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:36:10,784] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:36:10,784] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:36:15,333] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:36:19,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:36:22,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:36:26,705] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:36:30,329] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:36:34,117] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:36:38,089] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:36:41,670] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:36:45,442] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:36:49,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0185951108816695
[2022-12-07 10:36:49,381] [INFO] [runner_train_mujoco] Average state value: 0.4472190897067388
[2022-12-07 10:36:49,381] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 10:36:49,431] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04459
[2022-12-07 10:36:49,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.01702, loss val: 0.04461
[2022-12-07 10:36:49,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.02152, loss val: 0.04564
[2022-12-07 10:36:49,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.02393, loss val: 0.04547
[2022-12-07 10:36:49,586] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:36:49,757] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:36:49,758] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:36:53,716] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:36:57,805] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:37:01,922] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:37:06,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:37:09,842] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:37:13,799] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:37:17,624] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:37:21,395] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:37:25,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:37:29,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.977340435924427
[2022-12-07 10:37:29,165] [INFO] [runner_train_mujoco] Average state value: 0.4046068846980731
[2022-12-07 10:37:29,165] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 10:37:29,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01024, loss val: 0.04678
[2022-12-07 10:37:29,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.01389, loss val: 0.04730
[2022-12-07 10:37:29,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02328, loss val: 0.04666
[2022-12-07 10:37:29,366] [INFO] [controller] EPOCH 4 loss ppo:  -0.02536, loss val: 0.04712
[2022-12-07 10:37:29,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:37:29,544] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:37:29,545] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:37:33,599] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:37:37,767] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:37:41,852] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:37:45,817] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:37:49,832] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:37:54,170] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:37:57,994] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:38:02,046] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:38:06,327] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:38:10,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.052715435723742
[2022-12-07 10:38:10,324] [INFO] [runner_train_mujoco] Average state value: 0.41708135656515755
[2022-12-07 10:38:10,324] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 10:38:10,386] [INFO] [controller] EPOCH 1 loss ppo:  -0.01273, loss val: 0.05275
[2022-12-07 10:38:10,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.02033, loss val: 0.05353
[2022-12-07 10:38:10,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.02444, loss val: 0.05202
[2022-12-07 10:38:10,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.02960, loss val: 0.05191
[2022-12-07 10:38:10,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:38:10,732] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:38:10,733] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:38:14,772] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:38:18,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:38:22,789] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:38:26,681] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:38:30,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:38:34,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:38:38,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:38:42,966] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:38:47,235] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:38:51,360] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.3886791886446135
[2022-12-07 10:38:51,361] [INFO] [runner_train_mujoco] Average state value: 0.4404404552578926
[2022-12-07 10:38:51,361] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 10:38:51,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01267, loss val: 0.04096
[2022-12-07 10:38:51,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.01934, loss val: 0.04126
[2022-12-07 10:38:51,501] [INFO] [controller] EPOCH 3 loss ppo:  -0.02309, loss val: 0.04130
[2022-12-07 10:38:51,541] [INFO] [controller] EPOCH 4 loss ppo:  -0.02485, loss val: 0.04496
[2022-12-07 10:38:51,551] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:38:51,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:38:51,741] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:38:56,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:39:00,181] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:39:04,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:39:08,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:39:12,395] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:39:16,481] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:39:20,368] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:39:24,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:39:28,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:39:31,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.2644188610059235
[2022-12-07 10:39:31,841] [INFO] [runner_train_mujoco] Average state value: 0.45426422011852263
[2022-12-07 10:39:31,841] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 10:39:31,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04722
[2022-12-07 10:39:31,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.01912, loss val: 0.04632
[2022-12-07 10:39:31,985] [INFO] [controller] EPOCH 3 loss ppo:  -0.02291, loss val: 0.04766
[2022-12-07 10:39:32,028] [INFO] [controller] EPOCH 4 loss ppo:  -0.02592, loss val: 0.04502
[2022-12-07 10:39:32,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:39:32,211] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:39:32,212] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:39:35,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:39:40,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:39:44,010] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:39:48,138] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:39:52,340] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:39:56,331] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:40:00,034] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:40:04,199] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:40:08,006] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:40:11,860] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.155880452635774
[2022-12-07 10:40:11,861] [INFO] [runner_train_mujoco] Average state value: 0.4566602170268695
[2022-12-07 10:40:11,861] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 10:40:11,918] [INFO] [controller] EPOCH 1 loss ppo:  -0.01179, loss val: 0.05469
[2022-12-07 10:40:11,965] [INFO] [controller] EPOCH 2 loss ppo:  -0.01661, loss val: 0.05465
[2022-12-07 10:40:12,022] [INFO] [controller] EPOCH 3 loss ppo:  -0.02384, loss val: 0.05444
[2022-12-07 10:40:12,080] [INFO] [controller] EPOCH 4 loss ppo:  -0.02712, loss val: 0.05427
[2022-12-07 10:40:12,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:40:12,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:40:12,263] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:40:16,185] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:40:20,289] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:40:24,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:40:28,310] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:40:32,222] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:40:36,276] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:40:40,147] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:40:44,224] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:40:48,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:40:52,010] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.32985443702616
[2022-12-07 10:40:52,010] [INFO] [runner_train_mujoco] Average state value: 0.44426106502612434
[2022-12-07 10:40:52,010] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 10:40:52,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.04568
[2022-12-07 10:40:52,105] [INFO] [controller] EPOCH 2 loss ppo:  -0.01854, loss val: 0.04545
[2022-12-07 10:40:52,152] [INFO] [controller] EPOCH 3 loss ppo:  -0.02006, loss val: 0.04481
[2022-12-07 10:40:52,196] [INFO] [controller] EPOCH 4 loss ppo:  -0.02645, loss val: 0.04458
[2022-12-07 10:40:52,205] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:40:52,364] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:40:52,364] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:40:56,184] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:40:59,802] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:41:03,888] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:41:07,535] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:41:11,084] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:41:14,661] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:41:18,273] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:41:21,997] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:41:25,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:41:29,685] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.293963719269098
[2022-12-07 10:41:29,685] [INFO] [runner_train_mujoco] Average state value: 0.4233469462792079
[2022-12-07 10:41:29,685] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 10:41:29,736] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.05198
[2022-12-07 10:41:29,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.01690, loss val: 0.04986
[2022-12-07 10:41:29,821] [INFO] [controller] EPOCH 3 loss ppo:  -0.02285, loss val: 0.05107
[2022-12-07 10:41:29,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.02870, loss val: 0.05106
[2022-12-07 10:41:29,872] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:41:30,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:41:30,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:41:33,849] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:41:38,608] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:41:42,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:41:46,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:41:50,483] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:41:54,626] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:41:58,977] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:42:02,702] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:42:06,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:42:10,259] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.268734347575337
[2022-12-07 10:42:10,260] [INFO] [runner_train_mujoco] Average state value: 0.40170343659321467
[2022-12-07 10:42:10,260] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 10:42:10,311] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.04397
[2022-12-07 10:42:10,352] [INFO] [controller] EPOCH 2 loss ppo:  -0.02389, loss val: 0.04417
[2022-12-07 10:42:10,393] [INFO] [controller] EPOCH 3 loss ppo:  -0.02622, loss val: 0.04438
[2022-12-07 10:42:10,436] [INFO] [controller] EPOCH 4 loss ppo:  -0.02655, loss val: 0.04592
[2022-12-07 10:42:10,446] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:42:10,596] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:42:10,597] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:42:14,325] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:42:17,835] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:42:21,531] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:42:24,998] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:42:28,595] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:42:32,226] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:42:36,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:42:39,571] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:42:43,100] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:42:47,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.290308978091124
[2022-12-07 10:42:47,090] [INFO] [runner_train_mujoco] Average state value: 0.40351660605271655
[2022-12-07 10:42:47,090] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 10:42:47,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.01244, loss val: 0.04829
[2022-12-07 10:42:47,199] [INFO] [controller] EPOCH 2 loss ppo:  -0.01882, loss val: 0.04689
[2022-12-07 10:42:47,254] [INFO] [controller] EPOCH 3 loss ppo:  -0.02028, loss val: 0.04717
[2022-12-07 10:42:47,305] [INFO] [controller] EPOCH 4 loss ppo:  -0.02340, loss val: 0.04863
[2022-12-07 10:42:47,316] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:42:47,484] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:42:47,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:42:51,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:42:55,596] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:42:59,391] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:43:03,300] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:43:07,143] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:43:11,068] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:43:14,931] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:43:18,800] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:43:23,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:43:28,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.203229696515025
[2022-12-07 10:43:28,285] [INFO] [runner_train_mujoco] Average state value: 0.40350205117464066
[2022-12-07 10:43:28,285] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 10:43:28,343] [INFO] [controller] EPOCH 1 loss ppo:  -0.01101, loss val: 0.05933
[2022-12-07 10:43:28,392] [INFO] [controller] EPOCH 2 loss ppo:  -0.01492, loss val: 0.05928
[2022-12-07 10:43:28,441] [INFO] [controller] EPOCH 3 loss ppo:  -0.01872, loss val: 0.05934
[2022-12-07 10:43:28,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.02212, loss val: 0.05916
[2022-12-07 10:43:28,497] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:43:28,669] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:43:28,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:43:32,506] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:43:36,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:43:40,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:43:43,981] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:43:47,822] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:43:51,559] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:43:55,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:43:59,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:44:03,151] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:44:06,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.44668028310149
[2022-12-07 10:44:06,919] [INFO] [runner_train_mujoco] Average state value: 0.40592993644873304
[2022-12-07 10:44:06,919] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 10:44:06,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01280, loss val: 0.04751
[2022-12-07 10:44:07,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.01797, loss val: 0.04745
[2022-12-07 10:44:07,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.02361, loss val: 0.04942
[2022-12-07 10:44:07,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.02435, loss val: 0.04882
[2022-12-07 10:44:07,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:44:07,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:44:07,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:44:11,063] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:44:14,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:44:18,758] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:44:22,329] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:44:26,615] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:44:30,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:44:34,364] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:44:38,439] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:44:42,195] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:44:46,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.453489261361621
[2022-12-07 10:44:46,256] [INFO] [runner_train_mujoco] Average state value: 0.40452945109208427
[2022-12-07 10:44:46,256] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 10:44:46,312] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.04033
[2022-12-07 10:44:46,358] [INFO] [controller] EPOCH 2 loss ppo:  -0.01593, loss val: 0.03993
[2022-12-07 10:44:46,404] [INFO] [controller] EPOCH 3 loss ppo:  -0.02211, loss val: 0.04084
[2022-12-07 10:44:46,446] [INFO] [controller] EPOCH 4 loss ppo:  -0.02545, loss val: 0.03960
[2022-12-07 10:44:46,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:44:46,624] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:44:46,625] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:44:50,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:44:54,485] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:44:58,921] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:45:02,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:45:07,078] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:45:10,922] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:45:14,842] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:45:18,755] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:45:22,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:45:26,620] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.410910571244507
[2022-12-07 10:45:26,620] [INFO] [runner_train_mujoco] Average state value: 0.40695189936955767
[2022-12-07 10:45:26,620] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 10:45:26,678] [INFO] [controller] EPOCH 1 loss ppo:  -0.01249, loss val: 0.04732
[2022-12-07 10:45:26,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.01629, loss val: 0.04860
[2022-12-07 10:45:26,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.01926, loss val: 0.04705
[2022-12-07 10:45:26,815] [INFO] [controller] EPOCH 4 loss ppo:  -0.02018, loss val: 0.04722
[2022-12-07 10:45:26,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:45:26,986] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:45:26,986] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:45:30,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:45:35,003] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:45:40,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:45:45,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:45:49,527] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:45:54,039] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:45:58,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:46:02,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:46:07,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:46:12,511] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.674824742017526
[2022-12-07 10:46:12,512] [INFO] [runner_train_mujoco] Average state value: 0.41238028202454247
[2022-12-07 10:46:12,512] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 10:46:12,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01194, loss val: 0.05076
[2022-12-07 10:46:12,670] [INFO] [controller] EPOCH 2 loss ppo:  -0.01384, loss val: 0.04965
[2022-12-07 10:46:12,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.01704, loss val: 0.05063
[2022-12-07 10:46:12,767] [INFO] [controller] EPOCH 4 loss ppo:  -0.02050, loss val: 0.04886
[2022-12-07 10:46:12,779] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:46:12,978] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:46:12,979] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:46:17,579] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:46:21,751] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:46:25,984] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:46:30,113] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:46:34,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:46:38,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:46:42,954] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:46:47,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:46:51,638] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:46:55,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.622675762987294
[2022-12-07 10:46:55,642] [INFO] [runner_train_mujoco] Average state value: 0.40479793175061546
[2022-12-07 10:46:55,642] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 10:46:55,707] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.04743
[2022-12-07 10:46:55,761] [INFO] [controller] EPOCH 2 loss ppo:  -0.01489, loss val: 0.04875
[2022-12-07 10:46:55,810] [INFO] [controller] EPOCH 3 loss ppo:  -0.01937, loss val: 0.04908
[2022-12-07 10:46:55,858] [INFO] [controller] EPOCH 4 loss ppo:  -0.02228, loss val: 0.04901
[2022-12-07 10:46:55,869] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:46:56,052] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:46:56,053] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:47:00,372] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:47:04,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:47:08,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:47:12,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:47:15,963] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:47:20,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:47:24,098] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:47:28,230] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:47:32,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:47:36,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4347862569677545
[2022-12-07 10:47:36,633] [INFO] [runner_train_mujoco] Average state value: 0.39209726939598716
[2022-12-07 10:47:36,633] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 10:47:36,715] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.04286
[2022-12-07 10:47:36,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.01437, loss val: 0.04347
[2022-12-07 10:47:36,825] [INFO] [controller] EPOCH 3 loss ppo:  -0.01795, loss val: 0.04400
[2022-12-07 10:47:36,871] [INFO] [controller] EPOCH 4 loss ppo:  -0.02160, loss val: 0.04306
[2022-12-07 10:47:36,881] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:47:37,035] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:47:37,035] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:47:41,150] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:47:45,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:47:50,108] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:47:54,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:47:58,456] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:48:02,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:48:07,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:48:11,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:48:15,770] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:48:20,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.527204784903699
[2022-12-07 10:48:20,004] [INFO] [runner_train_mujoco] Average state value: 0.3925272194345792
[2022-12-07 10:48:20,004] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 10:48:20,070] [INFO] [controller] EPOCH 1 loss ppo:  -0.01211, loss val: 0.05038
[2022-12-07 10:48:20,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.01474, loss val: 0.05008
[2022-12-07 10:48:20,288] [INFO] [controller] EPOCH 3 loss ppo:  -0.01743, loss val: 0.05119
[2022-12-07 10:48:20,370] [INFO] [controller] EPOCH 4 loss ppo:  -0.01970, loss val: 0.05069
[2022-12-07 10:48:20,381] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:48:20,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:48:20,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:48:24,534] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:48:28,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:48:32,701] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:48:36,797] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:48:40,935] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:48:44,682] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:48:48,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:48:52,987] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:48:57,000] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:49:00,814] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5318356177484675
[2022-12-07 10:49:00,815] [INFO] [runner_train_mujoco] Average state value: 0.3968170531988144
[2022-12-07 10:49:00,815] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 10:49:00,877] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.04037
[2022-12-07 10:49:00,930] [INFO] [controller] EPOCH 2 loss ppo:  -0.01308, loss val: 0.04147
[2022-12-07 10:49:00,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.01493, loss val: 0.03961
[2022-12-07 10:49:01,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.01690, loss val: 0.03995
[2022-12-07 10:49:01,042] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:49:01,213] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:49:01,213] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:49:05,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:49:09,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:49:13,386] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:49:17,738] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:49:22,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:49:27,117] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:49:31,544] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:49:35,476] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:49:39,574] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:49:44,202] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5927419286397715
[2022-12-07 10:49:44,202] [INFO] [runner_train_mujoco] Average state value: 0.39953601954380674
[2022-12-07 10:49:44,202] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 10:49:44,259] [INFO] [controller] EPOCH 1 loss ppo:  -0.01196, loss val: 0.04705
[2022-12-07 10:49:44,306] [INFO] [controller] EPOCH 2 loss ppo:  -0.01263, loss val: 0.04608
[2022-12-07 10:49:44,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.01370, loss val: 0.04607
[2022-12-07 10:49:44,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.01507, loss val: 0.04830
[2022-12-07 10:49:44,414] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:49:44,564] [INFO] [optimize] Finished learning.
