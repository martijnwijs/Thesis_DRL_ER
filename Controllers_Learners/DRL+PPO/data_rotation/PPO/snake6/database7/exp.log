[2022-12-07 04:15:55,308] [INFO] [optimize] Starting learning
[2022-12-07 04:15:55,314] [INFO] [optimize] Starting learning process..
[2022-12-07 04:15:55,370] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:15:55,370] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:16:00,697] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:16:05,144] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:16:09,203] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:16:13,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:16:17,718] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:16:21,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:16:26,068] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:16:30,228] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:16:34,233] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:16:38,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42826542425298814
[2022-12-07 04:16:38,432] [INFO] [runner_train_mujoco] Average state value: 0.3120058158213893
[2022-12-07 04:16:38,433] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 04:16:38,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01710, loss val: 0.15354
[2022-12-07 04:16:38,538] [INFO] [controller] EPOCH 2 loss ppo:  -0.03054, loss val: 0.12846
[2022-12-07 04:16:38,586] [INFO] [controller] EPOCH 3 loss ppo:  -0.03833, loss val: 0.11120
[2022-12-07 04:16:38,629] [INFO] [controller] EPOCH 4 loss ppo:  -0.04191, loss val: 0.09653
[2022-12-07 04:16:38,637] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:16:38,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:16:38,790] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:16:42,710] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:16:46,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:16:50,826] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:16:54,912] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:16:58,999] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:17:03,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:17:07,376] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:17:11,601] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:17:15,401] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:17:19,229] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3518629561292096
[2022-12-07 04:17:19,230] [INFO] [runner_train_mujoco] Average state value: 0.4592271079719067
[2022-12-07 04:17:19,230] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 04:17:19,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.09612
[2022-12-07 04:17:19,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.02603, loss val: 0.08602
[2022-12-07 04:17:19,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.02942, loss val: 0.07264
[2022-12-07 04:17:19,450] [INFO] [controller] EPOCH 4 loss ppo:  -0.03773, loss val: 0.06822
[2022-12-07 04:17:19,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:17:19,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:17:19,610] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:17:23,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:17:27,386] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:17:31,482] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:17:35,524] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:17:39,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:17:43,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:17:48,023] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:17:52,333] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:17:56,800] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:18:00,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6096578039379782
[2022-12-07 04:18:00,528] [INFO] [runner_train_mujoco] Average state value: 0.5867932100991408
[2022-12-07 04:18:00,528] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 04:18:00,586] [INFO] [controller] EPOCH 1 loss ppo:  -0.01075, loss val: 0.06285
[2022-12-07 04:18:00,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.02116, loss val: 0.05720
[2022-12-07 04:18:00,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.02963, loss val: 0.05647
[2022-12-07 04:18:00,724] [INFO] [controller] EPOCH 4 loss ppo:  -0.03431, loss val: 0.04942
[2022-12-07 04:18:00,730] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:18:00,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:18:00,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:18:05,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:18:09,594] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:18:13,646] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:18:17,393] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:18:21,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:18:25,133] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:18:28,958] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:18:32,928] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:18:36,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:18:41,080] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4398739836564289
[2022-12-07 04:18:41,081] [INFO] [runner_train_mujoco] Average state value: 0.5963108920156955
[2022-12-07 04:18:41,081] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 04:18:41,139] [INFO] [controller] EPOCH 1 loss ppo:  -0.01000, loss val: 0.05905
[2022-12-07 04:18:41,284] [INFO] [controller] EPOCH 2 loss ppo:  -0.02084, loss val: 0.05748
[2022-12-07 04:18:41,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.02451, loss val: 0.05432
[2022-12-07 04:18:41,379] [INFO] [controller] EPOCH 4 loss ppo:  -0.03171, loss val: 0.05190
[2022-12-07 04:18:41,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:18:41,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:18:41,550] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:18:45,614] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:18:49,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:18:53,886] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:18:58,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:19:02,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:19:07,416] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:19:11,479] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:19:15,466] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:19:19,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:19:23,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5500465842190855
[2022-12-07 04:19:23,483] [INFO] [runner_train_mujoco] Average state value: 0.6231746531923613
[2022-12-07 04:19:23,484] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 04:19:23,532] [INFO] [controller] EPOCH 1 loss ppo:  -0.00917, loss val: 0.03943
[2022-12-07 04:19:23,583] [INFO] [controller] EPOCH 2 loss ppo:  -0.01743, loss val: 0.03760
[2022-12-07 04:19:23,627] [INFO] [controller] EPOCH 3 loss ppo:  -0.02615, loss val: 0.03743
[2022-12-07 04:19:23,672] [INFO] [controller] EPOCH 4 loss ppo:  -0.03204, loss val: 0.03941
[2022-12-07 04:19:23,682] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:19:23,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:19:23,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:19:28,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:19:32,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:19:36,669] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:19:40,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:19:44,732] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:19:48,887] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:19:52,888] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:19:56,884] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:20:00,677] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:20:04,876] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5853649598431382
[2022-12-07 04:20:04,876] [INFO] [runner_train_mujoco] Average state value: 0.6245112449924151
[2022-12-07 04:20:04,876] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 04:20:04,927] [INFO] [controller] EPOCH 1 loss ppo:  -0.01074, loss val: 0.03540
[2022-12-07 04:20:04,970] [INFO] [controller] EPOCH 2 loss ppo:  -0.01945, loss val: 0.03342
[2022-12-07 04:20:05,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.02166, loss val: 0.02954
[2022-12-07 04:20:05,052] [INFO] [controller] EPOCH 4 loss ppo:  -0.02599, loss val: 0.02691
[2022-12-07 04:20:05,062] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:20:05,215] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:20:05,215] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:20:09,447] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:20:13,608] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:20:17,887] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:20:22,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:20:26,239] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:20:30,413] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:20:34,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:20:38,108] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:20:41,896] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:20:46,121] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5523832841782608
[2022-12-07 04:20:46,121] [INFO] [runner_train_mujoco] Average state value: 0.5403593490123748
[2022-12-07 04:20:46,122] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 04:20:46,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.01019, loss val: 0.03403
[2022-12-07 04:20:46,224] [INFO] [controller] EPOCH 2 loss ppo:  -0.02104, loss val: 0.03073
[2022-12-07 04:20:46,268] [INFO] [controller] EPOCH 3 loss ppo:  -0.02269, loss val: 0.02891
[2022-12-07 04:20:46,312] [INFO] [controller] EPOCH 4 loss ppo:  -0.02655, loss val: 0.02858
[2022-12-07 04:20:46,322] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:20:46,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:20:46,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:20:50,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:20:54,651] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:20:59,080] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:21:03,350] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:21:07,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:21:11,486] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:21:15,616] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:21:19,379] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:21:23,432] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:21:27,326] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6464926614874054
[2022-12-07 04:21:27,326] [INFO] [runner_train_mujoco] Average state value: 0.4410147517323494
[2022-12-07 04:21:27,327] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 04:21:27,377] [INFO] [controller] EPOCH 1 loss ppo:  -0.01145, loss val: 0.04732
[2022-12-07 04:21:27,417] [INFO] [controller] EPOCH 2 loss ppo:  -0.02312, loss val: 0.04850
[2022-12-07 04:21:27,458] [INFO] [controller] EPOCH 3 loss ppo:  -0.03238, loss val: 0.04887
[2022-12-07 04:21:27,500] [INFO] [controller] EPOCH 4 loss ppo:  -0.03699, loss val: 0.04672
[2022-12-07 04:21:27,509] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:21:27,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:21:27,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:21:31,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:21:35,898] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:21:40,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:21:44,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:21:48,384] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:21:52,586] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:21:56,933] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:22:01,941] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:22:06,263] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:22:10,682] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6108790559955416
[2022-12-07 04:22:10,682] [INFO] [runner_train_mujoco] Average state value: 0.44612207890550293
[2022-12-07 04:22:10,682] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 04:22:10,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.03855
[2022-12-07 04:22:10,788] [INFO] [controller] EPOCH 2 loss ppo:  -0.02399, loss val: 0.03540
[2022-12-07 04:22:10,835] [INFO] [controller] EPOCH 3 loss ppo:  -0.02737, loss val: 0.03773
[2022-12-07 04:22:10,883] [INFO] [controller] EPOCH 4 loss ppo:  -0.03023, loss val: 0.03534
[2022-12-07 04:22:10,893] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:22:11,037] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:22:11,038] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:22:15,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:22:18,923] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:22:22,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:22:26,969] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:22:30,918] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:22:34,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:22:38,401] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:22:42,468] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:22:46,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:22:50,580] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.576221226021806
[2022-12-07 04:22:50,580] [INFO] [runner_train_mujoco] Average state value: 0.496142973601818
[2022-12-07 04:22:50,580] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 04:22:50,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.03097
[2022-12-07 04:22:50,680] [INFO] [controller] EPOCH 2 loss ppo:  -0.02159, loss val: 0.03134
[2022-12-07 04:22:50,723] [INFO] [controller] EPOCH 3 loss ppo:  -0.02331, loss val: 0.03090
[2022-12-07 04:22:50,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.02894, loss val: 0.03361
[2022-12-07 04:22:50,777] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:22:50,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:22:50,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:22:55,118] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:22:59,437] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:23:04,017] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:23:08,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:23:12,850] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:23:16,722] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:23:20,735] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:23:24,726] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:23:28,636] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:23:32,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5913679306294757
[2022-12-07 04:23:32,632] [INFO] [runner_train_mujoco] Average state value: 0.5145205805202325
[2022-12-07 04:23:32,632] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 04:23:32,684] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.03860
[2022-12-07 04:23:32,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.01950, loss val: 0.03788
[2022-12-07 04:23:32,776] [INFO] [controller] EPOCH 3 loss ppo:  -0.02482, loss val: 0.03504
[2022-12-07 04:23:32,821] [INFO] [controller] EPOCH 4 loss ppo:  -0.03123, loss val: 0.03370
[2022-12-07 04:23:32,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:23:32,983] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:23:32,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:23:36,936] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:23:40,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:23:44,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:23:48,948] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:23:52,693] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:23:56,706] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:24:00,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:24:04,766] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:24:08,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:24:13,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.64394282861183
[2022-12-07 04:24:13,110] [INFO] [runner_train_mujoco] Average state value: 0.577263708670934
[2022-12-07 04:24:13,110] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 04:24:13,164] [INFO] [controller] EPOCH 1 loss ppo:  -0.01029, loss val: 0.02928
[2022-12-07 04:24:13,210] [INFO] [controller] EPOCH 2 loss ppo:  -0.02264, loss val: 0.02943
[2022-12-07 04:24:13,254] [INFO] [controller] EPOCH 3 loss ppo:  -0.02695, loss val: 0.02920
[2022-12-07 04:24:13,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.03153, loss val: 0.02984
[2022-12-07 04:24:13,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:24:13,450] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:24:13,450] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:24:17,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:24:21,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:24:25,392] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:24:29,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:24:33,374] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:24:37,098] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:24:40,918] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:24:45,366] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:24:49,151] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:24:53,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9314823713970313
[2022-12-07 04:24:53,223] [INFO] [runner_train_mujoco] Average state value: 0.6194913760821025
[2022-12-07 04:24:53,223] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 04:24:53,280] [INFO] [controller] EPOCH 1 loss ppo:  -0.01108, loss val: 0.03998
[2022-12-07 04:24:53,331] [INFO] [controller] EPOCH 2 loss ppo:  -0.01781, loss val: 0.03804
[2022-12-07 04:24:53,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.02518, loss val: 0.03891
[2022-12-07 04:24:53,425] [INFO] [controller] EPOCH 4 loss ppo:  -0.03177, loss val: 0.03702
[2022-12-07 04:24:53,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:24:53,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:24:53,587] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:24:57,773] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:25:01,800] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:25:05,692] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:25:09,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:25:13,716] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:25:17,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:25:21,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:25:25,486] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:25:29,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:25:33,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7361372920974658
[2022-12-07 04:25:33,267] [INFO] [runner_train_mujoco] Average state value: 0.5930424707730612
[2022-12-07 04:25:33,267] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 04:25:33,361] [INFO] [controller] EPOCH 1 loss ppo:  -0.01174, loss val: 0.03779
[2022-12-07 04:25:33,407] [INFO] [controller] EPOCH 2 loss ppo:  -0.02260, loss val: 0.03992
[2022-12-07 04:25:33,455] [INFO] [controller] EPOCH 3 loss ppo:  -0.02617, loss val: 0.03921
[2022-12-07 04:25:33,495] [INFO] [controller] EPOCH 4 loss ppo:  -0.03150, loss val: 0.03856
[2022-12-07 04:25:33,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:25:33,633] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:25:33,633] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:25:37,868] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:25:41,886] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:25:46,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:25:50,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:25:54,038] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:25:58,138] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:26:02,167] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:26:06,208] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:26:10,391] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:26:14,339] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7812612274453689
[2022-12-07 04:26:14,340] [INFO] [runner_train_mujoco] Average state value: 0.5919141057729721
[2022-12-07 04:26:14,340] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 04:26:14,401] [INFO] [controller] EPOCH 1 loss ppo:  -0.01314, loss val: 0.04417
[2022-12-07 04:26:14,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.02552, loss val: 0.04142
[2022-12-07 04:26:14,562] [INFO] [controller] EPOCH 3 loss ppo:  -0.02833, loss val: 0.04413
[2022-12-07 04:26:14,614] [INFO] [controller] EPOCH 4 loss ppo:  -0.03242, loss val: 0.04316
[2022-12-07 04:26:14,624] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:26:14,783] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:26:14,783] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:26:18,662] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:26:22,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:26:26,219] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:26:30,248] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:26:33,888] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:26:37,837] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:26:41,952] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:26:45,887] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:26:50,171] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:26:54,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.288914155706864
[2022-12-07 04:26:54,072] [INFO] [runner_train_mujoco] Average state value: 0.5655770582358043
[2022-12-07 04:26:54,072] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 04:26:54,122] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.04211
[2022-12-07 04:26:54,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.02652, loss val: 0.04015
[2022-12-07 04:26:54,206] [INFO] [controller] EPOCH 3 loss ppo:  -0.03243, loss val: 0.03820
[2022-12-07 04:26:54,249] [INFO] [controller] EPOCH 4 loss ppo:  -0.04113, loss val: 0.03739
[2022-12-07 04:26:54,258] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:26:54,435] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:26:54,435] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:26:58,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:27:02,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:27:06,826] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:27:10,685] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:27:14,745] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:27:18,769] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:27:22,637] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:27:26,338] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:27:30,589] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:27:34,219] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5856532801736836
[2022-12-07 04:27:34,219] [INFO] [runner_train_mujoco] Average state value: 0.5008541894157729
[2022-12-07 04:27:34,219] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 04:27:34,271] [INFO] [controller] EPOCH 1 loss ppo:  -0.01581, loss val: 0.03981
[2022-12-07 04:27:34,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.02936, loss val: 0.04224
[2022-12-07 04:27:34,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.02892, loss val: 0.04155
[2022-12-07 04:27:34,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.03190, loss val: 0.04011
[2022-12-07 04:27:34,407] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:27:34,559] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:27:34,559] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:27:38,795] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:27:42,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:27:46,137] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:27:50,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:27:54,202] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:27:57,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:28:01,802] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:28:05,721] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:28:09,758] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:28:14,064] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1140999159755665
[2022-12-07 04:28:14,064] [INFO] [runner_train_mujoco] Average state value: 0.47510633740822483
[2022-12-07 04:28:14,064] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 04:28:14,115] [INFO] [controller] EPOCH 1 loss ppo:  -0.01504, loss val: 0.03751
[2022-12-07 04:28:14,164] [INFO] [controller] EPOCH 2 loss ppo:  -0.02670, loss val: 0.03755
[2022-12-07 04:28:14,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.02949, loss val: 0.03705
[2022-12-07 04:28:14,258] [INFO] [controller] EPOCH 4 loss ppo:  -0.03880, loss val: 0.03570
[2022-12-07 04:28:14,268] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:28:14,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:28:14,414] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:28:18,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:28:22,307] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:28:26,446] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:28:30,345] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:28:34,269] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:28:38,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:28:42,349] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:28:46,192] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:28:49,998] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:28:54,038] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9799410761395126
[2022-12-07 04:28:54,038] [INFO] [runner_train_mujoco] Average state value: 0.4430562573472659
[2022-12-07 04:28:54,039] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 04:28:54,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.04302
[2022-12-07 04:28:54,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.02461, loss val: 0.04231
[2022-12-07 04:28:54,174] [INFO] [controller] EPOCH 3 loss ppo:  -0.03500, loss val: 0.04101
[2022-12-07 04:28:54,218] [INFO] [controller] EPOCH 4 loss ppo:  -0.03795, loss val: 0.04396
[2022-12-07 04:28:54,227] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:28:54,383] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:28:54,383] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:28:58,195] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:29:02,071] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:29:06,157] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:29:10,071] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:29:14,176] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:29:18,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:29:21,602] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:29:25,674] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:29:29,721] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:29:33,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.507424586647386
[2022-12-07 04:29:33,534] [INFO] [runner_train_mujoco] Average state value: 0.39953976931174595
[2022-12-07 04:29:33,534] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 04:29:33,588] [INFO] [controller] EPOCH 1 loss ppo:  -0.01553, loss val: 0.04225
[2022-12-07 04:29:33,635] [INFO] [controller] EPOCH 2 loss ppo:  -0.02905, loss val: 0.04161
[2022-12-07 04:29:33,685] [INFO] [controller] EPOCH 3 loss ppo:  -0.02976, loss val: 0.04079
[2022-12-07 04:29:33,736] [INFO] [controller] EPOCH 4 loss ppo:  -0.03920, loss val: 0.03981
[2022-12-07 04:29:33,747] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:29:33,913] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:29:33,913] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:29:37,769] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:29:41,564] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:29:45,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:29:49,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:29:53,932] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:29:57,750] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:30:01,525] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:30:05,362] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:30:09,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:30:12,750] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.737377881805905
[2022-12-07 04:30:12,750] [INFO] [runner_train_mujoco] Average state value: 0.42680230859915413
[2022-12-07 04:30:12,750] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 04:30:12,803] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.03254
[2022-12-07 04:30:12,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.02765, loss val: 0.03317
[2022-12-07 04:30:12,887] [INFO] [controller] EPOCH 3 loss ppo:  -0.03688, loss val: 0.03246
[2022-12-07 04:30:12,932] [INFO] [controller] EPOCH 4 loss ppo:  -0.04046, loss val: 0.03101
[2022-12-07 04:30:12,941] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:30:13,101] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:30:13,101] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:30:16,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:30:20,393] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:30:23,799] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:30:27,424] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:30:30,625] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:30:34,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:30:37,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:30:41,343] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:30:44,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:30:48,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4055770401519205
[2022-12-07 04:30:48,028] [INFO] [runner_train_mujoco] Average state value: 0.40581781389315924
[2022-12-07 04:30:48,028] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 04:30:48,075] [INFO] [controller] EPOCH 1 loss ppo:  -0.01537, loss val: 0.04151
[2022-12-07 04:30:48,118] [INFO] [controller] EPOCH 2 loss ppo:  -0.03153, loss val: 0.04176
[2022-12-07 04:30:48,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.03567, loss val: 0.04231
[2022-12-07 04:30:48,195] [INFO] [controller] EPOCH 4 loss ppo:  -0.04187, loss val: 0.04213
[2022-12-07 04:30:48,204] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:30:48,347] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:30:48,347] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:30:51,772] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:30:54,932] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:30:58,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:31:02,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:31:05,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:31:09,174] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:31:12,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:31:16,028] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:31:19,524] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:31:23,120] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.594851471112657
[2022-12-07 04:31:23,120] [INFO] [runner_train_mujoco] Average state value: 0.3915089576641719
[2022-12-07 04:31:23,121] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 04:31:23,177] [INFO] [controller] EPOCH 1 loss ppo:  -0.01554, loss val: 0.05913
[2022-12-07 04:31:23,213] [INFO] [controller] EPOCH 2 loss ppo:  -0.02492, loss val: 0.05720
[2022-12-07 04:31:23,248] [INFO] [controller] EPOCH 3 loss ppo:  -0.03067, loss val: 0.05444
[2022-12-07 04:31:23,284] [INFO] [controller] EPOCH 4 loss ppo:  -0.03682, loss val: 0.05303
[2022-12-07 04:31:23,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:31:23,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:31:23,440] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:31:26,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:31:30,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:31:34,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:31:37,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:31:40,891] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:31:44,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:31:47,641] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:31:51,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:31:54,714] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:31:58,035] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.904016102772156
[2022-12-07 04:31:58,035] [INFO] [runner_train_mujoco] Average state value: 0.4537832073569298
[2022-12-07 04:31:58,035] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 04:31:58,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.04371
[2022-12-07 04:31:58,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.02237, loss val: 0.04625
[2022-12-07 04:31:58,172] [INFO] [controller] EPOCH 3 loss ppo:  -0.02810, loss val: 0.04655
[2022-12-07 04:31:58,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.03406, loss val: 0.04511
[2022-12-07 04:31:58,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:31:58,377] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:31:58,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:32:01,946] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:32:05,272] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:32:08,757] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:32:12,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:32:16,020] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:32:19,475] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:32:22,911] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:32:26,215] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:32:29,490] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:32:32,844] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9709023711626115
[2022-12-07 04:32:32,844] [INFO] [runner_train_mujoco] Average state value: 0.45767282877365745
[2022-12-07 04:32:32,844] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 04:32:32,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.04138
[2022-12-07 04:32:32,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.02415, loss val: 0.04092
[2022-12-07 04:32:32,963] [INFO] [controller] EPOCH 3 loss ppo:  -0.02649, loss val: 0.04016
[2022-12-07 04:32:33,004] [INFO] [controller] EPOCH 4 loss ppo:  -0.03305, loss val: 0.04052
[2022-12-07 04:32:33,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:32:33,155] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:32:33,155] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:32:36,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:32:39,959] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:32:43,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:32:46,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:32:50,315] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:32:53,551] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:32:56,783] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:33:00,321] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:33:03,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:33:07,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.892754973096926
[2022-12-07 04:33:07,371] [INFO] [runner_train_mujoco] Average state value: 0.4208136243224144
[2022-12-07 04:33:07,371] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 04:33:07,422] [INFO] [controller] EPOCH 1 loss ppo:  -0.01623, loss val: 0.04885
[2022-12-07 04:33:07,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.02399, loss val: 0.04979
[2022-12-07 04:33:07,501] [INFO] [controller] EPOCH 3 loss ppo:  -0.02832, loss val: 0.04851
[2022-12-07 04:33:07,544] [INFO] [controller] EPOCH 4 loss ppo:  -0.03748, loss val: 0.04662
[2022-12-07 04:33:07,552] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:33:07,695] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:33:07,695] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:33:11,313] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:33:14,996] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:33:18,505] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:33:21,719] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:33:24,963] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:33:28,566] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:33:31,699] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:33:35,254] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:33:38,567] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:33:41,617] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.027277810483353
[2022-12-07 04:33:41,617] [INFO] [runner_train_mujoco] Average state value: 0.44227047745386755
[2022-12-07 04:33:41,617] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 04:33:41,665] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04532
[2022-12-07 04:33:41,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.02454, loss val: 0.04625
[2022-12-07 04:33:41,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.02274, loss val: 0.04629
[2022-12-07 04:33:41,796] [INFO] [controller] EPOCH 4 loss ppo:  -0.03088, loss val: 0.04534
[2022-12-07 04:33:41,805] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:33:41,944] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:33:41,945] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:33:45,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:33:48,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:33:52,306] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:33:55,629] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:33:58,802] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:34:02,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:34:05,703] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:34:08,820] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:34:12,400] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:34:15,982] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.246837687249778
[2022-12-07 04:34:15,982] [INFO] [runner_train_mujoco] Average state value: 0.44763946964343393
[2022-12-07 04:34:15,983] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 04:34:16,029] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04505
[2022-12-07 04:34:16,071] [INFO] [controller] EPOCH 2 loss ppo:  -0.01728, loss val: 0.04365
[2022-12-07 04:34:16,113] [INFO] [controller] EPOCH 3 loss ppo:  -0.02466, loss val: 0.04297
[2022-12-07 04:34:16,157] [INFO] [controller] EPOCH 4 loss ppo:  -0.03295, loss val: 0.04416
[2022-12-07 04:34:16,165] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:34:16,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:34:16,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:34:19,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:34:23,545] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:34:27,127] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:34:30,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:34:33,882] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:34:37,285] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:34:40,758] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:34:44,301] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:34:47,647] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:34:50,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.22736534025814
[2022-12-07 04:34:50,914] [INFO] [runner_train_mujoco] Average state value: 0.4102704706986745
[2022-12-07 04:34:50,914] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 04:34:50,970] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04659
[2022-12-07 04:34:51,019] [INFO] [controller] EPOCH 2 loss ppo:  -0.02312, loss val: 0.04541
[2022-12-07 04:34:51,065] [INFO] [controller] EPOCH 3 loss ppo:  -0.02683, loss val: 0.04509
[2022-12-07 04:34:51,112] [INFO] [controller] EPOCH 4 loss ppo:  -0.03605, loss val: 0.04593
[2022-12-07 04:34:51,122] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:34:51,263] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:34:51,264] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:34:54,688] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:34:57,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:35:01,299] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:35:04,819] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:35:08,025] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:35:11,213] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:35:14,501] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:35:17,979] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:35:21,393] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:35:24,699] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.239881397824631
[2022-12-07 04:35:24,700] [INFO] [runner_train_mujoco] Average state value: 0.37327758374810216
[2022-12-07 04:35:24,700] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 04:35:24,745] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04184
[2022-12-07 04:35:24,789] [INFO] [controller] EPOCH 2 loss ppo:  -0.02244, loss val: 0.04203
[2022-12-07 04:35:24,829] [INFO] [controller] EPOCH 3 loss ppo:  -0.02735, loss val: 0.04287
[2022-12-07 04:35:24,868] [INFO] [controller] EPOCH 4 loss ppo:  -0.03247, loss val: 0.03977
[2022-12-07 04:35:24,877] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:35:25,024] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:35:25,025] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:35:28,447] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:35:32,000] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:35:35,658] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:35:39,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:35:42,352] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:35:45,980] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:35:49,336] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:35:52,665] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:35:55,843] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:35:59,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.432168714513833
[2022-12-07 04:35:59,304] [INFO] [runner_train_mujoco] Average state value: 0.39477062747875846
[2022-12-07 04:35:59,304] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 04:35:59,355] [INFO] [controller] EPOCH 1 loss ppo:  -0.01100, loss val: 0.04470
[2022-12-07 04:35:59,398] [INFO] [controller] EPOCH 2 loss ppo:  -0.01717, loss val: 0.04369
[2022-12-07 04:35:59,441] [INFO] [controller] EPOCH 3 loss ppo:  -0.02175, loss val: 0.04504
[2022-12-07 04:35:59,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.02734, loss val: 0.04233
[2022-12-07 04:35:59,494] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:35:59,643] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:35:59,643] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:36:03,281] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:36:06,516] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:36:10,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:36:13,334] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:36:16,732] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:36:20,147] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:36:23,322] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:36:26,715] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:36:30,404] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:36:34,034] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.488868101175384
[2022-12-07 04:36:34,034] [INFO] [runner_train_mujoco] Average state value: 0.44877741198738413
[2022-12-07 04:36:34,035] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 04:36:34,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04497
[2022-12-07 04:36:34,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.02108, loss val: 0.04449
[2022-12-07 04:36:34,172] [INFO] [controller] EPOCH 3 loss ppo:  -0.02682, loss val: 0.04554
[2022-12-07 04:36:34,213] [INFO] [controller] EPOCH 4 loss ppo:  -0.03241, loss val: 0.04671
[2022-12-07 04:36:34,222] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:36:34,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:36:34,370] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:36:37,862] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:36:41,430] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:36:44,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:36:48,177] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:36:51,364] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:36:54,577] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:36:57,928] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:37:01,231] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:37:04,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:37:07,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.594838490331037
[2022-12-07 04:37:07,923] [INFO] [runner_train_mujoco] Average state value: 0.46044777283072474
[2022-12-07 04:37:07,923] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 04:37:07,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01208, loss val: 0.05167
[2022-12-07 04:37:08,012] [INFO] [controller] EPOCH 2 loss ppo:  -0.01833, loss val: 0.05052
[2022-12-07 04:37:08,052] [INFO] [controller] EPOCH 3 loss ppo:  -0.02433, loss val: 0.05029
[2022-12-07 04:37:08,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.02954, loss val: 0.04971
[2022-12-07 04:37:08,102] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:37:08,245] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:37:08,245] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:37:11,524] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:37:14,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:37:18,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:37:21,865] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:37:24,961] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:37:28,370] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:37:31,903] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:37:34,994] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:37:38,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:37:41,756] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.606049551566448
[2022-12-07 04:37:41,756] [INFO] [runner_train_mujoco] Average state value: 0.43689606575171147
[2022-12-07 04:37:41,756] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 04:37:41,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01237, loss val: 0.04864
[2022-12-07 04:37:41,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.01866, loss val: 0.04846
[2022-12-07 04:37:41,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.02314, loss val: 0.04884
[2022-12-07 04:37:41,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.02595, loss val: 0.04710
[2022-12-07 04:37:41,935] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:37:42,081] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:37:42,081] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:37:45,342] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:37:48,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:37:51,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:37:54,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:37:58,150] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:38:01,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:38:04,715] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:38:08,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:38:11,718] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:38:14,879] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.596946725626313
[2022-12-07 04:38:14,879] [INFO] [runner_train_mujoco] Average state value: 0.4266624421676
[2022-12-07 04:38:14,879] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 04:38:14,926] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.05929
[2022-12-07 04:38:14,965] [INFO] [controller] EPOCH 2 loss ppo:  -0.01779, loss val: 0.05899
[2022-12-07 04:38:15,010] [INFO] [controller] EPOCH 3 loss ppo:  -0.02610, loss val: 0.06023
[2022-12-07 04:38:15,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.02979, loss val: 0.05894
[2022-12-07 04:38:15,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:38:15,233] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:38:15,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:38:18,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:38:22,212] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:38:25,525] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:38:28,844] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:38:32,223] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:38:35,751] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:38:38,806] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:38:41,923] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:38:45,508] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:38:48,598] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.724212669563974
[2022-12-07 04:38:48,599] [INFO] [runner_train_mujoco] Average state value: 0.4359967176914215
[2022-12-07 04:38:48,599] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 04:38:48,648] [INFO] [controller] EPOCH 1 loss ppo:  -0.00987, loss val: 0.04638
[2022-12-07 04:38:48,685] [INFO] [controller] EPOCH 2 loss ppo:  -0.01431, loss val: 0.04492
[2022-12-07 04:38:48,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.01937, loss val: 0.04432
[2022-12-07 04:38:48,760] [INFO] [controller] EPOCH 4 loss ppo:  -0.02248, loss val: 0.04108
[2022-12-07 04:38:48,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:38:48,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:38:48,894] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:38:52,325] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:38:55,395] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:38:58,781] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:39:02,253] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:39:05,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:39:09,182] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:39:12,350] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:39:15,432] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:39:18,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:39:21,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.843486362158134
[2022-12-07 04:39:21,836] [INFO] [runner_train_mujoco] Average state value: 0.46913240089019137
[2022-12-07 04:39:21,836] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 04:39:21,896] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.04244
[2022-12-07 04:39:21,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.01153, loss val: 0.04703
[2022-12-07 04:39:21,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.01323, loss val: 0.04940
[2022-12-07 04:39:22,019] [INFO] [controller] EPOCH 4 loss ppo:  -0.02281, loss val: 0.04785
[2022-12-07 04:39:22,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:39:22,166] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:39:22,166] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:39:25,406] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:39:28,728] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:39:31,948] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:39:35,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:39:38,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:39:42,057] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:39:45,246] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:39:48,419] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:39:51,817] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:39:54,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.732511067298509
[2022-12-07 04:39:54,931] [INFO] [runner_train_mujoco] Average state value: 0.4888311102787653
[2022-12-07 04:39:54,931] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 04:39:54,978] [INFO] [controller] EPOCH 1 loss ppo:  -0.01063, loss val: 0.04491
[2022-12-07 04:39:55,016] [INFO] [controller] EPOCH 2 loss ppo:  -0.02051, loss val: 0.04189
[2022-12-07 04:39:55,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.02352, loss val: 0.04267
[2022-12-07 04:39:55,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.02880, loss val: 0.04147
[2022-12-07 04:39:55,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:39:55,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:39:55,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:39:58,896] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:40:02,322] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:40:05,619] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:40:09,137] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:40:12,726] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:40:15,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:40:19,268] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:40:22,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:40:25,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:40:28,802] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.899498700636462
[2022-12-07 04:40:28,802] [INFO] [runner_train_mujoco] Average state value: 0.47751295785109205
[2022-12-07 04:40:28,802] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 04:40:28,849] [INFO] [controller] EPOCH 1 loss ppo:  -0.01195, loss val: 0.04530
[2022-12-07 04:40:28,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.01623, loss val: 0.04764
[2022-12-07 04:40:28,926] [INFO] [controller] EPOCH 3 loss ppo:  -0.01966, loss val: 0.04711
[2022-12-07 04:40:28,966] [INFO] [controller] EPOCH 4 loss ppo:  -0.02303, loss val: 0.04944
[2022-12-07 04:40:28,975] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:40:29,119] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:40:29,119] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:40:32,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:40:35,468] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:40:39,000] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:40:42,782] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:40:45,957] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:40:49,052] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:40:52,123] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:40:55,504] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:40:58,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:41:02,210] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.140904795419976
[2022-12-07 04:41:02,211] [INFO] [runner_train_mujoco] Average state value: 0.45366522363821665
[2022-12-07 04:41:02,211] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 04:41:02,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04765
[2022-12-07 04:41:02,293] [INFO] [controller] EPOCH 2 loss ppo:  -0.01361, loss val: 0.04545
[2022-12-07 04:41:02,336] [INFO] [controller] EPOCH 3 loss ppo:  -0.01774, loss val: 0.04679
[2022-12-07 04:41:02,376] [INFO] [controller] EPOCH 4 loss ppo:  -0.02272, loss val: 0.04581
[2022-12-07 04:41:02,386] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:41:02,555] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:41:02,556] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:41:05,777] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:41:09,281] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:41:12,735] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:41:15,979] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:41:19,507] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:41:22,730] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:41:25,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:41:29,172] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:41:32,409] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:41:35,743] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.12348754713152
[2022-12-07 04:41:35,743] [INFO] [runner_train_mujoco] Average state value: 0.4243391891717911
[2022-12-07 04:41:35,743] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 04:41:35,788] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.04495
[2022-12-07 04:41:35,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.01950, loss val: 0.04793
[2022-12-07 04:41:35,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.01820, loss val: 0.04383
[2022-12-07 04:41:35,907] [INFO] [controller] EPOCH 4 loss ppo:  -0.02664, loss val: 0.04327
[2022-12-07 04:41:35,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:41:36,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:41:36,057] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:41:39,366] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:41:42,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:41:46,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:41:49,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:41:52,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:41:56,386] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:41:59,552] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:42:02,759] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:42:06,239] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:42:09,356] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.9017304382072595
[2022-12-07 04:42:09,356] [INFO] [runner_train_mujoco] Average state value: 0.39388772018750506
[2022-12-07 04:42:09,356] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 04:42:09,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.05015
[2022-12-07 04:42:09,454] [INFO] [controller] EPOCH 2 loss ppo:  -0.01486, loss val: 0.05013
[2022-12-07 04:42:09,491] [INFO] [controller] EPOCH 3 loss ppo:  -0.01715, loss val: 0.04978
[2022-12-07 04:42:09,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.02127, loss val: 0.04854
[2022-12-07 04:42:09,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:42:09,700] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:42:09,700] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:42:12,833] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:42:16,256] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:42:19,630] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:42:22,955] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:42:26,519] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:42:29,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:42:33,378] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:42:36,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:42:39,841] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:42:42,915] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0789700895041765
[2022-12-07 04:42:42,916] [INFO] [runner_train_mujoco] Average state value: 0.4061791550517082
[2022-12-07 04:42:42,916] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 04:42:42,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01160, loss val: 0.05082
[2022-12-07 04:42:43,005] [INFO] [controller] EPOCH 2 loss ppo:  -0.01638, loss val: 0.05159
[2022-12-07 04:42:43,041] [INFO] [controller] EPOCH 3 loss ppo:  -0.01718, loss val: 0.05164
[2022-12-07 04:42:43,074] [INFO] [controller] EPOCH 4 loss ppo:  -0.02450, loss val: 0.05238
[2022-12-07 04:42:43,081] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:42:43,231] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:42:43,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:42:46,614] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:42:50,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:42:53,158] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:42:56,512] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:42:59,570] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:43:02,739] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:43:05,839] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:43:09,593] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:43:14,879] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:43:19,203] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.130639596978951
[2022-12-07 04:43:19,205] [INFO] [runner_train_mujoco] Average state value: 0.4187685053050518
[2022-12-07 04:43:19,205] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 04:43:19,294] [INFO] [controller] EPOCH 1 loss ppo:  -0.01057, loss val: 0.04072
[2022-12-07 04:43:19,377] [INFO] [controller] EPOCH 2 loss ppo:  -0.01177, loss val: 0.04261
[2022-12-07 04:43:19,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.01967, loss val: 0.04221
[2022-12-07 04:43:19,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.02783, loss val: 0.04091
[2022-12-07 04:43:19,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:43:19,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:43:19,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:43:24,546] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:43:28,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:43:31,852] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:43:35,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:43:39,672] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:43:44,415] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:43:48,157] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:43:51,680] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:43:55,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:43:58,766] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.205469022899763
[2022-12-07 04:43:58,767] [INFO] [runner_train_mujoco] Average state value: 0.41699514881769817
[2022-12-07 04:43:58,767] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 04:43:58,821] [INFO] [controller] EPOCH 1 loss ppo:  -0.01170, loss val: 0.05136
[2022-12-07 04:43:58,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.01658, loss val: 0.05158
[2022-12-07 04:43:58,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.01646, loss val: 0.05147
[2022-12-07 04:43:58,960] [INFO] [controller] EPOCH 4 loss ppo:  -0.02027, loss val: 0.05139
[2022-12-07 04:43:58,970] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:43:59,129] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:43:59,129] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:44:02,565] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:44:05,991] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:44:09,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:44:13,720] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:44:17,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:44:21,253] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:44:25,115] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:44:28,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:44:32,484] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:44:35,964] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.166764426096838
[2022-12-07 04:44:35,965] [INFO] [runner_train_mujoco] Average state value: 0.41260140601793927
[2022-12-07 04:44:35,965] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 04:44:36,014] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.04597
[2022-12-07 04:44:36,055] [INFO] [controller] EPOCH 2 loss ppo:  -0.01384, loss val: 0.04673
[2022-12-07 04:44:36,104] [INFO] [controller] EPOCH 3 loss ppo:  -0.01558, loss val: 0.04584
[2022-12-07 04:44:36,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.02112, loss val: 0.04755
[2022-12-07 04:44:36,151] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:44:36,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:44:36,293] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:44:39,885] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:44:43,383] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:44:46,920] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:44:50,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:44:54,317] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:44:58,651] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:45:04,204] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:45:08,418] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:45:12,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:45:16,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.237650450419466
[2022-12-07 04:45:16,930] [INFO] [runner_train_mujoco] Average state value: 0.41908533155918126
[2022-12-07 04:45:16,930] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 04:45:16,988] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.03886
[2022-12-07 04:45:17,051] [INFO] [controller] EPOCH 2 loss ppo:  -0.01809, loss val: 0.03879
[2022-12-07 04:45:17,104] [INFO] [controller] EPOCH 3 loss ppo:  -0.01550, loss val: 0.03890
[2022-12-07 04:45:17,153] [INFO] [controller] EPOCH 4 loss ppo:  -0.02028, loss val: 0.03824
[2022-12-07 04:45:17,163] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:45:17,325] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:45:17,325] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:45:21,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:45:26,543] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:45:31,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:45:35,586] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:45:40,177] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:45:45,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:45:49,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:45:54,414] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:45:58,779] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:46:03,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.244338487537078
[2022-12-07 04:46:03,384] [INFO] [runner_train_mujoco] Average state value: 0.4177190654873848
[2022-12-07 04:46:03,385] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 04:46:03,472] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.05249
[2022-12-07 04:46:03,533] [INFO] [controller] EPOCH 2 loss ppo:  -0.01705, loss val: 0.05136
[2022-12-07 04:46:03,596] [INFO] [controller] EPOCH 3 loss ppo:  -0.01787, loss val: 0.05127
[2022-12-07 04:46:03,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.02427, loss val: 0.05111
[2022-12-07 04:46:03,656] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:46:03,821] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:46:03,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:46:08,391] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:46:12,881] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:46:17,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:46:22,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:46:26,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:46:31,239] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:46:35,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:46:40,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:46:45,198] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:46:49,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.28495238695595
[2022-12-07 04:46:49,703] [INFO] [runner_train_mujoco] Average state value: 0.4122942935725053
[2022-12-07 04:46:49,703] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 04:46:49,766] [INFO] [controller] EPOCH 1 loss ppo:  -0.01138, loss val: 0.04313
[2022-12-07 04:46:49,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.01173, loss val: 0.04370
[2022-12-07 04:46:49,883] [INFO] [controller] EPOCH 3 loss ppo:  -0.01131, loss val: 0.04360
[2022-12-07 04:46:49,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.01541, loss val: 0.04288
[2022-12-07 04:46:49,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:46:50,118] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:46:50,118] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:46:54,658] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:46:59,191] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:47:03,859] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:47:08,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:47:13,100] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:47:17,441] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:47:22,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:47:26,666] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:47:31,135] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:47:35,647] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.328917148060759
[2022-12-07 04:47:35,648] [INFO] [runner_train_mujoco] Average state value: 0.40042697489261625
[2022-12-07 04:47:35,648] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 04:47:35,770] [INFO] [controller] EPOCH 1 loss ppo:  -0.01025, loss val: 0.04216
[2022-12-07 04:47:35,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.01217, loss val: 0.04205
[2022-12-07 04:47:35,894] [INFO] [controller] EPOCH 3 loss ppo:  -0.01656, loss val: 0.04182
[2022-12-07 04:47:35,945] [INFO] [controller] EPOCH 4 loss ppo:  -0.02158, loss val: 0.04174
[2022-12-07 04:47:35,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:47:36,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:47:36,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:47:40,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:47:44,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:47:48,887] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:47:53,183] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:47:57,242] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:48:01,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:48:05,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:48:09,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:48:13,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:48:17,787] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.262656366572933
[2022-12-07 04:48:17,788] [INFO] [runner_train_mujoco] Average state value: 0.38793414473533633
[2022-12-07 04:48:17,788] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 04:48:17,851] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.04778
[2022-12-07 04:48:17,898] [INFO] [controller] EPOCH 2 loss ppo:  -0.01433, loss val: 0.04725
[2022-12-07 04:48:17,945] [INFO] [controller] EPOCH 3 loss ppo:  -0.01633, loss val: 0.04692
[2022-12-07 04:48:17,993] [INFO] [controller] EPOCH 4 loss ppo:  -0.01988, loss val: 0.04868
[2022-12-07 04:48:18,003] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:48:18,164] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:48:18,165] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:48:22,419] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:48:26,440] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:48:30,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:48:34,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:48:38,623] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:48:43,063] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:48:47,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:48:51,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:48:55,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:48:59,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.9478891094492905
[2022-12-07 04:48:59,310] [INFO] [runner_train_mujoco] Average state value: 0.3737049679656823
[2022-12-07 04:48:59,310] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 04:48:59,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01099, loss val: 0.05252
[2022-12-07 04:48:59,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.01263, loss val: 0.05181
[2022-12-07 04:48:59,480] [INFO] [controller] EPOCH 3 loss ppo:  -0.01228, loss val: 0.05269
[2022-12-07 04:48:59,529] [INFO] [controller] EPOCH 4 loss ppo:  -0.01265, loss val: 0.05190
[2022-12-07 04:48:59,540] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:48:59,706] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:48:59,706] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:49:04,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:49:08,233] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:49:12,197] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:49:16,418] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:49:20,288] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:49:24,340] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:49:28,243] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:49:32,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:49:36,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:49:40,385] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.377297203716346
[2022-12-07 04:49:40,386] [INFO] [runner_train_mujoco] Average state value: 0.37812373628218976
[2022-12-07 04:49:40,386] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 04:49:40,447] [INFO] [controller] EPOCH 1 loss ppo:  -0.01142, loss val: 0.04813
[2022-12-07 04:49:40,508] [INFO] [controller] EPOCH 2 loss ppo:  -0.01402, loss val: 0.04859
[2022-12-07 04:49:40,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.01695, loss val: 0.04759
[2022-12-07 04:49:40,605] [INFO] [controller] EPOCH 4 loss ppo:  -0.01687, loss val: 0.04756
[2022-12-07 04:49:40,616] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:49:40,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:49:40,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:49:44,982] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:49:49,109] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:49:53,060] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:49:57,158] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:50:01,494] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:50:05,764] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:09,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:50:13,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:50:17,259] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:50:21,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.3182122865943455
[2022-12-07 04:50:21,508] [INFO] [runner_train_mujoco] Average state value: 0.3850214780469735
[2022-12-07 04:50:21,508] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 04:50:21,569] [INFO] [controller] EPOCH 1 loss ppo:  -0.01095, loss val: 0.04896
[2022-12-07 04:50:21,626] [INFO] [controller] EPOCH 2 loss ppo:  -0.01338, loss val: 0.05015
[2022-12-07 04:50:21,700] [INFO] [controller] EPOCH 3 loss ppo:  -0.01626, loss val: 0.04895
[2022-12-07 04:50:21,758] [INFO] [controller] EPOCH 4 loss ppo:  -0.01841, loss val: 0.04963
[2022-12-07 04:50:21,770] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:50:21,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:50:21,938] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:50:26,189] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:50:30,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:50:33,846] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:50:37,835] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:50:41,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:50:45,674] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:49,713] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:50:53,948] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:50:58,222] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:51:02,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.5646067305001345
[2022-12-07 04:51:02,375] [INFO] [runner_train_mujoco] Average state value: 0.38339149216810864
[2022-12-07 04:51:02,375] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 04:51:02,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01133, loss val: 0.04843
[2022-12-07 04:51:02,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.01526, loss val: 0.04808
[2022-12-07 04:51:02,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.01918, loss val: 0.04827
[2022-12-07 04:51:02,604] [INFO] [controller] EPOCH 4 loss ppo:  -0.02033, loss val: 0.04831
[2022-12-07 04:51:02,613] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:51:02,776] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:51:02,777] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:51:07,069] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:51:11,183] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:51:15,493] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:51:19,697] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:51:24,114] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:51:28,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:51:32,249] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:51:36,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:51:40,260] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:51:44,467] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.325227421875207
[2022-12-07 04:51:44,467] [INFO] [runner_train_mujoco] Average state value: 0.37800434754292167
[2022-12-07 04:51:44,467] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 04:51:44,519] [INFO] [controller] EPOCH 1 loss ppo:  -0.01100, loss val: 0.04516
[2022-12-07 04:51:44,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.01208, loss val: 0.04480
[2022-12-07 04:51:44,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.01421, loss val: 0.04282
[2022-12-07 04:51:44,668] [INFO] [controller] EPOCH 4 loss ppo:  -0.01648, loss val: 0.04426
[2022-12-07 04:51:44,677] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:51:44,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:51:44,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:51:48,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:51:53,027] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:51:57,100] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:52:01,195] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:52:05,248] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:52:09,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:52:13,525] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:52:17,744] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:52:21,636] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:52:25,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.50793095772787
[2022-12-07 04:52:25,426] [INFO] [runner_train_mujoco] Average state value: 0.37490751554568613
[2022-12-07 04:52:25,427] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 04:52:25,494] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.04842
[2022-12-07 04:52:25,551] [INFO] [controller] EPOCH 2 loss ppo:  -0.01222, loss val: 0.04846
[2022-12-07 04:52:25,635] [INFO] [controller] EPOCH 3 loss ppo:  -0.01416, loss val: 0.05075
[2022-12-07 04:52:25,689] [INFO] [controller] EPOCH 4 loss ppo:  -0.01552, loss val: 0.05182
[2022-12-07 04:52:25,699] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:52:25,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:52:25,863] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:52:30,000] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:52:34,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:52:38,092] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:52:42,009] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:52:46,006] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:52:49,650] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:52:53,295] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:52:57,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:53:01,295] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:53:05,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.435424496630733
[2022-12-07 04:53:05,342] [INFO] [runner_train_mujoco] Average state value: 0.3741024105747541
[2022-12-07 04:53:05,342] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 04:53:05,398] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.03941
[2022-12-07 04:53:05,451] [INFO] [controller] EPOCH 2 loss ppo:  -0.01162, loss val: 0.03931
[2022-12-07 04:53:05,503] [INFO] [controller] EPOCH 3 loss ppo:  -0.01237, loss val: 0.03925
[2022-12-07 04:53:05,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.01327, loss val: 0.03940
[2022-12-07 04:53:05,574] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:53:05,706] [INFO] [optimize] Finished learning.
