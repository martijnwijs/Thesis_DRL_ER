[2022-12-07 08:08:12,196] [INFO] [optimize] Starting learning
[2022-12-07 08:08:12,205] [INFO] [optimize] Starting learning process..
[2022-12-07 08:08:12,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:08:12,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:08:17,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:08:21,715] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:08:25,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:08:30,111] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:08:34,490] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:08:38,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:08:42,863] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:08:47,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:08:50,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:08:55,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47181781718478
[2022-12-07 08:08:55,301] [INFO] [runner_train_mujoco] Average state value: -0.12845863174522915
[2022-12-07 08:08:55,301] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:08:55,362] [INFO] [controller] EPOCH 1 loss ppo:  -0.01646, loss val: 0.63716
[2022-12-07 08:08:55,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.02950, loss val: 0.56722
[2022-12-07 08:08:55,458] [INFO] [controller] EPOCH 3 loss ppo:  -0.03510, loss val: 0.51393
[2022-12-07 08:08:55,501] [INFO] [controller] EPOCH 4 loss ppo:  -0.03517, loss val: 0.46065
[2022-12-07 08:08:55,511] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:08:55,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:08:55,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:08:59,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:09:04,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:09:08,301] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:09:12,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:09:17,160] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:09:21,911] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:09:26,441] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:09:30,705] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:09:34,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:09:38,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5018527425816373
[2022-12-07 08:09:38,072] [INFO] [runner_train_mujoco] Average state value: 0.06350667409785092
[2022-12-07 08:09:38,072] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:09:38,127] [INFO] [controller] EPOCH 1 loss ppo:  -0.01547, loss val: 0.28889
[2022-12-07 08:09:38,173] [INFO] [controller] EPOCH 2 loss ppo:  -0.02781, loss val: 0.24998
[2022-12-07 08:09:38,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.03407, loss val: 0.21672
[2022-12-07 08:09:38,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.03758, loss val: 0.18679
[2022-12-07 08:09:38,275] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:09:38,430] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:09:38,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:09:42,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:09:46,529] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:09:50,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:09:54,680] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:09:58,786] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:10:02,906] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:10:06,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:10,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:10:15,148] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:10:19,092] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42630655754240765
[2022-12-07 08:10:19,093] [INFO] [runner_train_mujoco] Average state value: 0.19222978107507033
[2022-12-07 08:10:19,093] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:10:19,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.30972
[2022-12-07 08:10:19,210] [INFO] [controller] EPOCH 2 loss ppo:  -0.02305, loss val: 0.26903
[2022-12-07 08:10:19,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.02851, loss val: 0.23310
[2022-12-07 08:10:19,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.03097, loss val: 0.19356
[2022-12-07 08:10:19,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:10:19,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:10:19,484] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:10:23,815] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:10:28,207] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:10:32,191] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:10:36,222] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:10:40,066] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:10:44,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:10:48,233] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:52,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:10:55,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:10:59,798] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4595484859482684
[2022-12-07 08:10:59,798] [INFO] [runner_train_mujoco] Average state value: 0.36301640371419486
[2022-12-07 08:10:59,799] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:10:59,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.11442
[2022-12-07 08:10:59,904] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.09640
[2022-12-07 08:10:59,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.02594, loss val: 0.08370
[2022-12-07 08:11:00,001] [INFO] [controller] EPOCH 4 loss ppo:  -0.03367, loss val: 0.07276
[2022-12-07 08:11:00,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:00,174] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:00,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:11:04,120] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:11:08,505] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:11:12,961] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:11:17,352] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:11:21,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:11:25,940] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:11:30,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:11:33,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:11:37,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:11:41,763] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5122616893104854
[2022-12-07 08:11:41,764] [INFO] [runner_train_mujoco] Average state value: 0.502635029728214
[2022-12-07 08:11:41,764] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:11:41,819] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.07115
[2022-12-07 08:11:41,864] [INFO] [controller] EPOCH 2 loss ppo:  -0.02530, loss val: 0.06138
[2022-12-07 08:11:41,923] [INFO] [controller] EPOCH 3 loss ppo:  -0.02806, loss val: 0.05559
[2022-12-07 08:11:41,972] [INFO] [controller] EPOCH 4 loss ppo:  -0.03065, loss val: 0.05084
[2022-12-07 08:11:41,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:42,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:42,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:11:46,020] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:11:49,805] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:11:54,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:11:57,955] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:12:01,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:12:05,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:12:10,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:12:14,281] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:12:18,744] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:12:22,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6095347880486416
[2022-12-07 08:12:22,420] [INFO] [runner_train_mujoco] Average state value: 0.6123870661755403
[2022-12-07 08:12:22,420] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:12:22,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01176, loss val: 0.04745
[2022-12-07 08:12:22,516] [INFO] [controller] EPOCH 2 loss ppo:  -0.02184, loss val: 0.04764
[2022-12-07 08:12:22,561] [INFO] [controller] EPOCH 3 loss ppo:  -0.02405, loss val: 0.04523
[2022-12-07 08:12:22,605] [INFO] [controller] EPOCH 4 loss ppo:  -0.02778, loss val: 0.04273
[2022-12-07 08:12:22,614] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:12:22,762] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:12:22,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:12:26,986] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:12:31,039] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:12:35,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:12:39,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:12:43,244] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:12:47,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:12:51,078] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:12:55,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:12:58,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:13:03,134] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5923659842096652
[2022-12-07 08:13:03,135] [INFO] [runner_train_mujoco] Average state value: 0.6183098896344503
[2022-12-07 08:13:03,135] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:13:03,207] [INFO] [controller] EPOCH 1 loss ppo:  -0.00947, loss val: 0.03701
[2022-12-07 08:13:03,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.02119, loss val: 0.03594
[2022-12-07 08:13:03,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.02634, loss val: 0.03509
[2022-12-07 08:13:03,360] [INFO] [controller] EPOCH 4 loss ppo:  -0.03212, loss val: 0.03487
[2022-12-07 08:13:03,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:13:03,524] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:13:03,525] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:13:07,369] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:13:11,477] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:13:15,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:13:20,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:13:24,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:13:28,300] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:13:32,049] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:13:35,874] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:13:39,560] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:13:43,530] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6958006660990959
[2022-12-07 08:13:43,530] [INFO] [runner_train_mujoco] Average state value: 0.5937880532344184
[2022-12-07 08:13:43,530] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:13:43,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.00930, loss val: 0.02965
[2022-12-07 08:13:43,623] [INFO] [controller] EPOCH 2 loss ppo:  -0.01900, loss val: 0.02836
[2022-12-07 08:13:43,666] [INFO] [controller] EPOCH 3 loss ppo:  -0.02349, loss val: 0.02964
[2022-12-07 08:13:43,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.02945, loss val: 0.02896
[2022-12-07 08:13:43,722] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:13:43,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:13:43,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:13:48,090] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:13:51,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:13:56,249] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:00,192] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:14:04,328] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:14:08,506] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:14:12,374] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:14:16,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:14:20,364] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:14:24,226] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8351290123701469
[2022-12-07 08:14:24,227] [INFO] [runner_train_mujoco] Average state value: 0.5825838528474172
[2022-12-07 08:14:24,227] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:14:24,287] [INFO] [controller] EPOCH 1 loss ppo:  -0.01136, loss val: 0.03153
[2022-12-07 08:14:24,333] [INFO] [controller] EPOCH 2 loss ppo:  -0.02274, loss val: 0.03407
[2022-12-07 08:14:24,378] [INFO] [controller] EPOCH 3 loss ppo:  -0.02598, loss val: 0.03197
[2022-12-07 08:14:24,422] [INFO] [controller] EPOCH 4 loss ppo:  -0.03006, loss val: 0.03151
[2022-12-07 08:14:24,431] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:14:24,585] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:14:24,586] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:14:28,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:14:32,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:14:36,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:41,005] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:14:44,773] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:14:48,817] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:14:52,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:14:56,743] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:15:00,731] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:15:04,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8361917756071199
[2022-12-07 08:15:04,521] [INFO] [runner_train_mujoco] Average state value: 0.5827190480828286
[2022-12-07 08:15:04,521] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 08:15:04,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03987
[2022-12-07 08:15:04,630] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.03937
[2022-12-07 08:15:04,677] [INFO] [controller] EPOCH 3 loss ppo:  -0.02709, loss val: 0.04013
[2022-12-07 08:15:04,735] [INFO] [controller] EPOCH 4 loss ppo:  -0.03413, loss val: 0.03767
[2022-12-07 08:15:04,752] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:15:04,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:15:04,910] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:15:08,984] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:15:13,152] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:15:17,473] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:15:21,605] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:15:25,818] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:15:29,937] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:15:33,591] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:15:37,329] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:15:41,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:15:45,397] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8662807231728289
[2022-12-07 08:15:45,397] [INFO] [runner_train_mujoco] Average state value: 0.5469111420710882
[2022-12-07 08:15:45,397] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 08:15:45,448] [INFO] [controller] EPOCH 1 loss ppo:  -0.01084, loss val: 0.03783
[2022-12-07 08:15:45,490] [INFO] [controller] EPOCH 2 loss ppo:  -0.02509, loss val: 0.03662
[2022-12-07 08:15:45,534] [INFO] [controller] EPOCH 3 loss ppo:  -0.02889, loss val: 0.03577
[2022-12-07 08:15:45,575] [INFO] [controller] EPOCH 4 loss ppo:  -0.03170, loss val: 0.03553
[2022-12-07 08:15:45,584] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:15:45,729] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:15:45,730] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:15:50,040] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:15:54,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:15:58,552] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:16:02,109] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:16:06,200] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:10,024] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:13,699] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:16:17,550] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:16:21,863] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:16:25,797] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0436694198285381
[2022-12-07 08:16:25,797] [INFO] [runner_train_mujoco] Average state value: 0.48969163937369986
[2022-12-07 08:16:25,797] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 08:16:25,848] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04154
[2022-12-07 08:16:25,892] [INFO] [controller] EPOCH 2 loss ppo:  -0.02305, loss val: 0.04276
[2022-12-07 08:16:25,934] [INFO] [controller] EPOCH 3 loss ppo:  -0.03043, loss val: 0.04181
[2022-12-07 08:16:25,979] [INFO] [controller] EPOCH 4 loss ppo:  -0.03378, loss val: 0.04125
[2022-12-07 08:16:25,988] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:16:26,128] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:16:26,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:16:30,115] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:16:34,193] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:16:38,341] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:16:42,538] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:16:46,692] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:50,735] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:54,776] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:16:58,632] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:17:03,036] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:17:06,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.849027172416808
[2022-12-07 08:17:06,819] [INFO] [runner_train_mujoco] Average state value: 0.4919442714452743
[2022-12-07 08:17:06,819] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 08:17:06,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01879, loss val: 0.03521
[2022-12-07 08:17:06,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.02783, loss val: 0.03357
[2022-12-07 08:17:06,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.02653, loss val: 0.03631
[2022-12-07 08:17:06,995] [INFO] [controller] EPOCH 4 loss ppo:  -0.04006, loss val: 0.03356
[2022-12-07 08:17:07,004] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:17:07,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:17:07,158] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:17:11,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:17:15,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:17:19,110] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:17:23,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:17:26,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:17:30,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:17:34,804] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:17:38,749] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:17:42,355] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:17:46,187] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.317782228431679
[2022-12-07 08:17:46,187] [INFO] [runner_train_mujoco] Average state value: 0.4975832931399345
[2022-12-07 08:17:46,187] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 08:17:46,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.03593
[2022-12-07 08:17:46,320] [INFO] [controller] EPOCH 2 loss ppo:  -0.02877, loss val: 0.03502
[2022-12-07 08:17:46,363] [INFO] [controller] EPOCH 3 loss ppo:  -0.03340, loss val: 0.03715
[2022-12-07 08:17:46,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.04006, loss val: 0.03471
[2022-12-07 08:17:46,407] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:17:46,545] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:17:46,546] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:17:50,642] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:17:54,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:17:58,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:18:02,911] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:18:07,381] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:18:11,500] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:18:15,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:18:20,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:18:24,350] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:18:28,615] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7175187696357574
[2022-12-07 08:18:28,615] [INFO] [runner_train_mujoco] Average state value: 0.46460705522696183
[2022-12-07 08:18:28,615] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 08:18:28,667] [INFO] [controller] EPOCH 1 loss ppo:  -0.01627, loss val: 0.03673
[2022-12-07 08:18:28,710] [INFO] [controller] EPOCH 2 loss ppo:  -0.02949, loss val: 0.03883
[2022-12-07 08:18:28,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.03140, loss val: 0.03628
[2022-12-07 08:18:28,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.03706, loss val: 0.03604
[2022-12-07 08:18:28,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:18:29,019] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:18:29,019] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:18:32,812] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:18:36,814] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:18:40,767] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:18:44,456] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:18:48,269] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:18:52,032] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:18:55,617] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:18:59,478] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:19:03,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:07,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.560217349806986
[2022-12-07 08:19:07,026] [INFO] [runner_train_mujoco] Average state value: 0.43199348116914427
[2022-12-07 08:19:07,027] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 08:19:07,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.01956, loss val: 0.04770
[2022-12-07 08:19:07,120] [INFO] [controller] EPOCH 2 loss ppo:  -0.02509, loss val: 0.04774
[2022-12-07 08:19:07,160] [INFO] [controller] EPOCH 3 loss ppo:  -0.03238, loss val: 0.04794
[2022-12-07 08:19:07,202] [INFO] [controller] EPOCH 4 loss ppo:  -0.03203, loss val: 0.04848
[2022-12-07 08:19:07,211] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:07,359] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:07,359] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:11,347] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:19:15,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:19:19,286] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:19:23,541] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:19:27,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:19:31,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:19:35,195] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:19:39,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:19:43,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:47,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3156968003416694
[2022-12-07 08:19:47,371] [INFO] [runner_train_mujoco] Average state value: 0.4301170299053192
[2022-12-07 08:19:47,372] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 08:19:47,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01895, loss val: 0.04479
[2022-12-07 08:19:47,476] [INFO] [controller] EPOCH 2 loss ppo:  -0.02220, loss val: 0.04551
[2022-12-07 08:19:47,519] [INFO] [controller] EPOCH 3 loss ppo:  -0.03186, loss val: 0.04456
[2022-12-07 08:19:47,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.03860, loss val: 0.04451
[2022-12-07 08:19:47,576] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:47,744] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:47,744] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:51,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:19:55,461] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:19:59,464] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:20:03,614] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:20:07,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:20:10,853] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:20:14,567] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:20:18,256] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:20:21,942] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:20:25,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.678140960171524
[2022-12-07 08:20:25,626] [INFO] [runner_train_mujoco] Average state value: 0.4235758384565512
[2022-12-07 08:20:25,626] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 08:20:25,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04161
[2022-12-07 08:20:25,718] [INFO] [controller] EPOCH 2 loss ppo:  -0.02380, loss val: 0.04057
[2022-12-07 08:20:25,760] [INFO] [controller] EPOCH 3 loss ppo:  -0.02939, loss val: 0.03786
[2022-12-07 08:20:25,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.03450, loss val: 0.03721
[2022-12-07 08:20:25,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:20:25,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:20:25,965] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:20:29,748] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:20:33,352] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:20:37,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:20:41,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:20:45,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:20:49,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:20:53,288] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:20:57,132] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:21:01,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:21:05,350] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.883016832422058
[2022-12-07 08:21:05,351] [INFO] [runner_train_mujoco] Average state value: 0.47208599004149443
[2022-12-07 08:21:05,351] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 08:21:05,404] [INFO] [controller] EPOCH 1 loss ppo:  -0.01704, loss val: 0.04675
[2022-12-07 08:21:05,453] [INFO] [controller] EPOCH 2 loss ppo:  -0.02300, loss val: 0.04734
[2022-12-07 08:21:05,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.02834, loss val: 0.04718
[2022-12-07 08:21:05,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.03573, loss val: 0.04693
[2022-12-07 08:21:05,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:21:05,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:21:05,708] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:21:09,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:21:13,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:16,692] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:20,431] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:21:24,130] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:21:27,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:21:31,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:21:35,210] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:21:39,394] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:21:43,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.883448290263838
[2022-12-07 08:21:43,115] [INFO] [runner_train_mujoco] Average state value: 0.4993392512301605
[2022-12-07 08:21:43,115] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 08:21:43,166] [INFO] [controller] EPOCH 1 loss ppo:  -0.01568, loss val: 0.04488
[2022-12-07 08:21:43,225] [INFO] [controller] EPOCH 2 loss ppo:  -0.02326, loss val: 0.04512
[2022-12-07 08:21:43,271] [INFO] [controller] EPOCH 3 loss ppo:  -0.02864, loss val: 0.04326
[2022-12-07 08:21:43,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.03236, loss val: 0.04291
[2022-12-07 08:21:43,332] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:21:43,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:21:43,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:21:47,228] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:21:51,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:55,077] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:58,601] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:02,176] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:22:05,905] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:22:09,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:22:13,561] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:22:17,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:22:21,163] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7082830973181666
[2022-12-07 08:22:21,163] [INFO] [runner_train_mujoco] Average state value: 0.4761194469134013
[2022-12-07 08:22:21,163] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 08:22:21,214] [INFO] [controller] EPOCH 1 loss ppo:  -0.01551, loss val: 0.04436
[2022-12-07 08:22:21,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.02733, loss val: 0.04374
[2022-12-07 08:22:21,301] [INFO] [controller] EPOCH 3 loss ppo:  -0.03532, loss val: 0.04473
[2022-12-07 08:22:21,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.03749, loss val: 0.04332
[2022-12-07 08:22:21,355] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:22:21,505] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:22:21,506] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:22:25,469] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:22:29,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:22:33,453] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:22:37,371] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:40,959] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:22:44,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:22:48,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:22:52,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:22:56,046] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:22:59,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.827477952249801
[2022-12-07 08:22:59,371] [INFO] [runner_train_mujoco] Average state value: 0.4389033177097638
[2022-12-07 08:22:59,371] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 08:22:59,418] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04292
[2022-12-07 08:22:59,461] [INFO] [controller] EPOCH 2 loss ppo:  -0.02440, loss val: 0.04089
[2022-12-07 08:22:59,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.02819, loss val: 0.04111
[2022-12-07 08:22:59,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.03269, loss val: 0.04277
[2022-12-07 08:22:59,562] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:22:59,728] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:22:59,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:23:03,379] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:23:07,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:23:10,582] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:23:14,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:23:18,116] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:23:21,680] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:23:25,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:23:29,249] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:23:33,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:23:37,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.851913569741577
[2022-12-07 08:23:37,275] [INFO] [runner_train_mujoco] Average state value: 0.42729536296923953
[2022-12-07 08:23:37,275] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 08:23:37,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.01608, loss val: 0.03591
[2022-12-07 08:23:37,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.02184, loss val: 0.03564
[2022-12-07 08:23:37,416] [INFO] [controller] EPOCH 3 loss ppo:  -0.02638, loss val: 0.03402
[2022-12-07 08:23:37,463] [INFO] [controller] EPOCH 4 loss ppo:  -0.03434, loss val: 0.03333
[2022-12-07 08:23:37,473] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:23:37,639] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:23:37,639] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:23:41,375] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:23:45,295] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:23:49,313] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:23:53,071] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:23:56,653] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:24:00,115] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:24:04,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:07,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:24:11,505] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:24:15,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.054456816076724
[2022-12-07 08:24:15,118] [INFO] [runner_train_mujoco] Average state value: 0.4670551232496897
[2022-12-07 08:24:15,118] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 08:24:15,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04864
[2022-12-07 08:24:15,218] [INFO] [controller] EPOCH 2 loss ppo:  -0.02080, loss val: 0.04936
[2022-12-07 08:24:15,263] [INFO] [controller] EPOCH 3 loss ppo:  -0.02637, loss val: 0.05113
[2022-12-07 08:24:15,305] [INFO] [controller] EPOCH 4 loss ppo:  -0.03152, loss val: 0.05089
[2022-12-07 08:24:15,314] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:24:15,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:24:15,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:24:19,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:24:23,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:24:26,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:24:31,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:24:34,620] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:24:38,577] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:24:42,579] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:46,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:24:49,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:24:53,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.2333667159929345
[2022-12-07 08:24:53,480] [INFO] [runner_train_mujoco] Average state value: 0.4804859832127889
[2022-12-07 08:24:53,480] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 08:24:53,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01172, loss val: 0.04159
[2022-12-07 08:24:53,571] [INFO] [controller] EPOCH 2 loss ppo:  -0.01623, loss val: 0.04400
[2022-12-07 08:24:53,611] [INFO] [controller] EPOCH 3 loss ppo:  -0.02200, loss val: 0.04143
[2022-12-07 08:24:53,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.02243, loss val: 0.04087
[2022-12-07 08:24:53,660] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:24:53,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:24:53,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:24:57,404] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:25:01,233] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:25:05,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:25:08,909] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:25:12,469] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:15,840] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:25:19,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:25:23,480] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:25:27,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:25:30,694] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.179410568180643
[2022-12-07 08:25:30,694] [INFO] [runner_train_mujoco] Average state value: 0.48515294194221503
[2022-12-07 08:25:30,695] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 08:25:30,742] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.03608
[2022-12-07 08:25:30,783] [INFO] [controller] EPOCH 2 loss ppo:  -0.02209, loss val: 0.03598
[2022-12-07 08:25:30,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.03129, loss val: 0.03727
[2022-12-07 08:25:30,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.03681, loss val: 0.03699
[2022-12-07 08:25:30,879] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:25:31,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:25:31,032] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:25:34,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:25:38,471] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:25:41,939] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:25:45,919] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:25:49,745] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:53,346] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:25:57,054] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:26:00,673] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:26:04,241] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:26:08,103] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.526530989155175
[2022-12-07 08:26:08,103] [INFO] [runner_train_mujoco] Average state value: 0.4838744261463484
[2022-12-07 08:26:08,104] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 08:26:08,170] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.05567
[2022-12-07 08:26:08,216] [INFO] [controller] EPOCH 2 loss ppo:  -0.02326, loss val: 0.05532
[2022-12-07 08:26:08,274] [INFO] [controller] EPOCH 3 loss ppo:  -0.02693, loss val: 0.05416
[2022-12-07 08:26:08,333] [INFO] [controller] EPOCH 4 loss ppo:  -0.03547, loss val: 0.05244
[2022-12-07 08:26:08,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:26:08,504] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:26:08,505] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:11,931] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:26:15,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:26:19,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:26:23,304] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:26:26,909] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:26:30,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:26:34,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:26:38,186] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:26:41,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:26:45,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.498174595316725
[2022-12-07 08:26:45,778] [INFO] [runner_train_mujoco] Average state value: 0.44258929656942686
[2022-12-07 08:26:45,779] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 08:26:45,831] [INFO] [controller] EPOCH 1 loss ppo:  -0.01601, loss val: 0.03951
[2022-12-07 08:26:45,880] [INFO] [controller] EPOCH 2 loss ppo:  -0.01929, loss val: 0.04058
[2022-12-07 08:26:45,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.01950, loss val: 0.03962
[2022-12-07 08:26:45,974] [INFO] [controller] EPOCH 4 loss ppo:  -0.03069, loss val: 0.04146
[2022-12-07 08:26:45,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:26:46,136] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:26:46,137] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:49,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:26:53,834] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:26:57,700] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:27:01,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:27:05,260] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:27:08,720] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:27:12,365] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:27:15,806] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:27:19,592] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:27:23,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.524091097509663
[2022-12-07 08:27:23,508] [INFO] [runner_train_mujoco] Average state value: 0.4142448012332121
[2022-12-07 08:27:23,508] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 08:27:23,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01233, loss val: 0.04721
[2022-12-07 08:27:23,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.01948, loss val: 0.04612
[2022-12-07 08:27:23,662] [INFO] [controller] EPOCH 3 loss ppo:  -0.02762, loss val: 0.04519
[2022-12-07 08:27:23,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.03164, loss val: 0.04459
[2022-12-07 08:27:23,715] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:27:23,861] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:27:23,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:27:27,748] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:27:31,168] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:27:35,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:27:39,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:27:43,201] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:27:46,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:27:50,649] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:27:54,178] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:27:58,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:28:01,449] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.6454158285506
[2022-12-07 08:28:01,449] [INFO] [runner_train_mujoco] Average state value: 0.4420377077062924
[2022-12-07 08:28:01,450] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 08:28:01,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01171, loss val: 0.04362
[2022-12-07 08:28:01,539] [INFO] [controller] EPOCH 2 loss ppo:  -0.01728, loss val: 0.04248
[2022-12-07 08:28:01,580] [INFO] [controller] EPOCH 3 loss ppo:  -0.02271, loss val: 0.04306
[2022-12-07 08:28:01,620] [INFO] [controller] EPOCH 4 loss ppo:  -0.02819, loss val: 0.04302
[2022-12-07 08:28:01,630] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:28:01,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:28:01,773] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:28:05,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:28:08,642] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:28:12,443] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:28:16,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:28:19,801] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:28:23,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:28:27,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:28:30,797] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:28:34,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:28:38,225] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.73049198852348
[2022-12-07 08:28:38,225] [INFO] [runner_train_mujoco] Average state value: 0.4786906994779905
[2022-12-07 08:28:38,225] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 08:28:38,278] [INFO] [controller] EPOCH 1 loss ppo:  -0.01021, loss val: 0.04533
[2022-12-07 08:28:38,320] [INFO] [controller] EPOCH 2 loss ppo:  -0.01708, loss val: 0.04799
[2022-12-07 08:28:38,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.02557, loss val: 0.04528
[2022-12-07 08:28:38,407] [INFO] [controller] EPOCH 4 loss ppo:  -0.02793, loss val: 0.04665
[2022-12-07 08:28:38,417] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:28:38,577] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:28:38,578] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:28:42,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:28:46,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:28:49,957] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:28:53,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:28:57,644] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:01,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:29:04,750] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:29:08,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:29:12,127] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:29:15,770] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.75507888807016
[2022-12-07 08:29:15,770] [INFO] [runner_train_mujoco] Average state value: 0.49160681513945265
[2022-12-07 08:29:15,770] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 08:29:15,822] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.04105
[2022-12-07 08:29:15,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.02002, loss val: 0.04199
[2022-12-07 08:29:15,910] [INFO] [controller] EPOCH 3 loss ppo:  -0.02281, loss val: 0.04006
[2022-12-07 08:29:15,951] [INFO] [controller] EPOCH 4 loss ppo:  -0.02980, loss val: 0.04166
[2022-12-07 08:29:15,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:29:16,108] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:29:16,108] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:29:19,752] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:29:23,338] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:29:26,964] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:29:30,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:29:34,468] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:38,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:29:41,990] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:29:45,803] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:29:49,333] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:29:53,124] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.996030992155836
[2022-12-07 08:29:53,124] [INFO] [runner_train_mujoco] Average state value: 0.47795065063238146
[2022-12-07 08:29:53,125] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 08:29:53,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.05838
[2022-12-07 08:29:53,224] [INFO] [controller] EPOCH 2 loss ppo:  -0.02051, loss val: 0.05693
[2022-12-07 08:29:53,267] [INFO] [controller] EPOCH 3 loss ppo:  -0.02592, loss val: 0.05613
[2022-12-07 08:29:53,309] [INFO] [controller] EPOCH 4 loss ppo:  -0.02586, loss val: 0.05437
[2022-12-07 08:29:53,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:29:53,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:29:53,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:29:57,216] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:30:01,050] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:30:04,887] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:30:08,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:30:12,537] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:30:16,073] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:30:19,663] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:30:23,331] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:30:26,834] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:30:30,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.841618585597042
[2022-12-07 08:30:30,341] [INFO] [runner_train_mujoco] Average state value: 0.4293744417130947
[2022-12-07 08:30:30,341] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 08:30:30,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.04817
[2022-12-07 08:30:30,436] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.04864
[2022-12-07 08:30:30,479] [INFO] [controller] EPOCH 3 loss ppo:  -0.02380, loss val: 0.04939
[2022-12-07 08:30:30,535] [INFO] [controller] EPOCH 4 loss ppo:  -0.03161, loss val: 0.04907
[2022-12-07 08:30:30,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:30:30,694] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:30:30,694] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:30:34,480] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:30:38,436] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:30:42,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:30:45,704] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:30:49,334] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:30:52,922] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:30:56,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:30:59,783] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:03,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:06,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.993128063478387
[2022-12-07 08:31:06,913] [INFO] [runner_train_mujoco] Average state value: 0.41409156506260236
[2022-12-07 08:31:06,913] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 08:31:06,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.04633
[2022-12-07 08:31:07,010] [INFO] [controller] EPOCH 2 loss ppo:  -0.01786, loss val: 0.04386
[2022-12-07 08:31:07,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.02028, loss val: 0.04384
[2022-12-07 08:31:07,097] [INFO] [controller] EPOCH 4 loss ppo:  -0.02910, loss val: 0.04343
[2022-12-07 08:31:07,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:07,257] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:07,257] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:31:10,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:31:15,027] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:31:18,596] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:31:22,235] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:31:26,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:31:30,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:31:33,586] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:31:37,428] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:40,866] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:44,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.972051600614485
[2022-12-07 08:31:44,507] [INFO] [runner_train_mujoco] Average state value: 0.4026576361854871
[2022-12-07 08:31:44,507] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 08:31:44,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01070, loss val: 0.05295
[2022-12-07 08:31:44,615] [INFO] [controller] EPOCH 2 loss ppo:  -0.01596, loss val: 0.05358
[2022-12-07 08:31:44,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.02163, loss val: 0.05354
[2022-12-07 08:31:44,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.02513, loss val: 0.05343
[2022-12-07 08:31:44,715] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:44,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:44,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:31:48,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:31:52,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:31:56,323] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:31:59,938] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:32:03,397] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:32:07,317] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:32:10,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:32:14,426] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:32:18,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:32:21,698] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.900764986610883
[2022-12-07 08:32:21,698] [INFO] [runner_train_mujoco] Average state value: 0.4097057620982329
[2022-12-07 08:32:21,699] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 08:32:21,765] [INFO] [controller] EPOCH 1 loss ppo:  -0.01170, loss val: 0.04847
[2022-12-07 08:32:21,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.01646, loss val: 0.04915
[2022-12-07 08:32:21,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.01754, loss val: 0.04878
[2022-12-07 08:32:21,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.02653, loss val: 0.04821
[2022-12-07 08:32:21,900] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:32:22,049] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:32:22,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:32:25,467] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:32:29,247] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:32:32,950] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:32:36,873] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:32:40,218] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:32:43,517] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:32:47,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:32:50,938] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:32:54,644] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:32:58,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.848730799720295
[2022-12-07 08:32:58,404] [INFO] [runner_train_mujoco] Average state value: 0.40148639742533365
[2022-12-07 08:32:58,404] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 08:32:58,463] [INFO] [controller] EPOCH 1 loss ppo:  -0.01235, loss val: 0.04322
[2022-12-07 08:32:58,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.01891, loss val: 0.04198
[2022-12-07 08:32:58,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.02141, loss val: 0.04200
[2022-12-07 08:32:58,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.03052, loss val: 0.04190
[2022-12-07 08:32:58,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:32:58,770] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:32:58,771] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:02,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:33:06,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:33:10,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:33:13,672] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:33:17,234] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:33:20,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:33:24,336] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:33:27,966] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:33:31,484] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:33:34,879] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.976007632345623
[2022-12-07 08:33:34,879] [INFO] [runner_train_mujoco] Average state value: 0.3991108808815479
[2022-12-07 08:33:34,879] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 08:33:34,928] [INFO] [controller] EPOCH 1 loss ppo:  -0.01134, loss val: 0.04061
[2022-12-07 08:33:34,971] [INFO] [controller] EPOCH 2 loss ppo:  -0.01099, loss val: 0.04017
[2022-12-07 08:33:35,014] [INFO] [controller] EPOCH 3 loss ppo:  -0.01435, loss val: 0.04081
[2022-12-07 08:33:35,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.02094, loss val: 0.04066
[2022-12-07 08:33:35,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:33:35,219] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:33:35,220] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:39,009] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:33:42,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:33:46,353] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:33:50,230] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:33:54,136] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:33:57,899] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:34:01,641] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:34:05,167] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:34:08,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:34:11,866] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.9733835980283665
[2022-12-07 08:34:11,866] [INFO] [runner_train_mujoco] Average state value: 0.39824483737846217
[2022-12-07 08:34:11,866] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 08:34:11,919] [INFO] [controller] EPOCH 1 loss ppo:  -0.01073, loss val: 0.05559
[2022-12-07 08:34:11,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.01429, loss val: 0.05306
[2022-12-07 08:34:12,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.01651, loss val: 0.05070
[2022-12-07 08:34:12,057] [INFO] [controller] EPOCH 4 loss ppo:  -0.02229, loss val: 0.05008
[2022-12-07 08:34:12,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:34:12,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:34:12,220] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:34:15,720] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:19,166] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:34:23,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:34:26,645] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:34:30,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:34:34,025] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:34:37,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:34:41,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:34:45,142] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:34:49,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.049220557600187
[2022-12-07 08:34:49,113] [INFO] [runner_train_mujoco] Average state value: 0.43814991436402
[2022-12-07 08:34:49,113] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 08:34:49,172] [INFO] [controller] EPOCH 1 loss ppo:  -0.01041, loss val: 0.04445
[2022-12-07 08:34:49,217] [INFO] [controller] EPOCH 2 loss ppo:  -0.01683, loss val: 0.04157
[2022-12-07 08:34:49,260] [INFO] [controller] EPOCH 3 loss ppo:  -0.01809, loss val: 0.04462
[2022-12-07 08:34:49,302] [INFO] [controller] EPOCH 4 loss ppo:  -0.02430, loss val: 0.04523
[2022-12-07 08:34:49,312] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:34:49,460] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:34:49,461] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:34:53,327] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:57,183] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:35:00,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:04,549] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:35:07,921] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:35:11,624] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:35:15,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:35:19,003] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:35:23,040] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:35:26,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.160974567939419
[2022-12-07 08:35:26,542] [INFO] [runner_train_mujoco] Average state value: 0.4642027881741523
[2022-12-07 08:35:26,542] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 08:35:26,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.01173, loss val: 0.04833
[2022-12-07 08:35:26,649] [INFO] [controller] EPOCH 2 loss ppo:  -0.01677, loss val: 0.04873
[2022-12-07 08:35:26,692] [INFO] [controller] EPOCH 3 loss ppo:  -0.01684, loss val: 0.04766
[2022-12-07 08:35:26,745] [INFO] [controller] EPOCH 4 loss ppo:  -0.02369, loss val: 0.04824
[2022-12-07 08:35:26,754] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:35:26,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:35:26,905] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:35:30,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:35:33,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:35:37,762] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:41,707] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:35:45,508] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:35:49,058] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:35:52,796] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:35:56,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:36:00,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:36:03,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.147020472711828
[2022-12-07 08:36:03,833] [INFO] [runner_train_mujoco] Average state value: 0.4471867540677389
[2022-12-07 08:36:03,833] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 08:36:03,890] [INFO] [controller] EPOCH 1 loss ppo:  -0.00811, loss val: 0.04102
[2022-12-07 08:36:03,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.01190, loss val: 0.04357
[2022-12-07 08:36:03,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.01638, loss val: 0.04016
[2022-12-07 08:36:04,035] [INFO] [controller] EPOCH 4 loss ppo:  -0.02022, loss val: 0.03994
[2022-12-07 08:36:04,045] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:36:04,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:36:04,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:36:07,962] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:36:11,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:36:15,256] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:36:18,977] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:22,658] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:36:25,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:36:29,941] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:36:33,513] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:36:37,220] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:36:41,172] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.263327468169761
[2022-12-07 08:36:41,172] [INFO] [runner_train_mujoco] Average state value: 0.42159070849418645
[2022-12-07 08:36:41,172] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 08:36:41,224] [INFO] [controller] EPOCH 1 loss ppo:  -0.00898, loss val: 0.04963
[2022-12-07 08:36:41,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.01240, loss val: 0.04945
[2022-12-07 08:36:41,311] [INFO] [controller] EPOCH 3 loss ppo:  -0.01648, loss val: 0.05016
[2022-12-07 08:36:41,353] [INFO] [controller] EPOCH 4 loss ppo:  -0.02196, loss val: 0.04775
[2022-12-07 08:36:41,362] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:36:41,516] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:36:41,516] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:36:45,213] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:36:49,044] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:36:52,936] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:36:56,549] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:59,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:37:03,680] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:37:07,198] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:37:10,702] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:37:14,223] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:37:17,643] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.243877628006876
[2022-12-07 08:37:17,643] [INFO] [runner_train_mujoco] Average state value: 0.4123269039988518
[2022-12-07 08:37:17,643] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 08:37:17,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.01009, loss val: 0.04564
[2022-12-07 08:37:17,740] [INFO] [controller] EPOCH 2 loss ppo:  -0.01400, loss val: 0.04530
[2022-12-07 08:37:17,787] [INFO] [controller] EPOCH 3 loss ppo:  -0.02089, loss val: 0.04600
[2022-12-07 08:37:17,839] [INFO] [controller] EPOCH 4 loss ppo:  -0.02241, loss val: 0.04600
[2022-12-07 08:37:17,852] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:37:17,999] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:37:17,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:37:21,717] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:37:25,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:37:29,226] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:37:33,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:37:36,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:37:40,275] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:37:44,103] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:37:47,748] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:37:51,459] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:37:56,678] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.23110992341042
[2022-12-07 08:37:56,679] [INFO] [runner_train_mujoco] Average state value: 0.4205581464966138
[2022-12-07 08:37:56,679] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 08:37:56,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01097, loss val: 0.04548
[2022-12-07 08:37:56,813] [INFO] [controller] EPOCH 2 loss ppo:  -0.01757, loss val: 0.04830
[2022-12-07 08:37:56,868] [INFO] [controller] EPOCH 3 loss ppo:  -0.01801, loss val: 0.04797
[2022-12-07 08:37:56,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.02048, loss val: 0.04796
[2022-12-07 08:37:56,937] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:37:57,101] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:37:57,102] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:38:01,577] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:38:05,394] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:38:08,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:38:12,636] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:38:16,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:38:20,210] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:38:25,586] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:38:29,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:38:32,863] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:38:36,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.289068019945791
[2022-12-07 08:38:36,780] [INFO] [runner_train_mujoco] Average state value: 0.42863852659861246
[2022-12-07 08:38:36,780] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 08:38:36,830] [INFO] [controller] EPOCH 1 loss ppo:  -0.01042, loss val: 0.04868
[2022-12-07 08:38:36,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.01538, loss val: 0.04805
[2022-12-07 08:38:36,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.01653, loss val: 0.04789
[2022-12-07 08:38:36,959] [INFO] [controller] EPOCH 4 loss ppo:  -0.02224, loss val: 0.05066
[2022-12-07 08:38:36,968] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:38:37,107] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:38:37,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:38:40,657] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:38:44,006] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:38:47,402] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:38:52,301] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:38:56,280] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:39:00,294] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:39:04,070] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:39:08,019] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:39:11,563] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:39:15,167] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.212547247666409
[2022-12-07 08:39:15,168] [INFO] [runner_train_mujoco] Average state value: 0.43186543828248974
[2022-12-07 08:39:15,168] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 08:39:15,216] [INFO] [controller] EPOCH 1 loss ppo:  -0.00957, loss val: 0.04744
[2022-12-07 08:39:15,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.01396, loss val: 0.04570
[2022-12-07 08:39:15,300] [INFO] [controller] EPOCH 3 loss ppo:  -0.01691, loss val: 0.04619
[2022-12-07 08:39:15,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.01963, loss val: 0.04688
[2022-12-07 08:39:15,346] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:39:15,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:39:15,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:39:19,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:39:22,576] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:39:26,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:39:29,971] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:39:33,617] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:39:37,402] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:39:41,010] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:39:44,440] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:39:48,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:39:51,707] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.197200429980054
[2022-12-07 08:39:51,707] [INFO] [runner_train_mujoco] Average state value: 0.422087892651558
[2022-12-07 08:39:51,707] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 08:39:51,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01026, loss val: 0.04447
[2022-12-07 08:39:51,823] [INFO] [controller] EPOCH 2 loss ppo:  -0.01343, loss val: 0.04532
[2022-12-07 08:39:51,882] [INFO] [controller] EPOCH 3 loss ppo:  -0.01573, loss val: 0.04370
[2022-12-07 08:39:51,935] [INFO] [controller] EPOCH 4 loss ppo:  -0.02063, loss val: 0.04377
[2022-12-07 08:39:51,946] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:39:52,089] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:39:52,089] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:39:55,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:39:59,421] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:40:03,163] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:40:06,881] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:10,626] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:40:13,925] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:40:17,939] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:40:21,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:40:24,754] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:40:28,456] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.100673909150709
[2022-12-07 08:40:28,456] [INFO] [runner_train_mujoco] Average state value: 0.4226026509205501
[2022-12-07 08:40:28,457] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 08:40:28,524] [INFO] [controller] EPOCH 1 loss ppo:  -0.00933, loss val: 0.04633
[2022-12-07 08:40:28,570] [INFO] [controller] EPOCH 2 loss ppo:  -0.01320, loss val: 0.04617
[2022-12-07 08:40:28,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.01616, loss val: 0.04889
[2022-12-07 08:40:28,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.01828, loss val: 0.04804
[2022-12-07 08:40:28,664] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:40:28,817] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:40:28,818] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:40:32,623] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:40:36,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:40:40,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:40:43,436] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:46,836] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:40:50,328] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:40:53,868] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:40:57,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:41:00,957] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:41:04,430] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.2505381515980165
[2022-12-07 08:41:04,430] [INFO] [runner_train_mujoco] Average state value: 0.4287202924887339
[2022-12-07 08:41:04,430] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 08:41:04,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.00963, loss val: 0.04732
[2022-12-07 08:41:04,532] [INFO] [controller] EPOCH 2 loss ppo:  -0.01250, loss val: 0.04620
[2022-12-07 08:41:04,581] [INFO] [controller] EPOCH 3 loss ppo:  -0.01391, loss val: 0.04565
[2022-12-07 08:41:04,629] [INFO] [controller] EPOCH 4 loss ppo:  -0.01655, loss val: 0.04407
[2022-12-07 08:41:04,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:41:04,790] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:41:04,791] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:41:08,785] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:41:12,615] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:41:15,927] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:41:19,340] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:41:23,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:41:26,645] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:41:30,001] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:41:34,034] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:41:37,563] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:41:41,618] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.306707002512718
[2022-12-07 08:41:41,618] [INFO] [runner_train_mujoco] Average state value: 0.44433173682292304
[2022-12-07 08:41:41,618] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 08:41:41,696] [INFO] [controller] EPOCH 1 loss ppo:  -0.01052, loss val: 0.04271
[2022-12-07 08:41:41,759] [INFO] [controller] EPOCH 2 loss ppo:  -0.01497, loss val: 0.04284
[2022-12-07 08:41:41,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.01622, loss val: 0.04736
[2022-12-07 08:41:41,866] [INFO] [controller] EPOCH 4 loss ppo:  -0.02039, loss val: 0.04285
[2022-12-07 08:41:41,876] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:41:42,028] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:41:42,029] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:41:45,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:41:49,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:41:53,412] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:41:57,325] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:42:00,813] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:42:04,039] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:42:07,975] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:42:11,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:42:15,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:42:18,648] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.404865046715935
[2022-12-07 08:42:18,648] [INFO] [runner_train_mujoco] Average state value: 0.4557236298322677
[2022-12-07 08:42:18,648] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 08:42:18,697] [INFO] [controller] EPOCH 1 loss ppo:  -0.01085, loss val: 0.05388
[2022-12-07 08:42:18,736] [INFO] [controller] EPOCH 2 loss ppo:  -0.01466, loss val: 0.05457
[2022-12-07 08:42:18,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.01523, loss val: 0.05471
[2022-12-07 08:42:18,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.01737, loss val: 0.05418
[2022-12-07 08:42:18,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:42:18,947] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:42:18,947] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:42:22,690] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:42:26,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:42:30,263] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:42:33,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:42:37,412] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:42:41,023] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:42:44,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:42:48,322] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:42:51,925] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:42:55,559] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.36808904240418
[2022-12-07 08:42:55,560] [INFO] [runner_train_mujoco] Average state value: 0.4550444007317225
[2022-12-07 08:42:55,560] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 08:42:55,609] [INFO] [controller] EPOCH 1 loss ppo:  -0.01008, loss val: 0.05863
[2022-12-07 08:42:55,660] [INFO] [controller] EPOCH 2 loss ppo:  -0.01116, loss val: 0.05373
[2022-12-07 08:42:55,703] [INFO] [controller] EPOCH 3 loss ppo:  -0.01424, loss val: 0.05528
[2022-12-07 08:42:55,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.01736, loss val: 0.05389
[2022-12-07 08:42:55,755] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:42:55,906] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:42:55,907] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:42:59,705] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:43:03,281] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:43:06,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:43:10,528] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:43:14,107] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:43:18,120] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:43:22,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:43:26,015] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:43:29,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:43:33,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.216997669398721
[2022-12-07 08:43:33,371] [INFO] [runner_train_mujoco] Average state value: 0.441798016016682
[2022-12-07 08:43:33,371] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 08:43:33,433] [INFO] [controller] EPOCH 1 loss ppo:  -0.01061, loss val: 0.04561
[2022-12-07 08:43:33,485] [INFO] [controller] EPOCH 2 loss ppo:  -0.01260, loss val: 0.04622
[2022-12-07 08:43:33,532] [INFO] [controller] EPOCH 3 loss ppo:  -0.01406, loss val: 0.04619
[2022-12-07 08:43:33,579] [INFO] [controller] EPOCH 4 loss ppo:  -0.01435, loss val: 0.04551
[2022-12-07 08:43:33,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:43:33,750] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:43:33,750] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:43:37,274] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:43:40,676] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:43:44,338] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:43:47,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:43:51,092] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:43:54,598] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:43:58,098] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:44:02,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:44:05,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:44:09,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.50871699883565
[2022-12-07 08:44:09,426] [INFO] [runner_train_mujoco] Average state value: 0.4398327019115289
[2022-12-07 08:44:09,426] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 08:44:09,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01028, loss val: 0.03737
[2022-12-07 08:44:09,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.01250, loss val: 0.03724
[2022-12-07 08:44:09,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.01572, loss val: 0.03943
[2022-12-07 08:44:09,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.01934, loss val: 0.04024
[2022-12-07 08:44:09,619] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:44:09,764] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:44:09,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:44:13,430] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:44:17,217] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:44:20,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:44:24,444] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:44:27,992] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:44:31,385] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:44:35,583] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:44:39,198] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:44:42,586] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:44:46,027] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.659570935675056
[2022-12-07 08:44:46,027] [INFO] [runner_train_mujoco] Average state value: 0.44592093098163604
[2022-12-07 08:44:46,027] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 08:44:46,077] [INFO] [controller] EPOCH 1 loss ppo:  -0.01025, loss val: 0.05895
[2022-12-07 08:44:46,124] [INFO] [controller] EPOCH 2 loss ppo:  -0.01134, loss val: 0.05888
[2022-12-07 08:44:46,163] [INFO] [controller] EPOCH 3 loss ppo:  -0.01300, loss val: 0.05929
[2022-12-07 08:44:46,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.01580, loss val: 0.06324
[2022-12-07 08:44:46,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:44:46,422] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:44:46,423] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:44:49,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:44:53,497] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:44:56,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:45:00,390] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:45:03,790] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:45:06,964] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:45:10,536] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:45:14,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:45:17,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:45:21,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.423631595686825
[2022-12-07 08:45:21,703] [INFO] [runner_train_mujoco] Average state value: 0.4447324523131052
[2022-12-07 08:45:21,703] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 08:45:21,764] [INFO] [controller] EPOCH 1 loss ppo:  -0.01027, loss val: 0.04731
[2022-12-07 08:45:21,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.01127, loss val: 0.04729
[2022-12-07 08:45:21,856] [INFO] [controller] EPOCH 3 loss ppo:  -0.01265, loss val: 0.04667
[2022-12-07 08:45:21,903] [INFO] [controller] EPOCH 4 loss ppo:  -0.01453, loss val: 0.04638
[2022-12-07 08:45:21,913] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:45:22,060] [INFO] [optimize] Finished learning.
