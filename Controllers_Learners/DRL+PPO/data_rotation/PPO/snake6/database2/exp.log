[2022-12-06 15:56:48,814] [INFO] [optimize] Starting learning
[2022-12-06 15:56:48,822] [INFO] [optimize] Starting learning process..
[2022-12-06 15:56:48,900] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:56:48,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:56:56,843] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:57:02,216] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:57:08,597] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:57:13,323] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:57:18,632] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:57:23,474] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:57:28,221] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:57:32,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:57:36,428] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:57:40,465] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4724619844391718
[2022-12-06 15:57:40,465] [INFO] [runner_train_mujoco] Average state value: 0.166241824477911
[2022-12-06 15:57:40,466] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 15:57:40,526] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.27665
[2022-12-06 15:57:40,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.02897, loss val: 0.24522
[2022-12-06 15:57:40,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.03462, loss val: 0.21137
[2022-12-06 15:57:40,667] [INFO] [controller] EPOCH 4 loss ppo:  -0.03646, loss val: 0.17386
[2022-12-06 15:57:40,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:57:40,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:57:40,839] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:57:45,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:57:49,244] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:57:53,414] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:57:57,585] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:58:01,807] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:58:06,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:58:10,254] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:58:14,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:58:18,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:58:22,963] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41746551765893897
[2022-12-06 15:58:22,964] [INFO] [runner_train_mujoco] Average state value: 0.318296944282949
[2022-12-06 15:58:22,964] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 15:58:23,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01217, loss val: 0.15584
[2022-12-06 15:58:23,088] [INFO] [controller] EPOCH 2 loss ppo:  -0.02507, loss val: 0.13482
[2022-12-06 15:58:23,136] [INFO] [controller] EPOCH 3 loss ppo:  -0.03111, loss val: 0.11686
[2022-12-06 15:58:23,181] [INFO] [controller] EPOCH 4 loss ppo:  -0.03285, loss val: 0.10495
[2022-12-06 15:58:23,192] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:58:23,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:58:23,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:58:27,417] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:58:31,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:58:35,714] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:58:39,717] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:58:43,880] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:58:47,772] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:58:51,946] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:58:55,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:58:59,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:59:03,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40667591579905366
[2022-12-06 15:59:03,760] [INFO] [runner_train_mujoco] Average state value: 0.47019614398510506
[2022-12-06 15:59:03,760] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 15:59:03,813] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.11099
[2022-12-06 15:59:03,859] [INFO] [controller] EPOCH 2 loss ppo:  -0.02547, loss val: 0.09733
[2022-12-06 15:59:03,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.02885, loss val: 0.08737
[2022-12-06 15:59:03,949] [INFO] [controller] EPOCH 4 loss ppo:  -0.03358, loss val: 0.07903
[2022-12-06 15:59:03,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:59:04,125] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:59:04,126] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:59:08,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:59:12,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:59:16,783] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:59:21,126] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:59:25,591] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:59:30,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:59:34,682] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:59:38,579] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:59:42,561] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:59:46,809] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5398950129319408
[2022-12-06 15:59:46,809] [INFO] [runner_train_mujoco] Average state value: 0.5926908611624192
[2022-12-06 15:59:46,809] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 15:59:46,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.07218
[2022-12-06 15:59:46,909] [INFO] [controller] EPOCH 2 loss ppo:  -0.02042, loss val: 0.06307
[2022-12-06 15:59:46,953] [INFO] [controller] EPOCH 3 loss ppo:  -0.02540, loss val: 0.05851
[2022-12-06 15:59:46,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.02862, loss val: 0.05544
[2022-12-06 15:59:47,003] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:59:47,161] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 15:59:47,162] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 15:59:51,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 15:59:55,020] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:59:59,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:00:03,345] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:00:07,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:00:11,091] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:00:14,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:00:18,477] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:00:22,195] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:00:25,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5577295918031213
[2022-12-06 16:00:25,837] [INFO] [runner_train_mujoco] Average state value: 0.6147372841338317
[2022-12-06 16:00:25,837] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 16:00:25,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.01127, loss val: 0.05085
[2022-12-06 16:00:25,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.02338, loss val: 0.04875
[2022-12-06 16:00:25,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.03007, loss val: 0.04504
[2022-12-06 16:00:26,021] [INFO] [controller] EPOCH 4 loss ppo:  -0.03231, loss val: 0.04188
[2022-12-06 16:00:26,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:00:26,202] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:00:26,203] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:00:30,067] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:00:33,636] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:00:37,300] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:00:41,158] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:00:44,778] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:00:48,456] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:00:52,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:00:57,075] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:01:01,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:01:06,711] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6460137614775883
[2022-12-06 16:01:06,711] [INFO] [runner_train_mujoco] Average state value: 0.5848974266846975
[2022-12-06 16:01:06,712] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 16:01:06,774] [INFO] [controller] EPOCH 1 loss ppo:  -0.01011, loss val: 0.04216
[2022-12-06 16:01:06,851] [INFO] [controller] EPOCH 2 loss ppo:  -0.02225, loss val: 0.04150
[2022-12-06 16:01:06,908] [INFO] [controller] EPOCH 3 loss ppo:  -0.02623, loss val: 0.03535
[2022-12-06 16:01:06,964] [INFO] [controller] EPOCH 4 loss ppo:  -0.03121, loss val: 0.03290
[2022-12-06 16:01:06,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:01:07,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:01:07,148] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:01:11,607] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:01:15,923] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:01:20,112] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:01:24,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:01:28,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:01:32,506] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:01:36,454] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:01:40,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:01:45,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:01:49,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5474336399446428
[2022-12-06 16:01:49,124] [INFO] [runner_train_mujoco] Average state value: 0.517900723238786
[2022-12-06 16:01:49,124] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 16:01:49,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.00997, loss val: 0.04237
[2022-12-06 16:01:49,209] [INFO] [controller] EPOCH 2 loss ppo:  -0.02226, loss val: 0.04949
[2022-12-06 16:01:49,250] [INFO] [controller] EPOCH 3 loss ppo:  -0.02751, loss val: 0.04186
[2022-12-06 16:01:49,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.03030, loss val: 0.03999
[2022-12-06 16:01:49,302] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:01:49,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:01:49,483] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:01:53,858] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:01:58,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:02:02,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:02:06,613] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:02:10,511] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:02:14,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:02:18,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:02:22,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:02:28,668] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:02:35,494] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6732123238835126
[2022-12-06 16:02:35,495] [INFO] [runner_train_mujoco] Average state value: 0.5156323237816494
[2022-12-06 16:02:35,495] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 16:02:35,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01045, loss val: 0.04034
[2022-12-06 16:02:35,630] [INFO] [controller] EPOCH 2 loss ppo:  -0.02131, loss val: 0.03916
[2022-12-06 16:02:35,685] [INFO] [controller] EPOCH 3 loss ppo:  -0.02496, loss val: 0.03951
[2022-12-06 16:02:35,734] [INFO] [controller] EPOCH 4 loss ppo:  -0.02952, loss val: 0.03730
[2022-12-06 16:02:35,745] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:02:35,917] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:02:35,917] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:02:41,152] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:02:47,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:02:54,444] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:02:59,894] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:03:05,746] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:03:11,481] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:03:16,233] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:03:21,738] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:03:27,226] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:03:32,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7466848843711811
[2022-12-06 16:03:32,893] [INFO] [runner_train_mujoco] Average state value: 0.572546579539776
[2022-12-06 16:03:32,893] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 16:03:32,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01157, loss val: 0.03335
[2022-12-06 16:03:33,024] [INFO] [controller] EPOCH 2 loss ppo:  -0.02005, loss val: 0.03557
[2022-12-06 16:03:33,111] [INFO] [controller] EPOCH 3 loss ppo:  -0.02492, loss val: 0.03603
[2022-12-06 16:03:33,175] [INFO] [controller] EPOCH 4 loss ppo:  -0.02982, loss val: 0.03515
[2022-12-06 16:03:33,187] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:03:33,379] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:03:33,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:03:39,370] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:03:44,630] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:03:50,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:03:56,589] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:04:02,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:04:08,268] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:04:13,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:04:20,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:04:26,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:04:32,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7364954331717284
[2022-12-06 16:04:32,564] [INFO] [runner_train_mujoco] Average state value: 0.5859392021695772
[2022-12-06 16:04:32,564] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 16:04:32,642] [INFO] [controller] EPOCH 1 loss ppo:  -0.01079, loss val: 0.04049
[2022-12-06 16:04:32,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.02350, loss val: 0.03832
[2022-12-06 16:04:32,771] [INFO] [controller] EPOCH 3 loss ppo:  -0.02798, loss val: 0.03835
[2022-12-06 16:04:32,834] [INFO] [controller] EPOCH 4 loss ppo:  -0.03071, loss val: 0.03876
[2022-12-06 16:04:32,846] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:04:33,067] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:04:33,068] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:04:38,994] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:04:44,971] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:04:50,370] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:04:57,614] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:05:03,913] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:05:09,372] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:05:15,074] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:05:20,366] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:05:26,726] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:05:32,631] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9217608112679084
[2022-12-06 16:05:32,631] [INFO] [runner_train_mujoco] Average state value: 0.5715662094553312
[2022-12-06 16:05:32,631] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 16:05:32,715] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.03654
[2022-12-06 16:05:32,785] [INFO] [controller] EPOCH 2 loss ppo:  -0.02741, loss val: 0.03553
[2022-12-06 16:05:32,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.03097, loss val: 0.03277
[2022-12-06 16:05:32,917] [INFO] [controller] EPOCH 4 loss ppo:  -0.03786, loss val: 0.03006
[2022-12-06 16:05:32,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:05:33,129] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:05:33,130] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:05:38,773] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:05:44,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:05:50,119] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:05:55,803] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:06:01,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:06:06,323] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:06:11,396] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:06:16,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:06:22,032] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:06:27,174] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2498132786427363
[2022-12-06 16:06:27,174] [INFO] [runner_train_mujoco] Average state value: 0.5088130115469296
[2022-12-06 16:06:27,175] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 16:06:27,267] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04138
[2022-12-06 16:06:27,374] [INFO] [controller] EPOCH 2 loss ppo:  -0.02663, loss val: 0.04194
[2022-12-06 16:06:27,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.03290, loss val: 0.04348
[2022-12-06 16:06:27,527] [INFO] [controller] EPOCH 4 loss ppo:  -0.03420, loss val: 0.04227
[2022-12-06 16:06:27,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:06:27,739] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:06:27,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:06:33,072] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:06:38,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:06:43,188] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:06:48,732] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:06:53,942] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:06:59,218] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:07:05,608] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:07:11,592] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:07:17,150] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:07:22,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1806053380681265
[2022-12-06 16:07:22,846] [INFO] [runner_train_mujoco] Average state value: 0.49069818770885465
[2022-12-06 16:07:22,846] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 16:07:22,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.03986
[2022-12-06 16:07:23,020] [INFO] [controller] EPOCH 2 loss ppo:  -0.02749, loss val: 0.03616
[2022-12-06 16:07:23,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.03040, loss val: 0.03692
[2022-12-06 16:07:23,153] [INFO] [controller] EPOCH 4 loss ppo:  -0.03395, loss val: 0.03585
[2022-12-06 16:07:23,164] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:07:23,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:07:23,355] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:07:28,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:07:33,834] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:07:38,912] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:07:43,482] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:07:48,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:07:53,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:07:57,893] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:08:02,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:08:07,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:08:12,196] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5213610048208928
[2022-12-06 16:08:12,196] [INFO] [runner_train_mujoco] Average state value: 0.5501165614525476
[2022-12-06 16:08:12,196] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 16:08:12,332] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.02990
[2022-12-06 16:08:12,396] [INFO] [controller] EPOCH 2 loss ppo:  -0.02604, loss val: 0.02996
[2022-12-06 16:08:12,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.02819, loss val: 0.03086
[2022-12-06 16:08:12,514] [INFO] [controller] EPOCH 4 loss ppo:  -0.03148, loss val: 0.02974
[2022-12-06 16:08:12,525] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:08:12,703] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:08:12,704] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:08:17,940] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:08:23,039] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:08:27,773] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:08:32,898] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:08:37,788] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:08:42,612] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:08:47,389] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:08:52,145] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:08:56,898] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:09:01,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7730753866711892
[2022-12-06 16:09:01,562] [INFO] [runner_train_mujoco] Average state value: 0.5496076944470405
[2022-12-06 16:09:01,562] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 16:09:01,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01262, loss val: 0.04688
[2022-12-06 16:09:01,682] [INFO] [controller] EPOCH 2 loss ppo:  -0.02060, loss val: 0.04206
[2022-12-06 16:09:01,812] [INFO] [controller] EPOCH 3 loss ppo:  -0.02896, loss val: 0.03998
[2022-12-06 16:09:01,871] [INFO] [controller] EPOCH 4 loss ppo:  -0.03209, loss val: 0.03836
[2022-12-06 16:09:01,882] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:09:02,070] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:09:02,071] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:09:06,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:09:11,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:09:16,106] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:09:21,076] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:09:25,537] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:09:30,873] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:09:35,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:09:40,303] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:09:45,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:09:50,325] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.019959447583582
[2022-12-06 16:09:50,325] [INFO] [runner_train_mujoco] Average state value: 0.4671202240188917
[2022-12-06 16:09:50,326] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 16:09:50,388] [INFO] [controller] EPOCH 1 loss ppo:  -0.01498, loss val: 0.03573
[2022-12-06 16:09:50,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.02665, loss val: 0.03385
[2022-12-06 16:09:50,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.02980, loss val: 0.03424
[2022-12-06 16:09:50,560] [INFO] [controller] EPOCH 4 loss ppo:  -0.03358, loss val: 0.03455
[2022-12-06 16:09:50,571] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:09:50,750] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:09:50,751] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:09:55,948] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:10:01,050] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:10:05,630] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:10:10,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:10:15,108] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:10:19,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:10:24,330] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:10:28,806] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:10:33,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:10:38,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.145443331209962
[2022-12-06 16:10:38,833] [INFO] [runner_train_mujoco] Average state value: 0.4103342964649201
[2022-12-06 16:10:38,833] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 16:10:38,899] [INFO] [controller] EPOCH 1 loss ppo:  -0.01569, loss val: 0.03419
[2022-12-06 16:10:38,956] [INFO] [controller] EPOCH 2 loss ppo:  -0.02854, loss val: 0.03366
[2022-12-06 16:10:39,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.02890, loss val: 0.03329
[2022-12-06 16:10:39,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.03682, loss val: 0.03316
[2022-12-06 16:10:39,074] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:10:39,258] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:10:39,258] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:10:44,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:10:49,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:10:55,177] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:11:00,500] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:11:05,242] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:11:09,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:11:14,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:11:19,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:11:24,951] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:11:30,073] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3272241699664904
[2022-12-06 16:11:30,074] [INFO] [runner_train_mujoco] Average state value: 0.42114196401834486
[2022-12-06 16:11:30,074] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 16:11:30,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.03359
[2022-12-06 16:11:30,238] [INFO] [controller] EPOCH 2 loss ppo:  -0.02696, loss val: 0.03320
[2022-12-06 16:11:30,305] [INFO] [controller] EPOCH 3 loss ppo:  -0.03440, loss val: 0.03263
[2022-12-06 16:11:30,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.03612, loss val: 0.03328
[2022-12-06 16:11:30,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:11:30,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:11:30,606] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:11:35,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:11:41,001] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:11:46,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:11:51,934] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:11:57,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:12:02,825] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:12:08,182] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:12:13,410] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:12:18,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:12:23,186] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8437213341981336
[2022-12-06 16:12:23,186] [INFO] [runner_train_mujoco] Average state value: 0.41697306041916216
[2022-12-06 16:12:23,186] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 16:12:23,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.01500, loss val: 0.04847
[2022-12-06 16:12:23,299] [INFO] [controller] EPOCH 2 loss ppo:  -0.02711, loss val: 0.04774
[2022-12-06 16:12:23,350] [INFO] [controller] EPOCH 3 loss ppo:  -0.03241, loss val: 0.04878
[2022-12-06 16:12:23,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.03838, loss val: 0.04497
[2022-12-06 16:12:23,427] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:12:23,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:12:23,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:12:28,766] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:12:34,199] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:12:39,379] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:12:44,723] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:12:49,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:12:55,113] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:13:00,445] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:13:05,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:13:10,521] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:13:15,657] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.103508303427618
[2022-12-06 16:13:15,658] [INFO] [runner_train_mujoco] Average state value: 0.45472276443243026
[2022-12-06 16:13:15,658] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 16:13:15,744] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.03920
[2022-12-06 16:13:15,804] [INFO] [controller] EPOCH 2 loss ppo:  -0.02549, loss val: 0.03945
[2022-12-06 16:13:15,864] [INFO] [controller] EPOCH 3 loss ppo:  -0.03335, loss val: 0.03898
[2022-12-06 16:13:15,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.03508, loss val: 0.03919
[2022-12-06 16:13:15,933] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:13:16,132] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:13:16,132] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:13:21,423] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:13:26,686] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:13:31,430] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:13:36,452] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:13:41,182] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:13:46,058] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:13:51,146] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:13:55,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:14:00,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:14:05,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.369323155643669
[2022-12-06 16:14:05,420] [INFO] [runner_train_mujoco] Average state value: 0.4825335924625397
[2022-12-06 16:14:05,420] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 16:14:05,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01511, loss val: 0.04181
[2022-12-06 16:14:05,537] [INFO] [controller] EPOCH 2 loss ppo:  -0.02378, loss val: 0.04261
[2022-12-06 16:14:05,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.03252, loss val: 0.04362
[2022-12-06 16:14:05,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.03926, loss val: 0.04140
[2022-12-06 16:14:05,660] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:14:05,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:05,838] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:14:10,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:14:15,773] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:14:20,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:14:25,165] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:14:30,145] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:14:34,745] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:14:39,741] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:14:44,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:14:49,584] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:14:55,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6540199578742354
[2022-12-06 16:14:55,527] [INFO] [runner_train_mujoco] Average state value: 0.4814186402956645
[2022-12-06 16:14:55,527] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 16:14:57,611] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.03838
[2022-12-06 16:14:58,392] [INFO] [controller] EPOCH 2 loss ppo:  -0.01794, loss val: 0.03747
[2022-12-06 16:14:58,806] [INFO] [controller] EPOCH 3 loss ppo:  -0.02659, loss val: 0.03574
[2022-12-06 16:14:58,876] [INFO] [controller] EPOCH 4 loss ppo:  -0.02950, loss val: 0.03519
[2022-12-06 16:14:58,887] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:14:59,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:59,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:15:04,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:15:09,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:15:14,912] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:15:20,873] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:15:25,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:15:31,008] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:15:36,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:15:41,632] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:15:46,897] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:15:52,668] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9401548183756345
[2022-12-06 16:15:52,668] [INFO] [runner_train_mujoco] Average state value: 0.43300036662817004
[2022-12-06 16:15:52,668] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 16:15:52,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01592, loss val: 0.04486
[2022-12-06 16:15:52,818] [INFO] [controller] EPOCH 2 loss ppo:  -0.02299, loss val: 0.04597
[2022-12-06 16:15:53,002] [INFO] [controller] EPOCH 3 loss ppo:  -0.02859, loss val: 0.04583
[2022-12-06 16:15:53,087] [INFO] [controller] EPOCH 4 loss ppo:  -0.03466, loss val: 0.04518
[2022-12-06 16:15:53,100] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:15:53,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:15:53,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:15:58,746] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:16:04,467] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:16:09,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:16:15,736] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:16:21,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:16:26,623] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:16:31,817] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:16:37,191] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:16:42,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:16:48,338] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6660522689735915
[2022-12-06 16:16:48,339] [INFO] [runner_train_mujoco] Average state value: 0.4365001957416535
[2022-12-06 16:16:48,339] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 16:16:48,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.01602, loss val: 0.04588
[2022-12-06 16:16:48,603] [INFO] [controller] EPOCH 2 loss ppo:  -0.02206, loss val: 0.04307
[2022-12-06 16:16:48,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.02991, loss val: 0.04482
[2022-12-06 16:16:48,809] [INFO] [controller] EPOCH 4 loss ppo:  -0.03611, loss val: 0.04416
[2022-12-06 16:16:48,820] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:16:49,027] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:16:49,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:16:54,535] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:17:00,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:17:06,068] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:17:11,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:17:17,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:17:22,854] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:17:28,791] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:17:34,547] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:17:40,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:17:45,829] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9338579960841287
[2022-12-06 16:17:45,829] [INFO] [runner_train_mujoco] Average state value: 0.4624717241128285
[2022-12-06 16:17:45,829] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 16:17:45,895] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03763
[2022-12-06 16:17:45,952] [INFO] [controller] EPOCH 2 loss ppo:  -0.02191, loss val: 0.03746
[2022-12-06 16:17:46,012] [INFO] [controller] EPOCH 3 loss ppo:  -0.02732, loss val: 0.03649
[2022-12-06 16:17:46,070] [INFO] [controller] EPOCH 4 loss ppo:  -0.03485, loss val: 0.03573
[2022-12-06 16:17:46,081] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:17:46,273] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:17:46,273] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:17:51,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:17:58,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:18:04,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:18:09,868] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:18:15,561] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:18:21,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:18:26,672] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:18:32,426] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:18:38,119] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:18:43,756] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.018659946382156
[2022-12-06 16:18:43,756] [INFO] [runner_train_mujoco] Average state value: 0.49079758038123444
[2022-12-06 16:18:43,756] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 16:18:43,851] [INFO] [controller] EPOCH 1 loss ppo:  -0.01579, loss val: 0.04527
[2022-12-06 16:18:43,903] [INFO] [controller] EPOCH 2 loss ppo:  -0.02381, loss val: 0.04480
[2022-12-06 16:18:43,972] [INFO] [controller] EPOCH 3 loss ppo:  -0.02790, loss val: 0.04335
[2022-12-06 16:18:44,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.03665, loss val: 0.04338
[2022-12-06 16:18:44,037] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:18:44,228] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:18:44,229] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:18:49,831] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:18:55,532] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:01,365] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:19:06,908] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:19:12,497] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:19:17,886] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:19:22,995] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:19:28,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:19:33,715] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:19:39,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.228634249905825
[2022-12-06 16:19:39,090] [INFO] [runner_train_mujoco] Average state value: 0.4673705094059309
[2022-12-06 16:19:39,090] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 16:19:39,197] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.03563
[2022-12-06 16:19:39,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.02097, loss val: 0.03497
[2022-12-06 16:19:39,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.02673, loss val: 0.03463
[2022-12-06 16:19:39,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.03025, loss val: 0.03448
[2022-12-06 16:19:39,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:19:39,632] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:19:39,633] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:19:45,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:19:50,602] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:55,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:20:00,830] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:20:05,955] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:20:10,976] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:20:16,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:20:21,909] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:20:27,264] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:20:32,796] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9617765780700767
[2022-12-06 16:20:32,796] [INFO] [runner_train_mujoco] Average state value: 0.4259094843665759
[2022-12-06 16:20:32,796] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 16:20:32,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01644, loss val: 0.05621
[2022-12-06 16:20:32,993] [INFO] [controller] EPOCH 2 loss ppo:  -0.01846, loss val: 0.05672
[2022-12-06 16:20:33,117] [INFO] [controller] EPOCH 3 loss ppo:  -0.02620, loss val: 0.05552
[2022-12-06 16:20:33,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.03453, loss val: 0.05327
[2022-12-06 16:20:33,232] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:20:33,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:20:33,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:20:38,760] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:20:43,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:20:48,945] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:20:53,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:20:58,842] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:03,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:21:09,011] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:21:14,131] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:21:19,391] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:21:24,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.014100921890362
[2022-12-06 16:21:24,065] [INFO] [runner_train_mujoco] Average state value: 0.44843611824512475
[2022-12-06 16:21:24,065] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 16:21:24,157] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.04822
[2022-12-06 16:21:24,209] [INFO] [controller] EPOCH 2 loss ppo:  -0.01919, loss val: 0.04682
[2022-12-06 16:21:24,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.02292, loss val: 0.04874
[2022-12-06 16:21:24,313] [INFO] [controller] EPOCH 4 loss ppo:  -0.03134, loss val: 0.04689
[2022-12-06 16:21:24,329] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:21:24,511] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:21:24,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:21:29,639] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:21:35,085] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:21:40,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:21:45,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:21:51,164] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:56,549] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:22:01,806] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:22:06,905] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:22:11,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:22:17,246] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.227072705406474
[2022-12-06 16:22:17,246] [INFO] [runner_train_mujoco] Average state value: 0.47876013203461965
[2022-12-06 16:22:17,246] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 16:22:17,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.01630, loss val: 0.05046
[2022-12-06 16:22:17,464] [INFO] [controller] EPOCH 2 loss ppo:  -0.02023, loss val: 0.05062
[2022-12-06 16:22:17,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.02148, loss val: 0.05067
[2022-12-06 16:22:17,651] [INFO] [controller] EPOCH 4 loss ppo:  -0.02849, loss val: 0.04929
[2022-12-06 16:22:17,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:22:17,892] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:22:17,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:22:23,041] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:22:28,365] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:22:33,623] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:22:38,828] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:22:43,883] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:22:48,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:22:54,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:22:59,889] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:23:05,530] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:23:11,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.193668903854041
[2022-12-06 16:23:11,258] [INFO] [runner_train_mujoco] Average state value: 0.4842356466253598
[2022-12-06 16:23:11,258] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 16:23:11,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.04194
[2022-12-06 16:23:11,403] [INFO] [controller] EPOCH 2 loss ppo:  -0.01912, loss val: 0.04198
[2022-12-06 16:23:11,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.02559, loss val: 0.04320
[2022-12-06 16:23:11,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.03163, loss val: 0.04132
[2022-12-06 16:23:11,540] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:23:11,732] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:23:11,733] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:23:17,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:23:23,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:23:28,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:23:34,141] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:23:39,304] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:23:44,691] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:23:50,206] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:23:55,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:24:01,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:24:07,041] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.329248858171296
[2022-12-06 16:24:07,041] [INFO] [runner_train_mujoco] Average state value: 0.45185999455054604
[2022-12-06 16:24:07,041] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 16:24:07,217] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04913
[2022-12-06 16:24:07,295] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.04976
[2022-12-06 16:24:07,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.02603, loss val: 0.04833
[2022-12-06 16:24:07,411] [INFO] [controller] EPOCH 4 loss ppo:  -0.03365, loss val: 0.04923
[2022-12-06 16:24:07,424] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:24:07,643] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:24:07,644] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:24:13,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:24:18,838] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:24:24,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:24:29,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:24:36,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:24:41,508] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:24:47,244] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:24:52,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:24:58,548] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:25:04,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.429549913639893
[2022-12-06 16:25:04,276] [INFO] [runner_train_mujoco] Average state value: 0.4278734914859136
[2022-12-06 16:25:04,276] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 16:25:04,367] [INFO] [controller] EPOCH 1 loss ppo:  -0.01188, loss val: 0.04458
[2022-12-06 16:25:04,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.01927, loss val: 0.04811
[2022-12-06 16:25:04,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.02716, loss val: 0.04669
[2022-12-06 16:25:04,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.03096, loss val: 0.04529
[2022-12-06 16:25:04,582] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:25:04,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:25:04,776] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:25:10,724] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:25:16,696] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:25:22,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:25:27,914] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:25:33,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:25:39,453] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:25:49,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:25:58,451] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:26:07,176] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:26:15,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.435343416289518
[2022-12-06 16:26:15,484] [INFO] [runner_train_mujoco] Average state value: 0.4284280157486598
[2022-12-06 16:26:15,484] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 16:26:15,703] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.04977
[2022-12-06 16:26:15,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.02052, loss val: 0.04839
[2022-12-06 16:26:16,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.02477, loss val: 0.04641
[2022-12-06 16:26:16,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.02916, loss val: 0.04465
[2022-12-06 16:26:16,159] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:26:16,378] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:26:16,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:26:24,408] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:26:32,761] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:26:40,241] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:26:47,781] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:26:54,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:27:01,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:27:09,305] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:27:15,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:27:20,593] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:27:25,883] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.580684431812889
[2022-12-06 16:27:25,884] [INFO] [runner_train_mujoco] Average state value: 0.47564473005135854
[2022-12-06 16:27:25,884] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 16:27:25,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.01217, loss val: 0.05282
[2022-12-06 16:27:26,014] [INFO] [controller] EPOCH 2 loss ppo:  -0.02041, loss val: 0.05414
[2022-12-06 16:27:26,086] [INFO] [controller] EPOCH 3 loss ppo:  -0.02725, loss val: 0.05387
[2022-12-06 16:27:26,141] [INFO] [controller] EPOCH 4 loss ppo:  -0.03190, loss val: 0.05356
[2022-12-06 16:27:26,156] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:27:26,352] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:27:26,352] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:27:32,134] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:27:38,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:27:45,312] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:27:54,100] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:28:02,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:28:08,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:28:15,216] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:28:21,159] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:28:27,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:28:32,890] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.626715545019399
[2022-12-06 16:28:32,890] [INFO] [runner_train_mujoco] Average state value: 0.4892128450075785
[2022-12-06 16:28:32,890] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 16:28:32,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.04528
[2022-12-06 16:28:33,046] [INFO] [controller] EPOCH 2 loss ppo:  -0.01820, loss val: 0.04029
[2022-12-06 16:28:33,109] [INFO] [controller] EPOCH 3 loss ppo:  -0.02335, loss val: 0.04309
[2022-12-06 16:28:33,195] [INFO] [controller] EPOCH 4 loss ppo:  -0.03003, loss val: 0.04244
[2022-12-06 16:28:33,207] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:28:33,405] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:28:33,405] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:28:39,163] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:28:45,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:28:50,752] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:28:56,595] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:29:02,265] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:29:08,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:29:14,475] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:29:21,421] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:29:27,744] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:29:34,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.830183352253497
[2022-12-06 16:29:34,033] [INFO] [runner_train_mujoco] Average state value: 0.47659006641308466
[2022-12-06 16:29:34,034] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 16:29:34,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.04747
[2022-12-06 16:29:34,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.01632, loss val: 0.04908
[2022-12-06 16:29:34,234] [INFO] [controller] EPOCH 3 loss ppo:  -0.02274, loss val: 0.04706
[2022-12-06 16:29:34,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.02820, loss val: 0.04707
[2022-12-06 16:29:34,305] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:29:34,504] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:29:34,505] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:29:40,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:29:47,082] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:29:52,614] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:29:58,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:30:03,791] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:30:09,067] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:30:14,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:30:20,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:30:25,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:30:30,781] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.648257769201926
[2022-12-06 16:30:30,782] [INFO] [runner_train_mujoco] Average state value: 0.49320499261220296
[2022-12-06 16:30:30,782] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 16:30:30,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01060, loss val: 0.05431
[2022-12-06 16:30:30,917] [INFO] [controller] EPOCH 2 loss ppo:  -0.01685, loss val: 0.05327
[2022-12-06 16:30:30,991] [INFO] [controller] EPOCH 3 loss ppo:  -0.02000, loss val: 0.05386
[2022-12-06 16:30:31,054] [INFO] [controller] EPOCH 4 loss ppo:  -0.02723, loss val: 0.05308
[2022-12-06 16:30:31,065] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:30:31,260] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:30:31,261] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:30:36,929] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:30:42,591] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:30:48,087] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:30:53,554] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:30:58,946] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:31:04,622] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:31:09,858] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:31:15,429] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:31:20,835] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:31:26,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.525541878374853
[2022-12-06 16:31:26,274] [INFO] [runner_train_mujoco] Average state value: 0.49447147597869234
[2022-12-06 16:31:26,274] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 16:31:26,388] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.04031
[2022-12-06 16:31:26,472] [INFO] [controller] EPOCH 2 loss ppo:  -0.01666, loss val: 0.03984
[2022-12-06 16:31:26,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.01938, loss val: 0.03856
[2022-12-06 16:31:26,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.02725, loss val: 0.04015
[2022-12-06 16:31:26,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:31:26,863] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:31:26,864] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:31:32,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:31:37,241] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:31:42,356] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:31:47,192] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:31:52,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:31:58,100] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:32:03,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:32:08,510] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:32:13,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:32:18,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7747540945457745
[2022-12-06 16:32:18,508] [INFO] [runner_train_mujoco] Average state value: 0.4996958169937134
[2022-12-06 16:32:18,508] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 16:32:18,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.04553
[2022-12-06 16:32:18,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.01317, loss val: 0.04530
[2022-12-06 16:32:18,742] [INFO] [controller] EPOCH 3 loss ppo:  -0.01787, loss val: 0.04736
[2022-12-06 16:32:18,832] [INFO] [controller] EPOCH 4 loss ppo:  -0.02304, loss val: 0.04607
[2022-12-06 16:32:18,843] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:32:19,025] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:32:19,025] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:32:24,335] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:32:29,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:32:34,733] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:32:39,897] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:32:45,370] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:32:50,947] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:32:56,131] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:33:01,324] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:33:06,043] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:33:10,765] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.828172750097465
[2022-12-06 16:33:10,765] [INFO] [runner_train_mujoco] Average state value: 0.4933115061124166
[2022-12-06 16:33:10,765] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 16:33:10,836] [INFO] [controller] EPOCH 1 loss ppo:  -0.01167, loss val: 0.04865
[2022-12-06 16:33:10,896] [INFO] [controller] EPOCH 2 loss ppo:  -0.01604, loss val: 0.04770
[2022-12-06 16:33:10,995] [INFO] [controller] EPOCH 3 loss ppo:  -0.01898, loss val: 0.04791
[2022-12-06 16:33:11,138] [INFO] [controller] EPOCH 4 loss ppo:  -0.02555, loss val: 0.04778
[2022-12-06 16:33:11,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:33:11,332] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:33:11,332] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:33:16,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:33:21,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:33:26,500] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:33:31,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:33:35,943] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:33:40,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:33:45,704] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:33:50,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:33:56,148] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:34:01,620] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.755998534467125
[2022-12-06 16:34:01,621] [INFO] [runner_train_mujoco] Average state value: 0.473151300728321
[2022-12-06 16:34:01,621] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 16:34:01,695] [INFO] [controller] EPOCH 1 loss ppo:  -0.01208, loss val: 0.04328
[2022-12-06 16:34:01,752] [INFO] [controller] EPOCH 2 loss ppo:  -0.01997, loss val: 0.04581
[2022-12-06 16:34:01,907] [INFO] [controller] EPOCH 3 loss ppo:  -0.02411, loss val: 0.04216
[2022-12-06 16:34:01,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.03113, loss val: 0.04387
[2022-12-06 16:34:01,980] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:34:02,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:34:02,172] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:34:07,328] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:34:12,367] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:34:18,248] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:34:24,074] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:34:29,336] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:34:36,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:34:42,203] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:34:47,581] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:34:54,653] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:35:03,163] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.816370964020358
[2022-12-06 16:35:03,163] [INFO] [runner_train_mujoco] Average state value: 0.4566724019050598
[2022-12-06 16:35:03,163] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 16:35:03,405] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.04270
[2022-12-06 16:35:03,555] [INFO] [controller] EPOCH 2 loss ppo:  -0.02078, loss val: 0.04513
[2022-12-06 16:35:03,621] [INFO] [controller] EPOCH 3 loss ppo:  -0.02284, loss val: 0.04372
[2022-12-06 16:35:03,863] [INFO] [controller] EPOCH 4 loss ppo:  -0.02655, loss val: 0.04240
[2022-12-06 16:35:03,875] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:35:04,081] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:35:04,081] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:35:11,845] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:35:17,361] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:35:22,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:35:28,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:35:34,066] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:35:39,541] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:35:44,983] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:35:50,013] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:35:55,076] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:36:00,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.838461623099869
[2022-12-06 16:36:00,305] [INFO] [runner_train_mujoco] Average state value: 0.4659361665447553
[2022-12-06 16:36:00,305] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 16:36:00,391] [INFO] [controller] EPOCH 1 loss ppo:  -0.01172, loss val: 0.04915
[2022-12-06 16:36:00,457] [INFO] [controller] EPOCH 2 loss ppo:  -0.01640, loss val: 0.04918
[2022-12-06 16:36:00,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.01882, loss val: 0.04879
[2022-12-06 16:36:00,580] [INFO] [controller] EPOCH 4 loss ppo:  -0.02251, loss val: 0.04934
[2022-12-06 16:36:00,592] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:36:00,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:36:00,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:36:06,292] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:36:11,413] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:36:17,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:36:24,639] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:36:31,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:36:39,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:36:46,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:36:52,245] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:36:57,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:37:04,151] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.803884472415915
[2022-12-06 16:37:04,152] [INFO] [runner_train_mujoco] Average state value: 0.4547670140465101
[2022-12-06 16:37:04,152] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 16:37:04,248] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.03919
[2022-12-06 16:37:04,348] [INFO] [controller] EPOCH 2 loss ppo:  -0.02006, loss val: 0.04044
[2022-12-06 16:37:04,408] [INFO] [controller] EPOCH 3 loss ppo:  -0.02021, loss val: 0.03915
[2022-12-06 16:37:04,471] [INFO] [controller] EPOCH 4 loss ppo:  -0.02349, loss val: 0.03903
[2022-12-06 16:37:04,484] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:37:04,725] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:37:04,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:37:10,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:37:16,374] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:37:22,382] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:37:28,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:37:34,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:37:40,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:37:45,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:37:51,374] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:37:57,221] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:38:03,071] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.917069289422151
[2022-12-06 16:38:03,071] [INFO] [runner_train_mujoco] Average state value: 0.4408266960382462
[2022-12-06 16:38:03,071] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 16:38:03,159] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.04066
[2022-12-06 16:38:03,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.01460, loss val: 0.04395
[2022-12-06 16:38:03,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.01957, loss val: 0.04107
[2022-12-06 16:38:03,426] [INFO] [controller] EPOCH 4 loss ppo:  -0.02434, loss val: 0.04226
[2022-12-06 16:38:03,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:38:03,633] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:38:03,633] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:38:09,537] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:38:15,470] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:38:21,761] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:38:31,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:38:41,346] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:38:48,662] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:38:54,810] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:39:01,222] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:39:07,826] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:39:15,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.856836632787843
[2022-12-06 16:39:15,166] [INFO] [runner_train_mujoco] Average state value: 0.44562288641929626
[2022-12-06 16:39:15,166] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 16:39:15,328] [INFO] [controller] EPOCH 1 loss ppo:  -0.01095, loss val: 0.04338
[2022-12-06 16:39:15,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.01598, loss val: 0.04496
[2022-12-06 16:39:15,688] [INFO] [controller] EPOCH 3 loss ppo:  -0.02168, loss val: 0.04431
[2022-12-06 16:39:15,767] [INFO] [controller] EPOCH 4 loss ppo:  -0.02559, loss val: 0.04405
[2022-12-06 16:39:15,785] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:39:16,094] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:39:16,094] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:39:23,406] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:39:31,227] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:39:37,738] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:39:44,245] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:39:50,964] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:39:56,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:40:02,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:40:10,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:40:17,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:40:24,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.046280953923617
[2022-12-06 16:40:24,297] [INFO] [runner_train_mujoco] Average state value: 0.45061776898304623
[2022-12-06 16:40:24,297] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 16:40:24,386] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.04299
[2022-12-06 16:40:24,444] [INFO] [controller] EPOCH 2 loss ppo:  -0.01706, loss val: 0.04508
[2022-12-06 16:40:24,497] [INFO] [controller] EPOCH 3 loss ppo:  -0.01790, loss val: 0.04079
[2022-12-06 16:40:24,568] [INFO] [controller] EPOCH 4 loss ppo:  -0.02246, loss val: 0.04350
[2022-12-06 16:40:24,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:40:24,812] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:40:24,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:40:30,767] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:40:36,740] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:40:42,548] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:40:48,441] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:40:54,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:00,005] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:41:05,564] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:41:11,048] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:41:16,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:41:22,500] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.009312347029735
[2022-12-06 16:41:22,501] [INFO] [runner_train_mujoco] Average state value: 0.4513391979138056
[2022-12-06 16:41:22,501] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 16:41:22,578] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.04668
[2022-12-06 16:41:22,698] [INFO] [controller] EPOCH 2 loss ppo:  -0.01658, loss val: 0.04605
[2022-12-06 16:41:22,805] [INFO] [controller] EPOCH 3 loss ppo:  -0.01726, loss val: 0.04492
[2022-12-06 16:41:22,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.02307, loss val: 0.04380
[2022-12-06 16:41:22,950] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:41:23,185] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:41:23,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:41:28,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:41:34,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:41:39,379] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:41:44,760] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:41:50,651] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:56,489] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:42:02,673] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:42:08,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:42:13,492] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:42:19,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.086631817242823
[2022-12-06 16:42:19,041] [INFO] [runner_train_mujoco] Average state value: 0.44162414360046387
[2022-12-06 16:42:19,041] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 16:42:19,172] [INFO] [controller] EPOCH 1 loss ppo:  -0.01151, loss val: 0.04414
[2022-12-06 16:42:19,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.01426, loss val: 0.04313
[2022-12-06 16:42:19,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.01866, loss val: 0.04438
[2022-12-06 16:42:19,353] [INFO] [controller] EPOCH 4 loss ppo:  -0.02300, loss val: 0.04272
[2022-12-06 16:42:19,365] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:42:19,569] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:42:19,570] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:42:25,303] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:42:30,865] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:42:36,384] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:42:41,623] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:42:47,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:42:52,512] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:42:57,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:43:03,428] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:43:08,732] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:43:14,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0899573126618565
[2022-12-06 16:43:14,364] [INFO] [runner_train_mujoco] Average state value: 0.4314696471691131
[2022-12-06 16:43:14,364] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 16:43:14,547] [INFO] [controller] EPOCH 1 loss ppo:  -0.01084, loss val: 0.04195
[2022-12-06 16:43:14,624] [INFO] [controller] EPOCH 2 loss ppo:  -0.01324, loss val: 0.04150
[2022-12-06 16:43:14,704] [INFO] [controller] EPOCH 3 loss ppo:  -0.01873, loss val: 0.04125
[2022-12-06 16:43:14,890] [INFO] [controller] EPOCH 4 loss ppo:  -0.02149, loss val: 0.04076
[2022-12-06 16:43:14,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:43:15,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:43:15,099] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:43:21,048] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:43:27,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:43:32,648] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:43:38,341] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:43:43,741] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:43:49,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:43:54,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:43:59,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:44:05,282] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:44:10,593] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.253727057964598
[2022-12-06 16:44:10,594] [INFO] [runner_train_mujoco] Average state value: 0.41672203425566356
[2022-12-06 16:44:10,594] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 16:44:10,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01126, loss val: 0.05264
[2022-12-06 16:44:10,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.01488, loss val: 0.05134
[2022-12-06 16:44:10,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.01788, loss val: 0.05194
[2022-12-06 16:44:10,879] [INFO] [controller] EPOCH 4 loss ppo:  -0.01878, loss val: 0.05217
[2022-12-06 16:44:10,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:44:11,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:44:11,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:44:16,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:44:22,623] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:44:28,665] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:44:34,269] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:44:40,053] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:44:46,189] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:44:51,560] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:44:57,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:45:02,814] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:45:08,460] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.271971833314022
[2022-12-06 16:45:08,460] [INFO] [runner_train_mujoco] Average state value: 0.40154631167650223
[2022-12-06 16:45:08,460] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 16:45:08,542] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.04901
[2022-12-06 16:45:08,619] [INFO] [controller] EPOCH 2 loss ppo:  -0.01641, loss val: 0.04933
[2022-12-06 16:45:08,700] [INFO] [controller] EPOCH 3 loss ppo:  -0.02206, loss val: 0.04821
[2022-12-06 16:45:08,767] [INFO] [controller] EPOCH 4 loss ppo:  -0.02441, loss val: 0.04925
[2022-12-06 16:45:08,778] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:45:08,991] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:45:08,992] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:45:14,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:45:21,681] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:45:28,276] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:45:34,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:45:41,144] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:45:47,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:45:54,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:46:00,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:46:06,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:46:13,229] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.127741082413138
[2022-12-06 16:46:13,230] [INFO] [runner_train_mujoco] Average state value: 0.40002648347616193
[2022-12-06 16:46:13,230] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 16:46:13,350] [INFO] [controller] EPOCH 1 loss ppo:  -0.01102, loss val: 0.05815
[2022-12-06 16:46:13,465] [INFO] [controller] EPOCH 2 loss ppo:  -0.01403, loss val: 0.05726
[2022-12-06 16:46:13,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.01739, loss val: 0.05794
[2022-12-06 16:46:13,801] [INFO] [controller] EPOCH 4 loss ppo:  -0.01927, loss val: 0.05802
[2022-12-06 16:46:13,823] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:46:14,057] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:46:14,058] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:46:21,078] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:46:27,559] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:46:33,552] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:46:39,515] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:46:45,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:46:52,388] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:46:58,696] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:47:04,774] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:47:10,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:47:17,259] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0429624431692455
[2022-12-06 16:47:17,259] [INFO] [runner_train_mujoco] Average state value: 0.4022346712152164
[2022-12-06 16:47:17,260] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 16:47:17,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.01117, loss val: 0.04286
[2022-12-06 16:47:17,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.01413, loss val: 0.04165
[2022-12-06 16:47:17,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.01909, loss val: 0.04199
[2022-12-06 16:47:17,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.02274, loss val: 0.04178
[2022-12-06 16:47:17,853] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:47:18,093] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:47:18,093] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:47:24,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:47:30,736] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:47:36,420] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:47:41,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:47:47,786] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:47:53,998] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:47:59,871] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:48:06,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:48:11,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:48:17,203] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.269184110805801
[2022-12-06 16:48:17,203] [INFO] [runner_train_mujoco] Average state value: 0.40346932377417877
[2022-12-06 16:48:17,203] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 16:48:17,290] [INFO] [controller] EPOCH 1 loss ppo:  -0.01131, loss val: 0.04110
[2022-12-06 16:48:17,356] [INFO] [controller] EPOCH 2 loss ppo:  -0.01353, loss val: 0.04189
[2022-12-06 16:48:17,422] [INFO] [controller] EPOCH 3 loss ppo:  -0.01757, loss val: 0.04184
[2022-12-06 16:48:17,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.02183, loss val: 0.04166
[2022-12-06 16:48:17,501] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:48:17,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:48:17,776] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:48:23,677] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:48:30,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:48:37,226] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:48:42,847] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:48:48,748] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:48:53,963] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:48:59,368] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:49:05,069] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:49:10,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:49:16,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.122002954446749
[2022-12-06 16:49:16,825] [INFO] [runner_train_mujoco] Average state value: 0.40599954799811044
[2022-12-06 16:49:16,825] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 16:49:17,256] [INFO] [controller] EPOCH 1 loss ppo:  -0.01104, loss val: 0.05165
[2022-12-06 16:49:17,359] [INFO] [controller] EPOCH 2 loss ppo:  -0.01309, loss val: 0.05156
[2022-12-06 16:49:17,450] [INFO] [controller] EPOCH 3 loss ppo:  -0.01599, loss val: 0.05170
[2022-12-06 16:49:17,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.01928, loss val: 0.05144
[2022-12-06 16:49:17,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:49:17,825] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:49:17,826] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:49:24,124] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:49:29,795] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:49:36,096] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:49:42,241] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:49:48,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:49:54,084] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:49:59,538] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:50:04,525] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:50:09,813] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:50:15,277] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.2661280026342965
[2022-12-06 16:50:15,277] [INFO] [runner_train_mujoco] Average state value: 0.4072630523045858
[2022-12-06 16:50:15,277] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 16:50:15,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.01105, loss val: 0.04697
[2022-12-06 16:50:15,427] [INFO] [controller] EPOCH 2 loss ppo:  -0.01192, loss val: 0.04526
[2022-12-06 16:50:15,495] [INFO] [controller] EPOCH 3 loss ppo:  -0.01324, loss val: 0.04681
[2022-12-06 16:50:15,608] [INFO] [controller] EPOCH 4 loss ppo:  -0.01494, loss val: 0.04660
[2022-12-06 16:50:15,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:50:15,807] [INFO] [optimize] Finished learning.
