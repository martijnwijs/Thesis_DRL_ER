[2022-12-06 18:17:44,316] [INFO] [optimize] Starting learning
[2022-12-06 18:17:44,322] [INFO] [optimize] Starting learning process..
[2022-12-06 18:17:44,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:17:44,391] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:17:50,493] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:17:54,409] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:17:58,452] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:18:02,276] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:18:06,305] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:18:10,446] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:18:14,517] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:18:18,402] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:18:22,600] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:18:26,373] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44769066085356746
[2022-12-06 18:18:26,373] [INFO] [runner_train_mujoco] Average state value: -0.2165692403508971
[2022-12-06 18:18:26,373] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 18:18:26,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.54154
[2022-12-06 18:18:26,473] [INFO] [controller] EPOCH 2 loss ppo:  -0.03385, loss val: 0.49986
[2022-12-06 18:18:26,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.03656, loss val: 0.44404
[2022-12-06 18:18:26,558] [INFO] [controller] EPOCH 4 loss ppo:  -0.04113, loss val: 0.38733
[2022-12-06 18:18:26,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:18:26,721] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:18:26,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:18:30,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:18:34,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:18:38,848] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:18:43,130] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:18:47,490] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:18:51,462] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:18:55,621] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:18:59,239] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:19:02,988] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:19:06,902] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4644354340319312
[2022-12-06 18:19:06,902] [INFO] [runner_train_mujoco] Average state value: -0.038584767442196605
[2022-12-06 18:19:06,902] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 18:19:06,954] [INFO] [controller] EPOCH 1 loss ppo:  -0.01514, loss val: 0.26925
[2022-12-06 18:19:06,999] [INFO] [controller] EPOCH 2 loss ppo:  -0.02417, loss val: 0.23684
[2022-12-06 18:19:07,055] [INFO] [controller] EPOCH 3 loss ppo:  -0.03092, loss val: 0.19698
[2022-12-06 18:19:07,102] [INFO] [controller] EPOCH 4 loss ppo:  -0.03522, loss val: 0.17427
[2022-12-06 18:19:07,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:19:07,265] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:19:07,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:19:11,136] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:19:14,838] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:19:18,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:19:22,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:19:26,879] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:19:30,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:19:34,938] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:19:38,550] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:19:42,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:19:46,278] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4744330828732973
[2022-12-06 18:19:46,278] [INFO] [runner_train_mujoco] Average state value: 0.13763838700329264
[2022-12-06 18:19:46,278] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 18:19:46,333] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.24200
[2022-12-06 18:19:46,374] [INFO] [controller] EPOCH 2 loss ppo:  -0.02295, loss val: 0.20639
[2022-12-06 18:19:46,417] [INFO] [controller] EPOCH 3 loss ppo:  -0.02873, loss val: 0.17404
[2022-12-06 18:19:46,459] [INFO] [controller] EPOCH 4 loss ppo:  -0.03087, loss val: 0.14088
[2022-12-06 18:19:46,467] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:19:46,627] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:19:46,628] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:19:50,737] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:19:54,481] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:19:58,710] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:20:02,841] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:20:06,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:20:10,480] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:20:14,370] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:20:18,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:20:22,098] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:20:25,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39584152989158355
[2022-12-06 18:20:25,912] [INFO] [runner_train_mujoco] Average state value: 0.29569219754636283
[2022-12-06 18:20:25,912] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 18:20:25,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01495, loss val: 0.13054
[2022-12-06 18:20:26,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.03127, loss val: 0.11487
[2022-12-06 18:20:26,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.03565, loss val: 0.09016
[2022-12-06 18:20:26,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.03674, loss val: 0.07210
[2022-12-06 18:20:26,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:20:26,261] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:20:26,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:20:30,250] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:20:34,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:20:38,497] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:20:42,635] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:20:46,642] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:20:50,653] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:20:54,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:20:58,445] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:21:02,524] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:21:06,551] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5096366897909488
[2022-12-06 18:21:06,551] [INFO] [runner_train_mujoco] Average state value: 0.4625270265166958
[2022-12-06 18:21:06,551] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 18:21:06,605] [INFO] [controller] EPOCH 1 loss ppo:  -0.01146, loss val: 0.05830
[2022-12-06 18:21:06,650] [INFO] [controller] EPOCH 2 loss ppo:  -0.02811, loss val: 0.04596
[2022-12-06 18:21:06,704] [INFO] [controller] EPOCH 3 loss ppo:  -0.02961, loss val: 0.04612
[2022-12-06 18:21:06,743] [INFO] [controller] EPOCH 4 loss ppo:  -0.03240, loss val: 0.04079
[2022-12-06 18:21:06,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:21:06,921] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:21:06,921] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:21:10,678] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:21:14,626] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:21:18,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:21:22,590] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:21:26,804] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:21:30,704] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:21:34,858] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:21:38,921] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:21:43,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:21:46,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5602239102387133
[2022-12-06 18:21:46,986] [INFO] [runner_train_mujoco] Average state value: 0.5903193833033245
[2022-12-06 18:21:46,986] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 18:21:47,042] [INFO] [controller] EPOCH 1 loss ppo:  -0.01058, loss val: 0.03367
[2022-12-06 18:21:47,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.01962, loss val: 0.03192
[2022-12-06 18:21:47,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.02314, loss val: 0.02835
[2022-12-06 18:21:47,182] [INFO] [controller] EPOCH 4 loss ppo:  -0.02866, loss val: 0.02585
[2022-12-06 18:21:47,192] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:21:47,356] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:21:47,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:21:51,158] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:21:55,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:21:59,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:22:03,645] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:22:07,783] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:22:11,744] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:22:15,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:22:19,702] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:22:24,017] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:22:28,062] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5720504588990749
[2022-12-06 18:22:28,063] [INFO] [runner_train_mujoco] Average state value: 0.628641791065534
[2022-12-06 18:22:28,063] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 18:22:28,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.00865, loss val: 0.03960
[2022-12-06 18:22:28,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.02278, loss val: 0.03837
[2022-12-06 18:22:28,208] [INFO] [controller] EPOCH 3 loss ppo:  -0.02917, loss val: 0.03722
[2022-12-06 18:22:28,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.03488, loss val: 0.03657
[2022-12-06 18:22:28,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:22:28,410] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:22:28,410] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:22:32,993] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:22:37,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:22:41,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:22:45,837] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:22:49,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:22:54,237] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:23:00,035] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:23:05,213] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:23:10,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:23:16,124] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5415045850395307
[2022-12-06 18:23:16,124] [INFO] [runner_train_mujoco] Average state value: 0.5991530515154203
[2022-12-06 18:23:16,125] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 18:23:16,189] [INFO] [controller] EPOCH 1 loss ppo:  -0.00928, loss val: 0.03678
[2022-12-06 18:23:16,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.02324, loss val: 0.03304
[2022-12-06 18:23:16,293] [INFO] [controller] EPOCH 3 loss ppo:  -0.02834, loss val: 0.03408
[2022-12-06 18:23:16,343] [INFO] [controller] EPOCH 4 loss ppo:  -0.03155, loss val: 0.03440
[2022-12-06 18:23:16,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:23:16,526] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:23:16,526] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:23:21,578] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:23:26,697] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:23:32,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:23:37,720] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:23:42,317] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:23:46,597] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:23:50,919] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:23:55,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:24:00,239] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:24:04,586] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6163026585495845
[2022-12-06 18:24:04,586] [INFO] [runner_train_mujoco] Average state value: 0.5663784149487814
[2022-12-06 18:24:04,586] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 18:24:04,753] [INFO] [controller] EPOCH 1 loss ppo:  -0.00957, loss val: 0.03410
[2022-12-06 18:24:04,803] [INFO] [controller] EPOCH 2 loss ppo:  -0.02379, loss val: 0.03336
[2022-12-06 18:24:04,855] [INFO] [controller] EPOCH 3 loss ppo:  -0.02730, loss val: 0.03324
[2022-12-06 18:24:04,928] [INFO] [controller] EPOCH 4 loss ppo:  -0.03099, loss val: 0.03337
[2022-12-06 18:24:04,944] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:24:05,137] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:24:05,138] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:24:09,139] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:24:13,346] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:24:18,099] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:24:22,610] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:24:26,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:24:30,951] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:24:35,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:24:38,885] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:24:43,002] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:24:47,206] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6967725557778597
[2022-12-06 18:24:47,207] [INFO] [runner_train_mujoco] Average state value: 0.5571142302354177
[2022-12-06 18:24:47,207] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 18:24:47,261] [INFO] [controller] EPOCH 1 loss ppo:  -0.01056, loss val: 0.03259
[2022-12-06 18:24:47,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.02837, loss val: 0.03026
[2022-12-06 18:24:47,362] [INFO] [controller] EPOCH 3 loss ppo:  -0.03194, loss val: 0.02999
[2022-12-06 18:24:47,418] [INFO] [controller] EPOCH 4 loss ppo:  -0.03454, loss val: 0.03667
[2022-12-06 18:24:47,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:24:47,632] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:24:47,633] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:24:52,140] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:24:56,367] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:25:00,397] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:25:04,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:25:08,952] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:25:12,934] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:25:17,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:25:21,191] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:25:25,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:25:29,106] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9189769778044992
[2022-12-06 18:25:29,107] [INFO] [runner_train_mujoco] Average state value: 0.5692256674965223
[2022-12-06 18:25:29,107] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 18:25:29,160] [INFO] [controller] EPOCH 1 loss ppo:  -0.01207, loss val: 0.03089
[2022-12-06 18:25:29,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.02291, loss val: 0.03219
[2022-12-06 18:25:29,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.02665, loss val: 0.03277
[2022-12-06 18:25:29,299] [INFO] [controller] EPOCH 4 loss ppo:  -0.03052, loss val: 0.03260
[2022-12-06 18:25:29,309] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:25:29,475] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:25:29,476] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:25:33,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:25:37,426] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:25:41,573] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:25:45,958] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:25:49,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:25:53,696] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:25:57,843] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:26:01,868] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:26:05,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:26:09,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2330258851716003
[2022-12-06 18:26:09,975] [INFO] [runner_train_mujoco] Average state value: 0.5769138961633046
[2022-12-06 18:26:09,975] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 18:26:10,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01197, loss val: 0.03651
[2022-12-06 18:26:10,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.02518, loss val: 0.03518
[2022-12-06 18:26:10,128] [INFO] [controller] EPOCH 3 loss ppo:  -0.02895, loss val: 0.03487
[2022-12-06 18:26:10,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.03332, loss val: 0.03313
[2022-12-06 18:26:10,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:26:10,340] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:26:10,341] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:26:14,435] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:26:18,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:26:22,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:26:26,281] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:26:29,889] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:26:33,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:26:38,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:26:44,987] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:26:49,580] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:26:54,343] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6109775117197205
[2022-12-06 18:26:54,343] [INFO] [runner_train_mujoco] Average state value: 0.51687453186512
[2022-12-06 18:26:54,344] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 18:26:54,410] [INFO] [controller] EPOCH 1 loss ppo:  -0.01646, loss val: 0.03877
[2022-12-06 18:26:54,459] [INFO] [controller] EPOCH 2 loss ppo:  -0.03012, loss val: 0.03938
[2022-12-06 18:26:54,512] [INFO] [controller] EPOCH 3 loss ppo:  -0.02770, loss val: 0.03923
[2022-12-06 18:26:54,565] [INFO] [controller] EPOCH 4 loss ppo:  -0.03848, loss val: 0.03906
[2022-12-06 18:26:54,575] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:26:54,758] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:26:54,758] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:26:59,643] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:27:04,377] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:27:08,882] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:27:13,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:27:17,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:27:22,581] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:27:27,262] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:27:31,480] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:27:37,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:27:44,394] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8486911553535292
[2022-12-06 18:27:44,395] [INFO] [runner_train_mujoco] Average state value: 0.5057501263221105
[2022-12-06 18:27:44,395] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 18:27:44,532] [INFO] [controller] EPOCH 1 loss ppo:  -0.01572, loss val: 0.03934
[2022-12-06 18:27:44,587] [INFO] [controller] EPOCH 2 loss ppo:  -0.02351, loss val: 0.03697
[2022-12-06 18:27:44,671] [INFO] [controller] EPOCH 3 loss ppo:  -0.02990, loss val: 0.03707
[2022-12-06 18:27:44,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.03620, loss val: 0.03689
[2022-12-06 18:27:44,741] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:27:44,934] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:27:44,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:27:50,454] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:27:56,106] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:28:01,419] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:28:07,145] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:28:12,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:28:17,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:28:23,069] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:28:28,449] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:28:34,094] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:28:39,374] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5624197843997134
[2022-12-06 18:28:39,374] [INFO] [runner_train_mujoco] Average state value: 0.5209765122731527
[2022-12-06 18:28:39,374] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 18:28:39,435] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.03906
[2022-12-06 18:28:39,483] [INFO] [controller] EPOCH 2 loss ppo:  -0.02845, loss val: 0.03897
[2022-12-06 18:28:39,603] [INFO] [controller] EPOCH 3 loss ppo:  -0.03497, loss val: 0.03949
[2022-12-06 18:28:39,663] [INFO] [controller] EPOCH 4 loss ppo:  -0.04016, loss val: 0.03881
[2022-12-06 18:28:39,674] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:28:39,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:28:39,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:28:45,549] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:28:51,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:28:55,948] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:29:01,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:29:07,371] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:29:12,489] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:29:18,248] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:29:24,157] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:29:29,966] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:29:35,773] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0354830497963574
[2022-12-06 18:29:35,773] [INFO] [runner_train_mujoco] Average state value: 0.5160592365662258
[2022-12-06 18:29:35,773] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 18:29:35,845] [INFO] [controller] EPOCH 1 loss ppo:  -0.01541, loss val: 0.04568
[2022-12-06 18:29:35,908] [INFO] [controller] EPOCH 2 loss ppo:  -0.02855, loss val: 0.04568
[2022-12-06 18:29:35,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.02758, loss val: 0.04554
[2022-12-06 18:29:36,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.03633, loss val: 0.04539
[2022-12-06 18:29:36,031] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:29:36,222] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:29:36,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:29:41,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:29:47,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:29:52,917] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:29:58,470] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:30:04,044] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:30:09,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:30:15,336] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:30:20,891] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:30:26,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:30:31,680] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.300282187138782
[2022-12-06 18:30:31,681] [INFO] [runner_train_mujoco] Average state value: 0.5285182658235232
[2022-12-06 18:30:31,681] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 18:30:31,750] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.03533
[2022-12-06 18:30:31,821] [INFO] [controller] EPOCH 2 loss ppo:  -0.02564, loss val: 0.03954
[2022-12-06 18:30:31,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.02994, loss val: 0.03504
[2022-12-06 18:30:31,960] [INFO] [controller] EPOCH 4 loss ppo:  -0.03857, loss val: 0.03616
[2022-12-06 18:30:31,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:30:32,166] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:30:32,166] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:30:38,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:30:43,365] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:30:49,004] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:30:54,576] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:30:59,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:31:05,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:31:11,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:31:16,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:31:21,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:31:26,510] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1610560161970107
[2022-12-06 18:31:26,510] [INFO] [runner_train_mujoco] Average state value: 0.49948791221777594
[2022-12-06 18:31:26,510] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 18:31:26,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.02405
[2022-12-06 18:31:26,628] [INFO] [controller] EPOCH 2 loss ppo:  -0.02627, loss val: 0.02381
[2022-12-06 18:31:26,711] [INFO] [controller] EPOCH 3 loss ppo:  -0.02930, loss val: 0.02496
[2022-12-06 18:31:26,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.03475, loss val: 0.02434
[2022-12-06 18:31:26,787] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:31:26,975] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:31:26,976] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:31:32,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:31:37,177] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:31:42,459] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:31:47,780] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:31:52,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:31:58,347] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:32:03,611] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:32:08,857] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:32:13,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:32:19,310] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.518080238092527
[2022-12-06 18:32:19,310] [INFO] [runner_train_mujoco] Average state value: 0.49369296489159264
[2022-12-06 18:32:19,310] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 18:32:19,374] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.03231
[2022-12-06 18:32:19,438] [INFO] [controller] EPOCH 2 loss ppo:  -0.02748, loss val: 0.03277
[2022-12-06 18:32:19,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.03346, loss val: 0.03183
[2022-12-06 18:32:19,593] [INFO] [controller] EPOCH 4 loss ppo:  -0.03961, loss val: 0.03532
[2022-12-06 18:32:19,604] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:32:19,785] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:32:19,786] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:32:24,797] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:32:29,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:32:34,697] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:32:39,820] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:32:44,724] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:32:49,531] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:32:54,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:32:59,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:33:04,477] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:33:09,601] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.823130807881984
[2022-12-06 18:33:09,602] [INFO] [runner_train_mujoco] Average state value: 0.48999645084142684
[2022-12-06 18:33:09,602] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 18:33:09,662] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.03913
[2022-12-06 18:33:09,711] [INFO] [controller] EPOCH 2 loss ppo:  -0.02556, loss val: 0.03900
[2022-12-06 18:33:09,773] [INFO] [controller] EPOCH 3 loss ppo:  -0.03010, loss val: 0.03869
[2022-12-06 18:33:09,829] [INFO] [controller] EPOCH 4 loss ppo:  -0.03512, loss val: 0.03819
[2022-12-06 18:33:09,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:33:10,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:33:10,021] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:33:14,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:33:19,732] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:33:25,076] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:33:30,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:33:34,952] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:33:39,914] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:33:44,426] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:33:48,901] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:33:53,816] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:33:58,650] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8683463278137333
[2022-12-06 18:33:58,650] [INFO] [runner_train_mujoco] Average state value: 0.46248116431633635
[2022-12-06 18:33:58,651] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 18:33:58,716] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.05157
[2022-12-06 18:33:58,761] [INFO] [controller] EPOCH 2 loss ppo:  -0.02534, loss val: 0.05154
[2022-12-06 18:33:58,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.02937, loss val: 0.04831
[2022-12-06 18:33:58,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.03706, loss val: 0.04760
[2022-12-06 18:33:58,869] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:33:59,047] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:33:59,048] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:34:04,300] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:34:09,340] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:34:14,098] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:34:18,895] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:34:24,293] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:34:29,631] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:34:34,874] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:34:39,944] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:34:44,907] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:34:49,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.851590983117808
[2022-12-06 18:34:49,907] [INFO] [runner_train_mujoco] Average state value: 0.4834280252854029
[2022-12-06 18:34:49,907] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 18:34:50,049] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.04656
[2022-12-06 18:34:50,114] [INFO] [controller] EPOCH 2 loss ppo:  -0.02579, loss val: 0.04550
[2022-12-06 18:34:50,184] [INFO] [controller] EPOCH 3 loss ppo:  -0.02821, loss val: 0.04464
[2022-12-06 18:34:50,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.03341, loss val: 0.04424
[2022-12-06 18:34:50,271] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:34:50,529] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:34:50,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:34:59,434] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:35:05,653] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:35:10,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:35:15,180] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:35:20,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:35:24,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:35:29,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:35:34,731] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:35:39,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:35:45,247] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.946479624166691
[2022-12-06 18:35:45,248] [INFO] [runner_train_mujoco] Average state value: 0.5164153818885485
[2022-12-06 18:35:45,248] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 18:35:45,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04648
[2022-12-06 18:35:45,364] [INFO] [controller] EPOCH 2 loss ppo:  -0.02444, loss val: 0.04506
[2022-12-06 18:35:45,439] [INFO] [controller] EPOCH 3 loss ppo:  -0.02445, loss val: 0.04475
[2022-12-06 18:35:45,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.03009, loss val: 0.04435
[2022-12-06 18:35:45,497] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:35:45,685] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:35:45,686] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:35:50,726] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:35:56,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:36:01,001] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:36:06,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:36:11,203] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:36:16,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:36:23,673] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:36:31,282] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:36:38,150] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:36:45,631] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2085673768723253
[2022-12-06 18:36:45,632] [INFO] [runner_train_mujoco] Average state value: 0.5054711744586626
[2022-12-06 18:36:45,632] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 18:36:45,841] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04339
[2022-12-06 18:36:45,972] [INFO] [controller] EPOCH 2 loss ppo:  -0.01817, loss val: 0.04171
[2022-12-06 18:36:46,095] [INFO] [controller] EPOCH 3 loss ppo:  -0.02375, loss val: 0.04124
[2022-12-06 18:36:46,219] [INFO] [controller] EPOCH 4 loss ppo:  -0.03244, loss val: 0.04033
[2022-12-06 18:36:46,233] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:36:46,469] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:36:46,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:36:54,700] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:37:02,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:37:08,750] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:37:15,040] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:37:22,000] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:37:30,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:37:36,664] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:37:43,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:37:50,137] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:37:58,536] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.398289160434758
[2022-12-06 18:37:58,538] [INFO] [runner_train_mujoco] Average state value: 0.4416271209319433
[2022-12-06 18:37:58,542] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 18:37:59,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01055, loss val: 0.04169
[2022-12-06 18:37:59,682] [INFO] [controller] EPOCH 2 loss ppo:  -0.01917, loss val: 0.04165
[2022-12-06 18:37:59,919] [INFO] [controller] EPOCH 3 loss ppo:  -0.02357, loss val: 0.04218
[2022-12-06 18:38:00,350] [INFO] [controller] EPOCH 4 loss ppo:  -0.03394, loss val: 0.04264
[2022-12-06 18:38:00,368] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:38:00,663] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:38:00,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:38:08,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:38:14,885] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:38:21,360] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:38:27,957] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:38:34,843] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:38:41,796] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:38:50,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:38:57,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:39:04,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:39:11,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5931021788540867
[2022-12-06 18:39:11,368] [INFO] [runner_train_mujoco] Average state value: 0.4154356874426206
[2022-12-06 18:39:11,368] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 18:39:11,459] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.05090
[2022-12-06 18:39:11,539] [INFO] [controller] EPOCH 2 loss ppo:  -0.01984, loss val: 0.05104
[2022-12-06 18:39:11,607] [INFO] [controller] EPOCH 3 loss ppo:  -0.02593, loss val: 0.04941
[2022-12-06 18:39:11,675] [INFO] [controller] EPOCH 4 loss ppo:  -0.02925, loss val: 0.04735
[2022-12-06 18:39:11,689] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:39:11,901] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:39:11,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:39:18,177] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:39:24,969] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:39:31,679] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:39:38,352] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:39:45,231] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:39:51,861] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:39:57,901] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:40:04,707] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:40:12,113] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:40:19,705] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6389870866517113
[2022-12-06 18:40:19,706] [INFO] [runner_train_mujoco] Average state value: 0.4660597013632456
[2022-12-06 18:40:19,706] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 18:40:19,804] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.05226
[2022-12-06 18:40:19,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.02366, loss val: 0.05171
[2022-12-06 18:40:19,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.02834, loss val: 0.05192
[2022-12-06 18:40:19,991] [INFO] [controller] EPOCH 4 loss ppo:  -0.03579, loss val: 0.05283
[2022-12-06 18:40:20,004] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:40:20,203] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:40:20,204] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:40:27,785] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:40:34,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:40:42,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:40:53,279] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:41:05,708] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:41:13,860] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:41:20,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:41:26,165] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:41:31,942] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:41:38,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7478440675552065
[2022-12-06 18:41:38,465] [INFO] [runner_train_mujoco] Average state value: 0.5189623509248097
[2022-12-06 18:41:38,465] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 18:41:38,542] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.03806
[2022-12-06 18:41:38,605] [INFO] [controller] EPOCH 2 loss ppo:  -0.02216, loss val: 0.03857
[2022-12-06 18:41:38,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.02646, loss val: 0.03761
[2022-12-06 18:41:38,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.03163, loss val: 0.03650
[2022-12-06 18:41:38,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:41:38,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:41:38,960] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:41:45,033] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:41:51,125] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:41:56,917] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:42:02,577] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:42:08,120] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:42:13,496] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:42:19,281] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:42:25,137] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:42:31,180] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:42:38,288] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.686323781071149
[2022-12-06 18:42:38,289] [INFO] [runner_train_mujoco] Average state value: 0.4990880720218023
[2022-12-06 18:42:38,290] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 18:42:38,569] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.05045
[2022-12-06 18:42:38,694] [INFO] [controller] EPOCH 2 loss ppo:  -0.02543, loss val: 0.04772
[2022-12-06 18:42:38,791] [INFO] [controller] EPOCH 3 loss ppo:  -0.02637, loss val: 0.04697
[2022-12-06 18:42:38,858] [INFO] [controller] EPOCH 4 loss ppo:  -0.03200, loss val: 0.04461
[2022-12-06 18:42:38,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:42:39,073] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:42:39,074] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:42:45,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:42:53,767] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:43:00,853] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:43:07,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:43:14,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:43:21,040] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:43:27,986] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:43:34,322] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:43:41,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:43:47,807] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5843671613591477
[2022-12-06 18:43:47,807] [INFO] [runner_train_mujoco] Average state value: 0.4373071921269099
[2022-12-06 18:43:47,807] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 18:43:47,948] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.05193
[2022-12-06 18:43:48,044] [INFO] [controller] EPOCH 2 loss ppo:  -0.02013, loss val: 0.05066
[2022-12-06 18:43:48,122] [INFO] [controller] EPOCH 3 loss ppo:  -0.02430, loss val: 0.05092
[2022-12-06 18:43:48,210] [INFO] [controller] EPOCH 4 loss ppo:  -0.03325, loss val: 0.05315
[2022-12-06 18:43:48,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:43:48,447] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:43:48,447] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:43:55,902] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:44:02,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:44:09,250] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:44:16,300] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:44:22,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:44:29,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:44:35,998] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:44:42,158] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:44:48,352] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:44:54,599] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.910985954419071
[2022-12-06 18:44:54,599] [INFO] [runner_train_mujoco] Average state value: 0.4209490955670675
[2022-12-06 18:44:54,599] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 18:44:54,684] [INFO] [controller] EPOCH 1 loss ppo:  -0.01261, loss val: 0.04036
[2022-12-06 18:44:54,761] [INFO] [controller] EPOCH 2 loss ppo:  -0.01715, loss val: 0.04033
[2022-12-06 18:44:54,832] [INFO] [controller] EPOCH 3 loss ppo:  -0.02186, loss val: 0.04078
[2022-12-06 18:44:54,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.03281, loss val: 0.04159
[2022-12-06 18:44:54,936] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:44:55,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:44:55,167] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:45:02,042] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:45:09,063] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:45:15,323] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:45:21,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:45:28,958] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:45:35,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:45:42,260] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:45:48,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:45:55,542] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:46:02,035] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.885355098776902
[2022-12-06 18:46:02,035] [INFO] [runner_train_mujoco] Average state value: 0.4326627246936162
[2022-12-06 18:46:02,035] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 18:46:02,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.00970, loss val: 0.03703
[2022-12-06 18:46:02,214] [INFO] [controller] EPOCH 2 loss ppo:  -0.01544, loss val: 0.03726
[2022-12-06 18:46:02,339] [INFO] [controller] EPOCH 3 loss ppo:  -0.01996, loss val: 0.03758
[2022-12-06 18:46:02,429] [INFO] [controller] EPOCH 4 loss ppo:  -0.03019, loss val: 0.03709
[2022-12-06 18:46:02,441] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:46:02,676] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:46:02,677] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:46:09,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:46:16,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:46:22,736] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:46:29,074] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:46:35,339] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:46:42,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:46:48,700] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:46:55,463] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:47:01,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:47:08,637] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9416097745560896
[2022-12-06 18:47:08,638] [INFO] [runner_train_mujoco] Average state value: 0.4393482751250267
[2022-12-06 18:47:08,638] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 18:47:08,727] [INFO] [controller] EPOCH 1 loss ppo:  -0.00778, loss val: 0.04622
[2022-12-06 18:47:08,808] [INFO] [controller] EPOCH 2 loss ppo:  -0.01454, loss val: 0.04547
[2022-12-06 18:47:08,879] [INFO] [controller] EPOCH 3 loss ppo:  -0.02001, loss val: 0.04484
[2022-12-06 18:47:08,950] [INFO] [controller] EPOCH 4 loss ppo:  -0.02661, loss val: 0.04430
[2022-12-06 18:47:08,970] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:47:09,192] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:47:09,192] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:47:15,823] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:47:22,870] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:47:29,415] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:47:36,030] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:47:43,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:47:49,565] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:47:56,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:48:02,783] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:48:09,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:48:15,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.118455092668727
[2022-12-06 18:48:15,780] [INFO] [runner_train_mujoco] Average state value: 0.41723385937015206
[2022-12-06 18:48:15,780] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 18:48:15,877] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.02775
[2022-12-06 18:48:15,939] [INFO] [controller] EPOCH 2 loss ppo:  -0.01770, loss val: 0.02757
[2022-12-06 18:48:16,014] [INFO] [controller] EPOCH 3 loss ppo:  -0.02589, loss val: 0.02738
[2022-12-06 18:48:16,076] [INFO] [controller] EPOCH 4 loss ppo:  -0.02814, loss val: 0.02749
[2022-12-06 18:48:16,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:48:16,312] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:48:16,313] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:48:23,213] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:48:29,922] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:48:36,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:48:42,450] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:48:48,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:48:55,072] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:49:01,433] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:49:08,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:49:14,509] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:49:20,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.142012954588776
[2022-12-06 18:49:20,676] [INFO] [runner_train_mujoco] Average state value: 0.39158979469537736
[2022-12-06 18:49:20,676] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 18:49:20,780] [INFO] [controller] EPOCH 1 loss ppo:  -0.00968, loss val: 0.05579
[2022-12-06 18:49:20,889] [INFO] [controller] EPOCH 2 loss ppo:  -0.01622, loss val: 0.05529
[2022-12-06 18:49:20,960] [INFO] [controller] EPOCH 3 loss ppo:  -0.02121, loss val: 0.05352
[2022-12-06 18:49:21,038] [INFO] [controller] EPOCH 4 loss ppo:  -0.02598, loss val: 0.05221
[2022-12-06 18:49:21,051] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:49:21,264] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:49:21,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:49:27,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:49:34,910] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:49:41,214] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:49:47,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:49:53,957] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:50:00,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:50:07,112] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:50:13,646] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:50:19,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:50:25,871] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9925856716687553
[2022-12-06 18:50:25,871] [INFO] [runner_train_mujoco] Average state value: 0.42692880753676093
[2022-12-06 18:50:25,872] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 18:50:25,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.03571
[2022-12-06 18:50:26,030] [INFO] [controller] EPOCH 2 loss ppo:  -0.01632, loss val: 0.03645
[2022-12-06 18:50:26,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.02165, loss val: 0.03547
[2022-12-06 18:50:26,194] [INFO] [controller] EPOCH 4 loss ppo:  -0.02804, loss val: 0.03828
[2022-12-06 18:50:26,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:50:26,405] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:50:26,406] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:50:32,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:50:39,390] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:50:46,322] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:50:52,673] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:50:59,449] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:51:05,604] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:51:11,942] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:51:18,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:51:24,907] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:51:31,396] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.167844448436891
[2022-12-06 18:51:31,396] [INFO] [runner_train_mujoco] Average state value: 0.4756394599278768
[2022-12-06 18:51:31,397] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 18:51:31,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.04121
[2022-12-06 18:51:31,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.01760, loss val: 0.04246
[2022-12-06 18:51:31,671] [INFO] [controller] EPOCH 3 loss ppo:  -0.02348, loss val: 0.04207
[2022-12-06 18:51:31,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.03188, loss val: 0.04281
[2022-12-06 18:51:31,756] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:51:31,987] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:51:31,987] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:51:38,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:51:44,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:51:51,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:51:57,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:52:04,116] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:52:10,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:52:17,470] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:52:23,868] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:52:29,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:52:36,219] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.260719232557598
[2022-12-06 18:52:36,219] [INFO] [runner_train_mujoco] Average state value: 0.4925369458595911
[2022-12-06 18:52:36,219] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 18:52:36,313] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.05200
[2022-12-06 18:52:36,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.01796, loss val: 0.05092
[2022-12-06 18:52:36,451] [INFO] [controller] EPOCH 3 loss ppo:  -0.01828, loss val: 0.04926
[2022-12-06 18:52:36,518] [INFO] [controller] EPOCH 4 loss ppo:  -0.02797, loss val: 0.04783
[2022-12-06 18:52:36,532] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:52:36,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:52:36,739] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:52:42,923] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:52:49,650] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:52:56,429] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:53:02,491] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:53:09,217] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:53:15,356] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:53:21,750] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:53:28,389] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:53:34,714] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:53:41,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.335179743388823
[2022-12-06 18:53:41,066] [INFO] [runner_train_mujoco] Average state value: 0.45272433324654904
[2022-12-06 18:53:41,066] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 18:53:41,165] [INFO] [controller] EPOCH 1 loss ppo:  -0.01168, loss val: 0.05305
[2022-12-06 18:53:41,233] [INFO] [controller] EPOCH 2 loss ppo:  -0.01849, loss val: 0.05211
[2022-12-06 18:53:41,313] [INFO] [controller] EPOCH 3 loss ppo:  -0.02422, loss val: 0.05279
[2022-12-06 18:53:41,393] [INFO] [controller] EPOCH 4 loss ppo:  -0.03100, loss val: 0.05354
[2022-12-06 18:53:41,407] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:53:41,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:53:41,620] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:53:47,972] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:53:54,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:54:00,924] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:54:07,459] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:54:13,582] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:54:19,698] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:54:25,868] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:54:32,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:54:38,753] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:54:45,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.421606407357203
[2022-12-06 18:54:45,365] [INFO] [runner_train_mujoco] Average state value: 0.4201070809563001
[2022-12-06 18:54:45,365] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 18:54:45,447] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.04700
[2022-12-06 18:54:45,528] [INFO] [controller] EPOCH 2 loss ppo:  -0.01519, loss val: 0.04851
[2022-12-06 18:54:45,601] [INFO] [controller] EPOCH 3 loss ppo:  -0.01950, loss val: 0.04763
[2022-12-06 18:54:45,663] [INFO] [controller] EPOCH 4 loss ppo:  -0.02294, loss val: 0.04847
[2022-12-06 18:54:45,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:54:45,913] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:54:45,913] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:54:51,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:54:58,406] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:55:04,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:55:11,034] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:55:17,921] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:55:24,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:55:31,191] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:55:37,635] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:55:44,052] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:55:50,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.560852907448519
[2022-12-06 18:55:50,271] [INFO] [runner_train_mujoco] Average state value: 0.4279678076505661
[2022-12-06 18:55:50,271] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 18:55:50,355] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.05077
[2022-12-06 18:55:50,425] [INFO] [controller] EPOCH 2 loss ppo:  -0.01676, loss val: 0.04921
[2022-12-06 18:55:50,513] [INFO] [controller] EPOCH 3 loss ppo:  -0.01925, loss val: 0.04964
[2022-12-06 18:55:50,589] [INFO] [controller] EPOCH 4 loss ppo:  -0.02306, loss val: 0.04955
[2022-12-06 18:55:50,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:55:50,833] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:55:50,833] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:55:57,252] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:56:03,749] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:56:09,821] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:56:16,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:56:22,428] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:56:28,775] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:56:35,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:56:41,909] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:56:47,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:56:53,471] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.596988402866836
[2022-12-06 18:56:53,471] [INFO] [runner_train_mujoco] Average state value: 0.44596843614180876
[2022-12-06 18:56:53,471] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 18:56:53,562] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.04972
[2022-12-06 18:56:53,642] [INFO] [controller] EPOCH 2 loss ppo:  -0.01940, loss val: 0.05161
[2022-12-06 18:56:53,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.02283, loss val: 0.05193
[2022-12-06 18:56:53,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.02981, loss val: 0.04987
[2022-12-06 18:56:53,815] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:56:54,043] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:56:54,043] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:56:59,841] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:57:05,895] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:57:11,798] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:57:17,173] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:57:22,487] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:57:29,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:57:35,493] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:57:41,664] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:57:47,747] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:57:54,158] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.524168895566804
[2022-12-06 18:57:54,158] [INFO] [runner_train_mujoco] Average state value: 0.4575299866298835
[2022-12-06 18:57:54,158] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 18:57:54,274] [INFO] [controller] EPOCH 1 loss ppo:  -0.01147, loss val: 0.04027
[2022-12-06 18:57:54,360] [INFO] [controller] EPOCH 2 loss ppo:  -0.01697, loss val: 0.04010
[2022-12-06 18:57:54,431] [INFO] [controller] EPOCH 3 loss ppo:  -0.01915, loss val: 0.04127
[2022-12-06 18:57:54,512] [INFO] [controller] EPOCH 4 loss ppo:  -0.02618, loss val: 0.03995
[2022-12-06 18:57:54,526] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:57:54,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:57:54,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:58:01,234] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:58:08,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:58:14,293] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:58:20,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:58:26,948] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:58:33,563] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:58:39,898] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:58:45,909] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:58:52,008] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:58:58,128] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.828087562224999
[2022-12-06 18:58:58,129] [INFO] [runner_train_mujoco] Average state value: 0.45937355655431744
[2022-12-06 18:58:58,129] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 18:58:58,211] [INFO] [controller] EPOCH 1 loss ppo:  -0.01086, loss val: 0.04548
[2022-12-06 18:58:58,285] [INFO] [controller] EPOCH 2 loss ppo:  -0.01524, loss val: 0.04628
[2022-12-06 18:58:58,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.01801, loss val: 0.04763
[2022-12-06 18:58:58,430] [INFO] [controller] EPOCH 4 loss ppo:  -0.02262, loss val: 0.04489
[2022-12-06 18:58:58,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:58:58,669] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:58:58,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:59:05,063] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:59:11,580] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:59:17,535] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:59:23,667] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:59:30,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:59:36,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:59:43,750] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:59:50,823] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:59:57,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:00:05,125] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.487510124679505
[2022-12-06 19:00:05,126] [INFO] [runner_train_mujoco] Average state value: 0.45158368301391605
[2022-12-06 19:00:05,126] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 19:00:05,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01215, loss val: 0.04046
[2022-12-06 19:00:05,342] [INFO] [controller] EPOCH 2 loss ppo:  -0.01542, loss val: 0.03874
[2022-12-06 19:00:05,435] [INFO] [controller] EPOCH 3 loss ppo:  -0.01795, loss val: 0.03847
[2022-12-06 19:00:05,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.02256, loss val: 0.03888
[2022-12-06 19:00:05,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:00:05,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:00:05,807] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:00:14,186] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:00:21,038] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:00:27,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:00:34,374] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:00:41,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:00:48,068] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:00:54,753] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:01:01,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:01:09,103] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:01:15,948] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.697743206940047
[2022-12-06 19:01:15,948] [INFO] [runner_train_mujoco] Average state value: 0.43535846638679504
[2022-12-06 19:01:15,949] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 19:01:16,041] [INFO] [controller] EPOCH 1 loss ppo:  -0.01110, loss val: 0.05400
[2022-12-06 19:01:16,144] [INFO] [controller] EPOCH 2 loss ppo:  -0.01779, loss val: 0.05351
[2022-12-06 19:01:16,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.02164, loss val: 0.05296
[2022-12-06 19:01:16,330] [INFO] [controller] EPOCH 4 loss ppo:  -0.02758, loss val: 0.05163
[2022-12-06 19:01:16,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:01:16,562] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:01:16,562] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:01:23,378] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:01:30,294] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:01:37,055] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:01:43,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:01:51,479] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:01:58,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:02:05,417] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:02:12,310] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:02:18,996] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:02:26,096] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.757735735840263
[2022-12-06 19:02:26,096] [INFO] [runner_train_mujoco] Average state value: 0.42763352786501246
[2022-12-06 19:02:26,096] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 19:02:26,211] [INFO] [controller] EPOCH 1 loss ppo:  -0.01110, loss val: 0.04429
[2022-12-06 19:02:26,492] [INFO] [controller] EPOCH 2 loss ppo:  -0.01635, loss val: 0.04392
[2022-12-06 19:02:26,576] [INFO] [controller] EPOCH 3 loss ppo:  -0.02228, loss val: 0.04243
[2022-12-06 19:02:26,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.02574, loss val: 0.04217
[2022-12-06 19:02:26,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:02:27,119] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:02:27,120] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:02:33,827] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:02:41,275] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:02:48,596] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:02:55,592] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:03:02,327] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:03:09,310] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:03:16,178] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:03:23,245] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:03:30,355] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:03:37,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.9849409436908605
[2022-12-06 19:03:37,344] [INFO] [runner_train_mujoco] Average state value: 0.4358023440440496
[2022-12-06 19:03:37,345] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 19:03:37,435] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.04700
[2022-12-06 19:03:37,504] [INFO] [controller] EPOCH 2 loss ppo:  -0.01763, loss val: 0.04682
[2022-12-06 19:03:37,581] [INFO] [controller] EPOCH 3 loss ppo:  -0.02083, loss val: 0.04680
[2022-12-06 19:03:37,658] [INFO] [controller] EPOCH 4 loss ppo:  -0.02280, loss val: 0.04669
[2022-12-06 19:03:37,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:03:37,924] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:03:37,924] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:03:44,934] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:03:52,370] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:03:59,844] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:04:07,063] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:04:14,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:04:20,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:04:27,828] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:04:34,871] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:04:41,718] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:04:48,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.770495270650075
[2022-12-06 19:04:48,548] [INFO] [runner_train_mujoco] Average state value: 0.4492856670022011
[2022-12-06 19:04:48,549] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 19:04:48,671] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.03851
[2022-12-06 19:04:48,754] [INFO] [controller] EPOCH 2 loss ppo:  -0.02026, loss val: 0.03819
[2022-12-06 19:04:48,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.02197, loss val: 0.03983
[2022-12-06 19:04:48,933] [INFO] [controller] EPOCH 4 loss ppo:  -0.02449, loss val: 0.03873
[2022-12-06 19:04:48,946] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:04:49,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:04:49,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:04:56,302] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:05:03,163] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:05:10,387] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:05:17,623] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:05:24,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:05:31,925] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:05:38,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:05:45,746] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:05:52,191] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:05:58,401] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.8063350633621
[2022-12-06 19:05:58,401] [INFO] [runner_train_mujoco] Average state value: 0.465435244957606
[2022-12-06 19:05:58,401] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 19:05:58,485] [INFO] [controller] EPOCH 1 loss ppo:  -0.01090, loss val: 0.04425
[2022-12-06 19:05:58,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.01705, loss val: 0.04514
[2022-12-06 19:05:58,676] [INFO] [controller] EPOCH 3 loss ppo:  -0.02550, loss val: 0.04511
[2022-12-06 19:05:58,786] [INFO] [controller] EPOCH 4 loss ppo:  -0.02834, loss val: 0.04458
[2022-12-06 19:05:58,804] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:05:59,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:05:59,011] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:06:05,015] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:06:11,055] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:06:16,897] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:06:22,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:06:28,463] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:06:34,650] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:06:41,116] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:06:47,253] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:06:54,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:07:01,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.035127220653335
[2022-12-06 19:07:01,328] [INFO] [runner_train_mujoco] Average state value: 0.4765543938080469
[2022-12-06 19:07:01,328] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 19:07:01,443] [INFO] [controller] EPOCH 1 loss ppo:  -0.01207, loss val: 0.04964
[2022-12-06 19:07:01,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.01744, loss val: 0.04745
[2022-12-06 19:07:01,865] [INFO] [controller] EPOCH 3 loss ppo:  -0.02175, loss val: 0.04739
[2022-12-06 19:07:01,961] [INFO] [controller] EPOCH 4 loss ppo:  -0.02400, loss val: 0.04773
[2022-12-06 19:07:01,977] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:07:02,227] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:07:02,228] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:07:10,652] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:07:18,273] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:07:25,593] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:07:32,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:07:40,073] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:07:47,099] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:07:53,689] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:08:00,652] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:08:07,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:08:14,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.187130036223367
[2022-12-06 19:08:14,170] [INFO] [runner_train_mujoco] Average state value: 0.47745725085337953
[2022-12-06 19:08:14,170] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 19:08:14,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01283, loss val: 0.05231
[2022-12-06 19:08:14,349] [INFO] [controller] EPOCH 2 loss ppo:  -0.01773, loss val: 0.05150
[2022-12-06 19:08:14,435] [INFO] [controller] EPOCH 3 loss ppo:  -0.02066, loss val: 0.05163
[2022-12-06 19:08:14,505] [INFO] [controller] EPOCH 4 loss ppo:  -0.02314, loss val: 0.05075
[2022-12-06 19:08:14,518] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:08:14,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:08:14,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:08:21,704] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:08:29,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:08:36,304] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:08:43,735] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:08:50,682] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:08:57,578] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:09:04,444] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:09:11,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:09:18,418] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:09:25,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.204866464716909
[2022-12-06 19:09:25,112] [INFO] [runner_train_mujoco] Average state value: 0.46292595080534615
[2022-12-06 19:09:25,112] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 19:09:25,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01150, loss val: 0.05091
[2022-12-06 19:09:25,390] [INFO] [controller] EPOCH 2 loss ppo:  -0.01382, loss val: 0.05004
[2022-12-06 19:09:25,496] [INFO] [controller] EPOCH 3 loss ppo:  -0.01714, loss val: 0.05077
[2022-12-06 19:09:25,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.02007, loss val: 0.04977
[2022-12-06 19:09:25,627] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:09:25,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:09:25,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:09:32,832] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:09:40,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:09:46,839] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:09:53,576] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:10:00,334] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:10:07,359] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:10:14,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:10:21,593] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:10:28,652] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:10:35,419] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.299229916676218
[2022-12-06 19:10:35,419] [INFO] [runner_train_mujoco] Average state value: 0.4523471688528856
[2022-12-06 19:10:35,419] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 19:10:35,543] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.04687
[2022-12-06 19:10:35,616] [INFO] [controller] EPOCH 2 loss ppo:  -0.01532, loss val: 0.04769
[2022-12-06 19:10:35,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.02016, loss val: 0.04752
[2022-12-06 19:10:35,789] [INFO] [controller] EPOCH 4 loss ppo:  -0.02292, loss val: 0.04696
[2022-12-06 19:10:35,804] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:10:36,016] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:10:36,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:10:43,112] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:10:50,107] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:10:57,035] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:11:03,957] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:11:10,685] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:11:17,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:11:23,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:11:30,570] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:11:38,073] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:11:45,064] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.156522536390949
[2022-12-06 19:11:45,065] [INFO] [runner_train_mujoco] Average state value: 0.4484282161096732
[2022-12-06 19:11:45,065] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 19:11:45,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.05347
[2022-12-06 19:11:45,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.01432, loss val: 0.05001
[2022-12-06 19:11:45,427] [INFO] [controller] EPOCH 3 loss ppo:  -0.01806, loss val: 0.05005
[2022-12-06 19:11:45,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.02017, loss val: 0.05130
[2022-12-06 19:11:45,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:11:45,826] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:11:45,827] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:11:52,524] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:11:59,235] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:12:06,110] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:12:13,452] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:12:20,203] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:12:27,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:12:34,551] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:12:41,152] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:12:47,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:12:54,416] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.29193465764879
[2022-12-06 19:12:54,416] [INFO] [runner_train_mujoco] Average state value: 0.44680909266074503
[2022-12-06 19:12:54,416] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 19:12:54,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.04876
[2022-12-06 19:12:54,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.01418, loss val: 0.04894
[2022-12-06 19:12:54,726] [INFO] [controller] EPOCH 3 loss ppo:  -0.01817, loss val: 0.04858
[2022-12-06 19:12:54,795] [INFO] [controller] EPOCH 4 loss ppo:  -0.02091, loss val: 0.04883
[2022-12-06 19:12:54,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:12:55,052] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:12:55,052] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:13:01,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:13:09,009] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:13:15,717] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:13:22,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:13:29,014] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:13:35,734] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:13:42,684] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:13:49,758] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:13:57,029] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:14:03,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.191480914719145
[2022-12-06 19:14:03,670] [INFO] [runner_train_mujoco] Average state value: 0.44462018895149225
[2022-12-06 19:14:03,670] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 19:14:03,772] [INFO] [controller] EPOCH 1 loss ppo:  -0.01152, loss val: 0.05050
[2022-12-06 19:14:03,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.01312, loss val: 0.05057
[2022-12-06 19:14:04,271] [INFO] [controller] EPOCH 3 loss ppo:  -0.01564, loss val: 0.05060
[2022-12-06 19:14:04,418] [INFO] [controller] EPOCH 4 loss ppo:  -0.01798, loss val: 0.05092
[2022-12-06 19:14:04,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:14:04,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:14:04,674] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:14:11,365] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:14:18,510] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:14:25,061] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:14:32,033] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:14:39,043] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:14:45,820] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:14:52,300] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:14:58,675] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:15:05,519] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:15:12,424] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.2568406180053255
[2022-12-06 19:15:12,424] [INFO] [runner_train_mujoco] Average state value: 0.44371806502342226
[2022-12-06 19:15:12,424] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 19:15:12,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01139, loss val: 0.05092
[2022-12-06 19:15:12,586] [INFO] [controller] EPOCH 2 loss ppo:  -0.01223, loss val: 0.05310
[2022-12-06 19:15:12,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.01344, loss val: 0.05246
[2022-12-06 19:15:12,742] [INFO] [controller] EPOCH 4 loss ppo:  -0.01523, loss val: 0.05078
[2022-12-06 19:15:12,755] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:15:12,933] [INFO] [optimize] Finished learning.
