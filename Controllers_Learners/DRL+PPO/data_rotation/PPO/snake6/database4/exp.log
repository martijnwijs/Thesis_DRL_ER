[2022-12-06 20:44:15,787] [INFO] [optimize] Starting learning
[2022-12-06 20:44:15,793] [INFO] [optimize] Starting learning process..
[2022-12-06 20:44:15,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:44:15,852] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:44:19,756] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:44:23,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:44:27,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:44:31,961] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:44:36,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:44:39,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:44:43,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:44:47,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:44:51,507] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:44:55,672] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5223795823221401
[2022-12-06 20:44:55,672] [INFO] [runner_train_mujoco] Average state value: 0.15205357349539797
[2022-12-06 20:44:55,672] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 20:44:55,735] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.25812
[2022-12-06 20:44:55,780] [INFO] [controller] EPOCH 2 loss ppo:  -0.03192, loss val: 0.22512
[2022-12-06 20:44:55,827] [INFO] [controller] EPOCH 3 loss ppo:  -0.03823, loss val: 0.18510
[2022-12-06 20:44:55,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.03920, loss val: 0.16188
[2022-12-06 20:44:55,884] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:44:56,029] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:44:56,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:44:59,918] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:45:03,964] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:45:09,423] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:45:13,691] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:45:17,830] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:45:21,903] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:45:26,466] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:45:32,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:45:36,435] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:45:40,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.34643012316080185
[2022-12-06 20:45:40,567] [INFO] [runner_train_mujoco] Average state value: 0.29120721177073816
[2022-12-06 20:45:40,567] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 20:45:40,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.01598, loss val: 0.18218
[2022-12-06 20:45:40,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.02944, loss val: 0.15534
[2022-12-06 20:45:40,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.03073, loss val: 0.13408
[2022-12-06 20:45:40,778] [INFO] [controller] EPOCH 4 loss ppo:  -0.03664, loss val: 0.11328
[2022-12-06 20:45:40,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:45:40,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:45:40,958] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:45:45,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:45:49,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:45:53,779] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:45:57,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:46:02,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:46:06,604] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:46:10,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:46:15,213] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:46:19,812] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:46:24,687] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40949909786122773
[2022-12-06 20:46:24,688] [INFO] [runner_train_mujoco] Average state value: 0.47353963642070696
[2022-12-06 20:46:24,688] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 20:46:24,746] [INFO] [controller] EPOCH 1 loss ppo:  -0.01094, loss val: 0.08689
[2022-12-06 20:46:24,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.02386, loss val: 0.07972
[2022-12-06 20:46:24,843] [INFO] [controller] EPOCH 3 loss ppo:  -0.02980, loss val: 0.07393
[2022-12-06 20:46:24,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.03355, loss val: 0.06906
[2022-12-06 20:46:24,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:46:25,072] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:46:25,073] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:46:29,378] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:46:33,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:46:37,853] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:46:41,711] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:46:45,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:46:49,228] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:46:53,017] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:46:56,637] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:47:00,436] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:47:04,060] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.497568977044989
[2022-12-06 20:47:04,060] [INFO] [runner_train_mujoco] Average state value: 0.5686042340192945
[2022-12-06 20:47:04,061] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 20:47:04,110] [INFO] [controller] EPOCH 1 loss ppo:  -0.01010, loss val: 0.06087
[2022-12-06 20:47:04,150] [INFO] [controller] EPOCH 2 loss ppo:  -0.02594, loss val: 0.05775
[2022-12-06 20:47:04,190] [INFO] [controller] EPOCH 3 loss ppo:  -0.03227, loss val: 0.05270
[2022-12-06 20:47:04,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.03199, loss val: 0.05115
[2022-12-06 20:47:04,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:47:04,389] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:47:04,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:47:08,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:47:11,887] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:47:15,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:47:19,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:47:23,044] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:47:26,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:47:30,353] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:47:34,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:47:37,964] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:47:41,631] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5972071348107388
[2022-12-06 20:47:41,631] [INFO] [runner_train_mujoco] Average state value: 0.5630243599365155
[2022-12-06 20:47:41,631] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 20:47:41,682] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.04548
[2022-12-06 20:47:41,724] [INFO] [controller] EPOCH 2 loss ppo:  -0.02522, loss val: 0.04451
[2022-12-06 20:47:41,764] [INFO] [controller] EPOCH 3 loss ppo:  -0.02732, loss val: 0.04143
[2022-12-06 20:47:41,808] [INFO] [controller] EPOCH 4 loss ppo:  -0.03079, loss val: 0.03953
[2022-12-06 20:47:41,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:47:41,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:47:41,973] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:47:45,699] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:47:49,464] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:47:53,289] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:47:57,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:48:00,963] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:48:04,702] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:48:08,886] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:48:12,473] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:48:16,160] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:48:19,857] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47430963300792517
[2022-12-06 20:48:19,857] [INFO] [runner_train_mujoco] Average state value: 0.552507033020258
[2022-12-06 20:48:19,857] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 20:48:19,913] [INFO] [controller] EPOCH 1 loss ppo:  -0.01108, loss val: 0.03596
[2022-12-06 20:48:19,949] [INFO] [controller] EPOCH 2 loss ppo:  -0.02327, loss val: 0.03617
[2022-12-06 20:48:19,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.02575, loss val: 0.03576
[2022-12-06 20:48:20,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.02837, loss val: 0.03331
[2022-12-06 20:48:20,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:48:20,206] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:48:20,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:48:23,908] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:48:27,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:48:31,777] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:48:35,476] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:48:39,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:48:43,037] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:48:47,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:48:50,855] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:48:54,777] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:48:58,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6505340041759747
[2022-12-06 20:48:58,475] [INFO] [runner_train_mujoco] Average state value: 0.5388536120255788
[2022-12-06 20:48:58,475] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 20:48:58,526] [INFO] [controller] EPOCH 1 loss ppo:  -0.01137, loss val: 0.03078
[2022-12-06 20:48:58,571] [INFO] [controller] EPOCH 2 loss ppo:  -0.02467, loss val: 0.02975
[2022-12-06 20:48:58,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.02617, loss val: 0.02969
[2022-12-06 20:48:58,668] [INFO] [controller] EPOCH 4 loss ppo:  -0.02835, loss val: 0.02849
[2022-12-06 20:48:58,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:48:58,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:48:58,842] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:49:03,080] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:49:07,349] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:49:11,792] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:49:15,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:49:19,544] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:49:23,472] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:49:27,358] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:49:31,051] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:49:34,787] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:49:38,763] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7222237252372672
[2022-12-06 20:49:38,763] [INFO] [runner_train_mujoco] Average state value: 0.5161989857554435
[2022-12-06 20:49:38,763] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 20:49:38,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.03546
[2022-12-06 20:49:38,859] [INFO] [controller] EPOCH 2 loss ppo:  -0.02286, loss val: 0.03181
[2022-12-06 20:49:38,902] [INFO] [controller] EPOCH 3 loss ppo:  -0.02989, loss val: 0.03144
[2022-12-06 20:49:38,948] [INFO] [controller] EPOCH 4 loss ppo:  -0.03346, loss val: 0.03142
[2022-12-06 20:49:38,959] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:49:39,121] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:49:39,121] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:49:42,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:49:46,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:49:50,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:49:54,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:49:57,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:50:02,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:50:06,388] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:50:10,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:50:13,995] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:50:17,941] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7186155083751729
[2022-12-06 20:50:17,942] [INFO] [runner_train_mujoco] Average state value: 0.49074176568786304
[2022-12-06 20:50:17,942] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 20:50:17,998] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.03574
[2022-12-06 20:50:18,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.02720, loss val: 0.03563
[2022-12-06 20:50:18,085] [INFO] [controller] EPOCH 3 loss ppo:  -0.02981, loss val: 0.03547
[2022-12-06 20:50:18,128] [INFO] [controller] EPOCH 4 loss ppo:  -0.03048, loss val: 0.03507
[2022-12-06 20:50:18,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:50:18,300] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:50:18,301] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:50:21,900] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:50:25,327] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:50:29,063] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:50:33,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:50:36,983] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:50:40,773] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:50:44,455] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:50:48,143] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:50:51,721] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:50:55,398] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.088313528375329
[2022-12-06 20:50:55,399] [INFO] [runner_train_mujoco] Average state value: 0.5091586949825286
[2022-12-06 20:50:55,399] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 20:50:55,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.02870
[2022-12-06 20:50:55,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.02907, loss val: 0.02813
[2022-12-06 20:50:55,538] [INFO] [controller] EPOCH 3 loss ppo:  -0.03139, loss val: 0.02901
[2022-12-06 20:50:55,582] [INFO] [controller] EPOCH 4 loss ppo:  -0.03531, loss val: 0.02797
[2022-12-06 20:50:55,591] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:50:55,741] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:50:55,741] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:50:59,514] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:51:03,101] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:51:06,849] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:51:10,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:51:14,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:51:17,993] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:51:21,449] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:51:25,254] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:51:28,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:51:32,606] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3941751003261764
[2022-12-06 20:51:32,606] [INFO] [runner_train_mujoco] Average state value: 0.5220913219650586
[2022-12-06 20:51:32,606] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 20:51:32,667] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.03323
[2022-12-06 20:51:32,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.02726, loss val: 0.03131
[2022-12-06 20:51:32,776] [INFO] [controller] EPOCH 3 loss ppo:  -0.03096, loss val: 0.03271
[2022-12-06 20:51:32,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.03706, loss val: 0.03202
[2022-12-06 20:51:32,852] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:51:33,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:51:33,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:51:36,637] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:51:40,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:51:44,395] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:51:48,154] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:51:51,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:51:55,566] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:51:59,120] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:52:02,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:52:06,126] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:52:09,613] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.574314545662386
[2022-12-06 20:52:09,613] [INFO] [runner_train_mujoco] Average state value: 0.49568882894515987
[2022-12-06 20:52:09,614] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 20:52:09,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.01610, loss val: 0.03333
[2022-12-06 20:52:09,706] [INFO] [controller] EPOCH 2 loss ppo:  -0.03152, loss val: 0.03224
[2022-12-06 20:52:09,739] [INFO] [controller] EPOCH 3 loss ppo:  -0.03438, loss val: 0.03250
[2022-12-06 20:52:09,776] [INFO] [controller] EPOCH 4 loss ppo:  -0.03989, loss val: 0.03309
[2022-12-06 20:52:09,784] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:52:09,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:52:09,938] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:52:13,469] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:52:16,819] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:52:20,245] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:52:23,716] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:52:27,384] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:52:30,764] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:52:34,343] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:52:37,962] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:52:41,698] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:52:45,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.232483310639927
[2022-12-06 20:52:45,195] [INFO] [runner_train_mujoco] Average state value: 0.44491273953517274
[2022-12-06 20:52:45,195] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 20:52:45,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01708, loss val: 0.02915
[2022-12-06 20:52:45,284] [INFO] [controller] EPOCH 2 loss ppo:  -0.03735, loss val: 0.02950
[2022-12-06 20:52:45,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.03874, loss val: 0.02907
[2022-12-06 20:52:45,364] [INFO] [controller] EPOCH 4 loss ppo:  -0.04340, loss val: 0.02856
[2022-12-06 20:52:45,373] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:52:45,527] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:52:45,527] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:52:49,053] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:52:52,587] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:52:56,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:53:00,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:53:03,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:53:07,311] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:53:10,913] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:53:14,377] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:53:17,904] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:53:21,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6642532826040997
[2022-12-06 20:53:21,389] [INFO] [runner_train_mujoco] Average state value: 0.45764005657037093
[2022-12-06 20:53:21,389] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 20:53:21,478] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.04337
[2022-12-06 20:53:21,515] [INFO] [controller] EPOCH 2 loss ppo:  -0.02844, loss val: 0.04336
[2022-12-06 20:53:21,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.03275, loss val: 0.04123
[2022-12-06 20:53:21,598] [INFO] [controller] EPOCH 4 loss ppo:  -0.03246, loss val: 0.03913
[2022-12-06 20:53:21,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:53:21,732] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:53:21,732] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:53:25,247] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:53:28,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:53:32,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:53:35,901] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:53:39,762] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:53:43,365] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:53:46,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:53:50,308] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:53:54,174] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:53:57,577] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.988039044908109
[2022-12-06 20:53:57,578] [INFO] [runner_train_mujoco] Average state value: 0.40783834972977645
[2022-12-06 20:53:57,578] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 20:53:57,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01694, loss val: 0.03952
[2022-12-06 20:53:57,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.02840, loss val: 0.04504
[2022-12-06 20:53:57,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.03432, loss val: 0.04332
[2022-12-06 20:53:57,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.03555, loss val: 0.04259
[2022-12-06 20:53:57,802] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:53:57,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:53:57,936] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:54:01,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:54:05,219] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:54:08,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:54:12,690] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:54:16,202] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:54:19,774] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:54:23,363] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:54:27,004] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:54:30,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:54:34,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2308491810351043
[2022-12-06 20:54:34,420] [INFO] [runner_train_mujoco] Average state value: 0.40026336119572326
[2022-12-06 20:54:34,421] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 20:54:34,467] [INFO] [controller] EPOCH 1 loss ppo:  -0.01628, loss val: 0.03160
[2022-12-06 20:54:34,516] [INFO] [controller] EPOCH 2 loss ppo:  -0.02419, loss val: 0.03169
[2022-12-06 20:54:34,563] [INFO] [controller] EPOCH 3 loss ppo:  -0.03193, loss val: 0.03265
[2022-12-06 20:54:34,612] [INFO] [controller] EPOCH 4 loss ppo:  -0.03573, loss val: 0.03347
[2022-12-06 20:54:34,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:54:34,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:54:34,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:54:38,463] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:54:42,257] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:54:45,925] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:54:49,701] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:54:53,421] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:54:57,028] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:55:00,705] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:55:04,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:55:08,288] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:55:11,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.472278702816832
[2022-12-06 20:55:11,914] [INFO] [runner_train_mujoco] Average state value: 0.434491504808267
[2022-12-06 20:55:11,914] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 20:55:11,973] [INFO] [controller] EPOCH 1 loss ppo:  -0.01834, loss val: 0.03280
[2022-12-06 20:55:12,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.02459, loss val: 0.03202
[2022-12-06 20:55:12,064] [INFO] [controller] EPOCH 3 loss ppo:  -0.03148, loss val: 0.03269
[2022-12-06 20:55:12,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.03903, loss val: 0.03230
[2022-12-06 20:55:12,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:55:12,275] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:55:12,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:55:16,528] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:55:20,164] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:55:24,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:55:28,025] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:55:31,540] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:55:35,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:55:39,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:55:42,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:55:46,371] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:55:49,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9384354890283175
[2022-12-06 20:55:49,983] [INFO] [runner_train_mujoco] Average state value: 0.4532163239518801
[2022-12-06 20:55:49,984] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 20:55:50,036] [INFO] [controller] EPOCH 1 loss ppo:  -0.01895, loss val: 0.04604
[2022-12-06 20:55:50,078] [INFO] [controller] EPOCH 2 loss ppo:  -0.01878, loss val: 0.04464
[2022-12-06 20:55:50,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.02987, loss val: 0.04352
[2022-12-06 20:55:50,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.03188, loss val: 0.04458
[2022-12-06 20:55:50,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:55:50,335] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:55:50,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:55:53,905] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:55:57,813] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:56:01,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:56:05,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:56:09,487] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:56:13,678] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:56:17,723] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:56:22,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:56:26,602] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:56:30,770] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.276595824403801
[2022-12-06 20:56:30,771] [INFO] [runner_train_mujoco] Average state value: 0.4442003834843636
[2022-12-06 20:56:30,771] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 20:56:30,829] [INFO] [controller] EPOCH 1 loss ppo:  -0.01647, loss val: 0.03928
[2022-12-06 20:56:30,885] [INFO] [controller] EPOCH 2 loss ppo:  -0.02272, loss val: 0.04001
[2022-12-06 20:56:30,944] [INFO] [controller] EPOCH 3 loss ppo:  -0.03347, loss val: 0.04062
[2022-12-06 20:56:31,003] [INFO] [controller] EPOCH 4 loss ppo:  -0.03599, loss val: 0.04080
[2022-12-06 20:56:31,013] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:56:31,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:56:31,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:56:35,340] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:56:39,909] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:56:44,276] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:56:48,210] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:56:52,250] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:56:56,199] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:57:00,270] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:57:04,300] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:57:10,254] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:57:14,131] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0996029161125085
[2022-12-06 20:57:14,131] [INFO] [runner_train_mujoco] Average state value: 0.4616702401836713
[2022-12-06 20:57:14,131] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 20:57:14,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01532, loss val: 0.04523
[2022-12-06 20:57:14,241] [INFO] [controller] EPOCH 2 loss ppo:  -0.01975, loss val: 0.04047
[2022-12-06 20:57:14,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.02425, loss val: 0.04160
[2022-12-06 20:57:14,338] [INFO] [controller] EPOCH 4 loss ppo:  -0.03020, loss val: 0.04319
[2022-12-06 20:57:14,347] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:57:14,519] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:57:14,519] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:57:19,699] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:57:23,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:57:27,886] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:57:32,049] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:57:36,078] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:57:40,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:57:43,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:57:47,815] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:57:52,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:57:57,322] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.404254616760246
[2022-12-06 20:57:57,322] [INFO] [runner_train_mujoco] Average state value: 0.45185376405715943
[2022-12-06 20:57:57,322] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 20:57:57,389] [INFO] [controller] EPOCH 1 loss ppo:  -0.01643, loss val: 0.04634
[2022-12-06 20:57:57,439] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.04620
[2022-12-06 20:57:57,495] [INFO] [controller] EPOCH 3 loss ppo:  -0.03346, loss val: 0.04645
[2022-12-06 20:57:57,554] [INFO] [controller] EPOCH 4 loss ppo:  -0.04197, loss val: 0.04442
[2022-12-06 20:57:57,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:57:57,735] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:57:57,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:58:02,261] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:58:06,786] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:58:12,357] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:58:16,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:58:20,722] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:58:25,201] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:58:29,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:58:34,087] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:58:38,762] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:58:43,335] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.455170338549041
[2022-12-06 20:58:43,335] [INFO] [runner_train_mujoco] Average state value: 0.40768865698575973
[2022-12-06 20:58:43,336] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 20:58:43,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01591, loss val: 0.04349
[2022-12-06 20:58:43,440] [INFO] [controller] EPOCH 2 loss ppo:  -0.01491, loss val: 0.04368
[2022-12-06 20:58:43,492] [INFO] [controller] EPOCH 3 loss ppo:  -0.02786, loss val: 0.04364
[2022-12-06 20:58:43,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.02968, loss val: 0.04385
[2022-12-06 20:58:43,557] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:58:43,738] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:58:43,738] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:58:48,200] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:58:52,779] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:58:57,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:59:02,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:59:07,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:59:11,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:59:15,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:59:20,399] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:59:24,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:59:28,966] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.665626581494318
[2022-12-06 20:59:28,966] [INFO] [runner_train_mujoco] Average state value: 0.4063791992167632
[2022-12-06 20:59:28,966] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 20:59:29,025] [INFO] [controller] EPOCH 1 loss ppo:  -0.01346, loss val: 0.03974
[2022-12-06 20:59:29,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.01784, loss val: 0.04047
[2022-12-06 20:59:29,123] [INFO] [controller] EPOCH 3 loss ppo:  -0.02519, loss val: 0.04019
[2022-12-06 20:59:29,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.02682, loss val: 0.03922
[2022-12-06 20:59:29,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:59:29,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:59:29,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:59:33,697] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:59:38,427] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:59:42,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:59:47,597] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:59:52,173] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:59:56,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:00:01,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:00:06,340] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:00:10,835] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:00:15,398] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.632909765301855
[2022-12-06 21:00:15,399] [INFO] [runner_train_mujoco] Average state value: 0.43286615763107933
[2022-12-06 21:00:15,399] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 21:00:15,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01886, loss val: 0.04463
[2022-12-06 21:00:15,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01259, loss val: 0.04843
[2022-12-06 21:00:15,562] [INFO] [controller] EPOCH 3 loss ppo:  -0.02726, loss val: 0.04473
[2022-12-06 21:00:15,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.03125, loss val: 0.04879
[2022-12-06 21:00:15,625] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:00:15,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:00:15,801] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:00:20,415] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:00:25,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:00:29,527] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:00:33,934] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:00:38,613] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:00:43,141] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:00:47,764] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:00:52,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:00:56,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:01:01,801] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.742700073416258
[2022-12-06 21:01:01,801] [INFO] [runner_train_mujoco] Average state value: 0.4370321320295334
[2022-12-06 21:01:01,802] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 21:01:01,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01753, loss val: 0.04072
[2022-12-06 21:01:01,940] [INFO] [controller] EPOCH 2 loss ppo:  -0.01546, loss val: 0.04013
[2022-12-06 21:01:02,017] [INFO] [controller] EPOCH 3 loss ppo:  -0.02291, loss val: 0.04077
[2022-12-06 21:01:02,082] [INFO] [controller] EPOCH 4 loss ppo:  -0.02520, loss val: 0.04053
[2022-12-06 21:01:02,093] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:01:02,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:01:02,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:01:06,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:01:11,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:01:16,261] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:01:20,995] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:01:25,742] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:01:30,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:01:35,228] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:01:39,765] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:01:44,634] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:01:49,196] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.623974334276482
[2022-12-06 21:01:49,196] [INFO] [runner_train_mujoco] Average state value: 0.4496570451259613
[2022-12-06 21:01:49,196] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 21:01:49,254] [INFO] [controller] EPOCH 1 loss ppo:  -0.01693, loss val: 0.04060
[2022-12-06 21:01:49,303] [INFO] [controller] EPOCH 2 loss ppo:  -0.01629, loss val: 0.04250
[2022-12-06 21:01:49,366] [INFO] [controller] EPOCH 3 loss ppo:  -0.02980, loss val: 0.04642
[2022-12-06 21:01:49,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.02545, loss val: 0.04129
[2022-12-06 21:01:49,427] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:01:49,600] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:01:49,601] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:01:54,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:01:58,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:02:03,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:02:07,727] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:02:12,393] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:02:16,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:02:21,419] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:02:25,813] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:02:30,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:02:34,801] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7999746981668245
[2022-12-06 21:02:34,801] [INFO] [runner_train_mujoco] Average state value: 0.43817643070220946
[2022-12-06 21:02:34,801] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 21:02:34,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.05335
[2022-12-06 21:02:34,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.01729, loss val: 0.05571
[2022-12-06 21:02:34,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.02596, loss val: 0.05310
[2022-12-06 21:02:35,032] [INFO] [controller] EPOCH 4 loss ppo:  -0.02463, loss val: 0.05377
[2022-12-06 21:02:35,043] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:02:35,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:02:35,214] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:02:39,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:02:44,381] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:02:48,898] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:02:53,281] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:02:57,752] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:03:02,168] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:03:06,701] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:03:11,010] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:03:15,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:03:19,683] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.049174552852068
[2022-12-06 21:03:19,684] [INFO] [runner_train_mujoco] Average state value: 0.40701203966140753
[2022-12-06 21:03:19,684] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 21:03:19,753] [INFO] [controller] EPOCH 1 loss ppo:  -0.01627, loss val: 0.05048
[2022-12-06 21:03:19,804] [INFO] [controller] EPOCH 2 loss ppo:  -0.02021, loss val: 0.04945
[2022-12-06 21:03:19,860] [INFO] [controller] EPOCH 3 loss ppo:  -0.02775, loss val: 0.05072
[2022-12-06 21:03:19,908] [INFO] [controller] EPOCH 4 loss ppo:  -0.02946, loss val: 0.05065
[2022-12-06 21:03:19,919] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:03:20,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:03:20,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:03:24,631] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:03:29,020] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:03:33,332] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:03:37,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:03:41,841] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:03:46,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:03:50,436] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:03:54,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:03:58,505] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:04:03,233] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.160002073176928
[2022-12-06 21:04:03,233] [INFO] [runner_train_mujoco] Average state value: 0.3827093624273936
[2022-12-06 21:04:03,233] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 21:04:03,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.05121
[2022-12-06 21:04:03,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.02066, loss val: 0.05153
[2022-12-06 21:04:03,397] [INFO] [controller] EPOCH 3 loss ppo:  -0.02728, loss val: 0.05107
[2022-12-06 21:04:03,445] [INFO] [controller] EPOCH 4 loss ppo:  -0.03000, loss val: 0.05212
[2022-12-06 21:04:03,455] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:04:03,619] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:04:03,620] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:04:07,938] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:04:12,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:04:16,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:04:20,475] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:04:24,684] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:04:28,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:04:33,079] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:04:36,896] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:04:41,471] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:04:45,900] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.247807032170807
[2022-12-06 21:04:45,901] [INFO] [runner_train_mujoco] Average state value: 0.38967827792962384
[2022-12-06 21:04:45,901] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 21:04:45,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.04590
[2022-12-06 21:04:46,018] [INFO] [controller] EPOCH 2 loss ppo:  -0.01735, loss val: 0.04481
[2022-12-06 21:04:46,066] [INFO] [controller] EPOCH 3 loss ppo:  -0.02207, loss val: 0.04645
[2022-12-06 21:04:46,116] [INFO] [controller] EPOCH 4 loss ppo:  -0.02662, loss val: 0.04511
[2022-12-06 21:04:46,126] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:04:46,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:04:46,293] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:04:50,515] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:04:54,537] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:04:59,065] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:05:03,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:05:07,743] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:05:11,944] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:05:16,295] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:05:20,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:05:24,737] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:05:29,048] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.980089450279374
[2022-12-06 21:05:29,048] [INFO] [runner_train_mujoco] Average state value: 0.38989994418621066
[2022-12-06 21:05:29,048] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 21:05:29,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.04929
[2022-12-06 21:05:29,178] [INFO] [controller] EPOCH 2 loss ppo:  -0.02009, loss val: 0.04909
[2022-12-06 21:05:29,272] [INFO] [controller] EPOCH 3 loss ppo:  -0.02417, loss val: 0.04931
[2022-12-06 21:05:29,335] [INFO] [controller] EPOCH 4 loss ppo:  -0.02755, loss val: 0.04933
[2022-12-06 21:05:29,346] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:05:29,514] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:05:29,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:05:33,875] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:05:38,281] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:05:42,868] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:05:47,265] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:05:51,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:05:55,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:05:59,585] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:06:04,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:06:08,695] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:06:12,995] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.009251980515086
[2022-12-06 21:06:12,996] [INFO] [runner_train_mujoco] Average state value: 0.3892840174039205
[2022-12-06 21:06:12,996] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 21:06:13,069] [INFO] [controller] EPOCH 1 loss ppo:  -0.01560, loss val: 0.04259
[2022-12-06 21:06:13,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.01874, loss val: 0.04299
[2022-12-06 21:06:13,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.02322, loss val: 0.04190
[2022-12-06 21:06:13,243] [INFO] [controller] EPOCH 4 loss ppo:  -0.03109, loss val: 0.04243
[2022-12-06 21:06:13,254] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:06:13,441] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:06:13,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:06:17,823] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:06:22,290] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:06:27,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:06:31,531] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:06:36,059] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:06:40,676] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:06:44,984] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:06:49,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:06:53,823] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:06:57,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.332002174024188
[2022-12-06 21:06:57,971] [INFO] [runner_train_mujoco] Average state value: 0.38736379505197205
[2022-12-06 21:06:57,971] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 21:06:58,038] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04739
[2022-12-06 21:06:58,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.01686, loss val: 0.04733
[2022-12-06 21:06:58,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.02262, loss val: 0.04726
[2022-12-06 21:06:58,190] [INFO] [controller] EPOCH 4 loss ppo:  -0.02342, loss val: 0.04758
[2022-12-06 21:06:58,201] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:06:58,384] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:06:58,385] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:07:03,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:07:09,129] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:07:13,961] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:07:19,178] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:07:24,297] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:07:28,995] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:07:33,442] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:07:38,015] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:07:42,412] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:07:47,292] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7951300167855395
[2022-12-06 21:07:47,292] [INFO] [runner_train_mujoco] Average state value: 0.368629162915051
[2022-12-06 21:07:47,292] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 21:07:47,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.04166
[2022-12-06 21:07:47,429] [INFO] [controller] EPOCH 2 loss ppo:  -0.01380, loss val: 0.04109
[2022-12-06 21:07:47,481] [INFO] [controller] EPOCH 3 loss ppo:  -0.01839, loss val: 0.03926
[2022-12-06 21:07:47,547] [INFO] [controller] EPOCH 4 loss ppo:  -0.02498, loss val: 0.03778
[2022-12-06 21:07:47,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:07:47,742] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:07:47,742] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:07:52,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:07:57,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:08:01,901] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:08:06,640] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:08:11,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:08:16,305] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:08:20,597] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:08:25,664] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:08:30,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:08:35,018] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.192748941133816
[2022-12-06 21:08:35,018] [INFO] [runner_train_mujoco] Average state value: 0.41340813110272084
[2022-12-06 21:08:35,018] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 21:08:35,085] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04743
[2022-12-06 21:08:35,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.01680, loss val: 0.04600
[2022-12-06 21:08:35,204] [INFO] [controller] EPOCH 3 loss ppo:  -0.01310, loss val: 0.04568
[2022-12-06 21:08:35,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.02746, loss val: 0.05143
[2022-12-06 21:08:35,276] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:08:35,469] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:08:35,469] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:08:39,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:08:44,458] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:08:49,219] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:08:53,467] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:08:57,505] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:09:02,300] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:09:06,414] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:09:10,718] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:09:15,218] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:09:19,569] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.14613682652107
[2022-12-06 21:09:19,569] [INFO] [runner_train_mujoco] Average state value: 0.4697991161346436
[2022-12-06 21:09:19,569] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 21:09:19,644] [INFO] [controller] EPOCH 1 loss ppo:  -0.01549, loss val: 0.06070
[2022-12-06 21:09:19,701] [INFO] [controller] EPOCH 2 loss ppo:  -0.01438, loss val: 0.05904
[2022-12-06 21:09:19,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.01631, loss val: 0.05834
[2022-12-06 21:09:19,824] [INFO] [controller] EPOCH 4 loss ppo:  -0.02721, loss val: 0.05479
[2022-12-06 21:09:19,835] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:09:20,023] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:09:20,023] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:09:24,624] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:09:29,257] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:09:33,732] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:09:38,343] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:09:42,894] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:09:47,204] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:09:51,699] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:09:56,339] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:10:00,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:10:05,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.139244935752698
[2022-12-06 21:10:05,371] [INFO] [runner_train_mujoco] Average state value: 0.42384130329142017
[2022-12-06 21:10:05,372] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 21:10:05,442] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.05152
[2022-12-06 21:10:05,496] [INFO] [controller] EPOCH 2 loss ppo:  -0.01278, loss val: 0.05372
[2022-12-06 21:10:05,555] [INFO] [controller] EPOCH 3 loss ppo:  -0.01699, loss val: 0.05226
[2022-12-06 21:10:05,624] [INFO] [controller] EPOCH 4 loss ppo:  -0.02118, loss val: 0.05126
[2022-12-06 21:10:05,634] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:10:05,810] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:10:05,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:10:10,095] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:10:14,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:10:19,056] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:10:23,353] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:10:27,792] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:10:32,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:10:36,470] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:10:40,439] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:10:44,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:10:49,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.167824290550955
[2022-12-06 21:10:49,017] [INFO] [runner_train_mujoco] Average state value: 0.43763398170471196
[2022-12-06 21:10:49,017] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 21:10:49,072] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.05219
[2022-12-06 21:10:49,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.01808, loss val: 0.05123
[2022-12-06 21:10:49,172] [INFO] [controller] EPOCH 3 loss ppo:  -0.01623, loss val: 0.05411
[2022-12-06 21:10:49,230] [INFO] [controller] EPOCH 4 loss ppo:  -0.02041, loss val: 0.05443
[2022-12-06 21:10:49,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:10:49,409] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:10:49,409] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:10:53,859] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:10:58,210] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:11:02,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:11:06,597] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:11:10,614] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:11:14,873] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:11:19,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:11:23,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:11:27,641] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:11:31,786] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.112739089585338
[2022-12-06 21:11:31,786] [INFO] [runner_train_mujoco] Average state value: 0.442398877799511
[2022-12-06 21:11:31,786] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 21:11:31,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04922
[2022-12-06 21:11:31,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.01470, loss val: 0.04797
[2022-12-06 21:11:31,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.01730, loss val: 0.04778
[2022-12-06 21:11:32,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.02488, loss val: 0.04722
[2022-12-06 21:11:32,025] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:11:32,187] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:11:32,187] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:11:36,475] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:11:41,025] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:11:45,304] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:11:49,441] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:11:53,628] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:11:57,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:12:01,870] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:12:05,896] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:12:10,035] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:12:14,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.19999424287328
[2022-12-06 21:12:14,328] [INFO] [runner_train_mujoco] Average state value: 0.4083311488628388
[2022-12-06 21:12:14,329] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 21:12:14,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01235, loss val: 0.04906
[2022-12-06 21:12:14,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.01890, loss val: 0.04862
[2022-12-06 21:12:14,501] [INFO] [controller] EPOCH 3 loss ppo:  -0.02114, loss val: 0.04890
[2022-12-06 21:12:14,549] [INFO] [controller] EPOCH 4 loss ppo:  -0.02787, loss val: 0.04933
[2022-12-06 21:12:14,558] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:12:14,727] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:12:14,728] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:12:18,731] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:12:23,020] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:12:27,368] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:12:31,588] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:12:35,767] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:12:40,353] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:12:44,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:12:48,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:12:52,932] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:12:56,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.246734260689969
[2022-12-06 21:12:56,915] [INFO] [runner_train_mujoco] Average state value: 0.3989816666841507
[2022-12-06 21:12:56,915] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 21:12:56,989] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.04881
[2022-12-06 21:12:57,038] [INFO] [controller] EPOCH 2 loss ppo:  -0.01360, loss val: 0.04683
[2022-12-06 21:12:57,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.01485, loss val: 0.04816
[2022-12-06 21:12:57,132] [INFO] [controller] EPOCH 4 loss ppo:  -0.02611, loss val: 0.04695
[2022-12-06 21:12:57,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:12:57,310] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:12:57,310] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:13:01,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:13:05,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:13:10,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:13:14,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:13:19,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:13:23,538] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:13:27,468] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:13:31,535] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:13:35,799] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:13:39,857] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.259083334950344
[2022-12-06 21:13:39,858] [INFO] [runner_train_mujoco] Average state value: 0.39666539214054747
[2022-12-06 21:13:39,858] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 21:13:39,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04954
[2022-12-06 21:13:39,970] [INFO] [controller] EPOCH 2 loss ppo:  -0.01690, loss val: 0.04993
[2022-12-06 21:13:40,023] [INFO] [controller] EPOCH 3 loss ppo:  -0.02037, loss val: 0.05093
[2022-12-06 21:13:40,077] [INFO] [controller] EPOCH 4 loss ppo:  -0.02744, loss val: 0.04956
[2022-12-06 21:13:40,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:13:40,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:13:40,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:13:44,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:13:49,320] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:13:53,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:13:58,163] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:14:02,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:14:06,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:14:10,868] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:14:15,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:14:19,527] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:14:23,911] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.17245183376396
[2022-12-06 21:14:23,912] [INFO] [runner_train_mujoco] Average state value: 0.39621832793951034
[2022-12-06 21:14:23,912] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 21:14:24,003] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.04439
[2022-12-06 21:14:24,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.01607, loss val: 0.04409
[2022-12-06 21:14:24,111] [INFO] [controller] EPOCH 3 loss ppo:  -0.01818, loss val: 0.04448
[2022-12-06 21:14:24,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.02263, loss val: 0.04422
[2022-12-06 21:14:24,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:14:24,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:14:24,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:14:28,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:14:33,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:14:37,630] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:14:42,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:14:46,483] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:14:51,205] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:14:55,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:15:00,563] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:15:05,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:15:09,842] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.11014946913358
[2022-12-06 21:15:09,842] [INFO] [runner_train_mujoco] Average state value: 0.39837318747242295
[2022-12-06 21:15:09,842] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 21:15:09,924] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.04816
[2022-12-06 21:15:09,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.01536, loss val: 0.04778
[2022-12-06 21:15:10,044] [INFO] [controller] EPOCH 3 loss ppo:  -0.01564, loss val: 0.04716
[2022-12-06 21:15:10,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.02004, loss val: 0.04529
[2022-12-06 21:15:10,117] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:15:10,301] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:15:10,302] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:15:14,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:15:19,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:15:23,715] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:15:28,268] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:15:33,526] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:15:37,742] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:15:42,080] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:15:46,647] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:15:51,240] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:15:55,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.097714651341396
[2022-12-06 21:15:55,979] [INFO] [runner_train_mujoco] Average state value: 0.42314789724349977
[2022-12-06 21:15:55,979] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 21:15:56,036] [INFO] [controller] EPOCH 1 loss ppo:  -0.01171, loss val: 0.04738
[2022-12-06 21:15:56,085] [INFO] [controller] EPOCH 2 loss ppo:  -0.01516, loss val: 0.04802
[2022-12-06 21:15:56,136] [INFO] [controller] EPOCH 3 loss ppo:  -0.01747, loss val: 0.04760
[2022-12-06 21:15:56,184] [INFO] [controller] EPOCH 4 loss ppo:  -0.02288, loss val: 0.04816
[2022-12-06 21:15:56,195] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:15:56,368] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:15:56,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:16:00,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:16:05,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:16:09,869] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:16:14,458] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:16:19,271] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:16:23,586] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:16:28,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:16:32,585] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:16:36,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:16:41,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.438700569058254
[2022-12-06 21:16:41,054] [INFO] [runner_train_mujoco] Average state value: 0.442654316743215
[2022-12-06 21:16:41,054] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 21:16:41,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01264, loss val: 0.03489
[2022-12-06 21:16:41,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.01556, loss val: 0.03554
[2022-12-06 21:16:41,218] [INFO] [controller] EPOCH 3 loss ppo:  -0.01818, loss val: 0.03556
[2022-12-06 21:16:41,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.02281, loss val: 0.03506
[2022-12-06 21:16:41,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:16:41,456] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:16:41,456] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:16:45,832] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:16:50,161] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:16:54,309] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:16:58,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:17:03,057] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:17:07,292] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:17:11,423] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:17:15,621] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:17:19,670] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:17:23,905] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.281725787539816
[2022-12-06 21:17:23,905] [INFO] [runner_train_mujoco] Average state value: 0.45716160913308457
[2022-12-06 21:17:23,906] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 21:17:23,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01280, loss val: 0.05470
[2022-12-06 21:17:24,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.01893, loss val: 0.05470
[2022-12-06 21:17:24,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.01857, loss val: 0.05470
[2022-12-06 21:17:24,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.02144, loss val: 0.05445
[2022-12-06 21:17:24,116] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:17:24,286] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:17:24,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:17:28,523] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:17:32,797] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:17:37,042] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:17:41,300] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:17:45,524] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:17:49,664] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:17:53,649] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:17:57,705] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:18:01,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:18:05,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.267323774246598
[2022-12-06 21:18:05,979] [INFO] [runner_train_mujoco] Average state value: 0.4559135907292366
[2022-12-06 21:18:05,979] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 21:18:06,045] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.04505
[2022-12-06 21:18:06,092] [INFO] [controller] EPOCH 2 loss ppo:  -0.01488, loss val: 0.04535
[2022-12-06 21:18:06,153] [INFO] [controller] EPOCH 3 loss ppo:  -0.01811, loss val: 0.04388
[2022-12-06 21:18:06,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.02399, loss val: 0.04416
[2022-12-06 21:18:06,213] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:18:06,389] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:18:06,389] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:18:10,661] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:18:14,694] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:18:19,093] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:18:23,043] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:18:27,553] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:18:31,714] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:18:35,910] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:18:40,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:18:44,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:18:48,635] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.294099540534241
[2022-12-06 21:18:48,636] [INFO] [runner_train_mujoco] Average state value: 0.43828929801781974
[2022-12-06 21:18:48,636] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 21:18:48,695] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.03958
[2022-12-06 21:18:48,750] [INFO] [controller] EPOCH 2 loss ppo:  -0.01526, loss val: 0.03980
[2022-12-06 21:18:48,805] [INFO] [controller] EPOCH 3 loss ppo:  -0.01847, loss val: 0.03885
[2022-12-06 21:18:48,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.02218, loss val: 0.03847
[2022-12-06 21:18:48,865] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:18:49,037] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:18:49,038] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:18:53,072] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:18:57,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:19:01,509] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:19:05,495] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:19:09,512] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:19:13,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:19:17,848] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:19:21,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:19:26,393] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:19:30,816] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.240023808568794
[2022-12-06 21:19:30,817] [INFO] [runner_train_mujoco] Average state value: 0.4311877898176511
[2022-12-06 21:19:30,817] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 21:19:30,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04503
[2022-12-06 21:19:30,945] [INFO] [controller] EPOCH 2 loss ppo:  -0.01647, loss val: 0.04557
[2022-12-06 21:19:31,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.02046, loss val: 0.04476
[2022-12-06 21:19:31,064] [INFO] [controller] EPOCH 4 loss ppo:  -0.02264, loss val: 0.04478
[2022-12-06 21:19:31,075] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:19:31,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:19:31,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:19:35,421] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:19:39,526] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:19:43,654] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:19:48,015] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:19:52,437] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:19:57,067] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:20:01,189] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:20:05,432] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:20:09,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:20:14,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.342024222749993
[2022-12-06 21:20:14,562] [INFO] [runner_train_mujoco] Average state value: 0.4271195879379908
[2022-12-06 21:20:14,562] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 21:20:14,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01221, loss val: 0.05340
[2022-12-06 21:20:14,689] [INFO] [controller] EPOCH 2 loss ppo:  -0.01475, loss val: 0.05351
[2022-12-06 21:20:14,751] [INFO] [controller] EPOCH 3 loss ppo:  -0.01529, loss val: 0.05288
[2022-12-06 21:20:14,806] [INFO] [controller] EPOCH 4 loss ppo:  -0.01715, loss val: 0.05224
[2022-12-06 21:20:14,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:20:14,992] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:20:14,993] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:20:19,349] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:20:23,999] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:20:28,391] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:20:32,907] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:20:37,212] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:20:41,735] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:20:46,046] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:20:50,420] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:20:54,557] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:20:58,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.466713096653681
[2022-12-06 21:20:58,904] [INFO] [runner_train_mujoco] Average state value: 0.40886438131332403
[2022-12-06 21:20:58,904] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 21:20:58,970] [INFO] [controller] EPOCH 1 loss ppo:  -0.01239, loss val: 0.05655
[2022-12-06 21:20:59,020] [INFO] [controller] EPOCH 2 loss ppo:  -0.01614, loss val: 0.05610
[2022-12-06 21:20:59,073] [INFO] [controller] EPOCH 3 loss ppo:  -0.01861, loss val: 0.05562
[2022-12-06 21:20:59,123] [INFO] [controller] EPOCH 4 loss ppo:  -0.01924, loss val: 0.05533
[2022-12-06 21:20:59,136] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:20:59,316] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:20:59,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:21:03,653] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:21:07,975] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:21:12,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:21:17,676] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:21:22,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:21:26,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:21:31,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:21:35,808] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:21:40,103] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:21:44,657] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.249315616560646
[2022-12-06 21:21:44,657] [INFO] [runner_train_mujoco] Average state value: 0.38753551451365154
[2022-12-06 21:21:44,657] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 21:21:44,734] [INFO] [controller] EPOCH 1 loss ppo:  -0.01198, loss val: 0.04905
[2022-12-06 21:21:44,789] [INFO] [controller] EPOCH 2 loss ppo:  -0.01410, loss val: 0.04955
[2022-12-06 21:21:44,847] [INFO] [controller] EPOCH 3 loss ppo:  -0.01838, loss val: 0.04891
[2022-12-06 21:21:44,938] [INFO] [controller] EPOCH 4 loss ppo:  -0.02097, loss val: 0.05011
[2022-12-06 21:21:44,949] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:21:45,135] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:21:45,135] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:21:49,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:21:53,965] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:21:58,613] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:22:03,176] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:22:07,719] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:22:12,175] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:22:16,899] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:22:21,484] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:22:26,219] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:22:30,697] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.368364509899157
[2022-12-06 21:22:30,697] [INFO] [runner_train_mujoco] Average state value: 0.3812997782031695
[2022-12-06 21:22:30,697] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 21:22:30,765] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.04618
[2022-12-06 21:22:30,818] [INFO] [controller] EPOCH 2 loss ppo:  -0.01426, loss val: 0.04663
[2022-12-06 21:22:30,870] [INFO] [controller] EPOCH 3 loss ppo:  -0.01838, loss val: 0.04574
[2022-12-06 21:22:30,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.01858, loss val: 0.04905
[2022-12-06 21:22:30,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:22:31,118] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:22:31,119] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:22:35,234] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:22:39,525] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:22:43,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:22:48,443] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:22:52,929] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:22:57,426] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:23:02,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:23:06,606] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:23:11,195] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:23:15,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.411228043529771
[2022-12-06 21:23:15,907] [INFO] [runner_train_mujoco] Average state value: 0.37670533307393395
[2022-12-06 21:23:15,907] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 21:23:16,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01196, loss val: 0.04372
[2022-12-06 21:23:16,171] [INFO] [controller] EPOCH 2 loss ppo:  -0.01329, loss val: 0.04352
[2022-12-06 21:23:16,281] [INFO] [controller] EPOCH 3 loss ppo:  -0.01698, loss val: 0.04500
[2022-12-06 21:23:16,343] [INFO] [controller] EPOCH 4 loss ppo:  -0.02133, loss val: 0.04468
[2022-12-06 21:23:16,355] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:23:16,536] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:23:16,538] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:23:20,813] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:23:25,166] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:23:29,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:23:34,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:23:38,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:23:41,935] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:23:46,327] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:23:50,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:23:54,630] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:23:58,844] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.377383022693218
[2022-12-06 21:23:58,844] [INFO] [runner_train_mujoco] Average state value: 0.3774124539395173
[2022-12-06 21:23:58,844] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 21:23:58,906] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.05032
[2022-12-06 21:23:58,953] [INFO] [controller] EPOCH 2 loss ppo:  -0.01263, loss val: 0.04773
[2022-12-06 21:23:59,001] [INFO] [controller] EPOCH 3 loss ppo:  -0.01482, loss val: 0.04927
[2022-12-06 21:23:59,060] [INFO] [controller] EPOCH 4 loss ppo:  -0.01686, loss val: 0.04780
[2022-12-06 21:23:59,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:23:59,248] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:23:59,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:24:03,592] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:24:07,932] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:24:12,493] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:24:16,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:24:21,294] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:24:25,628] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:24:29,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:24:34,147] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:24:38,275] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:24:42,255] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.418506834490904
[2022-12-06 21:24:42,256] [INFO] [runner_train_mujoco] Average state value: 0.37711203241348273
[2022-12-06 21:24:42,256] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 21:24:42,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.04822
[2022-12-06 21:24:42,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.01261, loss val: 0.04577
[2022-12-06 21:24:42,427] [INFO] [controller] EPOCH 3 loss ppo:  -0.01394, loss val: 0.04464
[2022-12-06 21:24:42,475] [INFO] [controller] EPOCH 4 loss ppo:  -0.01595, loss val: 0.04593
[2022-12-06 21:24:42,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:24:42,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:24:42,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:24:46,987] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:24:51,186] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:24:55,589] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:24:59,901] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:25:03,591] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:25:07,914] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:25:11,865] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:25:15,913] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:25:20,104] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:25:24,359] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.463752848407027
[2022-12-06 21:25:24,359] [INFO] [runner_train_mujoco] Average state value: 0.3796746670603752
[2022-12-06 21:25:24,360] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 21:25:24,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.05159
[2022-12-06 21:25:24,461] [INFO] [controller] EPOCH 2 loss ppo:  -0.01208, loss val: 0.05144
[2022-12-06 21:25:24,511] [INFO] [controller] EPOCH 3 loss ppo:  -0.01267, loss val: 0.05141
[2022-12-06 21:25:24,558] [INFO] [controller] EPOCH 4 loss ppo:  -0.01328, loss val: 0.05220
[2022-12-06 21:25:24,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:25:24,696] [INFO] [optimize] Finished learning.
