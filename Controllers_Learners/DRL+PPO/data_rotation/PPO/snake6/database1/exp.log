[2022-12-06 13:30:37,446] [INFO] [optimize] Starting learning
[2022-12-06 13:30:37,456] [INFO] [optimize] Starting learning process..
[2022-12-06 13:30:37,545] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:30:37,545] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:30:42,853] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:30:46,173] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:30:49,700] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:30:53,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:30:59,315] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:31:03,647] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:31:08,280] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:31:12,679] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:31:17,087] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:31:21,811] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.45488805178350306
[2022-12-06 13:31:21,812] [INFO] [runner_train_mujoco] Average state value: 0.02171527340511481
[2022-12-06 13:31:21,812] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 13:31:21,903] [INFO] [controller] EPOCH 1 loss ppo:  -0.01820, loss val: 0.44374
[2022-12-06 13:31:21,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.03148, loss val: 0.37831
[2022-12-06 13:31:22,058] [INFO] [controller] EPOCH 3 loss ppo:  -0.03955, loss val: 0.32246
[2022-12-06 13:31:22,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.04269, loss val: 0.27717
[2022-12-06 13:31:22,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:31:22,530] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:31:22,531] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:31:31,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:31:36,850] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:31:42,262] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:31:48,025] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:31:53,674] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:31:59,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:32:06,816] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:32:12,808] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:32:17,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:32:23,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6668533696932304
[2022-12-06 13:32:23,525] [INFO] [runner_train_mujoco] Average state value: 0.20010719735796254
[2022-12-06 13:32:23,525] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 13:32:23,687] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.12749
[2022-12-06 13:32:23,808] [INFO] [controller] EPOCH 2 loss ppo:  -0.03068, loss val: 0.10340
[2022-12-06 13:32:23,869] [INFO] [controller] EPOCH 3 loss ppo:  -0.03602, loss val: 0.08048
[2022-12-06 13:32:23,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.03869, loss val: 0.06722
[2022-12-06 13:32:23,940] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:32:24,129] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:32:24,129] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:32:29,589] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:32:35,310] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:32:40,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:32:45,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:32:50,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:32:55,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:33:01,221] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:33:06,627] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:33:12,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:33:17,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44416794409707966
[2022-12-06 13:33:17,305] [INFO] [runner_train_mujoco] Average state value: 0.33763822505623103
[2022-12-06 13:33:17,305] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 13:33:17,423] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.05441
[2022-12-06 13:33:17,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.02548, loss val: 0.04335
[2022-12-06 13:33:17,555] [INFO] [controller] EPOCH 3 loss ppo:  -0.03658, loss val: 0.03711
[2022-12-06 13:33:17,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.03923, loss val: 0.03089
[2022-12-06 13:33:17,648] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:33:17,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:33:17,835] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:33:23,399] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:33:28,895] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:33:34,579] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:33:40,116] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:33:45,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:33:51,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:33:57,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:34:03,107] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:34:08,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:34:14,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5494281019907636
[2022-12-06 13:34:14,524] [INFO] [runner_train_mujoco] Average state value: 0.4642896868089835
[2022-12-06 13:34:14,524] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 13:34:14,586] [INFO] [controller] EPOCH 1 loss ppo:  -0.01213, loss val: 0.03878
[2022-12-06 13:34:14,637] [INFO] [controller] EPOCH 2 loss ppo:  -0.02521, loss val: 0.03892
[2022-12-06 13:34:14,694] [INFO] [controller] EPOCH 3 loss ppo:  -0.02610, loss val: 0.03613
[2022-12-06 13:34:14,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.02985, loss val: 0.03606
[2022-12-06 13:34:14,758] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:34:14,964] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:34:14,965] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:34:20,740] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:34:26,872] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:34:32,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:34:38,717] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:34:44,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:34:50,099] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:34:56,053] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:35:01,683] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:35:07,823] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:35:13,409] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5685753963414506
[2022-12-06 13:35:13,409] [INFO] [runner_train_mujoco] Average state value: 0.519274660617113
[2022-12-06 13:35:13,409] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 13:35:13,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.00949, loss val: 0.03036
[2022-12-06 13:35:13,559] [INFO] [controller] EPOCH 2 loss ppo:  -0.02269, loss val: 0.03008
[2022-12-06 13:35:13,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.03021, loss val: 0.02927
[2022-12-06 13:35:13,674] [INFO] [controller] EPOCH 4 loss ppo:  -0.03141, loss val: 0.02911
[2022-12-06 13:35:13,685] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:35:13,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:35:13,880] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:35:20,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:35:26,395] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:35:32,574] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:35:38,341] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:35:44,402] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:35:50,359] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:35:56,850] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:36:03,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:36:09,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:36:15,479] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7491258323287443
[2022-12-06 13:36:15,480] [INFO] [runner_train_mujoco] Average state value: 0.5140648543636004
[2022-12-06 13:36:15,480] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 13:36:15,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.03172
[2022-12-06 13:36:15,671] [INFO] [controller] EPOCH 2 loss ppo:  -0.02504, loss val: 0.03159
[2022-12-06 13:36:15,746] [INFO] [controller] EPOCH 3 loss ppo:  -0.02744, loss val: 0.03116
[2022-12-06 13:36:15,807] [INFO] [controller] EPOCH 4 loss ppo:  -0.03242, loss val: 0.03128
[2022-12-06 13:36:15,819] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:36:16,041] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:36:16,041] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:36:22,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:36:28,540] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:36:34,720] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:36:41,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:36:47,511] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:36:53,621] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:36:59,904] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:37:06,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:37:12,989] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:37:19,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0600410925532677
[2022-12-06 13:37:19,325] [INFO] [runner_train_mujoco] Average state value: 0.5045283737579982
[2022-12-06 13:37:19,325] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 13:37:19,408] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.03037
[2022-12-06 13:37:19,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.02470, loss val: 0.03179
[2022-12-06 13:37:19,525] [INFO] [controller] EPOCH 3 loss ppo:  -0.02831, loss val: 0.02969
[2022-12-06 13:37:19,616] [INFO] [controller] EPOCH 4 loss ppo:  -0.03230, loss val: 0.03097
[2022-12-06 13:37:19,628] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:37:19,851] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:37:19,852] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:37:25,621] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:37:31,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:37:37,637] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:37:43,194] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:37:48,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:37:54,840] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:38:00,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:38:06,762] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:38:12,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:38:18,231] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.037352751084026
[2022-12-06 13:38:18,232] [INFO] [runner_train_mujoco] Average state value: 0.4931375770370166
[2022-12-06 13:38:18,232] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 13:38:18,299] [INFO] [controller] EPOCH 1 loss ppo:  -0.01270, loss val: 0.04276
[2022-12-06 13:38:18,353] [INFO] [controller] EPOCH 2 loss ppo:  -0.02464, loss val: 0.04210
[2022-12-06 13:38:18,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.02717, loss val: 0.03951
[2022-12-06 13:38:18,460] [INFO] [controller] EPOCH 4 loss ppo:  -0.03105, loss val: 0.03984
[2022-12-06 13:38:18,472] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:38:18,667] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:38:18,667] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:38:24,390] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:38:30,254] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:38:36,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:38:42,490] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:38:47,853] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:38:53,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:38:59,275] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:39:04,719] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:39:10,188] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:39:15,488] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3415081693208868
[2022-12-06 13:39:15,488] [INFO] [runner_train_mujoco] Average state value: 0.5463354662656784
[2022-12-06 13:39:15,488] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 13:39:15,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.03578
[2022-12-06 13:39:15,642] [INFO] [controller] EPOCH 2 loss ppo:  -0.02602, loss val: 0.03677
[2022-12-06 13:39:15,744] [INFO] [controller] EPOCH 3 loss ppo:  -0.02953, loss val: 0.03689
[2022-12-06 13:39:15,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.03621, loss val: 0.03672
[2022-12-06 13:39:15,872] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:39:16,083] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:39:16,083] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:39:21,312] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:39:26,844] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:39:32,288] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:39:37,357] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:39:42,894] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:39:47,923] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:39:53,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:39:58,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:40:04,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:40:10,319] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.678453909290455
[2022-12-06 13:40:10,320] [INFO] [runner_train_mujoco] Average state value: 0.5593192874193191
[2022-12-06 13:40:10,320] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 13:40:10,490] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.04526
[2022-12-06 13:40:10,736] [INFO] [controller] EPOCH 2 loss ppo:  -0.02721, loss val: 0.04127
[2022-12-06 13:40:10,934] [INFO] [controller] EPOCH 3 loss ppo:  -0.03168, loss val: 0.03927
[2022-12-06 13:40:11,019] [INFO] [controller] EPOCH 4 loss ppo:  -0.03499, loss val: 0.03776
[2022-12-06 13:40:11,031] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:40:11,229] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:40:11,229] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:40:17,295] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:40:22,790] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:40:28,079] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:40:33,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:40:38,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:40:43,999] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:40:49,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:40:54,084] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:40:59,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:41:04,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8134054691880828
[2022-12-06 13:41:04,316] [INFO] [runner_train_mujoco] Average state value: 0.48663461198409397
[2022-12-06 13:41:04,316] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 13:41:04,436] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.03998
[2022-12-06 13:41:04,521] [INFO] [controller] EPOCH 2 loss ppo:  -0.02547, loss val: 0.03932
[2022-12-06 13:41:04,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.02926, loss val: 0.04085
[2022-12-06 13:41:04,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.03278, loss val: 0.03978
[2022-12-06 13:41:04,706] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:41:04,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:41:04,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:41:10,551] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:41:16,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:41:21,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:41:27,465] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:41:33,007] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:41:38,562] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:41:43,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:41:49,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:41:54,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:42:00,213] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0696774145298766
[2022-12-06 13:42:00,213] [INFO] [runner_train_mujoco] Average state value: 0.4521689724624157
[2022-12-06 13:42:00,214] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 13:42:00,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.05409
[2022-12-06 13:42:00,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.02861, loss val: 0.05262
[2022-12-06 13:42:00,504] [INFO] [controller] EPOCH 3 loss ppo:  -0.02858, loss val: 0.05177
[2022-12-06 13:42:00,567] [INFO] [controller] EPOCH 4 loss ppo:  -0.03329, loss val: 0.04950
[2022-12-06 13:42:00,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:42:00,786] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:42:00,787] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:42:05,903] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:42:11,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:42:17,027] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:42:22,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:42:28,260] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:42:33,705] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:42:39,484] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:42:45,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:42:50,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:42:56,375] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3572106572532783
[2022-12-06 13:42:56,376] [INFO] [runner_train_mujoco] Average state value: 0.5051672389705976
[2022-12-06 13:42:56,376] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 13:42:56,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.03997
[2022-12-06 13:42:56,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.02303, loss val: 0.04232
[2022-12-06 13:42:56,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.03123, loss val: 0.04155
[2022-12-06 13:42:56,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.03684, loss val: 0.04193
[2022-12-06 13:42:56,787] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:42:56,988] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:42:56,989] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:43:02,696] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:43:08,082] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:43:13,732] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:43:19,570] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:43:25,322] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:43:30,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:43:36,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:43:42,078] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:43:47,905] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:43:53,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.793068630401797
[2022-12-06 13:43:53,760] [INFO] [runner_train_mujoco] Average state value: 0.5109698753158252
[2022-12-06 13:43:53,760] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 13:43:53,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01824, loss val: 0.04333
[2022-12-06 13:43:53,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.03027, loss val: 0.04211
[2022-12-06 13:43:54,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.03272, loss val: 0.04343
[2022-12-06 13:43:54,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.03810, loss val: 0.04058
[2022-12-06 13:43:54,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:43:54,329] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:43:54,329] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:44:00,153] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:44:06,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:44:12,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:44:18,209] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:44:24,452] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:44:30,365] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:44:36,296] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:44:42,414] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:44:48,135] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:44:54,313] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6808336582786545
[2022-12-06 13:44:54,313] [INFO] [runner_train_mujoco] Average state value: 0.4689309097925823
[2022-12-06 13:44:54,313] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 13:44:54,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04403
[2022-12-06 13:44:54,440] [INFO] [controller] EPOCH 2 loss ppo:  -0.03254, loss val: 0.04169
[2022-12-06 13:44:54,571] [INFO] [controller] EPOCH 3 loss ppo:  -0.03615, loss val: 0.04434
[2022-12-06 13:44:54,633] [INFO] [controller] EPOCH 4 loss ppo:  -0.03756, loss val: 0.04136
[2022-12-06 13:44:54,646] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:44:54,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:44:54,854] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:45:00,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:45:06,879] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:45:13,113] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:45:19,075] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:45:24,642] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:45:30,328] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:45:35,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:45:41,820] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:45:47,488] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:45:53,416] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9738589036085195
[2022-12-06 13:45:53,417] [INFO] [runner_train_mujoco] Average state value: 0.47283578451474506
[2022-12-06 13:45:53,417] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 13:45:53,534] [INFO] [controller] EPOCH 1 loss ppo:  -0.01575, loss val: 0.03604
[2022-12-06 13:45:53,614] [INFO] [controller] EPOCH 2 loss ppo:  -0.02858, loss val: 0.03226
[2022-12-06 13:45:53,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.03694, loss val: 0.03524
[2022-12-06 13:45:53,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.03935, loss val: 0.03300
[2022-12-06 13:45:53,795] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:45:53,985] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:45:53,985] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:45:59,940] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:46:05,897] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:46:11,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:46:17,179] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:46:22,356] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:46:28,084] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:46:33,347] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:46:39,184] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:46:44,489] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:46:49,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4682186591799122
[2022-12-06 13:46:49,839] [INFO] [runner_train_mujoco] Average state value: 0.48423287926117586
[2022-12-06 13:46:49,839] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 13:46:49,917] [INFO] [controller] EPOCH 1 loss ppo:  -0.01589, loss val: 0.04269
[2022-12-06 13:46:49,971] [INFO] [controller] EPOCH 2 loss ppo:  -0.02629, loss val: 0.04146
[2022-12-06 13:46:50,038] [INFO] [controller] EPOCH 3 loss ppo:  -0.03471, loss val: 0.03959
[2022-12-06 13:46:50,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.03594, loss val: 0.03836
[2022-12-06 13:46:50,111] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:46:50,307] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:46:50,307] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:46:55,777] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:47:01,549] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:47:06,807] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:47:12,299] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:47:17,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:47:22,957] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:47:28,439] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:47:33,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:47:38,566] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:47:43,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.79105451323284
[2022-12-06 13:47:43,542] [INFO] [runner_train_mujoco] Average state value: 0.4280328755378723
[2022-12-06 13:47:43,542] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 13:47:43,637] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.03681
[2022-12-06 13:47:43,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.02445, loss val: 0.03747
[2022-12-06 13:47:43,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.03258, loss val: 0.03819
[2022-12-06 13:47:43,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.03076, loss val: 0.03982
[2022-12-06 13:47:43,929] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:47:44,113] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:47:44,114] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:47:49,278] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:47:54,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:47:59,992] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:48:05,157] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:48:10,533] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:48:15,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:48:20,977] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:48:26,011] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:48:30,780] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:48:36,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.086255155072829
[2022-12-06 13:48:36,272] [INFO] [runner_train_mujoco] Average state value: 0.41960165262222293
[2022-12-06 13:48:36,272] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 13:48:36,338] [INFO] [controller] EPOCH 1 loss ppo:  -0.01248, loss val: 0.03435
[2022-12-06 13:48:36,391] [INFO] [controller] EPOCH 2 loss ppo:  -0.01500, loss val: 0.03443
[2022-12-06 13:48:36,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.02688, loss val: 0.03784
[2022-12-06 13:48:36,510] [INFO] [controller] EPOCH 4 loss ppo:  -0.03014, loss val: 0.03826
[2022-12-06 13:48:36,521] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:48:36,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:48:36,708] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:48:41,524] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:48:46,736] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:48:52,065] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:48:57,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:49:02,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:49:07,151] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:49:12,457] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:49:17,539] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:49:22,589] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:49:27,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.976328534241701
[2022-12-06 13:49:27,370] [INFO] [runner_train_mujoco] Average state value: 0.4270842851201693
[2022-12-06 13:49:27,370] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 13:49:27,445] [INFO] [controller] EPOCH 1 loss ppo:  -0.01737, loss val: 0.03343
[2022-12-06 13:49:27,526] [INFO] [controller] EPOCH 2 loss ppo:  -0.01491, loss val: 0.03655
[2022-12-06 13:49:27,608] [INFO] [controller] EPOCH 3 loss ppo:  -0.02558, loss val: 0.03594
[2022-12-06 13:49:27,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.02906, loss val: 0.03440
[2022-12-06 13:49:27,706] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:49:27,890] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:49:27,890] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:49:32,838] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:49:37,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:49:43,048] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:49:47,939] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:49:52,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:49:57,621] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:50:02,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:50:07,448] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:50:12,380] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:50:17,449] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.342748144770948
[2022-12-06 13:50:17,449] [INFO] [runner_train_mujoco] Average state value: 0.43127815329035124
[2022-12-06 13:50:17,449] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 13:50:17,509] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04241
[2022-12-06 13:50:17,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.01600, loss val: 0.04408
[2022-12-06 13:50:17,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.02873, loss val: 0.03975
[2022-12-06 13:50:17,668] [INFO] [controller] EPOCH 4 loss ppo:  -0.02930, loss val: 0.03832
[2022-12-06 13:50:17,679] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:50:17,908] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:50:17,909] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:50:22,929] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:50:28,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:50:33,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:50:38,506] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:50:43,673] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:50:48,929] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:50:54,289] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:50:59,507] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:51:04,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:51:09,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.452287527774605
[2022-12-06 13:51:09,837] [INFO] [runner_train_mujoco] Average state value: 0.39671886155009267
[2022-12-06 13:51:09,837] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 13:51:09,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.01798, loss val: 0.04976
[2022-12-06 13:51:10,032] [INFO] [controller] EPOCH 2 loss ppo:  -0.01375, loss val: 0.04981
[2022-12-06 13:51:10,130] [INFO] [controller] EPOCH 3 loss ppo:  -0.02729, loss val: 0.05053
[2022-12-06 13:51:10,195] [INFO] [controller] EPOCH 4 loss ppo:  -0.02801, loss val: 0.04962
[2022-12-06 13:51:10,207] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:51:10,393] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:51:10,394] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:51:15,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:51:21,537] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:51:26,624] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:51:32,018] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:51:37,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:51:42,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:51:47,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:51:52,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:51:58,634] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:52:04,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.343828208329908
[2022-12-06 13:52:04,026] [INFO] [runner_train_mujoco] Average state value: 0.39355859378973646
[2022-12-06 13:52:04,026] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 13:52:04,105] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.05387
[2022-12-06 13:52:04,202] [INFO] [controller] EPOCH 2 loss ppo:  -0.01920, loss val: 0.05116
[2022-12-06 13:52:04,302] [INFO] [controller] EPOCH 3 loss ppo:  -0.02624, loss val: 0.05197
[2022-12-06 13:52:04,409] [INFO] [controller] EPOCH 4 loss ppo:  -0.03146, loss val: 0.05169
[2022-12-06 13:52:04,421] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:52:04,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:52:04,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:52:10,417] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:52:15,891] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:52:21,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:52:27,119] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:52:32,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:52:38,055] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:52:43,884] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:52:49,422] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:52:54,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:52:59,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.566910715170449
[2022-12-06 13:52:59,837] [INFO] [runner_train_mujoco] Average state value: 0.43134198693434395
[2022-12-06 13:52:59,837] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 13:52:59,904] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.05034
[2022-12-06 13:52:59,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.01697, loss val: 0.04960
[2022-12-06 13:53:00,041] [INFO] [controller] EPOCH 3 loss ppo:  -0.02794, loss val: 0.05126
[2022-12-06 13:53:00,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.03098, loss val: 0.05024
[2022-12-06 13:53:00,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:53:00,307] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:53:00,308] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:53:06,044] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:53:11,677] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:53:17,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:53:23,585] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:53:29,651] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:53:35,408] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:53:41,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:53:47,010] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:53:52,859] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:53:58,486] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.352101205390198
[2022-12-06 13:53:58,486] [INFO] [runner_train_mujoco] Average state value: 0.4408194048702717
[2022-12-06 13:53:58,486] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 13:53:58,576] [INFO] [controller] EPOCH 1 loss ppo:  -0.01507, loss val: 0.03620
[2022-12-06 13:53:58,631] [INFO] [controller] EPOCH 2 loss ppo:  -0.01365, loss val: 0.03671
[2022-12-06 13:53:58,728] [INFO] [controller] EPOCH 3 loss ppo:  -0.02432, loss val: 0.03549
[2022-12-06 13:53:58,799] [INFO] [controller] EPOCH 4 loss ppo:  -0.02411, loss val: 0.03619
[2022-12-06 13:53:58,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:53:59,043] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:53:59,043] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:54:04,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:54:10,177] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:54:15,618] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:54:21,406] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:54:26,515] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:54:31,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:54:37,162] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:54:42,337] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:54:47,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:54:53,413] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.731803296850252
[2022-12-06 13:54:53,414] [INFO] [runner_train_mujoco] Average state value: 0.41108561880389854
[2022-12-06 13:54:53,414] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 13:54:53,487] [INFO] [controller] EPOCH 1 loss ppo:  -0.01590, loss val: 0.04310
[2022-12-06 13:54:53,564] [INFO] [controller] EPOCH 2 loss ppo:  -0.01773, loss val: 0.04296
[2022-12-06 13:54:53,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.02550, loss val: 0.04466
[2022-12-06 13:54:53,756] [INFO] [controller] EPOCH 4 loss ppo:  -0.02627, loss val: 0.04459
[2022-12-06 13:54:53,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:54:54,014] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:54:54,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:54:59,460] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:55:04,805] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:55:10,013] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:55:15,652] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:55:21,193] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:55:26,423] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:55:31,459] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:55:36,674] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:55:41,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:55:46,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.821757470431146
[2022-12-06 13:55:46,524] [INFO] [runner_train_mujoco] Average state value: 0.39405726818243664
[2022-12-06 13:55:46,525] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 13:55:46,597] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04055
[2022-12-06 13:55:46,647] [INFO] [controller] EPOCH 2 loss ppo:  -0.02266, loss val: 0.03938
[2022-12-06 13:55:46,699] [INFO] [controller] EPOCH 3 loss ppo:  -0.03022, loss val: 0.03949
[2022-12-06 13:55:46,759] [INFO] [controller] EPOCH 4 loss ppo:  -0.03130, loss val: 0.04071
[2022-12-06 13:55:46,770] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:55:46,949] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:55:46,949] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:55:51,738] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:55:56,708] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:56:01,519] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:56:06,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:56:11,748] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:56:16,796] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:56:22,121] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:56:27,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:56:32,697] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:56:37,742] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.796721152203446
[2022-12-06 13:56:37,743] [INFO] [runner_train_mujoco] Average state value: 0.3940000156362852
[2022-12-06 13:56:37,743] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 13:56:37,882] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.02970
[2022-12-06 13:56:38,014] [INFO] [controller] EPOCH 2 loss ppo:  -0.01854, loss val: 0.02958
[2022-12-06 13:56:38,077] [INFO] [controller] EPOCH 3 loss ppo:  -0.02472, loss val: 0.02921
[2022-12-06 13:56:38,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.03137, loss val: 0.03480
[2022-12-06 13:56:38,189] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:56:38,379] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:56:38,379] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:56:43,728] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:56:48,472] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:56:53,704] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:56:58,236] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:57:03,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:57:07,934] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:57:12,754] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:57:17,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:57:22,748] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:57:27,923] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.840835625948147
[2022-12-06 13:57:27,923] [INFO] [runner_train_mujoco] Average state value: 0.4007022961179415
[2022-12-06 13:57:27,923] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 13:57:28,049] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.04186
[2022-12-06 13:57:28,099] [INFO] [controller] EPOCH 2 loss ppo:  -0.01900, loss val: 0.04152
[2022-12-06 13:57:28,154] [INFO] [controller] EPOCH 3 loss ppo:  -0.02360, loss val: 0.04208
[2022-12-06 13:57:28,205] [INFO] [controller] EPOCH 4 loss ppo:  -0.02982, loss val: 0.04082
[2022-12-06 13:57:28,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:57:28,406] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:57:28,406] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:57:33,501] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:57:38,794] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:57:44,125] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:57:49,248] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:57:54,777] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:57:59,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:58:06,019] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:58:13,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:58:20,320] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:58:27,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.842142895447493
[2022-12-06 13:58:27,333] [INFO] [runner_train_mujoco] Average state value: 0.4334834116895994
[2022-12-06 13:58:27,333] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 13:58:27,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.04484
[2022-12-06 13:58:27,569] [INFO] [controller] EPOCH 2 loss ppo:  -0.01765, loss val: 0.04479
[2022-12-06 13:58:27,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.02439, loss val: 0.04426
[2022-12-06 13:58:27,891] [INFO] [controller] EPOCH 4 loss ppo:  -0.02760, loss val: 0.04339
[2022-12-06 13:58:27,902] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:58:28,105] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:58:28,105] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:58:33,417] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:58:39,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:58:45,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:58:53,798] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:59:01,560] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:59:09,074] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:59:15,517] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:59:22,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:59:28,882] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:59:36,303] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.010978905223206
[2022-12-06 13:59:36,303] [INFO] [runner_train_mujoco] Average state value: 0.4187521238525709
[2022-12-06 13:59:36,304] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 13:59:36,507] [INFO] [controller] EPOCH 1 loss ppo:  -0.01174, loss val: 0.04079
[2022-12-06 13:59:37,437] [INFO] [controller] EPOCH 2 loss ppo:  -0.01809, loss val: 0.04117
[2022-12-06 13:59:38,492] [INFO] [controller] EPOCH 3 loss ppo:  -0.02169, loss val: 0.04180
[2022-12-06 13:59:39,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.02659, loss val: 0.04119
[2022-12-06 13:59:39,566] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:59:39,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:59:39,870] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:59:46,845] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:59:53,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:59:59,159] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:00:05,301] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:00:10,925] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:00:17,551] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:00:23,650] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:00:29,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:00:35,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:00:43,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.807925050308204
[2022-12-06 14:00:43,126] [INFO] [runner_train_mujoco] Average state value: 0.4102224308947722
[2022-12-06 14:00:43,127] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 14:00:43,311] [INFO] [controller] EPOCH 1 loss ppo:  -0.01193, loss val: 0.04218
[2022-12-06 14:00:43,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.01666, loss val: 0.04140
[2022-12-06 14:00:43,673] [INFO] [controller] EPOCH 3 loss ppo:  -0.02127, loss val: 0.04188
[2022-12-06 14:00:43,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.02714, loss val: 0.04100
[2022-12-06 14:00:43,897] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:00:44,153] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:00:44,153] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:00:52,647] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:01:01,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:01:09,624] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:01:18,269] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:01:26,426] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:01:34,480] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:01:44,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:01:53,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:02:00,987] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:02:07,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.998933689526206
[2022-12-06 14:02:07,372] [INFO] [runner_train_mujoco] Average state value: 0.4281035012205442
[2022-12-06 14:02:07,372] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 14:02:07,466] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.04790
[2022-12-06 14:02:07,608] [INFO] [controller] EPOCH 2 loss ppo:  -0.02179, loss val: 0.04819
[2022-12-06 14:02:07,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.02821, loss val: 0.04801
[2022-12-06 14:02:07,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.03164, loss val: 0.04968
[2022-12-06 14:02:07,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:02:08,044] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:02:08,045] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:02:14,342] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:02:20,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:02:27,027] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:02:33,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:02:40,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:02:46,110] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:02:52,265] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:02:58,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:03:04,247] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:03:11,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.985259250582555
[2022-12-06 14:03:11,238] [INFO] [runner_train_mujoco] Average state value: 0.4258405845959981
[2022-12-06 14:03:11,238] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 14:03:11,341] [INFO] [controller] EPOCH 1 loss ppo:  -0.01150, loss val: 0.04390
[2022-12-06 14:03:11,397] [INFO] [controller] EPOCH 2 loss ppo:  -0.02168, loss val: 0.04312
[2022-12-06 14:03:11,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.02350, loss val: 0.04304
[2022-12-06 14:03:11,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.03005, loss val: 0.04279
[2022-12-06 14:03:11,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:03:11,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:03:11,736] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:03:18,114] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:03:24,957] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:03:31,126] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:03:36,649] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:03:42,166] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:03:48,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:03:53,647] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:03:59,070] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:04:04,536] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:04:10,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.098167597449387
[2022-12-06 14:04:10,196] [INFO] [runner_train_mujoco] Average state value: 0.43418789072831465
[2022-12-06 14:04:10,196] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 14:04:10,286] [INFO] [controller] EPOCH 1 loss ppo:  -0.01094, loss val: 0.04865
[2022-12-06 14:04:10,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.01452, loss val: 0.04917
[2022-12-06 14:04:10,403] [INFO] [controller] EPOCH 3 loss ppo:  -0.01873, loss val: 0.04645
[2022-12-06 14:04:10,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.02280, loss val: 0.04851
[2022-12-06 14:04:10,480] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:04:10,698] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:04:10,699] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:04:16,263] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:04:21,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:04:27,031] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:04:32,516] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:04:37,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:04:43,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:04:48,465] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:04:53,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:04:59,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:05:04,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.052495539993211
[2022-12-06 14:05:04,462] [INFO] [runner_train_mujoco] Average state value: 0.42091078708569213
[2022-12-06 14:05:04,463] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 14:05:04,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.04611
[2022-12-06 14:05:04,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.02007, loss val: 0.04663
[2022-12-06 14:05:04,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.02445, loss val: 0.04637
[2022-12-06 14:05:04,750] [INFO] [controller] EPOCH 4 loss ppo:  -0.02828, loss val: 0.04642
[2022-12-06 14:05:04,762] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:05:04,962] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:05:04,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:05:09,767] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:05:14,993] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:05:20,298] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:05:25,922] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:05:31,766] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:05:37,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:05:43,181] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:05:48,537] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:05:53,548] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:05:58,513] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.983292250964562
[2022-12-06 14:05:58,514] [INFO] [runner_train_mujoco] Average state value: 0.412478460252285
[2022-12-06 14:05:58,514] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 14:05:58,574] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.04455
[2022-12-06 14:05:58,623] [INFO] [controller] EPOCH 2 loss ppo:  -0.01814, loss val: 0.04436
[2022-12-06 14:05:58,671] [INFO] [controller] EPOCH 3 loss ppo:  -0.02117, loss val: 0.04432
[2022-12-06 14:05:58,769] [INFO] [controller] EPOCH 4 loss ppo:  -0.02806, loss val: 0.04394
[2022-12-06 14:05:58,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:05:58,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:05:58,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:06:04,239] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:06:09,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:06:14,807] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:06:20,656] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:06:28,693] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:06:36,307] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:06:43,248] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:06:49,944] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:06:57,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:07:05,416] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.131257679382633
[2022-12-06 14:07:05,416] [INFO] [runner_train_mujoco] Average state value: 0.42130576936403913
[2022-12-06 14:07:05,416] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 14:07:06,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.00984, loss val: 0.04878
[2022-12-06 14:07:06,254] [INFO] [controller] EPOCH 2 loss ppo:  -0.01466, loss val: 0.04743
[2022-12-06 14:07:06,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.01793, loss val: 0.04738
[2022-12-06 14:07:07,130] [INFO] [controller] EPOCH 4 loss ppo:  -0.02312, loss val: 0.04942
[2022-12-06 14:07:07,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:07:07,543] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:07:07,543] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:07:14,948] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:07:20,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:07:27,333] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:07:34,993] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:07:42,806] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:07:49,320] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:07:54,561] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:07:59,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:08:04,987] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:08:10,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.037474150721152
[2022-12-06 14:08:10,485] [INFO] [runner_train_mujoco] Average state value: 0.43157981626192726
[2022-12-06 14:08:10,485] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 14:08:10,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01138, loss val: 0.04545
[2022-12-06 14:08:10,635] [INFO] [controller] EPOCH 2 loss ppo:  -0.02038, loss val: 0.04520
[2022-12-06 14:08:10,701] [INFO] [controller] EPOCH 3 loss ppo:  -0.02366, loss val: 0.04584
[2022-12-06 14:08:10,760] [INFO] [controller] EPOCH 4 loss ppo:  -0.02972, loss val: 0.04451
[2022-12-06 14:08:10,772] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:08:10,968] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:08:10,969] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:08:16,542] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:08:21,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:08:27,368] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:08:32,803] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:08:38,445] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:08:44,237] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:08:49,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:08:55,205] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:09:00,362] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:09:05,962] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.073100803548301
[2022-12-06 14:09:05,962] [INFO] [runner_train_mujoco] Average state value: 0.4210380558768908
[2022-12-06 14:09:05,962] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 14:09:06,046] [INFO] [controller] EPOCH 1 loss ppo:  -0.01104, loss val: 0.05054
[2022-12-06 14:09:06,133] [INFO] [controller] EPOCH 2 loss ppo:  -0.01840, loss val: 0.05058
[2022-12-06 14:09:06,193] [INFO] [controller] EPOCH 3 loss ppo:  -0.01932, loss val: 0.04944
[2022-12-06 14:09:06,248] [INFO] [controller] EPOCH 4 loss ppo:  -0.02550, loss val: 0.04889
[2022-12-06 14:09:06,260] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:09:06,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:09:06,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:09:12,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:09:18,501] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:09:23,857] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:09:29,380] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:09:35,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:09:40,709] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:09:46,369] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:09:52,166] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:09:57,917] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:10:03,726] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.004551964494166
[2022-12-06 14:10:03,726] [INFO] [runner_train_mujoco] Average state value: 0.4015509146650632
[2022-12-06 14:10:03,726] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 14:10:03,810] [INFO] [controller] EPOCH 1 loss ppo:  -0.01256, loss val: 0.03693
[2022-12-06 14:10:03,899] [INFO] [controller] EPOCH 2 loss ppo:  -0.02001, loss val: 0.03740
[2022-12-06 14:10:03,967] [INFO] [controller] EPOCH 3 loss ppo:  -0.02313, loss val: 0.03701
[2022-12-06 14:10:04,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.02820, loss val: 0.03594
[2022-12-06 14:10:04,049] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:10:04,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:10:04,244] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:10:09,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:10:15,619] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:10:21,031] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:10:26,355] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:10:31,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:10:37,426] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:10:42,879] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:10:48,520] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:10:54,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:10:59,161] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.927817939026702
[2022-12-06 14:10:59,161] [INFO] [runner_train_mujoco] Average state value: 0.40106776404380795
[2022-12-06 14:10:59,161] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 14:10:59,289] [INFO] [controller] EPOCH 1 loss ppo:  -0.01144, loss val: 0.04798
[2022-12-06 14:10:59,416] [INFO] [controller] EPOCH 2 loss ppo:  -0.01710, loss val: 0.04823
[2022-12-06 14:10:59,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.01629, loss val: 0.04774
[2022-12-06 14:10:59,598] [INFO] [controller] EPOCH 4 loss ppo:  -0.02259, loss val: 0.04768
[2022-12-06 14:10:59,610] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:10:59,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:10:59,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:11:05,024] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:11:10,882] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:11:16,476] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:11:22,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:11:28,431] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:11:34,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:11:39,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:11:45,088] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:11:50,183] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:11:55,384] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.230085102821541
[2022-12-06 14:11:55,384] [INFO] [runner_train_mujoco] Average state value: 0.3939085435668628
[2022-12-06 14:11:55,384] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 14:11:55,475] [INFO] [controller] EPOCH 1 loss ppo:  -0.01087, loss val: 0.04701
[2022-12-06 14:11:55,539] [INFO] [controller] EPOCH 2 loss ppo:  -0.01695, loss val: 0.04721
[2022-12-06 14:11:55,664] [INFO] [controller] EPOCH 3 loss ppo:  -0.01760, loss val: 0.04673
[2022-12-06 14:11:55,759] [INFO] [controller] EPOCH 4 loss ppo:  -0.02142, loss val: 0.04637
[2022-12-06 14:11:55,771] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:11:55,974] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:11:55,974] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:12:01,154] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:12:06,233] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:12:11,471] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:12:16,538] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:12:21,484] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:12:26,835] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:12:31,768] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:12:37,165] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:12:42,181] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:12:47,180] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.017497217491512
[2022-12-06 14:12:47,180] [INFO] [runner_train_mujoco] Average state value: 0.4002702513138453
[2022-12-06 14:12:47,180] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 14:12:47,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.05024
[2022-12-06 14:12:47,299] [INFO] [controller] EPOCH 2 loss ppo:  -0.01912, loss val: 0.04957
[2022-12-06 14:12:47,353] [INFO] [controller] EPOCH 3 loss ppo:  -0.01641, loss val: 0.04968
[2022-12-06 14:12:47,404] [INFO] [controller] EPOCH 4 loss ppo:  -0.02430, loss val: 0.04954
[2022-12-06 14:12:47,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:12:47,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:12:47,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:12:52,751] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:12:58,180] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:13:03,393] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:13:08,580] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:13:13,506] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:13:18,492] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:13:23,246] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:13:28,071] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:13:33,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:13:38,029] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.268165878952404
[2022-12-06 14:13:38,029] [INFO] [runner_train_mujoco] Average state value: 0.41357106580336883
[2022-12-06 14:13:38,029] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 14:13:38,114] [INFO] [controller] EPOCH 1 loss ppo:  -0.01201, loss val: 0.05159
[2022-12-06 14:13:38,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.01208, loss val: 0.05172
[2022-12-06 14:13:38,224] [INFO] [controller] EPOCH 3 loss ppo:  -0.01516, loss val: 0.05325
[2022-12-06 14:13:38,348] [INFO] [controller] EPOCH 4 loss ppo:  -0.01949, loss val: 0.05270
[2022-12-06 14:13:38,359] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:13:38,548] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:13:38,548] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:13:43,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:13:48,625] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:13:53,557] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:13:58,315] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:14:03,512] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:14:08,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:14:13,619] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:14:19,366] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:14:24,741] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:14:30,566] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.949411757058615
[2022-12-06 14:14:30,566] [INFO] [runner_train_mujoco] Average state value: 0.4132716869612535
[2022-12-06 14:14:30,567] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 14:14:30,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01070, loss val: 0.04904
[2022-12-06 14:14:30,739] [INFO] [controller] EPOCH 2 loss ppo:  -0.01507, loss val: 0.04805
[2022-12-06 14:14:30,816] [INFO] [controller] EPOCH 3 loss ppo:  -0.01708, loss val: 0.04908
[2022-12-06 14:14:30,875] [INFO] [controller] EPOCH 4 loss ppo:  -0.02284, loss val: 0.04670
[2022-12-06 14:14:30,886] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:14:31,079] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:14:31,080] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:14:36,215] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:14:41,498] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:14:46,585] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:14:51,923] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:14:57,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:15:02,124] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:15:07,367] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:15:12,603] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:15:18,572] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:15:24,862] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.19619485198145
[2022-12-06 14:15:24,862] [INFO] [runner_train_mujoco] Average state value: 0.4079271038373312
[2022-12-06 14:15:24,862] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 14:15:24,949] [INFO] [controller] EPOCH 1 loss ppo:  -0.01138, loss val: 0.04812
[2022-12-06 14:15:25,000] [INFO] [controller] EPOCH 2 loss ppo:  -0.01564, loss val: 0.04936
[2022-12-06 14:15:25,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.01828, loss val: 0.04802
[2022-12-06 14:15:25,105] [INFO] [controller] EPOCH 4 loss ppo:  -0.02277, loss val: 0.04883
[2022-12-06 14:15:25,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:15:25,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:15:25,305] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:15:30,357] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:15:36,304] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:15:42,392] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:15:48,219] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:15:53,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:15:59,830] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:16:05,974] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:16:12,857] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:16:20,215] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:16:27,114] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.298003015262873
[2022-12-06 14:16:27,114] [INFO] [runner_train_mujoco] Average state value: 0.39936626017093657
[2022-12-06 14:16:27,115] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 14:16:27,879] [INFO] [controller] EPOCH 1 loss ppo:  -0.01144, loss val: 0.04884
[2022-12-06 14:16:28,026] [INFO] [controller] EPOCH 2 loss ppo:  -0.01874, loss val: 0.04922
[2022-12-06 14:16:28,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.02297, loss val: 0.04810
[2022-12-06 14:16:28,319] [INFO] [controller] EPOCH 4 loss ppo:  -0.02533, loss val: 0.04868
[2022-12-06 14:16:28,334] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:16:28,608] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:16:28,608] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:16:34,674] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:16:40,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:16:48,712] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:16:56,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:17:03,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:17:09,028] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:17:14,830] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:17:20,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:17:26,501] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:17:31,709] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.375180819728124
[2022-12-06 14:17:31,710] [INFO] [runner_train_mujoco] Average state value: 0.38653960054119424
[2022-12-06 14:17:31,710] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 14:17:31,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.04551
[2022-12-06 14:17:31,835] [INFO] [controller] EPOCH 2 loss ppo:  -0.01460, loss val: 0.04569
[2022-12-06 14:17:31,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.01625, loss val: 0.04523
[2022-12-06 14:17:31,987] [INFO] [controller] EPOCH 4 loss ppo:  -0.01850, loss val: 0.04523
[2022-12-06 14:17:32,001] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:17:32,236] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:17:32,236] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:17:38,304] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:17:44,194] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:17:50,593] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:17:56,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:18:02,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:18:08,232] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:18:13,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:18:20,792] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:18:26,976] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:18:32,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.205779054296607
[2022-12-06 14:18:32,404] [INFO] [runner_train_mujoco] Average state value: 0.39709284592668215
[2022-12-06 14:18:32,404] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 14:18:32,482] [INFO] [controller] EPOCH 1 loss ppo:  -0.01237, loss val: 0.04607
[2022-12-06 14:18:32,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.01935, loss val: 0.04437
[2022-12-06 14:18:32,671] [INFO] [controller] EPOCH 3 loss ppo:  -0.01725, loss val: 0.04468
[2022-12-06 14:18:32,742] [INFO] [controller] EPOCH 4 loss ppo:  -0.01835, loss val: 0.04390
[2022-12-06 14:18:32,755] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:18:32,983] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:18:32,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:18:38,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:18:45,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:18:51,477] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:18:57,637] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:19:03,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:19:09,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:19:15,901] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:19:21,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:19:27,436] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:19:33,125] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.316314379396191
[2022-12-06 14:19:33,125] [INFO] [runner_train_mujoco] Average state value: 0.4134639874200027
[2022-12-06 14:19:33,126] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 14:19:33,207] [INFO] [controller] EPOCH 1 loss ppo:  -0.01084, loss val: 0.04808
[2022-12-06 14:19:33,261] [INFO] [controller] EPOCH 2 loss ppo:  -0.01491, loss val: 0.04707
[2022-12-06 14:19:33,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.01682, loss val: 0.04638
[2022-12-06 14:19:33,392] [INFO] [controller] EPOCH 4 loss ppo:  -0.01887, loss val: 0.04730
[2022-12-06 14:19:33,404] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:19:33,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:19:33,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:19:39,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:19:45,153] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:19:50,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:19:55,590] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:20:01,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:20:07,108] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:20:12,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:20:19,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:20:24,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:20:30,306] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.178221438023689
[2022-12-06 14:20:30,307] [INFO] [runner_train_mujoco] Average state value: 0.4188923741777738
[2022-12-06 14:20:30,307] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 14:20:30,453] [INFO] [controller] EPOCH 1 loss ppo:  -0.01043, loss val: 0.05136
[2022-12-06 14:20:30,508] [INFO] [controller] EPOCH 2 loss ppo:  -0.01423, loss val: 0.04901
[2022-12-06 14:20:30,564] [INFO] [controller] EPOCH 3 loss ppo:  -0.01788, loss val: 0.05242
[2022-12-06 14:20:30,619] [INFO] [controller] EPOCH 4 loss ppo:  -0.02013, loss val: 0.04860
[2022-12-06 14:20:30,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:20:30,831] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:20:30,831] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:20:36,262] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:20:42,128] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:20:47,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:20:53,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:20:58,016] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:21:04,003] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:21:10,742] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:21:17,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:21:24,810] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:21:30,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.358032857838845
[2022-12-06 14:21:30,333] [INFO] [runner_train_mujoco] Average state value: 0.425288740336895
[2022-12-06 14:21:30,333] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 14:21:30,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.01042, loss val: 0.05501
[2022-12-06 14:21:30,817] [INFO] [controller] EPOCH 2 loss ppo:  -0.01235, loss val: 0.05435
[2022-12-06 14:21:31,033] [INFO] [controller] EPOCH 3 loss ppo:  -0.01544, loss val: 0.05344
[2022-12-06 14:21:31,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.01712, loss val: 0.05418
[2022-12-06 14:21:31,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:21:31,335] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:21:31,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:21:37,146] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:21:45,240] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:21:51,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:21:57,254] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:22:02,794] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:22:08,018] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:22:12,971] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:22:17,718] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:22:23,268] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:22:28,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.284880765042207
[2022-12-06 14:22:28,298] [INFO] [runner_train_mujoco] Average state value: 0.41997469870249426
[2022-12-06 14:22:28,298] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 14:22:28,359] [INFO] [controller] EPOCH 1 loss ppo:  -0.01074, loss val: 0.04636
[2022-12-06 14:22:28,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.01304, loss val: 0.04693
[2022-12-06 14:22:28,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.01656, loss val: 0.04621
[2022-12-06 14:22:28,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.01782, loss val: 0.04617
[2022-12-06 14:22:28,612] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:22:28,807] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:22:28,807] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:22:33,655] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:22:38,832] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:22:44,609] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:22:50,078] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:22:55,540] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:23:00,939] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:23:06,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:23:12,187] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:23:18,216] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:23:23,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.302423712632435
[2022-12-06 14:23:23,885] [INFO] [runner_train_mujoco] Average state value: 0.40978487141927084
[2022-12-06 14:23:23,885] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 14:23:23,952] [INFO] [controller] EPOCH 1 loss ppo:  -0.01052, loss val: 0.05177
[2022-12-06 14:23:24,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.01132, loss val: 0.05337
[2022-12-06 14:23:24,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.01398, loss val: 0.05204
[2022-12-06 14:23:24,126] [INFO] [controller] EPOCH 4 loss ppo:  -0.01607, loss val: 0.05147
[2022-12-06 14:23:24,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:23:24,337] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:23:24,337] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:23:29,908] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:23:35,099] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:23:40,247] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:23:45,715] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:23:50,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:23:55,835] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:24:00,858] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:24:05,991] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:24:11,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:24:16,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.412251808506604
[2022-12-06 14:24:16,887] [INFO] [runner_train_mujoco] Average state value: 0.4068068649371465
[2022-12-06 14:24:16,887] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 14:24:17,224] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.04741
[2022-12-06 14:24:17,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.01145, loss val: 0.05048
[2022-12-06 14:24:17,679] [INFO] [controller] EPOCH 3 loss ppo:  -0.01285, loss val: 0.05126
[2022-12-06 14:24:17,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.01525, loss val: 0.04714
[2022-12-06 14:24:17,759] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:24:18,003] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:24:18,003] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:24:24,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:24:30,007] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:24:36,050] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:24:41,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:24:46,461] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:24:51,442] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:24:56,429] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:25:02,887] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:25:08,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:25:14,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.36056959075173
[2022-12-06 14:25:14,975] [INFO] [runner_train_mujoco] Average state value: 0.40199765924612685
[2022-12-06 14:25:14,975] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 14:25:15,176] [INFO] [controller] EPOCH 1 loss ppo:  -0.01050, loss val: 0.04226
[2022-12-06 14:25:15,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.01112, loss val: 0.04108
[2022-12-06 14:25:15,380] [INFO] [controller] EPOCH 3 loss ppo:  -0.01229, loss val: 0.04112
[2022-12-06 14:25:15,486] [INFO] [controller] EPOCH 4 loss ppo:  -0.01391, loss val: 0.04151
[2022-12-06 14:25:15,504] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:25:15,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:25:15,731] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:25:22,043] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:25:27,564] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:25:34,670] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:25:41,571] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:25:47,345] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:25:54,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:26:00,873] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:26:07,077] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:26:14,082] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:26:20,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.229791614451837
[2022-12-06 14:26:20,603] [INFO] [runner_train_mujoco] Average state value: 0.39029861887916917
[2022-12-06 14:26:20,603] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 14:26:20,718] [INFO] [controller] EPOCH 1 loss ppo:  -0.01039, loss val: 0.05238
[2022-12-06 14:26:20,781] [INFO] [controller] EPOCH 2 loss ppo:  -0.01100, loss val: 0.05281
[2022-12-06 14:26:20,864] [INFO] [controller] EPOCH 3 loss ppo:  -0.01188, loss val: 0.05219
[2022-12-06 14:26:20,951] [INFO] [controller] EPOCH 4 loss ppo:  -0.01311, loss val: 0.05206
[2022-12-06 14:26:20,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:26:21,153] [INFO] [optimize] Finished learning.
