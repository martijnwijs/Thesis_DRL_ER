[2022-12-07 02:41:06,501] [INFO] [optimize] Starting learning
[2022-12-07 02:41:06,506] [INFO] [optimize] Starting learning process..
[2022-12-07 02:41:06,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:41:06,561] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:41:13,167] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:41:18,205] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:41:22,636] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:41:27,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:41:31,698] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:41:36,290] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:41:41,201] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:41:46,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:41:50,507] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:41:55,305] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1620679812281343
[2022-12-07 02:41:55,305] [INFO] [runner_train_mujoco] Average state value: 0.0925308585241437
[2022-12-07 02:41:55,305] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 02:41:55,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01080, loss val: 0.28765
[2022-12-07 02:41:55,417] [INFO] [controller] EPOCH 2 loss ppo:  -0.02736, loss val: 0.24706
[2022-12-07 02:41:55,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.03307, loss val: 0.21121
[2022-12-07 02:41:55,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.03594, loss val: 0.17712
[2022-12-07 02:41:55,521] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:41:55,692] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:41:55,693] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:42:00,862] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:42:05,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:42:10,542] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:42:15,460] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:42:20,308] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:42:24,685] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:42:29,397] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:42:34,199] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:42:38,640] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:42:43,027] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17608167963239493
[2022-12-07 02:42:43,027] [INFO] [runner_train_mujoco] Average state value: 0.2617578364657238
[2022-12-07 02:42:43,027] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 02:42:43,073] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.16285
[2022-12-07 02:42:43,111] [INFO] [controller] EPOCH 2 loss ppo:  -0.03053, loss val: 0.13557
[2022-12-07 02:42:43,148] [INFO] [controller] EPOCH 3 loss ppo:  -0.03643, loss val: 0.11187
[2022-12-07 02:42:43,195] [INFO] [controller] EPOCH 4 loss ppo:  -0.03984, loss val: 0.09272
[2022-12-07 02:42:43,204] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:42:43,376] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:42:43,376] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:42:49,146] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:42:55,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:43:00,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:43:05,623] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:43:10,932] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:43:16,140] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:43:22,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:43:27,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:43:32,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:43:38,157] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21845101580472642
[2022-12-07 02:43:38,157] [INFO] [runner_train_mujoco] Average state value: 0.4147018221262842
[2022-12-07 02:43:38,157] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 02:43:38,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01101, loss val: 0.09858
[2022-12-07 02:43:38,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.02252, loss val: 0.08750
[2022-12-07 02:43:38,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.02876, loss val: 0.06650
[2022-12-07 02:43:38,379] [INFO] [controller] EPOCH 4 loss ppo:  -0.03124, loss val: 0.05391
[2022-12-07 02:43:38,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:43:38,556] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:43:38,556] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:43:43,680] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:43:49,144] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:43:53,926] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:43:59,238] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:44:04,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:44:09,658] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:44:14,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:44:19,656] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:44:25,118] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:44:30,523] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1955751830237928
[2022-12-07 02:44:30,523] [INFO] [runner_train_mujoco] Average state value: 0.5844790860613187
[2022-12-07 02:44:30,524] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 02:44:30,587] [INFO] [controller] EPOCH 1 loss ppo:  -0.01196, loss val: 0.06843
[2022-12-07 02:44:30,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.02441, loss val: 0.05888
[2022-12-07 02:44:30,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.02838, loss val: 0.05331
[2022-12-07 02:44:30,743] [INFO] [controller] EPOCH 4 loss ppo:  -0.03180, loss val: 0.05071
[2022-12-07 02:44:30,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:44:30,926] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:44:30,926] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:44:36,325] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:44:41,740] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:44:47,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:44:52,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:44:57,507] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:45:02,605] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:45:07,722] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:45:13,005] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:45:18,035] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:45:23,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15568945332055809
[2022-12-07 02:45:23,201] [INFO] [runner_train_mujoco] Average state value: 0.7257306178410847
[2022-12-07 02:45:23,201] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 02:45:23,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.00797, loss val: 0.03997
[2022-12-07 02:45:23,304] [INFO] [controller] EPOCH 2 loss ppo:  -0.01692, loss val: 0.04027
[2022-12-07 02:45:23,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.02211, loss val: 0.03992
[2022-12-07 02:45:23,409] [INFO] [controller] EPOCH 4 loss ppo:  -0.02658, loss val: 0.03757
[2022-12-07 02:45:23,421] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:45:23,588] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:45:23,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:45:29,040] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:45:34,121] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:45:40,010] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:45:45,466] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:45:50,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:45:56,082] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:46:01,198] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:46:06,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:46:12,269] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:46:17,728] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19050890498869372
[2022-12-07 02:46:17,729] [INFO] [runner_train_mujoco] Average state value: 0.7781013029813766
[2022-12-07 02:46:17,729] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 02:46:17,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.00607, loss val: 0.04468
[2022-12-07 02:46:17,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.02187, loss val: 0.04382
[2022-12-07 02:46:17,875] [INFO] [controller] EPOCH 3 loss ppo:  -0.02726, loss val: 0.04287
[2022-12-07 02:46:17,929] [INFO] [controller] EPOCH 4 loss ppo:  -0.03002, loss val: 0.04209
[2022-12-07 02:46:17,939] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:46:18,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:46:18,110] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:46:23,187] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:46:28,430] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:46:33,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:46:38,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:46:44,337] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:46:49,788] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:46:55,281] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:47:00,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:47:05,789] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:47:10,747] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19313053451961337
[2022-12-07 02:47:10,747] [INFO] [runner_train_mujoco] Average state value: 0.7553201451698939
[2022-12-07 02:47:10,747] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 02:47:10,800] [INFO] [controller] EPOCH 1 loss ppo:  -0.00568, loss val: 0.04209
[2022-12-07 02:47:10,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.01732, loss val: 0.04013
[2022-12-07 02:47:10,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.02309, loss val: 0.03855
[2022-12-07 02:47:10,971] [INFO] [controller] EPOCH 4 loss ppo:  -0.02405, loss val: 0.03707
[2022-12-07 02:47:10,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:47:11,152] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:47:11,153] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:47:16,660] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:47:22,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:47:27,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:47:32,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:47:38,403] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:47:43,869] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:47:48,824] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:47:54,099] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:47:59,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:48:04,575] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2135912018405474
[2022-12-07 02:48:04,575] [INFO] [runner_train_mujoco] Average state value: 0.6956912225286166
[2022-12-07 02:48:04,575] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 02:48:04,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.00505, loss val: 0.03685
[2022-12-07 02:48:04,717] [INFO] [controller] EPOCH 2 loss ppo:  -0.01848, loss val: 0.03670
[2022-12-07 02:48:04,771] [INFO] [controller] EPOCH 3 loss ppo:  -0.02357, loss val: 0.03665
[2022-12-07 02:48:04,819] [INFO] [controller] EPOCH 4 loss ppo:  -0.02714, loss val: 0.03764
[2022-12-07 02:48:04,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:48:05,013] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:48:05,013] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:48:10,142] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:48:15,632] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:48:20,972] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:48:26,152] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:48:31,438] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:48:36,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:48:41,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:48:47,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:48:52,743] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:48:58,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14805689934115943
[2022-12-07 02:48:58,092] [INFO] [runner_train_mujoco] Average state value: 0.6689758182962735
[2022-12-07 02:48:58,092] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 02:48:58,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.00485, loss val: 0.04436
[2022-12-07 02:48:58,200] [INFO] [controller] EPOCH 2 loss ppo:  -0.01307, loss val: 0.04335
[2022-12-07 02:48:58,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.02088, loss val: 0.04215
[2022-12-07 02:48:58,304] [INFO] [controller] EPOCH 4 loss ppo:  -0.02356, loss val: 0.04060
[2022-12-07 02:48:58,313] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:48:58,486] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:48:58,487] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:49:03,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:49:09,001] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:49:14,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:49:19,986] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:49:25,271] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:49:30,413] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:49:35,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:49:40,744] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:49:45,855] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:49:51,073] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.27169330657151614
[2022-12-07 02:49:51,073] [INFO] [runner_train_mujoco] Average state value: 0.7128059173027673
[2022-12-07 02:49:51,073] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 02:49:51,138] [INFO] [controller] EPOCH 1 loss ppo:  -0.00582, loss val: 0.03768
[2022-12-07 02:49:51,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.01629, loss val: 0.03865
[2022-12-07 02:49:51,240] [INFO] [controller] EPOCH 3 loss ppo:  -0.02254, loss val: 0.03789
[2022-12-07 02:49:51,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.02680, loss val: 0.03847
[2022-12-07 02:49:51,300] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:49:51,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:49:51,468] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:49:56,798] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:50:01,941] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:50:06,826] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:50:12,241] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:50:17,324] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:50:22,552] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:50:27,968] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:50:33,114] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:50:38,097] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:50:43,314] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4311712582403568
[2022-12-07 02:50:43,315] [INFO] [runner_train_mujoco] Average state value: 0.7329731577634812
[2022-12-07 02:50:43,315] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 02:50:43,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.00684, loss val: 0.03820
[2022-12-07 02:50:43,427] [INFO] [controller] EPOCH 2 loss ppo:  -0.01653, loss val: 0.03818
[2022-12-07 02:50:43,476] [INFO] [controller] EPOCH 3 loss ppo:  -0.02160, loss val: 0.03674
[2022-12-07 02:50:43,530] [INFO] [controller] EPOCH 4 loss ppo:  -0.02310, loss val: 0.03790
[2022-12-07 02:50:43,541] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:50:43,730] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:50:43,731] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:50:48,945] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:50:54,668] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:50:59,919] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:51:05,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:51:10,394] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:51:15,419] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:51:21,061] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:51:25,781] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:51:30,941] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:51:36,322] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2886495561409497
[2022-12-07 02:51:36,322] [INFO] [runner_train_mujoco] Average state value: 0.6960204323927561
[2022-12-07 02:51:36,322] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 02:51:36,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.00708, loss val: 0.04293
[2022-12-07 02:51:36,444] [INFO] [controller] EPOCH 2 loss ppo:  -0.01976, loss val: 0.04351
[2022-12-07 02:51:36,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.02348, loss val: 0.04288
[2022-12-07 02:51:36,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.02655, loss val: 0.04279
[2022-12-07 02:51:36,564] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:51:36,730] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:51:36,730] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:51:41,770] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:51:46,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:51:52,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:51:57,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:52:02,583] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:52:07,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:52:12,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:52:18,223] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:52:23,419] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:52:28,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4141940023901684
[2022-12-07 02:52:28,702] [INFO] [runner_train_mujoco] Average state value: 0.7056650879780452
[2022-12-07 02:52:28,702] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 02:52:28,766] [INFO] [controller] EPOCH 1 loss ppo:  -0.00952, loss val: 0.04073
[2022-12-07 02:52:28,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.02147, loss val: 0.04001
[2022-12-07 02:52:28,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.02284, loss val: 0.03999
[2022-12-07 02:52:28,926] [INFO] [controller] EPOCH 4 loss ppo:  -0.02509, loss val: 0.03884
[2022-12-07 02:52:28,935] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:52:29,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:52:29,112] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:52:34,439] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:52:39,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:52:45,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:52:50,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:52:55,441] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:53:00,857] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:53:05,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:53:11,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:53:16,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:53:21,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39888217180184204
[2022-12-07 02:53:21,887] [INFO] [runner_train_mujoco] Average state value: 0.7478467920223871
[2022-12-07 02:53:21,887] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 02:53:21,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.00754, loss val: 0.04299
[2022-12-07 02:53:21,997] [INFO] [controller] EPOCH 2 loss ppo:  -0.02380, loss val: 0.04309
[2022-12-07 02:53:22,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.02932, loss val: 0.04298
[2022-12-07 02:53:22,102] [INFO] [controller] EPOCH 4 loss ppo:  -0.03060, loss val: 0.04212
[2022-12-07 02:53:22,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:53:22,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:53:22,287] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:53:27,411] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:53:32,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:53:37,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:53:43,100] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:53:48,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:53:53,369] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:53:58,654] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:54:03,832] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:54:09,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:54:14,034] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5354944152930587
[2022-12-07 02:54:14,034] [INFO] [runner_train_mujoco] Average state value: 0.7280227814912796
[2022-12-07 02:54:14,034] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 02:54:14,095] [INFO] [controller] EPOCH 1 loss ppo:  -0.00935, loss val: 0.04274
[2022-12-07 02:54:14,154] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.04090
[2022-12-07 02:54:14,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.02870, loss val: 0.03981
[2022-12-07 02:54:14,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.03231, loss val: 0.03963
[2022-12-07 02:54:14,277] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:54:14,448] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:54:14,449] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:54:19,949] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:54:25,078] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:54:30,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:54:35,454] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:54:40,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:54:45,430] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:54:50,501] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:54:55,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:55:00,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:55:05,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5579449167888975
[2022-12-07 02:55:05,906] [INFO] [runner_train_mujoco] Average state value: 0.6556878164013227
[2022-12-07 02:55:05,907] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 02:55:05,974] [INFO] [controller] EPOCH 1 loss ppo:  -0.00963, loss val: 0.03956
[2022-12-07 02:55:06,023] [INFO] [controller] EPOCH 2 loss ppo:  -0.02201, loss val: 0.03833
[2022-12-07 02:55:06,075] [INFO] [controller] EPOCH 3 loss ppo:  -0.02781, loss val: 0.03950
[2022-12-07 02:55:06,139] [INFO] [controller] EPOCH 4 loss ppo:  -0.03163, loss val: 0.03697
[2022-12-07 02:55:06,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:55:06,324] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:55:06,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:55:11,602] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:55:16,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:55:22,298] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:55:27,737] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:55:32,556] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:55:37,667] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:55:43,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:55:48,035] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:55:53,030] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:55:58,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7855703175850822
[2022-12-07 02:55:58,105] [INFO] [runner_train_mujoco] Average state value: 0.656508017917474
[2022-12-07 02:55:58,105] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 02:55:58,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.00957, loss val: 0.04087
[2022-12-07 02:55:58,249] [INFO] [controller] EPOCH 2 loss ppo:  -0.01903, loss val: 0.03864
[2022-12-07 02:55:58,295] [INFO] [controller] EPOCH 3 loss ppo:  -0.02509, loss val: 0.03837
[2022-12-07 02:55:58,345] [INFO] [controller] EPOCH 4 loss ppo:  -0.02809, loss val: 0.03881
[2022-12-07 02:55:58,355] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:55:58,525] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:55:58,525] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:56:03,709] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:56:08,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:56:14,101] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:56:19,418] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:56:24,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:56:31,014] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:56:36,397] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:56:41,830] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:56:46,886] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:56:52,058] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.792539508112581
[2022-12-07 02:56:52,059] [INFO] [runner_train_mujoco] Average state value: 0.6960199122428894
[2022-12-07 02:56:52,059] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 02:56:52,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.00955, loss val: 0.04053
[2022-12-07 02:56:52,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.02049, loss val: 0.03994
[2022-12-07 02:56:52,303] [INFO] [controller] EPOCH 3 loss ppo:  -0.02446, loss val: 0.04000
[2022-12-07 02:56:52,353] [INFO] [controller] EPOCH 4 loss ppo:  -0.02948, loss val: 0.04057
[2022-12-07 02:56:52,363] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:56:52,546] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:56:52,547] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:56:57,956] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:57:03,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:57:08,673] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:57:13,895] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:57:19,237] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:57:25,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:57:30,483] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:57:35,899] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:57:41,684] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:57:46,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8600261972655228
[2022-12-07 02:57:46,527] [INFO] [runner_train_mujoco] Average state value: 0.7125101972818374
[2022-12-07 02:57:46,527] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 02:57:46,588] [INFO] [controller] EPOCH 1 loss ppo:  -0.00884, loss val: 0.04069
[2022-12-07 02:57:46,649] [INFO] [controller] EPOCH 2 loss ppo:  -0.02118, loss val: 0.04042
[2022-12-07 02:57:46,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.02371, loss val: 0.04018
[2022-12-07 02:57:46,798] [INFO] [controller] EPOCH 4 loss ppo:  -0.02753, loss val: 0.04002
[2022-12-07 02:57:46,809] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:57:46,980] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:57:46,980] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:57:52,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:57:57,414] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:58:02,580] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:58:07,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:58:13,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:58:18,229] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:58:23,531] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:58:28,722] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:58:34,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:58:39,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9224242756022631
[2022-12-07 02:58:39,047] [INFO] [runner_train_mujoco] Average state value: 0.6929173085689545
[2022-12-07 02:58:39,047] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 02:58:39,104] [INFO] [controller] EPOCH 1 loss ppo:  -0.01024, loss val: 0.04186
[2022-12-07 02:58:39,152] [INFO] [controller] EPOCH 2 loss ppo:  -0.01998, loss val: 0.04081
[2022-12-07 02:58:39,195] [INFO] [controller] EPOCH 3 loss ppo:  -0.02378, loss val: 0.03918
[2022-12-07 02:58:39,241] [INFO] [controller] EPOCH 4 loss ppo:  -0.02827, loss val: 0.03819
[2022-12-07 02:58:39,251] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:58:39,422] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:58:39,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:58:44,477] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:58:49,712] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:58:54,853] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:58:59,690] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:59:04,893] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:59:09,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:59:14,414] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:59:19,402] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:59:24,501] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:59:29,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1384534950537581
[2022-12-07 02:59:29,824] [INFO] [runner_train_mujoco] Average state value: 0.633966480533282
[2022-12-07 02:59:29,824] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 02:59:29,900] [INFO] [controller] EPOCH 1 loss ppo:  -0.01123, loss val: 0.04165
[2022-12-07 02:59:29,962] [INFO] [controller] EPOCH 2 loss ppo:  -0.02118, loss val: 0.04118
[2022-12-07 02:59:30,015] [INFO] [controller] EPOCH 3 loss ppo:  -0.02854, loss val: 0.04115
[2022-12-07 02:59:30,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.03399, loss val: 0.03982
[2022-12-07 02:59:30,089] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:59:30,267] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:59:30,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:59:35,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:59:40,636] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:59:46,025] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:59:50,831] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:59:55,922] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:00:01,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:00:06,441] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:00:11,264] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:00:16,540] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:00:21,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1714497398181072
[2022-12-07 03:00:21,701] [INFO] [runner_train_mujoco] Average state value: 0.6464234816233316
[2022-12-07 03:00:21,701] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 03:00:21,763] [INFO] [controller] EPOCH 1 loss ppo:  -0.01260, loss val: 0.03775
[2022-12-07 03:00:21,832] [INFO] [controller] EPOCH 2 loss ppo:  -0.02623, loss val: 0.03808
[2022-12-07 03:00:21,886] [INFO] [controller] EPOCH 3 loss ppo:  -0.03260, loss val: 0.03806
[2022-12-07 03:00:21,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.03626, loss val: 0.03742
[2022-12-07 03:00:21,980] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:00:22,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:00:22,172] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:00:27,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:00:32,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:00:37,636] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:00:42,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:00:47,960] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:00:52,824] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:00:57,818] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:01:02,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:01:07,501] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:01:13,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2480218669901264
[2022-12-07 03:01:13,077] [INFO] [runner_train_mujoco] Average state value: 0.643605996410052
[2022-12-07 03:01:13,077] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 03:01:13,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01174, loss val: 0.03614
[2022-12-07 03:01:13,267] [INFO] [controller] EPOCH 2 loss ppo:  -0.02230, loss val: 0.03596
[2022-12-07 03:01:13,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.02468, loss val: 0.03595
[2022-12-07 03:01:13,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.03233, loss val: 0.03552
[2022-12-07 03:01:13,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:01:13,546] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:01:13,547] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:01:18,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:01:23,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:01:29,192] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:01:34,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:01:39,650] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:01:44,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:01:50,012] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:01:54,965] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:01:59,602] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:02:04,449] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1022330160257792
[2022-12-07 03:02:04,449] [INFO] [runner_train_mujoco] Average state value: 0.6158364422520002
[2022-12-07 03:02:04,449] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 03:02:04,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01180, loss val: 0.03462
[2022-12-07 03:02:04,577] [INFO] [controller] EPOCH 2 loss ppo:  -0.02383, loss val: 0.03476
[2022-12-07 03:02:04,644] [INFO] [controller] EPOCH 3 loss ppo:  -0.02770, loss val: 0.03507
[2022-12-07 03:02:04,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.03355, loss val: 0.03505
[2022-12-07 03:02:04,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:02:04,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:02:04,906] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:02:09,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:02:15,067] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:02:19,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:02:25,077] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:02:30,212] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:02:35,346] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:02:40,876] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:02:45,939] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:02:51,043] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:02:55,955] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1835361621290257
[2022-12-07 03:02:55,955] [INFO] [runner_train_mujoco] Average state value: 0.6192225736975671
[2022-12-07 03:02:55,955] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 03:02:56,014] [INFO] [controller] EPOCH 1 loss ppo:  -0.01173, loss val: 0.05035
[2022-12-07 03:02:56,061] [INFO] [controller] EPOCH 2 loss ppo:  -0.02087, loss val: 0.04980
[2022-12-07 03:02:56,106] [INFO] [controller] EPOCH 3 loss ppo:  -0.02743, loss val: 0.04806
[2022-12-07 03:02:56,152] [INFO] [controller] EPOCH 4 loss ppo:  -0.03316, loss val: 0.04569
[2022-12-07 03:02:56,162] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:02:56,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:02:56,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:03:01,709] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:03:07,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:03:12,415] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:03:17,602] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:03:22,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:03:28,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:03:33,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:03:38,564] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:03:43,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:03:48,638] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2643623702792228
[2022-12-07 03:03:48,638] [INFO] [runner_train_mujoco] Average state value: 0.6768066639502843
[2022-12-07 03:03:48,638] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 03:03:48,698] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04338
[2022-12-07 03:03:48,747] [INFO] [controller] EPOCH 2 loss ppo:  -0.02799, loss val: 0.04479
[2022-12-07 03:03:48,799] [INFO] [controller] EPOCH 3 loss ppo:  -0.03015, loss val: 0.04424
[2022-12-07 03:03:48,851] [INFO] [controller] EPOCH 4 loss ppo:  -0.03386, loss val: 0.04534
[2022-12-07 03:03:48,860] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:03:49,033] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:03:49,034] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:03:54,101] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:03:59,352] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:04:04,400] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:04:09,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:04:14,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:04:19,649] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:04:24,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:04:30,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:04:35,196] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:04:40,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3425384638338156
[2022-12-07 03:04:40,676] [INFO] [runner_train_mujoco] Average state value: 0.6742413516044616
[2022-12-07 03:04:40,677] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 03:04:40,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04593
[2022-12-07 03:04:40,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.02478, loss val: 0.04577
[2022-12-07 03:04:40,855] [INFO] [controller] EPOCH 3 loss ppo:  -0.02864, loss val: 0.04561
[2022-12-07 03:04:40,910] [INFO] [controller] EPOCH 4 loss ppo:  -0.03666, loss val: 0.04556
[2022-12-07 03:04:40,921] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:04:41,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:04:41,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:04:46,099] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:04:51,490] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:04:56,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:05:01,309] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:05:06,564] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:05:11,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:05:16,569] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:05:21,511] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:05:26,847] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:05:31,538] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4351669706796835
[2022-12-07 03:05:31,538] [INFO] [runner_train_mujoco] Average state value: 0.6729276432991027
[2022-12-07 03:05:31,538] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 03:05:31,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04271
[2022-12-07 03:05:31,636] [INFO] [controller] EPOCH 2 loss ppo:  -0.02547, loss val: 0.04208
[2022-12-07 03:05:31,683] [INFO] [controller] EPOCH 3 loss ppo:  -0.02581, loss val: 0.04185
[2022-12-07 03:05:31,729] [INFO] [controller] EPOCH 4 loss ppo:  -0.03124, loss val: 0.04215
[2022-12-07 03:05:31,738] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:05:31,900] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:05:31,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:05:37,074] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:05:42,428] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:05:47,525] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:05:52,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:05:57,615] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:06:02,725] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:06:08,009] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:06:13,108] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:06:18,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:06:23,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4874190862821037
[2022-12-07 03:06:23,149] [INFO] [runner_train_mujoco] Average state value: 0.6824002989927929
[2022-12-07 03:06:23,149] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 03:06:23,226] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.03810
[2022-12-07 03:06:23,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.02113, loss val: 0.03815
[2022-12-07 03:06:23,346] [INFO] [controller] EPOCH 3 loss ppo:  -0.02700, loss val: 0.03787
[2022-12-07 03:06:23,402] [INFO] [controller] EPOCH 4 loss ppo:  -0.03657, loss val: 0.03809
[2022-12-07 03:06:23,412] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:06:23,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:06:23,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:06:29,256] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:06:34,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:06:39,613] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:06:44,701] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:06:49,856] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:06:54,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:07:00,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:07:06,570] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:07:12,590] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:07:18,211] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6014894189964959
[2022-12-07 03:07:18,212] [INFO] [runner_train_mujoco] Average state value: 0.6800995036760967
[2022-12-07 03:07:18,212] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 03:07:18,324] [INFO] [controller] EPOCH 1 loss ppo:  -0.01150, loss val: 0.04127
[2022-12-07 03:07:18,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.01943, loss val: 0.04045
[2022-12-07 03:07:18,437] [INFO] [controller] EPOCH 3 loss ppo:  -0.02566, loss val: 0.04019
[2022-12-07 03:07:18,518] [INFO] [controller] EPOCH 4 loss ppo:  -0.03179, loss val: 0.04048
[2022-12-07 03:07:18,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:07:18,695] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:07:18,695] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:07:24,120] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:07:29,336] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:07:34,629] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:07:39,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:07:44,479] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:07:49,920] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:07:55,276] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:08:00,313] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:08:05,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:08:10,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7005545224436152
[2022-12-07 03:08:10,959] [INFO] [runner_train_mujoco] Average state value: 0.6688941862185797
[2022-12-07 03:08:10,959] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 03:08:11,033] [INFO] [controller] EPOCH 1 loss ppo:  -0.01237, loss val: 0.04157
[2022-12-07 03:08:11,078] [INFO] [controller] EPOCH 2 loss ppo:  -0.02056, loss val: 0.04154
[2022-12-07 03:08:11,128] [INFO] [controller] EPOCH 3 loss ppo:  -0.02537, loss val: 0.04137
[2022-12-07 03:08:11,174] [INFO] [controller] EPOCH 4 loss ppo:  -0.03127, loss val: 0.04152
[2022-12-07 03:08:11,185] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:08:11,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:08:11,357] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:08:16,398] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:08:21,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:08:26,880] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:08:31,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:08:36,859] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:08:41,679] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:08:46,240] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:08:51,078] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:08:56,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:09:01,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8689725784756324
[2022-12-07 03:09:01,108] [INFO] [runner_train_mujoco] Average state value: 0.6654198612968127
[2022-12-07 03:09:01,108] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 03:09:01,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04184
[2022-12-07 03:09:01,237] [INFO] [controller] EPOCH 2 loss ppo:  -0.02046, loss val: 0.04152
[2022-12-07 03:09:01,288] [INFO] [controller] EPOCH 3 loss ppo:  -0.02549, loss val: 0.04149
[2022-12-07 03:09:01,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.03174, loss val: 0.04213
[2022-12-07 03:09:01,350] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:09:01,521] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:09:01,521] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:09:06,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:09:12,076] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:09:17,313] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:09:22,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:09:27,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:09:32,287] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:09:37,427] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:09:42,236] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:09:47,273] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:09:52,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8184155855521453
[2022-12-07 03:09:52,391] [INFO] [runner_train_mujoco] Average state value: 0.6655446104208627
[2022-12-07 03:09:52,391] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 03:09:52,442] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04077
[2022-12-07 03:09:52,485] [INFO] [controller] EPOCH 2 loss ppo:  -0.02543, loss val: 0.04101
[2022-12-07 03:09:52,531] [INFO] [controller] EPOCH 3 loss ppo:  -0.03101, loss val: 0.04046
[2022-12-07 03:09:52,574] [INFO] [controller] EPOCH 4 loss ppo:  -0.03605, loss val: 0.04075
[2022-12-07 03:09:52,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:09:52,747] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:09:52,747] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:09:57,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:02,981] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:10:08,352] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:10:13,870] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:10:18,845] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:10:23,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:10:28,846] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:10:33,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:10:38,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:10:43,963] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8223038771562858
[2022-12-07 03:10:43,963] [INFO] [runner_train_mujoco] Average state value: 0.6534284514188766
[2022-12-07 03:10:43,963] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 03:10:44,022] [INFO] [controller] EPOCH 1 loss ppo:  -0.01131, loss val: 0.03589
[2022-12-07 03:10:44,070] [INFO] [controller] EPOCH 2 loss ppo:  -0.01848, loss val: 0.03591
[2022-12-07 03:10:44,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.02307, loss val: 0.03644
[2022-12-07 03:10:44,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.02980, loss val: 0.03599
[2022-12-07 03:10:44,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:10:44,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:10:44,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:10:49,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:54,760] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:00,102] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:11:05,089] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:11:10,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:11:15,295] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:11:20,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:11:24,797] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:11:30,185] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:11:35,185] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.011113209842896
[2022-12-07 03:11:35,185] [INFO] [runner_train_mujoco] Average state value: 0.6322171757817269
[2022-12-07 03:11:35,185] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 03:11:35,256] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04198
[2022-12-07 03:11:35,300] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.04213
[2022-12-07 03:11:35,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.02557, loss val: 0.04323
[2022-12-07 03:11:35,388] [INFO] [controller] EPOCH 4 loss ppo:  -0.03441, loss val: 0.04165
[2022-12-07 03:11:35,397] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:11:35,569] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:11:35,570] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:11:40,945] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:11:45,808] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:51,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:11:56,227] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:01,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:12:05,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:12:10,915] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:12:15,931] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:12:20,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:12:26,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9493546657799612
[2022-12-07 03:12:26,191] [INFO] [runner_train_mujoco] Average state value: 0.6375016482671103
[2022-12-07 03:12:26,191] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 03:12:26,250] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04193
[2022-12-07 03:12:26,312] [INFO] [controller] EPOCH 2 loss ppo:  -0.01986, loss val: 0.04057
[2022-12-07 03:12:26,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.02223, loss val: 0.04187
[2022-12-07 03:12:26,422] [INFO] [controller] EPOCH 4 loss ppo:  -0.03057, loss val: 0.04071
[2022-12-07 03:12:26,431] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:12:26,604] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:12:26,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:12:31,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:12:36,848] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:12:42,291] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:12:47,303] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:52,309] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:12:57,312] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:13:02,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:13:06,992] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:13:11,955] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:13:17,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9081819233678412
[2022-12-07 03:13:17,115] [INFO] [runner_train_mujoco] Average state value: 0.6564237577319145
[2022-12-07 03:13:17,116] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 03:13:17,178] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04028
[2022-12-07 03:13:17,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.02154, loss val: 0.04021
[2022-12-07 03:13:17,275] [INFO] [controller] EPOCH 3 loss ppo:  -0.02204, loss val: 0.04122
[2022-12-07 03:13:17,321] [INFO] [controller] EPOCH 4 loss ppo:  -0.02943, loss val: 0.04110
[2022-12-07 03:13:17,332] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:13:17,501] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:13:17,501] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:13:22,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:13:26,971] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:13:32,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:13:37,722] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:13:42,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:13:47,910] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:13:52,768] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:13:57,984] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:14:03,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:14:08,258] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8738966736516864
[2022-12-07 03:14:08,259] [INFO] [runner_train_mujoco] Average state value: 0.6469166455864908
[2022-12-07 03:14:08,259] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 03:14:08,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01252, loss val: 0.04168
[2022-12-07 03:14:08,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.01865, loss val: 0.04159
[2022-12-07 03:14:08,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.02222, loss val: 0.04135
[2022-12-07 03:14:08,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.02826, loss val: 0.04154
[2022-12-07 03:14:08,476] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:14:08,658] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:14:08,659] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:14:13,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:14:18,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:14:23,826] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:14:28,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:14:34,093] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:14:39,108] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:14:44,073] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:14:49,264] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:14:54,305] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:14:59,029] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9447447629702512
[2022-12-07 03:14:59,029] [INFO] [runner_train_mujoco] Average state value: 0.6426305399735769
[2022-12-07 03:14:59,029] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 03:14:59,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.03942
[2022-12-07 03:14:59,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.02046, loss val: 0.03883
[2022-12-07 03:14:59,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.02563, loss val: 0.03889
[2022-12-07 03:14:59,226] [INFO] [controller] EPOCH 4 loss ppo:  -0.03056, loss val: 0.03888
[2022-12-07 03:14:59,236] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:14:59,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:14:59,401] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:15:04,427] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:15:09,551] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:15:14,446] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:15:19,693] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:15:24,853] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:15:29,880] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:15:34,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:15:40,501] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:15:45,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:15:50,588] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0320461975208515
[2022-12-07 03:15:50,589] [INFO] [runner_train_mujoco] Average state value: 0.6503893224000932
[2022-12-07 03:15:50,589] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 03:15:50,655] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.04639
[2022-12-07 03:15:50,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.02036, loss val: 0.04771
[2022-12-07 03:15:50,765] [INFO] [controller] EPOCH 3 loss ppo:  -0.02661, loss val: 0.04669
[2022-12-07 03:15:50,826] [INFO] [controller] EPOCH 4 loss ppo:  -0.03173, loss val: 0.04660
[2022-12-07 03:15:50,837] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:15:51,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:15:51,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:15:56,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:16:01,275] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:16:06,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:16:11,531] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:16:15,796] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:16:20,628] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:16:25,052] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:16:29,287] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:16:33,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:16:38,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.076829164108635
[2022-12-07 03:16:38,028] [INFO] [runner_train_mujoco] Average state value: 0.6582340480486552
[2022-12-07 03:16:38,028] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 03:16:38,079] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04295
[2022-12-07 03:16:38,119] [INFO] [controller] EPOCH 2 loss ppo:  -0.01696, loss val: 0.04196
[2022-12-07 03:16:38,161] [INFO] [controller] EPOCH 3 loss ppo:  -0.01937, loss val: 0.04184
[2022-12-07 03:16:38,204] [INFO] [controller] EPOCH 4 loss ppo:  -0.02473, loss val: 0.04241
[2022-12-07 03:16:38,213] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:16:38,383] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:16:38,383] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:16:42,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:16:47,648] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:16:52,091] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:16:56,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:17:01,729] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:17:06,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:17:10,932] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:17:15,139] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:17:19,741] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:17:24,064] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.000748233329737
[2022-12-07 03:17:24,065] [INFO] [runner_train_mujoco] Average state value: 0.6719223667383194
[2022-12-07 03:17:24,065] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 03:17:24,124] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.04289
[2022-12-07 03:17:24,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.02049, loss val: 0.04281
[2022-12-07 03:17:24,206] [INFO] [controller] EPOCH 3 loss ppo:  -0.02857, loss val: 0.04367
[2022-12-07 03:17:24,249] [INFO] [controller] EPOCH 4 loss ppo:  -0.03269, loss val: 0.04299
[2022-12-07 03:17:24,259] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:17:24,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:17:24,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:17:28,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:17:33,212] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:17:37,890] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:17:42,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:17:46,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:17:51,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:17:56,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:18:00,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:18:05,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:18:10,270] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.092337072726507
[2022-12-07 03:18:10,270] [INFO] [runner_train_mujoco] Average state value: 0.680641583164533
[2022-12-07 03:18:10,271] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 03:18:10,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.03994
[2022-12-07 03:18:10,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.01943, loss val: 0.03908
[2022-12-07 03:18:10,408] [INFO] [controller] EPOCH 3 loss ppo:  -0.02464, loss val: 0.03830
[2022-12-07 03:18:10,449] [INFO] [controller] EPOCH 4 loss ppo:  -0.02790, loss val: 0.03805
[2022-12-07 03:18:10,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:18:10,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:18:10,626] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:18:14,771] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:18:19,470] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:18:24,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:18:29,008] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:18:33,517] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:18:38,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:18:42,411] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:18:46,903] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:18:51,439] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:18:56,031] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.170979634914345
[2022-12-07 03:18:56,031] [INFO] [runner_train_mujoco] Average state value: 0.6605810638666153
[2022-12-07 03:18:56,031] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 03:18:56,096] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04276
[2022-12-07 03:18:56,139] [INFO] [controller] EPOCH 2 loss ppo:  -0.02373, loss val: 0.04298
[2022-12-07 03:18:56,196] [INFO] [controller] EPOCH 3 loss ppo:  -0.03047, loss val: 0.04310
[2022-12-07 03:18:56,242] [INFO] [controller] EPOCH 4 loss ppo:  -0.03338, loss val: 0.04345
[2022-12-07 03:18:56,252] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:18:56,410] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:18:56,410] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:19:00,933] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:19:05,716] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:19:10,434] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:19:14,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:19:19,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:19:23,605] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:19:28,296] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:19:32,974] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:19:37,305] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:19:42,001] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3009313724064357
[2022-12-07 03:19:42,001] [INFO] [runner_train_mujoco] Average state value: 0.6476244083245597
[2022-12-07 03:19:42,001] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 03:19:42,051] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.03921
[2022-12-07 03:19:42,091] [INFO] [controller] EPOCH 2 loss ppo:  -0.02019, loss val: 0.03915
[2022-12-07 03:19:42,132] [INFO] [controller] EPOCH 3 loss ppo:  -0.02520, loss val: 0.03836
[2022-12-07 03:19:42,170] [INFO] [controller] EPOCH 4 loss ppo:  -0.02751, loss val: 0.03842
[2022-12-07 03:19:42,179] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:19:42,345] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:19:42,346] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:19:47,020] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:19:51,685] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:19:56,293] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:20:01,102] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:20:05,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:20:10,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:20:14,682] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:20:19,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:20:23,508] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:20:28,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3106638258972847
[2022-12-07 03:20:28,052] [INFO] [runner_train_mujoco] Average state value: 0.622094762245814
[2022-12-07 03:20:28,052] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 03:20:28,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.03984
[2022-12-07 03:20:28,147] [INFO] [controller] EPOCH 2 loss ppo:  -0.01730, loss val: 0.04009
[2022-12-07 03:20:28,190] [INFO] [controller] EPOCH 3 loss ppo:  -0.02147, loss val: 0.04011
[2022-12-07 03:20:28,228] [INFO] [controller] EPOCH 4 loss ppo:  -0.02422, loss val: 0.03946
[2022-12-07 03:20:28,237] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:20:28,396] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:20:28,396] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:20:32,589] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:20:36,793] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:20:41,333] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:20:45,758] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:20:50,397] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:20:54,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:20:59,794] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:21:04,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:21:09,276] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:21:13,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.357166088858677
[2022-12-07 03:21:13,741] [INFO] [runner_train_mujoco] Average state value: 0.6042750168442726
[2022-12-07 03:21:13,742] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 03:21:13,804] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04159
[2022-12-07 03:21:13,911] [INFO] [controller] EPOCH 2 loss ppo:  -0.02194, loss val: 0.04194
[2022-12-07 03:21:13,951] [INFO] [controller] EPOCH 3 loss ppo:  -0.02697, loss val: 0.04131
[2022-12-07 03:21:14,004] [INFO] [controller] EPOCH 4 loss ppo:  -0.02698, loss val: 0.04105
[2022-12-07 03:21:14,014] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:21:14,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:21:14,172] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:21:18,651] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:21:23,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:21:27,567] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:21:31,559] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:21:36,027] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:21:40,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:21:44,770] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:21:49,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:21:54,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:21:58,385] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.264627421651223
[2022-12-07 03:21:58,386] [INFO] [runner_train_mujoco] Average state value: 0.6170067774852117
[2022-12-07 03:21:58,386] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 03:21:58,442] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04729
[2022-12-07 03:21:58,491] [INFO] [controller] EPOCH 2 loss ppo:  -0.01797, loss val: 0.04691
[2022-12-07 03:21:58,535] [INFO] [controller] EPOCH 3 loss ppo:  -0.02450, loss val: 0.04684
[2022-12-07 03:21:58,579] [INFO] [controller] EPOCH 4 loss ppo:  -0.02909, loss val: 0.04621
[2022-12-07 03:21:58,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:21:58,741] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:21:58,741] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:22:03,148] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:22:07,654] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:22:12,499] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:22:16,789] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:22:21,260] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:22:25,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:22:30,470] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:22:34,877] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:22:39,484] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:22:43,710] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.339533882721317
[2022-12-07 03:22:43,710] [INFO] [runner_train_mujoco] Average state value: 0.6426776670614879
[2022-12-07 03:22:43,710] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 03:22:43,762] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.03936
[2022-12-07 03:22:43,806] [INFO] [controller] EPOCH 2 loss ppo:  -0.02025, loss val: 0.04121
[2022-12-07 03:22:43,850] [INFO] [controller] EPOCH 3 loss ppo:  -0.02232, loss val: 0.04006
[2022-12-07 03:22:43,893] [INFO] [controller] EPOCH 4 loss ppo:  -0.02589, loss val: 0.03956
[2022-12-07 03:22:43,902] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:22:44,063] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:22:44,063] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:22:48,906] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:22:53,425] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:22:57,864] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:23:02,648] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:23:07,283] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:23:11,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:23:16,042] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:23:20,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:23:24,700] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:23:29,224] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.407926368622433
[2022-12-07 03:23:29,225] [INFO] [runner_train_mujoco] Average state value: 0.6539317770799001
[2022-12-07 03:23:29,225] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 03:23:29,283] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04012
[2022-12-07 03:23:29,327] [INFO] [controller] EPOCH 2 loss ppo:  -0.01694, loss val: 0.04024
[2022-12-07 03:23:29,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.02320, loss val: 0.03986
[2022-12-07 03:23:29,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.02669, loss val: 0.04036
[2022-12-07 03:23:29,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:23:29,592] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:23:29,592] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:23:33,897] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:23:38,227] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:23:43,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:23:48,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:23:52,490] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:23:56,905] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:24:01,683] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:24:06,254] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:24:11,129] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:24:15,333] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.409359526928117
[2022-12-07 03:24:15,333] [INFO] [runner_train_mujoco] Average state value: 0.6515869940916696
[2022-12-07 03:24:15,333] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 03:24:15,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.04320
[2022-12-07 03:24:15,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.01841, loss val: 0.04339
[2022-12-07 03:24:15,473] [INFO] [controller] EPOCH 3 loss ppo:  -0.02402, loss val: 0.04321
[2022-12-07 03:24:15,520] [INFO] [controller] EPOCH 4 loss ppo:  -0.02684, loss val: 0.04332
[2022-12-07 03:24:15,530] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:24:15,697] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:24:15,697] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:24:19,991] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:24:24,356] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:24:28,878] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:24:32,983] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:24:37,285] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:24:41,917] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:24:46,420] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:24:51,160] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:24:55,628] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:25:00,022] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.387182535339758
[2022-12-07 03:25:00,023] [INFO] [runner_train_mujoco] Average state value: 0.6485778773625691
[2022-12-07 03:25:00,023] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 03:25:00,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.04347
[2022-12-07 03:25:00,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.01569, loss val: 0.04430
[2022-12-07 03:25:00,185] [INFO] [controller] EPOCH 3 loss ppo:  -0.01944, loss val: 0.04489
[2022-12-07 03:25:00,235] [INFO] [controller] EPOCH 4 loss ppo:  -0.02195, loss val: 0.04345
[2022-12-07 03:25:00,245] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:25:00,404] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:25:00,405] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:25:04,722] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:25:09,594] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:14,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:25:18,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:25:23,259] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:25:27,428] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:25:31,558] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:25:36,063] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:25:40,576] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:25:45,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.39758840248341
[2022-12-07 03:25:45,364] [INFO] [runner_train_mujoco] Average state value: 0.6504100652933121
[2022-12-07 03:25:45,365] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 03:25:45,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.04550
[2022-12-07 03:25:45,463] [INFO] [controller] EPOCH 2 loss ppo:  -0.01524, loss val: 0.04567
[2022-12-07 03:25:45,507] [INFO] [controller] EPOCH 3 loss ppo:  -0.02047, loss val: 0.04652
[2022-12-07 03:25:45,552] [INFO] [controller] EPOCH 4 loss ppo:  -0.02399, loss val: 0.04609
[2022-12-07 03:25:45,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:25:45,702] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:25:45,703] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:25:49,933] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:25:54,359] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:59,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:26:03,453] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:26:07,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:26:12,177] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:26:16,415] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:26:21,149] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:26:25,539] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:26:30,194] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.346691684864602
[2022-12-07 03:26:30,194] [INFO] [runner_train_mujoco] Average state value: 0.6555062979857127
[2022-12-07 03:26:30,194] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 03:26:30,254] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.04253
[2022-12-07 03:26:30,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.01656, loss val: 0.04245
[2022-12-07 03:26:30,342] [INFO] [controller] EPOCH 3 loss ppo:  -0.02145, loss val: 0.04242
[2022-12-07 03:26:30,390] [INFO] [controller] EPOCH 4 loss ppo:  -0.02505, loss val: 0.04301
[2022-12-07 03:26:30,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:26:30,596] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:26:30,597] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:26:35,275] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:26:40,493] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:26:45,619] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:26:50,330] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:26:54,651] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:26:58,894] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:27:03,039] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:27:07,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:27:11,671] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:27:16,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3960405811110856
[2022-12-07 03:27:16,201] [INFO] [runner_train_mujoco] Average state value: 0.6589952928622564
[2022-12-07 03:27:16,201] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 03:27:16,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.04002
[2022-12-07 03:27:16,306] [INFO] [controller] EPOCH 2 loss ppo:  -0.01451, loss val: 0.03952
[2022-12-07 03:27:16,352] [INFO] [controller] EPOCH 3 loss ppo:  -0.01817, loss val: 0.03993
[2022-12-07 03:27:16,397] [INFO] [controller] EPOCH 4 loss ppo:  -0.02201, loss val: 0.04002
[2022-12-07 03:27:16,408] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:27:16,572] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:27:16,572] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:27:21,252] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:27:25,378] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:27:30,003] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:27:34,553] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:27:38,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:27:43,729] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:27:48,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:27:52,763] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:27:57,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:28:01,883] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.307918830465298
[2022-12-07 03:28:01,883] [INFO] [runner_train_mujoco] Average state value: 0.6545129196643831
[2022-12-07 03:28:01,883] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 03:28:01,932] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.04414
[2022-12-07 03:28:01,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.01384, loss val: 0.04504
[2022-12-07 03:28:02,027] [INFO] [controller] EPOCH 3 loss ppo:  -0.01658, loss val: 0.04403
[2022-12-07 03:28:02,073] [INFO] [controller] EPOCH 4 loss ppo:  -0.02011, loss val: 0.04401
[2022-12-07 03:28:02,085] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:28:02,251] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:28:02,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:28:06,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:28:11,689] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:28:16,478] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:28:20,931] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:28:25,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:28:29,420] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:28:33,578] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:28:38,275] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:28:42,909] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:28:47,603] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4527012605889515
[2022-12-07 03:28:47,603] [INFO] [runner_train_mujoco] Average state value: 0.6477355012893676
[2022-12-07 03:28:47,603] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 03:28:47,656] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.04322
[2022-12-07 03:28:47,700] [INFO] [controller] EPOCH 2 loss ppo:  -0.01475, loss val: 0.04255
[2022-12-07 03:28:47,743] [INFO] [controller] EPOCH 3 loss ppo:  -0.01748, loss val: 0.04253
[2022-12-07 03:28:47,789] [INFO] [controller] EPOCH 4 loss ppo:  -0.02072, loss val: 0.04242
[2022-12-07 03:28:47,797] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:28:47,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:28:47,953] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:28:52,508] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:28:57,028] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:29:01,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:29:05,729] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:29:10,224] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:29:14,669] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:29:19,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:29:23,885] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:29:28,729] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:29:32,937] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4010455147693786
[2022-12-07 03:29:32,937] [INFO] [runner_train_mujoco] Average state value: 0.6429509060382843
[2022-12-07 03:29:32,937] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 03:29:33,002] [INFO] [controller] EPOCH 1 loss ppo:  -0.01255, loss val: 0.04228
[2022-12-07 03:29:33,058] [INFO] [controller] EPOCH 2 loss ppo:  -0.01319, loss val: 0.04216
[2022-12-07 03:29:33,107] [INFO] [controller] EPOCH 3 loss ppo:  -0.01420, loss val: 0.04182
[2022-12-07 03:29:33,150] [INFO] [controller] EPOCH 4 loss ppo:  -0.01569, loss val: 0.04208
[2022-12-07 03:29:33,160] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:29:33,310] [INFO] [optimize] Finished learning.
