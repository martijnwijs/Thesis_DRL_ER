[2022-12-07 08:47:41,095] [INFO] [optimize] Starting learning
[2022-12-07 08:47:41,100] [INFO] [optimize] Starting learning process..
[2022-12-07 08:47:41,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:47:41,161] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:47:47,783] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:47:52,975] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:47:58,029] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:48:02,823] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:48:07,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:48:11,929] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:48:16,744] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:48:21,383] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:48:26,225] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:48:30,995] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17619046729532364
[2022-12-07 08:48:30,995] [INFO] [runner_train_mujoco] Average state value: -0.06420360298454761
[2022-12-07 08:48:30,995] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:48:31,056] [INFO] [controller] EPOCH 1 loss ppo:  -0.01188, loss val: 0.39451
[2022-12-07 08:48:31,104] [INFO] [controller] EPOCH 2 loss ppo:  -0.02829, loss val: 0.37651
[2022-12-07 08:48:31,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.03479, loss val: 0.28974
[2022-12-07 08:48:31,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.03689, loss val: 0.24241
[2022-12-07 08:48:31,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:48:31,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:48:31,394] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:48:35,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:48:40,377] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:48:45,179] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:48:49,730] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:48:54,204] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:48:58,377] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:49:02,900] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:49:07,093] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:49:11,942] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:49:16,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20779080529343585
[2022-12-07 08:49:16,219] [INFO] [runner_train_mujoco] Average state value: 0.09906690656145414
[2022-12-07 08:49:16,219] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:49:16,279] [INFO] [controller] EPOCH 1 loss ppo:  -0.01716, loss val: 0.23237
[2022-12-07 08:49:16,323] [INFO] [controller] EPOCH 2 loss ppo:  -0.03025, loss val: 0.19646
[2022-12-07 08:49:16,372] [INFO] [controller] EPOCH 3 loss ppo:  -0.03691, loss val: 0.16390
[2022-12-07 08:49:16,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.04239, loss val: 0.13656
[2022-12-07 08:49:16,425] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:49:16,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:49:16,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:49:21,446] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:49:25,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:49:30,256] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:49:35,813] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:49:42,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:49:47,171] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:49:52,667] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:49:57,924] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:50:03,459] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:50:08,601] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1932517614481301
[2022-12-07 08:50:08,602] [INFO] [runner_train_mujoco] Average state value: 0.2914996249495695
[2022-12-07 08:50:08,602] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:50:08,661] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.15281
[2022-12-07 08:50:08,710] [INFO] [controller] EPOCH 2 loss ppo:  -0.02125, loss val: 0.12418
[2022-12-07 08:50:08,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.03032, loss val: 0.10679
[2022-12-07 08:50:08,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.03235, loss val: 0.09126
[2022-12-07 08:50:08,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:50:09,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:50:09,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:50:14,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:50:19,364] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:50:24,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:50:29,728] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:50:34,876] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:50:40,154] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:50:45,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:50:50,804] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:50:55,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:51:00,886] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23346804013578729
[2022-12-07 08:51:00,887] [INFO] [runner_train_mujoco] Average state value: 0.4699885979810109
[2022-12-07 08:51:00,887] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:51:00,941] [INFO] [controller] EPOCH 1 loss ppo:  -0.01091, loss val: 0.09136
[2022-12-07 08:51:00,986] [INFO] [controller] EPOCH 2 loss ppo:  -0.02222, loss val: 0.07554
[2022-12-07 08:51:01,033] [INFO] [controller] EPOCH 3 loss ppo:  -0.02701, loss val: 0.06513
[2022-12-07 08:51:01,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.02978, loss val: 0.05867
[2022-12-07 08:51:01,088] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:51:01,257] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:51:01,257] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:06,543] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:51:11,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:51:17,229] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:51:22,238] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:51:27,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:51:32,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:51:37,610] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:51:42,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:51:47,698] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:51:52,987] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24579194712975266
[2022-12-07 08:51:52,988] [INFO] [runner_train_mujoco] Average state value: 0.6109765351215998
[2022-12-07 08:51:52,988] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:51:53,055] [INFO] [controller] EPOCH 1 loss ppo:  -0.00951, loss val: 0.06401
[2022-12-07 08:51:53,114] [INFO] [controller] EPOCH 2 loss ppo:  -0.02061, loss val: 0.05884
[2022-12-07 08:51:53,164] [INFO] [controller] EPOCH 3 loss ppo:  -0.02427, loss val: 0.05285
[2022-12-07 08:51:53,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.03136, loss val: 0.05026
[2022-12-07 08:51:53,224] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:51:53,388] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:51:53,388] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:58,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:52:03,380] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:52:09,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:52:14,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:52:19,642] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:52:24,514] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:52:29,882] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:52:34,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:52:39,990] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:52:45,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1670356603978699
[2022-12-07 08:52:45,084] [INFO] [runner_train_mujoco] Average state value: 0.7133322775562605
[2022-12-07 08:52:45,084] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:52:45,138] [INFO] [controller] EPOCH 1 loss ppo:  -0.00622, loss val: 0.04751
[2022-12-07 08:52:45,190] [INFO] [controller] EPOCH 2 loss ppo:  -0.01555, loss val: 0.04700
[2022-12-07 08:52:45,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.02308, loss val: 0.04487
[2022-12-07 08:52:45,301] [INFO] [controller] EPOCH 4 loss ppo:  -0.02926, loss val: 0.04328
[2022-12-07 08:52:45,311] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:52:45,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:52:45,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:52:50,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:52:55,632] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:00,743] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:05,834] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:53:10,711] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:16,147] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:53:21,269] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:53:26,240] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:53:31,322] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:53:36,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.28911116907058987
[2022-12-07 08:53:36,149] [INFO] [runner_train_mujoco] Average state value: 0.7097353557149569
[2022-12-07 08:53:36,149] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:53:36,210] [INFO] [controller] EPOCH 1 loss ppo:  -0.00758, loss val: 0.04209
[2022-12-07 08:53:36,257] [INFO] [controller] EPOCH 2 loss ppo:  -0.01795, loss val: 0.04329
[2022-12-07 08:53:36,308] [INFO] [controller] EPOCH 3 loss ppo:  -0.02240, loss val: 0.04328
[2022-12-07 08:53:36,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.02531, loss val: 0.04295
[2022-12-07 08:53:36,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:53:36,528] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:53:36,528] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:53:41,633] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:53:46,680] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:51,918] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:57,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:54:01,930] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:54:06,848] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:54:12,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:54:17,606] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:54:23,127] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:54:28,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2630425838656915
[2022-12-07 08:54:28,214] [INFO] [runner_train_mujoco] Average state value: 0.6936648436983427
[2022-12-07 08:54:28,214] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:54:28,278] [INFO] [controller] EPOCH 1 loss ppo:  -0.00670, loss val: 0.03767
[2022-12-07 08:54:28,409] [INFO] [controller] EPOCH 2 loss ppo:  -0.01803, loss val: 0.03722
[2022-12-07 08:54:28,654] [INFO] [controller] EPOCH 3 loss ppo:  -0.02206, loss val: 0.03727
[2022-12-07 08:54:28,717] [INFO] [controller] EPOCH 4 loss ppo:  -0.02676, loss val: 0.03777
[2022-12-07 08:54:28,726] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:54:28,894] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:54:28,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:54:34,134] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:54:39,605] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:54:44,983] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:54:49,975] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:54:55,009] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:54:59,994] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:04,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:55:09,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:55:14,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:55:19,880] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2996052032250988
[2022-12-07 08:55:19,880] [INFO] [runner_train_mujoco] Average state value: 0.6990952146450679
[2022-12-07 08:55:19,880] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:55:20,059] [INFO] [controller] EPOCH 1 loss ppo:  -0.00807, loss val: 0.04248
[2022-12-07 08:55:20,120] [INFO] [controller] EPOCH 2 loss ppo:  -0.01856, loss val: 0.03963
[2022-12-07 08:55:20,181] [INFO] [controller] EPOCH 3 loss ppo:  -0.02190, loss val: 0.03686
[2022-12-07 08:55:20,241] [INFO] [controller] EPOCH 4 loss ppo:  -0.02748, loss val: 0.03450
[2022-12-07 08:55:20,250] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:55:20,468] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:55:20,469] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:55:25,896] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:55:31,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:55:36,471] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:55:41,575] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:55:46,875] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:55:52,135] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:56,727] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:56:01,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:56:06,759] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:56:11,805] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.38670413042913865
[2022-12-07 08:56:11,806] [INFO] [runner_train_mujoco] Average state value: 0.62674588316679
[2022-12-07 08:56:11,806] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 08:56:11,859] [INFO] [controller] EPOCH 1 loss ppo:  -0.00890, loss val: 0.04272
[2022-12-07 08:56:11,907] [INFO] [controller] EPOCH 2 loss ppo:  -0.01728, loss val: 0.04533
[2022-12-07 08:56:11,951] [INFO] [controller] EPOCH 3 loss ppo:  -0.02156, loss val: 0.04447
[2022-12-07 08:56:11,998] [INFO] [controller] EPOCH 4 loss ppo:  -0.02632, loss val: 0.04328
[2022-12-07 08:56:12,008] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:56:12,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:56:12,184] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:56:17,509] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:56:22,924] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:56:28,520] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:56:33,798] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:56:39,483] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:56:44,806] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:56:50,150] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:56:55,061] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:00,072] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:05,142] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5052607780186695
[2022-12-07 08:57:05,143] [INFO] [runner_train_mujoco] Average state value: 0.6298593427538872
[2022-12-07 08:57:05,143] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 08:57:05,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.00860, loss val: 0.03488
[2022-12-07 08:57:05,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.01606, loss val: 0.03500
[2022-12-07 08:57:05,299] [INFO] [controller] EPOCH 3 loss ppo:  -0.02244, loss val: 0.03569
[2022-12-07 08:57:05,347] [INFO] [controller] EPOCH 4 loss ppo:  -0.02942, loss val: 0.03503
[2022-12-07 08:57:05,356] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:05,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:05,521] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:57:10,624] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:57:16,073] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:57:21,364] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:57:26,202] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:57:31,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:57:36,758] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:57:41,755] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:57:46,992] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:52,099] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:57,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.36604555840459857
[2022-12-07 08:57:57,005] [INFO] [runner_train_mujoco] Average state value: 0.6548410335381826
[2022-12-07 08:57:57,005] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 08:57:57,058] [INFO] [controller] EPOCH 1 loss ppo:  -0.00856, loss val: 0.04020
[2022-12-07 08:57:57,101] [INFO] [controller] EPOCH 2 loss ppo:  -0.02184, loss val: 0.03928
[2022-12-07 08:57:57,144] [INFO] [controller] EPOCH 3 loss ppo:  -0.02549, loss val: 0.03866
[2022-12-07 08:57:57,187] [INFO] [controller] EPOCH 4 loss ppo:  -0.02897, loss val: 0.03857
[2022-12-07 08:57:57,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:57,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:57,361] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:58:02,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:58:06,918] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:58:12,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:58:17,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:58:22,283] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:58:27,334] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:58:32,405] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:37,601] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:58:42,705] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:58:48,075] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5489781243404603
[2022-12-07 08:58:48,075] [INFO] [runner_train_mujoco] Average state value: 0.6905321630040804
[2022-12-07 08:58:48,075] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 08:58:48,130] [INFO] [controller] EPOCH 1 loss ppo:  -0.00895, loss val: 0.04114
[2022-12-07 08:58:48,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.01744, loss val: 0.04019
[2022-12-07 08:58:48,215] [INFO] [controller] EPOCH 3 loss ppo:  -0.02260, loss val: 0.04207
[2022-12-07 08:58:48,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.02707, loss val: 0.04029
[2022-12-07 08:58:48,274] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:58:48,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:58:48,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:58:53,931] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:58:59,122] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:59:04,543] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:59:09,341] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:59:14,484] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:59:19,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:59:24,633] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:59:29,209] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:59:34,440] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:59:39,461] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4849641118329477
[2022-12-07 08:59:39,461] [INFO] [runner_train_mujoco] Average state value: 0.714060655494531
[2022-12-07 08:59:39,461] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 08:59:39,516] [INFO] [controller] EPOCH 1 loss ppo:  -0.00794, loss val: 0.04272
[2022-12-07 08:59:39,563] [INFO] [controller] EPOCH 2 loss ppo:  -0.02066, loss val: 0.04091
[2022-12-07 08:59:39,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.02063, loss val: 0.04317
[2022-12-07 08:59:39,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.02549, loss val: 0.04179
[2022-12-07 08:59:39,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:59:39,861] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:59:39,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:59:45,295] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:59:50,492] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:59:55,772] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:00:00,933] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:00:05,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:00:11,014] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:00:16,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:00:21,719] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:00:26,999] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:00:32,183] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5016395870508061
[2022-12-07 09:00:32,184] [INFO] [runner_train_mujoco] Average state value: 0.6852937999566396
[2022-12-07 09:00:32,184] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 09:00:32,271] [INFO] [controller] EPOCH 1 loss ppo:  -0.00816, loss val: 0.03687
[2022-12-07 09:00:32,343] [INFO] [controller] EPOCH 2 loss ppo:  -0.02116, loss val: 0.03584
[2022-12-07 09:00:32,495] [INFO] [controller] EPOCH 3 loss ppo:  -0.02924, loss val: 0.03532
[2022-12-07 09:00:32,553] [INFO] [controller] EPOCH 4 loss ppo:  -0.03071, loss val: 0.03562
[2022-12-07 09:00:32,566] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:00:32,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:00:32,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:00:37,623] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:00:42,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:00:48,014] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:00:53,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:00:58,107] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:03,019] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:08,300] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:01:13,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:01:18,340] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:01:23,491] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5475378647373237
[2022-12-07 09:01:23,491] [INFO] [runner_train_mujoco] Average state value: 0.6288297665715217
[2022-12-07 09:01:23,491] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 09:01:23,562] [INFO] [controller] EPOCH 1 loss ppo:  -0.00879, loss val: 0.04354
[2022-12-07 09:01:23,609] [INFO] [controller] EPOCH 2 loss ppo:  -0.01930, loss val: 0.04330
[2022-12-07 09:01:23,655] [INFO] [controller] EPOCH 3 loss ppo:  -0.02207, loss val: 0.04260
[2022-12-07 09:01:23,704] [INFO] [controller] EPOCH 4 loss ppo:  -0.02958, loss val: 0.04128
[2022-12-07 09:01:23,714] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:01:23,886] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:01:23,887] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:01:28,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:01:34,093] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:01:39,444] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:01:44,548] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:01:49,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:54,215] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:59,732] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:02:04,914] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:02:10,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:02:15,571] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5828684649967408
[2022-12-07 09:02:15,572] [INFO] [runner_train_mujoco] Average state value: 0.6577936607996623
[2022-12-07 09:02:15,572] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 09:02:15,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01040, loss val: 0.04062
[2022-12-07 09:02:15,674] [INFO] [controller] EPOCH 2 loss ppo:  -0.02388, loss val: 0.04043
[2022-12-07 09:02:15,726] [INFO] [controller] EPOCH 3 loss ppo:  -0.02941, loss val: 0.04045
[2022-12-07 09:02:15,769] [INFO] [controller] EPOCH 4 loss ppo:  -0.03123, loss val: 0.04011
[2022-12-07 09:02:15,779] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:02:15,941] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:02:15,941] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:21,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:02:26,279] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:02:31,379] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:02:36,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:02:41,821] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:02:46,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:02:52,209] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:02:57,465] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:03:02,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:08,075] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6764671743580971
[2022-12-07 09:03:08,075] [INFO] [runner_train_mujoco] Average state value: 0.6995939669211706
[2022-12-07 09:03:08,075] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 09:03:08,132] [INFO] [controller] EPOCH 1 loss ppo:  -0.00915, loss val: 0.04068
[2022-12-07 09:03:08,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.02150, loss val: 0.04079
[2022-12-07 09:03:08,228] [INFO] [controller] EPOCH 3 loss ppo:  -0.02603, loss val: 0.04080
[2022-12-07 09:03:08,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.02689, loss val: 0.04070
[2022-12-07 09:03:08,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:03:08,452] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:03:08,452] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:03:13,538] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:03:18,764] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:03:23,951] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:03:29,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:03:33,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:03:39,364] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:03:44,585] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:03:49,596] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:03:54,825] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:59,957] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7732745490418321
[2022-12-07 09:03:59,957] [INFO] [runner_train_mujoco] Average state value: 0.7036259732246399
[2022-12-07 09:03:59,958] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 09:04:00,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.00994, loss val: 0.04131
[2022-12-07 09:04:00,072] [INFO] [controller] EPOCH 2 loss ppo:  -0.02595, loss val: 0.04120
[2022-12-07 09:04:00,130] [INFO] [controller] EPOCH 3 loss ppo:  -0.02933, loss val: 0.04033
[2022-12-07 09:04:00,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.03222, loss val: 0.03930
[2022-12-07 09:04:00,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:04:00,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:04:00,355] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:04:05,660] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:04:10,799] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:04:15,867] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:04:20,699] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:04:26,000] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:04:31,239] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:04:36,066] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:04:40,759] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:04:45,484] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:04:50,227] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7836796031865911
[2022-12-07 09:04:50,227] [INFO] [runner_train_mujoco] Average state value: 0.6694026624361674
[2022-12-07 09:04:50,227] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 09:04:50,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01024, loss val: 0.03505
[2022-12-07 09:04:50,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.03531
[2022-12-07 09:04:50,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.02140, loss val: 0.03467
[2022-12-07 09:04:50,396] [INFO] [controller] EPOCH 4 loss ppo:  -0.02744, loss val: 0.03889
[2022-12-07 09:04:50,406] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:04:50,567] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:04:50,568] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:04:54,922] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:04:59,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:04,132] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:08,697] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:05:12,917] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:05:17,666] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:05:22,274] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:05:26,741] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:05:31,662] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:05:36,441] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0114058288716912
[2022-12-07 09:05:36,441] [INFO] [runner_train_mujoco] Average state value: 0.6616711903015773
[2022-12-07 09:05:36,441] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 09:05:36,489] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.03860
[2022-12-07 09:05:36,525] [INFO] [controller] EPOCH 2 loss ppo:  -0.02332, loss val: 0.04030
[2022-12-07 09:05:36,566] [INFO] [controller] EPOCH 3 loss ppo:  -0.03228, loss val: 0.04094
[2022-12-07 09:05:36,607] [INFO] [controller] EPOCH 4 loss ppo:  -0.03197, loss val: 0.03872
[2022-12-07 09:05:36,615] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:05:36,777] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:05:36,777] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:05:41,305] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:05:45,593] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:50,171] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:55,048] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:05:59,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:06:03,831] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:06:08,150] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:06:12,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:06:17,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:06:21,679] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1112391490659868
[2022-12-07 09:06:21,680] [INFO] [runner_train_mujoco] Average state value: 0.6713289879163107
[2022-12-07 09:06:21,680] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 09:06:21,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01157, loss val: 0.04131
[2022-12-07 09:06:21,801] [INFO] [controller] EPOCH 2 loss ppo:  -0.02543, loss val: 0.04173
[2022-12-07 09:06:21,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.02841, loss val: 0.04188
[2022-12-07 09:06:21,899] [INFO] [controller] EPOCH 4 loss ppo:  -0.03268, loss val: 0.04206
[2022-12-07 09:06:21,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:06:22,102] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:06:22,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:06:26,498] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:06:31,199] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:06:35,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:06:40,248] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:06:44,938] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:06:49,300] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:06:53,788] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:06:57,973] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:07:02,643] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:07:07,999] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2859752607856605
[2022-12-07 09:07:07,999] [INFO] [runner_train_mujoco] Average state value: 0.6661424434979757
[2022-12-07 09:07:07,999] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 09:07:08,054] [INFO] [controller] EPOCH 1 loss ppo:  -0.01208, loss val: 0.03858
[2022-12-07 09:07:08,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.02457, loss val: 0.03798
[2022-12-07 09:07:08,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.03089, loss val: 0.03764
[2022-12-07 09:07:08,288] [INFO] [controller] EPOCH 4 loss ppo:  -0.03485, loss val: 0.03727
[2022-12-07 09:07:08,299] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:07:08,465] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:07:08,466] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:07:13,405] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:07:18,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:07:23,990] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:07:28,474] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:07:33,305] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:07:37,762] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:07:42,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:07:46,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:07:51,536] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:07:55,707] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3175604885131997
[2022-12-07 09:07:55,707] [INFO] [runner_train_mujoco] Average state value: 0.6316227710644404
[2022-12-07 09:07:55,707] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 09:07:55,755] [INFO] [controller] EPOCH 1 loss ppo:  -0.01288, loss val: 0.04480
[2022-12-07 09:07:55,797] [INFO] [controller] EPOCH 2 loss ppo:  -0.02796, loss val: 0.04578
[2022-12-07 09:07:55,839] [INFO] [controller] EPOCH 3 loss ppo:  -0.02944, loss val: 0.04514
[2022-12-07 09:07:55,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.03341, loss val: 0.04454
[2022-12-07 09:07:55,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:07:56,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:07:56,061] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:08:00,550] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:08:04,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:08:09,579] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:08:14,044] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:08:18,865] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:08:23,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:08:27,940] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:08:32,574] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:08:36,789] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:08:41,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.539970646455044
[2022-12-07 09:08:41,331] [INFO] [runner_train_mujoco] Average state value: 0.6423091231981913
[2022-12-07 09:08:41,331] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 09:08:41,382] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04701
[2022-12-07 09:08:41,422] [INFO] [controller] EPOCH 2 loss ppo:  -0.02593, loss val: 0.04695
[2022-12-07 09:08:41,465] [INFO] [controller] EPOCH 3 loss ppo:  -0.02850, loss val: 0.04637
[2022-12-07 09:08:41,506] [INFO] [controller] EPOCH 4 loss ppo:  -0.03342, loss val: 0.04653
[2022-12-07 09:08:41,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:08:41,663] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:08:41,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:08:46,048] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:08:50,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:08:55,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:08:59,423] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:09:04,124] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:09:08,234] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:09:12,895] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:09:17,671] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:09:21,730] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:09:25,863] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.641012822838778
[2022-12-07 09:09:25,863] [INFO] [runner_train_mujoco] Average state value: 0.6607277703483899
[2022-12-07 09:09:25,864] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 09:09:25,911] [INFO] [controller] EPOCH 1 loss ppo:  -0.01127, loss val: 0.04007
[2022-12-07 09:09:25,952] [INFO] [controller] EPOCH 2 loss ppo:  -0.02065, loss val: 0.04133
[2022-12-07 09:09:25,993] [INFO] [controller] EPOCH 3 loss ppo:  -0.02582, loss val: 0.03994
[2022-12-07 09:09:26,035] [INFO] [controller] EPOCH 4 loss ppo:  -0.03317, loss val: 0.04078
[2022-12-07 09:09:26,044] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:09:26,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:09:26,214] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:09:31,160] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:09:35,903] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:09:40,091] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:09:44,413] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:09:48,745] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:09:53,979] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:09:58,662] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:10:03,050] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:10:07,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:10:11,509] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6842700727034845
[2022-12-07 09:10:11,509] [INFO] [runner_train_mujoco] Average state value: 0.6678365290959676
[2022-12-07 09:10:11,509] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 09:10:11,559] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.04193
[2022-12-07 09:10:11,602] [INFO] [controller] EPOCH 2 loss ppo:  -0.02390, loss val: 0.04238
[2022-12-07 09:10:11,644] [INFO] [controller] EPOCH 3 loss ppo:  -0.02409, loss val: 0.04208
[2022-12-07 09:10:11,687] [INFO] [controller] EPOCH 4 loss ppo:  -0.03217, loss val: 0.04200
[2022-12-07 09:10:11,695] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:10:11,852] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:10:11,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:10:16,432] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:10:21,156] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:10:26,154] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:10:31,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:10:35,300] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:10:39,754] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:10:44,090] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:10:48,393] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:10:53,022] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:10:57,194] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7033601211646014
[2022-12-07 09:10:57,194] [INFO] [runner_train_mujoco] Average state value: 0.6577608015139897
[2022-12-07 09:10:57,194] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 09:10:57,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.04357
[2022-12-07 09:10:57,280] [INFO] [controller] EPOCH 2 loss ppo:  -0.01956, loss val: 0.04195
[2022-12-07 09:10:57,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.02703, loss val: 0.04032
[2022-12-07 09:10:57,366] [INFO] [controller] EPOCH 4 loss ppo:  -0.03353, loss val: 0.03913
[2022-12-07 09:10:57,375] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:10:57,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:10:57,532] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:11:02,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:11:07,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:11:11,100] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:11:15,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:11:19,856] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:11:24,284] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:11:29,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:11:33,529] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:11:38,114] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:11:42,803] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8557478319027787
[2022-12-07 09:11:42,804] [INFO] [runner_train_mujoco] Average state value: 0.596744340201219
[2022-12-07 09:11:42,804] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 09:11:42,852] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.04103
[2022-12-07 09:11:42,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.02112, loss val: 0.04192
[2022-12-07 09:11:42,943] [INFO] [controller] EPOCH 3 loss ppo:  -0.02811, loss val: 0.04153
[2022-12-07 09:11:42,987] [INFO] [controller] EPOCH 4 loss ppo:  -0.03517, loss val: 0.04086
[2022-12-07 09:11:42,996] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:11:43,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:11:43,158] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:11:47,794] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:11:52,346] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:11:56,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:12:01,199] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:12:05,778] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:12:09,930] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:12:14,872] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:12:19,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:12:23,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:12:28,616] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8429081531014233
[2022-12-07 09:12:28,616] [INFO] [runner_train_mujoco] Average state value: 0.6013743100961049
[2022-12-07 09:12:28,617] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 09:12:28,674] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.03701
[2022-12-07 09:12:28,719] [INFO] [controller] EPOCH 2 loss ppo:  -0.02344, loss val: 0.03777
[2022-12-07 09:12:28,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.02737, loss val: 0.03712
[2022-12-07 09:12:28,810] [INFO] [controller] EPOCH 4 loss ppo:  -0.03279, loss val: 0.03726
[2022-12-07 09:12:28,820] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:12:29,002] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:12:29,002] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:12:33,405] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:12:38,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:12:42,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:12:46,884] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:12:51,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:12:55,537] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:12:59,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:13:04,241] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:13:08,729] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:13,442] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7739226941938955
[2022-12-07 09:13:13,442] [INFO] [runner_train_mujoco] Average state value: 0.6210774690111478
[2022-12-07 09:13:13,443] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 09:13:13,498] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04504
[2022-12-07 09:13:13,550] [INFO] [controller] EPOCH 2 loss ppo:  -0.02518, loss val: 0.04540
[2022-12-07 09:13:13,600] [INFO] [controller] EPOCH 3 loss ppo:  -0.02692, loss val: 0.04587
[2022-12-07 09:13:13,645] [INFO] [controller] EPOCH 4 loss ppo:  -0.02830, loss val: 0.04486
[2022-12-07 09:13:13,652] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:13,812] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:13,812] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:13:18,446] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:13:23,385] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:13:27,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:13:32,369] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:13:36,949] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:13:41,410] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:13:45,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:13:50,380] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:13:54,683] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:58,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9119922235523663
[2022-12-07 09:13:58,884] [INFO] [runner_train_mujoco] Average state value: 0.6375020922025045
[2022-12-07 09:13:58,884] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 09:13:58,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04431
[2022-12-07 09:13:58,989] [INFO] [controller] EPOCH 2 loss ppo:  -0.02326, loss val: 0.04417
[2022-12-07 09:13:59,030] [INFO] [controller] EPOCH 3 loss ppo:  -0.02928, loss val: 0.04448
[2022-12-07 09:13:59,071] [INFO] [controller] EPOCH 4 loss ppo:  -0.03343, loss val: 0.04434
[2022-12-07 09:13:59,081] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:59,248] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:59,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:14:03,644] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:14:08,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:14:12,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:14:17,274] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:14:21,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:14:26,431] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:14:31,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:14:35,880] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:14:40,106] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:14:44,469] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9248871096806177
[2022-12-07 09:14:44,469] [INFO] [runner_train_mujoco] Average state value: 0.6424405405322711
[2022-12-07 09:14:44,469] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 09:14:44,514] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.04446
[2022-12-07 09:14:44,555] [INFO] [controller] EPOCH 2 loss ppo:  -0.02256, loss val: 0.04445
[2022-12-07 09:14:44,596] [INFO] [controller] EPOCH 3 loss ppo:  -0.02723, loss val: 0.04372
[2022-12-07 09:14:44,635] [INFO] [controller] EPOCH 4 loss ppo:  -0.03148, loss val: 0.04473
[2022-12-07 09:14:44,645] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:14:44,806] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:14:44,807] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:14:49,216] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:14:53,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:14:58,406] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:03,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:15:07,395] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:15:12,032] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:15:16,460] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:15:20,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:15:25,316] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:15:29,522] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.098589702338412
[2022-12-07 09:15:29,522] [INFO] [runner_train_mujoco] Average state value: 0.6421094649632771
[2022-12-07 09:15:29,522] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 09:15:29,582] [INFO] [controller] EPOCH 1 loss ppo:  -0.01083, loss val: 0.04370
[2022-12-07 09:15:29,622] [INFO] [controller] EPOCH 2 loss ppo:  -0.01726, loss val: 0.04215
[2022-12-07 09:15:29,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.02495, loss val: 0.04293
[2022-12-07 09:15:29,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.02977, loss val: 0.04284
[2022-12-07 09:15:29,715] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:15:29,869] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:15:29,869] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:15:34,215] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:15:38,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:15:43,072] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:47,631] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:15:52,637] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:15:57,224] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:16:01,415] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:16:05,618] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:16:10,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:16:14,247] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.089135409352953
[2022-12-07 09:16:14,248] [INFO] [runner_train_mujoco] Average state value: 0.6434413306911786
[2022-12-07 09:16:14,248] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 09:16:14,303] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.04574
[2022-12-07 09:16:14,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.01952, loss val: 0.04414
[2022-12-07 09:16:14,388] [INFO] [controller] EPOCH 3 loss ppo:  -0.02818, loss val: 0.04474
[2022-12-07 09:16:14,429] [INFO] [controller] EPOCH 4 loss ppo:  -0.03226, loss val: 0.04486
[2022-12-07 09:16:14,439] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:16:14,584] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:16:14,585] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:16:19,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:16:23,967] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:16:28,611] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:16:33,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:16:37,559] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:16:42,133] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:16:46,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:16:50,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:16:55,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:16:59,564] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.12691927326237
[2022-12-07 09:16:59,564] [INFO] [runner_train_mujoco] Average state value: 0.631851996342341
[2022-12-07 09:16:59,564] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 09:16:59,621] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.04047
[2022-12-07 09:16:59,663] [INFO] [controller] EPOCH 2 loss ppo:  -0.02018, loss val: 0.03981
[2022-12-07 09:16:59,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.02862, loss val: 0.03886
[2022-12-07 09:16:59,751] [INFO] [controller] EPOCH 4 loss ppo:  -0.03373, loss val: 0.03851
[2022-12-07 09:16:59,761] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:16:59,921] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:16:59,921] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:17:04,192] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:17:08,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:17:13,144] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:17:17,878] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:17:22,756] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:17:27,483] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:17:32,064] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:17:36,525] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:17:40,658] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:17:44,655] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.154005281260331
[2022-12-07 09:17:44,655] [INFO] [runner_train_mujoco] Average state value: 0.5929746458729108
[2022-12-07 09:17:44,655] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 09:17:44,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.03723
[2022-12-07 09:17:44,747] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.03752
[2022-12-07 09:17:44,790] [INFO] [controller] EPOCH 3 loss ppo:  -0.02620, loss val: 0.03759
[2022-12-07 09:17:44,831] [INFO] [controller] EPOCH 4 loss ppo:  -0.02988, loss val: 0.03744
[2022-12-07 09:17:44,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:17:44,999] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:17:44,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:17:49,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:17:53,451] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:17:57,764] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:18:02,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:18:06,763] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:18:11,073] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:15,306] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:18:19,993] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:18:24,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:18:28,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.21309683342869
[2022-12-07 09:18:28,331] [INFO] [runner_train_mujoco] Average state value: 0.5670680271983147
[2022-12-07 09:18:28,332] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 09:18:28,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.03725
[2022-12-07 09:18:28,423] [INFO] [controller] EPOCH 2 loss ppo:  -0.01970, loss val: 0.03667
[2022-12-07 09:18:28,464] [INFO] [controller] EPOCH 3 loss ppo:  -0.02337, loss val: 0.03471
[2022-12-07 09:18:28,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.03075, loss val: 0.03473
[2022-12-07 09:18:28,513] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:18:28,673] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:18:28,673] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:18:33,387] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:18:37,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:18:41,990] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:18:46,318] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:18:50,259] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:18:54,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:58,863] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:19:03,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:19:07,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:19:12,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0654079233827067
[2022-12-07 09:19:12,462] [INFO] [runner_train_mujoco] Average state value: 0.6043579569260279
[2022-12-07 09:19:12,463] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 09:19:12,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04285
[2022-12-07 09:19:12,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.02289, loss val: 0.04290
[2022-12-07 09:19:12,602] [INFO] [controller] EPOCH 3 loss ppo:  -0.02478, loss val: 0.04313
[2022-12-07 09:19:12,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.02856, loss val: 0.04268
[2022-12-07 09:19:12,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:19:12,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:19:12,823] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:19:17,356] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:19:21,589] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:19:26,384] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:19:30,806] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:19:35,175] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:19:39,410] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:19:43,769] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:19:48,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:19:53,115] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:19:57,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.335222083698709
[2022-12-07 09:19:57,651] [INFO] [runner_train_mujoco] Average state value: 0.6129716704885164
[2022-12-07 09:19:57,651] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 09:19:57,704] [INFO] [controller] EPOCH 1 loss ppo:  -0.01044, loss val: 0.03580
[2022-12-07 09:19:57,746] [INFO] [controller] EPOCH 2 loss ppo:  -0.01598, loss val: 0.03522
[2022-12-07 09:19:57,791] [INFO] [controller] EPOCH 3 loss ppo:  -0.01963, loss val: 0.03488
[2022-12-07 09:19:57,833] [INFO] [controller] EPOCH 4 loss ppo:  -0.02705, loss val: 0.03465
[2022-12-07 09:19:57,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:19:58,000] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:19:58,001] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:20:02,659] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:20:06,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:20:11,316] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:20:15,918] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:20:20,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:20:24,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:20:29,168] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:20:33,510] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:20:38,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:20:42,951] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3012316690082644
[2022-12-07 09:20:42,952] [INFO] [runner_train_mujoco] Average state value: 0.5863539725939433
[2022-12-07 09:20:42,952] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 09:20:43,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04242
[2022-12-07 09:20:43,044] [INFO] [controller] EPOCH 2 loss ppo:  -0.01878, loss val: 0.04072
[2022-12-07 09:20:43,088] [INFO] [controller] EPOCH 3 loss ppo:  -0.02210, loss val: 0.04006
[2022-12-07 09:20:43,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.02381, loss val: 0.04177
[2022-12-07 09:20:43,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:20:43,307] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:20:43,307] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:20:47,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:20:52,086] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:20:56,597] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:21:01,179] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:21:05,354] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:21:09,443] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:21:13,841] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:21:18,165] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:21:22,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:21:26,924] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.311015469424907
[2022-12-07 09:21:26,924] [INFO] [runner_train_mujoco] Average state value: 0.5893775664567947
[2022-12-07 09:21:26,924] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 09:21:26,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.04044
[2022-12-07 09:21:27,017] [INFO] [controller] EPOCH 2 loss ppo:  -0.01995, loss val: 0.03925
[2022-12-07 09:21:27,059] [INFO] [controller] EPOCH 3 loss ppo:  -0.02272, loss val: 0.03969
[2022-12-07 09:21:27,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.02867, loss val: 0.03870
[2022-12-07 09:21:27,110] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:21:27,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:21:27,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:21:31,545] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:21:35,749] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:21:40,485] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:21:44,515] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:21:48,741] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:21:52,722] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:21:57,373] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:22:01,560] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:22:05,883] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:22:10,703] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2832604321557897
[2022-12-07 09:22:10,703] [INFO] [runner_train_mujoco] Average state value: 0.5900097289284071
[2022-12-07 09:22:10,703] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 09:22:10,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04019
[2022-12-07 09:22:10,822] [INFO] [controller] EPOCH 2 loss ppo:  -0.01935, loss val: 0.04021
[2022-12-07 09:22:10,872] [INFO] [controller] EPOCH 3 loss ppo:  -0.02344, loss val: 0.03968
[2022-12-07 09:22:10,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.02827, loss val: 0.03945
[2022-12-07 09:22:10,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:22:11,085] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:22:11,086] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:22:15,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:22:19,330] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:22:24,116] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:22:28,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:22:33,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:22:37,856] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:22:42,240] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:22:46,638] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:22:50,963] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:22:55,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.403799314576733
[2022-12-07 09:22:55,660] [INFO] [runner_train_mujoco] Average state value: 0.5786918799082439
[2022-12-07 09:22:55,660] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 09:22:55,716] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04253
[2022-12-07 09:22:55,758] [INFO] [controller] EPOCH 2 loss ppo:  -0.01899, loss val: 0.04254
[2022-12-07 09:22:55,800] [INFO] [controller] EPOCH 3 loss ppo:  -0.02259, loss val: 0.04287
[2022-12-07 09:22:55,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.02904, loss val: 0.04258
[2022-12-07 09:22:55,855] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:22:56,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:22:56,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:00,141] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:23:04,337] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:23:08,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:23:13,477] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:23:17,976] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:23:22,456] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:23:26,613] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:23:30,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:23:34,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:23:39,117] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3870166428646997
[2022-12-07 09:23:39,117] [INFO] [runner_train_mujoco] Average state value: 0.5877902237971624
[2022-12-07 09:23:39,117] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 09:23:39,170] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.04456
[2022-12-07 09:23:39,211] [INFO] [controller] EPOCH 2 loss ppo:  -0.02215, loss val: 0.04351
[2022-12-07 09:23:39,253] [INFO] [controller] EPOCH 3 loss ppo:  -0.02463, loss val: 0.04387
[2022-12-07 09:23:39,295] [INFO] [controller] EPOCH 4 loss ppo:  -0.02924, loss val: 0.04316
[2022-12-07 09:23:39,304] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:23:39,456] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:23:39,456] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:43,696] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:23:48,052] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:23:52,455] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:23:56,988] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:24:01,525] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:24:05,925] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:24:10,601] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:24:14,905] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:24:18,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:24:23,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3519750334727925
[2022-12-07 09:24:23,190] [INFO] [runner_train_mujoco] Average state value: 0.6149109298785528
[2022-12-07 09:24:23,190] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 09:24:23,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.03769
[2022-12-07 09:24:23,303] [INFO] [controller] EPOCH 2 loss ppo:  -0.01768, loss val: 0.03826
[2022-12-07 09:24:23,348] [INFO] [controller] EPOCH 3 loss ppo:  -0.02103, loss val: 0.03789
[2022-12-07 09:24:23,391] [INFO] [controller] EPOCH 4 loss ppo:  -0.02481, loss val: 0.03773
[2022-12-07 09:24:23,400] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:24:23,576] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:24:23,576] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:24:27,490] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:24:31,567] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:24:36,151] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:24:40,509] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:24:44,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:24:49,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:24:53,684] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:24:57,918] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:25:02,266] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:25:06,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4623185511425456
[2022-12-07 09:25:06,784] [INFO] [runner_train_mujoco] Average state value: 0.6060707008838653
[2022-12-07 09:25:06,784] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 09:25:06,833] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.04118
[2022-12-07 09:25:06,939] [INFO] [controller] EPOCH 2 loss ppo:  -0.01904, loss val: 0.04107
[2022-12-07 09:25:06,981] [INFO] [controller] EPOCH 3 loss ppo:  -0.02418, loss val: 0.04226
[2022-12-07 09:25:07,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.03057, loss val: 0.04171
[2022-12-07 09:25:07,033] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:25:07,177] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:25:07,177] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:25:11,290] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:25:15,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:25:20,135] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:25:24,497] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:25:28,898] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:25:32,966] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:25:37,144] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:25:41,548] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:25:45,582] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:25:49,956] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4423789000499063
[2022-12-07 09:25:49,956] [INFO] [runner_train_mujoco] Average state value: 0.5968741041024526
[2022-12-07 09:25:49,956] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 09:25:50,016] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.04664
[2022-12-07 09:25:50,062] [INFO] [controller] EPOCH 2 loss ppo:  -0.01695, loss val: 0.04595
[2022-12-07 09:25:50,107] [INFO] [controller] EPOCH 3 loss ppo:  -0.02152, loss val: 0.04594
[2022-12-07 09:25:50,152] [INFO] [controller] EPOCH 4 loss ppo:  -0.02632, loss val: 0.04605
[2022-12-07 09:25:50,161] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:25:50,309] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:25:50,310] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:25:54,508] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:25:58,921] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:26:03,822] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:26:08,206] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:26:12,628] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:26:16,696] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:26:21,347] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:26:25,361] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:26:29,393] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:33,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.55556285518146
[2022-12-07 09:26:33,381] [INFO] [runner_train_mujoco] Average state value: 0.5909177589813869
[2022-12-07 09:26:33,381] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 09:26:33,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04808
[2022-12-07 09:26:33,472] [INFO] [controller] EPOCH 2 loss ppo:  -0.02088, loss val: 0.04642
[2022-12-07 09:26:33,515] [INFO] [controller] EPOCH 3 loss ppo:  -0.02700, loss val: 0.04639
[2022-12-07 09:26:33,556] [INFO] [controller] EPOCH 4 loss ppo:  -0.02919, loss val: 0.04801
[2022-12-07 09:26:33,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:33,731] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:33,732] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:26:38,122] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:26:42,625] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:26:47,013] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:26:51,309] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:26:55,805] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:27:00,180] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:27:04,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:27:08,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:27:12,982] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:27:17,083] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.738131723759777
[2022-12-07 09:27:17,083] [INFO] [runner_train_mujoco] Average state value: 0.5919557030002276
[2022-12-07 09:27:17,084] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 09:27:17,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.04139
[2022-12-07 09:27:17,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.01600, loss val: 0.04172
[2022-12-07 09:27:17,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.02257, loss val: 0.04144
[2022-12-07 09:27:17,298] [INFO] [controller] EPOCH 4 loss ppo:  -0.02773, loss val: 0.04087
[2022-12-07 09:27:17,308] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:27:17,473] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:27:17,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:27:22,087] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:27:25,855] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:30,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:27:34,640] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:27:38,460] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:27:42,823] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:27:47,121] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:27:51,344] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:27:55,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:28:00,597] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.744895333471267
[2022-12-07 09:28:00,598] [INFO] [runner_train_mujoco] Average state value: 0.5891423349579176
[2022-12-07 09:28:00,598] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 09:28:00,650] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.04280
[2022-12-07 09:28:00,701] [INFO] [controller] EPOCH 2 loss ppo:  -0.01704, loss val: 0.04248
[2022-12-07 09:28:00,742] [INFO] [controller] EPOCH 3 loss ppo:  -0.02268, loss val: 0.04174
[2022-12-07 09:28:00,789] [INFO] [controller] EPOCH 4 loss ppo:  -0.02449, loss val: 0.04142
[2022-12-07 09:28:00,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:28:00,931] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:28:00,932] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:28:05,080] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:28:09,079] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:28:13,219] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:28:17,634] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:28:21,619] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:28:25,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:28:29,785] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:28:34,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:28:38,008] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:28:42,343] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8545719254193895
[2022-12-07 09:28:42,344] [INFO] [runner_train_mujoco] Average state value: 0.5750477016568184
[2022-12-07 09:28:42,344] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 09:28:42,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.03873
[2022-12-07 09:28:42,437] [INFO] [controller] EPOCH 2 loss ppo:  -0.01706, loss val: 0.03866
[2022-12-07 09:28:42,482] [INFO] [controller] EPOCH 3 loss ppo:  -0.02184, loss val: 0.03985
[2022-12-07 09:28:42,524] [INFO] [controller] EPOCH 4 loss ppo:  -0.02292, loss val: 0.04031
[2022-12-07 09:28:42,534] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:28:42,695] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:28:42,696] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:28:47,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:28:51,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:28:56,403] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:00,791] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:29:05,017] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:29:09,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:29:13,186] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:17,392] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:29:21,741] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:29:25,693] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9193131807775634
[2022-12-07 09:29:25,693] [INFO] [runner_train_mujoco] Average state value: 0.5622753020127615
[2022-12-07 09:29:25,693] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 09:29:25,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.04503
[2022-12-07 09:29:25,783] [INFO] [controller] EPOCH 2 loss ppo:  -0.01654, loss val: 0.04476
[2022-12-07 09:29:25,823] [INFO] [controller] EPOCH 3 loss ppo:  -0.02151, loss val: 0.04496
[2022-12-07 09:29:25,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.02400, loss val: 0.04559
[2022-12-07 09:29:25,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:29:26,026] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:29:26,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:29:30,255] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:29:34,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:29:38,776] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:42,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:29:47,192] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:29:51,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:29:55,546] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:59,453] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:03,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:08,123] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0353388070155924
[2022-12-07 09:30:08,123] [INFO] [runner_train_mujoco] Average state value: 0.5535546990831693
[2022-12-07 09:30:08,123] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 09:30:08,181] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04073
[2022-12-07 09:30:08,242] [INFO] [controller] EPOCH 2 loss ppo:  -0.01343, loss val: 0.04002
[2022-12-07 09:30:08,299] [INFO] [controller] EPOCH 3 loss ppo:  -0.01474, loss val: 0.04033
[2022-12-07 09:30:08,344] [INFO] [controller] EPOCH 4 loss ppo:  -0.01629, loss val: 0.03993
[2022-12-07 09:30:08,353] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:08,528] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:08,528] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:12,810] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:30:17,228] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:30:21,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:30:25,674] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:30:29,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:30:33,714] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:30:37,753] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:30:41,970] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:45,956] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:50,318] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0236450905858057
[2022-12-07 09:30:50,319] [INFO] [runner_train_mujoco] Average state value: 0.551118418097496
[2022-12-07 09:30:50,319] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 09:30:50,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.04264
[2022-12-07 09:30:50,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.01589, loss val: 0.04237
[2022-12-07 09:30:50,484] [INFO] [controller] EPOCH 3 loss ppo:  -0.02027, loss val: 0.04356
[2022-12-07 09:30:50,536] [INFO] [controller] EPOCH 4 loss ppo:  -0.02317, loss val: 0.04318
[2022-12-07 09:30:50,548] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:50,705] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:50,706] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:54,985] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:30:59,290] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:31:03,492] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:31:07,792] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:31:11,896] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:31:16,112] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:31:20,180] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:31:24,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:31:28,374] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:31:32,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.06783755963283
[2022-12-07 09:31:32,904] [INFO] [runner_train_mujoco] Average state value: 0.5507306145628293
[2022-12-07 09:31:32,904] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 09:31:32,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.04321
[2022-12-07 09:31:33,000] [INFO] [controller] EPOCH 2 loss ppo:  -0.01584, loss val: 0.04186
[2022-12-07 09:31:33,039] [INFO] [controller] EPOCH 3 loss ppo:  -0.02000, loss val: 0.04158
[2022-12-07 09:31:33,082] [INFO] [controller] EPOCH 4 loss ppo:  -0.02289, loss val: 0.04119
[2022-12-07 09:31:33,091] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:31:33,270] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:31:33,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:31:37,936] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:31:42,461] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:31:46,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:31:51,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:31:55,395] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:31:59,642] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:32:04,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:32:08,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:32:12,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:32:16,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0439131946022724
[2022-12-07 09:32:16,330] [INFO] [runner_train_mujoco] Average state value: 0.5443163483540217
[2022-12-07 09:32:16,330] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 09:32:16,391] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.03818
[2022-12-07 09:32:16,434] [INFO] [controller] EPOCH 2 loss ppo:  -0.01406, loss val: 0.03857
[2022-12-07 09:32:16,477] [INFO] [controller] EPOCH 3 loss ppo:  -0.01575, loss val: 0.03947
[2022-12-07 09:32:16,543] [INFO] [controller] EPOCH 4 loss ppo:  -0.01772, loss val: 0.03778
[2022-12-07 09:32:16,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:32:16,719] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:32:16,720] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:32:20,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:32:24,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:32:28,695] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:32:33,067] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:32:37,537] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:32:41,913] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:32:45,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:32:49,981] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:32:54,404] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:32:58,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0720421931343305
[2022-12-07 09:32:58,661] [INFO] [runner_train_mujoco] Average state value: 0.5377851434151332
[2022-12-07 09:32:58,661] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 09:32:58,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.04551
[2022-12-07 09:32:59,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.01419, loss val: 0.04472
[2022-12-07 09:32:59,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.01573, loss val: 0.04420
[2022-12-07 09:32:59,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.01812, loss val: 0.04434
[2022-12-07 09:32:59,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:32:59,248] [INFO] [optimize] Finished learning.
