[2022-12-06 20:56:09,857] [INFO] [optimize] Starting learning
[2022-12-06 20:56:09,867] [INFO] [optimize] Starting learning process..
[2022-12-06 20:56:09,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:56:09,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:56:14,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:56:19,909] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:56:25,354] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:56:30,399] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:56:35,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:56:40,804] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:56:45,787] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:56:50,420] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:56:55,376] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:57:00,216] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2378308441442988
[2022-12-06 20:57:00,217] [INFO] [runner_train_mujoco] Average state value: -0.08404926524062953
[2022-12-06 20:57:00,217] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 20:57:00,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01403, loss val: 0.50553
[2022-12-06 20:57:00,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.02410, loss val: 0.45676
[2022-12-06 20:57:00,385] [INFO] [controller] EPOCH 3 loss ppo:  -0.02969, loss val: 0.39230
[2022-12-06 20:57:00,432] [INFO] [controller] EPOCH 4 loss ppo:  -0.03305, loss val: 0.33989
[2022-12-06 20:57:00,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:57:00,619] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:57:00,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:57:05,939] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:57:12,292] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:57:18,221] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:57:23,487] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:57:28,802] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:57:33,743] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:57:38,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:57:43,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:57:48,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:57:54,349] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1791018146577609
[2022-12-06 20:57:54,349] [INFO] [runner_train_mujoco] Average state value: 0.09194379335083067
[2022-12-06 20:57:54,349] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 20:57:54,424] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.26050
[2022-12-06 20:57:54,478] [INFO] [controller] EPOCH 2 loss ppo:  -0.02654, loss val: 0.21928
[2022-12-06 20:57:54,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.03272, loss val: 0.19369
[2022-12-06 20:57:54,583] [INFO] [controller] EPOCH 4 loss ppo:  -0.03689, loss val: 0.16247
[2022-12-06 20:57:54,602] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:57:54,792] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:57:54,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:58:00,288] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:58:05,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:58:12,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:58:17,891] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:58:23,551] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:58:28,912] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:58:34,405] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:58:40,091] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:58:45,787] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:58:51,202] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19770825543117232
[2022-12-06 20:58:51,203] [INFO] [runner_train_mujoco] Average state value: 0.2859993924008062
[2022-12-06 20:58:51,203] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 20:58:51,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.17622
[2022-12-06 20:58:51,320] [INFO] [controller] EPOCH 2 loss ppo:  -0.02297, loss val: 0.14401
[2022-12-06 20:58:51,370] [INFO] [controller] EPOCH 3 loss ppo:  -0.02665, loss val: 0.12241
[2022-12-06 20:58:51,424] [INFO] [controller] EPOCH 4 loss ppo:  -0.03044, loss val: 0.10495
[2022-12-06 20:58:51,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:58:51,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:58:51,610] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:58:57,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:59:03,454] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:59:09,058] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:59:14,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:59:20,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:59:25,362] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:59:30,795] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:59:36,492] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:59:42,273] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:59:48,121] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17704711496758727
[2022-12-06 20:59:48,122] [INFO] [runner_train_mujoco] Average state value: 0.40696311180666084
[2022-12-06 20:59:48,122] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 20:59:48,195] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.11710
[2022-12-06 20:59:48,251] [INFO] [controller] EPOCH 2 loss ppo:  -0.02231, loss val: 0.09841
[2022-12-06 20:59:48,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.02577, loss val: 0.08503
[2022-12-06 20:59:48,378] [INFO] [controller] EPOCH 4 loss ppo:  -0.03036, loss val: 0.07463
[2022-12-06 20:59:48,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:59:48,575] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:59:48,575] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:59:54,208] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:59:59,921] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:00:05,827] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:00:11,515] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:00:17,116] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:00:22,625] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:00:28,271] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:00:33,615] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:00:39,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:00:45,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21340485705391948
[2022-12-06 21:00:45,273] [INFO] [runner_train_mujoco] Average state value: 0.5867888992577791
[2022-12-06 21:00:45,273] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 21:00:45,329] [INFO] [controller] EPOCH 1 loss ppo:  -0.01053, loss val: 0.06642
[2022-12-06 21:00:45,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.02328, loss val: 0.05914
[2022-12-06 21:00:45,438] [INFO] [controller] EPOCH 3 loss ppo:  -0.02991, loss val: 0.05470
[2022-12-06 21:00:45,491] [INFO] [controller] EPOCH 4 loss ppo:  -0.03062, loss val: 0.05239
[2022-12-06 21:00:45,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:00:45,693] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:00:45,693] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:00:51,553] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:00:57,440] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:01:03,619] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:01:09,472] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:01:15,310] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:01:21,157] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:01:26,616] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:01:32,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:01:37,876] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:01:43,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.13674275801505284
[2022-12-06 21:01:43,888] [INFO] [runner_train_mujoco] Average state value: 0.6929921915332475
[2022-12-06 21:01:43,888] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 21:01:43,953] [INFO] [controller] EPOCH 1 loss ppo:  -0.00997, loss val: 0.05538
[2022-12-06 21:01:44,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.02668, loss val: 0.05241
[2022-12-06 21:01:44,077] [INFO] [controller] EPOCH 3 loss ppo:  -0.03069, loss val: 0.04997
[2022-12-06 21:01:44,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.03235, loss val: 0.04830
[2022-12-06 21:01:44,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:01:44,339] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:01:44,339] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:01:50,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:01:56,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:02:01,882] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:02:07,733] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:02:13,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:02:19,446] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:02:25,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:02:30,630] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:02:36,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:02:41,932] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2030924693922486
[2022-12-06 21:02:41,932] [INFO] [runner_train_mujoco] Average state value: 0.7351164732575416
[2022-12-06 21:02:41,932] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 21:02:41,996] [INFO] [controller] EPOCH 1 loss ppo:  -0.00833, loss val: 0.04967
[2022-12-06 21:02:42,062] [INFO] [controller] EPOCH 2 loss ppo:  -0.01756, loss val: 0.04753
[2022-12-06 21:02:42,110] [INFO] [controller] EPOCH 3 loss ppo:  -0.02163, loss val: 0.04490
[2022-12-06 21:02:42,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.02671, loss val: 0.04151
[2022-12-06 21:02:42,177] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:02:42,364] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:02:42,364] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:02:48,030] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:02:53,565] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:02:59,155] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:03:04,905] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:03:10,482] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:03:15,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:03:21,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:03:26,923] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:03:32,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:03:37,898] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14814033725954304
[2022-12-06 21:03:37,898] [INFO] [runner_train_mujoco] Average state value: 0.6814645354747773
[2022-12-06 21:03:37,898] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 21:03:37,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.00777, loss val: 0.03517
[2022-12-06 21:03:38,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.01613, loss val: 0.03337
[2022-12-06 21:03:38,067] [INFO] [controller] EPOCH 3 loss ppo:  -0.02187, loss val: 0.03609
[2022-12-06 21:03:38,116] [INFO] [controller] EPOCH 4 loss ppo:  -0.02756, loss val: 0.03177
[2022-12-06 21:03:38,127] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:03:38,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:03:38,305] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:03:43,664] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:03:49,060] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:03:54,211] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:03:59,266] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:04:04,942] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:04:10,365] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:04:15,541] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:04:20,792] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:04:25,675] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:04:31,024] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3011731310778749
[2022-12-06 21:04:31,024] [INFO] [runner_train_mujoco] Average state value: 0.5977470746835073
[2022-12-06 21:04:31,024] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 21:04:31,090] [INFO] [controller] EPOCH 1 loss ppo:  -0.00922, loss val: 0.04619
[2022-12-06 21:04:31,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.01781, loss val: 0.04626
[2022-12-06 21:04:31,191] [INFO] [controller] EPOCH 3 loss ppo:  -0.02132, loss val: 0.04451
[2022-12-06 21:04:31,240] [INFO] [controller] EPOCH 4 loss ppo:  -0.02749, loss val: 0.04254
[2022-12-06 21:04:31,250] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:04:31,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:04:31,432] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:04:36,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:04:42,319] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:04:47,712] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:04:52,763] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:04:58,203] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:05:03,596] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:05:09,248] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:05:14,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:05:20,415] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:05:25,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3009667717927063
[2022-12-06 21:05:25,427] [INFO] [runner_train_mujoco] Average state value: 0.626593586285909
[2022-12-06 21:05:25,427] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 21:05:25,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.00849, loss val: 0.03905
[2022-12-06 21:05:25,540] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.03807
[2022-12-06 21:05:25,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.02778, loss val: 0.03778
[2022-12-06 21:05:25,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.03072, loss val: 0.03815
[2022-12-06 21:05:25,641] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:05:25,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:05:25,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:05:31,239] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:05:36,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:05:42,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:05:47,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:05:53,046] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:05:58,201] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:06:03,618] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:06:09,240] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:06:14,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:06:20,260] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2249082179041184
[2022-12-06 21:06:20,261] [INFO] [runner_train_mujoco] Average state value: 0.6871982491612434
[2022-12-06 21:06:20,261] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 21:06:20,324] [INFO] [controller] EPOCH 1 loss ppo:  -0.00769, loss val: 0.04413
[2022-12-06 21:06:20,369] [INFO] [controller] EPOCH 2 loss ppo:  -0.01872, loss val: 0.04264
[2022-12-06 21:06:20,418] [INFO] [controller] EPOCH 3 loss ppo:  -0.02315, loss val: 0.04206
[2022-12-06 21:06:20,465] [INFO] [controller] EPOCH 4 loss ppo:  -0.02654, loss val: 0.04027
[2022-12-06 21:06:20,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:06:20,683] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:06:20,683] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:06:26,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:06:32,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:06:38,376] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:06:44,016] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:06:49,653] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:06:55,056] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:07:00,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:07:08,321] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:07:14,656] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:07:21,112] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2637845925450332
[2022-12-06 21:07:21,112] [INFO] [runner_train_mujoco] Average state value: 0.7510857548713683
[2022-12-06 21:07:21,112] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 21:07:21,192] [INFO] [controller] EPOCH 1 loss ppo:  -0.00688, loss val: 0.04312
[2022-12-06 21:07:21,257] [INFO] [controller] EPOCH 2 loss ppo:  -0.01731, loss val: 0.04463
[2022-12-06 21:07:21,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02350, loss val: 0.04411
[2022-12-06 21:07:21,387] [INFO] [controller] EPOCH 4 loss ppo:  -0.02731, loss val: 0.04309
[2022-12-06 21:07:21,398] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:07:21,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:07:21,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:07:27,622] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:07:33,357] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:07:39,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:07:44,991] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:07:50,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:07:56,901] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:08:03,107] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:08:08,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:08:15,482] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:08:21,144] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.265509353954983
[2022-12-06 21:08:21,145] [INFO] [runner_train_mujoco] Average state value: 0.7418796413143476
[2022-12-06 21:08:21,145] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 21:08:21,216] [INFO] [controller] EPOCH 1 loss ppo:  -0.00617, loss val: 0.04351
[2022-12-06 21:08:21,273] [INFO] [controller] EPOCH 2 loss ppo:  -0.01445, loss val: 0.04237
[2022-12-06 21:08:21,335] [INFO] [controller] EPOCH 3 loss ppo:  -0.02123, loss val: 0.04167
[2022-12-06 21:08:21,397] [INFO] [controller] EPOCH 4 loss ppo:  -0.02901, loss val: 0.04170
[2022-12-06 21:08:21,408] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:08:21,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:08:21,610] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:08:27,903] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:08:33,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:08:39,696] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:08:45,464] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:08:51,279] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:08:57,172] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:09:03,069] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:09:08,703] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:09:14,325] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:09:19,656] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2694194098041258
[2022-12-06 21:09:19,656] [INFO] [runner_train_mujoco] Average state value: 0.6929083843032519
[2022-12-06 21:09:19,657] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 21:09:19,740] [INFO] [controller] EPOCH 1 loss ppo:  -0.00769, loss val: 0.04708
[2022-12-06 21:09:19,796] [INFO] [controller] EPOCH 2 loss ppo:  -0.01560, loss val: 0.04742
[2022-12-06 21:09:19,859] [INFO] [controller] EPOCH 3 loss ppo:  -0.02169, loss val: 0.04641
[2022-12-06 21:09:19,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.02825, loss val: 0.04620
[2022-12-06 21:09:19,932] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:09:20,122] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:09:20,122] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:09:25,903] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:09:31,549] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:09:37,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:09:43,120] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:09:48,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:09:54,566] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:09:59,780] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:10:05,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:10:10,890] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:10:16,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.407805185359043
[2022-12-06 21:10:16,548] [INFO] [runner_train_mujoco] Average state value: 0.6874278519749641
[2022-12-06 21:10:16,548] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 21:10:16,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.00817, loss val: 0.04251
[2022-12-06 21:10:16,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.01816, loss val: 0.04341
[2022-12-06 21:10:16,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.02234, loss val: 0.04244
[2022-12-06 21:10:16,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.02909, loss val: 0.04296
[2022-12-06 21:10:16,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:10:16,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:10:16,972] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:10:22,153] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:10:27,792] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:10:33,114] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:10:38,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:10:43,908] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:10:49,472] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:10:55,126] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:11:00,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:11:06,145] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:11:11,147] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3182280184696217
[2022-12-06 21:11:11,147] [INFO] [runner_train_mujoco] Average state value: 0.6964538491169611
[2022-12-06 21:11:11,147] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 21:11:11,203] [INFO] [controller] EPOCH 1 loss ppo:  -0.00764, loss val: 0.03923
[2022-12-06 21:11:11,255] [INFO] [controller] EPOCH 2 loss ppo:  -0.01871, loss val: 0.03935
[2022-12-06 21:11:11,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.02535, loss val: 0.03698
[2022-12-06 21:11:11,375] [INFO] [controller] EPOCH 4 loss ppo:  -0.02627, loss val: 0.03654
[2022-12-06 21:11:11,385] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:11:11,568] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:11:11,569] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:11:16,946] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:11:22,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:11:27,795] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:11:33,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:11:38,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:11:44,650] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:11:49,863] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:11:54,935] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:11:59,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:12:05,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4762101113089468
[2022-12-06 21:12:05,391] [INFO] [runner_train_mujoco] Average state value: 0.7194737929304441
[2022-12-06 21:12:05,391] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 21:12:05,460] [INFO] [controller] EPOCH 1 loss ppo:  -0.00991, loss val: 0.04088
[2022-12-06 21:12:05,515] [INFO] [controller] EPOCH 2 loss ppo:  -0.02143, loss val: 0.04167
[2022-12-06 21:12:05,573] [INFO] [controller] EPOCH 3 loss ppo:  -0.02464, loss val: 0.04030
[2022-12-06 21:12:05,629] [INFO] [controller] EPOCH 4 loss ppo:  -0.03389, loss val: 0.03843
[2022-12-06 21:12:05,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:12:05,817] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:12:05,818] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:12:11,107] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:12:16,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:12:22,217] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:12:27,756] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:12:32,929] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:12:38,636] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:12:44,100] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:12:49,714] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:12:54,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:13:00,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6223586664612256
[2022-12-06 21:13:00,109] [INFO] [runner_train_mujoco] Average state value: 0.7054267816146215
[2022-12-06 21:13:00,109] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 21:13:00,170] [INFO] [controller] EPOCH 1 loss ppo:  -0.00996, loss val: 0.03894
[2022-12-06 21:13:00,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.02575, loss val: 0.03822
[2022-12-06 21:13:00,303] [INFO] [controller] EPOCH 3 loss ppo:  -0.02922, loss val: 0.03824
[2022-12-06 21:13:00,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.03469, loss val: 0.03813
[2022-12-06 21:13:00,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:13:00,560] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:13:00,560] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:13:05,611] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:13:10,909] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:13:16,535] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:13:22,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:13:27,477] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:13:32,715] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:13:38,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:13:43,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:13:49,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:13:55,395] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4436826719378269
[2022-12-06 21:13:55,396] [INFO] [runner_train_mujoco] Average state value: 0.6580440991719564
[2022-12-06 21:13:55,396] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 21:13:55,464] [INFO] [controller] EPOCH 1 loss ppo:  -0.00942, loss val: 0.03508
[2022-12-06 21:13:55,513] [INFO] [controller] EPOCH 2 loss ppo:  -0.01686, loss val: 0.03547
[2022-12-06 21:13:55,560] [INFO] [controller] EPOCH 3 loss ppo:  -0.02011, loss val: 0.03576
[2022-12-06 21:13:55,611] [INFO] [controller] EPOCH 4 loss ppo:  -0.02715, loss val: 0.03512
[2022-12-06 21:13:55,623] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:13:55,821] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:13:55,821] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:14:01,548] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:14:07,088] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:14:12,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:14:17,936] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:14:23,357] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:14:29,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:14:34,396] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:14:40,259] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:14:45,323] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:14:51,169] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5700624963885399
[2022-12-06 21:14:51,170] [INFO] [runner_train_mujoco] Average state value: 0.654384121954441
[2022-12-06 21:14:51,170] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 21:14:51,230] [INFO] [controller] EPOCH 1 loss ppo:  -0.00933, loss val: 0.04046
[2022-12-06 21:14:51,283] [INFO] [controller] EPOCH 2 loss ppo:  -0.02242, loss val: 0.03876
[2022-12-06 21:14:51,337] [INFO] [controller] EPOCH 3 loss ppo:  -0.02894, loss val: 0.03826
[2022-12-06 21:14:51,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.03312, loss val: 0.03874
[2022-12-06 21:14:51,399] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:14:51,586] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:14:51,586] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:14:57,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:15:03,255] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:15:09,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:15:14,999] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:15:20,810] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:15:26,143] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:15:32,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:15:38,064] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:15:43,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:15:49,137] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6867102085331691
[2022-12-06 21:15:49,137] [INFO] [runner_train_mujoco] Average state value: 0.6345813733736674
[2022-12-06 21:15:49,138] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 21:15:49,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01050, loss val: 0.04091
[2022-12-06 21:15:49,260] [INFO] [controller] EPOCH 2 loss ppo:  -0.02519, loss val: 0.04254
[2022-12-06 21:15:49,313] [INFO] [controller] EPOCH 3 loss ppo:  -0.02957, loss val: 0.04157
[2022-12-06 21:15:49,365] [INFO] [controller] EPOCH 4 loss ppo:  -0.03257, loss val: 0.04128
[2022-12-06 21:15:49,375] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:15:49,556] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:15:49,557] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:15:55,287] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:16:01,008] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:16:06,721] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:16:12,391] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:16:18,140] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:16:23,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:16:29,558] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:16:34,904] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:16:40,294] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:16:45,888] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8688984891252522
[2022-12-06 21:16:45,889] [INFO] [runner_train_mujoco] Average state value: 0.6484163747429847
[2022-12-06 21:16:45,889] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 21:16:45,946] [INFO] [controller] EPOCH 1 loss ppo:  -0.00823, loss val: 0.04255
[2022-12-06 21:16:46,017] [INFO] [controller] EPOCH 2 loss ppo:  -0.01802, loss val: 0.04197
[2022-12-06 21:16:46,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.02714, loss val: 0.04199
[2022-12-06 21:16:46,118] [INFO] [controller] EPOCH 4 loss ppo:  -0.03098, loss val: 0.04233
[2022-12-06 21:16:46,129] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:16:46,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:16:46,315] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:16:51,866] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:16:57,348] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:17:02,643] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:17:07,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:17:13,061] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:17:18,678] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:17:24,105] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:17:29,433] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:17:34,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:17:40,312] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9952272361296177
[2022-12-06 21:17:40,313] [INFO] [runner_train_mujoco] Average state value: 0.701792813181877
[2022-12-06 21:17:40,313] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 21:17:40,372] [INFO] [controller] EPOCH 1 loss ppo:  -0.00989, loss val: 0.04147
[2022-12-06 21:17:40,502] [INFO] [controller] EPOCH 2 loss ppo:  -0.01955, loss val: 0.04130
[2022-12-06 21:17:40,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.02566, loss val: 0.04148
[2022-12-06 21:17:40,608] [INFO] [controller] EPOCH 4 loss ppo:  -0.02998, loss val: 0.04158
[2022-12-06 21:17:40,618] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:17:40,815] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:17:40,815] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:17:46,358] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:17:51,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:17:56,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:18:01,850] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:18:07,252] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:18:12,427] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:18:17,812] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:18:22,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:18:28,403] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:18:33,844] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1041070552736931
[2022-12-06 21:18:33,845] [INFO] [runner_train_mujoco] Average state value: 0.7010704204440117
[2022-12-06 21:18:33,845] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 21:18:33,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01112, loss val: 0.03882
[2022-12-06 21:18:33,954] [INFO] [controller] EPOCH 2 loss ppo:  -0.02565, loss val: 0.03949
[2022-12-06 21:18:34,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.03098, loss val: 0.03930
[2022-12-06 21:18:34,054] [INFO] [controller] EPOCH 4 loss ppo:  -0.03243, loss val: 0.03859
[2022-12-06 21:18:34,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:18:34,238] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:18:34,238] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:18:39,598] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:18:44,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:18:50,282] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:18:55,442] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:19:00,594] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:19:05,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:19:11,103] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:19:16,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:19:22,199] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:19:27,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.294751968537414
[2022-12-06 21:19:27,887] [INFO] [runner_train_mujoco] Average state value: 0.6744118588566781
[2022-12-06 21:19:27,888] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 21:19:27,949] [INFO] [controller] EPOCH 1 loss ppo:  -0.01075, loss val: 0.04260
[2022-12-06 21:19:28,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.02059, loss val: 0.04196
[2022-12-06 21:19:28,058] [INFO] [controller] EPOCH 3 loss ppo:  -0.02740, loss val: 0.04196
[2022-12-06 21:19:28,112] [INFO] [controller] EPOCH 4 loss ppo:  -0.03218, loss val: 0.04246
[2022-12-06 21:19:28,126] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:19:28,300] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:19:28,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:19:33,782] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:19:39,305] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:19:44,764] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:19:50,550] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:19:56,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:20:01,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:20:06,630] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:20:12,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:20:18,155] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:20:23,724] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3396718366867753
[2022-12-06 21:20:23,724] [INFO] [runner_train_mujoco] Average state value: 0.6905341012875239
[2022-12-06 21:20:23,725] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 21:20:23,789] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.04121
[2022-12-06 21:20:23,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.02590, loss val: 0.04067
[2022-12-06 21:20:23,896] [INFO] [controller] EPOCH 3 loss ppo:  -0.03181, loss val: 0.04142
[2022-12-06 21:20:23,948] [INFO] [controller] EPOCH 4 loss ppo:  -0.03703, loss val: 0.04045
[2022-12-06 21:20:23,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:20:24,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:20:24,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:20:29,975] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:20:35,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:20:40,895] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:20:46,680] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:20:52,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:20:57,803] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:21:03,154] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:21:08,617] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:21:14,628] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:21:20,467] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2646964689355713
[2022-12-06 21:21:20,467] [INFO] [runner_train_mujoco] Average state value: 0.6880364146033923
[2022-12-06 21:21:20,467] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 21:21:20,536] [INFO] [controller] EPOCH 1 loss ppo:  -0.01209, loss val: 0.04246
[2022-12-06 21:21:20,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.04118
[2022-12-06 21:21:20,652] [INFO] [controller] EPOCH 3 loss ppo:  -0.02500, loss val: 0.04096
[2022-12-06 21:21:20,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.03003, loss val: 0.04067
[2022-12-06 21:21:20,712] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:21:20,901] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:21:20,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:21:26,728] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:21:32,459] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:21:38,331] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:21:43,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:21:49,758] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:21:55,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:22:01,556] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:22:07,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:22:12,811] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:22:18,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.385465275529414
[2022-12-06 21:22:18,738] [INFO] [runner_train_mujoco] Average state value: 0.6443474079966546
[2022-12-06 21:22:18,738] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 21:22:18,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.03908
[2022-12-06 21:22:18,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.02512, loss val: 0.03895
[2022-12-06 21:22:18,899] [INFO] [controller] EPOCH 3 loss ppo:  -0.02548, loss val: 0.03900
[2022-12-06 21:22:18,950] [INFO] [controller] EPOCH 4 loss ppo:  -0.03022, loss val: 0.04020
[2022-12-06 21:22:18,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:22:19,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:22:19,182] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:22:24,855] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:22:30,936] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:22:36,339] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:22:41,760] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:22:47,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:22:52,977] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:22:58,592] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:23:04,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:23:10,147] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:23:15,790] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5146250526377871
[2022-12-06 21:23:15,790] [INFO] [runner_train_mujoco] Average state value: 0.6214691051046053
[2022-12-06 21:23:15,790] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 21:23:15,863] [INFO] [controller] EPOCH 1 loss ppo:  -0.01296, loss val: 0.03875
[2022-12-06 21:23:15,934] [INFO] [controller] EPOCH 2 loss ppo:  -0.02473, loss val: 0.03946
[2022-12-06 21:23:16,024] [INFO] [controller] EPOCH 3 loss ppo:  -0.03247, loss val: 0.03935
[2022-12-06 21:23:16,097] [INFO] [controller] EPOCH 4 loss ppo:  -0.03406, loss val: 0.03641
[2022-12-06 21:23:16,110] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:23:16,330] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:23:16,330] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:23:21,598] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:23:27,023] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:23:32,912] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:23:37,968] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:23:43,401] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:23:48,936] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:23:54,245] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:23:59,560] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:24:04,727] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:24:09,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7089393066284306
[2022-12-06 21:24:09,979] [INFO] [runner_train_mujoco] Average state value: 0.621706439892451
[2022-12-06 21:24:09,979] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 21:24:10,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.03517
[2022-12-06 21:24:10,098] [INFO] [controller] EPOCH 2 loss ppo:  -0.02815, loss val: 0.03522
[2022-12-06 21:24:10,156] [INFO] [controller] EPOCH 3 loss ppo:  -0.03220, loss val: 0.03525
[2022-12-06 21:24:10,210] [INFO] [controller] EPOCH 4 loss ppo:  -0.03620, loss val: 0.03484
[2022-12-06 21:24:10,222] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:24:10,410] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:24:10,410] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:24:16,188] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:24:21,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:24:27,173] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:24:32,595] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:24:38,158] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:24:43,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:24:48,919] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:24:54,403] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:24:59,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:25:04,725] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7512241313417831
[2022-12-06 21:25:04,725] [INFO] [runner_train_mujoco] Average state value: 0.6025806549588839
[2022-12-06 21:25:04,725] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 21:25:04,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04348
[2022-12-06 21:25:04,826] [INFO] [controller] EPOCH 2 loss ppo:  -0.02240, loss val: 0.04298
[2022-12-06 21:25:04,874] [INFO] [controller] EPOCH 3 loss ppo:  -0.02880, loss val: 0.04327
[2022-12-06 21:25:04,934] [INFO] [controller] EPOCH 4 loss ppo:  -0.03382, loss val: 0.04263
[2022-12-06 21:25:04,944] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:25:05,119] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:25:05,119] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:25:10,378] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:25:15,571] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:25:20,767] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:25:26,335] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:25:31,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:25:36,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:25:42,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:25:47,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:25:52,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:25:57,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8287646674651885
[2022-12-06 21:25:57,550] [INFO] [runner_train_mujoco] Average state value: 0.6249753194451332
[2022-12-06 21:25:57,550] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 21:25:57,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.03705
[2022-12-06 21:25:57,677] [INFO] [controller] EPOCH 2 loss ppo:  -0.01905, loss val: 0.04219
[2022-12-06 21:25:57,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.02602, loss val: 0.03757
[2022-12-06 21:25:57,781] [INFO] [controller] EPOCH 4 loss ppo:  -0.03276, loss val: 0.04166
[2022-12-06 21:25:57,792] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:25:57,969] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:25:57,969] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:26:03,148] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:26:09,527] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:26:15,163] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:26:20,508] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:26:25,574] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:26:30,674] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:26:35,877] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:26:40,988] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:26:46,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:26:51,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8002214344264638
[2022-12-06 21:26:51,045] [INFO] [runner_train_mujoco] Average state value: 0.6439605479836463
[2022-12-06 21:26:51,045] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 21:26:51,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.01323, loss val: 0.03915
[2022-12-06 21:26:51,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.02131, loss val: 0.03953
[2022-12-06 21:26:51,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.02883, loss val: 0.03811
[2022-12-06 21:26:51,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.03376, loss val: 0.04027
[2022-12-06 21:26:51,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:26:51,460] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:26:51,460] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:26:56,347] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:27:01,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:27:06,969] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:27:12,115] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:27:17,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:27:22,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:27:28,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:27:33,526] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:27:39,032] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:27:44,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8870492155224547
[2022-12-06 21:27:44,433] [INFO] [runner_train_mujoco] Average state value: 0.654398156662782
[2022-12-06 21:27:44,433] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 21:27:44,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.04231
[2022-12-06 21:27:44,560] [INFO] [controller] EPOCH 2 loss ppo:  -0.02204, loss val: 0.04245
[2022-12-06 21:27:44,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.03084, loss val: 0.04189
[2022-12-06 21:27:44,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.03817, loss val: 0.04194
[2022-12-06 21:27:44,675] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:27:44,861] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:27:44,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:27:50,170] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:27:55,790] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:28:01,479] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:28:06,879] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:28:12,127] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:28:17,662] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:28:22,864] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:28:28,179] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:28:33,595] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:28:38,897] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.899933299219327
[2022-12-06 21:28:38,897] [INFO] [runner_train_mujoco] Average state value: 0.6541229940454165
[2022-12-06 21:28:38,897] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 21:28:38,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04183
[2022-12-06 21:28:39,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.02517, loss val: 0.04051
[2022-12-06 21:28:39,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.02918, loss val: 0.04127
[2022-12-06 21:28:39,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.03280, loss val: 0.03978
[2022-12-06 21:28:39,120] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:28:39,322] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:28:39,322] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:28:44,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:28:50,722] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:28:56,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:29:02,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:29:08,101] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:29:13,947] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:29:19,135] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:29:24,497] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:29:30,181] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:29:35,675] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9473970945272512
[2022-12-06 21:29:35,676] [INFO] [runner_train_mujoco] Average state value: 0.6756466646194458
[2022-12-06 21:29:35,676] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 21:29:35,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.04838
[2022-12-06 21:29:35,792] [INFO] [controller] EPOCH 2 loss ppo:  -0.02021, loss val: 0.04824
[2022-12-06 21:29:35,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.02266, loss val: 0.04840
[2022-12-06 21:29:35,902] [INFO] [controller] EPOCH 4 loss ppo:  -0.03385, loss val: 0.04874
[2022-12-06 21:29:35,913] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:29:36,106] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:29:36,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:29:41,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:29:47,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:29:52,594] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:29:58,398] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:30:04,146] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:30:09,690] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:30:15,467] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:30:20,913] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:30:26,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:30:32,496] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9045164703721404
[2022-12-06 21:30:32,496] [INFO] [runner_train_mujoco] Average state value: 0.6960170424381892
[2022-12-06 21:30:32,497] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 21:30:32,569] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.04578
[2022-12-06 21:30:32,621] [INFO] [controller] EPOCH 2 loss ppo:  -0.02152, loss val: 0.04597
[2022-12-06 21:30:32,685] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.04552
[2022-12-06 21:30:32,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.03295, loss val: 0.04488
[2022-12-06 21:30:32,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:30:32,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:30:32,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:30:38,495] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:30:44,559] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:30:50,096] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:30:55,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:31:01,251] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:31:06,880] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:31:12,742] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:31:18,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:31:23,480] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:31:28,734] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0157878464361145
[2022-12-06 21:31:28,735] [INFO] [runner_train_mujoco] Average state value: 0.679253848652045
[2022-12-06 21:31:28,735] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 21:31:28,814] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.04410
[2022-12-06 21:31:28,868] [INFO] [controller] EPOCH 2 loss ppo:  -0.02066, loss val: 0.04317
[2022-12-06 21:31:28,940] [INFO] [controller] EPOCH 3 loss ppo:  -0.02665, loss val: 0.04321
[2022-12-06 21:31:28,995] [INFO] [controller] EPOCH 4 loss ppo:  -0.03084, loss val: 0.04324
[2022-12-06 21:31:29,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:31:29,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:31:29,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:31:34,721] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:31:40,415] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:31:45,999] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:31:51,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:31:56,887] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:32:02,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:32:07,899] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:32:13,495] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:32:18,785] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:32:24,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.028244955031373
[2022-12-06 21:32:24,098] [INFO] [runner_train_mujoco] Average state value: 0.6629510691165924
[2022-12-06 21:32:24,098] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 21:32:24,162] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.04403
[2022-12-06 21:32:24,207] [INFO] [controller] EPOCH 2 loss ppo:  -0.02143, loss val: 0.04382
[2022-12-06 21:32:24,257] [INFO] [controller] EPOCH 3 loss ppo:  -0.02925, loss val: 0.04400
[2022-12-06 21:32:24,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.03353, loss val: 0.04389
[2022-12-06 21:32:24,317] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:32:24,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:32:24,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:32:29,938] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:32:35,136] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:32:40,235] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:32:45,843] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:32:52,259] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:32:58,018] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:33:04,113] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:33:11,203] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:33:17,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:33:22,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1273361575655145
[2022-12-06 21:33:22,626] [INFO] [runner_train_mujoco] Average state value: 0.6575295079946517
[2022-12-06 21:33:22,626] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 21:33:22,711] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.04443
[2022-12-06 21:33:22,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.01980, loss val: 0.04456
[2022-12-06 21:33:22,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.02358, loss val: 0.04446
[2022-12-06 21:33:22,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.03098, loss val: 0.04383
[2022-12-06 21:33:22,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:33:23,107] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:33:23,107] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:33:29,198] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:33:35,172] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:33:41,003] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:33:46,701] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:33:52,350] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:33:58,155] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:34:04,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:34:11,103] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:34:17,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:34:22,860] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9903275111558862
[2022-12-06 21:34:22,860] [INFO] [runner_train_mujoco] Average state value: 0.6570174544850985
[2022-12-06 21:34:22,860] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 21:34:22,920] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04349
[2022-12-06 21:34:22,984] [INFO] [controller] EPOCH 2 loss ppo:  -0.01891, loss val: 0.04346
[2022-12-06 21:34:23,032] [INFO] [controller] EPOCH 3 loss ppo:  -0.02470, loss val: 0.04413
[2022-12-06 21:34:23,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.02933, loss val: 0.04400
[2022-12-06 21:34:23,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:34:23,280] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:34:23,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:34:29,353] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:34:35,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:34:41,063] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:34:47,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:34:52,717] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:34:59,004] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:35:04,899] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:35:10,902] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:35:17,092] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:35:23,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1315522391446953
[2022-12-06 21:35:23,052] [INFO] [runner_train_mujoco] Average state value: 0.6492036489248276
[2022-12-06 21:35:23,052] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 21:35:23,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04281
[2022-12-06 21:35:23,205] [INFO] [controller] EPOCH 2 loss ppo:  -0.02004, loss val: 0.04287
[2022-12-06 21:35:23,299] [INFO] [controller] EPOCH 3 loss ppo:  -0.02280, loss val: 0.04245
[2022-12-06 21:35:23,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.02696, loss val: 0.04220
[2022-12-06 21:35:23,396] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:35:23,580] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:35:23,580] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:35:29,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:35:35,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:35:41,672] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:35:47,797] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:35:54,130] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:36:00,238] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:36:06,523] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:36:12,777] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:36:18,857] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:36:25,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1165478363953456
[2022-12-06 21:36:25,054] [INFO] [runner_train_mujoco] Average state value: 0.6585278803507487
[2022-12-06 21:36:25,054] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 21:36:25,141] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.03938
[2022-12-06 21:36:25,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.01951, loss val: 0.04083
[2022-12-06 21:36:25,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.02233, loss val: 0.03942
[2022-12-06 21:36:25,318] [INFO] [controller] EPOCH 4 loss ppo:  -0.02695, loss val: 0.04039
[2022-12-06 21:36:25,330] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:36:25,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:36:25,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:36:31,799] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:36:38,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:36:44,572] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:36:50,940] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:36:57,095] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:37:03,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:37:10,264] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:37:16,684] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:37:23,464] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:37:29,647] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.312007583821493
[2022-12-06 21:37:29,647] [INFO] [runner_train_mujoco] Average state value: 0.6535731610059738
[2022-12-06 21:37:29,648] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 21:37:29,742] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04203
[2022-12-06 21:37:29,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.02027, loss val: 0.04241
[2022-12-06 21:37:29,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.02308, loss val: 0.04208
[2022-12-06 21:37:30,005] [INFO] [controller] EPOCH 4 loss ppo:  -0.02569, loss val: 0.04213
[2022-12-06 21:37:30,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:37:30,208] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:37:30,209] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:37:36,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:37:43,001] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:37:49,246] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:37:55,713] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:38:02,570] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:38:09,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:38:15,568] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:38:21,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:38:27,683] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:38:34,138] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2205254503077696
[2022-12-06 21:38:34,138] [INFO] [runner_train_mujoco] Average state value: 0.6413723175525665
[2022-12-06 21:38:34,138] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 21:38:34,221] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.03999
[2022-12-06 21:38:34,282] [INFO] [controller] EPOCH 2 loss ppo:  -0.01960, loss val: 0.04020
[2022-12-06 21:38:34,392] [INFO] [controller] EPOCH 3 loss ppo:  -0.02343, loss val: 0.04003
[2022-12-06 21:38:34,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.02664, loss val: 0.03988
[2022-12-06 21:38:34,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:38:34,660] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:38:34,661] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:38:41,350] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:38:47,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:38:53,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:38:59,452] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:39:05,583] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:39:11,844] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:39:17,917] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:39:23,772] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:39:29,966] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:39:36,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0794497206328026
[2022-12-06 21:39:36,033] [INFO] [runner_train_mujoco] Average state value: 0.6320512268543244
[2022-12-06 21:39:36,033] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 21:39:36,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.04406
[2022-12-06 21:39:36,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.01804, loss val: 0.04551
[2022-12-06 21:39:36,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.02565, loss val: 0.04547
[2022-12-06 21:39:36,413] [INFO] [controller] EPOCH 4 loss ppo:  -0.02992, loss val: 0.04587
[2022-12-06 21:39:36,424] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:39:36,619] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:39:36,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:39:42,617] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:39:48,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:39:54,621] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:40:00,762] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:40:06,764] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:40:12,753] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:40:18,894] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:40:24,604] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:40:30,260] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:40:39,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2511231145043675
[2022-12-06 21:40:39,065] [INFO] [runner_train_mujoco] Average state value: 0.637018237054348
[2022-12-06 21:40:39,065] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 21:40:41,820] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04476
[2022-12-06 21:40:44,434] [INFO] [controller] EPOCH 2 loss ppo:  -0.01931, loss val: 0.04503
[2022-12-06 21:40:45,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.02529, loss val: 0.04482
[2022-12-06 21:40:45,727] [INFO] [controller] EPOCH 4 loss ppo:  -0.02815, loss val: 0.04500
[2022-12-06 21:40:45,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:40:46,024] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:40:46,025] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:40:54,927] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:42:50,086] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:43:00,604] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:43:11,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:43:21,140] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:43:32,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:43:42,467] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:43:51,247] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:43:59,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:44:06,391] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.232105002764221
[2022-12-06 21:44:06,392] [INFO] [runner_train_mujoco] Average state value: 0.6419392530719439
[2022-12-06 21:44:06,392] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 21:44:06,520] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04266
[2022-12-06 21:44:06,597] [INFO] [controller] EPOCH 2 loss ppo:  -0.01853, loss val: 0.04416
[2022-12-06 21:44:06,684] [INFO] [controller] EPOCH 3 loss ppo:  -0.02057, loss val: 0.04277
[2022-12-06 21:44:06,761] [INFO] [controller] EPOCH 4 loss ppo:  -0.02615, loss val: 0.04269
[2022-12-06 21:44:06,774] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:44:07,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:44:07,006] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:44:14,456] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:44:21,540] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:44:28,982] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:44:36,276] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:44:43,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:44:51,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:44:59,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:45:06,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:45:14,509] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:45:22,018] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.292520356829047
[2022-12-06 21:45:22,019] [INFO] [runner_train_mujoco] Average state value: 0.6403688458998997
[2022-12-06 21:45:22,019] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 21:45:22,113] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.03841
[2022-12-06 21:45:22,183] [INFO] [controller] EPOCH 2 loss ppo:  -0.01562, loss val: 0.03817
[2022-12-06 21:45:22,252] [INFO] [controller] EPOCH 3 loss ppo:  -0.02037, loss val: 0.03817
[2022-12-06 21:45:22,316] [INFO] [controller] EPOCH 4 loss ppo:  -0.02760, loss val: 0.03798
[2022-12-06 21:45:22,329] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:45:22,550] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:45:22,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:45:29,753] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:45:37,365] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:45:44,256] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:45:51,742] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:45:58,817] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:46:05,820] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:46:12,991] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:46:20,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:46:27,519] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:46:34,938] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.274696723996818
[2022-12-06 21:46:34,939] [INFO] [runner_train_mujoco] Average state value: 0.6290103919506074
[2022-12-06 21:46:34,939] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 21:46:35,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.04160
[2022-12-06 21:46:35,107] [INFO] [controller] EPOCH 2 loss ppo:  -0.01916, loss val: 0.04180
[2022-12-06 21:46:35,182] [INFO] [controller] EPOCH 3 loss ppo:  -0.02352, loss val: 0.04154
[2022-12-06 21:46:35,252] [INFO] [controller] EPOCH 4 loss ppo:  -0.02746, loss val: 0.04211
[2022-12-06 21:46:35,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:46:35,478] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:46:35,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:46:42,840] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:46:50,254] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:46:57,531] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:47:04,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:47:10,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:47:18,360] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:47:25,252] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:47:32,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:47:40,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:47:47,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.289726105325953
[2022-12-06 21:47:47,116] [INFO] [runner_train_mujoco] Average state value: 0.6216741193532943
[2022-12-06 21:47:47,117] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 21:47:47,214] [INFO] [controller] EPOCH 1 loss ppo:  -0.01442, loss val: 0.04324
[2022-12-06 21:47:47,278] [INFO] [controller] EPOCH 2 loss ppo:  -0.02144, loss val: 0.04329
[2022-12-06 21:47:47,348] [INFO] [controller] EPOCH 3 loss ppo:  -0.02576, loss val: 0.04330
[2022-12-06 21:47:47,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.02893, loss val: 0.04504
[2022-12-06 21:47:47,434] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:47:47,666] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:47:47,666] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:47:54,878] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:48:02,633] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:48:09,618] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:48:16,890] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:48:24,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:48:31,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:48:38,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:48:45,854] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:48:52,566] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:48:59,596] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.386500346400548
[2022-12-06 21:48:59,596] [INFO] [runner_train_mujoco] Average state value: 0.6162644259134928
[2022-12-06 21:48:59,597] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 21:48:59,689] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04143
[2022-12-06 21:48:59,765] [INFO] [controller] EPOCH 2 loss ppo:  -0.01952, loss val: 0.04051
[2022-12-06 21:48:59,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.02042, loss val: 0.04055
[2022-12-06 21:48:59,913] [INFO] [controller] EPOCH 4 loss ppo:  -0.02387, loss val: 0.04018
[2022-12-06 21:48:59,925] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:49:00,151] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:49:00,151] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:49:07,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:49:15,000] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:49:21,805] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:49:29,165] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:49:36,757] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:49:44,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:49:53,103] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:50:01,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:50:10,504] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:50:20,709] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4006350005209702
[2022-12-06 21:50:20,709] [INFO] [runner_train_mujoco] Average state value: 0.6130500035087267
[2022-12-06 21:50:20,709] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 21:50:20,816] [INFO] [controller] EPOCH 1 loss ppo:  -0.01260, loss val: 0.04610
[2022-12-06 21:50:20,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.01529, loss val: 0.04511
[2022-12-06 21:50:20,965] [INFO] [controller] EPOCH 3 loss ppo:  -0.01909, loss val: 0.04509
[2022-12-06 21:50:21,069] [INFO] [controller] EPOCH 4 loss ppo:  -0.02377, loss val: 0.04497
[2022-12-06 21:50:21,084] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:50:21,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:50:21,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:50:30,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:50:39,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:50:48,632] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:50:57,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:51:07,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:51:15,712] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:51:24,721] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:51:33,672] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:51:42,355] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:51:51,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3976160428148647
[2022-12-06 21:51:51,515] [INFO] [runner_train_mujoco] Average state value: 0.6130862187544504
[2022-12-06 21:51:51,515] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 21:51:51,611] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04410
[2022-12-06 21:51:51,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.01525, loss val: 0.04416
[2022-12-06 21:51:51,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.01941, loss val: 0.04400
[2022-12-06 21:51:51,897] [INFO] [controller] EPOCH 4 loss ppo:  -0.02297, loss val: 0.04526
[2022-12-06 21:51:51,911] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:51:52,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:51:52,149] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:52:01,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:52:09,720] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:52:18,477] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:52:27,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:52:36,446] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:52:45,166] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:52:53,744] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:53:02,382] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:53:11,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:53:19,762] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4645327901452694
[2022-12-06 21:53:19,762] [INFO] [runner_train_mujoco] Average state value: 0.6176793787479401
[2022-12-06 21:53:19,762] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 21:53:19,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.05180
[2022-12-06 21:53:20,033] [INFO] [controller] EPOCH 2 loss ppo:  -0.01576, loss val: 0.05172
[2022-12-06 21:53:20,175] [INFO] [controller] EPOCH 3 loss ppo:  -0.01869, loss val: 0.05151
[2022-12-06 21:53:20,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.02205, loss val: 0.05124
[2022-12-06 21:53:20,318] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:53:20,575] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:53:20,576] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:53:29,422] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:53:37,253] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:53:44,658] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:53:52,278] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:53:59,599] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:54:07,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:54:14,379] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:54:21,776] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:54:28,790] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:54:35,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4774399372785743
[2022-12-06 21:54:35,642] [INFO] [runner_train_mujoco] Average state value: 0.6246125346024831
[2022-12-06 21:54:35,642] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 21:54:35,768] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.04617
[2022-12-06 21:54:35,844] [INFO] [controller] EPOCH 2 loss ppo:  -0.01408, loss val: 0.04607
[2022-12-06 21:54:35,930] [INFO] [controller] EPOCH 3 loss ppo:  -0.01607, loss val: 0.04647
[2022-12-06 21:54:36,035] [INFO] [controller] EPOCH 4 loss ppo:  -0.01878, loss val: 0.04619
[2022-12-06 21:54:36,049] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:54:36,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:54:36,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:54:43,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:54:50,791] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:54:58,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:55:05,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:55:12,711] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:55:19,867] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:55:26,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:55:33,719] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:55:40,437] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:55:46,804] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.489394462462557
[2022-12-06 21:55:46,804] [INFO] [runner_train_mujoco] Average state value: 0.6277593216697375
[2022-12-06 21:55:46,804] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 21:55:46,901] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04490
[2022-12-06 21:55:46,959] [INFO] [controller] EPOCH 2 loss ppo:  -0.01400, loss val: 0.04624
[2022-12-06 21:55:47,026] [INFO] [controller] EPOCH 3 loss ppo:  -0.01602, loss val: 0.04494
[2022-12-06 21:55:47,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.01809, loss val: 0.04529
[2022-12-06 21:55:47,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:55:47,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 21:55:47,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 21:55:53,977] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 21:56:00,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 21:56:07,198] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 21:56:13,860] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 21:56:20,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 21:56:27,653] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 21:56:38,967] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 21:56:47,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 21:56:55,339] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 21:57:03,685] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.532715193032222
[2022-12-06 21:57:03,685] [INFO] [runner_train_mujoco] Average state value: 0.6297545113960903
[2022-12-06 21:57:03,685] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 21:57:03,771] [INFO] [controller] EPOCH 1 loss ppo:  -0.01305, loss val: 0.04717
[2022-12-06 21:57:03,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.01351, loss val: 0.04737
[2022-12-06 21:57:03,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.01433, loss val: 0.04724
[2022-12-06 21:57:04,001] [INFO] [controller] EPOCH 4 loss ppo:  -0.01561, loss val: 0.04740
[2022-12-06 21:57:04,013] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 21:57:04,226] [INFO] [optimize] Finished learning.
