[2022-12-06 13:29:23,948] [INFO] [optimize] Starting learning
[2022-12-06 13:29:23,952] [INFO] [optimize] Starting learning process..
[2022-12-06 13:29:23,996] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:29:23,997] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:29:28,752] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:29:32,018] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:29:35,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:29:39,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:29:43,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:29:48,089] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:29:51,324] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:29:54,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:29:57,921] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:30:01,585] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18090829542152392
[2022-12-06 13:30:01,586] [INFO] [runner_train_mujoco] Average state value: 0.1118989132406811
[2022-12-06 13:30:01,586] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 13:30:01,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.29084
[2022-12-06 13:30:01,665] [INFO] [controller] EPOCH 2 loss ppo:  -0.02845, loss val: 0.24860
[2022-12-06 13:30:01,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.03511, loss val: 0.20350
[2022-12-06 13:30:01,725] [INFO] [controller] EPOCH 4 loss ppo:  -0.03759, loss val: 0.17060
[2022-12-06 13:30:01,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:30:01,850] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:30:01,850] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:30:05,165] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:30:08,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:30:11,598] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:30:15,168] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:30:18,406] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:30:21,745] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:30:25,042] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:30:28,239] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:30:31,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:30:34,713] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.15837196721331187
[2022-12-06 13:30:34,713] [INFO] [runner_train_mujoco] Average state value: 0.30599461594348154
[2022-12-06 13:30:34,713] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 13:30:34,764] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.16308
[2022-12-06 13:30:34,807] [INFO] [controller] EPOCH 2 loss ppo:  -0.03006, loss val: 0.13265
[2022-12-06 13:30:34,852] [INFO] [controller] EPOCH 3 loss ppo:  -0.03928, loss val: 0.11479
[2022-12-06 13:30:34,889] [INFO] [controller] EPOCH 4 loss ppo:  -0.04206, loss val: 0.10029
[2022-12-06 13:30:34,898] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:30:35,043] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:30:35,043] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:30:40,507] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:30:44,615] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:30:48,506] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:30:52,184] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:30:57,996] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:31:03,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:31:08,377] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:31:13,209] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:31:18,028] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:31:24,661] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24829228248671384
[2022-12-06 13:31:24,662] [INFO] [runner_train_mujoco] Average state value: 0.4718267456342777
[2022-12-06 13:31:24,662] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 13:31:24,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.10189
[2022-12-06 13:31:25,071] [INFO] [controller] EPOCH 2 loss ppo:  -0.02339, loss val: 0.08595
[2022-12-06 13:31:25,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.02871, loss val: 0.06950
[2022-12-06 13:31:25,270] [INFO] [controller] EPOCH 4 loss ppo:  -0.03564, loss val: 0.06285
[2022-12-06 13:31:25,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:31:25,549] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:31:25,549] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:31:33,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:31:39,785] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:31:45,640] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:31:52,341] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:31:59,213] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:32:06,879] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:32:13,508] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:32:19,379] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:32:25,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:32:32,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.14754521465714526
[2022-12-06 13:32:32,004] [INFO] [runner_train_mujoco] Average state value: 0.6184492006575069
[2022-12-06 13:32:32,004] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 13:32:32,078] [INFO] [controller] EPOCH 1 loss ppo:  -0.00996, loss val: 0.06879
[2022-12-06 13:32:32,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.02198, loss val: 0.06141
[2022-12-06 13:32:32,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.02702, loss val: 0.05670
[2022-12-06 13:32:32,267] [INFO] [controller] EPOCH 4 loss ppo:  -0.03023, loss val: 0.05346
[2022-12-06 13:32:32,278] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:32:32,459] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:32:32,460] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:32:38,378] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:32:44,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:32:50,251] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:32:56,228] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:33:02,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:33:08,509] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:33:14,508] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:33:20,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:33:26,819] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:33:32,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.277445786680364
[2022-12-06 13:33:32,837] [INFO] [runner_train_mujoco] Average state value: 0.7252800782521567
[2022-12-06 13:33:32,837] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 13:33:32,903] [INFO] [controller] EPOCH 1 loss ppo:  -0.00798, loss val: 0.05104
[2022-12-06 13:33:32,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.02249, loss val: 0.04813
[2022-12-06 13:33:33,014] [INFO] [controller] EPOCH 3 loss ppo:  -0.02986, loss val: 0.04753
[2022-12-06 13:33:33,097] [INFO] [controller] EPOCH 4 loss ppo:  -0.03321, loss val: 0.04651
[2022-12-06 13:33:33,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:33:33,309] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:33:33,309] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:33:39,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:33:45,995] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:33:52,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:33:58,838] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:34:05,463] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:34:11,669] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:34:18,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:34:24,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:34:31,569] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:34:38,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2261468206437675
[2022-12-06 13:34:38,126] [INFO] [runner_train_mujoco] Average state value: 0.7663287533124288
[2022-12-06 13:34:38,126] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 13:34:38,214] [INFO] [controller] EPOCH 1 loss ppo:  -0.00711, loss val: 0.04764
[2022-12-06 13:34:38,279] [INFO] [controller] EPOCH 2 loss ppo:  -0.01485, loss val: 0.04553
[2022-12-06 13:34:38,337] [INFO] [controller] EPOCH 3 loss ppo:  -0.01861, loss val: 0.04265
[2022-12-06 13:34:38,401] [INFO] [controller] EPOCH 4 loss ppo:  -0.02142, loss val: 0.04098
[2022-12-06 13:34:38,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:34:38,607] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:34:38,608] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:34:45,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:34:52,197] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:34:59,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:35:06,025] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:35:12,652] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:35:19,867] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:35:27,060] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:35:33,925] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:35:40,660] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:35:47,486] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24380306101287483
[2022-12-06 13:35:47,486] [INFO] [runner_train_mujoco] Average state value: 0.7068059458335241
[2022-12-06 13:35:47,486] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 13:35:47,637] [INFO] [controller] EPOCH 1 loss ppo:  -0.00692, loss val: 0.04050
[2022-12-06 13:35:47,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.01713, loss val: 0.04049
[2022-12-06 13:35:47,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.02152, loss val: 0.04199
[2022-12-06 13:35:47,843] [INFO] [controller] EPOCH 4 loss ppo:  -0.02541, loss val: 0.04074
[2022-12-06 13:35:47,856] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:35:48,071] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:35:48,072] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:35:55,422] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:36:02,117] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:36:09,403] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:36:16,940] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:36:24,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:36:31,175] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:36:38,341] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:36:45,463] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:36:52,754] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:36:59,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.159495975158969
[2022-12-06 13:36:59,833] [INFO] [runner_train_mujoco] Average state value: 0.6669564135273298
[2022-12-06 13:36:59,833] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 13:36:59,909] [INFO] [controller] EPOCH 1 loss ppo:  -0.00577, loss val: 0.04756
[2022-12-06 13:36:59,992] [INFO] [controller] EPOCH 2 loss ppo:  -0.01892, loss val: 0.04666
[2022-12-06 13:37:00,100] [INFO] [controller] EPOCH 3 loss ppo:  -0.02536, loss val: 0.04597
[2022-12-06 13:37:00,223] [INFO] [controller] EPOCH 4 loss ppo:  -0.03017, loss val: 0.04451
[2022-12-06 13:37:00,236] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:37:00,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:37:00,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:37:07,854] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:37:15,231] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:37:22,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:37:28,796] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:37:35,680] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:37:42,768] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:37:49,263] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:37:55,859] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:38:02,294] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:38:08,933] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24276683386390294
[2022-12-06 13:38:08,933] [INFO] [runner_train_mujoco] Average state value: 0.7123989289800327
[2022-12-06 13:38:08,934] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 13:38:08,997] [INFO] [controller] EPOCH 1 loss ppo:  -0.00773, loss val: 0.04338
[2022-12-06 13:38:09,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.01982, loss val: 0.04291
[2022-12-06 13:38:09,103] [INFO] [controller] EPOCH 3 loss ppo:  -0.02508, loss val: 0.04299
[2022-12-06 13:38:09,159] [INFO] [controller] EPOCH 4 loss ppo:  -0.02901, loss val: 0.04314
[2022-12-06 13:38:09,171] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:38:09,371] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:38:09,371] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:38:15,558] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:38:22,237] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:38:28,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:38:34,996] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:38:42,031] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:38:48,386] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:38:54,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:39:00,728] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:39:06,881] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:39:13,197] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.25402740451597106
[2022-12-06 13:39:13,197] [INFO] [runner_train_mujoco] Average state value: 0.7544209017356237
[2022-12-06 13:39:13,198] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 13:39:13,272] [INFO] [controller] EPOCH 1 loss ppo:  -0.00648, loss val: 0.04282
[2022-12-06 13:39:13,329] [INFO] [controller] EPOCH 2 loss ppo:  -0.01539, loss val: 0.04316
[2022-12-06 13:39:13,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.01959, loss val: 0.04324
[2022-12-06 13:39:13,436] [INFO] [controller] EPOCH 4 loss ppo:  -0.02495, loss val: 0.04303
[2022-12-06 13:39:13,447] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:39:13,638] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:39:13,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:39:20,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:39:26,477] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:39:32,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:39:38,459] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:39:44,882] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:39:51,351] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:39:57,730] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:40:04,716] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:40:11,467] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:40:18,247] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2864056792241538
[2022-12-06 13:40:18,247] [INFO] [runner_train_mujoco] Average state value: 0.7608680498003959
[2022-12-06 13:40:18,247] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 13:40:18,327] [INFO] [controller] EPOCH 1 loss ppo:  -0.00653, loss val: 0.04537
[2022-12-06 13:40:18,499] [INFO] [controller] EPOCH 2 loss ppo:  -0.01605, loss val: 0.04399
[2022-12-06 13:40:18,601] [INFO] [controller] EPOCH 3 loss ppo:  -0.02326, loss val: 0.04205
[2022-12-06 13:40:18,692] [INFO] [controller] EPOCH 4 loss ppo:  -0.02791, loss val: 0.04049
[2022-12-06 13:40:18,703] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:40:18,895] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:40:18,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:40:25,045] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:40:31,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:40:37,465] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:40:43,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:40:49,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:40:55,208] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:41:01,344] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:41:07,496] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:41:14,005] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:41:20,419] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19465264234489144
[2022-12-06 13:41:20,419] [INFO] [runner_train_mujoco] Average state value: 0.7013609870274861
[2022-12-06 13:41:20,420] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 13:41:20,505] [INFO] [controller] EPOCH 1 loss ppo:  -0.00683, loss val: 0.03904
[2022-12-06 13:41:20,560] [INFO] [controller] EPOCH 2 loss ppo:  -0.01780, loss val: 0.03912
[2022-12-06 13:41:20,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.02204, loss val: 0.03731
[2022-12-06 13:41:20,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.02816, loss val: 0.03775
[2022-12-06 13:41:20,677] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:41:20,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:41:20,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:41:27,391] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:41:33,961] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:41:40,304] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:41:46,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:41:52,481] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:41:58,878] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:42:04,976] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:42:11,480] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:42:17,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:42:23,919] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.30744487380487706
[2022-12-06 13:42:23,920] [INFO] [runner_train_mujoco] Average state value: 0.6370141219099363
[2022-12-06 13:42:23,920] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 13:42:24,010] [INFO] [controller] EPOCH 1 loss ppo:  -0.00690, loss val: 0.04839
[2022-12-06 13:42:24,081] [INFO] [controller] EPOCH 2 loss ppo:  -0.02165, loss val: 0.05004
[2022-12-06 13:42:24,179] [INFO] [controller] EPOCH 3 loss ppo:  -0.02611, loss val: 0.04562
[2022-12-06 13:42:24,267] [INFO] [controller] EPOCH 4 loss ppo:  -0.02839, loss val: 0.04218
[2022-12-06 13:42:24,279] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:42:24,481] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:42:24,482] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:42:31,013] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:42:37,378] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:42:43,733] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:42:50,168] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:42:56,972] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:43:03,787] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:43:10,190] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:43:16,902] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:43:23,789] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:43:30,436] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3479970922316987
[2022-12-06 13:43:30,436] [INFO] [runner_train_mujoco] Average state value: 0.6869292140205701
[2022-12-06 13:43:30,437] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 13:43:30,548] [INFO] [controller] EPOCH 1 loss ppo:  -0.00610, loss val: 0.04821
[2022-12-06 13:43:30,685] [INFO] [controller] EPOCH 2 loss ppo:  -0.01894, loss val: 0.04590
[2022-12-06 13:43:30,761] [INFO] [controller] EPOCH 3 loss ppo:  -0.02370, loss val: 0.04455
[2022-12-06 13:43:30,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.02906, loss val: 0.04487
[2022-12-06 13:43:30,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:43:31,090] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:43:31,091] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:43:37,337] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:43:44,034] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:43:50,320] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:43:57,284] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:44:03,987] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:44:10,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:44:17,780] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:44:25,195] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:44:32,027] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:44:38,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.28474928614406475
[2022-12-06 13:44:38,974] [INFO] [runner_train_mujoco] Average state value: 0.7788531968593597
[2022-12-06 13:44:38,974] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 13:44:39,058] [INFO] [controller] EPOCH 1 loss ppo:  -0.00585, loss val: 0.04368
[2022-12-06 13:44:39,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.01470, loss val: 0.04446
[2022-12-06 13:44:39,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.02266, loss val: 0.04312
[2022-12-06 13:44:39,284] [INFO] [controller] EPOCH 4 loss ppo:  -0.02736, loss val: 0.04263
[2022-12-06 13:44:39,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:44:39,511] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:44:39,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:44:46,460] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:44:53,492] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:45:00,390] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:45:07,559] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:45:15,020] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:45:22,007] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:45:28,804] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:45:35,391] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:45:42,146] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:45:48,749] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3116130339963342
[2022-12-06 13:45:48,750] [INFO] [runner_train_mujoco] Average state value: 0.7499420508543649
[2022-12-06 13:45:48,750] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 13:45:48,835] [INFO] [controller] EPOCH 1 loss ppo:  -0.00727, loss val: 0.04328
[2022-12-06 13:45:48,896] [INFO] [controller] EPOCH 2 loss ppo:  -0.01661, loss val: 0.04127
[2022-12-06 13:45:48,985] [INFO] [controller] EPOCH 3 loss ppo:  -0.01878, loss val: 0.04023
[2022-12-06 13:45:49,071] [INFO] [controller] EPOCH 4 loss ppo:  -0.02165, loss val: 0.04040
[2022-12-06 13:45:49,083] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:45:49,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:45:49,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:45:56,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:46:03,483] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:46:10,287] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:46:16,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:46:23,144] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:46:29,355] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:46:35,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:46:41,386] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:46:47,713] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:46:54,124] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4199206263386853
[2022-12-06 13:46:54,124] [INFO] [runner_train_mujoco] Average state value: 0.6758589068253835
[2022-12-06 13:46:54,124] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 13:46:54,186] [INFO] [controller] EPOCH 1 loss ppo:  -0.00777, loss val: 0.04169
[2022-12-06 13:46:54,237] [INFO] [controller] EPOCH 2 loss ppo:  -0.02005, loss val: 0.04098
[2022-12-06 13:46:54,288] [INFO] [controller] EPOCH 3 loss ppo:  -0.02845, loss val: 0.04091
[2022-12-06 13:46:54,348] [INFO] [controller] EPOCH 4 loss ppo:  -0.03222, loss val: 0.04060
[2022-12-06 13:46:54,360] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:46:54,578] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:46:54,578] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:47:01,243] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:47:07,458] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:47:14,211] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:47:20,501] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:47:26,975] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:47:33,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:47:39,498] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:47:45,904] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:47:51,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:47:57,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4503296127120934
[2022-12-06 13:47:57,304] [INFO] [runner_train_mujoco] Average state value: 0.6726901797850927
[2022-12-06 13:47:57,305] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 13:47:57,371] [INFO] [controller] EPOCH 1 loss ppo:  -0.00594, loss val: 0.03763
[2022-12-06 13:47:57,421] [INFO] [controller] EPOCH 2 loss ppo:  -0.01649, loss val: 0.03746
[2022-12-06 13:47:57,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.02283, loss val: 0.03719
[2022-12-06 13:47:57,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.02531, loss val: 0.03726
[2022-12-06 13:47:57,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:47:57,750] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:47:57,751] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:48:04,115] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:48:10,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:48:17,003] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:48:23,084] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:48:28,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:48:34,601] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:48:40,753] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:48:46,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:48:52,779] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:48:58,767] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3807529899278859
[2022-12-06 13:48:58,767] [INFO] [runner_train_mujoco] Average state value: 0.7006762318611146
[2022-12-06 13:48:58,767] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 13:48:58,849] [INFO] [controller] EPOCH 1 loss ppo:  -0.00810, loss val: 0.03847
[2022-12-06 13:48:58,903] [INFO] [controller] EPOCH 2 loss ppo:  -0.01857, loss val: 0.03848
[2022-12-06 13:48:58,990] [INFO] [controller] EPOCH 3 loss ppo:  -0.02055, loss val: 0.03856
[2022-12-06 13:48:59,082] [INFO] [controller] EPOCH 4 loss ppo:  -0.02574, loss val: 0.04056
[2022-12-06 13:48:59,094] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:48:59,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:48:59,288] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:49:05,020] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:49:10,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:49:16,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:49:22,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:49:28,374] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:49:34,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:49:40,822] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:49:46,954] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:49:53,266] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:49:59,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.29329357629692043
[2022-12-06 13:49:59,427] [INFO] [runner_train_mujoco] Average state value: 0.7264966170787811
[2022-12-06 13:49:59,427] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 13:49:59,498] [INFO] [controller] EPOCH 1 loss ppo:  -0.00616, loss val: 0.03936
[2022-12-06 13:49:59,555] [INFO] [controller] EPOCH 2 loss ppo:  -0.01894, loss val: 0.03946
[2022-12-06 13:49:59,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.02429, loss val: 0.03996
[2022-12-06 13:49:59,705] [INFO] [controller] EPOCH 4 loss ppo:  -0.02762, loss val: 0.03809
[2022-12-06 13:49:59,717] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:49:59,919] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:49:59,920] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:50:05,881] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:50:11,648] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:50:17,827] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:50:24,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:50:30,859] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:50:36,990] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:50:43,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:50:49,604] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:50:56,126] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:51:02,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3611875059032008
[2022-12-06 13:51:02,432] [INFO] [runner_train_mujoco] Average state value: 0.7368173588514327
[2022-12-06 13:51:02,432] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 13:51:02,502] [INFO] [controller] EPOCH 1 loss ppo:  -0.00765, loss val: 0.04342
[2022-12-06 13:51:02,554] [INFO] [controller] EPOCH 2 loss ppo:  -0.01534, loss val: 0.04144
[2022-12-06 13:51:02,606] [INFO] [controller] EPOCH 3 loss ppo:  -0.01980, loss val: 0.03904
[2022-12-06 13:51:02,674] [INFO] [controller] EPOCH 4 loss ppo:  -0.02455, loss val: 0.03706
[2022-12-06 13:51:02,685] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:51:02,880] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:51:02,880] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:51:09,098] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:51:15,775] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:51:22,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:51:28,840] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:51:35,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:51:41,455] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:51:48,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:51:54,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:52:01,182] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:52:07,830] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40521207970562634
[2022-12-06 13:52:07,830] [INFO] [runner_train_mujoco] Average state value: 0.6753602277636528
[2022-12-06 13:52:07,830] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 13:52:07,935] [INFO] [controller] EPOCH 1 loss ppo:  -0.00816, loss val: 0.03824
[2022-12-06 13:52:08,090] [INFO] [controller] EPOCH 2 loss ppo:  -0.02158, loss val: 0.03877
[2022-12-06 13:52:08,187] [INFO] [controller] EPOCH 3 loss ppo:  -0.02411, loss val: 0.03901
[2022-12-06 13:52:08,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.02846, loss val: 0.03905
[2022-12-06 13:52:08,269] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:52:08,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:52:08,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:52:15,004] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:52:22,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:52:29,045] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:52:35,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:52:42,124] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:52:48,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:52:55,531] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:53:02,260] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:53:09,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:53:15,685] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.551343745673429
[2022-12-06 13:53:15,685] [INFO] [runner_train_mujoco] Average state value: 0.6508335106770197
[2022-12-06 13:53:15,685] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 13:53:15,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.00665, loss val: 0.04231
[2022-12-06 13:53:15,902] [INFO] [controller] EPOCH 2 loss ppo:  -0.01557, loss val: 0.04217
[2022-12-06 13:53:15,958] [INFO] [controller] EPOCH 3 loss ppo:  -0.01897, loss val: 0.04132
[2022-12-06 13:53:16,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.02273, loss val: 0.04196
[2022-12-06 13:53:16,056] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:53:16,273] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:53:16,274] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:53:23,324] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:53:30,928] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:53:37,844] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:53:44,968] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:53:51,596] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:53:58,240] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:54:04,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:54:11,419] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:54:17,942] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:54:24,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5878008149391881
[2022-12-06 13:54:24,515] [INFO] [runner_train_mujoco] Average state value: 0.685392133017381
[2022-12-06 13:54:24,515] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 13:54:24,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.00958, loss val: 0.03741
[2022-12-06 13:54:24,668] [INFO] [controller] EPOCH 2 loss ppo:  -0.02667, loss val: 0.03749
[2022-12-06 13:54:24,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.03034, loss val: 0.03767
[2022-12-06 13:54:24,787] [INFO] [controller] EPOCH 4 loss ppo:  -0.03224, loss val: 0.03750
[2022-12-06 13:54:24,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:54:25,004] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:54:25,004] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:54:31,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:54:37,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:54:44,307] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:54:50,797] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:54:57,544] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:55:04,003] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:55:10,589] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:55:17,391] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:55:23,844] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:55:29,693] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7123234496463567
[2022-12-06 13:55:29,693] [INFO] [runner_train_mujoco] Average state value: 0.6872050467530887
[2022-12-06 13:55:29,693] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 13:55:29,758] [INFO] [controller] EPOCH 1 loss ppo:  -0.00779, loss val: 0.04260
[2022-12-06 13:55:29,812] [INFO] [controller] EPOCH 2 loss ppo:  -0.01942, loss val: 0.04304
[2022-12-06 13:55:29,881] [INFO] [controller] EPOCH 3 loss ppo:  -0.02537, loss val: 0.04258
[2022-12-06 13:55:29,936] [INFO] [controller] EPOCH 4 loss ppo:  -0.02963, loss val: 0.04257
[2022-12-06 13:55:29,947] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:55:30,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:55:30,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:55:36,486] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:55:42,784] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:55:49,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:55:55,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:56:01,191] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:56:06,900] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:56:13,258] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:56:19,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:56:26,350] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:56:32,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8472164056261459
[2022-12-06 13:56:32,836] [INFO] [runner_train_mujoco] Average state value: 0.6860013590455055
[2022-12-06 13:56:32,836] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 13:56:32,906] [INFO] [controller] EPOCH 1 loss ppo:  -0.00895, loss val: 0.04090
[2022-12-06 13:56:32,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.01879, loss val: 0.04210
[2022-12-06 13:56:33,016] [INFO] [controller] EPOCH 3 loss ppo:  -0.02472, loss val: 0.04161
[2022-12-06 13:56:33,087] [INFO] [controller] EPOCH 4 loss ppo:  -0.02984, loss val: 0.04104
[2022-12-06 13:56:33,098] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:56:33,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:56:33,293] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:56:39,900] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:56:46,270] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:56:52,272] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:56:58,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:57:04,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:57:10,103] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:57:16,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:57:22,036] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:57:27,928] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:57:34,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8647619680333645
[2022-12-06 13:57:34,116] [INFO] [runner_train_mujoco] Average state value: 0.7032845272620519
[2022-12-06 13:57:34,116] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 13:57:34,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01018, loss val: 0.04100
[2022-12-06 13:57:34,245] [INFO] [controller] EPOCH 2 loss ppo:  -0.02005, loss val: 0.04084
[2022-12-06 13:57:34,317] [INFO] [controller] EPOCH 3 loss ppo:  -0.02305, loss val: 0.04042
[2022-12-06 13:57:34,378] [INFO] [controller] EPOCH 4 loss ppo:  -0.02698, loss val: 0.03956
[2022-12-06 13:57:34,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:57:34,579] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:57:34,579] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:57:40,835] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:57:46,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:57:53,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:57:59,517] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:58:07,326] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:58:16,162] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:58:24,936] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:58:32,226] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:58:39,125] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:58:47,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.819328853203149
[2022-12-06 13:58:47,835] [INFO] [runner_train_mujoco] Average state value: 0.6822893076539039
[2022-12-06 13:58:47,835] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 13:58:48,036] [INFO] [controller] EPOCH 1 loss ppo:  -0.00926, loss val: 0.04014
[2022-12-06 13:58:48,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.02083, loss val: 0.04016
[2022-12-06 13:58:48,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.02706, loss val: 0.04100
[2022-12-06 13:58:48,330] [INFO] [controller] EPOCH 4 loss ppo:  -0.03011, loss val: 0.04286
[2022-12-06 13:58:48,343] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:58:48,586] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:58:48,586] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:58:57,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:59:07,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:59:15,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:59:24,037] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:59:32,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:59:41,217] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:59:49,871] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:59:57,212] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:00:04,413] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:00:11,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0117515319169148
[2022-12-06 14:00:11,521] [INFO] [runner_train_mujoco] Average state value: 0.6591973107457162
[2022-12-06 14:00:11,522] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 14:00:11,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.00977, loss val: 0.03914
[2022-12-06 14:00:11,735] [INFO] [controller] EPOCH 2 loss ppo:  -0.02022, loss val: 0.03774
[2022-12-06 14:00:11,833] [INFO] [controller] EPOCH 3 loss ppo:  -0.02677, loss val: 0.03723
[2022-12-06 14:00:11,983] [INFO] [controller] EPOCH 4 loss ppo:  -0.02752, loss val: 0.03727
[2022-12-06 14:00:11,995] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:00:12,208] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:00:12,208] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:00:19,873] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:00:27,176] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:00:34,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:00:43,579] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:00:53,960] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:01:04,683] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:01:14,893] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:01:24,863] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:01:34,857] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:01:46,948] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0417042669255687
[2022-12-06 14:01:46,949] [INFO] [runner_train_mujoco] Average state value: 0.6517634878754616
[2022-12-06 14:01:46,950] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 14:01:47,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01078, loss val: 0.03906
[2022-12-06 14:01:47,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.01914, loss val: 0.03872
[2022-12-06 14:01:47,763] [INFO] [controller] EPOCH 3 loss ppo:  -0.02623, loss val: 0.03872
[2022-12-06 14:01:47,955] [INFO] [controller] EPOCH 4 loss ppo:  -0.02889, loss val: 0.03884
[2022-12-06 14:01:47,969] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:01:48,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:01:48,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:01:58,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:02:05,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:02:13,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:02:20,762] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:02:28,863] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:02:37,284] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:02:44,726] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:02:51,980] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:02:59,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:03:06,854] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2875075319779783
[2022-12-06 14:03:06,854] [INFO] [runner_train_mujoco] Average state value: 0.6606242132385571
[2022-12-06 14:03:06,855] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 14:03:06,966] [INFO] [controller] EPOCH 1 loss ppo:  -0.01048, loss val: 0.04213
[2022-12-06 14:03:07,046] [INFO] [controller] EPOCH 2 loss ppo:  -0.02417, loss val: 0.04157
[2022-12-06 14:03:07,228] [INFO] [controller] EPOCH 3 loss ppo:  -0.02766, loss val: 0.04159
[2022-12-06 14:03:07,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.03384, loss val: 0.04202
[2022-12-06 14:03:07,354] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:03:07,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:03:07,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:03:15,529] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:03:24,039] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:03:31,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:03:38,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:03:45,171] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:03:52,155] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:03:58,839] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:04:05,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:04:12,488] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:04:19,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3908911317398664
[2022-12-06 14:04:19,340] [INFO] [runner_train_mujoco] Average state value: 0.6806201330423355
[2022-12-06 14:04:19,340] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 14:04:19,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.03938
[2022-12-06 14:04:19,494] [INFO] [controller] EPOCH 2 loss ppo:  -0.01997, loss val: 0.04011
[2022-12-06 14:04:19,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.02446, loss val: 0.03979
[2022-12-06 14:04:19,626] [INFO] [controller] EPOCH 4 loss ppo:  -0.03008, loss val: 0.03983
[2022-12-06 14:04:19,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:04:19,878] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:04:19,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:04:26,617] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:04:33,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:04:39,680] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:04:45,933] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:04:52,167] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:04:58,397] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:05:04,575] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:05:11,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:05:17,481] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:05:23,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4049224824657243
[2022-12-06 14:05:23,515] [INFO] [runner_train_mujoco] Average state value: 0.6927620137731234
[2022-12-06 14:05:23,515] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 14:05:23,591] [INFO] [controller] EPOCH 1 loss ppo:  -0.01153, loss val: 0.04358
[2022-12-06 14:05:23,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.01919, loss val: 0.04302
[2022-12-06 14:05:23,749] [INFO] [controller] EPOCH 3 loss ppo:  -0.02408, loss val: 0.04270
[2022-12-06 14:05:23,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.03115, loss val: 0.04209
[2022-12-06 14:05:23,877] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:05:24,139] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:05:24,140] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:05:31,444] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:05:38,459] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:05:45,354] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:05:51,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:05:57,590] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:06:03,636] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:06:09,458] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:06:16,228] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:06:24,345] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:06:33,892] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4785418582254723
[2022-12-06 14:06:33,892] [INFO] [runner_train_mujoco] Average state value: 0.6617238378723462
[2022-12-06 14:06:33,893] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 14:06:34,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.04183
[2022-12-06 14:06:34,100] [INFO] [controller] EPOCH 2 loss ppo:  -0.02205, loss val: 0.04430
[2022-12-06 14:06:34,176] [INFO] [controller] EPOCH 3 loss ppo:  -0.02471, loss val: 0.04238
[2022-12-06 14:06:34,247] [INFO] [controller] EPOCH 4 loss ppo:  -0.02812, loss val: 0.04193
[2022-12-06 14:06:34,262] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:06:34,528] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:06:34,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:06:43,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:06:51,205] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:07:00,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:07:10,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:07:18,287] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:07:25,496] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:07:35,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:07:44,557] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:07:51,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:07:58,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5200645139782507
[2022-12-06 14:07:58,515] [INFO] [runner_train_mujoco] Average state value: 0.6644215694069862
[2022-12-06 14:07:58,515] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 14:07:58,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01149, loss val: 0.04209
[2022-12-06 14:07:58,640] [INFO] [controller] EPOCH 2 loss ppo:  -0.02048, loss val: 0.04189
[2022-12-06 14:07:58,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.02742, loss val: 0.04185
[2022-12-06 14:07:58,760] [INFO] [controller] EPOCH 4 loss ppo:  -0.03414, loss val: 0.04139
[2022-12-06 14:07:58,771] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:07:58,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:07:58,972] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:08:05,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:08:12,035] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:08:18,767] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:08:25,352] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:08:32,147] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:08:38,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:08:45,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:08:52,556] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:08:58,606] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:09:04,863] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.752407234181905
[2022-12-06 14:09:04,863] [INFO] [runner_train_mujoco] Average state value: 0.6478418684403102
[2022-12-06 14:09:04,864] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 14:09:04,952] [INFO] [controller] EPOCH 1 loss ppo:  -0.01555, loss val: 0.03773
[2022-12-06 14:09:05,066] [INFO] [controller] EPOCH 2 loss ppo:  -0.02387, loss val: 0.03798
[2022-12-06 14:09:05,247] [INFO] [controller] EPOCH 3 loss ppo:  -0.02711, loss val: 0.03701
[2022-12-06 14:09:05,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.03153, loss val: 0.03758
[2022-12-06 14:09:05,371] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:09:05,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:09:05,584] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:09:12,338] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:09:19,436] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:09:25,887] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:09:32,601] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:09:38,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:09:45,632] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:09:52,315] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:09:59,208] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:10:06,057] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:10:12,699] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8244808651673121
[2022-12-06 14:10:12,699] [INFO] [runner_train_mujoco] Average state value: 0.6491416975657145
[2022-12-06 14:10:12,700] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 14:10:12,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.03721
[2022-12-06 14:10:12,845] [INFO] [controller] EPOCH 2 loss ppo:  -0.02414, loss val: 0.03691
[2022-12-06 14:10:12,918] [INFO] [controller] EPOCH 3 loss ppo:  -0.02684, loss val: 0.03747
[2022-12-06 14:10:12,979] [INFO] [controller] EPOCH 4 loss ppo:  -0.03021, loss val: 0.03643
[2022-12-06 14:10:12,991] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:10:13,201] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:10:13,202] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:10:19,998] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:10:27,056] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:10:33,805] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:10:40,446] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:10:47,257] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:10:54,201] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:11:01,324] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:11:07,952] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:11:14,778] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:11:21,638] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8260593812629082
[2022-12-06 14:11:21,638] [INFO] [runner_train_mujoco] Average state value: 0.6471281973520915
[2022-12-06 14:11:21,638] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 14:11:21,713] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.05029
[2022-12-06 14:11:21,778] [INFO] [controller] EPOCH 2 loss ppo:  -0.02216, loss val: 0.04966
[2022-12-06 14:11:21,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.02526, loss val: 0.04957
[2022-12-06 14:11:21,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.03186, loss val: 0.04864
[2022-12-06 14:11:21,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:11:22,161] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:11:22,162] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:11:29,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:11:36,363] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:11:42,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:11:49,050] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:11:55,144] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:12:01,625] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:12:08,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:12:14,422] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:12:20,537] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:12:26,935] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9069826053959205
[2022-12-06 14:12:26,936] [INFO] [runner_train_mujoco] Average state value: 0.6660263979434967
[2022-12-06 14:12:26,936] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 14:12:27,007] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.05004
[2022-12-06 14:12:27,057] [INFO] [controller] EPOCH 2 loss ppo:  -0.02071, loss val: 0.04852
[2022-12-06 14:12:27,117] [INFO] [controller] EPOCH 3 loss ppo:  -0.02842, loss val: 0.04848
[2022-12-06 14:12:27,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.03003, loss val: 0.04859
[2022-12-06 14:12:27,183] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:12:27,379] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:12:27,379] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:12:33,268] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:12:39,700] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:12:45,645] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:12:52,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:12:59,041] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:13:05,007] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:13:10,864] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:13:17,193] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:13:23,114] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:13:28,898] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0441192901060634
[2022-12-06 14:13:28,898] [INFO] [runner_train_mujoco] Average state value: 0.6930263444781304
[2022-12-06 14:13:28,898] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 14:13:28,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04383
[2022-12-06 14:13:29,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.02142, loss val: 0.04361
[2022-12-06 14:13:29,066] [INFO] [controller] EPOCH 3 loss ppo:  -0.02500, loss val: 0.04295
[2022-12-06 14:13:29,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.03076, loss val: 0.04199
[2022-12-06 14:13:29,126] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:13:29,327] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:13:29,328] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:13:35,169] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:13:41,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:13:47,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:13:53,489] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:13:59,162] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:14:05,546] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:14:11,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:14:19,154] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:14:25,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:14:32,476] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0174518842929254
[2022-12-06 14:14:32,477] [INFO] [runner_train_mujoco] Average state value: 0.6721385747790337
[2022-12-06 14:14:32,477] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 14:14:32,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.04092
[2022-12-06 14:14:32,670] [INFO] [controller] EPOCH 2 loss ppo:  -0.02057, loss val: 0.03988
[2022-12-06 14:14:32,735] [INFO] [controller] EPOCH 3 loss ppo:  -0.02868, loss val: 0.03891
[2022-12-06 14:14:32,814] [INFO] [controller] EPOCH 4 loss ppo:  -0.02961, loss val: 0.03981
[2022-12-06 14:14:32,825] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:14:33,026] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:14:33,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:14:39,582] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:14:45,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:14:51,661] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:14:58,138] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:15:04,310] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:15:10,487] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:15:17,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:15:25,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:15:31,768] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:15:39,184] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.205680652788858
[2022-12-06 14:15:39,184] [INFO] [runner_train_mujoco] Average state value: 0.6242290905912717
[2022-12-06 14:15:39,185] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 14:15:39,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.04642
[2022-12-06 14:15:39,329] [INFO] [controller] EPOCH 2 loss ppo:  -0.02143, loss val: 0.04394
[2022-12-06 14:15:39,389] [INFO] [controller] EPOCH 3 loss ppo:  -0.02699, loss val: 0.04535
[2022-12-06 14:15:39,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.03022, loss val: 0.04360
[2022-12-06 14:15:39,463] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:15:39,696] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:15:39,696] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:15:46,704] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:15:53,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:16:01,016] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:16:08,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:16:17,502] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:16:26,486] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:16:34,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:16:42,709] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:16:52,749] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:17:01,247] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2279342387598473
[2022-12-06 14:17:01,247] [INFO] [runner_train_mujoco] Average state value: 0.6315811274250349
[2022-12-06 14:17:01,247] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 14:17:01,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04912
[2022-12-06 14:17:01,547] [INFO] [controller] EPOCH 2 loss ppo:  -0.02341, loss val: 0.04780
[2022-12-06 14:17:01,607] [INFO] [controller] EPOCH 3 loss ppo:  -0.02454, loss val: 0.04728
[2022-12-06 14:17:01,678] [INFO] [controller] EPOCH 4 loss ppo:  -0.02697, loss val: 0.04595
[2022-12-06 14:17:01,690] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:17:01,925] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:17:01,926] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:17:09,021] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:17:16,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:17:23,612] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:17:30,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:17:36,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:17:44,302] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:17:52,400] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:17:59,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:18:07,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:18:14,154] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.254761236097065
[2022-12-06 14:18:14,155] [INFO] [runner_train_mujoco] Average state value: 0.6702229427496592
[2022-12-06 14:18:14,155] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 14:18:14,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01102, loss val: 0.04135
[2022-12-06 14:18:14,378] [INFO] [controller] EPOCH 2 loss ppo:  -0.01500, loss val: 0.04170
[2022-12-06 14:18:14,520] [INFO] [controller] EPOCH 3 loss ppo:  -0.02287, loss val: 0.04294
[2022-12-06 14:18:14,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.02829, loss val: 0.04153
[2022-12-06 14:18:14,652] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:18:14,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:18:14,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:18:22,880] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:18:30,332] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:18:37,705] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:18:45,705] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:18:53,245] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:19:00,729] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:19:07,990] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:19:15,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:19:22,821] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:19:29,764] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3133509994161523
[2022-12-06 14:19:29,764] [INFO] [runner_train_mujoco] Average state value: 0.6716344407796859
[2022-12-06 14:19:29,764] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 14:19:29,852] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04176
[2022-12-06 14:19:29,911] [INFO] [controller] EPOCH 2 loss ppo:  -0.02099, loss val: 0.04159
[2022-12-06 14:19:29,966] [INFO] [controller] EPOCH 3 loss ppo:  -0.02611, loss val: 0.04021
[2022-12-06 14:19:30,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.02819, loss val: 0.04011
[2022-12-06 14:19:30,037] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:19:30,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:19:30,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:19:37,303] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:19:44,684] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:19:51,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:19:58,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:20:04,992] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:20:12,208] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:20:19,881] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:20:27,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:20:33,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:20:40,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.361062515808137
[2022-12-06 14:20:40,894] [INFO] [runner_train_mujoco] Average state value: 0.6547432561715444
[2022-12-06 14:20:40,894] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 14:20:41,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04799
[2022-12-06 14:20:41,409] [INFO] [controller] EPOCH 2 loss ppo:  -0.02021, loss val: 0.04923
[2022-12-06 14:20:41,467] [INFO] [controller] EPOCH 3 loss ppo:  -0.02222, loss val: 0.04902
[2022-12-06 14:20:41,523] [INFO] [controller] EPOCH 4 loss ppo:  -0.02456, loss val: 0.04775
[2022-12-06 14:20:41,536] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:20:41,745] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:20:41,745] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:20:48,413] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:20:54,941] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:21:01,526] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:21:10,000] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:21:17,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:21:26,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:21:33,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:21:41,645] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:21:50,780] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:21:57,555] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.438763706232608
[2022-12-06 14:21:57,555] [INFO] [runner_train_mujoco] Average state value: 0.6614081720908482
[2022-12-06 14:21:57,555] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 14:21:57,637] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.04539
[2022-12-06 14:21:57,793] [INFO] [controller] EPOCH 2 loss ppo:  -0.01946, loss val: 0.04565
[2022-12-06 14:21:57,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.02185, loss val: 0.04565
[2022-12-06 14:21:57,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.02461, loss val: 0.04544
[2022-12-06 14:21:57,940] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:21:58,168] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:21:58,169] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:22:04,863] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:22:11,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:22:17,007] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:22:23,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:22:29,714] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:22:35,974] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:22:42,653] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:22:49,165] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:22:55,847] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:23:02,197] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.51134795506644
[2022-12-06 14:23:02,197] [INFO] [runner_train_mujoco] Average state value: 0.6745803448756537
[2022-12-06 14:23:02,197] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 14:23:02,266] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04630
[2022-12-06 14:23:02,319] [INFO] [controller] EPOCH 2 loss ppo:  -0.01903, loss val: 0.04557
[2022-12-06 14:23:02,387] [INFO] [controller] EPOCH 3 loss ppo:  -0.02419, loss val: 0.04628
[2022-12-06 14:23:02,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.02526, loss val: 0.04605
[2022-12-06 14:23:02,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:23:02,675] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:23:02,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:23:09,686] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:23:16,739] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:23:23,784] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:23:30,536] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:23:37,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:23:43,696] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:23:49,997] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:23:56,410] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:24:02,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:24:09,399] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.491469343891272
[2022-12-06 14:24:09,400] [INFO] [runner_train_mujoco] Average state value: 0.6847412757078807
[2022-12-06 14:24:09,400] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 14:24:09,466] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04490
[2022-12-06 14:24:09,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.02108, loss val: 0.04423
[2022-12-06 14:24:09,590] [INFO] [controller] EPOCH 3 loss ppo:  -0.02377, loss val: 0.04473
[2022-12-06 14:24:09,645] [INFO] [controller] EPOCH 4 loss ppo:  -0.02645, loss val: 0.04443
[2022-12-06 14:24:09,656] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:24:09,862] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:24:09,862] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:24:16,686] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:24:24,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:24:31,371] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:24:38,706] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:24:45,019] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:24:51,216] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:24:57,873] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:25:06,090] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:25:12,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:25:21,037] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.511122267894854
[2022-12-06 14:25:21,037] [INFO] [runner_train_mujoco] Average state value: 0.6758042261203131
[2022-12-06 14:25:21,038] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 14:25:21,106] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.04271
[2022-12-06 14:25:21,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.01769, loss val: 0.04346
[2022-12-06 14:25:21,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.02054, loss val: 0.04254
[2022-12-06 14:25:21,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.02455, loss val: 0.04428
[2022-12-06 14:25:21,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:25:21,524] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:25:21,525] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:25:28,708] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:25:37,799] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:25:45,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:25:53,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:26:01,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:26:09,043] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:26:17,755] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:26:25,671] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:26:36,076] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:26:44,752] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.714238251390452
[2022-12-06 14:26:44,752] [INFO] [runner_train_mujoco] Average state value: 0.6676979844172797
[2022-12-06 14:26:44,753] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 14:26:45,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01350, loss val: 0.04624
[2022-12-06 14:26:45,331] [INFO] [controller] EPOCH 2 loss ppo:  -0.01728, loss val: 0.04666
[2022-12-06 14:26:45,521] [INFO] [controller] EPOCH 3 loss ppo:  -0.02053, loss val: 0.04627
[2022-12-06 14:26:45,595] [INFO] [controller] EPOCH 4 loss ppo:  -0.02472, loss val: 0.04669
[2022-12-06 14:26:45,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:26:45,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:26:45,843] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:26:53,305] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:27:00,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:27:07,967] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:27:14,993] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:27:22,611] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:27:30,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:27:38,668] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:27:46,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:27:54,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:28:03,235] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6199314967178404
[2022-12-06 14:28:03,235] [INFO] [runner_train_mujoco] Average state value: 0.6725261458555857
[2022-12-06 14:28:03,235] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 14:28:03,381] [INFO] [controller] EPOCH 1 loss ppo:  -0.01147, loss val: 0.04622
[2022-12-06 14:28:03,871] [INFO] [controller] EPOCH 2 loss ppo:  -0.01250, loss val: 0.04710
[2022-12-06 14:28:04,075] [INFO] [controller] EPOCH 3 loss ppo:  -0.01665, loss val: 0.04736
[2022-12-06 14:28:04,158] [INFO] [controller] EPOCH 4 loss ppo:  -0.02164, loss val: 0.04617
[2022-12-06 14:28:04,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:28:04,414] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:28:04,414] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:28:14,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:28:24,277] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:28:33,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:28:41,758] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:28:50,349] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:28:58,534] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:29:07,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:29:14,983] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:29:23,009] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:29:31,961] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5813047684124726
[2022-12-06 14:29:31,962] [INFO] [runner_train_mujoco] Average state value: 0.677912882645925
[2022-12-06 14:29:31,962] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 14:29:32,071] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04457
[2022-12-06 14:29:32,140] [INFO] [controller] EPOCH 2 loss ppo:  -0.01542, loss val: 0.04507
[2022-12-06 14:29:32,230] [INFO] [controller] EPOCH 3 loss ppo:  -0.01904, loss val: 0.04452
[2022-12-06 14:29:32,295] [INFO] [controller] EPOCH 4 loss ppo:  -0.02270, loss val: 0.04564
[2022-12-06 14:29:32,309] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:29:32,570] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:29:32,570] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:29:41,262] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:29:51,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:29:59,373] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:30:08,622] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:30:17,195] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:30:26,880] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:30:35,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:30:46,111] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:30:54,687] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:31:04,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6785273955427327
[2022-12-06 14:31:04,202] [INFO] [runner_train_mujoco] Average state value: 0.6699878995021183
[2022-12-06 14:31:04,202] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 14:31:04,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04337
[2022-12-06 14:31:04,449] [INFO] [controller] EPOCH 2 loss ppo:  -0.01553, loss val: 0.04356
[2022-12-06 14:31:04,651] [INFO] [controller] EPOCH 3 loss ppo:  -0.01875, loss val: 0.04415
[2022-12-06 14:31:04,723] [INFO] [controller] EPOCH 4 loss ppo:  -0.02117, loss val: 0.04329
[2022-12-06 14:31:04,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:31:05,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:31:05,013] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:31:13,214] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:31:21,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:31:30,079] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:31:39,110] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:31:48,684] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:31:56,921] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:32:05,047] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:32:13,329] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:32:21,368] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:32:28,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.608012690010144
[2022-12-06 14:32:28,974] [INFO] [runner_train_mujoco] Average state value: 0.6667568581899007
[2022-12-06 14:32:28,974] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 14:32:29,068] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04326
[2022-12-06 14:32:29,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.01580, loss val: 0.04304
[2022-12-06 14:32:29,366] [INFO] [controller] EPOCH 3 loss ppo:  -0.02038, loss val: 0.04300
[2022-12-06 14:32:29,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.02336, loss val: 0.04327
[2022-12-06 14:32:29,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:32:29,685] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:32:29,685] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:32:37,295] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:32:44,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:32:52,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:33:00,433] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:33:07,552] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:33:14,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:33:21,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:33:29,019] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:33:36,463] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:33:43,690] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.724323485718611
[2022-12-06 14:33:43,690] [INFO] [runner_train_mujoco] Average state value: 0.6652869399388631
[2022-12-06 14:33:43,690] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 14:33:43,772] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04201
[2022-12-06 14:33:43,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.01539, loss val: 0.04190
[2022-12-06 14:33:43,925] [INFO] [controller] EPOCH 3 loss ppo:  -0.01962, loss val: 0.04187
[2022-12-06 14:33:43,988] [INFO] [controller] EPOCH 4 loss ppo:  -0.02229, loss val: 0.04203
[2022-12-06 14:33:44,001] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:33:44,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:33:44,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:33:51,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:33:58,546] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:34:05,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:34:13,061] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:34:20,182] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:34:27,593] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:34:34,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:34:42,517] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:34:50,608] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:34:58,533] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7018443747197454
[2022-12-06 14:34:58,533] [INFO] [runner_train_mujoco] Average state value: 0.6637447674671809
[2022-12-06 14:34:58,533] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 14:34:58,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.04308
[2022-12-06 14:34:58,846] [INFO] [controller] EPOCH 2 loss ppo:  -0.01301, loss val: 0.04246
[2022-12-06 14:34:58,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.01489, loss val: 0.04243
[2022-12-06 14:34:59,076] [INFO] [controller] EPOCH 4 loss ppo:  -0.01746, loss val: 0.04194
[2022-12-06 14:34:59,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:34:59,351] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:34:59,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:35:07,334] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:35:14,963] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:35:22,685] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:35:30,471] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:35:37,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:35:44,770] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:35:51,578] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:35:58,221] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:36:04,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:36:10,804] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.69670652830572
[2022-12-06 14:36:10,804] [INFO] [runner_train_mujoco] Average state value: 0.6637320054968199
[2022-12-06 14:36:10,805] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 14:36:10,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.04400
[2022-12-06 14:36:10,923] [INFO] [controller] EPOCH 2 loss ppo:  -0.01315, loss val: 0.04396
[2022-12-06 14:36:10,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.01433, loss val: 0.04397
[2022-12-06 14:36:11,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.01594, loss val: 0.04394
[2022-12-06 14:36:11,054] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:36:11,222] [INFO] [optimize] Finished learning.
