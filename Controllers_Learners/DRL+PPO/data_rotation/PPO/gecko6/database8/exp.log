[2022-12-07 06:45:07,749] [INFO] [optimize] Starting learning
[2022-12-07 06:45:07,758] [INFO] [optimize] Starting learning process..
[2022-12-07 06:45:07,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:45:07,875] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:45:13,728] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:45:18,589] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:45:23,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:45:27,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:45:32,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:45:36,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:45:41,706] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:45:46,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:45:51,550] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:45:56,661] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22897580470156562
[2022-12-07 06:45:56,661] [INFO] [runner_train_mujoco] Average state value: 0.06448846074442069
[2022-12-07 06:45:56,661] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 06:45:56,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01055, loss val: 0.25666
[2022-12-07 06:45:56,790] [INFO] [controller] EPOCH 2 loss ppo:  -0.02820, loss val: 0.21452
[2022-12-07 06:45:56,835] [INFO] [controller] EPOCH 3 loss ppo:  -0.03451, loss val: 0.18815
[2022-12-07 06:45:56,883] [INFO] [controller] EPOCH 4 loss ppo:  -0.03802, loss val: 0.16268
[2022-12-07 06:45:56,895] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:45:57,048] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:45:57,048] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:46:01,874] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:46:06,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:46:10,908] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:46:15,588] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:46:20,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:46:25,294] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:46:30,128] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:46:34,494] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:46:39,489] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:46:44,106] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21214004128232394
[2022-12-07 06:46:44,106] [INFO] [runner_train_mujoco] Average state value: 0.23855950683914123
[2022-12-07 06:46:44,106] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 06:46:44,161] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.14999
[2022-12-07 06:46:44,203] [INFO] [controller] EPOCH 2 loss ppo:  -0.02960, loss val: 0.13752
[2022-12-07 06:46:44,249] [INFO] [controller] EPOCH 3 loss ppo:  -0.03507, loss val: 0.11507
[2022-12-07 06:46:44,297] [INFO] [controller] EPOCH 4 loss ppo:  -0.03676, loss val: 0.09993
[2022-12-07 06:46:44,307] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:46:44,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:46:44,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:46:49,288] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:46:54,134] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:46:59,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:47:05,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:47:11,346] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:47:16,832] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:47:22,246] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:47:27,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:47:33,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:47:39,300] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20466560772502565
[2022-12-07 06:47:39,300] [INFO] [runner_train_mujoco] Average state value: 0.37449076742678883
[2022-12-07 06:47:39,300] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 06:47:39,363] [INFO] [controller] EPOCH 1 loss ppo:  -0.01192, loss val: 0.15331
[2022-12-07 06:47:39,407] [INFO] [controller] EPOCH 2 loss ppo:  -0.02040, loss val: 0.12779
[2022-12-07 06:47:39,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.03330, loss val: 0.10960
[2022-12-07 06:47:39,508] [INFO] [controller] EPOCH 4 loss ppo:  -0.03652, loss val: 0.09581
[2022-12-07 06:47:39,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:47:39,699] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:47:39,699] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:47:45,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:47:50,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:47:55,303] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:48:00,621] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:48:05,788] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:48:10,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:48:16,403] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:48:21,904] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:48:26,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:48:32,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18110423337289935
[2022-12-07 06:48:32,324] [INFO] [runner_train_mujoco] Average state value: 0.5530211370786031
[2022-12-07 06:48:32,324] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 06:48:32,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01147, loss val: 0.08781
[2022-12-07 06:48:32,448] [INFO] [controller] EPOCH 2 loss ppo:  -0.02528, loss val: 0.07513
[2022-12-07 06:48:32,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.03071, loss val: 0.06820
[2022-12-07 06:48:32,572] [INFO] [controller] EPOCH 4 loss ppo:  -0.03435, loss val: 0.06425
[2022-12-07 06:48:32,582] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:48:32,753] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:48:32,754] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:48:38,010] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:48:43,349] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:48:48,842] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:48:53,674] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:48:59,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:49:04,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:49:09,628] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:49:14,833] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:49:20,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:49:25,455] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2397215316640881
[2022-12-07 06:49:25,456] [INFO] [runner_train_mujoco] Average state value: 0.6925626560548941
[2022-12-07 06:49:25,456] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 06:49:25,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.00768, loss val: 0.05860
[2022-12-07 06:49:25,578] [INFO] [controller] EPOCH 2 loss ppo:  -0.01674, loss val: 0.05631
[2022-12-07 06:49:25,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.02254, loss val: 0.05284
[2022-12-07 06:49:25,670] [INFO] [controller] EPOCH 4 loss ppo:  -0.02634, loss val: 0.05045
[2022-12-07 06:49:25,680] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:49:25,847] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:49:25,847] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:49:31,247] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:49:36,941] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:49:41,991] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:49:47,619] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:49:53,627] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:49:58,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:50:04,100] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:50:09,262] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:50:14,458] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:50:19,503] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23397415838452615
[2022-12-07 06:50:19,503] [INFO] [runner_train_mujoco] Average state value: 0.7363228776454925
[2022-12-07 06:50:19,504] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 06:50:19,562] [INFO] [controller] EPOCH 1 loss ppo:  -0.00886, loss val: 0.04940
[2022-12-07 06:50:19,611] [INFO] [controller] EPOCH 2 loss ppo:  -0.01832, loss val: 0.04743
[2022-12-07 06:50:19,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.01983, loss val: 0.04560
[2022-12-07 06:50:19,722] [INFO] [controller] EPOCH 4 loss ppo:  -0.02777, loss val: 0.04497
[2022-12-07 06:50:19,732] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:50:19,900] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:50:19,900] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:50:24,986] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:50:30,270] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:50:35,494] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:50:40,752] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:50:46,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:50:51,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:50:56,602] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:51:01,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:51:07,003] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:51:12,299] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23093229167648738
[2022-12-07 06:51:12,300] [INFO] [runner_train_mujoco] Average state value: 0.7255143419305484
[2022-12-07 06:51:12,300] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 06:51:12,372] [INFO] [controller] EPOCH 1 loss ppo:  -0.00794, loss val: 0.04753
[2022-12-07 06:51:12,418] [INFO] [controller] EPOCH 2 loss ppo:  -0.02055, loss val: 0.04649
[2022-12-07 06:51:12,474] [INFO] [controller] EPOCH 3 loss ppo:  -0.02710, loss val: 0.04608
[2022-12-07 06:51:12,521] [INFO] [controller] EPOCH 4 loss ppo:  -0.02906, loss val: 0.04473
[2022-12-07 06:51:12,530] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:51:12,695] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:51:12,696] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:51:17,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:51:22,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:51:27,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:51:33,163] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:51:38,327] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:51:43,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:51:48,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:51:54,642] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:52:00,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:52:06,137] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2277906739646272
[2022-12-07 06:52:06,138] [INFO] [runner_train_mujoco] Average state value: 0.7293141130010288
[2022-12-07 06:52:06,138] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 06:52:06,205] [INFO] [controller] EPOCH 1 loss ppo:  -0.00709, loss val: 0.04250
[2022-12-07 06:52:06,252] [INFO] [controller] EPOCH 2 loss ppo:  -0.01921, loss val: 0.04215
[2022-12-07 06:52:06,301] [INFO] [controller] EPOCH 3 loss ppo:  -0.02218, loss val: 0.04179
[2022-12-07 06:52:06,359] [INFO] [controller] EPOCH 4 loss ppo:  -0.02548, loss val: 0.04180
[2022-12-07 06:52:06,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:52:06,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:52:06,587] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:52:12,432] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:52:18,095] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:52:23,568] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:52:29,238] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:52:34,738] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:52:39,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:52:44,696] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:52:50,037] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:52:55,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:53:00,438] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21320093187585254
[2022-12-07 06:53:00,439] [INFO] [runner_train_mujoco] Average state value: 0.7423147184054056
[2022-12-07 06:53:00,439] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 06:53:00,512] [INFO] [controller] EPOCH 1 loss ppo:  -0.00781, loss val: 0.04446
[2022-12-07 06:53:00,565] [INFO] [controller] EPOCH 2 loss ppo:  -0.02014, loss val: 0.04295
[2022-12-07 06:53:00,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.02154, loss val: 0.04093
[2022-12-07 06:53:00,679] [INFO] [controller] EPOCH 4 loss ppo:  -0.02511, loss val: 0.04044
[2022-12-07 06:53:00,689] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:53:00,858] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:53:00,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:53:06,402] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:53:11,894] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:53:17,127] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:53:22,444] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:53:27,287] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:53:32,238] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:53:37,457] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:53:42,917] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:53:48,117] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:53:53,311] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24308741330573466
[2022-12-07 06:53:53,312] [INFO] [runner_train_mujoco] Average state value: 0.680759656171004
[2022-12-07 06:53:53,312] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 06:53:53,379] [INFO] [controller] EPOCH 1 loss ppo:  -0.00731, loss val: 0.03649
[2022-12-07 06:53:53,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.01525, loss val: 0.03657
[2022-12-07 06:53:53,479] [INFO] [controller] EPOCH 3 loss ppo:  -0.02173, loss val: 0.03681
[2022-12-07 06:53:53,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.02764, loss val: 0.03720
[2022-12-07 06:53:53,544] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:53:53,709] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:53:53,709] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:53:58,669] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:54:03,741] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:54:09,532] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:54:14,736] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:54:19,703] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:54:24,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:54:30,159] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:54:35,222] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:54:40,489] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:54:45,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2090772175901101
[2022-12-07 06:54:45,543] [INFO] [runner_train_mujoco] Average state value: 0.6395540812214215
[2022-12-07 06:54:45,543] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 06:54:45,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.00868, loss val: 0.03831
[2022-12-07 06:54:45,653] [INFO] [controller] EPOCH 2 loss ppo:  -0.01716, loss val: 0.03799
[2022-12-07 06:54:45,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.02208, loss val: 0.03787
[2022-12-07 06:54:45,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.02523, loss val: 0.03806
[2022-12-07 06:54:45,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:54:45,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:54:45,938] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:54:51,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:54:56,107] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:55:01,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:55:06,798] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:55:12,251] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:55:17,646] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:55:23,157] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:55:28,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:55:33,813] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:55:39,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23688386116144647
[2022-12-07 06:55:39,015] [INFO] [runner_train_mujoco] Average state value: 0.6487212374210357
[2022-12-07 06:55:39,015] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 06:55:39,100] [INFO] [controller] EPOCH 1 loss ppo:  -0.00706, loss val: 0.04294
[2022-12-07 06:55:39,157] [INFO] [controller] EPOCH 2 loss ppo:  -0.01430, loss val: 0.04094
[2022-12-07 06:55:39,207] [INFO] [controller] EPOCH 3 loss ppo:  -0.02314, loss val: 0.04186
[2022-12-07 06:55:39,261] [INFO] [controller] EPOCH 4 loss ppo:  -0.02748, loss val: 0.03924
[2022-12-07 06:55:39,272] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:55:39,442] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:55:39,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:55:44,684] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:55:50,210] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:55:55,192] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:56:00,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:56:05,322] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:56:10,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:56:16,107] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:56:21,484] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:56:26,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:56:31,644] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22284574826664535
[2022-12-07 06:56:31,645] [INFO] [runner_train_mujoco] Average state value: 0.6847349871794381
[2022-12-07 06:56:31,645] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 06:56:31,707] [INFO] [controller] EPOCH 1 loss ppo:  -0.00676, loss val: 0.03876
[2022-12-07 06:56:31,758] [INFO] [controller] EPOCH 2 loss ppo:  -0.01673, loss val: 0.03862
[2022-12-07 06:56:31,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.02276, loss val: 0.04088
[2022-12-07 06:56:31,864] [INFO] [controller] EPOCH 4 loss ppo:  -0.02716, loss val: 0.03864
[2022-12-07 06:56:31,874] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:56:32,039] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:56:32,039] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:56:37,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:56:42,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:56:49,067] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:56:54,994] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:57:00,464] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:57:05,671] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:57:11,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:57:16,027] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:57:21,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:57:26,366] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24393897531144298
[2022-12-07 06:57:26,366] [INFO] [runner_train_mujoco] Average state value: 0.7046586583654085
[2022-12-07 06:57:26,366] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 06:57:26,434] [INFO] [controller] EPOCH 1 loss ppo:  -0.00787, loss val: 0.04284
[2022-12-07 06:57:26,493] [INFO] [controller] EPOCH 2 loss ppo:  -0.01881, loss val: 0.04197
[2022-12-07 06:57:26,541] [INFO] [controller] EPOCH 3 loss ppo:  -0.02248, loss val: 0.04306
[2022-12-07 06:57:26,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.02643, loss val: 0.04252
[2022-12-07 06:57:26,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:57:26,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:57:26,779] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:57:32,132] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:57:37,427] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:57:42,843] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:57:48,081] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:57:53,353] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:57:58,402] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:58:03,624] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:58:08,635] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:58:13,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:58:18,757] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2751196032343531
[2022-12-07 06:58:18,758] [INFO] [runner_train_mujoco] Average state value: 0.721849862575531
[2022-12-07 06:58:18,758] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 06:58:18,815] [INFO] [controller] EPOCH 1 loss ppo:  -0.00945, loss val: 0.03989
[2022-12-07 06:58:18,873] [INFO] [controller] EPOCH 2 loss ppo:  -0.02279, loss val: 0.03854
[2022-12-07 06:58:18,952] [INFO] [controller] EPOCH 3 loss ppo:  -0.02553, loss val: 0.03736
[2022-12-07 06:58:19,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.02847, loss val: 0.03655
[2022-12-07 06:58:19,029] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:58:19,209] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:58:19,209] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:58:24,478] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:58:29,810] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:58:34,815] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:58:39,622] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:58:44,859] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:58:49,886] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:58:54,951] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:58:59,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:59:05,111] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:59:09,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3646251113612468
[2022-12-07 06:59:09,907] [INFO] [runner_train_mujoco] Average state value: 0.6762832449277243
[2022-12-07 06:59:09,907] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 06:59:09,975] [INFO] [controller] EPOCH 1 loss ppo:  -0.00820, loss val: 0.03481
[2022-12-07 06:59:10,027] [INFO] [controller] EPOCH 2 loss ppo:  -0.01479, loss val: 0.03401
[2022-12-07 06:59:10,076] [INFO] [controller] EPOCH 3 loss ppo:  -0.02182, loss val: 0.03428
[2022-12-07 06:59:10,130] [INFO] [controller] EPOCH 4 loss ppo:  -0.02621, loss val: 0.03537
[2022-12-07 06:59:10,140] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:59:10,316] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:59:10,317] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:59:15,408] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:59:20,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:59:26,083] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:59:31,396] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:59:36,526] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:59:41,532] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:59:46,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:59:52,113] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:59:57,447] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:00:02,667] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4199474401494928
[2022-12-07 07:00:02,667] [INFO] [runner_train_mujoco] Average state value: 0.64462023717165
[2022-12-07 07:00:02,667] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 07:00:02,742] [INFO] [controller] EPOCH 1 loss ppo:  -0.00840, loss val: 0.04491
[2022-12-07 07:00:02,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.02118, loss val: 0.04290
[2022-12-07 07:00:02,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.02740, loss val: 0.03982
[2022-12-07 07:00:02,913] [INFO] [controller] EPOCH 4 loss ppo:  -0.03023, loss val: 0.04009
[2022-12-07 07:00:02,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:00:03,090] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:00:03,091] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:00:08,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:00:13,200] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:00:18,216] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:00:23,060] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:00:28,123] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:00:33,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:00:38,293] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:00:43,106] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:00:48,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:00:53,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6341118914051236
[2022-12-07 07:00:53,421] [INFO] [runner_train_mujoco] Average state value: 0.7150906137228012
[2022-12-07 07:00:53,421] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 07:00:53,475] [INFO] [controller] EPOCH 1 loss ppo:  -0.00922, loss val: 0.03633
[2022-12-07 07:00:53,519] [INFO] [controller] EPOCH 2 loss ppo:  -0.01830, loss val: 0.03672
[2022-12-07 07:00:53,564] [INFO] [controller] EPOCH 3 loss ppo:  -0.02173, loss val: 0.03686
[2022-12-07 07:00:53,610] [INFO] [controller] EPOCH 4 loss ppo:  -0.02470, loss val: 0.03598
[2022-12-07 07:00:53,620] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:00:53,784] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:00:53,784] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:00:59,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:01:04,536] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:01:09,621] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:01:14,512] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:01:19,761] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:01:24,914] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:01:29,757] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:01:34,759] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:01:40,160] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:01:45,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4636088744275759
[2022-12-07 07:01:45,066] [INFO] [runner_train_mujoco] Average state value: 0.7193663024504979
[2022-12-07 07:01:45,066] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 07:01:45,138] [INFO] [controller] EPOCH 1 loss ppo:  -0.00876, loss val: 0.04230
[2022-12-07 07:01:45,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.01734, loss val: 0.04000
[2022-12-07 07:01:45,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.02395, loss val: 0.03886
[2022-12-07 07:01:45,283] [INFO] [controller] EPOCH 4 loss ppo:  -0.03125, loss val: 0.03802
[2022-12-07 07:01:45,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:01:45,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:01:45,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:01:50,545] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:01:56,102] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:02:00,914] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:02:06,254] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:02:11,075] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:02:16,128] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:02:21,492] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:02:26,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:02:31,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:02:37,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6492051459133225
[2022-12-07 07:02:37,172] [INFO] [runner_train_mujoco] Average state value: 0.6411957146724065
[2022-12-07 07:02:37,172] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 07:02:37,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.00969, loss val: 0.04478
[2022-12-07 07:02:37,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.02272, loss val: 0.04569
[2022-12-07 07:02:37,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.02859, loss val: 0.04486
[2022-12-07 07:02:37,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.03178, loss val: 0.04272
[2022-12-07 07:02:37,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:02:37,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:02:37,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:02:42,814] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:02:47,885] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:02:52,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:02:57,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:03:03,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:03:08,638] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:03:13,903] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:03:19,048] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:03:24,313] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:03:29,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.673007882881149
[2022-12-07 07:03:29,544] [INFO] [runner_train_mujoco] Average state value: 0.6609449638724326
[2022-12-07 07:03:29,544] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 07:03:29,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.00993, loss val: 0.04327
[2022-12-07 07:03:29,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.01832, loss val: 0.04149
[2022-12-07 07:03:29,691] [INFO] [controller] EPOCH 3 loss ppo:  -0.02446, loss val: 0.04140
[2022-12-07 07:03:29,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.02898, loss val: 0.04112
[2022-12-07 07:03:29,749] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:03:29,908] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:03:29,908] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:03:34,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:03:40,393] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:03:45,657] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:03:50,582] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:03:55,869] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:04:00,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:04:05,902] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:04:10,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:04:15,801] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:04:21,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6433544101359951
[2022-12-07 07:04:21,447] [INFO] [runner_train_mujoco] Average state value: 0.720278768201669
[2022-12-07 07:04:21,447] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 07:04:21,508] [INFO] [controller] EPOCH 1 loss ppo:  -0.01047, loss val: 0.04339
[2022-12-07 07:04:21,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.02343, loss val: 0.04327
[2022-12-07 07:04:21,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.02579, loss val: 0.04312
[2022-12-07 07:04:21,673] [INFO] [controller] EPOCH 4 loss ppo:  -0.02876, loss val: 0.04225
[2022-12-07 07:04:21,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:04:21,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:04:21,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:04:26,982] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:04:32,238] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:04:37,414] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:04:42,421] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:04:47,456] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:04:52,478] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:04:57,542] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:05:02,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:05:07,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:05:12,357] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7727029805303988
[2022-12-07 07:05:12,357] [INFO] [runner_train_mujoco] Average state value: 0.7109864042202632
[2022-12-07 07:05:12,357] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 07:05:12,415] [INFO] [controller] EPOCH 1 loss ppo:  -0.01094, loss val: 0.03915
[2022-12-07 07:05:12,544] [INFO] [controller] EPOCH 2 loss ppo:  -0.02532, loss val: 0.03927
[2022-12-07 07:05:12,600] [INFO] [controller] EPOCH 3 loss ppo:  -0.03503, loss val: 0.03834
[2022-12-07 07:05:12,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.03958, loss val: 0.03885
[2022-12-07 07:05:12,663] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:05:12,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:05:12,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:05:18,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:05:23,385] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:05:28,517] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:05:33,964] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:05:39,206] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:05:44,311] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:05:49,508] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:05:54,524] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:05:59,688] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:06:04,767] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8948949765593671
[2022-12-07 07:06:04,767] [INFO] [runner_train_mujoco] Average state value: 0.6656967090169589
[2022-12-07 07:06:04,768] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 07:06:04,823] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.03809
[2022-12-07 07:06:04,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.02129, loss val: 0.03822
[2022-12-07 07:06:04,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.02464, loss val: 0.03921
[2022-12-07 07:06:04,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.02767, loss val: 0.03976
[2022-12-07 07:06:04,979] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:06:05,145] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:06:05,146] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:06:10,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:06:15,181] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:06:20,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:06:25,284] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:06:30,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:06:35,790] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:06:41,197] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:06:46,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:06:51,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:06:56,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7922968429662348
[2022-12-07 07:06:56,527] [INFO] [runner_train_mujoco] Average state value: 0.6472983483076096
[2022-12-07 07:06:56,527] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 07:06:56,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.01204, loss val: 0.03597
[2022-12-07 07:06:56,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.02195, loss val: 0.03664
[2022-12-07 07:06:56,688] [INFO] [controller] EPOCH 3 loss ppo:  -0.02846, loss val: 0.03693
[2022-12-07 07:06:56,733] [INFO] [controller] EPOCH 4 loss ppo:  -0.03209, loss val: 0.03644
[2022-12-07 07:06:56,743] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:06:56,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:06:56,910] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:07:01,986] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:07:08,232] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:07:13,644] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:07:19,220] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:07:24,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:07:30,233] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:07:35,454] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:07:40,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:07:45,897] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:07:50,875] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0318945478582495
[2022-12-07 07:07:50,876] [INFO] [runner_train_mujoco] Average state value: 0.6414480577309927
[2022-12-07 07:07:50,876] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 07:07:50,946] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.04185
[2022-12-07 07:07:51,000] [INFO] [controller] EPOCH 2 loss ppo:  -0.02323, loss val: 0.04365
[2022-12-07 07:07:51,060] [INFO] [controller] EPOCH 3 loss ppo:  -0.03173, loss val: 0.04241
[2022-12-07 07:07:51,112] [INFO] [controller] EPOCH 4 loss ppo:  -0.03966, loss val: 0.04132
[2022-12-07 07:07:51,122] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:07:51,296] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:07:51,296] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:07:55,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:08:00,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:08:05,820] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:08:10,519] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:08:15,442] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:08:20,315] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:08:25,119] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:08:30,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:08:35,421] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:08:40,244] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0443470435321975
[2022-12-07 07:08:40,244] [INFO] [runner_train_mujoco] Average state value: 0.66415557517608
[2022-12-07 07:08:40,244] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 07:08:40,298] [INFO] [controller] EPOCH 1 loss ppo:  -0.01090, loss val: 0.03701
[2022-12-07 07:08:40,345] [INFO] [controller] EPOCH 2 loss ppo:  -0.01982, loss val: 0.03758
[2022-12-07 07:08:40,394] [INFO] [controller] EPOCH 3 loss ppo:  -0.02586, loss val: 0.03698
[2022-12-07 07:08:40,441] [INFO] [controller] EPOCH 4 loss ppo:  -0.02854, loss val: 0.03851
[2022-12-07 07:08:40,451] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:08:40,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:08:40,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:08:46,187] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:08:51,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:08:56,328] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:09:01,023] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:09:05,497] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:09:09,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:09:14,314] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:09:18,742] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:09:23,086] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:09:27,677] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1560164958015884
[2022-12-07 07:09:27,677] [INFO] [runner_train_mujoco] Average state value: 0.6776070372660955
[2022-12-07 07:09:27,678] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 07:09:27,729] [INFO] [controller] EPOCH 1 loss ppo:  -0.01256, loss val: 0.03660
[2022-12-07 07:09:27,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.02110, loss val: 0.03622
[2022-12-07 07:09:27,820] [INFO] [controller] EPOCH 3 loss ppo:  -0.02388, loss val: 0.03603
[2022-12-07 07:09:27,863] [INFO] [controller] EPOCH 4 loss ppo:  -0.02976, loss val: 0.03851
[2022-12-07 07:09:27,871] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:09:28,033] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:09:28,034] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:09:32,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:09:37,098] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:09:41,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:09:46,632] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:09:51,001] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:09:55,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:10:00,241] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:10:04,698] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:10:09,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:10:13,537] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1615660207945642
[2022-12-07 07:10:13,537] [INFO] [runner_train_mujoco] Average state value: 0.7014356926878293
[2022-12-07 07:10:13,537] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 07:10:13,600] [INFO] [controller] EPOCH 1 loss ppo:  -0.01119, loss val: 0.03917
[2022-12-07 07:10:13,648] [INFO] [controller] EPOCH 2 loss ppo:  -0.01852, loss val: 0.04078
[2022-12-07 07:10:13,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.02778, loss val: 0.03906
[2022-12-07 07:10:13,743] [INFO] [controller] EPOCH 4 loss ppo:  -0.03684, loss val: 0.03926
[2022-12-07 07:10:13,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:10:13,912] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:10:13,913] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:10:18,394] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:10:22,567] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:10:27,319] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:10:32,172] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:10:36,438] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:10:40,850] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:10:45,553] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:10:50,010] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:10:54,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:10:59,057] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.285580367235988
[2022-12-07 07:10:59,057] [INFO] [runner_train_mujoco] Average state value: 0.6931565391222636
[2022-12-07 07:10:59,057] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 07:10:59,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.04110
[2022-12-07 07:10:59,164] [INFO] [controller] EPOCH 2 loss ppo:  -0.02246, loss val: 0.04180
[2022-12-07 07:10:59,205] [INFO] [controller] EPOCH 3 loss ppo:  -0.02527, loss val: 0.04103
[2022-12-07 07:10:59,254] [INFO] [controller] EPOCH 4 loss ppo:  -0.02954, loss val: 0.04104
[2022-12-07 07:10:59,265] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:10:59,435] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:10:59,435] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:11:03,711] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:11:08,393] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:11:12,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:11:17,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:11:21,518] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:11:26,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:11:30,609] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:11:35,014] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:11:39,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:11:44,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.353122364604873
[2022-12-07 07:11:44,047] [INFO] [runner_train_mujoco] Average state value: 0.6802530691623687
[2022-12-07 07:11:44,047] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 07:11:44,119] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.04059
[2022-12-07 07:11:44,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.02077, loss val: 0.04081
[2022-12-07 07:11:44,211] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.04257
[2022-12-07 07:11:44,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.03394, loss val: 0.04016
[2022-12-07 07:11:44,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:11:44,433] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:11:44,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:11:49,232] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:11:53,890] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:11:58,134] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:12:02,574] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:12:07,096] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:12:11,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:12:15,194] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:12:19,413] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:12:23,535] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:12:27,908] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3790241307060669
[2022-12-07 07:12:27,908] [INFO] [runner_train_mujoco] Average state value: 0.6707284380793571
[2022-12-07 07:12:27,908] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 07:12:27,957] [INFO] [controller] EPOCH 1 loss ppo:  -0.01173, loss val: 0.03954
[2022-12-07 07:12:28,001] [INFO] [controller] EPOCH 2 loss ppo:  -0.02131, loss val: 0.03920
[2022-12-07 07:12:28,049] [INFO] [controller] EPOCH 3 loss ppo:  -0.02845, loss val: 0.03866
[2022-12-07 07:12:28,104] [INFO] [controller] EPOCH 4 loss ppo:  -0.03174, loss val: 0.03937
[2022-12-07 07:12:28,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:12:28,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:12:28,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:12:32,543] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:12:37,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:12:41,565] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:12:46,718] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:12:51,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:12:55,937] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:13:00,045] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:13:04,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:13:08,963] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:13:13,084] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6291579645572596
[2022-12-07 07:13:13,085] [INFO] [runner_train_mujoco] Average state value: 0.6501537809769312
[2022-12-07 07:13:13,085] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 07:13:13,129] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.03784
[2022-12-07 07:13:13,168] [INFO] [controller] EPOCH 2 loss ppo:  -0.02221, loss val: 0.03739
[2022-12-07 07:13:13,208] [INFO] [controller] EPOCH 3 loss ppo:  -0.02948, loss val: 0.03756
[2022-12-07 07:13:13,253] [INFO] [controller] EPOCH 4 loss ppo:  -0.03424, loss val: 0.03721
[2022-12-07 07:13:13,263] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:13:13,426] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:13:13,426] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:13:17,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:13:22,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:13:27,274] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:13:31,323] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:13:36,138] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:13:40,399] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:13:45,386] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:13:49,461] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:13:53,991] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:13:58,180] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5835033152780489
[2022-12-07 07:13:58,181] [INFO] [runner_train_mujoco] Average state value: 0.624429440955321
[2022-12-07 07:13:58,181] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 07:13:58,231] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.03513
[2022-12-07 07:13:58,275] [INFO] [controller] EPOCH 2 loss ppo:  -0.02435, loss val: 0.03504
[2022-12-07 07:13:58,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.02858, loss val: 0.03547
[2022-12-07 07:13:58,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.03051, loss val: 0.03486
[2022-12-07 07:13:58,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:13:58,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:13:58,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:14:02,959] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:14:07,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:14:11,353] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:14:15,907] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:14:19,986] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:14:24,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:14:29,187] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:14:33,679] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:14:38,069] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:14:42,510] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4936670619522499
[2022-12-07 07:14:42,510] [INFO] [runner_train_mujoco] Average state value: 0.6164768798351289
[2022-12-07 07:14:42,510] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 07:14:42,565] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.03396
[2022-12-07 07:14:42,626] [INFO] [controller] EPOCH 2 loss ppo:  -0.02286, loss val: 0.03262
[2022-12-07 07:14:42,668] [INFO] [controller] EPOCH 3 loss ppo:  -0.02583, loss val: 0.03417
[2022-12-07 07:14:42,713] [INFO] [controller] EPOCH 4 loss ppo:  -0.03083, loss val: 0.03478
[2022-12-07 07:14:42,722] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:14:42,885] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:14:42,885] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:14:47,272] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:14:51,502] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:14:55,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:15:00,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:15:04,747] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:15:09,029] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:15:13,140] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:15:17,545] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:15:21,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:15:26,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6647937819594376
[2022-12-07 07:15:26,415] [INFO] [runner_train_mujoco] Average state value: 0.626156918823719
[2022-12-07 07:15:26,415] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 07:15:26,466] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04232
[2022-12-07 07:15:26,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.02487, loss val: 0.04241
[2022-12-07 07:15:26,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.03053, loss val: 0.04101
[2022-12-07 07:15:26,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.03720, loss val: 0.03996
[2022-12-07 07:15:26,612] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:15:26,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:15:26,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:15:31,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:15:35,709] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:15:40,139] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:15:44,602] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:15:49,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:15:53,788] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:15:58,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:16:02,247] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:16:06,274] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:16:10,577] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8212412872127661
[2022-12-07 07:16:10,578] [INFO] [runner_train_mujoco] Average state value: 0.6746899449825288
[2022-12-07 07:16:10,578] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 07:16:10,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.01607, loss val: 0.04031
[2022-12-07 07:16:10,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.02261, loss val: 0.04079
[2022-12-07 07:16:10,733] [INFO] [controller] EPOCH 3 loss ppo:  -0.02475, loss val: 0.04042
[2022-12-07 07:16:10,776] [INFO] [controller] EPOCH 4 loss ppo:  -0.03008, loss val: 0.03997
[2022-12-07 07:16:10,785] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:16:10,944] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:16:10,944] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:16:15,133] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:16:19,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:16:24,332] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:16:28,758] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:16:33,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:16:37,468] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:16:41,997] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:16:46,594] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:16:50,831] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:16:54,903] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9328807716339127
[2022-12-07 07:16:54,903] [INFO] [runner_train_mujoco] Average state value: 0.6631439592838287
[2022-12-07 07:16:54,903] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 07:16:54,965] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.03990
[2022-12-07 07:16:55,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.01883, loss val: 0.03878
[2022-12-07 07:16:55,059] [INFO] [controller] EPOCH 3 loss ppo:  -0.02440, loss val: 0.03791
[2022-12-07 07:16:55,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.03301, loss val: 0.03760
[2022-12-07 07:16:55,117] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:16:55,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:16:55,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:17:00,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:17:04,487] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:17:09,107] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:17:13,463] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:17:17,577] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:17:21,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:17:26,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:17:30,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:17:34,696] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:17:39,060] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.911703455852405
[2022-12-07 07:17:39,060] [INFO] [runner_train_mujoco] Average state value: 0.6155101783672969
[2022-12-07 07:17:39,060] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 07:17:39,121] [INFO] [controller] EPOCH 1 loss ppo:  -0.01489, loss val: 0.03907
[2022-12-07 07:17:39,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.02707, loss val: 0.03947
[2022-12-07 07:17:39,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.03060, loss val: 0.03940
[2022-12-07 07:17:39,260] [INFO] [controller] EPOCH 4 loss ppo:  -0.03484, loss val: 0.03911
[2022-12-07 07:17:39,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:17:39,429] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:17:39,429] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:17:43,632] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:17:47,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:17:52,582] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:17:57,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:18:02,484] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:18:06,962] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:18:11,312] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:18:15,550] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:18:20,360] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:18:24,677] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8941083256112894
[2022-12-07 07:18:24,677] [INFO] [runner_train_mujoco] Average state value: 0.6033947331309318
[2022-12-07 07:18:24,677] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 07:18:24,730] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03777
[2022-12-07 07:18:24,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.02153, loss val: 0.03775
[2022-12-07 07:18:24,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.02642, loss val: 0.03761
[2022-12-07 07:18:24,858] [INFO] [controller] EPOCH 4 loss ppo:  -0.03188, loss val: 0.03930
[2022-12-07 07:18:24,867] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:18:25,030] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:18:25,030] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:18:29,576] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:18:33,717] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:18:38,469] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:18:42,547] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:18:46,908] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:18:51,495] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:18:55,976] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:19:00,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:19:04,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:19:08,560] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9924960869401922
[2022-12-07 07:19:08,560] [INFO] [runner_train_mujoco] Average state value: 0.6069042423168819
[2022-12-07 07:19:08,560] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 07:19:08,609] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.04787
[2022-12-07 07:19:08,651] [INFO] [controller] EPOCH 2 loss ppo:  -0.02153, loss val: 0.04918
[2022-12-07 07:19:08,694] [INFO] [controller] EPOCH 3 loss ppo:  -0.02569, loss val: 0.04817
[2022-12-07 07:19:08,736] [INFO] [controller] EPOCH 4 loss ppo:  -0.03098, loss val: 0.04770
[2022-12-07 07:19:08,745] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:19:08,895] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:19:08,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:19:13,017] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:19:17,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:19:21,950] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:19:26,278] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:19:30,902] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:19:35,479] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:19:39,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:19:44,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:19:49,031] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:19:53,383] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1275165522298245
[2022-12-07 07:19:53,383] [INFO] [runner_train_mujoco] Average state value: 0.6364377014239629
[2022-12-07 07:19:53,383] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 07:19:53,441] [INFO] [controller] EPOCH 1 loss ppo:  -0.01490, loss val: 0.04852
[2022-12-07 07:19:53,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.02018, loss val: 0.04943
[2022-12-07 07:19:53,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.02398, loss val: 0.04840
[2022-12-07 07:19:53,579] [INFO] [controller] EPOCH 4 loss ppo:  -0.03087, loss val: 0.04869
[2022-12-07 07:19:53,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:19:53,747] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:19:53,748] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:19:58,079] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:20:02,367] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:20:06,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:20:10,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:20:15,215] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:20:19,237] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:20:23,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:20:28,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:20:32,626] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:20:36,809] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.230391611953631
[2022-12-07 07:20:36,809] [INFO] [runner_train_mujoco] Average state value: 0.668330213646094
[2022-12-07 07:20:36,809] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 07:20:36,861] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04179
[2022-12-07 07:20:36,903] [INFO] [controller] EPOCH 2 loss ppo:  -0.02108, loss val: 0.04128
[2022-12-07 07:20:36,944] [INFO] [controller] EPOCH 3 loss ppo:  -0.02423, loss val: 0.03923
[2022-12-07 07:20:36,988] [INFO] [controller] EPOCH 4 loss ppo:  -0.03121, loss val: 0.03840
[2022-12-07 07:20:36,997] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:20:37,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:20:37,160] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:20:41,441] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:20:45,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:20:50,200] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:20:54,682] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:20:58,809] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:21:03,215] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:21:07,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:21:12,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:21:16,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:21:21,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1395427108877625
[2022-12-07 07:21:21,334] [INFO] [runner_train_mujoco] Average state value: 0.6431449321508408
[2022-12-07 07:21:21,334] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 07:21:21,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04000
[2022-12-07 07:21:21,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.01834, loss val: 0.03901
[2022-12-07 07:21:21,466] [INFO] [controller] EPOCH 3 loss ppo:  -0.02470, loss val: 0.03916
[2022-12-07 07:21:21,510] [INFO] [controller] EPOCH 4 loss ppo:  -0.03020, loss val: 0.03870
[2022-12-07 07:21:21,519] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:21:21,684] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:21:21,685] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:21:26,238] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:21:30,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:21:34,814] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:21:39,319] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:21:43,720] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:21:47,729] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:21:52,050] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:21:56,083] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:22:00,386] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:22:04,995] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.098003199573214
[2022-12-07 07:22:04,995] [INFO] [runner_train_mujoco] Average state value: 0.6033957070310911
[2022-12-07 07:22:04,996] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 07:22:05,065] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.04416
[2022-12-07 07:22:05,114] [INFO] [controller] EPOCH 2 loss ppo:  -0.02068, loss val: 0.04252
[2022-12-07 07:22:05,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.02773, loss val: 0.04304
[2022-12-07 07:22:05,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.03206, loss val: 0.04279
[2022-12-07 07:22:05,233] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:22:05,407] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:22:05,408] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:22:09,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:22:14,225] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:22:18,941] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:22:23,280] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:22:27,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:22:32,027] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:22:36,423] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:22:40,938] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:22:45,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:22:49,443] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.372128481793792
[2022-12-07 07:22:49,444] [INFO] [runner_train_mujoco] Average state value: 0.5899030940731367
[2022-12-07 07:22:49,444] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 07:22:49,506] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.04401
[2022-12-07 07:22:49,550] [INFO] [controller] EPOCH 2 loss ppo:  -0.02283, loss val: 0.04516
[2022-12-07 07:22:49,594] [INFO] [controller] EPOCH 3 loss ppo:  -0.02824, loss val: 0.04473
[2022-12-07 07:22:49,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.03269, loss val: 0.04452
[2022-12-07 07:22:49,656] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:22:49,815] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:22:49,816] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:22:54,164] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:22:58,540] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:23:02,918] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:23:07,192] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:23:11,587] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:23:15,755] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:23:19,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:23:24,009] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:23:28,142] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:23:32,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.291555976817677
[2022-12-07 07:23:32,272] [INFO] [runner_train_mujoco] Average state value: 0.6005926854610444
[2022-12-07 07:23:32,272] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 07:23:32,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.03787
[2022-12-07 07:23:32,450] [INFO] [controller] EPOCH 2 loss ppo:  -0.01932, loss val: 0.03783
[2022-12-07 07:23:32,494] [INFO] [controller] EPOCH 3 loss ppo:  -0.02534, loss val: 0.03845
[2022-12-07 07:23:32,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.02806, loss val: 0.03777
[2022-12-07 07:23:32,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:23:32,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:23:32,711] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:23:37,314] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:23:42,022] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:23:46,381] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:23:51,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:23:55,607] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:24:00,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:04,566] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:24:09,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:24:13,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:24:17,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2622833377576312
[2022-12-07 07:24:17,469] [INFO] [runner_train_mujoco] Average state value: 0.6140602850715319
[2022-12-07 07:24:17,469] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 07:24:17,523] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.03580
[2022-12-07 07:24:17,563] [INFO] [controller] EPOCH 2 loss ppo:  -0.01962, loss val: 0.03440
[2022-12-07 07:24:17,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.02520, loss val: 0.03591
[2022-12-07 07:24:17,672] [INFO] [controller] EPOCH 4 loss ppo:  -0.02805, loss val: 0.03454
[2022-12-07 07:24:17,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:24:17,843] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:24:17,843] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:24:22,222] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:24:26,235] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:24:30,886] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:24:35,315] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:24:39,255] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:24:43,365] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:47,561] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:24:51,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:24:56,205] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:25:00,350] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4336424502617833
[2022-12-07 07:25:00,350] [INFO] [runner_train_mujoco] Average state value: 0.5994325414498647
[2022-12-07 07:25:00,350] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 07:25:00,403] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.04022
[2022-12-07 07:25:00,448] [INFO] [controller] EPOCH 2 loss ppo:  -0.01791, loss val: 0.04144
[2022-12-07 07:25:00,492] [INFO] [controller] EPOCH 3 loss ppo:  -0.02174, loss val: 0.04101
[2022-12-07 07:25:00,538] [INFO] [controller] EPOCH 4 loss ppo:  -0.02627, loss val: 0.04042
[2022-12-07 07:25:00,548] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:25:00,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:25:00,709] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:25:05,645] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:25:10,092] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:25:14,638] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:25:19,441] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:25:23,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:25:27,848] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:25:31,883] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:25:35,904] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:25:40,097] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:25:44,087] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.393682321930341
[2022-12-07 07:25:44,087] [INFO] [runner_train_mujoco] Average state value: 0.5963190583586694
[2022-12-07 07:25:44,087] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 07:25:44,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01345, loss val: 0.04094
[2022-12-07 07:25:44,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.01505, loss val: 0.03954
[2022-12-07 07:25:44,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.01994, loss val: 0.04073
[2022-12-07 07:25:44,265] [INFO] [controller] EPOCH 4 loss ppo:  -0.02435, loss val: 0.04012
[2022-12-07 07:25:44,273] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:25:44,432] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:25:44,433] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:25:48,671] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:25:53,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:25:57,876] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:26:02,375] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:26:06,350] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:26:10,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:26:14,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:26:19,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:26:23,025] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:26:27,662] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.513357903034474
[2022-12-07 07:26:27,663] [INFO] [runner_train_mujoco] Average state value: 0.6076922412912051
[2022-12-07 07:26:27,663] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 07:26:27,721] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04405
[2022-12-07 07:26:27,765] [INFO] [controller] EPOCH 2 loss ppo:  -0.01624, loss val: 0.04340
[2022-12-07 07:26:27,811] [INFO] [controller] EPOCH 3 loss ppo:  -0.02020, loss val: 0.04319
[2022-12-07 07:26:27,856] [INFO] [controller] EPOCH 4 loss ppo:  -0.02253, loss val: 0.04312
[2022-12-07 07:26:27,864] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:26:28,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:26:28,032] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:26:32,535] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:26:37,102] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:26:41,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:26:45,996] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:26:50,611] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:26:55,014] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:26:59,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:27:03,563] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:27:07,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:27:11,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5960774300081257
[2022-12-07 07:27:11,913] [INFO] [runner_train_mujoco] Average state value: 0.6244268218477567
[2022-12-07 07:27:11,913] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 07:27:11,961] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04085
[2022-12-07 07:27:12,003] [INFO] [controller] EPOCH 2 loss ppo:  -0.01924, loss val: 0.04032
[2022-12-07 07:27:12,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.02344, loss val: 0.04064
[2022-12-07 07:27:12,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.02819, loss val: 0.04105
[2022-12-07 07:27:12,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:27:12,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:27:12,293] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:27:16,593] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:27:21,179] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:27:25,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:27:29,618] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:27:34,026] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:27:38,121] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:27:42,192] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:27:46,836] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:27:51,105] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:27:55,630] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5536344608677677
[2022-12-07 07:27:55,631] [INFO] [runner_train_mujoco] Average state value: 0.6284807773828507
[2022-12-07 07:27:55,631] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 07:27:55,685] [INFO] [controller] EPOCH 1 loss ppo:  -0.01347, loss val: 0.03962
[2022-12-07 07:27:55,727] [INFO] [controller] EPOCH 2 loss ppo:  -0.01569, loss val: 0.03960
[2022-12-07 07:27:55,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.01992, loss val: 0.03977
[2022-12-07 07:27:55,839] [INFO] [controller] EPOCH 4 loss ppo:  -0.02455, loss val: 0.03909
[2022-12-07 07:27:55,850] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:27:55,990] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:27:55,991] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:28:00,263] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:28:04,669] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:28:09,043] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:28:13,297] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:28:17,503] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:28:21,765] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:28:25,974] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:28:30,092] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:28:34,100] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:28:38,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5376002124302053
[2022-12-07 07:28:38,571] [INFO] [runner_train_mujoco] Average state value: 0.6209317881266276
[2022-12-07 07:28:38,571] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 07:28:38,622] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04041
[2022-12-07 07:28:38,662] [INFO] [controller] EPOCH 2 loss ppo:  -0.01630, loss val: 0.04012
[2022-12-07 07:28:38,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.01996, loss val: 0.04087
[2022-12-07 07:28:38,745] [INFO] [controller] EPOCH 4 loss ppo:  -0.02265, loss val: 0.03986
[2022-12-07 07:28:38,754] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:28:38,917] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:28:38,917] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:28:43,228] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:28:47,469] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:28:51,903] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:28:56,292] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:29:00,690] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:29:05,254] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:29:09,813] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:29:14,303] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:29:18,729] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:29:22,920] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5346940255775836
[2022-12-07 07:29:22,920] [INFO] [runner_train_mujoco] Average state value: 0.6028673296968143
[2022-12-07 07:29:22,920] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 07:29:22,970] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04076
[2022-12-07 07:29:23,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.01613, loss val: 0.04116
[2022-12-07 07:29:23,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.02040, loss val: 0.04047
[2022-12-07 07:29:23,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.02369, loss val: 0.04049
[2022-12-07 07:29:23,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:29:23,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:29:23,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:29:27,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:29:31,567] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:29:35,897] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:29:40,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:29:44,268] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:29:48,682] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:29:53,302] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:29:57,864] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:30:02,048] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:30:06,158] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6734564416066635
[2022-12-07 07:30:06,159] [INFO] [runner_train_mujoco] Average state value: 0.5939453706542651
[2022-12-07 07:30:06,159] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 07:30:06,209] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04175
[2022-12-07 07:30:06,253] [INFO] [controller] EPOCH 2 loss ppo:  -0.01699, loss val: 0.04172
[2022-12-07 07:30:06,296] [INFO] [controller] EPOCH 3 loss ppo:  -0.02020, loss val: 0.04170
[2022-12-07 07:30:06,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.02360, loss val: 0.04168
[2022-12-07 07:30:06,347] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:30:06,513] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:30:06,513] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:30:10,517] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:30:14,571] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:30:18,905] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:30:23,171] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:30:27,397] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:30:31,897] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:30:36,369] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:30:40,833] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:30:45,128] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:30:49,501] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7782940687373836
[2022-12-07 07:30:49,502] [INFO] [runner_train_mujoco] Average state value: 0.5968252465923627
[2022-12-07 07:30:49,502] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 07:30:49,553] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04336
[2022-12-07 07:30:49,597] [INFO] [controller] EPOCH 2 loss ppo:  -0.01479, loss val: 0.04429
[2022-12-07 07:30:49,641] [INFO] [controller] EPOCH 3 loss ppo:  -0.01620, loss val: 0.04333
[2022-12-07 07:30:49,685] [INFO] [controller] EPOCH 4 loss ppo:  -0.01805, loss val: 0.04324
[2022-12-07 07:30:49,694] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:30:49,859] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:30:49,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:30:53,895] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:30:58,027] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:31:02,675] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:31:06,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:31:10,951] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:31:14,927] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:31:18,916] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:31:23,288] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:31:27,553] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:31:31,671] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.785613979454226
[2022-12-07 07:31:31,671] [INFO] [runner_train_mujoco] Average state value: 0.6020441273649533
[2022-12-07 07:31:31,671] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 07:31:31,723] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.03821
[2022-12-07 07:31:31,764] [INFO] [controller] EPOCH 2 loss ppo:  -0.01418, loss val: 0.03848
[2022-12-07 07:31:31,808] [INFO] [controller] EPOCH 3 loss ppo:  -0.01519, loss val: 0.03805
[2022-12-07 07:31:31,852] [INFO] [controller] EPOCH 4 loss ppo:  -0.01643, loss val: 0.03820
[2022-12-07 07:31:31,863] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:31:31,995] [INFO] [optimize] Finished learning.
