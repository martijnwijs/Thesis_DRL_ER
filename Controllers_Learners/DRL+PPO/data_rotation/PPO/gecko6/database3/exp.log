[2022-12-06 18:26:39,602] [INFO] [optimize] Starting learning
[2022-12-06 18:26:39,608] [INFO] [optimize] Starting learning process..
[2022-12-06 18:26:39,662] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:26:39,662] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:26:47,010] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:26:52,308] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:26:57,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:27:03,057] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:27:08,292] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:27:13,530] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:27:18,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:27:24,053] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:27:29,365] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:27:34,942] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23319759014453587
[2022-12-06 18:27:34,942] [INFO] [runner_train_mujoco] Average state value: 0.10701290487373868
[2022-12-06 18:27:34,942] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 18:27:35,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.29251
[2022-12-06 18:27:35,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.02924, loss val: 0.25305
[2022-12-06 18:27:35,127] [INFO] [controller] EPOCH 3 loss ppo:  -0.03396, loss val: 0.22643
[2022-12-06 18:27:35,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.03491, loss val: 0.19544
[2022-12-06 18:27:35,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:27:35,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:27:35,401] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:27:43,639] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:27:49,742] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:27:56,172] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:28:02,517] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:28:09,219] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:28:15,301] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:28:21,480] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:28:27,602] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:28:33,980] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:28:40,680] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21742810732397846
[2022-12-06 18:28:40,680] [INFO] [runner_train_mujoco] Average state value: 0.30178790488839147
[2022-12-06 18:28:40,680] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 18:28:40,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.18819
[2022-12-06 18:28:40,820] [INFO] [controller] EPOCH 2 loss ppo:  -0.02649, loss val: 0.16275
[2022-12-06 18:28:40,881] [INFO] [controller] EPOCH 3 loss ppo:  -0.03424, loss val: 0.14799
[2022-12-06 18:28:41,225] [INFO] [controller] EPOCH 4 loss ppo:  -0.03669, loss val: 0.12458
[2022-12-06 18:28:41,240] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:28:41,446] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:28:41,446] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:28:47,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:28:54,346] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:29:00,932] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:29:07,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:29:13,504] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:29:20,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:29:27,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:29:33,357] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:29:40,100] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:29:46,122] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2110250129899597
[2022-12-06 18:29:46,122] [INFO] [runner_train_mujoco] Average state value: 0.45052932916581634
[2022-12-06 18:29:46,122] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 18:29:46,184] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.16947
[2022-12-06 18:29:46,252] [INFO] [controller] EPOCH 2 loss ppo:  -0.01678, loss val: 0.14463
[2022-12-06 18:29:46,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.02143, loss val: 0.12429
[2022-12-06 18:29:46,384] [INFO] [controller] EPOCH 4 loss ppo:  -0.02757, loss val: 0.10810
[2022-12-06 18:29:46,396] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:29:46,603] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:29:46,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:29:52,955] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:29:59,559] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:30:06,518] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:30:12,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:30:19,469] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:30:25,721] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:30:31,895] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:30:38,561] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:30:45,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:30:51,670] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.203136862582291
[2022-12-06 18:30:51,670] [INFO] [runner_train_mujoco] Average state value: 0.6229695974811912
[2022-12-06 18:30:51,670] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 18:30:51,731] [INFO] [controller] EPOCH 1 loss ppo:  -0.01069, loss val: 0.08454
[2022-12-06 18:30:51,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.02789, loss val: 0.07919
[2022-12-06 18:30:51,834] [INFO] [controller] EPOCH 3 loss ppo:  -0.03032, loss val: 0.07502
[2022-12-06 18:30:51,885] [INFO] [controller] EPOCH 4 loss ppo:  -0.03542, loss val: 0.06963
[2022-12-06 18:30:51,896] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:30:52,102] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:30:52,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:30:58,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:31:04,897] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:31:11,535] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:31:17,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:31:24,000] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:31:30,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:31:36,238] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:31:42,344] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:31:48,539] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:31:54,816] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.26263089977759874
[2022-12-06 18:31:54,816] [INFO] [runner_train_mujoco] Average state value: 0.7000298471450807
[2022-12-06 18:31:54,816] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 18:31:54,879] [INFO] [controller] EPOCH 1 loss ppo:  -0.01003, loss val: 0.07195
[2022-12-06 18:31:54,937] [INFO] [controller] EPOCH 2 loss ppo:  -0.02144, loss val: 0.06836
[2022-12-06 18:31:54,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.02492, loss val: 0.06325
[2022-12-06 18:31:55,070] [INFO] [controller] EPOCH 4 loss ppo:  -0.02896, loss val: 0.06022
[2022-12-06 18:31:55,081] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:31:55,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:31:55,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:32:01,095] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:32:07,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:32:13,202] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:32:19,757] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:32:25,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:32:31,204] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:32:37,384] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:32:43,311] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:32:48,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:32:54,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18381259283565185
[2022-12-06 18:32:54,633] [INFO] [runner_train_mujoco] Average state value: 0.7175904313723247
[2022-12-06 18:32:54,634] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 18:32:54,700] [INFO] [controller] EPOCH 1 loss ppo:  -0.00748, loss val: 0.05595
[2022-12-06 18:32:54,756] [INFO] [controller] EPOCH 2 loss ppo:  -0.02071, loss val: 0.05332
[2022-12-06 18:32:54,806] [INFO] [controller] EPOCH 3 loss ppo:  -0.02610, loss val: 0.05032
[2022-12-06 18:32:54,856] [INFO] [controller] EPOCH 4 loss ppo:  -0.02889, loss val: 0.04838
[2022-12-06 18:32:54,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:32:55,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:32:55,063] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:33:00,742] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:33:06,777] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:33:12,831] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:33:18,476] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:33:24,473] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:33:30,472] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:33:36,057] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:33:41,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:33:47,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:33:52,701] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17972765285296588
[2022-12-06 18:33:52,701] [INFO] [runner_train_mujoco] Average state value: 0.6867902966737748
[2022-12-06 18:33:52,701] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 18:33:52,758] [INFO] [controller] EPOCH 1 loss ppo:  -0.00802, loss val: 0.04986
[2022-12-06 18:33:52,805] [INFO] [controller] EPOCH 2 loss ppo:  -0.01651, loss val: 0.04871
[2022-12-06 18:33:52,855] [INFO] [controller] EPOCH 3 loss ppo:  -0.02208, loss val: 0.04779
[2022-12-06 18:33:52,902] [INFO] [controller] EPOCH 4 loss ppo:  -0.02644, loss val: 0.04692
[2022-12-06 18:33:52,913] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:33:53,115] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:33:53,116] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:33:58,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:34:05,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:34:10,838] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:34:16,743] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:34:22,967] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:34:28,934] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:34:35,045] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:34:40,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:34:46,678] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:34:54,777] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16465610791949936
[2022-12-06 18:34:54,778] [INFO] [runner_train_mujoco] Average state value: 0.6756108597715695
[2022-12-06 18:34:54,778] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 18:34:55,241] [INFO] [controller] EPOCH 1 loss ppo:  -0.00643, loss val: 0.04111
[2022-12-06 18:34:55,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.01603, loss val: 0.04127
[2022-12-06 18:34:55,675] [INFO] [controller] EPOCH 3 loss ppo:  -0.02101, loss val: 0.03882
[2022-12-06 18:34:55,827] [INFO] [controller] EPOCH 4 loss ppo:  -0.02785, loss val: 0.03757
[2022-12-06 18:34:55,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:34:56,102] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:34:56,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:35:04,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:35:10,299] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:35:15,518] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:35:21,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:35:26,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:35:32,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:35:38,528] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:35:44,782] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:35:50,848] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:35:57,051] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.27437255292005414
[2022-12-06 18:35:57,051] [INFO] [runner_train_mujoco] Average state value: 0.718622601568699
[2022-12-06 18:35:57,051] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 18:35:57,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.00977, loss val: 0.03799
[2022-12-06 18:35:57,185] [INFO] [controller] EPOCH 2 loss ppo:  -0.02441, loss val: 0.03862
[2022-12-06 18:35:57,242] [INFO] [controller] EPOCH 3 loss ppo:  -0.02941, loss val: 0.03713
[2022-12-06 18:35:57,311] [INFO] [controller] EPOCH 4 loss ppo:  -0.03346, loss val: 0.03629
[2022-12-06 18:35:57,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:35:57,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:35:57,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:36:03,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:36:09,277] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:36:15,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:36:23,423] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:36:32,271] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:36:41,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:36:49,905] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:37:00,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:37:07,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:37:14,962] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.443480283079401
[2022-12-06 18:37:14,963] [INFO] [runner_train_mujoco] Average state value: 0.6889563411275546
[2022-12-06 18:37:14,963] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 18:37:15,041] [INFO] [controller] EPOCH 1 loss ppo:  -0.00873, loss val: 0.03693
[2022-12-06 18:37:15,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.02431, loss val: 0.03921
[2022-12-06 18:37:15,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.02819, loss val: 0.03475
[2022-12-06 18:37:15,270] [INFO] [controller] EPOCH 4 loss ppo:  -0.03220, loss val: 0.03351
[2022-12-06 18:37:15,289] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:37:15,516] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:37:15,516] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:37:24,241] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:37:33,467] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:37:40,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:37:48,416] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:37:57,784] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:38:07,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:38:15,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:38:23,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:38:31,309] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:38:39,715] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48789532232516314
[2022-12-06 18:38:39,715] [INFO] [runner_train_mujoco] Average state value: 0.617045305152734
[2022-12-06 18:38:39,715] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 18:38:39,844] [INFO] [controller] EPOCH 1 loss ppo:  -0.01028, loss val: 0.05015
[2022-12-06 18:38:39,926] [INFO] [controller] EPOCH 2 loss ppo:  -0.02460, loss val: 0.05135
[2022-12-06 18:38:40,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.02616, loss val: 0.05059
[2022-12-06 18:38:40,077] [INFO] [controller] EPOCH 4 loss ppo:  -0.02911, loss val: 0.04737
[2022-12-06 18:38:40,090] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:38:40,308] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:38:40,309] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:38:50,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:38:59,333] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:39:07,385] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:39:15,253] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:39:23,097] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:39:31,299] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:39:38,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:39:46,749] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:39:54,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:40:02,157] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6335842811682985
[2022-12-06 18:40:02,157] [INFO] [runner_train_mujoco] Average state value: 0.6501794906059901
[2022-12-06 18:40:02,157] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 18:40:02,274] [INFO] [controller] EPOCH 1 loss ppo:  -0.00876, loss val: 0.04074
[2022-12-06 18:40:02,352] [INFO] [controller] EPOCH 2 loss ppo:  -0.02414, loss val: 0.03860
[2022-12-06 18:40:02,424] [INFO] [controller] EPOCH 3 loss ppo:  -0.02767, loss val: 0.03865
[2022-12-06 18:40:02,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.02920, loss val: 0.03909
[2022-12-06 18:40:02,505] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:40:02,716] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:40:02,717] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:40:10,792] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:40:20,050] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:40:28,988] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:40:36,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:40:46,344] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:41:02,666] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:41:13,252] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:41:20,561] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:41:27,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:41:34,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.704365467543014
[2022-12-06 18:41:34,996] [INFO] [runner_train_mujoco] Average state value: 0.7036563776334127
[2022-12-06 18:41:34,997] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 18:41:35,084] [INFO] [controller] EPOCH 1 loss ppo:  -0.00939, loss val: 0.03693
[2022-12-06 18:41:35,192] [INFO] [controller] EPOCH 2 loss ppo:  -0.02272, loss val: 0.03702
[2022-12-06 18:41:35,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.02770, loss val: 0.03753
[2022-12-06 18:41:35,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.02912, loss val: 0.03656
[2022-12-06 18:41:35,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:41:35,587] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:41:35,588] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:41:42,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:41:50,025] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:41:56,658] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:42:03,036] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:42:09,685] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:42:16,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:42:23,586] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:42:30,503] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:42:39,087] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:42:47,098] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9405993633212597
[2022-12-06 18:42:47,099] [INFO] [runner_train_mujoco] Average state value: 0.6979980785051982
[2022-12-06 18:42:47,099] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 18:42:47,215] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.04001
[2022-12-06 18:42:47,310] [INFO] [controller] EPOCH 2 loss ppo:  -0.01918, loss val: 0.03951
[2022-12-06 18:42:47,383] [INFO] [controller] EPOCH 3 loss ppo:  -0.02753, loss val: 0.04090
[2022-12-06 18:42:47,456] [INFO] [controller] EPOCH 4 loss ppo:  -0.02838, loss val: 0.04009
[2022-12-06 18:42:47,470] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:42:47,713] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:42:47,713] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:42:56,854] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:43:04,867] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:43:12,801] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:43:20,657] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:43:28,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:43:36,647] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:43:44,423] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:43:53,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:44:01,447] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:44:09,408] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8867371217281198
[2022-12-06 18:44:09,408] [INFO] [runner_train_mujoco] Average state value: 0.6782138812939327
[2022-12-06 18:44:09,408] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 18:44:09,510] [INFO] [controller] EPOCH 1 loss ppo:  -0.01065, loss val: 0.04108
[2022-12-06 18:44:09,592] [INFO] [controller] EPOCH 2 loss ppo:  -0.02303, loss val: 0.04107
[2022-12-06 18:44:09,687] [INFO] [controller] EPOCH 3 loss ppo:  -0.02561, loss val: 0.04054
[2022-12-06 18:44:09,766] [INFO] [controller] EPOCH 4 loss ppo:  -0.03056, loss val: 0.04056
[2022-12-06 18:44:09,780] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:44:10,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:44:10,020] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:44:18,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:44:26,007] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:44:33,694] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:44:41,547] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:44:49,292] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:44:56,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:45:04,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:45:12,712] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:45:19,932] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:45:28,096] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.992729207216723
[2022-12-06 18:45:28,096] [INFO] [runner_train_mujoco] Average state value: 0.6764910829265911
[2022-12-06 18:45:28,097] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 18:45:28,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.00988, loss val: 0.04496
[2022-12-06 18:45:28,253] [INFO] [controller] EPOCH 2 loss ppo:  -0.02315, loss val: 0.04422
[2022-12-06 18:45:28,328] [INFO] [controller] EPOCH 3 loss ppo:  -0.03020, loss val: 0.04416
[2022-12-06 18:45:28,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.03128, loss val: 0.04289
[2022-12-06 18:45:28,412] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:45:28,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:45:28,669] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:45:36,144] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:45:44,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:45:52,115] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:45:59,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:46:07,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:46:15,887] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:46:23,601] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:46:31,313] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:46:39,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:46:46,316] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0806218199693665
[2022-12-06 18:46:46,316] [INFO] [runner_train_mujoco] Average state value: 0.71742056230704
[2022-12-06 18:46:46,316] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 18:46:46,427] [INFO] [controller] EPOCH 1 loss ppo:  -0.01168, loss val: 0.04141
[2022-12-06 18:46:46,519] [INFO] [controller] EPOCH 2 loss ppo:  -0.02473, loss val: 0.04099
[2022-12-06 18:46:46,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.02587, loss val: 0.04128
[2022-12-06 18:46:46,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.02930, loss val: 0.04098
[2022-12-06 18:46:46,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:46:47,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:46:47,005] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:46:54,876] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:47:02,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:47:10,381] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:47:18,186] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:47:26,320] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:47:33,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:47:42,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:47:49,652] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:47:57,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:48:05,204] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2136684039360097
[2022-12-06 18:48:05,207] [INFO] [runner_train_mujoco] Average state value: 0.7292597739299138
[2022-12-06 18:48:05,207] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 18:48:05,313] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04713
[2022-12-06 18:48:05,403] [INFO] [controller] EPOCH 2 loss ppo:  -0.02309, loss val: 0.04681
[2022-12-06 18:48:05,490] [INFO] [controller] EPOCH 3 loss ppo:  -0.02922, loss val: 0.04672
[2022-12-06 18:48:05,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.03485, loss val: 0.04571
[2022-12-06 18:48:05,565] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:48:05,811] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:48:05,811] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:48:13,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:48:21,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:48:29,713] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:48:37,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:48:44,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:48:52,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:48:59,743] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:49:07,905] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:49:15,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:49:22,822] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2531148381798707
[2022-12-06 18:49:22,823] [INFO] [runner_train_mujoco] Average state value: 0.6956013813416163
[2022-12-06 18:49:22,823] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 18:49:22,945] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.04613
[2022-12-06 18:49:23,021] [INFO] [controller] EPOCH 2 loss ppo:  -0.02610, loss val: 0.04624
[2022-12-06 18:49:23,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.03429, loss val: 0.04557
[2022-12-06 18:49:23,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.03995, loss val: 0.04543
[2022-12-06 18:49:23,358] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:49:23,661] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:49:23,662] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:49:31,298] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:49:39,158] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:49:46,684] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:49:54,267] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:50:02,204] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:50:09,883] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:50:17,375] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:50:24,609] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:50:32,017] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:50:40,335] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3690536436843055
[2022-12-06 18:50:40,336] [INFO] [runner_train_mujoco] Average state value: 0.660415455698967
[2022-12-06 18:50:40,336] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 18:50:40,440] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04338
[2022-12-06 18:50:40,513] [INFO] [controller] EPOCH 2 loss ppo:  -0.02503, loss val: 0.04329
[2022-12-06 18:50:40,593] [INFO] [controller] EPOCH 3 loss ppo:  -0.02672, loss val: 0.04367
[2022-12-06 18:50:40,674] [INFO] [controller] EPOCH 4 loss ppo:  -0.03158, loss val: 0.04250
[2022-12-06 18:50:40,688] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:50:40,926] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:50:40,926] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:50:48,823] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:50:56,781] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:51:03,968] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:51:11,115] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:51:18,725] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:51:26,460] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:51:34,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:51:41,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:51:49,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:51:57,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5358626263872823
[2022-12-06 18:51:57,666] [INFO] [runner_train_mujoco] Average state value: 0.628349588473638
[2022-12-06 18:51:57,666] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 18:51:57,746] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.04028
[2022-12-06 18:51:57,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.02283, loss val: 0.03935
[2022-12-06 18:51:57,874] [INFO] [controller] EPOCH 3 loss ppo:  -0.02843, loss val: 0.03935
[2022-12-06 18:51:58,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.03560, loss val: 0.03930
[2022-12-06 18:51:58,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:51:58,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:51:58,245] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:52:05,822] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:52:13,784] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:52:21,792] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:52:29,241] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:52:36,753] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:52:44,281] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:52:51,990] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:52:59,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:53:07,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:53:14,684] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5524239554702581
[2022-12-06 18:53:14,684] [INFO] [runner_train_mujoco] Average state value: 0.6289677295088769
[2022-12-06 18:53:14,684] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 18:53:14,770] [INFO] [controller] EPOCH 1 loss ppo:  -0.01366, loss val: 0.03513
[2022-12-06 18:53:14,836] [INFO] [controller] EPOCH 2 loss ppo:  -0.02736, loss val: 0.03612
[2022-12-06 18:53:14,903] [INFO] [controller] EPOCH 3 loss ppo:  -0.03421, loss val: 0.03522
[2022-12-06 18:53:14,975] [INFO] [controller] EPOCH 4 loss ppo:  -0.03944, loss val: 0.03508
[2022-12-06 18:53:14,989] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:53:15,228] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:53:15,229] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:53:22,485] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:53:30,166] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:53:38,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:53:45,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:53:53,429] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:54:01,147] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:54:08,912] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:54:16,344] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:54:23,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:54:30,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7224955355125608
[2022-12-06 18:54:30,992] [INFO] [runner_train_mujoco] Average state value: 0.6257353339393934
[2022-12-06 18:54:30,992] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 18:54:31,081] [INFO] [controller] EPOCH 1 loss ppo:  -0.01412, loss val: 0.03962
[2022-12-06 18:54:31,252] [INFO] [controller] EPOCH 2 loss ppo:  -0.02813, loss val: 0.03853
[2022-12-06 18:54:31,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.03043, loss val: 0.03851
[2022-12-06 18:54:31,385] [INFO] [controller] EPOCH 4 loss ppo:  -0.03557, loss val: 0.03832
[2022-12-06 18:54:31,398] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:54:31,659] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:54:31,660] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:54:39,437] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:54:47,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:54:54,826] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:55:02,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:55:10,089] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:55:17,963] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:55:25,879] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:55:33,484] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:55:40,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:55:48,261] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6636473959167462
[2022-12-06 18:55:48,261] [INFO] [runner_train_mujoco] Average state value: 0.6289231638511021
[2022-12-06 18:55:48,261] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 18:55:48,355] [INFO] [controller] EPOCH 1 loss ppo:  -0.01171, loss val: 0.04325
[2022-12-06 18:55:48,414] [INFO] [controller] EPOCH 2 loss ppo:  -0.02210, loss val: 0.04313
[2022-12-06 18:55:48,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.02749, loss val: 0.04219
[2022-12-06 18:55:48,566] [INFO] [controller] EPOCH 4 loss ppo:  -0.02841, loss val: 0.04231
[2022-12-06 18:55:48,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:55:48,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:55:48,823] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:55:56,570] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:56:04,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:56:11,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:56:19,476] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:56:27,120] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:56:34,725] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:56:42,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:56:49,289] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:56:56,456] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:57:03,021] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7060385583399384
[2022-12-06 18:57:03,021] [INFO] [runner_train_mujoco] Average state value: 0.6604573637247085
[2022-12-06 18:57:03,021] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 18:57:03,112] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.04382
[2022-12-06 18:57:03,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.02338, loss val: 0.04369
[2022-12-06 18:57:03,238] [INFO] [controller] EPOCH 3 loss ppo:  -0.03001, loss val: 0.04391
[2022-12-06 18:57:03,301] [INFO] [controller] EPOCH 4 loss ppo:  -0.03840, loss val: 0.04319
[2022-12-06 18:57:03,313] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:57:03,536] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:57:03,536] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:57:10,668] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:57:17,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:57:23,541] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:57:31,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:57:39,064] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:57:46,256] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:57:53,810] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:58:01,606] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:58:09,870] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:58:17,486] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7380513613265964
[2022-12-06 18:58:17,487] [INFO] [runner_train_mujoco] Average state value: 0.6893975546558699
[2022-12-06 18:58:17,487] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 18:58:17,580] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.03756
[2022-12-06 18:58:17,677] [INFO] [controller] EPOCH 2 loss ppo:  -0.01937, loss val: 0.03766
[2022-12-06 18:58:17,745] [INFO] [controller] EPOCH 3 loss ppo:  -0.02674, loss val: 0.03798
[2022-12-06 18:58:17,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.03322, loss val: 0.03798
[2022-12-06 18:58:17,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:58:18,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:58:18,052] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:58:25,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:58:33,597] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:58:41,354] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 18:58:48,692] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 18:58:55,961] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 18:59:03,510] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 18:59:10,962] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 18:59:18,310] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 18:59:25,772] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 18:59:33,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7932765203069707
[2022-12-06 18:59:33,447] [INFO] [runner_train_mujoco] Average state value: 0.6863405586481094
[2022-12-06 18:59:33,447] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 18:59:33,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04057
[2022-12-06 18:59:33,612] [INFO] [controller] EPOCH 2 loss ppo:  -0.02286, loss val: 0.04074
[2022-12-06 18:59:33,679] [INFO] [controller] EPOCH 3 loss ppo:  -0.02748, loss val: 0.03952
[2022-12-06 18:59:33,753] [INFO] [controller] EPOCH 4 loss ppo:  -0.03435, loss val: 0.03852
[2022-12-06 18:59:33,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 18:59:34,036] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:59:34,036] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 18:59:42,235] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 18:59:50,869] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 18:59:59,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:00:08,993] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:00:18,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:00:26,868] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:00:34,855] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:00:42,853] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:00:51,119] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:00:59,630] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.742345353424918
[2022-12-06 19:00:59,631] [INFO] [runner_train_mujoco] Average state value: 0.6413633949359259
[2022-12-06 19:00:59,631] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 19:00:59,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01155, loss val: 0.03832
[2022-12-06 19:00:59,820] [INFO] [controller] EPOCH 2 loss ppo:  -0.01947, loss val: 0.03905
[2022-12-06 19:00:59,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.02754, loss val: 0.03885
[2022-12-06 19:00:59,977] [INFO] [controller] EPOCH 4 loss ppo:  -0.02917, loss val: 0.03842
[2022-12-06 19:00:59,991] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:01:00,257] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:01:00,258] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:01:09,099] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:01:17,456] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:01:25,906] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:01:34,244] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:01:42,463] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:01:50,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:01:59,169] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:02:07,750] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:02:15,957] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:02:24,213] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.904641465133468
[2022-12-06 19:02:24,213] [INFO] [runner_train_mujoco] Average state value: 0.6315615255832673
[2022-12-06 19:02:24,213] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 19:02:24,309] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.04596
[2022-12-06 19:02:24,442] [INFO] [controller] EPOCH 2 loss ppo:  -0.02282, loss val: 0.04550
[2022-12-06 19:02:24,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.02711, loss val: 0.04413
[2022-12-06 19:02:24,679] [INFO] [controller] EPOCH 4 loss ppo:  -0.03314, loss val: 0.04291
[2022-12-06 19:02:24,699] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:02:24,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:02:24,930] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:02:33,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:02:42,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:02:50,935] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:02:59,037] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:03:07,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:03:15,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:03:23,672] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:03:31,936] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:03:40,270] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:03:48,675] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.870599506100416
[2022-12-06 19:03:48,676] [INFO] [runner_train_mujoco] Average state value: 0.6830056767463685
[2022-12-06 19:03:48,676] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 19:03:48,780] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.04716
[2022-12-06 19:03:48,871] [INFO] [controller] EPOCH 2 loss ppo:  -0.02127, loss val: 0.04715
[2022-12-06 19:03:48,968] [INFO] [controller] EPOCH 3 loss ppo:  -0.02882, loss val: 0.04774
[2022-12-06 19:03:49,098] [INFO] [controller] EPOCH 4 loss ppo:  -0.03345, loss val: 0.04779
[2022-12-06 19:03:49,113] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:03:49,379] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:03:49,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:03:57,969] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:04:06,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:04:15,245] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:04:23,421] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:04:31,447] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:04:39,646] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:04:47,776] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:04:56,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:05:04,506] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:05:13,118] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8831070313980178
[2022-12-06 19:05:13,119] [INFO] [runner_train_mujoco] Average state value: 0.7106573441823324
[2022-12-06 19:05:13,119] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 19:05:13,257] [INFO] [controller] EPOCH 1 loss ppo:  -0.01097, loss val: 0.04444
[2022-12-06 19:05:13,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.01617, loss val: 0.04555
[2022-12-06 19:05:13,455] [INFO] [controller] EPOCH 3 loss ppo:  -0.02644, loss val: 0.04348
[2022-12-06 19:05:13,594] [INFO] [controller] EPOCH 4 loss ppo:  -0.03262, loss val: 0.04292
[2022-12-06 19:05:13,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:05:13,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:05:13,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:05:21,846] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:05:30,700] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:05:39,150] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:05:47,572] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:05:55,284] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:06:02,631] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:06:10,043] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:06:17,215] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:06:24,423] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:06:31,835] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9749607270774159
[2022-12-06 19:06:31,836] [INFO] [runner_train_mujoco] Average state value: 0.6745959818561872
[2022-12-06 19:06:31,836] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 19:06:31,921] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.04327
[2022-12-06 19:06:31,987] [INFO] [controller] EPOCH 2 loss ppo:  -0.02119, loss val: 0.04389
[2022-12-06 19:06:32,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.02843, loss val: 0.04344
[2022-12-06 19:06:32,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.03301, loss val: 0.04361
[2022-12-06 19:06:32,121] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:06:32,343] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:06:32,344] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:06:39,676] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:06:47,262] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:06:55,613] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:07:04,845] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:07:14,999] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:07:23,919] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:07:33,058] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:07:41,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:07:49,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:07:57,388] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9426384885777292
[2022-12-06 19:07:57,388] [INFO] [runner_train_mujoco] Average state value: 0.6643200713992118
[2022-12-06 19:07:57,389] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 19:07:57,496] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04512
[2022-12-06 19:07:57,626] [INFO] [controller] EPOCH 2 loss ppo:  -0.02053, loss val: 0.04487
[2022-12-06 19:07:57,789] [INFO] [controller] EPOCH 3 loss ppo:  -0.02378, loss val: 0.04484
[2022-12-06 19:07:57,908] [INFO] [controller] EPOCH 4 loss ppo:  -0.03346, loss val: 0.04514
[2022-12-06 19:07:57,924] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:07:58,162] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:07:58,163] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:08:06,259] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:08:14,786] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:08:23,209] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:08:32,067] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:08:40,855] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:08:49,375] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:08:57,640] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:09:05,992] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:09:14,407] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:09:22,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9433557878935726
[2022-12-06 19:09:22,591] [INFO] [runner_train_mujoco] Average state value: 0.665069815337658
[2022-12-06 19:09:22,591] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 19:09:22,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.03731
[2022-12-06 19:09:22,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.01849, loss val: 0.03724
[2022-12-06 19:09:22,885] [INFO] [controller] EPOCH 3 loss ppo:  -0.02451, loss val: 0.03762
[2022-12-06 19:09:22,957] [INFO] [controller] EPOCH 4 loss ppo:  -0.02926, loss val: 0.03670
[2022-12-06 19:09:22,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:09:23,256] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:09:23,256] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:09:31,569] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:09:40,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:09:48,564] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:09:56,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:10:05,148] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:10:14,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:10:22,443] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:10:31,062] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:10:39,505] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:10:47,918] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.027245826141582
[2022-12-06 19:10:47,919] [INFO] [runner_train_mujoco] Average state value: 0.6466149230400721
[2022-12-06 19:10:47,919] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 19:10:48,023] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.04078
[2022-12-06 19:10:48,106] [INFO] [controller] EPOCH 2 loss ppo:  -0.02273, loss val: 0.04301
[2022-12-06 19:10:48,203] [INFO] [controller] EPOCH 3 loss ppo:  -0.02799, loss val: 0.04110
[2022-12-06 19:10:48,348] [INFO] [controller] EPOCH 4 loss ppo:  -0.03298, loss val: 0.04060
[2022-12-06 19:10:48,365] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:10:48,590] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:10:48,596] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:10:57,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:11:05,744] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:11:14,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:11:22,113] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:11:30,103] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:11:38,980] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:11:47,615] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:11:55,785] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:12:04,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:12:12,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.070840367098476
[2022-12-06 19:12:12,564] [INFO] [runner_train_mujoco] Average state value: 0.6296811367670695
[2022-12-06 19:12:12,564] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 19:12:12,854] [INFO] [controller] EPOCH 1 loss ppo:  -0.01297, loss val: 0.04289
[2022-12-06 19:12:12,945] [INFO] [controller] EPOCH 2 loss ppo:  -0.02607, loss val: 0.04212
[2022-12-06 19:12:13,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.03004, loss val: 0.04267
[2022-12-06 19:12:13,185] [INFO] [controller] EPOCH 4 loss ppo:  -0.03433, loss val: 0.04223
[2022-12-06 19:12:13,204] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:12:13,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:12:13,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:12:21,972] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:12:30,524] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:12:38,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:12:47,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:12:55,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:13:03,962] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:13:12,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:13:20,615] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:13:28,926] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:13:36,968] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.091370772780587
[2022-12-06 19:13:36,968] [INFO] [runner_train_mujoco] Average state value: 0.6363926223715147
[2022-12-06 19:13:36,969] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 19:13:37,064] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.03673
[2022-12-06 19:13:37,137] [INFO] [controller] EPOCH 2 loss ppo:  -0.01850, loss val: 0.03891
[2022-12-06 19:13:37,209] [INFO] [controller] EPOCH 3 loss ppo:  -0.02462, loss val: 0.03708
[2022-12-06 19:13:37,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.03116, loss val: 0.03667
[2022-12-06 19:13:37,375] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:13:37,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:13:37,624] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:13:46,040] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:13:54,714] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:14:03,071] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:14:11,537] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:14:19,888] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:14:28,111] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:14:36,754] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:14:44,890] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:14:52,885] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:15:00,702] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2029796186602733
[2022-12-06 19:15:00,702] [INFO] [runner_train_mujoco] Average state value: 0.663350256284078
[2022-12-06 19:15:00,703] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 19:15:00,814] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.04544
[2022-12-06 19:15:00,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.02124, loss val: 0.04624
[2022-12-06 19:15:00,971] [INFO] [controller] EPOCH 3 loss ppo:  -0.02704, loss val: 0.04549
[2022-12-06 19:15:01,045] [INFO] [controller] EPOCH 4 loss ppo:  -0.03113, loss val: 0.04617
[2022-12-06 19:15:01,068] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:15:01,299] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:15:01,300] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:15:09,441] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:15:17,646] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:15:26,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:15:35,475] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:15:44,100] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:15:52,244] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:16:00,464] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:16:10,150] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:16:20,062] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:16:28,307] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1493254376333093
[2022-12-06 19:16:28,308] [INFO] [runner_train_mujoco] Average state value: 0.6813497552871705
[2022-12-06 19:16:28,308] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 19:16:28,481] [INFO] [controller] EPOCH 1 loss ppo:  -0.01188, loss val: 0.04589
[2022-12-06 19:16:28,548] [INFO] [controller] EPOCH 2 loss ppo:  -0.01607, loss val: 0.04508
[2022-12-06 19:16:28,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.02244, loss val: 0.04479
[2022-12-06 19:16:28,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.02589, loss val: 0.04384
[2022-12-06 19:16:28,712] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:16:28,939] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:16:28,939] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:16:36,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:16:45,042] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:16:54,299] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:17:03,192] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:17:12,059] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:17:20,676] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:17:31,010] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:17:39,410] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:17:49,551] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:17:58,434] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2208824051445983
[2022-12-06 19:17:58,434] [INFO] [runner_train_mujoco] Average state value: 0.6631114141146341
[2022-12-06 19:17:58,434] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 19:17:58,587] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.04347
[2022-12-06 19:17:58,676] [INFO] [controller] EPOCH 2 loss ppo:  -0.01880, loss val: 0.04244
[2022-12-06 19:17:58,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.02415, loss val: 0.04245
[2022-12-06 19:17:58,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.02994, loss val: 0.04348
[2022-12-06 19:17:58,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:17:59,061] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:17:59,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:18:07,835] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:18:15,800] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:18:23,225] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:18:30,344] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:18:39,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:18:58,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:19:16,322] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:19:28,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:19:37,498] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:19:45,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.170029047175207
[2022-12-06 19:19:45,066] [INFO] [runner_train_mujoco] Average state value: 0.6416186419725418
[2022-12-06 19:19:45,066] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 19:19:45,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.04377
[2022-12-06 19:19:45,292] [INFO] [controller] EPOCH 2 loss ppo:  -0.02035, loss val: 0.04394
[2022-12-06 19:19:45,354] [INFO] [controller] EPOCH 3 loss ppo:  -0.02227, loss val: 0.04424
[2022-12-06 19:19:45,459] [INFO] [controller] EPOCH 4 loss ppo:  -0.02744, loss val: 0.04383
[2022-12-06 19:19:45,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:19:45,646] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:19:45,646] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:19:51,984] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:19:58,099] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:20:03,508] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:20:09,404] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:20:14,771] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:20:20,113] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:20:25,696] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:20:31,368] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:20:37,267] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:20:42,758] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2933681631943363
[2022-12-06 19:20:42,759] [INFO] [runner_train_mujoco] Average state value: 0.6403252986669541
[2022-12-06 19:20:42,759] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 19:20:42,832] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.03952
[2022-12-06 19:20:42,894] [INFO] [controller] EPOCH 2 loss ppo:  -0.02039, loss val: 0.03899
[2022-12-06 19:20:42,945] [INFO] [controller] EPOCH 3 loss ppo:  -0.01864, loss val: 0.03910
[2022-12-06 19:20:43,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.02755, loss val: 0.03853
[2022-12-06 19:20:43,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:20:43,207] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:20:43,207] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:20:48,829] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:20:54,488] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:21:00,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:21:06,219] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:21:11,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:21:17,092] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:21:22,825] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:21:28,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:21:34,211] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:21:39,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2847318282603917
[2022-12-06 19:21:39,784] [INFO] [runner_train_mujoco] Average state value: 0.6277096753517787
[2022-12-06 19:21:39,784] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 19:21:39,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04764
[2022-12-06 19:21:39,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.01184, loss val: 0.04867
[2022-12-06 19:21:39,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.01441, loss val: 0.04750
[2022-12-06 19:21:40,060] [INFO] [controller] EPOCH 4 loss ppo:  -0.02452, loss val: 0.04721
[2022-12-06 19:21:40,070] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:21:40,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:21:40,246] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:21:45,631] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:21:51,165] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:21:56,828] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:22:02,559] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:22:08,319] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:22:14,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:22:20,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:22:25,699] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:22:31,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:22:37,682] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.341685714807162
[2022-12-06 19:22:37,682] [INFO] [runner_train_mujoco] Average state value: 0.6328311302860579
[2022-12-06 19:22:37,682] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 19:22:37,772] [INFO] [controller] EPOCH 1 loss ppo:  -0.01212, loss val: 0.04532
[2022-12-06 19:22:37,836] [INFO] [controller] EPOCH 2 loss ppo:  -0.01816, loss val: 0.04661
[2022-12-06 19:22:37,890] [INFO] [controller] EPOCH 3 loss ppo:  -0.02618, loss val: 0.04504
[2022-12-06 19:22:37,946] [INFO] [controller] EPOCH 4 loss ppo:  -0.02895, loss val: 0.04515
[2022-12-06 19:22:37,956] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:22:38,170] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:22:38,171] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:22:44,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:22:49,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:22:55,393] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:23:00,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:23:06,875] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:23:12,731] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:23:19,010] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:23:25,001] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:23:31,052] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:23:37,183] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3550120608688885
[2022-12-06 19:23:37,184] [INFO] [runner_train_mujoco] Average state value: 0.6514453029831251
[2022-12-06 19:23:37,184] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 19:23:37,258] [INFO] [controller] EPOCH 1 loss ppo:  -0.01293, loss val: 0.04763
[2022-12-06 19:23:37,305] [INFO] [controller] EPOCH 2 loss ppo:  -0.01811, loss val: 0.04679
[2022-12-06 19:23:37,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.02007, loss val: 0.04612
[2022-12-06 19:23:37,432] [INFO] [controller] EPOCH 4 loss ppo:  -0.02700, loss val: 0.04667
[2022-12-06 19:23:37,445] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:23:37,635] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:23:37,635] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:23:43,846] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:23:49,956] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:23:55,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:24:02,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:24:08,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:24:14,755] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:24:20,991] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:24:27,236] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:24:33,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:24:40,204] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.291015966511742
[2022-12-06 19:24:40,204] [INFO] [runner_train_mujoco] Average state value: 0.6597426190773645
[2022-12-06 19:24:40,204] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 19:24:40,308] [INFO] [controller] EPOCH 1 loss ppo:  -0.01271, loss val: 0.03961
[2022-12-06 19:24:40,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.01510, loss val: 0.03964
[2022-12-06 19:24:40,462] [INFO] [controller] EPOCH 3 loss ppo:  -0.01802, loss val: 0.03938
[2022-12-06 19:24:40,541] [INFO] [controller] EPOCH 4 loss ppo:  -0.02319, loss val: 0.04031
[2022-12-06 19:24:40,554] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:24:40,750] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:24:40,751] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:24:46,914] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:24:53,294] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:24:59,377] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:25:05,604] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:25:11,794] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:25:18,047] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:25:23,902] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:25:30,099] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:25:36,684] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:25:43,380] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.332638077272084
[2022-12-06 19:25:43,380] [INFO] [runner_train_mujoco] Average state value: 0.6492176579833031
[2022-12-06 19:25:43,380] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 19:25:43,466] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04271
[2022-12-06 19:25:43,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.01799, loss val: 0.04315
[2022-12-06 19:25:43,673] [INFO] [controller] EPOCH 3 loss ppo:  -0.02284, loss val: 0.04251
[2022-12-06 19:25:43,760] [INFO] [controller] EPOCH 4 loss ppo:  -0.02571, loss val: 0.04253
[2022-12-06 19:25:43,772] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:25:43,980] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:25:43,980] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:25:50,869] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:25:57,412] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:26:04,194] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:26:10,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:26:16,974] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:26:23,205] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:26:29,798] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:26:36,405] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:26:43,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:26:50,021] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3812612003150155
[2022-12-06 19:26:50,021] [INFO] [runner_train_mujoco] Average state value: 0.6439405494332313
[2022-12-06 19:26:50,021] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 19:26:50,127] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04406
[2022-12-06 19:26:50,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.01693, loss val: 0.04375
[2022-12-06 19:26:50,276] [INFO] [controller] EPOCH 3 loss ppo:  -0.02017, loss val: 0.04411
[2022-12-06 19:26:50,357] [INFO] [controller] EPOCH 4 loss ppo:  -0.02542, loss val: 0.04403
[2022-12-06 19:26:50,370] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:26:50,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:26:50,583] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:26:57,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:27:04,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:27:11,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:27:18,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:27:25,199] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:27:32,187] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:27:39,146] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:27:45,912] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:27:53,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:28:00,340] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3483337572907628
[2022-12-06 19:28:00,341] [INFO] [runner_train_mujoco] Average state value: 0.6489476025104521
[2022-12-06 19:28:00,341] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 19:28:00,441] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.04041
[2022-12-06 19:28:00,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01973, loss val: 0.04040
[2022-12-06 19:28:00,585] [INFO] [controller] EPOCH 3 loss ppo:  -0.02365, loss val: 0.03974
[2022-12-06 19:28:00,651] [INFO] [controller] EPOCH 4 loss ppo:  -0.02881, loss val: 0.03937
[2022-12-06 19:28:00,665] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:28:00,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:28:00,875] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:28:08,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:28:15,420] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:28:22,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:28:29,501] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:28:36,703] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:28:44,126] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:28:51,549] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:28:58,339] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:29:06,071] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:29:13,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.366396423194052
[2022-12-06 19:29:13,761] [INFO] [runner_train_mujoco] Average state value: 0.630357630709807
[2022-12-06 19:29:13,761] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 19:29:13,837] [INFO] [controller] EPOCH 1 loss ppo:  -0.01327, loss val: 0.04165
[2022-12-06 19:29:13,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.01783, loss val: 0.04148
[2022-12-06 19:29:13,961] [INFO] [controller] EPOCH 3 loss ppo:  -0.02045, loss val: 0.04089
[2022-12-06 19:29:14,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.02537, loss val: 0.04224
[2022-12-06 19:29:14,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:29:14,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:29:14,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:29:21,873] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:29:29,338] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:29:36,921] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:29:44,424] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:29:52,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:29:59,937] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:30:08,360] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:30:16,995] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:30:25,541] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:30:33,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3653038696466915
[2022-12-06 19:30:33,931] [INFO] [runner_train_mujoco] Average state value: 0.6146239129702249
[2022-12-06 19:30:33,931] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 19:30:34,043] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.04276
[2022-12-06 19:30:34,136] [INFO] [controller] EPOCH 2 loss ppo:  -0.01765, loss val: 0.04195
[2022-12-06 19:30:34,233] [INFO] [controller] EPOCH 3 loss ppo:  -0.01958, loss val: 0.04188
[2022-12-06 19:30:34,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.02289, loss val: 0.04107
[2022-12-06 19:30:34,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:30:34,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:30:34,583] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:30:42,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:30:51,495] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:30:59,731] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:31:08,032] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:31:16,177] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:31:24,721] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:31:33,552] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:31:42,996] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:31:52,952] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:32:02,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.442508961972429
[2022-12-06 19:32:02,906] [INFO] [runner_train_mujoco] Average state value: 0.6119329798221587
[2022-12-06 19:32:02,906] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 19:32:03,059] [INFO] [controller] EPOCH 1 loss ppo:  -0.01280, loss val: 0.04067
[2022-12-06 19:32:03,164] [INFO] [controller] EPOCH 2 loss ppo:  -0.01602, loss val: 0.04242
[2022-12-06 19:32:03,261] [INFO] [controller] EPOCH 3 loss ppo:  -0.02033, loss val: 0.04066
[2022-12-06 19:32:03,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.02350, loss val: 0.04206
[2022-12-06 19:32:03,366] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:32:03,654] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:32:03,654] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:32:13,660] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:32:23,425] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:32:33,186] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:32:44,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:32:54,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:33:05,107] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:33:15,484] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:33:26,433] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:33:38,137] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:33:49,789] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.390298288272599
[2022-12-06 19:33:49,790] [INFO] [runner_train_mujoco] Average state value: 0.6227437883416811
[2022-12-06 19:33:49,790] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 19:33:49,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.04738
[2022-12-06 19:33:50,001] [INFO] [controller] EPOCH 2 loss ppo:  -0.01401, loss val: 0.04721
[2022-12-06 19:33:50,100] [INFO] [controller] EPOCH 3 loss ppo:  -0.01888, loss val: 0.04759
[2022-12-06 19:33:50,204] [INFO] [controller] EPOCH 4 loss ppo:  -0.02394, loss val: 0.04598
[2022-12-06 19:33:50,222] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:33:50,528] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:33:50,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:34:02,436] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:34:13,654] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:34:25,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:34:35,161] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:34:45,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:34:55,780] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:35:05,510] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:35:15,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:35:24,472] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:35:33,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.446001563264645
[2022-12-06 19:35:33,660] [INFO] [runner_train_mujoco] Average state value: 0.6404142436782518
[2022-12-06 19:35:33,660] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 19:35:33,758] [INFO] [controller] EPOCH 1 loss ppo:  -0.01248, loss val: 0.04490
[2022-12-06 19:35:33,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.01484, loss val: 0.04331
[2022-12-06 19:35:34,040] [INFO] [controller] EPOCH 3 loss ppo:  -0.01815, loss val: 0.04328
[2022-12-06 19:35:34,139] [INFO] [controller] EPOCH 4 loss ppo:  -0.02066, loss val: 0.04347
[2022-12-06 19:35:34,156] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:35:34,446] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:35:34,447] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:35:44,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:35:52,973] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:36:01,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:36:10,791] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:36:19,500] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:36:28,163] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:36:36,783] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:36:46,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:36:54,210] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:37:01,707] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.34596855923529
[2022-12-06 19:37:01,708] [INFO] [runner_train_mujoco] Average state value: 0.6545663788914682
[2022-12-06 19:37:01,708] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 19:37:01,844] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.04433
[2022-12-06 19:37:02,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.01515, loss val: 0.04422
[2022-12-06 19:37:02,092] [INFO] [controller] EPOCH 3 loss ppo:  -0.01770, loss val: 0.04421
[2022-12-06 19:37:02,156] [INFO] [controller] EPOCH 4 loss ppo:  -0.02000, loss val: 0.04463
[2022-12-06 19:37:02,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:37:02,442] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:37:02,442] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:37:10,224] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:37:18,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:37:26,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:37:33,898] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:37:41,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:37:49,508] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:37:57,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:38:04,837] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:38:12,271] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:38:19,977] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.420852478493043
[2022-12-06 19:38:19,978] [INFO] [runner_train_mujoco] Average state value: 0.6560061428546906
[2022-12-06 19:38:19,978] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 19:38:20,102] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.04285
[2022-12-06 19:38:20,184] [INFO] [controller] EPOCH 2 loss ppo:  -0.01379, loss val: 0.04285
[2022-12-06 19:38:20,250] [INFO] [controller] EPOCH 3 loss ppo:  -0.01556, loss val: 0.04356
[2022-12-06 19:38:20,317] [INFO] [controller] EPOCH 4 loss ppo:  -0.01772, loss val: 0.04357
[2022-12-06 19:38:20,332] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:38:20,563] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:38:20,563] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:38:27,994] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:38:35,454] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:38:42,643] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:38:49,765] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:38:56,672] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:39:03,696] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:39:10,827] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:39:18,118] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:39:25,647] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:39:33,109] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3722509389978144
[2022-12-06 19:39:33,110] [INFO] [runner_train_mujoco] Average state value: 0.6518140949010849
[2022-12-06 19:39:33,110] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 19:39:33,198] [INFO] [controller] EPOCH 1 loss ppo:  -0.01265, loss val: 0.04263
[2022-12-06 19:39:33,276] [INFO] [controller] EPOCH 2 loss ppo:  -0.01349, loss val: 0.04268
[2022-12-06 19:39:33,346] [INFO] [controller] EPOCH 3 loss ppo:  -0.01521, loss val: 0.04259
[2022-12-06 19:39:33,422] [INFO] [controller] EPOCH 4 loss ppo:  -0.01712, loss val: 0.04263
[2022-12-06 19:39:33,436] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:39:33,669] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:39:33,670] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:39:41,312] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:39:49,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:39:56,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:40:04,556] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:40:12,082] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:40:19,457] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:40:27,280] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:40:35,339] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:40:43,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:40:51,757] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4576470606178686
[2022-12-06 19:40:51,757] [INFO] [runner_train_mujoco] Average state value: 0.6514469808340072
[2022-12-06 19:40:51,757] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 19:40:52,032] [INFO] [controller] EPOCH 1 loss ppo:  -0.01256, loss val: 0.04236
[2022-12-06 19:40:52,141] [INFO] [controller] EPOCH 2 loss ppo:  -0.01245, loss val: 0.04314
[2022-12-06 19:40:52,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.01288, loss val: 0.04232
[2022-12-06 19:40:52,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.01354, loss val: 0.04293
[2022-12-06 19:40:52,436] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:40:52,643] [INFO] [optimize] Finished learning.
