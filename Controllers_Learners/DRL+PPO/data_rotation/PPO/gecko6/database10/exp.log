[2022-12-07 10:59:14,723] [INFO] [optimize] Starting learning
[2022-12-07 10:59:14,733] [INFO] [optimize] Starting learning process..
[2022-12-07 10:59:14,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:59:14,801] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:59:22,454] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:59:29,331] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:59:35,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:59:41,889] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:59:47,928] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:59:54,595] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:00:01,210] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:00:07,076] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:00:13,349] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:00:19,916] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22613615830360492
[2022-12-07 11:00:19,917] [INFO] [runner_train_mujoco] Average state value: 0.19142835554232202
[2022-12-07 11:00:19,917] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 11:00:19,994] [INFO] [controller] EPOCH 1 loss ppo:  -0.01112, loss val: 0.23382
[2022-12-07 11:00:20,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.02825, loss val: 0.19443
[2022-12-07 11:00:20,162] [INFO] [controller] EPOCH 3 loss ppo:  -0.03511, loss val: 0.16873
[2022-12-07 11:00:20,246] [INFO] [controller] EPOCH 4 loss ppo:  -0.03914, loss val: 0.15270
[2022-12-07 11:00:20,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:00:20,476] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:00:20,477] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:00:27,227] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:00:33,833] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:00:40,534] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:00:46,955] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:00:53,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:01:00,154] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:01:06,583] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:01:12,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:01:18,976] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:01:25,477] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.25800936774557537
[2022-12-07 11:01:25,477] [INFO] [runner_train_mujoco] Average state value: 0.4004058730428418
[2022-12-07 11:01:25,477] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 11:01:25,593] [INFO] [controller] EPOCH 1 loss ppo:  -0.01255, loss val: 0.14799
[2022-12-07 11:01:25,673] [INFO] [controller] EPOCH 2 loss ppo:  -0.02251, loss val: 0.12461
[2022-12-07 11:01:25,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.02666, loss val: 0.10865
[2022-12-07 11:01:25,829] [INFO] [controller] EPOCH 4 loss ppo:  -0.02956, loss val: 0.09458
[2022-12-07 11:01:25,841] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:01:26,073] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:01:26,073] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:01:34,119] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:01:41,443] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:01:47,974] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:01:55,102] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:02:02,030] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:02:09,657] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:02:16,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:02:23,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:02:29,767] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:02:36,553] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21101278011794194
[2022-12-07 11:02:36,554] [INFO] [runner_train_mujoco] Average state value: 0.555611107877766
[2022-12-07 11:02:36,554] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 11:02:36,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01057, loss val: 0.08478
[2022-12-07 11:02:36,699] [INFO] [controller] EPOCH 2 loss ppo:  -0.02696, loss val: 0.07822
[2022-12-07 11:02:36,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.03177, loss val: 0.07427
[2022-12-07 11:02:36,818] [INFO] [controller] EPOCH 4 loss ppo:  -0.03397, loss val: 0.06908
[2022-12-07 11:02:36,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:02:37,029] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:02:37,029] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:02:43,425] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:02:50,642] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:02:56,920] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:03:03,715] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:03:10,080] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:03:16,662] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:03:23,339] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:03:29,855] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:03:36,534] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:03:42,786] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.25692224843478717
[2022-12-07 11:03:42,786] [INFO] [runner_train_mujoco] Average state value: 0.6403945380200943
[2022-12-07 11:03:42,786] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 11:03:42,889] [INFO] [controller] EPOCH 1 loss ppo:  -0.00883, loss val: 0.07342
[2022-12-07 11:03:43,091] [INFO] [controller] EPOCH 2 loss ppo:  -0.01875, loss val: 0.06866
[2022-12-07 11:03:43,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.02817, loss val: 0.06403
[2022-12-07 11:03:43,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.02947, loss val: 0.06112
[2022-12-07 11:03:43,294] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:03:43,483] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:03:43,483] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:03:50,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:03:57,219] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:04:03,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:04:10,213] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:04:16,435] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:04:22,405] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:04:28,574] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:04:34,652] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:04:40,646] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:04:46,677] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1731539259224844
[2022-12-07 11:04:46,677] [INFO] [runner_train_mujoco] Average state value: 0.6791955599387487
[2022-12-07 11:04:46,677] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 11:04:46,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.00842, loss val: 0.05183
[2022-12-07 11:04:46,793] [INFO] [controller] EPOCH 2 loss ppo:  -0.02457, loss val: 0.04963
[2022-12-07 11:04:46,863] [INFO] [controller] EPOCH 3 loss ppo:  -0.02526, loss val: 0.04796
[2022-12-07 11:04:46,919] [INFO] [controller] EPOCH 4 loss ppo:  -0.02519, loss val: 0.04637
[2022-12-07 11:04:46,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:04:47,130] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:04:47,131] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:04:52,984] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:04:59,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:05:04,847] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:05:10,801] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:05:17,115] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:05:23,494] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:05:29,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:05:35,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:05:41,625] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:05:47,617] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18946811128277888
[2022-12-07 11:05:47,617] [INFO] [runner_train_mujoco] Average state value: 0.7200050190289815
[2022-12-07 11:05:47,617] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 11:05:47,696] [INFO] [controller] EPOCH 1 loss ppo:  -0.00767, loss val: 0.04693
[2022-12-07 11:05:47,759] [INFO] [controller] EPOCH 2 loss ppo:  -0.01658, loss val: 0.04554
[2022-12-07 11:05:47,808] [INFO] [controller] EPOCH 3 loss ppo:  -0.01935, loss val: 0.04579
[2022-12-07 11:05:47,859] [INFO] [controller] EPOCH 4 loss ppo:  -0.02335, loss val: 0.04413
[2022-12-07 11:05:47,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:05:48,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:05:48,051] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:05:54,085] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:06:00,356] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:06:06,143] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:06:12,009] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:06:17,919] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:06:24,113] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:06:30,568] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:06:36,729] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:06:43,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:06:49,620] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2542410656494435
[2022-12-07 11:06:49,621] [INFO] [runner_train_mujoco] Average state value: 0.7293434720635414
[2022-12-07 11:06:49,621] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 11:06:49,790] [INFO] [controller] EPOCH 1 loss ppo:  -0.00716, loss val: 0.04240
[2022-12-07 11:06:49,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.01492, loss val: 0.04112
[2022-12-07 11:06:49,920] [INFO] [controller] EPOCH 3 loss ppo:  -0.02078, loss val: 0.04040
[2022-12-07 11:06:49,977] [INFO] [controller] EPOCH 4 loss ppo:  -0.02551, loss val: 0.03930
[2022-12-07 11:06:49,988] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:06:50,179] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:06:50,179] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:06:56,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:07:02,976] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:07:11,008] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:07:19,195] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:07:27,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:07:35,279] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:07:42,489] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:07:48,888] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:07:55,408] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:08:01,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19907599614148855
[2022-12-07 11:08:01,992] [INFO] [runner_train_mujoco] Average state value: 0.6845234848658245
[2022-12-07 11:08:01,992] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 11:08:02,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.00688, loss val: 0.03932
[2022-12-07 11:08:02,153] [INFO] [controller] EPOCH 2 loss ppo:  -0.01784, loss val: 0.03918
[2022-12-07 11:08:02,221] [INFO] [controller] EPOCH 3 loss ppo:  -0.02187, loss val: 0.03962
[2022-12-07 11:08:02,331] [INFO] [controller] EPOCH 4 loss ppo:  -0.02763, loss val: 0.03960
[2022-12-07 11:08:02,342] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:08:02,547] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:08:02,547] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:08:09,440] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:08:16,722] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:08:23,499] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:08:30,852] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:08:38,084] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:08:45,295] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:08:52,486] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:08:59,323] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:09:06,168] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:09:13,108] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21659279085956823
[2022-12-07 11:09:13,108] [INFO] [runner_train_mujoco] Average state value: 0.6728571617801984
[2022-12-07 11:09:13,108] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 11:09:13,235] [INFO] [controller] EPOCH 1 loss ppo:  -0.00756, loss val: 0.04121
[2022-12-07 11:09:13,304] [INFO] [controller] EPOCH 2 loss ppo:  -0.01506, loss val: 0.04106
[2022-12-07 11:09:13,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.02024, loss val: 0.04202
[2022-12-07 11:09:13,617] [INFO] [controller] EPOCH 4 loss ppo:  -0.02413, loss val: 0.04047
[2022-12-07 11:09:13,629] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:09:13,830] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:09:13,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:09:20,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:09:28,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:09:36,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:09:43,779] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:09:50,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:09:57,601] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:10:03,613] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:10:10,030] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:10:16,576] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:10:22,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19262804255081972
[2022-12-07 11:10:22,782] [INFO] [runner_train_mujoco] Average state value: 0.7040518478353818
[2022-12-07 11:10:22,782] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 11:10:22,858] [INFO] [controller] EPOCH 1 loss ppo:  -0.00607, loss val: 0.04396
[2022-12-07 11:10:22,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.01708, loss val: 0.04317
[2022-12-07 11:10:22,979] [INFO] [controller] EPOCH 3 loss ppo:  -0.02246, loss val: 0.04317
[2022-12-07 11:10:23,032] [INFO] [controller] EPOCH 4 loss ppo:  -0.02535, loss val: 0.04284
[2022-12-07 11:10:23,043] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:10:23,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:10:23,246] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:10:29,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:10:35,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:10:42,166] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:10:48,658] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:10:54,405] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:11:00,750] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:11:07,132] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:11:15,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:11:21,820] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:11:28,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19599296231775495
[2022-12-07 11:11:28,548] [INFO] [runner_train_mujoco] Average state value: 0.7090822351972262
[2022-12-07 11:11:28,548] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 11:11:28,639] [INFO] [controller] EPOCH 1 loss ppo:  -0.00655, loss val: 0.03708
[2022-12-07 11:11:28,695] [INFO] [controller] EPOCH 2 loss ppo:  -0.01435, loss val: 0.03654
[2022-12-07 11:11:28,751] [INFO] [controller] EPOCH 3 loss ppo:  -0.01943, loss val: 0.03577
[2022-12-07 11:11:28,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.02283, loss val: 0.03768
[2022-12-07 11:11:28,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:11:29,007] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:11:29,008] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:11:34,679] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:11:40,927] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:11:47,499] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:11:53,970] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:11:59,993] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:12:06,423] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:12:12,198] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:12:17,285] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:12:22,532] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:12:27,353] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2280606248475463
[2022-12-07 11:12:27,353] [INFO] [runner_train_mujoco] Average state value: 0.6961463705301285
[2022-12-07 11:12:27,353] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 11:12:27,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.00636, loss val: 0.03881
[2022-12-07 11:12:27,456] [INFO] [controller] EPOCH 2 loss ppo:  -0.01296, loss val: 0.03673
[2022-12-07 11:12:27,502] [INFO] [controller] EPOCH 3 loss ppo:  -0.01867, loss val: 0.03415
[2022-12-07 11:12:27,554] [INFO] [controller] EPOCH 4 loss ppo:  -0.02257, loss val: 0.03219
[2022-12-07 11:12:27,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:12:27,753] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:12:27,753] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:12:32,813] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:12:37,737] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:12:43,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:12:48,168] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:12:53,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:12:59,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:13:04,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:13:09,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:13:13,980] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:13:18,994] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2130982599318903
[2022-12-07 11:13:18,994] [INFO] [runner_train_mujoco] Average state value: 0.6207116232514382
[2022-12-07 11:13:18,994] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 11:13:19,044] [INFO] [controller] EPOCH 1 loss ppo:  -0.00618, loss val: 0.04243
[2022-12-07 11:13:19,086] [INFO] [controller] EPOCH 2 loss ppo:  -0.01581, loss val: 0.04340
[2022-12-07 11:13:19,131] [INFO] [controller] EPOCH 3 loss ppo:  -0.02229, loss val: 0.04309
[2022-12-07 11:13:19,175] [INFO] [controller] EPOCH 4 loss ppo:  -0.02490, loss val: 0.04185
[2022-12-07 11:13:19,185] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:13:19,355] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:13:19,356] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:13:24,231] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:13:29,489] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:13:34,394] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:13:39,055] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:13:43,758] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:13:48,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:13:52,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:13:57,679] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:14:02,277] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:14:07,191] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1783333093994773
[2022-12-07 11:14:07,192] [INFO] [runner_train_mujoco] Average state value: 0.6276128873427709
[2022-12-07 11:14:07,192] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 11:14:07,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.00416, loss val: 0.04084
[2022-12-07 11:14:07,292] [INFO] [controller] EPOCH 2 loss ppo:  -0.01639, loss val: 0.03884
[2022-12-07 11:14:07,338] [INFO] [controller] EPOCH 3 loss ppo:  -0.02728, loss val: 0.03824
[2022-12-07 11:14:07,392] [INFO] [controller] EPOCH 4 loss ppo:  -0.03100, loss val: 0.03775
[2022-12-07 11:14:07,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:14:07,572] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:14:07,573] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:14:12,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:14:17,347] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:14:22,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:14:27,737] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:14:32,373] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:14:37,462] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:14:42,038] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:14:46,641] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:14:51,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:14:56,443] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23412935200848634
[2022-12-07 11:14:56,443] [INFO] [runner_train_mujoco] Average state value: 0.7092900698184967
[2022-12-07 11:14:56,444] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 11:14:56,512] [INFO] [controller] EPOCH 1 loss ppo:  -0.00736, loss val: 0.04128
[2022-12-07 11:14:56,564] [INFO] [controller] EPOCH 2 loss ppo:  -0.01792, loss val: 0.04107
[2022-12-07 11:14:56,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.02395, loss val: 0.04097
[2022-12-07 11:14:56,665] [INFO] [controller] EPOCH 4 loss ppo:  -0.02616, loss val: 0.04129
[2022-12-07 11:14:56,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:14:56,875] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:14:56,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:15:02,308] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:15:08,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:15:14,948] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:15:20,146] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:15:25,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:15:30,612] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:15:36,792] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:15:42,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:15:48,398] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:15:53,826] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.19570879937434366
[2022-12-07 11:15:53,827] [INFO] [runner_train_mujoco] Average state value: 0.7396597919464112
[2022-12-07 11:15:53,827] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 11:15:53,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.00580, loss val: 0.04165
[2022-12-07 11:15:53,930] [INFO] [controller] EPOCH 2 loss ppo:  -0.01365, loss val: 0.03997
[2022-12-07 11:15:53,982] [INFO] [controller] EPOCH 3 loss ppo:  -0.01937, loss val: 0.03987
[2022-12-07 11:15:54,032] [INFO] [controller] EPOCH 4 loss ppo:  -0.02732, loss val: 0.03878
[2022-12-07 11:15:54,040] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:15:54,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:15:54,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:16:02,020] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:16:07,983] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:16:13,474] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:16:19,212] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:16:24,669] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:16:29,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:16:34,520] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:16:39,685] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:16:44,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:16:50,880] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17584345552188377
[2022-12-07 11:16:50,881] [INFO] [runner_train_mujoco] Average state value: 0.6923345876733462
[2022-12-07 11:16:50,881] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 11:16:50,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.00658, loss val: 0.03824
[2022-12-07 11:16:51,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.01585, loss val: 0.04041
[2022-12-07 11:16:51,059] [INFO] [controller] EPOCH 3 loss ppo:  -0.01773, loss val: 0.03992
[2022-12-07 11:16:51,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.02365, loss val: 0.04217
[2022-12-07 11:16:51,120] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:16:51,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:16:51,305] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:16:57,160] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:17:02,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:17:08,463] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:17:13,902] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:17:18,930] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:17:24,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:17:30,082] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:17:35,584] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:17:42,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:17:49,235] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.28016489503267344
[2022-12-07 11:17:49,236] [INFO] [runner_train_mujoco] Average state value: 0.6675296992262205
[2022-12-07 11:17:49,236] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 11:17:49,351] [INFO] [controller] EPOCH 1 loss ppo:  -0.00771, loss val: 0.03599
[2022-12-07 11:17:49,432] [INFO] [controller] EPOCH 2 loss ppo:  -0.01750, loss val: 0.03620
[2022-12-07 11:17:49,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.02356, loss val: 0.03645
[2022-12-07 11:17:49,550] [INFO] [controller] EPOCH 4 loss ppo:  -0.02904, loss val: 0.03586
[2022-12-07 11:17:49,562] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:17:49,764] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:17:49,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:17:55,318] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:18:00,539] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:18:06,555] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:18:12,252] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:18:17,527] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:18:22,686] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:18:27,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:18:32,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:18:37,849] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:18:43,424] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.26686010881631195
[2022-12-07 11:18:43,424] [INFO] [runner_train_mujoco] Average state value: 0.657933754503727
[2022-12-07 11:18:43,424] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 11:18:43,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.00647, loss val: 0.04266
[2022-12-07 11:18:43,532] [INFO] [controller] EPOCH 2 loss ppo:  -0.01708, loss val: 0.04009
[2022-12-07 11:18:43,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.02270, loss val: 0.03987
[2022-12-07 11:18:43,627] [INFO] [controller] EPOCH 4 loss ppo:  -0.02788, loss val: 0.03951
[2022-12-07 11:18:43,638] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:18:43,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:18:43,835] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:18:49,361] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:18:54,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:18:59,475] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:19:04,837] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:19:10,340] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:19:15,999] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:19:21,554] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:19:27,965] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:19:33,407] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:19:38,970] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.32882462297195747
[2022-12-07 11:19:38,971] [INFO] [runner_train_mujoco] Average state value: 0.6744208368460336
[2022-12-07 11:19:38,971] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 11:19:39,039] [INFO] [controller] EPOCH 1 loss ppo:  -0.00802, loss val: 0.03708
[2022-12-07 11:19:39,087] [INFO] [controller] EPOCH 2 loss ppo:  -0.02204, loss val: 0.03721
[2022-12-07 11:19:39,136] [INFO] [controller] EPOCH 3 loss ppo:  -0.02609, loss val: 0.03709
[2022-12-07 11:19:39,198] [INFO] [controller] EPOCH 4 loss ppo:  -0.02568, loss val: 0.03708
[2022-12-07 11:19:39,209] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:19:39,409] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:19:39,409] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:19:44,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:19:51,060] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:19:56,711] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:20:02,766] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:20:07,691] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:20:12,991] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:20:17,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:20:22,627] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:20:28,038] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:20:33,604] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.25399829642600447
[2022-12-07 11:20:33,604] [INFO] [runner_train_mujoco] Average state value: 0.6637773364384969
[2022-12-07 11:20:33,604] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 11:20:33,665] [INFO] [controller] EPOCH 1 loss ppo:  -0.00752, loss val: 0.03656
[2022-12-07 11:20:33,719] [INFO] [controller] EPOCH 2 loss ppo:  -0.01732, loss val: 0.03808
[2022-12-07 11:20:33,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.02431, loss val: 0.03597
[2022-12-07 11:20:33,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.02936, loss val: 0.03699
[2022-12-07 11:20:33,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:20:34,015] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:20:34,015] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:20:39,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:20:45,124] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:20:50,515] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:20:55,757] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:21:01,472] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:21:07,237] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:21:13,828] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:21:19,370] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:21:24,563] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:21:30,630] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.35401112790759376
[2022-12-07 11:21:30,631] [INFO] [runner_train_mujoco] Average state value: 0.6609078902403513
[2022-12-07 11:21:30,631] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 11:21:30,743] [INFO] [controller] EPOCH 1 loss ppo:  -0.00819, loss val: 0.03398
[2022-12-07 11:21:30,820] [INFO] [controller] EPOCH 2 loss ppo:  -0.01770, loss val: 0.03340
[2022-12-07 11:21:30,947] [INFO] [controller] EPOCH 3 loss ppo:  -0.02199, loss val: 0.03318
[2022-12-07 11:21:31,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.02610, loss val: 0.03297
[2022-12-07 11:21:31,061] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:21:31,310] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:21:31,310] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:21:36,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:21:42,647] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:21:48,852] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:21:53,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:21:58,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:22:02,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:22:07,440] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:22:12,455] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:22:17,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:22:22,599] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4348040960466336
[2022-12-07 11:22:22,599] [INFO] [runner_train_mujoco] Average state value: 0.6415932171344757
[2022-12-07 11:22:22,599] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 11:22:22,650] [INFO] [controller] EPOCH 1 loss ppo:  -0.00980, loss val: 0.03591
[2022-12-07 11:22:22,760] [INFO] [controller] EPOCH 2 loss ppo:  -0.02324, loss val: 0.03551
[2022-12-07 11:22:22,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.02362, loss val: 0.03557
[2022-12-07 11:22:22,851] [INFO] [controller] EPOCH 4 loss ppo:  -0.02612, loss val: 0.03652
[2022-12-07 11:22:22,862] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:22:23,061] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:22:23,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:22:28,501] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:22:33,830] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:22:39,185] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:22:44,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:22:49,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:22:55,009] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:22:59,692] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:23:04,916] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:23:10,107] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:23:15,025] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39200506020581927
[2022-12-07 11:23:15,026] [INFO] [runner_train_mujoco] Average state value: 0.597240614215533
[2022-12-07 11:23:15,026] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 11:23:15,085] [INFO] [controller] EPOCH 1 loss ppo:  -0.00757, loss val: 0.05067
[2022-12-07 11:23:15,127] [INFO] [controller] EPOCH 2 loss ppo:  -0.01503, loss val: 0.04953
[2022-12-07 11:23:15,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.02142, loss val: 0.04698
[2022-12-07 11:23:15,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.02561, loss val: 0.04193
[2022-12-07 11:23:15,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:23:15,407] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:23:15,408] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:23:20,838] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:23:26,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:23:32,055] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:23:36,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:23:41,868] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:23:46,855] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:23:52,099] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:23:57,639] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:24:03,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:24:09,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5034328707440106
[2022-12-07 11:24:09,091] [INFO] [runner_train_mujoco] Average state value: 0.6641522167523701
[2022-12-07 11:24:09,091] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 11:24:09,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.00925, loss val: 0.03791
[2022-12-07 11:24:09,225] [INFO] [controller] EPOCH 2 loss ppo:  -0.02001, loss val: 0.03832
[2022-12-07 11:24:09,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.02471, loss val: 0.03867
[2022-12-07 11:24:09,334] [INFO] [controller] EPOCH 4 loss ppo:  -0.02693, loss val: 0.04013
[2022-12-07 11:24:09,345] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:24:09,523] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:24:09,524] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:24:15,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:24:20,122] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:24:25,435] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:24:30,889] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:24:36,039] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:24:41,285] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:24:46,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:24:52,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:24:57,722] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:25:02,521] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4972015125246728
[2022-12-07 11:25:02,521] [INFO] [runner_train_mujoco] Average state value: 0.7147856824000677
[2022-12-07 11:25:02,521] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 11:25:02,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.00844, loss val: 0.03947
[2022-12-07 11:25:02,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.01793, loss val: 0.03904
[2022-12-07 11:25:02,728] [INFO] [controller] EPOCH 3 loss ppo:  -0.02187, loss val: 0.04017
[2022-12-07 11:25:02,782] [INFO] [controller] EPOCH 4 loss ppo:  -0.02796, loss val: 0.03923
[2022-12-07 11:25:02,793] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:25:02,989] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:25:02,989] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:25:07,933] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:25:13,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:25:18,267] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:25:23,121] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:25:28,599] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:25:34,121] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:25:39,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:25:45,762] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:25:51,923] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:25:57,252] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41575342526612935
[2022-12-07 11:25:57,252] [INFO] [runner_train_mujoco] Average state value: 0.6941922733187675
[2022-12-07 11:25:57,252] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 11:25:57,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.00790, loss val: 0.03947
[2022-12-07 11:25:57,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.01549, loss val: 0.03953
[2022-12-07 11:25:57,411] [INFO] [controller] EPOCH 3 loss ppo:  -0.02270, loss val: 0.03898
[2022-12-07 11:25:57,458] [INFO] [controller] EPOCH 4 loss ppo:  -0.02519, loss val: 0.03895
[2022-12-07 11:25:57,469] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:25:57,646] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:25:57,646] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:26:03,178] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:26:08,798] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:26:14,710] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:26:20,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:26:26,251] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:26:31,862] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:26:37,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:26:42,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:26:49,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:26:55,318] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.555501215290376
[2022-12-07 11:26:55,318] [INFO] [runner_train_mujoco] Average state value: 0.6720237318277359
[2022-12-07 11:26:55,318] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 11:26:55,399] [INFO] [controller] EPOCH 1 loss ppo:  -0.00889, loss val: 0.04107
[2022-12-07 11:26:55,468] [INFO] [controller] EPOCH 2 loss ppo:  -0.01839, loss val: 0.04100
[2022-12-07 11:26:55,515] [INFO] [controller] EPOCH 3 loss ppo:  -0.02565, loss val: 0.04294
[2022-12-07 11:26:55,564] [INFO] [controller] EPOCH 4 loss ppo:  -0.03028, loss val: 0.04096
[2022-12-07 11:26:55,574] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:26:55,751] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:26:55,751] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:27:01,608] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:27:06,998] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:27:12,286] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:27:17,400] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:27:22,552] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:27:27,799] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:27:33,534] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:27:39,461] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:27:45,036] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:27:50,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6973451128786812
[2022-12-07 11:27:50,165] [INFO] [runner_train_mujoco] Average state value: 0.671725178996722
[2022-12-07 11:27:50,165] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 11:27:50,224] [INFO] [controller] EPOCH 1 loss ppo:  -0.00993, loss val: 0.04008
[2022-12-07 11:27:50,274] [INFO] [controller] EPOCH 2 loss ppo:  -0.02000, loss val: 0.04021
[2022-12-07 11:27:50,329] [INFO] [controller] EPOCH 3 loss ppo:  -0.02411, loss val: 0.03712
[2022-12-07 11:27:50,376] [INFO] [controller] EPOCH 4 loss ppo:  -0.02969, loss val: 0.03437
[2022-12-07 11:27:50,387] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:27:50,570] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:27:50,570] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:27:55,833] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:28:00,855] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:28:06,135] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:28:11,351] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:28:16,378] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:28:21,257] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:28:26,148] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:28:31,232] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:28:37,003] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:28:42,717] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8887449118907993
[2022-12-07 11:28:42,717] [INFO] [runner_train_mujoco] Average state value: 0.6159871407747269
[2022-12-07 11:28:42,717] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 11:28:42,786] [INFO] [controller] EPOCH 1 loss ppo:  -0.01134, loss val: 0.04203
[2022-12-07 11:28:42,849] [INFO] [controller] EPOCH 2 loss ppo:  -0.01902, loss val: 0.04323
[2022-12-07 11:28:42,910] [INFO] [controller] EPOCH 3 loss ppo:  -0.02412, loss val: 0.04433
[2022-12-07 11:28:42,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.03172, loss val: 0.04333
[2022-12-07 11:28:43,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:28:43,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:28:43,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:28:48,369] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:28:54,148] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:28:59,435] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:29:04,829] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:29:10,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:29:15,425] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:29:20,205] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:29:25,598] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:29:31,780] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:29:36,966] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.06067538548458
[2022-12-07 11:29:36,966] [INFO] [runner_train_mujoco] Average state value: 0.6151458573937416
[2022-12-07 11:29:36,967] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 11:29:37,145] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.04215
[2022-12-07 11:29:37,257] [INFO] [controller] EPOCH 2 loss ppo:  -0.01947, loss val: 0.04017
[2022-12-07 11:29:37,446] [INFO] [controller] EPOCH 3 loss ppo:  -0.02587, loss val: 0.03869
[2022-12-07 11:29:37,584] [INFO] [controller] EPOCH 4 loss ppo:  -0.03026, loss val: 0.03857
[2022-12-07 11:29:37,598] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:29:37,824] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:29:37,824] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:29:45,110] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:29:51,963] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:29:56,468] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:30:01,165] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:30:06,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:30:12,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:30:18,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:30:23,797] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:30:28,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:30:33,438] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1382118339737912
[2022-12-07 11:30:33,438] [INFO] [runner_train_mujoco] Average state value: 0.662626522620519
[2022-12-07 11:30:33,439] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 11:30:33,492] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.03709
[2022-12-07 11:30:33,535] [INFO] [controller] EPOCH 2 loss ppo:  -0.02057, loss val: 0.03664
[2022-12-07 11:30:33,586] [INFO] [controller] EPOCH 3 loss ppo:  -0.02867, loss val: 0.03648
[2022-12-07 11:30:33,632] [INFO] [controller] EPOCH 4 loss ppo:  -0.03209, loss val: 0.03504
[2022-12-07 11:30:33,641] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:30:33,834] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:30:33,835] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:30:38,852] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:30:44,201] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:30:48,850] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:30:53,877] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:30:58,415] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:31:03,330] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:31:08,077] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:31:12,696] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:31:17,569] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:31:22,615] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.304024242317124
[2022-12-07 11:31:22,616] [INFO] [runner_train_mujoco] Average state value: 0.6397329393227895
[2022-12-07 11:31:22,616] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 11:31:22,676] [INFO] [controller] EPOCH 1 loss ppo:  -0.01192, loss val: 0.03900
[2022-12-07 11:31:22,720] [INFO] [controller] EPOCH 2 loss ppo:  -0.02043, loss val: 0.03699
[2022-12-07 11:31:22,763] [INFO] [controller] EPOCH 3 loss ppo:  -0.02329, loss val: 0.03760
[2022-12-07 11:31:22,805] [INFO] [controller] EPOCH 4 loss ppo:  -0.02989, loss val: 0.03750
[2022-12-07 11:31:22,814] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:31:22,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:31:22,972] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:31:27,998] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:31:33,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:31:38,078] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:31:43,863] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:31:50,033] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:31:58,009] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:32:03,363] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:32:08,792] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:32:14,088] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:32:19,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.049520245547257
[2022-12-07 11:32:19,485] [INFO] [runner_train_mujoco] Average state value: 0.6016089541117351
[2022-12-07 11:32:19,485] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 11:32:19,552] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.03924
[2022-12-07 11:32:19,603] [INFO] [controller] EPOCH 2 loss ppo:  -0.02114, loss val: 0.03877
[2022-12-07 11:32:19,651] [INFO] [controller] EPOCH 3 loss ppo:  -0.02752, loss val: 0.03813
[2022-12-07 11:32:19,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.03033, loss val: 0.03728
[2022-12-07 11:32:19,712] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:32:19,899] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:32:19,899] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:32:25,327] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:32:30,730] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:32:36,803] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:32:41,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:32:46,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:32:52,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:33:00,174] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:33:05,249] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:33:10,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:33:15,704] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2827133118262846
[2022-12-07 11:33:15,705] [INFO] [runner_train_mujoco] Average state value: 0.6189760753909748
[2022-12-07 11:33:15,705] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 11:33:15,792] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04140
[2022-12-07 11:33:15,846] [INFO] [controller] EPOCH 2 loss ppo:  -0.02454, loss val: 0.04170
[2022-12-07 11:33:15,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.02768, loss val: 0.04111
[2022-12-07 11:33:15,943] [INFO] [controller] EPOCH 4 loss ppo:  -0.03359, loss val: 0.04085
[2022-12-07 11:33:15,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:33:16,142] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:33:16,142] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:33:21,530] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:33:26,902] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:33:32,363] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:33:37,416] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:33:42,705] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:33:48,083] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:33:54,556] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:34:03,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:34:09,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:34:15,215] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5471598517039518
[2022-12-07 11:34:15,215] [INFO] [runner_train_mujoco] Average state value: 0.6468847764531771
[2022-12-07 11:34:15,216] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 11:34:15,284] [INFO] [controller] EPOCH 1 loss ppo:  -0.01137, loss val: 0.03756
[2022-12-07 11:34:15,342] [INFO] [controller] EPOCH 2 loss ppo:  -0.02010, loss val: 0.03773
[2022-12-07 11:34:15,393] [INFO] [controller] EPOCH 3 loss ppo:  -0.02598, loss val: 0.03814
[2022-12-07 11:34:15,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.02991, loss val: 0.03788
[2022-12-07 11:34:15,453] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:34:15,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:34:15,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:34:21,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:34:28,275] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:34:34,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:34:40,535] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:34:45,778] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:34:51,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:34:57,072] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:35:02,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:35:08,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:35:13,585] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6121215941266822
[2022-12-07 11:35:13,585] [INFO] [runner_train_mujoco] Average state value: 0.6641364470720291
[2022-12-07 11:35:13,586] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 11:35:13,656] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.03877
[2022-12-07 11:35:13,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.02204, loss val: 0.04004
[2022-12-07 11:35:13,773] [INFO] [controller] EPOCH 3 loss ppo:  -0.02577, loss val: 0.03792
[2022-12-07 11:35:13,843] [INFO] [controller] EPOCH 4 loss ppo:  -0.03425, loss val: 0.03833
[2022-12-07 11:35:13,854] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:35:14,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:35:14,051] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:35:23,376] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:35:32,577] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:35:39,158] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:35:45,038] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:35:53,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:35:59,562] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:36:04,909] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:36:10,096] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:36:18,093] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:36:26,422] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8550327501848334
[2022-12-07 11:36:26,423] [INFO] [runner_train_mujoco] Average state value: 0.6408655794461569
[2022-12-07 11:36:26,423] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 11:36:26,552] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04001
[2022-12-07 11:36:26,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.02154, loss val: 0.03981
[2022-12-07 11:36:26,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.02670, loss val: 0.03825
[2022-12-07 11:36:26,962] [INFO] [controller] EPOCH 4 loss ppo:  -0.03058, loss val: 0.03845
[2022-12-07 11:36:26,979] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:36:27,222] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:36:27,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:36:34,396] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:36:41,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:36:47,856] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:36:54,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:37:00,508] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:37:05,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:37:09,984] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:37:14,981] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:37:19,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:37:24,996] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9643447711979323
[2022-12-07 11:37:24,996] [INFO] [runner_train_mujoco] Average state value: 0.6046223958730698
[2022-12-07 11:37:24,996] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 11:37:25,075] [INFO] [controller] EPOCH 1 loss ppo:  -0.01518, loss val: 0.03745
[2022-12-07 11:37:25,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.02334, loss val: 0.03678
[2022-12-07 11:37:25,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.02818, loss val: 0.03625
[2022-12-07 11:37:25,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.03742, loss val: 0.03650
[2022-12-07 11:37:25,221] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:37:25,398] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:37:25,399] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:37:30,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:37:36,163] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:37:41,711] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:37:46,782] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:37:51,610] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:37:56,750] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:38:02,820] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:38:08,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:38:14,970] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:38:21,689] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0630991873122917
[2022-12-07 11:38:21,689] [INFO] [runner_train_mujoco] Average state value: 0.5711103786627452
[2022-12-07 11:38:21,690] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 11:38:21,755] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.04045
[2022-12-07 11:38:21,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.02504, loss val: 0.03914
[2022-12-07 11:38:21,864] [INFO] [controller] EPOCH 3 loss ppo:  -0.02825, loss val: 0.03919
[2022-12-07 11:38:21,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.03332, loss val: 0.03910
[2022-12-07 11:38:21,929] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:38:22,103] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:38:22,103] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:38:28,071] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:38:36,437] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:38:43,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:38:48,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:38:53,832] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:38:58,895] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:39:04,001] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:39:11,369] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:39:19,263] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:39:24,814] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2843450539758905
[2022-12-07 11:39:24,814] [INFO] [runner_train_mujoco] Average state value: 0.561266223390897
[2022-12-07 11:39:24,814] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 11:39:24,872] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.04113
[2022-12-07 11:39:24,922] [INFO] [controller] EPOCH 2 loss ppo:  -0.02367, loss val: 0.04279
[2022-12-07 11:39:24,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.02727, loss val: 0.04101
[2022-12-07 11:39:25,023] [INFO] [controller] EPOCH 4 loss ppo:  -0.03229, loss val: 0.04089
[2022-12-07 11:39:25,035] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:39:25,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:39:25,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:39:31,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:39:37,439] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:39:43,834] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:39:49,724] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:39:55,663] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:40:01,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:40:07,786] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:40:13,800] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:40:19,387] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:40:24,503] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.363369916973265
[2022-12-07 11:40:24,503] [INFO] [runner_train_mujoco] Average state value: 0.5713203196128209
[2022-12-07 11:40:24,503] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 11:40:24,559] [INFO] [controller] EPOCH 1 loss ppo:  -0.01348, loss val: 0.04084
[2022-12-07 11:40:24,607] [INFO] [controller] EPOCH 2 loss ppo:  -0.02183, loss val: 0.04083
[2022-12-07 11:40:24,656] [INFO] [controller] EPOCH 3 loss ppo:  -0.02549, loss val: 0.03995
[2022-12-07 11:40:24,709] [INFO] [controller] EPOCH 4 loss ppo:  -0.03140, loss val: 0.03982
[2022-12-07 11:40:24,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:40:24,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:40:24,950] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:40:31,009] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:40:36,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:40:41,877] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:40:47,492] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:40:52,771] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:40:58,382] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:41:04,450] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:41:10,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:41:16,370] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:41:21,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.490445458869843
[2022-12-07 11:41:21,719] [INFO] [runner_train_mujoco] Average state value: 0.5900333721240363
[2022-12-07 11:41:21,719] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 11:41:21,776] [INFO] [controller] EPOCH 1 loss ppo:  -0.01145, loss val: 0.03870
[2022-12-07 11:41:21,821] [INFO] [controller] EPOCH 2 loss ppo:  -0.01912, loss val: 0.03833
[2022-12-07 11:41:21,866] [INFO] [controller] EPOCH 3 loss ppo:  -0.02645, loss val: 0.03840
[2022-12-07 11:41:21,910] [INFO] [controller] EPOCH 4 loss ppo:  -0.03341, loss val: 0.03871
[2022-12-07 11:41:21,921] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:41:22,098] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:41:22,098] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:41:26,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:41:31,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:41:36,699] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:41:42,504] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:41:47,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:41:52,432] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:41:57,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:42:02,611] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:42:07,997] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:42:13,655] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.637304063912377
[2022-12-07 11:42:13,656] [INFO] [runner_train_mujoco] Average state value: 0.5979574857354164
[2022-12-07 11:42:13,656] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 11:42:13,716] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.03596
[2022-12-07 11:42:13,762] [INFO] [controller] EPOCH 2 loss ppo:  -0.02309, loss val: 0.03605
[2022-12-07 11:42:13,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.02552, loss val: 0.03687
[2022-12-07 11:42:13,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.02716, loss val: 0.03578
[2022-12-07 11:42:13,864] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:42:14,052] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:42:14,052] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:42:18,845] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:42:23,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:42:28,858] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:42:34,299] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:42:39,248] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:42:44,448] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:42:49,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:42:55,056] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:42:59,818] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:43:04,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8734695521033093
[2022-12-07 11:43:04,839] [INFO] [runner_train_mujoco] Average state value: 0.5919397869308789
[2022-12-07 11:43:04,839] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 11:43:04,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03796
[2022-12-07 11:43:04,992] [INFO] [controller] EPOCH 2 loss ppo:  -0.01852, loss val: 0.03872
[2022-12-07 11:43:05,043] [INFO] [controller] EPOCH 3 loss ppo:  -0.01991, loss val: 0.03883
[2022-12-07 11:43:05,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.02548, loss val: 0.03871
[2022-12-07 11:43:05,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:43:05,283] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:43:05,284] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:43:10,427] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:43:15,472] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:43:21,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:43:27,470] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:43:32,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:43:37,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:43:42,167] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:43:46,954] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:43:51,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:43:56,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.677624513369443
[2022-12-07 11:43:56,201] [INFO] [runner_train_mujoco] Average state value: 0.582699509302775
[2022-12-07 11:43:56,201] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 11:43:56,257] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.04638
[2022-12-07 11:43:56,316] [INFO] [controller] EPOCH 2 loss ppo:  -0.01621, loss val: 0.04612
[2022-12-07 11:43:56,369] [INFO] [controller] EPOCH 3 loss ppo:  -0.02064, loss val: 0.04549
[2022-12-07 11:43:56,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.02494, loss val: 0.04547
[2022-12-07 11:43:56,425] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:43:56,602] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:43:56,602] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:44:01,665] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:44:06,901] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:44:12,699] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:44:19,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:44:26,771] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:44:34,255] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:44:40,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:44:45,535] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:44:50,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:44:55,352] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8677347528157022
[2022-12-07 11:44:55,352] [INFO] [runner_train_mujoco] Average state value: 0.5913794510761897
[2022-12-07 11:44:55,352] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 11:44:55,412] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04403
[2022-12-07 11:44:55,538] [INFO] [controller] EPOCH 2 loss ppo:  -0.02022, loss val: 0.04367
[2022-12-07 11:44:55,584] [INFO] [controller] EPOCH 3 loss ppo:  -0.02301, loss val: 0.04446
[2022-12-07 11:44:55,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.02967, loss val: 0.04425
[2022-12-07 11:44:55,639] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:44:55,822] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:44:55,822] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:45:01,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:45:06,876] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:45:12,110] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:45:17,081] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:45:22,446] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:45:27,817] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:45:33,862] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:45:40,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:45:47,232] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:45:53,559] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.945084282448363
[2022-12-07 11:45:53,559] [INFO] [runner_train_mujoco] Average state value: 0.6099975943366686
[2022-12-07 11:45:53,559] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 11:45:53,632] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.04165
[2022-12-07 11:45:53,688] [INFO] [controller] EPOCH 2 loss ppo:  -0.01583, loss val: 0.04189
[2022-12-07 11:45:53,752] [INFO] [controller] EPOCH 3 loss ppo:  -0.02204, loss val: 0.03957
[2022-12-07 11:45:53,812] [INFO] [controller] EPOCH 4 loss ppo:  -0.02749, loss val: 0.03964
[2022-12-07 11:45:53,824] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:45:54,079] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:45:54,079] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:46:01,021] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:46:07,839] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:46:14,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:46:20,674] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:46:26,545] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:46:32,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:46:38,099] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:46:43,992] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:46:50,329] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:46:56,503] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.879636322323722
[2022-12-07 11:46:56,504] [INFO] [runner_train_mujoco] Average state value: 0.6181226234833399
[2022-12-07 11:46:56,504] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 11:46:56,575] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03903
[2022-12-07 11:46:56,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.01977, loss val: 0.03978
[2022-12-07 11:46:56,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.02455, loss val: 0.03930
[2022-12-07 11:46:56,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.03009, loss val: 0.03956
[2022-12-07 11:46:56,763] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:46:56,953] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:46:56,953] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:47:02,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:47:08,568] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:47:14,246] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:47:19,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:47:24,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:47:30,406] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:47:36,117] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:47:42,007] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:47:47,267] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:47:53,076] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9939481750311323
[2022-12-07 11:47:53,076] [INFO] [runner_train_mujoco] Average state value: 0.6072279813885689
[2022-12-07 11:47:53,076] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 11:47:53,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01334, loss val: 0.04194
[2022-12-07 11:47:53,184] [INFO] [controller] EPOCH 2 loss ppo:  -0.01808, loss val: 0.04246
[2022-12-07 11:47:53,257] [INFO] [controller] EPOCH 3 loss ppo:  -0.02252, loss val: 0.04216
[2022-12-07 11:47:53,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.02605, loss val: 0.04256
[2022-12-07 11:47:53,321] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:47:53,529] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:47:53,530] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:47:59,903] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:48:06,214] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:48:12,045] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:48:17,511] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:48:22,419] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:48:27,521] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:48:33,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:48:38,036] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:48:43,285] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:48:48,224] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0988767883784223
[2022-12-07 11:48:48,225] [INFO] [runner_train_mujoco] Average state value: 0.5942799125313759
[2022-12-07 11:48:48,225] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 11:48:48,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.03582
[2022-12-07 11:48:48,379] [INFO] [controller] EPOCH 2 loss ppo:  -0.01802, loss val: 0.03645
[2022-12-07 11:48:48,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.02218, loss val: 0.03556
[2022-12-07 11:48:48,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.02511, loss val: 0.03541
[2022-12-07 11:48:48,508] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:48:48,703] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:48:48,703] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:48:53,717] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:48:59,450] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:49:05,276] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:49:10,693] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:49:16,816] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:49:22,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:49:27,792] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:49:33,852] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:49:39,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:49:44,478] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.203498158674448
[2022-12-07 11:49:44,478] [INFO] [runner_train_mujoco] Average state value: 0.5804331903060278
[2022-12-07 11:49:44,478] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 11:49:44,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.04217
[2022-12-07 11:49:44,584] [INFO] [controller] EPOCH 2 loss ppo:  -0.01529, loss val: 0.04215
[2022-12-07 11:49:44,632] [INFO] [controller] EPOCH 3 loss ppo:  -0.02157, loss val: 0.04254
[2022-12-07 11:49:44,680] [INFO] [controller] EPOCH 4 loss ppo:  -0.02595, loss val: 0.04216
[2022-12-07 11:49:44,691] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:49:44,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:49:44,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:49:50,080] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:49:55,575] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:50:00,945] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:50:06,214] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:50:11,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:50:16,739] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:50:21,946] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:50:27,122] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:50:31,665] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:50:36,791] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0751916895345577
[2022-12-07 11:50:36,791] [INFO] [runner_train_mujoco] Average state value: 0.5766136378248533
[2022-12-07 11:50:36,791] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 11:50:36,846] [INFO] [controller] EPOCH 1 loss ppo:  -0.01252, loss val: 0.04643
[2022-12-07 11:50:36,891] [INFO] [controller] EPOCH 2 loss ppo:  -0.01659, loss val: 0.04614
[2022-12-07 11:50:36,934] [INFO] [controller] EPOCH 3 loss ppo:  -0.02088, loss val: 0.04520
[2022-12-07 11:50:36,979] [INFO] [controller] EPOCH 4 loss ppo:  -0.02355, loss val: 0.04599
[2022-12-07 11:50:36,989] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:50:37,168] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:50:37,168] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:50:42,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:50:47,266] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:50:52,294] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:50:57,208] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:51:02,313] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:51:07,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:51:12,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:51:17,368] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:51:22,068] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:51:26,826] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2907905245747457
[2022-12-07 11:51:26,826] [INFO] [runner_train_mujoco] Average state value: 0.5777310713529589
[2022-12-07 11:51:26,826] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 11:51:26,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.03685
[2022-12-07 11:51:26,925] [INFO] [controller] EPOCH 2 loss ppo:  -0.01784, loss val: 0.03724
[2022-12-07 11:51:26,980] [INFO] [controller] EPOCH 3 loss ppo:  -0.02476, loss val: 0.03568
[2022-12-07 11:51:27,030] [INFO] [controller] EPOCH 4 loss ppo:  -0.02885, loss val: 0.03573
[2022-12-07 11:51:27,041] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:51:27,217] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:51:27,217] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:51:31,865] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:51:37,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:51:41,917] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:51:46,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:51:51,217] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:51:55,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:52:00,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:52:05,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:52:10,457] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:52:15,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2575165761165437
[2022-12-07 11:52:15,223] [INFO] [runner_train_mujoco] Average state value: 0.577027741889159
[2022-12-07 11:52:15,223] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 11:52:15,288] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.04132
[2022-12-07 11:52:15,352] [INFO] [controller] EPOCH 2 loss ppo:  -0.01566, loss val: 0.04164
[2022-12-07 11:52:15,407] [INFO] [controller] EPOCH 3 loss ppo:  -0.01948, loss val: 0.04121
[2022-12-07 11:52:15,458] [INFO] [controller] EPOCH 4 loss ppo:  -0.02318, loss val: 0.04161
[2022-12-07 11:52:15,469] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:52:15,652] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:52:15,652] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:52:20,818] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:52:25,846] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:52:31,353] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:52:36,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:52:41,644] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:52:46,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:52:51,138] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:52:55,803] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:53:00,503] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:53:05,336] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3431605255045795
[2022-12-07 11:53:05,336] [INFO] [runner_train_mujoco] Average state value: 0.5754999800324441
[2022-12-07 11:53:05,336] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 11:53:05,398] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.03905
[2022-12-07 11:53:05,448] [INFO] [controller] EPOCH 2 loss ppo:  -0.01573, loss val: 0.03904
[2022-12-07 11:53:05,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.01871, loss val: 0.03932
[2022-12-07 11:53:05,551] [INFO] [controller] EPOCH 4 loss ppo:  -0.02159, loss val: 0.03953
[2022-12-07 11:53:05,563] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:53:05,745] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:53:05,745] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:53:10,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:53:16,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:53:21,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:53:26,876] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:53:32,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:53:37,356] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:53:42,181] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:53:47,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:53:52,278] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:53:56,948] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.215026359128932
[2022-12-07 11:53:56,948] [INFO] [runner_train_mujoco] Average state value: 0.5754703645904858
[2022-12-07 11:53:56,949] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 11:53:57,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.01324, loss val: 0.04207
[2022-12-07 11:53:57,100] [INFO] [controller] EPOCH 2 loss ppo:  -0.01503, loss val: 0.04219
[2022-12-07 11:53:57,228] [INFO] [controller] EPOCH 3 loss ppo:  -0.01829, loss val: 0.04217
[2022-12-07 11:53:57,315] [INFO] [controller] EPOCH 4 loss ppo:  -0.02218, loss val: 0.04208
[2022-12-07 11:53:57,328] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:53:57,548] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:53:57,548] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:54:02,883] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:54:11,125] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:54:18,098] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:54:23,122] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:54:28,752] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:54:35,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:54:43,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:54:50,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:54:57,215] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:55:04,860] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2690764928098766
[2022-12-07 11:55:04,860] [INFO] [runner_train_mujoco] Average state value: 0.5728380965789158
[2022-12-07 11:55:04,860] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 11:55:05,013] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.04197
[2022-12-07 11:55:05,115] [INFO] [controller] EPOCH 2 loss ppo:  -0.01411, loss val: 0.04148
[2022-12-07 11:55:05,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.01604, loss val: 0.04148
[2022-12-07 11:55:05,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.01794, loss val: 0.04229
[2022-12-07 11:55:05,353] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:55:05,541] [INFO] [optimize] Finished learning.
