[2022-12-06 16:02:26,788] [INFO] [optimize] Starting learning
[2022-12-06 16:02:26,800] [INFO] [optimize] Starting learning process..
[2022-12-06 16:02:26,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:02:26,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:02:35,074] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:02:41,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:02:49,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:02:56,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:03:02,583] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:03:08,744] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:03:14,990] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:03:21,057] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:03:27,004] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:03:33,771] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2406704128624674
[2022-12-06 16:03:33,771] [INFO] [runner_train_mujoco] Average state value: 0.2684729322145383
[2022-12-06 16:03:33,771] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 16:03:33,847] [INFO] [controller] EPOCH 1 loss ppo:  -0.01261, loss val: 0.19447
[2022-12-06 16:03:33,898] [INFO] [controller] EPOCH 2 loss ppo:  -0.02371, loss val: 0.18140
[2022-12-06 16:03:33,969] [INFO] [controller] EPOCH 3 loss ppo:  -0.03217, loss val: 0.14238
[2022-12-06 16:03:34,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.03469, loss val: 0.12533
[2022-12-06 16:03:34,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:03:34,234] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:03:34,234] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:03:40,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:03:47,138] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:03:53,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:04:00,607] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:04:07,442] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:04:13,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:04:21,054] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:04:27,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:04:34,910] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:04:41,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20443491147459306
[2022-12-06 16:04:41,462] [INFO] [runner_train_mujoco] Average state value: 0.4251227453431735
[2022-12-06 16:04:41,463] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 16:04:41,534] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.15477
[2022-12-06 16:04:41,594] [INFO] [controller] EPOCH 2 loss ppo:  -0.02119, loss val: 0.13507
[2022-12-06 16:04:41,648] [INFO] [controller] EPOCH 3 loss ppo:  -0.02813, loss val: 0.11522
[2022-12-06 16:04:41,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.03138, loss val: 0.10177
[2022-12-06 16:04:41,714] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:04:41,936] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:04:41,936] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:04:48,272] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:04:55,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:05:03,366] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:05:10,064] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:05:16,507] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:05:22,993] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:05:30,660] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:05:36,855] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:05:43,673] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:05:50,159] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.16571329664119072
[2022-12-06 16:05:50,159] [INFO] [runner_train_mujoco] Average state value: 0.584534938360254
[2022-12-06 16:05:50,159] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 16:05:50,220] [INFO] [controller] EPOCH 1 loss ppo:  -0.01095, loss val: 0.09726
[2022-12-06 16:05:50,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.02542, loss val: 0.08678
[2022-12-06 16:05:50,327] [INFO] [controller] EPOCH 3 loss ppo:  -0.03394, loss val: 0.07953
[2022-12-06 16:05:50,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.03823, loss val: 0.07399
[2022-12-06 16:05:50,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:05:50,618] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:05:50,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:05:56,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:06:02,676] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:06:08,594] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:06:14,217] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:06:20,309] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:06:26,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:06:32,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:06:38,718] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:06:44,177] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:06:50,320] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.23433407607320594
[2022-12-06 16:06:50,320] [INFO] [runner_train_mujoco] Average state value: 0.70219091446201
[2022-12-06 16:06:50,321] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 16:06:50,392] [INFO] [controller] EPOCH 1 loss ppo:  -0.00932, loss val: 0.06748
[2022-12-06 16:06:50,443] [INFO] [controller] EPOCH 2 loss ppo:  -0.02042, loss val: 0.06462
[2022-12-06 16:06:50,498] [INFO] [controller] EPOCH 3 loss ppo:  -0.02849, loss val: 0.06045
[2022-12-06 16:06:50,549] [INFO] [controller] EPOCH 4 loss ppo:  -0.03092, loss val: 0.05636
[2022-12-06 16:06:50,561] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:06:50,749] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:06:50,750] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:06:56,707] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:07:03,362] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:07:10,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:07:17,077] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:07:23,873] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:07:29,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:07:35,477] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:07:40,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:07:46,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:07:51,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2830891948830943
[2022-12-06 16:07:51,842] [INFO] [runner_train_mujoco] Average state value: 0.7434101487100124
[2022-12-06 16:07:51,842] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 16:07:51,902] [INFO] [controller] EPOCH 1 loss ppo:  -0.00870, loss val: 0.05707
[2022-12-06 16:07:51,952] [INFO] [controller] EPOCH 2 loss ppo:  -0.01856, loss val: 0.05301
[2022-12-06 16:07:52,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.02590, loss val: 0.04823
[2022-12-06 16:07:52,065] [INFO] [controller] EPOCH 4 loss ppo:  -0.02763, loss val: 0.04504
[2022-12-06 16:07:52,079] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:07:52,265] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:07:52,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:07:58,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:08:03,905] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:08:09,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:08:15,546] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:08:21,726] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:08:26,993] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:08:32,953] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:08:38,660] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:08:44,049] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:08:49,118] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3092939318711133
[2022-12-06 16:08:49,118] [INFO] [runner_train_mujoco] Average state value: 0.6764491405089696
[2022-12-06 16:08:49,119] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 16:08:49,176] [INFO] [controller] EPOCH 1 loss ppo:  -0.01033, loss val: 0.04761
[2022-12-06 16:08:49,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.02033, loss val: 0.04729
[2022-12-06 16:08:49,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.02342, loss val: 0.04623
[2022-12-06 16:08:49,328] [INFO] [controller] EPOCH 4 loss ppo:  -0.02979, loss val: 0.04647
[2022-12-06 16:08:49,339] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:08:49,529] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:08:49,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:08:54,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:09:00,259] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:09:05,544] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:09:11,220] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:09:16,468] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:09:22,025] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:09:27,672] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:09:33,599] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:09:39,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:09:44,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3692995472307488
[2022-12-06 16:09:44,819] [INFO] [runner_train_mujoco] Average state value: 0.6491175931692124
[2022-12-06 16:09:44,819] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 16:09:44,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.00805, loss val: 0.05076
[2022-12-06 16:09:44,943] [INFO] [controller] EPOCH 2 loss ppo:  -0.01974, loss val: 0.04917
[2022-12-06 16:09:44,997] [INFO] [controller] EPOCH 3 loss ppo:  -0.02427, loss val: 0.04793
[2022-12-06 16:09:45,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.02580, loss val: 0.04778
[2022-12-06 16:09:45,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:09:45,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:09:45,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:09:51,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:09:56,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:10:02,778] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:10:08,451] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:10:14,225] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:10:19,698] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:10:25,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:10:30,640] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:10:36,407] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:10:42,354] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4087079720849932
[2022-12-06 16:10:42,354] [INFO] [runner_train_mujoco] Average state value: 0.691170292576154
[2022-12-06 16:10:42,354] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 16:10:42,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.00787, loss val: 0.04272
[2022-12-06 16:10:42,478] [INFO] [controller] EPOCH 2 loss ppo:  -0.01952, loss val: 0.04137
[2022-12-06 16:10:42,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.02388, loss val: 0.04091
[2022-12-06 16:10:42,580] [INFO] [controller] EPOCH 4 loss ppo:  -0.02514, loss val: 0.04042
[2022-12-06 16:10:42,590] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:10:42,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:10:42,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:10:49,299] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:10:55,922] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:11:01,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:11:07,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:11:12,646] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:11:17,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:11:23,643] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:11:29,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:11:35,425] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:11:41,511] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3680202428838805
[2022-12-06 16:11:41,511] [INFO] [runner_train_mujoco] Average state value: 0.7556235046784082
[2022-12-06 16:11:41,512] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 16:11:41,581] [INFO] [controller] EPOCH 1 loss ppo:  -0.00974, loss val: 0.04158
[2022-12-06 16:11:41,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.02499, loss val: 0.03934
[2022-12-06 16:11:41,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.02617, loss val: 0.04023
[2022-12-06 16:11:41,765] [INFO] [controller] EPOCH 4 loss ppo:  -0.02764, loss val: 0.03754
[2022-12-06 16:11:41,776] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:11:41,984] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:11:41,985] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:11:48,082] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:11:54,757] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:12:00,845] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:12:07,165] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:12:13,129] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:12:18,925] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:12:24,678] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:12:30,516] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:12:36,502] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:12:42,074] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.642773287342715
[2022-12-06 16:12:42,074] [INFO] [runner_train_mujoco] Average state value: 0.7272065598169963
[2022-12-06 16:12:42,075] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 16:12:42,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.00961, loss val: 0.04337
[2022-12-06 16:12:42,196] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.04323
[2022-12-06 16:12:42,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.02483, loss val: 0.04296
[2022-12-06 16:12:42,311] [INFO] [controller] EPOCH 4 loss ppo:  -0.02910, loss val: 0.04270
[2022-12-06 16:12:42,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:12:42,525] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:12:42,525] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:12:48,306] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:12:54,338] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:13:00,290] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:13:05,878] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:13:12,000] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:13:18,272] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:13:24,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:13:30,273] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:13:35,604] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:13:41,099] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6146136638264007
[2022-12-06 16:13:41,099] [INFO] [runner_train_mujoco] Average state value: 0.6863040174643198
[2022-12-06 16:13:41,099] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 16:13:41,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01065, loss val: 0.04117
[2022-12-06 16:13:41,207] [INFO] [controller] EPOCH 2 loss ppo:  -0.02252, loss val: 0.04135
[2022-12-06 16:13:41,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.03009, loss val: 0.04101
[2022-12-06 16:13:41,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.03159, loss val: 0.04212
[2022-12-06 16:13:41,321] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:13:41,514] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:13:41,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:13:46,790] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:13:52,561] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:13:57,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:14:03,651] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:14:09,351] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:14:14,988] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:14:20,579] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:14:26,330] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:14:32,188] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:14:37,598] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6220691917343881
[2022-12-06 16:14:37,598] [INFO] [runner_train_mujoco] Average state value: 0.6775860553781191
[2022-12-06 16:14:37,598] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 16:14:37,666] [INFO] [controller] EPOCH 1 loss ppo:  -0.00894, loss val: 0.03805
[2022-12-06 16:14:37,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.01895, loss val: 0.03684
[2022-12-06 16:14:37,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.02235, loss val: 0.03580
[2022-12-06 16:14:37,824] [INFO] [controller] EPOCH 4 loss ppo:  -0.02398, loss val: 0.03386
[2022-12-06 16:14:37,834] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:14:38,037] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:38,038] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:14:43,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:14:49,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:14:56,707] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:15:03,782] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:15:09,757] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:15:15,955] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:15:23,110] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:15:28,943] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:15:34,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:15:40,908] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8366258336183192
[2022-12-06 16:15:40,908] [INFO] [runner_train_mujoco] Average state value: 0.6111295822262763
[2022-12-06 16:15:40,908] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 16:15:40,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.00936, loss val: 0.04252
[2022-12-06 16:15:41,045] [INFO] [controller] EPOCH 2 loss ppo:  -0.02048, loss val: 0.04328
[2022-12-06 16:15:41,105] [INFO] [controller] EPOCH 3 loss ppo:  -0.02402, loss val: 0.04492
[2022-12-06 16:15:41,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.02736, loss val: 0.04228
[2022-12-06 16:15:41,172] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:15:41,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:15:41,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:15:48,034] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:15:55,028] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:16:01,664] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:16:08,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:16:14,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:16:21,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:16:27,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:16:33,968] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:16:40,377] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:16:47,057] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8401356024367068
[2022-12-06 16:16:47,057] [INFO] [runner_train_mujoco] Average state value: 0.6074077064593634
[2022-12-06 16:16:47,058] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 16:16:47,141] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04135
[2022-12-06 16:16:47,227] [INFO] [controller] EPOCH 2 loss ppo:  -0.02399, loss val: 0.04158
[2022-12-06 16:16:47,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.02740, loss val: 0.04178
[2022-12-06 16:16:47,345] [INFO] [controller] EPOCH 4 loss ppo:  -0.03551, loss val: 0.04261
[2022-12-06 16:16:47,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:16:47,554] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:16:47,555] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:16:54,066] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:17:00,912] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:17:07,426] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:17:14,104] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:17:20,671] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:17:27,278] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:17:34,284] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:17:41,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:17:47,403] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:17:54,351] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9988229975115948
[2022-12-06 16:17:54,351] [INFO] [runner_train_mujoco] Average state value: 0.6430897827943165
[2022-12-06 16:17:54,351] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 16:17:54,470] [INFO] [controller] EPOCH 1 loss ppo:  -0.01035, loss val: 0.03551
[2022-12-06 16:17:54,587] [INFO] [controller] EPOCH 2 loss ppo:  -0.01824, loss val: 0.03518
[2022-12-06 16:17:54,678] [INFO] [controller] EPOCH 3 loss ppo:  -0.02320, loss val: 0.03426
[2022-12-06 16:17:54,789] [INFO] [controller] EPOCH 4 loss ppo:  -0.02882, loss val: 0.03396
[2022-12-06 16:17:54,801] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:17:55,028] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:17:55,029] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:18:02,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:18:08,831] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:18:15,540] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:18:21,871] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:18:28,293] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:18:34,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:18:40,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:18:47,463] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:18:53,678] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:19:00,668] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0283127774251437
[2022-12-06 16:19:00,669] [INFO] [runner_train_mujoco] Average state value: 0.609271588285764
[2022-12-06 16:19:00,669] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 16:19:00,799] [INFO] [controller] EPOCH 1 loss ppo:  -0.01291, loss val: 0.03765
[2022-12-06 16:19:00,893] [INFO] [controller] EPOCH 2 loss ppo:  -0.02268, loss val: 0.03801
[2022-12-06 16:19:01,015] [INFO] [controller] EPOCH 3 loss ppo:  -0.02432, loss val: 0.04045
[2022-12-06 16:19:01,120] [INFO] [controller] EPOCH 4 loss ppo:  -0.03190, loss val: 0.03737
[2022-12-06 16:19:01,131] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:19:01,354] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:19:01,354] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:19:07,991] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:19:14,653] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:21,240] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:19:27,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:19:33,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:19:40,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:19:46,492] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:19:52,823] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:19:58,818] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:20:05,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9309347241643291
[2022-12-06 16:20:05,004] [INFO] [runner_train_mujoco] Average state value: 0.6136180155078569
[2022-12-06 16:20:05,004] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 16:20:05,083] [INFO] [controller] EPOCH 1 loss ppo:  -0.01078, loss val: 0.05175
[2022-12-06 16:20:05,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.02070, loss val: 0.04974
[2022-12-06 16:20:05,198] [INFO] [controller] EPOCH 3 loss ppo:  -0.02509, loss val: 0.04728
[2022-12-06 16:20:05,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.02957, loss val: 0.04648
[2022-12-06 16:20:05,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:20:05,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:20:05,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:20:11,979] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:20:18,070] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:20:24,526] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:20:30,815] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:20:37,176] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:20:43,372] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:20:49,462] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:20:55,353] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:21:01,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:21:07,753] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9822907395526643
[2022-12-06 16:21:07,754] [INFO] [runner_train_mujoco] Average state value: 0.6976700797080995
[2022-12-06 16:21:07,754] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 16:21:07,838] [INFO] [controller] EPOCH 1 loss ppo:  -0.01002, loss val: 0.04021
[2022-12-06 16:21:07,890] [INFO] [controller] EPOCH 2 loss ppo:  -0.01971, loss val: 0.04158
[2022-12-06 16:21:08,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.02600, loss val: 0.04073
[2022-12-06 16:21:08,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.03117, loss val: 0.03989
[2022-12-06 16:21:08,190] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:21:08,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:21:08,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:21:14,115] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:21:20,437] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:21:26,498] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:21:32,745] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:21:38,849] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:44,945] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:21:51,108] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:21:57,505] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:22:03,817] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:22:09,894] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1388526573280373
[2022-12-06 16:22:09,894] [INFO] [runner_train_mujoco] Average state value: 0.6828211192091306
[2022-12-06 16:22:09,894] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 16:22:09,955] [INFO] [controller] EPOCH 1 loss ppo:  -0.01029, loss val: 0.03369
[2022-12-06 16:22:10,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.02164, loss val: 0.03751
[2022-12-06 16:22:10,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.02682, loss val: 0.03645
[2022-12-06 16:22:10,122] [INFO] [controller] EPOCH 4 loss ppo:  -0.03221, loss val: 0.03364
[2022-12-06 16:22:10,133] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:22:10,330] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:22:10,330] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:22:16,313] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:22:22,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:22:29,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:22:35,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:22:41,906] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:22:47,852] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:22:54,165] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:23:00,593] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:23:07,010] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:23:13,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2034089507167305
[2022-12-06 16:23:13,665] [INFO] [runner_train_mujoco] Average state value: 0.6597619896531105
[2022-12-06 16:23:13,665] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 16:23:13,744] [INFO] [controller] EPOCH 1 loss ppo:  -0.01034, loss val: 0.03982
[2022-12-06 16:23:13,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.02347, loss val: 0.03932
[2022-12-06 16:23:13,954] [INFO] [controller] EPOCH 3 loss ppo:  -0.02590, loss val: 0.03992
[2022-12-06 16:23:14,017] [INFO] [controller] EPOCH 4 loss ppo:  -0.03122, loss val: 0.03943
[2022-12-06 16:23:14,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:23:14,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:23:14,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:23:20,710] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:23:27,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:23:33,708] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:23:40,079] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:23:46,778] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:23:53,619] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:24:00,423] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:24:07,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:24:14,022] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:24:20,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.35849101021953
[2022-12-06 16:24:20,516] [INFO] [runner_train_mujoco] Average state value: 0.6773242730498313
[2022-12-06 16:24:20,516] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 16:24:20,644] [INFO] [controller] EPOCH 1 loss ppo:  -0.01154, loss val: 0.04549
[2022-12-06 16:24:20,704] [INFO] [controller] EPOCH 2 loss ppo:  -0.02468, loss val: 0.04497
[2022-12-06 16:24:20,774] [INFO] [controller] EPOCH 3 loss ppo:  -0.03275, loss val: 0.04419
[2022-12-06 16:24:20,831] [INFO] [controller] EPOCH 4 loss ppo:  -0.03713, loss val: 0.04237
[2022-12-06 16:24:20,844] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:24:21,065] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:24:21,065] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:24:28,034] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:24:34,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:24:41,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:24:47,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:24:54,690] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:25:01,590] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:25:08,609] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:25:15,193] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:25:22,030] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:25:28,811] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3588604436620357
[2022-12-06 16:25:28,811] [INFO] [runner_train_mujoco] Average state value: 0.6403743345538775
[2022-12-06 16:25:28,811] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 16:25:28,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01209, loss val: 0.04114
[2022-12-06 16:25:28,933] [INFO] [controller] EPOCH 2 loss ppo:  -0.02020, loss val: 0.04012
[2022-12-06 16:25:28,990] [INFO] [controller] EPOCH 3 loss ppo:  -0.02754, loss val: 0.04138
[2022-12-06 16:25:29,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.03341, loss val: 0.04196
[2022-12-06 16:25:29,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:25:29,276] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:25:29,276] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:25:36,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:25:45,042] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:25:56,662] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:26:07,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:26:16,765] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:26:26,509] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:26:35,771] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:26:44,522] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:26:53,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:27:01,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.524126314266389
[2022-12-06 16:27:01,508] [INFO] [runner_train_mujoco] Average state value: 0.6019355525573095
[2022-12-06 16:27:01,508] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 16:27:01,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04173
[2022-12-06 16:27:01,763] [INFO] [controller] EPOCH 2 loss ppo:  -0.02423, loss val: 0.04144
[2022-12-06 16:27:01,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.03203, loss val: 0.04139
[2022-12-06 16:27:01,947] [INFO] [controller] EPOCH 4 loss ppo:  -0.03561, loss val: 0.04158
[2022-12-06 16:27:01,960] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:27:02,216] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:27:02,217] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:27:11,147] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:27:17,525] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:27:24,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:27:30,847] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:27:38,793] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:27:46,840] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:27:57,773] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:28:06,211] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:28:13,974] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:28:20,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.575324246581727
[2022-12-06 16:28:20,824] [INFO] [runner_train_mujoco] Average state value: 0.6032784741918246
[2022-12-06 16:28:20,824] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 16:28:20,910] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04387
[2022-12-06 16:28:20,981] [INFO] [controller] EPOCH 2 loss ppo:  -0.02460, loss val: 0.04361
[2022-12-06 16:28:21,076] [INFO] [controller] EPOCH 3 loss ppo:  -0.02747, loss val: 0.04409
[2022-12-06 16:28:21,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.03323, loss val: 0.04295
[2022-12-06 16:28:21,153] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:28:21,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:28:21,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:28:28,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:28:35,345] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:28:42,090] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:28:48,671] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:28:55,082] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:29:01,849] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:29:08,633] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:29:16,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:29:24,281] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:29:31,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6987473895074392
[2022-12-06 16:29:31,817] [INFO] [runner_train_mujoco] Average state value: 0.6257348181804021
[2022-12-06 16:29:31,818] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 16:29:31,931] [INFO] [controller] EPOCH 1 loss ppo:  -0.01095, loss val: 0.04199
[2022-12-06 16:29:31,998] [INFO] [controller] EPOCH 2 loss ppo:  -0.01949, loss val: 0.04178
[2022-12-06 16:29:32,101] [INFO] [controller] EPOCH 3 loss ppo:  -0.02800, loss val: 0.04107
[2022-12-06 16:29:32,187] [INFO] [controller] EPOCH 4 loss ppo:  -0.02941, loss val: 0.04139
[2022-12-06 16:29:32,199] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:29:32,414] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:29:32,414] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:29:39,291] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:29:46,817] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:29:53,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:30:00,311] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:30:07,039] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:30:13,572] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:30:19,654] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:30:25,881] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:30:32,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:30:39,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6935596256630994
[2022-12-06 16:30:39,174] [INFO] [runner_train_mujoco] Average state value: 0.6531179427107175
[2022-12-06 16:30:39,174] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 16:30:39,260] [INFO] [controller] EPOCH 1 loss ppo:  -0.01744, loss val: 0.03754
[2022-12-06 16:30:39,314] [INFO] [controller] EPOCH 2 loss ppo:  -0.02649, loss val: 0.03724
[2022-12-06 16:30:39,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.02943, loss val: 0.03681
[2022-12-06 16:30:39,437] [INFO] [controller] EPOCH 4 loss ppo:  -0.03493, loss val: 0.03649
[2022-12-06 16:30:39,448] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:30:39,655] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:30:39,655] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:30:46,120] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:30:52,549] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:30:59,103] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:31:05,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:31:12,381] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:31:18,770] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:31:25,252] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:31:31,438] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:31:37,741] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:31:43,961] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.804360091852842
[2022-12-06 16:31:43,961] [INFO] [runner_train_mujoco] Average state value: 0.6345794049501419
[2022-12-06 16:31:43,962] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 16:31:44,027] [INFO] [controller] EPOCH 1 loss ppo:  -0.01194, loss val: 0.03821
[2022-12-06 16:31:44,089] [INFO] [controller] EPOCH 2 loss ppo:  -0.02034, loss val: 0.03635
[2022-12-06 16:31:44,141] [INFO] [controller] EPOCH 3 loss ppo:  -0.02956, loss val: 0.03490
[2022-12-06 16:31:44,195] [INFO] [controller] EPOCH 4 loss ppo:  -0.03632, loss val: 0.03358
[2022-12-06 16:31:44,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:31:44,399] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:31:44,399] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:31:51,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:31:57,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:32:04,156] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:32:09,978] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:32:15,973] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:32:22,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:32:28,157] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:32:34,803] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:32:40,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:32:46,967] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6845505304808164
[2022-12-06 16:32:46,967] [INFO] [runner_train_mujoco] Average state value: 0.5719639831582705
[2022-12-06 16:32:46,967] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 16:32:47,042] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04216
[2022-12-06 16:32:47,105] [INFO] [controller] EPOCH 2 loss ppo:  -0.02382, loss val: 0.04338
[2022-12-06 16:32:47,193] [INFO] [controller] EPOCH 3 loss ppo:  -0.02693, loss val: 0.04365
[2022-12-06 16:32:47,251] [INFO] [controller] EPOCH 4 loss ppo:  -0.03494, loss val: 0.04246
[2022-12-06 16:32:47,262] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:32:47,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:32:47,456] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:32:53,572] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:32:59,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:33:05,478] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:33:11,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:33:17,809] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:33:23,704] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:33:29,367] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:33:35,138] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:33:40,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:33:46,466] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9100053966882395
[2022-12-06 16:33:46,467] [INFO] [runner_train_mujoco] Average state value: 0.5729277711113293
[2022-12-06 16:33:46,467] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 16:33:46,542] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.03739
[2022-12-06 16:33:46,636] [INFO] [controller] EPOCH 2 loss ppo:  -0.02185, loss val: 0.03279
[2022-12-06 16:33:46,709] [INFO] [controller] EPOCH 3 loss ppo:  -0.02603, loss val: 0.03661
[2022-12-06 16:33:46,762] [INFO] [controller] EPOCH 4 loss ppo:  -0.03190, loss val: 0.03373
[2022-12-06 16:33:46,774] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:33:46,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:33:46,966] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:33:53,291] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:33:59,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:34:05,815] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:34:11,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:34:18,748] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:34:25,533] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:34:32,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:34:39,850] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:34:46,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:34:53,957] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0737815176236696
[2022-12-06 16:34:53,958] [INFO] [runner_train_mujoco] Average state value: 0.6063563848733902
[2022-12-06 16:34:53,958] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 16:34:54,640] [INFO] [controller] EPOCH 1 loss ppo:  -0.01192, loss val: 0.04152
[2022-12-06 16:34:54,787] [INFO] [controller] EPOCH 2 loss ppo:  -0.02363, loss val: 0.04174
[2022-12-06 16:34:54,904] [INFO] [controller] EPOCH 3 loss ppo:  -0.03063, loss val: 0.04116
[2022-12-06 16:34:55,035] [INFO] [controller] EPOCH 4 loss ppo:  -0.03215, loss val: 0.04164
[2022-12-06 16:34:55,049] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:34:55,319] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:34:55,319] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:35:05,129] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:35:13,517] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:35:20,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:35:26,473] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:35:33,335] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:35:39,682] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:35:46,249] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:35:52,214] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:35:58,527] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:36:04,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.216950754411814
[2022-12-06 16:36:04,914] [INFO] [runner_train_mujoco] Average state value: 0.606893570125103
[2022-12-06 16:36:04,914] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 16:36:05,031] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.03867
[2022-12-06 16:36:05,130] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.03970
[2022-12-06 16:36:05,195] [INFO] [controller] EPOCH 3 loss ppo:  -0.02586, loss val: 0.04108
[2022-12-06 16:36:05,248] [INFO] [controller] EPOCH 4 loss ppo:  -0.03115, loss val: 0.03844
[2022-12-06 16:36:05,261] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:36:05,466] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:36:05,466] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:36:11,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:36:19,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:36:27,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:36:36,826] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:36:45,341] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:36:52,114] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:36:59,269] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:37:06,631] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:37:13,625] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:37:20,429] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3170485535438408
[2022-12-06 16:37:20,430] [INFO] [runner_train_mujoco] Average state value: 0.5905386839906375
[2022-12-06 16:37:20,430] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 16:37:20,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04350
[2022-12-06 16:37:20,576] [INFO] [controller] EPOCH 2 loss ppo:  -0.01676, loss val: 0.04265
[2022-12-06 16:37:20,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.02043, loss val: 0.04282
[2022-12-06 16:37:20,720] [INFO] [controller] EPOCH 4 loss ppo:  -0.02762, loss val: 0.04209
[2022-12-06 16:37:20,733] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:37:20,965] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:37:20,965] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:37:28,280] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:37:35,112] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:37:42,034] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:37:48,827] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:37:55,677] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:38:02,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:38:09,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:38:16,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:38:25,863] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:38:37,753] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2414211578254797
[2022-12-06 16:38:37,753] [INFO] [runner_train_mujoco] Average state value: 0.5868885318040847
[2022-12-06 16:38:37,753] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 16:38:37,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01276, loss val: 0.03771
[2022-12-06 16:38:38,037] [INFO] [controller] EPOCH 2 loss ppo:  -0.02293, loss val: 0.03765
[2022-12-06 16:38:38,190] [INFO] [controller] EPOCH 3 loss ppo:  -0.03115, loss val: 0.03745
[2022-12-06 16:38:38,370] [INFO] [controller] EPOCH 4 loss ppo:  -0.03627, loss val: 0.03751
[2022-12-06 16:38:38,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:38:38,672] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:38:38,673] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:38:47,909] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:38:55,459] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:39:02,951] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:39:11,161] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:39:20,538] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:39:29,470] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:39:37,314] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:39:44,984] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:39:52,721] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:39:59,968] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.484720802353756
[2022-12-06 16:39:59,969] [INFO] [runner_train_mujoco] Average state value: 0.574690675397714
[2022-12-06 16:39:59,969] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 16:40:00,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01051, loss val: 0.03600
[2022-12-06 16:40:00,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.01562, loss val: 0.03630
[2022-12-06 16:40:00,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.02343, loss val: 0.03624
[2022-12-06 16:40:00,527] [INFO] [controller] EPOCH 4 loss ppo:  -0.02712, loss val: 0.03525
[2022-12-06 16:40:00,540] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:40:00,775] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:40:00,775] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:40:09,053] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:40:18,256] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:40:25,953] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:40:33,159] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:40:40,372] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:40:47,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:40:54,332] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:41:00,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:41:07,726] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:41:14,133] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4535060835500233
[2022-12-06 16:41:14,134] [INFO] [runner_train_mujoco] Average state value: 0.5681485960880914
[2022-12-06 16:41:14,134] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 16:41:14,218] [INFO] [controller] EPOCH 1 loss ppo:  -0.01256, loss val: 0.03679
[2022-12-06 16:41:14,291] [INFO] [controller] EPOCH 2 loss ppo:  -0.01723, loss val: 0.03993
[2022-12-06 16:41:14,348] [INFO] [controller] EPOCH 3 loss ppo:  -0.02340, loss val: 0.03898
[2022-12-06 16:41:14,402] [INFO] [controller] EPOCH 4 loss ppo:  -0.02433, loss val: 0.03640
[2022-12-06 16:41:14,414] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:41:14,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:41:14,626] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:41:21,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:41:27,720] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:41:34,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:41:40,953] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:41:47,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:54,642] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:42:01,555] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:42:08,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:42:14,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:42:21,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4841145523292454
[2022-12-06 16:42:21,535] [INFO] [runner_train_mujoco] Average state value: 0.5637107624808947
[2022-12-06 16:42:21,535] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 16:42:21,647] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04632
[2022-12-06 16:42:21,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.01599, loss val: 0.04460
[2022-12-06 16:42:21,812] [INFO] [controller] EPOCH 3 loss ppo:  -0.01733, loss val: 0.04582
[2022-12-06 16:42:21,876] [INFO] [controller] EPOCH 4 loss ppo:  -0.02745, loss val: 0.04444
[2022-12-06 16:42:21,888] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:42:22,109] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:42:22,109] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:42:29,111] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:42:35,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:42:41,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:42:47,802] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:42:54,290] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:43:00,808] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:43:07,360] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:43:14,056] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:43:21,243] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:43:28,435] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5027648758595884
[2022-12-06 16:43:28,435] [INFO] [runner_train_mujoco] Average state value: 0.5647288132111231
[2022-12-06 16:43:28,435] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 16:43:28,513] [INFO] [controller] EPOCH 1 loss ppo:  -0.01119, loss val: 0.03846
[2022-12-06 16:43:28,597] [INFO] [controller] EPOCH 2 loss ppo:  -0.01949, loss val: 0.03836
[2022-12-06 16:43:28,666] [INFO] [controller] EPOCH 3 loss ppo:  -0.02282, loss val: 0.03823
[2022-12-06 16:43:28,724] [INFO] [controller] EPOCH 4 loss ppo:  -0.02535, loss val: 0.03911
[2022-12-06 16:43:28,735] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:43:28,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:43:28,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:43:35,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:43:42,221] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:43:48,493] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:43:54,897] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:44:01,539] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:44:08,106] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:44:14,812] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:44:21,747] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:44:29,099] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:44:36,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5352359620048555
[2022-12-06 16:44:36,190] [INFO] [runner_train_mujoco] Average state value: 0.5615492841005325
[2022-12-06 16:44:36,190] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 16:44:36,270] [INFO] [controller] EPOCH 1 loss ppo:  -0.01002, loss val: 0.03976
[2022-12-06 16:44:36,338] [INFO] [controller] EPOCH 2 loss ppo:  -0.01589, loss val: 0.03965
[2022-12-06 16:44:36,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.02501, loss val: 0.03876
[2022-12-06 16:44:36,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.02901, loss val: 0.03855
[2022-12-06 16:44:36,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:44:36,715] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:44:36,715] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:44:43,391] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:44:50,578] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:44:57,413] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:45:04,436] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:45:11,218] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:45:18,044] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:45:26,924] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:45:34,651] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:45:42,660] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:45:50,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.71914513674448
[2022-12-06 16:45:50,230] [INFO] [runner_train_mujoco] Average state value: 0.536992016851902
[2022-12-06 16:45:50,230] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 16:45:50,383] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.04100
[2022-12-06 16:45:50,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.02064, loss val: 0.04162
[2022-12-06 16:45:50,647] [INFO] [controller] EPOCH 3 loss ppo:  -0.02403, loss val: 0.04156
[2022-12-06 16:45:50,795] [INFO] [controller] EPOCH 4 loss ppo:  -0.02696, loss val: 0.04101
[2022-12-06 16:45:50,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:45:51,057] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:45:51,057] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:45:58,660] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:46:06,629] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:46:14,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:46:23,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:46:30,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:46:38,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:46:45,670] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:46:53,852] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:47:01,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:47:08,795] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6689110991839247
[2022-12-06 16:47:08,795] [INFO] [runner_train_mujoco] Average state value: 0.534488972723484
[2022-12-06 16:47:08,796] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 16:47:08,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01161, loss val: 0.04574
[2022-12-06 16:47:08,941] [INFO] [controller] EPOCH 2 loss ppo:  -0.01700, loss val: 0.04541
[2022-12-06 16:47:09,015] [INFO] [controller] EPOCH 3 loss ppo:  -0.01900, loss val: 0.04523
[2022-12-06 16:47:09,078] [INFO] [controller] EPOCH 4 loss ppo:  -0.02343, loss val: 0.04526
[2022-12-06 16:47:09,091] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:47:09,303] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:47:09,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:47:16,816] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:47:24,865] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:47:32,296] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:47:39,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:47:46,189] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:47:53,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:48:00,823] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:48:08,237] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:48:14,512] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:48:22,150] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6007569088834956
[2022-12-06 16:48:22,150] [INFO] [runner_train_mujoco] Average state value: 0.5577250048319498
[2022-12-06 16:48:22,150] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 16:48:22,250] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.03992
[2022-12-06 16:48:22,314] [INFO] [controller] EPOCH 2 loss ppo:  -0.02014, loss val: 0.03868
[2022-12-06 16:48:22,383] [INFO] [controller] EPOCH 3 loss ppo:  -0.01999, loss val: 0.04014
[2022-12-06 16:48:22,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.02411, loss val: 0.04029
[2022-12-06 16:48:22,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:48:22,692] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:48:22,692] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:48:31,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:48:38,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:48:45,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:48:52,107] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:48:58,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:49:05,173] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:49:11,959] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:49:19,789] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:49:26,939] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:49:34,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.805046535442137
[2022-12-06 16:49:34,324] [INFO] [runner_train_mujoco] Average state value: 0.5604682374596596
[2022-12-06 16:49:34,325] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 16:49:34,469] [INFO] [controller] EPOCH 1 loss ppo:  -0.01126, loss val: 0.04473
[2022-12-06 16:49:34,623] [INFO] [controller] EPOCH 2 loss ppo:  -0.01824, loss val: 0.04541
[2022-12-06 16:49:34,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.02159, loss val: 0.04495
[2022-12-06 16:49:34,789] [INFO] [controller] EPOCH 4 loss ppo:  -0.02573, loss val: 0.04480
[2022-12-06 16:49:34,804] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:49:35,028] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:49:35,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:49:42,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:49:49,848] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:49:56,513] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:50:02,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:50:09,248] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:50:16,133] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:50:24,306] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:50:32,230] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:50:39,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:50:46,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8927705387046743
[2022-12-06 16:50:46,342] [INFO] [runner_train_mujoco] Average state value: 0.5518799848357838
[2022-12-06 16:50:46,342] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 16:50:46,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01313, loss val: 0.04456
[2022-12-06 16:50:46,485] [INFO] [controller] EPOCH 2 loss ppo:  -0.01864, loss val: 0.04475
[2022-12-06 16:50:46,608] [INFO] [controller] EPOCH 3 loss ppo:  -0.01907, loss val: 0.04450
[2022-12-06 16:50:46,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.02354, loss val: 0.04567
[2022-12-06 16:50:46,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:50:46,918] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:50:46,919] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:50:53,966] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:51:01,542] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:51:08,724] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:51:16,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:51:23,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:51:31,549] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:51:39,307] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:51:46,120] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:51:53,085] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:52:00,231] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.932158853560222
[2022-12-06 16:52:00,232] [INFO] [runner_train_mujoco] Average state value: 0.5586652463475863
[2022-12-06 16:52:00,232] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 16:52:00,478] [INFO] [controller] EPOCH 1 loss ppo:  -0.01085, loss val: 0.04184
[2022-12-06 16:52:00,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.01473, loss val: 0.04294
[2022-12-06 16:52:00,733] [INFO] [controller] EPOCH 3 loss ppo:  -0.01696, loss val: 0.04365
[2022-12-06 16:52:00,797] [INFO] [controller] EPOCH 4 loss ppo:  -0.02209, loss val: 0.04239
[2022-12-06 16:52:00,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:52:01,026] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:52:01,027] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:52:08,236] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:52:15,256] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:52:22,304] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:52:28,838] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:52:35,674] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:52:42,404] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:52:49,227] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:52:56,018] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:53:02,812] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:53:09,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.988851336368127
[2022-12-06 16:53:09,372] [INFO] [runner_train_mujoco] Average state value: 0.5629791491627694
[2022-12-06 16:53:09,372] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 16:53:09,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01275, loss val: 0.04491
[2022-12-06 16:53:09,500] [INFO] [controller] EPOCH 2 loss ppo:  -0.01526, loss val: 0.04512
[2022-12-06 16:53:09,553] [INFO] [controller] EPOCH 3 loss ppo:  -0.01522, loss val: 0.04506
[2022-12-06 16:53:09,639] [INFO] [controller] EPOCH 4 loss ppo:  -0.02056, loss val: 0.04590
[2022-12-06 16:53:09,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:53:09,895] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:53:09,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:53:16,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:53:22,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:53:29,289] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:53:35,794] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:53:42,380] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:53:48,718] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:53:55,187] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:54:01,605] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:54:07,949] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:54:14,721] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9735544894016117
[2022-12-06 16:54:14,722] [INFO] [runner_train_mujoco] Average state value: 0.5587631921569506
[2022-12-06 16:54:14,722] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 16:54:14,922] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.05003
[2022-12-06 16:54:15,069] [INFO] [controller] EPOCH 2 loss ppo:  -0.01920, loss val: 0.05053
[2022-12-06 16:54:15,157] [INFO] [controller] EPOCH 3 loss ppo:  -0.02078, loss val: 0.05023
[2022-12-06 16:54:15,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.02494, loss val: 0.05096
[2022-12-06 16:54:15,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:54:15,419] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:54:15,419] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:54:22,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:54:28,645] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:54:34,771] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:54:41,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:54:47,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:54:53,348] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:54:59,455] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:55:05,509] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:55:11,439] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:55:17,572] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0754756076581753
[2022-12-06 16:55:17,572] [INFO] [runner_train_mujoco] Average state value: 0.5587993131875992
[2022-12-06 16:55:17,573] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 16:55:17,638] [INFO] [controller] EPOCH 1 loss ppo:  -0.01158, loss val: 0.04810
[2022-12-06 16:55:17,773] [INFO] [controller] EPOCH 2 loss ppo:  -0.01432, loss val: 0.04928
[2022-12-06 16:55:17,829] [INFO] [controller] EPOCH 3 loss ppo:  -0.01693, loss val: 0.04721
[2022-12-06 16:55:17,879] [INFO] [controller] EPOCH 4 loss ppo:  -0.02193, loss val: 0.04968
[2022-12-06 16:55:17,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:55:18,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:55:18,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:55:24,551] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:55:30,883] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:55:37,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:55:43,200] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:55:49,233] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:55:55,207] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:56:01,123] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:56:07,129] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:56:13,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:56:19,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.236854047375325
[2022-12-06 16:56:19,028] [INFO] [runner_train_mujoco] Average state value: 0.5681961608926455
[2022-12-06 16:56:19,028] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 16:56:19,113] [INFO] [controller] EPOCH 1 loss ppo:  -0.01221, loss val: 0.04552
[2022-12-06 16:56:19,167] [INFO] [controller] EPOCH 2 loss ppo:  -0.01656, loss val: 0.04533
[2022-12-06 16:56:19,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.01769, loss val: 0.04566
[2022-12-06 16:56:19,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.01965, loss val: 0.04490
[2022-12-06 16:56:19,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:56:19,492] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:56:19,493] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:56:25,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:56:32,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:56:39,309] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:56:45,810] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:56:52,213] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:56:58,722] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:57:05,579] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:57:11,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:57:18,119] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:57:24,104] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.218112520435534
[2022-12-06 16:57:24,104] [INFO] [runner_train_mujoco] Average state value: 0.5535423377950986
[2022-12-06 16:57:24,104] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 16:57:24,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.01185, loss val: 0.04776
[2022-12-06 16:57:24,270] [INFO] [controller] EPOCH 2 loss ppo:  -0.01680, loss val: 0.04769
[2022-12-06 16:57:24,330] [INFO] [controller] EPOCH 3 loss ppo:  -0.01810, loss val: 0.04765
[2022-12-06 16:57:24,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.02240, loss val: 0.04790
[2022-12-06 16:57:24,431] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:57:24,653] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:57:24,653] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:57:31,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:57:38,093] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:57:44,080] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:57:50,052] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:57:56,697] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:58:03,390] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:58:09,662] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:58:16,432] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:58:22,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:58:29,264] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3211221611643267
[2022-12-06 16:58:29,264] [INFO] [runner_train_mujoco] Average state value: 0.5420352887908617
[2022-12-06 16:58:29,264] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 16:58:29,341] [INFO] [controller] EPOCH 1 loss ppo:  -0.01218, loss val: 0.04646
[2022-12-06 16:58:29,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.01612, loss val: 0.04615
[2022-12-06 16:58:29,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.01810, loss val: 0.04609
[2022-12-06 16:58:29,548] [INFO] [controller] EPOCH 4 loss ppo:  -0.02025, loss val: 0.04609
[2022-12-06 16:58:29,562] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:58:29,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:58:29,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:58:36,580] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:58:43,695] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:58:51,026] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:58:58,041] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:59:05,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:59:12,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:59:20,287] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:59:26,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:59:33,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:59:40,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3135425052915446
[2022-12-06 16:59:40,696] [INFO] [runner_train_mujoco] Average state value: 0.5311554461916288
[2022-12-06 16:59:40,697] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 16:59:40,824] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.04302
[2022-12-06 16:59:40,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.01577, loss val: 0.04416
[2022-12-06 16:59:40,984] [INFO] [controller] EPOCH 3 loss ppo:  -0.01857, loss val: 0.04342
[2022-12-06 16:59:41,066] [INFO] [controller] EPOCH 4 loss ppo:  -0.01846, loss val: 0.04268
[2022-12-06 16:59:41,080] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:59:41,318] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:59:41,319] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:59:48,666] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:59:55,779] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:00:03,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:00:10,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:00:16,885] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:00:23,544] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:00:30,357] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:00:36,823] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:00:43,684] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:00:50,283] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.384930200702892
[2022-12-06 17:00:50,284] [INFO] [runner_train_mujoco] Average state value: 0.5195136821071307
[2022-12-06 17:00:50,284] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 17:00:50,433] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.04475
[2022-12-06 17:00:50,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01474, loss val: 0.04451
[2022-12-06 17:00:51,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.01847, loss val: 0.04342
[2022-12-06 17:00:51,728] [INFO] [controller] EPOCH 4 loss ppo:  -0.02034, loss val: 0.04366
[2022-12-06 17:00:51,743] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:00:51,969] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:00:51,970] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:00:58,480] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:01:05,587] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:01:12,199] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:01:18,407] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:01:24,855] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:01:31,466] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:01:37,979] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:01:45,365] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:01:52,020] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:01:58,786] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.428503430385598
[2022-12-06 17:01:58,787] [INFO] [runner_train_mujoco] Average state value: 0.5107621466318767
[2022-12-06 17:01:58,787] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 17:01:58,911] [INFO] [controller] EPOCH 1 loss ppo:  -0.01171, loss val: 0.04746
[2022-12-06 17:01:58,995] [INFO] [controller] EPOCH 2 loss ppo:  -0.01550, loss val: 0.04795
[2022-12-06 17:01:59,065] [INFO] [controller] EPOCH 3 loss ppo:  -0.01876, loss val: 0.04848
[2022-12-06 17:01:59,162] [INFO] [controller] EPOCH 4 loss ppo:  -0.01807, loss val: 0.04805
[2022-12-06 17:01:59,177] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:01:59,408] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:01:59,409] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:02:06,377] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:02:13,473] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:02:20,067] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:02:26,976] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:02:33,550] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:02:39,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:02:46,262] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:02:52,184] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:02:58,263] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:03:04,927] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4530948429433748
[2022-12-06 17:03:04,928] [INFO] [runner_train_mujoco] Average state value: 0.5052154146234193
[2022-12-06 17:03:04,928] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 17:03:05,001] [INFO] [controller] EPOCH 1 loss ppo:  -0.01158, loss val: 0.05022
[2022-12-06 17:03:05,072] [INFO] [controller] EPOCH 2 loss ppo:  -0.01438, loss val: 0.04887
[2022-12-06 17:03:05,147] [INFO] [controller] EPOCH 3 loss ppo:  -0.01822, loss val: 0.04997
[2022-12-06 17:03:05,210] [INFO] [controller] EPOCH 4 loss ppo:  -0.02065, loss val: 0.05028
[2022-12-06 17:03:05,224] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:03:05,434] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:03:05,434] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:03:11,738] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:03:18,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:03:24,292] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:03:30,045] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:03:36,172] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:03:42,522] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:03:48,647] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:03:54,659] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:04:00,591] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:04:06,677] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5904796655907716
[2022-12-06 17:04:06,677] [INFO] [runner_train_mujoco] Average state value: 0.5046688430309295
[2022-12-06 17:04:06,677] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 17:04:06,760] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.04513
[2022-12-06 17:04:06,837] [INFO] [controller] EPOCH 2 loss ppo:  -0.01475, loss val: 0.04571
[2022-12-06 17:04:06,909] [INFO] [controller] EPOCH 3 loss ppo:  -0.01777, loss val: 0.04574
[2022-12-06 17:04:06,999] [INFO] [controller] EPOCH 4 loss ppo:  -0.01828, loss val: 0.04523
[2022-12-06 17:04:07,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:04:07,218] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:04:07,218] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:04:13,108] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:04:19,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:04:25,082] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:04:31,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:04:37,627] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:04:44,063] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:04:50,181] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:04:57,282] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:05:03,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:05:08,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5548370541825074
[2022-12-06 17:05:08,783] [INFO] [runner_train_mujoco] Average state value: 0.5058751968741417
[2022-12-06 17:05:08,783] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 17:05:08,851] [INFO] [controller] EPOCH 1 loss ppo:  -0.01164, loss val: 0.04924
[2022-12-06 17:05:08,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.01278, loss val: 0.04771
[2022-12-06 17:05:08,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.01444, loss val: 0.04898
[2022-12-06 17:05:09,079] [INFO] [controller] EPOCH 4 loss ppo:  -0.01667, loss val: 0.04773
[2022-12-06 17:05:09,090] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:05:09,302] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:05:09,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:05:15,227] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:05:21,036] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:05:26,932] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:05:33,737] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:05:40,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:05:46,731] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:05:53,322] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:06:00,112] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:06:06,568] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:06:13,051] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5816955341152914
[2022-12-06 17:06:13,052] [INFO] [runner_train_mujoco] Average state value: 0.5078838994304339
[2022-12-06 17:06:13,052] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 17:06:13,198] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.04422
[2022-12-06 17:06:13,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.01316, loss val: 0.04444
[2022-12-06 17:06:13,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.01492, loss val: 0.04407
[2022-12-06 17:06:13,501] [INFO] [controller] EPOCH 4 loss ppo:  -0.01733, loss val: 0.04588
[2022-12-06 17:06:13,513] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:06:13,737] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:06:13,738] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:06:21,051] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:06:28,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:06:35,029] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:06:41,000] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:06:47,437] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:06:54,736] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:07:02,152] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:07:11,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:07:18,887] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:07:25,782] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4750362771704544
[2022-12-06 17:07:25,783] [INFO] [runner_train_mujoco] Average state value: 0.51266789239645
[2022-12-06 17:07:25,783] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 17:07:25,904] [INFO] [controller] EPOCH 1 loss ppo:  -0.01151, loss val: 0.04403
[2022-12-06 17:07:26,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.01207, loss val: 0.04373
[2022-12-06 17:07:26,109] [INFO] [controller] EPOCH 3 loss ppo:  -0.01279, loss val: 0.04382
[2022-12-06 17:07:26,236] [INFO] [controller] EPOCH 4 loss ppo:  -0.01363, loss val: 0.04378
[2022-12-06 17:07:26,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:07:26,432] [INFO] [optimize] Finished learning.
