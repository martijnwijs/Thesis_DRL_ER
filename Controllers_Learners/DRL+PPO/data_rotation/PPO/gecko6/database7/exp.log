[2022-12-07 04:43:09,261] [INFO] [optimize] Starting learning
[2022-12-07 04:43:09,270] [INFO] [optimize] Starting learning process..
[2022-12-07 04:43:09,325] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:43:09,326] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:43:15,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:43:21,176] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:43:26,613] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:43:31,315] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:43:35,885] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:43:41,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:43:46,425] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:43:51,108] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:43:55,386] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:44:00,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17447075199370438
[2022-12-07 04:44:00,054] [INFO] [runner_train_mujoco] Average state value: -0.06625873389467597
[2022-12-07 04:44:00,055] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 04:44:00,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.01727, loss val: 0.47319
[2022-12-07 04:44:00,154] [INFO] [controller] EPOCH 2 loss ppo:  -0.02760, loss val: 0.40736
[2022-12-07 04:44:00,192] [INFO] [controller] EPOCH 3 loss ppo:  -0.03513, loss val: 0.35283
[2022-12-07 04:44:00,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.03531, loss val: 0.31016
[2022-12-07 04:44:00,242] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:44:00,402] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:44:00,402] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:44:05,053] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:44:09,863] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:44:14,907] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:44:19,693] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:44:24,363] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:44:29,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:44:33,560] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:44:38,203] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:44:42,689] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:44:47,233] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.1611312509714389
[2022-12-07 04:44:47,234] [INFO] [runner_train_mujoco] Average state value: 0.11209307281610865
[2022-12-07 04:44:47,234] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 04:44:47,288] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.17937
[2022-12-07 04:44:47,336] [INFO] [controller] EPOCH 2 loss ppo:  -0.02757, loss val: 0.15542
[2022-12-07 04:44:47,387] [INFO] [controller] EPOCH 3 loss ppo:  -0.03063, loss val: 0.13589
[2022-12-07 04:44:47,434] [INFO] [controller] EPOCH 4 loss ppo:  -0.03309, loss val: 0.10185
[2022-12-07 04:44:47,443] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:44:47,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:44:47,606] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:44:52,071] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:44:56,902] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:45:03,568] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:45:08,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:45:14,224] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:45:19,783] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:45:25,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:45:31,414] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:45:37,289] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:45:42,650] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.18735010995728915
[2022-12-07 04:45:42,651] [INFO] [runner_train_mujoco] Average state value: 0.29724663033895193
[2022-12-07 04:45:42,651] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 04:45:42,723] [INFO] [controller] EPOCH 1 loss ppo:  -0.01204, loss val: 0.12861
[2022-12-07 04:45:42,777] [INFO] [controller] EPOCH 2 loss ppo:  -0.02200, loss val: 0.10636
[2022-12-07 04:45:42,849] [INFO] [controller] EPOCH 3 loss ppo:  -0.02920, loss val: 0.08639
[2022-12-07 04:45:42,915] [INFO] [controller] EPOCH 4 loss ppo:  -0.03324, loss val: 0.07182
[2022-12-07 04:45:42,925] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:45:43,141] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:45:43,141] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:45:49,378] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:45:55,041] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:46:00,651] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:46:06,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:46:12,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:46:18,333] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:46:24,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:46:29,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:46:35,241] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:46:41,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.20249061113977315
[2022-12-07 04:46:41,372] [INFO] [runner_train_mujoco] Average state value: 0.44666524247204265
[2022-12-07 04:46:41,372] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 04:46:41,453] [INFO] [controller] EPOCH 1 loss ppo:  -0.01158, loss val: 0.10223
[2022-12-07 04:46:41,524] [INFO] [controller] EPOCH 2 loss ppo:  -0.02299, loss val: 0.08210
[2022-12-07 04:46:41,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.02798, loss val: 0.06731
[2022-12-07 04:46:41,673] [INFO] [controller] EPOCH 4 loss ppo:  -0.03341, loss val: 0.05526
[2022-12-07 04:46:41,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:46:41,860] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:46:41,861] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:46:47,543] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:46:53,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:46:59,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:47:05,136] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:47:11,057] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:47:16,551] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:47:22,469] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:47:28,257] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:47:34,007] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:47:39,952] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22888210791650215
[2022-12-07 04:47:39,952] [INFO] [runner_train_mujoco] Average state value: 0.6251615647276243
[2022-12-07 04:47:39,952] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 04:47:40,007] [INFO] [controller] EPOCH 1 loss ppo:  -0.00786, loss val: 0.04269
[2022-12-07 04:47:40,054] [INFO] [controller] EPOCH 2 loss ppo:  -0.02049, loss val: 0.04062
[2022-12-07 04:47:40,101] [INFO] [controller] EPOCH 3 loss ppo:  -0.02471, loss val: 0.03993
[2022-12-07 04:47:40,147] [INFO] [controller] EPOCH 4 loss ppo:  -0.02997, loss val: 0.04010
[2022-12-07 04:47:40,157] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:47:40,327] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:47:40,328] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:47:45,830] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:47:51,014] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:47:56,664] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:48:01,754] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:48:07,044] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:48:11,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:48:17,066] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:48:22,557] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:48:27,733] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:48:33,058] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22337063135888893
[2022-12-07 04:48:33,059] [INFO] [runner_train_mujoco] Average state value: 0.7099030066331227
[2022-12-07 04:48:33,059] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 04:48:33,119] [INFO] [controller] EPOCH 1 loss ppo:  -0.00470, loss val: 0.04121
[2022-12-07 04:48:33,184] [INFO] [controller] EPOCH 2 loss ppo:  -0.01986, loss val: 0.03989
[2022-12-07 04:48:33,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.02513, loss val: 0.03995
[2022-12-07 04:48:33,286] [INFO] [controller] EPOCH 4 loss ppo:  -0.02923, loss val: 0.03946
[2022-12-07 04:48:33,298] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:48:33,478] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:48:33,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:48:38,264] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:48:44,019] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:48:49,472] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:48:54,672] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:49:00,040] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:49:05,401] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:49:10,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:49:16,127] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:49:21,144] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:49:26,388] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21055201156512604
[2022-12-07 04:49:26,389] [INFO] [runner_train_mujoco] Average state value: 0.7371945906480153
[2022-12-07 04:49:26,389] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 04:49:26,448] [INFO] [controller] EPOCH 1 loss ppo:  -0.00692, loss val: 0.04291
[2022-12-07 04:49:26,493] [INFO] [controller] EPOCH 2 loss ppo:  -0.01547, loss val: 0.04245
[2022-12-07 04:49:26,543] [INFO] [controller] EPOCH 3 loss ppo:  -0.02100, loss val: 0.04068
[2022-12-07 04:49:26,596] [INFO] [controller] EPOCH 4 loss ppo:  -0.02681, loss val: 0.03920
[2022-12-07 04:49:26,605] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:49:26,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:49:26,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:49:31,639] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:49:36,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:49:42,064] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:49:47,381] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:49:52,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:49:57,923] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:03,270] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:50:08,600] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:50:13,724] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:50:18,926] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.17837221385498073
[2022-12-07 04:50:18,926] [INFO] [runner_train_mujoco] Average state value: 0.6880533400177955
[2022-12-07 04:50:18,926] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 04:50:18,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.00483, loss val: 0.04382
[2022-12-07 04:50:19,034] [INFO] [controller] EPOCH 2 loss ppo:  -0.01924, loss val: 0.04646
[2022-12-07 04:50:19,086] [INFO] [controller] EPOCH 3 loss ppo:  -0.02239, loss val: 0.04578
[2022-12-07 04:50:19,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.02856, loss val: 0.04420
[2022-12-07 04:50:19,147] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:50:19,324] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:50:19,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:50:24,880] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:50:29,718] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:50:34,685] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:50:39,852] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:50:44,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:50:50,080] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:55,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:51:00,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:51:06,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:51:11,437] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.24054965604606754
[2022-12-07 04:51:11,437] [INFO] [runner_train_mujoco] Average state value: 0.7018862281640371
[2022-12-07 04:51:11,437] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 04:51:11,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.00600, loss val: 0.03679
[2022-12-07 04:51:11,590] [INFO] [controller] EPOCH 2 loss ppo:  -0.01718, loss val: 0.03785
[2022-12-07 04:51:11,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.02312, loss val: 0.03659
[2022-12-07 04:51:11,751] [INFO] [controller] EPOCH 4 loss ppo:  -0.03095, loss val: 0.03594
[2022-12-07 04:51:11,761] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:51:11,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:51:11,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:51:17,261] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:51:22,581] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:51:27,676] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:51:33,089] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:51:38,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:51:43,556] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:51:48,802] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:51:54,032] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:51:59,393] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:52:04,398] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.235106283186889
[2022-12-07 04:52:04,399] [INFO] [runner_train_mujoco] Average state value: 0.6870092973311742
[2022-12-07 04:52:04,399] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 04:52:04,470] [INFO] [controller] EPOCH 1 loss ppo:  -0.00561, loss val: 0.03932
[2022-12-07 04:52:04,524] [INFO] [controller] EPOCH 2 loss ppo:  -0.01683, loss val: 0.03972
[2022-12-07 04:52:04,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.02268, loss val: 0.03999
[2022-12-07 04:52:04,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.02534, loss val: 0.04029
[2022-12-07 04:52:04,671] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:52:04,866] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:52:04,866] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:52:10,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:52:15,588] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:52:20,829] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:52:26,009] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:52:31,412] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:52:36,450] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:52:41,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:52:46,658] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:52:51,078] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:52:55,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.22967123144091053
[2022-12-07 04:52:55,562] [INFO] [runner_train_mujoco] Average state value: 0.6779328253865242
[2022-12-07 04:52:55,562] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 04:52:55,629] [INFO] [controller] EPOCH 1 loss ppo:  -0.00672, loss val: 0.04282
[2022-12-07 04:52:55,705] [INFO] [controller] EPOCH 2 loss ppo:  -0.01809, loss val: 0.04238
[2022-12-07 04:52:55,766] [INFO] [controller] EPOCH 3 loss ppo:  -0.02135, loss val: 0.04115
[2022-12-07 04:52:55,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.02669, loss val: 0.04244
[2022-12-07 04:52:55,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:52:56,005] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:52:56,005] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:01,469] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:53:06,950] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:53:13,470] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:53:19,018] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:53:24,059] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:53:29,336] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:53:34,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:53:39,039] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:53:44,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:53:49,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.21662043582775561
[2022-12-07 04:53:49,275] [INFO] [runner_train_mujoco] Average state value: 0.716376505057017
[2022-12-07 04:53:49,275] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 04:53:49,331] [INFO] [controller] EPOCH 1 loss ppo:  -0.00793, loss val: 0.04080
[2022-12-07 04:53:49,379] [INFO] [controller] EPOCH 2 loss ppo:  -0.02055, loss val: 0.04017
[2022-12-07 04:53:49,423] [INFO] [controller] EPOCH 3 loss ppo:  -0.02357, loss val: 0.03986
[2022-12-07 04:53:49,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.02753, loss val: 0.03826
[2022-12-07 04:53:49,477] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:53:49,653] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:53:49,653] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:55,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:54:00,154] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:54:05,466] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:54:10,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:54:15,921] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:54:20,848] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:54:26,077] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:54:30,962] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:54:36,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:54:40,729] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2159823588660046
[2022-12-07 04:54:40,730] [INFO] [runner_train_mujoco] Average state value: 0.6769851020971934
[2022-12-07 04:54:40,730] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 04:54:40,782] [INFO] [controller] EPOCH 1 loss ppo:  -0.00557, loss val: 0.04276
[2022-12-07 04:54:40,829] [INFO] [controller] EPOCH 2 loss ppo:  -0.01485, loss val: 0.04139
[2022-12-07 04:54:40,877] [INFO] [controller] EPOCH 3 loss ppo:  -0.02308, loss val: 0.04120
[2022-12-07 04:54:40,920] [INFO] [controller] EPOCH 4 loss ppo:  -0.02946, loss val: 0.04136
[2022-12-07 04:54:40,929] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:54:41,097] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:54:41,098] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:54:46,554] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:54:51,797] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:54:56,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:55:01,968] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:55:07,312] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:55:12,172] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:55:17,024] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:55:22,276] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:55:27,309] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:55:32,409] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.30253141947078727
[2022-12-07 04:55:32,409] [INFO] [runner_train_mujoco] Average state value: 0.6613680492838222
[2022-12-07 04:55:32,409] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 04:55:32,467] [INFO] [controller] EPOCH 1 loss ppo:  -0.00692, loss val: 0.04454
[2022-12-07 04:55:32,522] [INFO] [controller] EPOCH 2 loss ppo:  -0.01575, loss val: 0.04342
[2022-12-07 04:55:32,572] [INFO] [controller] EPOCH 3 loss ppo:  -0.01902, loss val: 0.04278
[2022-12-07 04:55:32,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.02429, loss val: 0.04214
[2022-12-07 04:55:32,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:55:32,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:55:32,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:55:37,618] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:55:42,681] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:55:47,951] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:55:52,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:55:57,879] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:56:03,271] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:56:08,366] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:56:13,436] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:56:18,619] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:56:23,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.395071049532192
[2022-12-07 04:56:23,824] [INFO] [runner_train_mujoco] Average state value: 0.7190195600986481
[2022-12-07 04:56:23,824] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 04:56:23,891] [INFO] [controller] EPOCH 1 loss ppo:  -0.00824, loss val: 0.04177
[2022-12-07 04:56:23,953] [INFO] [controller] EPOCH 2 loss ppo:  -0.02166, loss val: 0.04175
[2022-12-07 04:56:24,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.02671, loss val: 0.04161
[2022-12-07 04:56:24,072] [INFO] [controller] EPOCH 4 loss ppo:  -0.02769, loss val: 0.04087
[2022-12-07 04:56:24,081] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:56:24,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:56:24,247] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:56:29,573] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:56:34,434] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:56:39,980] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:56:45,342] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:56:50,604] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:56:55,546] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:57:00,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:57:05,667] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:57:10,848] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:57:15,704] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.412367266615666
[2022-12-07 04:57:15,704] [INFO] [runner_train_mujoco] Average state value: 0.7064555900494257
[2022-12-07 04:57:15,704] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 04:57:15,763] [INFO] [controller] EPOCH 1 loss ppo:  -0.00766, loss val: 0.03935
[2022-12-07 04:57:15,811] [INFO] [controller] EPOCH 2 loss ppo:  -0.02217, loss val: 0.04039
[2022-12-07 04:57:15,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.02422, loss val: 0.03940
[2022-12-07 04:57:15,922] [INFO] [controller] EPOCH 4 loss ppo:  -0.02956, loss val: 0.04052
[2022-12-07 04:57:15,932] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:57:16,105] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:57:16,105] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:57:21,356] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:57:26,352] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:57:31,522] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:57:36,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:57:41,436] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:57:47,184] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:57:52,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:57:58,716] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:58:03,973] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:58:09,176] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42729265572254216
[2022-12-07 04:58:09,176] [INFO] [runner_train_mujoco] Average state value: 0.6896798094511032
[2022-12-07 04:58:09,176] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 04:58:09,228] [INFO] [controller] EPOCH 1 loss ppo:  -0.00855, loss val: 0.03824
[2022-12-07 04:58:09,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.01870, loss val: 0.03821
[2022-12-07 04:58:09,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.02093, loss val: 0.03815
[2022-12-07 04:58:09,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.02849, loss val: 0.03799
[2022-12-07 04:58:09,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:58:09,539] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:58:09,540] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:58:14,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:58:19,930] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:58:25,178] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:58:30,424] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:58:35,479] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:58:40,291] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:58:45,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:58:50,461] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:58:55,142] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:59:00,171] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5857710682656115
[2022-12-07 04:59:00,171] [INFO] [runner_train_mujoco] Average state value: 0.6845047618548076
[2022-12-07 04:59:00,171] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 04:59:00,240] [INFO] [controller] EPOCH 1 loss ppo:  -0.00995, loss val: 0.03694
[2022-12-07 04:59:00,293] [INFO] [controller] EPOCH 2 loss ppo:  -0.01751, loss val: 0.03697
[2022-12-07 04:59:00,363] [INFO] [controller] EPOCH 3 loss ppo:  -0.01784, loss val: 0.03639
[2022-12-07 04:59:00,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.02355, loss val: 0.03563
[2022-12-07 04:59:00,428] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:59:00,604] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:59:00,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:59:05,690] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:59:10,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:59:15,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:59:20,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:59:26,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:59:31,567] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:59:36,620] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:59:41,424] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:59:46,520] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:59:51,646] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5926758376875358
[2022-12-07 04:59:51,647] [INFO] [runner_train_mujoco] Average state value: 0.6597659830848377
[2022-12-07 04:59:51,647] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 04:59:51,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.00994, loss val: 0.04156
[2022-12-07 04:59:51,766] [INFO] [controller] EPOCH 2 loss ppo:  -0.02019, loss val: 0.04121
[2022-12-07 04:59:51,821] [INFO] [controller] EPOCH 3 loss ppo:  -0.02458, loss val: 0.04131
[2022-12-07 04:59:51,865] [INFO] [controller] EPOCH 4 loss ppo:  -0.03141, loss val: 0.04078
[2022-12-07 04:59:51,875] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:59:52,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:59:52,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:59:56,928] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:00:02,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:00:07,343] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:00:12,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:00:16,885] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:00:21,620] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:00:26,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:00:31,941] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:00:36,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:00:41,860] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7502141340269344
[2022-12-07 05:00:41,861] [INFO] [runner_train_mujoco] Average state value: 0.6709261240164439
[2022-12-07 05:00:41,861] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:00:41,915] [INFO] [controller] EPOCH 1 loss ppo:  -0.00966, loss val: 0.04192
[2022-12-07 05:00:41,959] [INFO] [controller] EPOCH 2 loss ppo:  -0.01921, loss val: 0.04183
[2022-12-07 05:00:42,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.02717, loss val: 0.04169
[2022-12-07 05:00:42,045] [INFO] [controller] EPOCH 4 loss ppo:  -0.03149, loss val: 0.04174
[2022-12-07 05:00:42,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:00:42,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:00:42,221] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:00:47,038] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:00:51,760] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:00:56,604] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:01:02,053] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:01:07,191] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:01:12,152] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:01:17,250] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:01:21,895] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:01:27,046] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:01:32,242] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8764104133874955
[2022-12-07 05:01:32,243] [INFO] [runner_train_mujoco] Average state value: 0.6858511941631635
[2022-12-07 05:01:32,243] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 05:01:32,300] [INFO] [controller] EPOCH 1 loss ppo:  -0.00920, loss val: 0.03691
[2022-12-07 05:01:32,343] [INFO] [controller] EPOCH 2 loss ppo:  -0.01659, loss val: 0.03838
[2022-12-07 05:01:32,394] [INFO] [controller] EPOCH 3 loss ppo:  -0.02094, loss val: 0.03789
[2022-12-07 05:01:32,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.02806, loss val: 0.03875
[2022-12-07 05:01:32,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:01:32,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:01:32,618] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:01:37,806] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:01:42,844] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:01:47,678] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:01:52,392] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:01:56,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:02:01,729] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:02:06,656] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:02:11,582] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:02:16,654] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:02:21,823] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9557189799986736
[2022-12-07 05:02:21,823] [INFO] [runner_train_mujoco] Average state value: 0.686344992717107
[2022-12-07 05:02:21,824] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 05:02:21,884] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.04322
[2022-12-07 05:02:21,929] [INFO] [controller] EPOCH 2 loss ppo:  -0.02482, loss val: 0.04172
[2022-12-07 05:02:21,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.02646, loss val: 0.04151
[2022-12-07 05:02:22,018] [INFO] [controller] EPOCH 4 loss ppo:  -0.03062, loss val: 0.04134
[2022-12-07 05:02:22,027] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:02:22,191] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:02:22,191] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:02:27,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:02:32,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:02:37,257] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:02:42,490] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:02:47,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:02:52,244] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:02:57,155] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:03:01,947] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:03:06,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:03:11,897] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.968953909903054
[2022-12-07 05:03:11,897] [INFO] [runner_train_mujoco] Average state value: 0.6615013501048088
[2022-12-07 05:03:11,897] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 05:03:11,967] [INFO] [controller] EPOCH 1 loss ppo:  -0.01110, loss val: 0.04087
[2022-12-07 05:03:12,087] [INFO] [controller] EPOCH 2 loss ppo:  -0.02073, loss val: 0.04094
[2022-12-07 05:03:12,134] [INFO] [controller] EPOCH 3 loss ppo:  -0.02643, loss val: 0.04093
[2022-12-07 05:03:12,181] [INFO] [controller] EPOCH 4 loss ppo:  -0.03400, loss val: 0.04232
[2022-12-07 05:03:12,190] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:03:12,357] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:03:12,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:03:17,527] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:03:22,554] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:03:27,370] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:03:32,227] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:03:37,048] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:03:41,885] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:03:46,761] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:03:51,527] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:03:56,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:04:01,490] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.08924595735655
[2022-12-07 05:04:01,491] [INFO] [runner_train_mujoco] Average state value: 0.6521619349718094
[2022-12-07 05:04:01,491] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 05:04:01,546] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.04208
[2022-12-07 05:04:01,598] [INFO] [controller] EPOCH 2 loss ppo:  -0.02215, loss val: 0.04021
[2022-12-07 05:04:01,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.02583, loss val: 0.04020
[2022-12-07 05:04:01,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.03429, loss val: 0.04012
[2022-12-07 05:04:01,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:01,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:01,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:04:06,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:04:11,495] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:04:16,865] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:04:21,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:04:26,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:04:31,680] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:04:36,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:04:41,363] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:04:46,261] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:04:51,259] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1343875395229734
[2022-12-07 05:04:51,260] [INFO] [runner_train_mujoco] Average state value: 0.6502486633857092
[2022-12-07 05:04:51,260] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 05:04:51,328] [INFO] [controller] EPOCH 1 loss ppo:  -0.01123, loss val: 0.03655
[2022-12-07 05:04:51,374] [INFO] [controller] EPOCH 2 loss ppo:  -0.01807, loss val: 0.03788
[2022-12-07 05:04:51,426] [INFO] [controller] EPOCH 3 loss ppo:  -0.02621, loss val: 0.03656
[2022-12-07 05:04:51,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.03187, loss val: 0.03690
[2022-12-07 05:04:51,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:51,661] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:51,661] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:04:56,943] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:05:01,733] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:05:06,839] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:05:12,105] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:05:17,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:05:22,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:05:27,290] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:05:32,368] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:05:37,267] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:05:42,104] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.278832130129482
[2022-12-07 05:05:42,104] [INFO] [runner_train_mujoco] Average state value: 0.6515918191274007
[2022-12-07 05:05:42,104] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 05:05:42,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04414
[2022-12-07 05:05:42,219] [INFO] [controller] EPOCH 2 loss ppo:  -0.02006, loss val: 0.04422
[2022-12-07 05:05:42,266] [INFO] [controller] EPOCH 3 loss ppo:  -0.02464, loss val: 0.04372
[2022-12-07 05:05:42,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.02531, loss val: 0.04261
[2022-12-07 05:05:42,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:05:42,490] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:05:42,491] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:05:47,708] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:05:52,800] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:05:57,393] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:06:02,563] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:06:07,545] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:06:12,549] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:06:17,519] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:06:22,179] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:06:26,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:06:31,795] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.412460721232959
[2022-12-07 05:06:31,795] [INFO] [runner_train_mujoco] Average state value: 0.6861647037665048
[2022-12-07 05:06:31,796] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 05:06:31,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01226, loss val: 0.04361
[2022-12-07 05:06:31,924] [INFO] [controller] EPOCH 2 loss ppo:  -0.02338, loss val: 0.04346
[2022-12-07 05:06:31,978] [INFO] [controller] EPOCH 3 loss ppo:  -0.02735, loss val: 0.04356
[2022-12-07 05:06:32,026] [INFO] [controller] EPOCH 4 loss ppo:  -0.03216, loss val: 0.04349
[2022-12-07 05:06:32,037] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:06:32,200] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:06:32,200] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:06:37,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:06:42,538] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:06:47,397] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:06:52,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:06:57,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:07:02,417] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:07:08,474] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:07:14,198] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:07:19,807] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:07:25,185] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.401992850736872
[2022-12-07 05:07:25,186] [INFO] [runner_train_mujoco] Average state value: 0.7121524370511373
[2022-12-07 05:07:25,186] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 05:07:25,265] [INFO] [controller] EPOCH 1 loss ppo:  -0.01110, loss val: 0.04120
[2022-12-07 05:07:25,397] [INFO] [controller] EPOCH 2 loss ppo:  -0.02085, loss val: 0.04144
[2022-12-07 05:07:25,511] [INFO] [controller] EPOCH 3 loss ppo:  -0.02747, loss val: 0.03986
[2022-12-07 05:07:25,573] [INFO] [controller] EPOCH 4 loss ppo:  -0.03381, loss val: 0.03907
[2022-12-07 05:07:25,583] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:07:25,752] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:07:25,752] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:07:30,788] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:07:36,200] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:07:41,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:07:46,419] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:07:51,340] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:07:56,123] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:08:00,645] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:08:05,530] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:08:10,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:08:14,922] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6046136103570412
[2022-12-07 05:08:14,922] [INFO] [runner_train_mujoco] Average state value: 0.6752561312913895
[2022-12-07 05:08:14,922] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 05:08:14,976] [INFO] [controller] EPOCH 1 loss ppo:  -0.01230, loss val: 0.03923
[2022-12-07 05:08:15,038] [INFO] [controller] EPOCH 2 loss ppo:  -0.01954, loss val: 0.03770
[2022-12-07 05:08:15,089] [INFO] [controller] EPOCH 3 loss ppo:  -0.02257, loss val: 0.04181
[2022-12-07 05:08:15,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.03057, loss val: 0.03599
[2022-12-07 05:08:15,144] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:08:15,311] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:08:15,311] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:08:20,556] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:08:25,394] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:08:30,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:08:35,260] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:08:40,218] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:08:45,800] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:08:50,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:08:55,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:09:00,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:09:05,658] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.444551215620795
[2022-12-07 05:09:05,659] [INFO] [runner_train_mujoco] Average state value: 0.6160451349417368
[2022-12-07 05:09:05,659] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 05:09:05,719] [INFO] [controller] EPOCH 1 loss ppo:  -0.01222, loss val: 0.03688
[2022-12-07 05:09:05,770] [INFO] [controller] EPOCH 2 loss ppo:  -0.01798, loss val: 0.03714
[2022-12-07 05:09:05,815] [INFO] [controller] EPOCH 3 loss ppo:  -0.02574, loss val: 0.03755
[2022-12-07 05:09:05,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.03332, loss val: 0.03703
[2022-12-07 05:09:05,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:09:06,036] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:09:06,037] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:09:10,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:09:15,660] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:09:20,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:09:25,190] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:09:30,023] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:09:34,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:09:40,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:09:45,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:09:50,283] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:09:55,294] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6075126076639363
[2022-12-07 05:09:55,294] [INFO] [runner_train_mujoco] Average state value: 0.6074274869759877
[2022-12-07 05:09:55,294] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 05:09:55,354] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04032
[2022-12-07 05:09:55,400] [INFO] [controller] EPOCH 2 loss ppo:  -0.02252, loss val: 0.03963
[2022-12-07 05:09:55,447] [INFO] [controller] EPOCH 3 loss ppo:  -0.02710, loss val: 0.04037
[2022-12-07 05:09:55,495] [INFO] [controller] EPOCH 4 loss ppo:  -0.03200, loss val: 0.03986
[2022-12-07 05:09:55,504] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:09:55,670] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:09:55,670] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:10:00,593] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:10:05,631] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:10:10,654] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:10:15,421] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:10:20,477] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:10:25,307] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:10:30,308] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:10:35,521] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:10:40,392] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:10:45,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6542022922220858
[2022-12-07 05:10:45,331] [INFO] [runner_train_mujoco] Average state value: 0.6481056345899899
[2022-12-07 05:10:45,331] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 05:10:45,464] [INFO] [controller] EPOCH 1 loss ppo:  -0.01099, loss val: 0.04167
[2022-12-07 05:10:45,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01889, loss val: 0.04161
[2022-12-07 05:10:45,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.02386, loss val: 0.04062
[2022-12-07 05:10:45,608] [INFO] [controller] EPOCH 4 loss ppo:  -0.02928, loss val: 0.04059
[2022-12-07 05:10:45,617] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:10:45,787] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:10:45,787] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:10:50,692] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:10:55,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:11:00,572] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:11:05,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:11:10,186] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:11:14,516] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:11:19,146] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:11:24,223] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:11:28,881] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:11:33,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7568776527410066
[2022-12-07 05:11:33,632] [INFO] [runner_train_mujoco] Average state value: 0.688661429564158
[2022-12-07 05:11:33,632] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 05:11:33,688] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04348
[2022-12-07 05:11:33,743] [INFO] [controller] EPOCH 2 loss ppo:  -0.01981, loss val: 0.04324
[2022-12-07 05:11:33,813] [INFO] [controller] EPOCH 3 loss ppo:  -0.02582, loss val: 0.04231
[2022-12-07 05:11:33,866] [INFO] [controller] EPOCH 4 loss ppo:  -0.03466, loss val: 0.04124
[2022-12-07 05:11:33,875] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:11:34,048] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:11:34,048] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:11:39,256] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:11:44,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:11:49,627] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:11:54,440] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:11:59,444] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:12:04,389] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:12:09,181] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:12:13,837] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:12:18,617] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:12:23,243] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.726702603594434
[2022-12-07 05:12:23,243] [INFO] [runner_train_mujoco] Average state value: 0.6609630137284597
[2022-12-07 05:12:23,244] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 05:12:23,307] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04174
[2022-12-07 05:12:23,353] [INFO] [controller] EPOCH 2 loss ppo:  -0.02457, loss val: 0.04327
[2022-12-07 05:12:23,396] [INFO] [controller] EPOCH 3 loss ppo:  -0.02632, loss val: 0.04251
[2022-12-07 05:12:23,441] [INFO] [controller] EPOCH 4 loss ppo:  -0.02887, loss val: 0.04284
[2022-12-07 05:12:23,455] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:12:23,624] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:12:23,624] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:12:28,588] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:12:33,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:12:37,900] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:12:42,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:12:47,637] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:12:52,214] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:12:56,691] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:13:01,215] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:13:05,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:13:09,514] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8444389886348969
[2022-12-07 05:13:09,514] [INFO] [runner_train_mujoco] Average state value: 0.6316183953483898
[2022-12-07 05:13:09,515] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 05:13:09,566] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.03945
[2022-12-07 05:13:09,607] [INFO] [controller] EPOCH 2 loss ppo:  -0.01947, loss val: 0.03939
[2022-12-07 05:13:09,649] [INFO] [controller] EPOCH 3 loss ppo:  -0.02550, loss val: 0.03854
[2022-12-07 05:13:09,693] [INFO] [controller] EPOCH 4 loss ppo:  -0.03301, loss val: 0.03668
[2022-12-07 05:13:09,702] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:13:09,854] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:13:09,854] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:13:14,223] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:13:18,999] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:13:23,204] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:13:27,329] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:13:31,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:13:36,086] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:13:40,336] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:13:44,820] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:13:49,008] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:13:53,543] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9292521675218075
[2022-12-07 05:13:53,544] [INFO] [runner_train_mujoco] Average state value: 0.591034578581651
[2022-12-07 05:13:53,544] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 05:13:53,618] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.04155
[2022-12-07 05:13:53,666] [INFO] [controller] EPOCH 2 loss ppo:  -0.02389, loss val: 0.04194
[2022-12-07 05:13:53,715] [INFO] [controller] EPOCH 3 loss ppo:  -0.02532, loss val: 0.03986
[2022-12-07 05:13:53,765] [INFO] [controller] EPOCH 4 loss ppo:  -0.02936, loss val: 0.03956
[2022-12-07 05:13:53,775] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:13:53,940] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:13:53,941] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:13:58,016] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:02,378] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:14:06,812] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:14:11,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:14:15,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:14:19,810] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:14:24,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:14:28,328] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:14:32,406] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:14:36,464] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9960756556989903
[2022-12-07 05:14:36,465] [INFO] [runner_train_mujoco] Average state value: 0.5890278636813164
[2022-12-07 05:14:36,465] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 05:14:36,517] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.04188
[2022-12-07 05:14:36,558] [INFO] [controller] EPOCH 2 loss ppo:  -0.02521, loss val: 0.03956
[2022-12-07 05:14:36,602] [INFO] [controller] EPOCH 3 loss ppo:  -0.02667, loss val: 0.04146
[2022-12-07 05:14:36,650] [INFO] [controller] EPOCH 4 loss ppo:  -0.03427, loss val: 0.03950
[2022-12-07 05:14:36,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:14:36,840] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:14:36,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:14:41,532] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:45,943] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:14:50,612] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:14:55,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:14:59,465] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:15:03,622] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:15:07,967] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:15:12,060] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:15:15,906] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:15:20,036] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1319110896383933
[2022-12-07 05:15:20,037] [INFO] [runner_train_mujoco] Average state value: 0.6108499821225801
[2022-12-07 05:15:20,037] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 05:15:20,087] [INFO] [controller] EPOCH 1 loss ppo:  -0.01272, loss val: 0.04419
[2022-12-07 05:15:20,126] [INFO] [controller] EPOCH 2 loss ppo:  -0.01871, loss val: 0.04472
[2022-12-07 05:15:20,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.02422, loss val: 0.04511
[2022-12-07 05:15:20,209] [INFO] [controller] EPOCH 4 loss ppo:  -0.02596, loss val: 0.04423
[2022-12-07 05:15:20,216] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:15:20,382] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:15:20,383] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:15:24,419] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:15:28,744] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:15:33,357] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:15:37,673] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:15:42,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:15:47,419] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:15:51,455] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:15:55,476] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:15:59,787] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:16:03,953] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.117537108802167
[2022-12-07 05:16:03,954] [INFO] [runner_train_mujoco] Average state value: 0.6310745280981064
[2022-12-07 05:16:03,954] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 05:16:04,019] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04375
[2022-12-07 05:16:04,063] [INFO] [controller] EPOCH 2 loss ppo:  -0.02184, loss val: 0.04357
[2022-12-07 05:16:04,105] [INFO] [controller] EPOCH 3 loss ppo:  -0.02970, loss val: 0.04351
[2022-12-07 05:16:04,145] [INFO] [controller] EPOCH 4 loss ppo:  -0.03393, loss val: 0.04358
[2022-12-07 05:16:04,155] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:16:04,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:16:04,323] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:16:08,293] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:16:12,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:16:17,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:16:21,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:16:26,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:16:30,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:16:34,313] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:16:39,012] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:16:43,349] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:16:47,885] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.185530964702435
[2022-12-07 05:16:47,885] [INFO] [runner_train_mujoco] Average state value: 0.6320733164548873
[2022-12-07 05:16:47,885] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 05:16:47,950] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.04135
[2022-12-07 05:16:48,004] [INFO] [controller] EPOCH 2 loss ppo:  -0.02400, loss val: 0.04102
[2022-12-07 05:16:48,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.02908, loss val: 0.04138
[2022-12-07 05:16:48,098] [INFO] [controller] EPOCH 4 loss ppo:  -0.03071, loss val: 0.04023
[2022-12-07 05:16:48,108] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:16:48,266] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:16:48,267] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:16:52,668] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:16:56,729] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:17:01,155] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:17:05,668] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:17:09,693] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:17:13,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:17:17,973] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:17:22,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:17:26,285] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:17:30,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.290496110097665
[2022-12-07 05:17:30,634] [INFO] [runner_train_mujoco] Average state value: 0.6108240152200064
[2022-12-07 05:17:30,634] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 05:17:30,686] [INFO] [controller] EPOCH 1 loss ppo:  -0.01281, loss val: 0.04111
[2022-12-07 05:17:30,727] [INFO] [controller] EPOCH 2 loss ppo:  -0.02223, loss val: 0.04151
[2022-12-07 05:17:30,770] [INFO] [controller] EPOCH 3 loss ppo:  -0.02846, loss val: 0.04113
[2022-12-07 05:17:30,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.03268, loss val: 0.04119
[2022-12-07 05:17:30,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:17:30,988] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:17:30,988] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:17:35,245] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:17:39,825] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:17:44,371] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:17:48,880] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:17:53,116] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:17:57,344] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:18:01,804] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:18:06,094] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:18:10,286] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:18:14,639] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.235628202284398
[2022-12-07 05:18:14,639] [INFO] [runner_train_mujoco] Average state value: 0.6106743140618007
[2022-12-07 05:18:14,639] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 05:18:14,686] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.03978
[2022-12-07 05:18:14,738] [INFO] [controller] EPOCH 2 loss ppo:  -0.02249, loss val: 0.03831
[2022-12-07 05:18:14,784] [INFO] [controller] EPOCH 3 loss ppo:  -0.02617, loss val: 0.03908
[2022-12-07 05:18:14,835] [INFO] [controller] EPOCH 4 loss ppo:  -0.03114, loss val: 0.03822
[2022-12-07 05:18:14,846] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:18:15,014] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:18:15,014] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:18:19,121] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:18:23,454] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:18:28,052] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:18:32,172] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:18:36,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:18:41,110] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:18:45,160] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:18:49,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:18:54,373] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:18:58,418] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.268146691775556
[2022-12-07 05:18:58,418] [INFO] [runner_train_mujoco] Average state value: 0.6065856797496478
[2022-12-07 05:18:58,419] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 05:18:58,474] [INFO] [controller] EPOCH 1 loss ppo:  -0.01277, loss val: 0.04135
[2022-12-07 05:18:58,518] [INFO] [controller] EPOCH 2 loss ppo:  -0.01937, loss val: 0.04166
[2022-12-07 05:18:58,562] [INFO] [controller] EPOCH 3 loss ppo:  -0.02511, loss val: 0.04141
[2022-12-07 05:18:58,611] [INFO] [controller] EPOCH 4 loss ppo:  -0.02930, loss val: 0.04122
[2022-12-07 05:18:58,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:18:58,783] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:18:58,783] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:19:03,187] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:19:07,442] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:19:11,781] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:19:16,249] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:19:20,384] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:19:24,450] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:19:28,860] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:19:33,329] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:19:37,732] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:19:41,849] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.415271914719826
[2022-12-07 05:19:41,850] [INFO] [runner_train_mujoco] Average state value: 0.6153025134007135
[2022-12-07 05:19:41,850] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 05:19:41,907] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04185
[2022-12-07 05:19:41,956] [INFO] [controller] EPOCH 2 loss ppo:  -0.02384, loss val: 0.04306
[2022-12-07 05:19:42,003] [INFO] [controller] EPOCH 3 loss ppo:  -0.03018, loss val: 0.04186
[2022-12-07 05:19:42,048] [INFO] [controller] EPOCH 4 loss ppo:  -0.03207, loss val: 0.04136
[2022-12-07 05:19:42,057] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:19:42,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:19:42,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:19:46,841] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:19:51,333] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:19:55,625] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:19:59,667] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:20:03,794] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:20:07,976] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:20:12,437] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:20:16,448] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:20:20,885] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:20:25,871] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3593292958554732
[2022-12-07 05:20:25,871] [INFO] [runner_train_mujoco] Average state value: 0.6384424782196682
[2022-12-07 05:20:25,871] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 05:20:25,929] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.03694
[2022-12-07 05:20:25,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.02183, loss val: 0.03792
[2022-12-07 05:20:26,024] [INFO] [controller] EPOCH 3 loss ppo:  -0.02601, loss val: 0.03657
[2022-12-07 05:20:26,073] [INFO] [controller] EPOCH 4 loss ppo:  -0.02947, loss val: 0.03675
[2022-12-07 05:20:26,082] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:20:26,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:20:26,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:20:30,565] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:20:34,901] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:20:39,281] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:20:43,882] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:20:48,122] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:20:52,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:20:56,843] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:21:01,143] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:21:05,649] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:21:09,817] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.59032271911893
[2022-12-07 05:21:09,818] [INFO] [runner_train_mujoco] Average state value: 0.6209559604724247
[2022-12-07 05:21:09,818] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 05:21:09,869] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04105
[2022-12-07 05:21:09,907] [INFO] [controller] EPOCH 2 loss ppo:  -0.01769, loss val: 0.04027
[2022-12-07 05:21:09,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.02217, loss val: 0.03941
[2022-12-07 05:21:10,006] [INFO] [controller] EPOCH 4 loss ppo:  -0.02598, loss val: 0.04131
[2022-12-07 05:21:10,016] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:21:10,172] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:21:10,172] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:21:14,650] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:21:19,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:21:23,097] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:21:27,340] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:21:31,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:21:36,099] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:21:40,613] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:21:45,232] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:21:49,717] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:21:53,833] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.6208276143040945
[2022-12-07 05:21:53,833] [INFO] [runner_train_mujoco] Average state value: 0.5811806826194128
[2022-12-07 05:21:53,833] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 05:21:53,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.01319, loss val: 0.04309
[2022-12-07 05:21:54,014] [INFO] [controller] EPOCH 2 loss ppo:  -0.01740, loss val: 0.04367
[2022-12-07 05:21:54,062] [INFO] [controller] EPOCH 3 loss ppo:  -0.02197, loss val: 0.04317
[2022-12-07 05:21:54,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.02806, loss val: 0.04344
[2022-12-07 05:21:54,116] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:21:54,286] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:21:54,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:21:58,856] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:22:03,137] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:22:07,361] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:22:11,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:22:15,898] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:22:20,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:22:24,198] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:22:28,727] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:22:32,770] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:22:37,480] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.605547483796683
[2022-12-07 05:22:37,480] [INFO] [runner_train_mujoco] Average state value: 0.5765109964609146
[2022-12-07 05:22:37,480] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 05:22:37,530] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.04576
[2022-12-07 05:22:37,583] [INFO] [controller] EPOCH 2 loss ppo:  -0.01878, loss val: 0.04679
[2022-12-07 05:22:37,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.02280, loss val: 0.04555
[2022-12-07 05:22:37,683] [INFO] [controller] EPOCH 4 loss ppo:  -0.02445, loss val: 0.04479
[2022-12-07 05:22:37,693] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:22:37,854] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:22:37,855] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:22:42,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:22:46,544] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:22:50,900] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:22:54,928] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:22:58,903] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:23:03,237] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:23:07,518] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:23:11,946] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:23:15,953] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:23:20,194] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.599635793957225
[2022-12-07 05:23:20,194] [INFO] [runner_train_mujoco] Average state value: 0.600916562974453
[2022-12-07 05:23:20,194] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 05:23:20,272] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04891
[2022-12-07 05:23:20,319] [INFO] [controller] EPOCH 2 loss ppo:  -0.01727, loss val: 0.04885
[2022-12-07 05:23:20,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.02364, loss val: 0.04879
[2022-12-07 05:23:20,412] [INFO] [controller] EPOCH 4 loss ppo:  -0.02709, loss val: 0.04877
[2022-12-07 05:23:20,424] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:23:20,599] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:23:20,599] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:23:25,435] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:23:29,540] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:23:34,135] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:23:38,879] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:23:43,528] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:23:48,043] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:23:52,090] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:23:56,222] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:24:00,414] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:24:04,541] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.716602115379411
[2022-12-07 05:24:04,542] [INFO] [runner_train_mujoco] Average state value: 0.625143117904663
[2022-12-07 05:24:04,542] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 05:24:04,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04123
[2022-12-07 05:24:04,651] [INFO] [controller] EPOCH 2 loss ppo:  -0.01790, loss val: 0.04108
[2022-12-07 05:24:04,696] [INFO] [controller] EPOCH 3 loss ppo:  -0.02415, loss val: 0.04156
[2022-12-07 05:24:04,737] [INFO] [controller] EPOCH 4 loss ppo:  -0.02600, loss val: 0.04126
[2022-12-07 05:24:04,746] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:24:04,915] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:24:04,915] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:24:09,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:24:13,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:24:18,083] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:24:22,946] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:24:27,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:24:31,257] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:24:35,492] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:24:39,900] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:24:44,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:24:48,481] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.792304738268902
[2022-12-07 05:24:48,482] [INFO] [runner_train_mujoco] Average state value: 0.6127404657800992
[2022-12-07 05:24:48,482] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 05:24:48,532] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.04266
[2022-12-07 05:24:48,572] [INFO] [controller] EPOCH 2 loss ppo:  -0.02400, loss val: 0.04230
[2022-12-07 05:24:48,612] [INFO] [controller] EPOCH 3 loss ppo:  -0.02918, loss val: 0.04198
[2022-12-07 05:24:48,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.03090, loss val: 0.04128
[2022-12-07 05:24:48,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:24:48,833] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:24:48,834] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:24:53,141] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:24:57,394] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:25:01,862] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:25:06,483] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:25:10,537] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:25:14,682] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:25:19,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:25:23,372] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:25:27,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:25:32,060] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9203533841676417
[2022-12-07 05:25:32,060] [INFO] [runner_train_mujoco] Average state value: 0.5880231220126153
[2022-12-07 05:25:32,060] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 05:25:32,125] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.04262
[2022-12-07 05:25:32,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.01621, loss val: 0.04310
[2022-12-07 05:25:32,219] [INFO] [controller] EPOCH 3 loss ppo:  -0.02123, loss val: 0.04305
[2022-12-07 05:25:32,263] [INFO] [controller] EPOCH 4 loss ppo:  -0.02409, loss val: 0.04354
[2022-12-07 05:25:32,273] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:25:32,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:25:32,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:25:36,360] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:25:40,705] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:25:44,677] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:25:49,205] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:25:53,532] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:25:57,668] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:26:01,729] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:26:05,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:26:09,959] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:26:14,227] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0882717623348905
[2022-12-07 05:26:14,227] [INFO] [runner_train_mujoco] Average state value: 0.5850663585861524
[2022-12-07 05:26:14,227] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 05:26:14,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04563
[2022-12-07 05:26:14,392] [INFO] [controller] EPOCH 2 loss ppo:  -0.01951, loss val: 0.04334
[2022-12-07 05:26:14,469] [INFO] [controller] EPOCH 3 loss ppo:  -0.02608, loss val: 0.04333
[2022-12-07 05:26:14,523] [INFO] [controller] EPOCH 4 loss ppo:  -0.02937, loss val: 0.04520
[2022-12-07 05:26:14,534] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:26:14,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:26:14,720] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:26:19,155] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:26:23,569] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:26:28,201] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:26:32,821] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:26:37,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:26:41,700] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:26:46,273] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:26:50,422] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:26:54,378] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:26:58,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0952869118027686
[2022-12-07 05:26:58,432] [INFO] [runner_train_mujoco] Average state value: 0.5800586557189624
[2022-12-07 05:26:58,433] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 05:26:58,486] [INFO] [controller] EPOCH 1 loss ppo:  -0.01390, loss val: 0.04147
[2022-12-07 05:26:58,540] [INFO] [controller] EPOCH 2 loss ppo:  -0.01615, loss val: 0.04396
[2022-12-07 05:26:58,586] [INFO] [controller] EPOCH 3 loss ppo:  -0.02009, loss val: 0.04195
[2022-12-07 05:26:58,633] [INFO] [controller] EPOCH 4 loss ppo:  -0.02409, loss val: 0.04139
[2022-12-07 05:26:58,643] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:26:58,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:26:58,805] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:27:02,869] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:27:06,918] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:27:11,600] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:27:15,771] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:27:20,157] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:27:24,564] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:27:29,117] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:27:33,393] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:27:37,725] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:27:41,801] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.18586353749439
[2022-12-07 05:27:41,801] [INFO] [runner_train_mujoco] Average state value: 0.575546076933543
[2022-12-07 05:27:41,801] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 05:27:41,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.04307
[2022-12-07 05:27:41,891] [INFO] [controller] EPOCH 2 loss ppo:  -0.01734, loss val: 0.04331
[2022-12-07 05:27:41,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.02123, loss val: 0.04313
[2022-12-07 05:27:41,975] [INFO] [controller] EPOCH 4 loss ppo:  -0.02228, loss val: 0.04309
[2022-12-07 05:27:41,984] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:27:42,126] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:27:42,127] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:27:46,535] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:27:50,457] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:27:54,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:27:59,015] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:28:02,953] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:28:07,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:28:11,752] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:28:16,187] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:28:20,614] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:28:24,709] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.330493475793194
[2022-12-07 05:28:24,709] [INFO] [runner_train_mujoco] Average state value: 0.583623064339161
[2022-12-07 05:28:24,709] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 05:28:24,761] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.04366
[2022-12-07 05:28:24,805] [INFO] [controller] EPOCH 2 loss ppo:  -0.01565, loss val: 0.04397
[2022-12-07 05:28:24,851] [INFO] [controller] EPOCH 3 loss ppo:  -0.01935, loss val: 0.04385
[2022-12-07 05:28:24,895] [INFO] [controller] EPOCH 4 loss ppo:  -0.02389, loss val: 0.04350
[2022-12-07 05:28:24,905] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:28:25,065] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:28:25,066] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:28:29,474] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:28:33,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:28:38,098] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:28:42,572] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:28:46,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:28:50,990] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:28:55,014] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:28:59,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:29:03,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:29:08,253] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.457271528964346
[2022-12-07 05:29:08,254] [INFO] [runner_train_mujoco] Average state value: 0.5865838038921356
[2022-12-07 05:29:08,254] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 05:29:08,304] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.04553
[2022-12-07 05:29:08,349] [INFO] [controller] EPOCH 2 loss ppo:  -0.01667, loss val: 0.04489
[2022-12-07 05:29:08,392] [INFO] [controller] EPOCH 3 loss ppo:  -0.02009, loss val: 0.04568
[2022-12-07 05:29:08,437] [INFO] [controller] EPOCH 4 loss ppo:  -0.02380, loss val: 0.04466
[2022-12-07 05:29:08,446] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:29:08,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:29:08,597] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:29:12,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:29:16,781] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:29:21,263] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:29:25,103] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:29:29,386] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:29:33,457] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:29:37,426] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:29:41,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:29:45,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:29:49,958] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3782146542670475
[2022-12-07 05:29:49,959] [INFO] [runner_train_mujoco] Average state value: 0.5888783742586772
[2022-12-07 05:29:49,959] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 05:29:50,008] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04063
[2022-12-07 05:29:50,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.01518, loss val: 0.04169
[2022-12-07 05:29:50,091] [INFO] [controller] EPOCH 3 loss ppo:  -0.01704, loss val: 0.04084
[2022-12-07 05:29:50,134] [INFO] [controller] EPOCH 4 loss ppo:  -0.01932, loss val: 0.04062
[2022-12-07 05:29:50,143] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:29:50,261] [INFO] [optimize] Finished learning.
