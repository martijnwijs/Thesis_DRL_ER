[2022-12-07 00:34:26,051] [INFO] [optimize] Starting learning
[2022-12-07 00:34:26,069] [INFO] [optimize] Starting learning process..
[2022-12-07 00:34:26,171] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:34:26,172] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:34:35,778] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:34:43,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:34:49,946] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:34:56,714] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:35:03,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:35:11,063] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:35:18,199] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:35:25,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:35:32,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:35:39,053] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4507488343584812
[2022-12-07 00:35:39,053] [INFO] [runner_train_mujoco] Average state value: 0.14917230148116747
[2022-12-07 00:35:39,053] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 00:35:39,116] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.33656
[2022-12-07 00:35:39,165] [INFO] [controller] EPOCH 2 loss ppo:  -0.04441, loss val: 0.29780
[2022-12-07 00:35:39,215] [INFO] [controller] EPOCH 3 loss ppo:  -0.05518, loss val: 0.26948
[2022-12-07 00:35:39,267] [INFO] [controller] EPOCH 4 loss ppo:  -0.06321, loss val: 0.23466
[2022-12-07 00:35:39,279] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:35:39,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:35:39,501] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:35:46,459] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:35:53,382] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:35:59,970] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:36:06,676] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:36:13,055] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:36:20,098] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:36:26,987] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:36:34,240] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:36:43,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:36:51,024] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3399315912461732
[2022-12-07 00:36:51,024] [INFO] [runner_train_mujoco] Average state value: 0.30294723012484603
[2022-12-07 00:36:51,024] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 00:36:51,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01328, loss val: 0.23588
[2022-12-07 00:36:51,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.03616, loss val: 0.21251
[2022-12-07 00:36:51,214] [INFO] [controller] EPOCH 3 loss ppo:  -0.04924, loss val: 0.18528
[2022-12-07 00:36:51,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.05730, loss val: 0.16681
[2022-12-07 00:36:51,285] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:36:51,488] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:36:51,488] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:36:58,709] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:37:05,894] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:37:13,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:37:20,835] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:37:27,963] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:37:35,771] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:37:43,475] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:37:50,630] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:37:58,372] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:38:05,951] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.35485297109596664
[2022-12-07 00:38:05,951] [INFO] [runner_train_mujoco] Average state value: 0.4721150960500042
[2022-12-07 00:38:05,951] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 00:38:06,013] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.14019
[2022-12-07 00:38:06,066] [INFO] [controller] EPOCH 2 loss ppo:  -0.04022, loss val: 0.13016
[2022-12-07 00:38:06,120] [INFO] [controller] EPOCH 3 loss ppo:  -0.05308, loss val: 0.12608
[2022-12-07 00:38:06,175] [INFO] [controller] EPOCH 4 loss ppo:  -0.05834, loss val: 0.12281
[2022-12-07 00:38:06,185] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:38:06,395] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:38:06,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:38:13,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:38:21,705] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:38:29,219] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:38:36,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:38:44,719] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:38:52,158] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:39:00,217] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:39:07,933] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:39:15,571] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:39:23,469] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3699219697693767
[2022-12-07 00:39:23,469] [INFO] [runner_train_mujoco] Average state value: 0.5282581655407946
[2022-12-07 00:39:23,469] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 00:39:23,550] [INFO] [controller] EPOCH 1 loss ppo:  -0.01248, loss val: 0.10788
[2022-12-07 00:39:23,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.03984, loss val: 0.10201
[2022-12-07 00:39:23,670] [INFO] [controller] EPOCH 3 loss ppo:  -0.05047, loss val: 0.09595
[2022-12-07 00:39:23,729] [INFO] [controller] EPOCH 4 loss ppo:  -0.05655, loss val: 0.08921
[2022-12-07 00:39:23,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:39:23,962] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:39:23,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:39:30,953] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:39:38,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:39:46,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:39:54,326] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:40:02,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:40:10,741] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:40:18,774] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:40:26,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:40:34,883] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:40:42,733] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4496005331587618
[2022-12-07 00:40:42,733] [INFO] [runner_train_mujoco] Average state value: 0.5312593662266931
[2022-12-07 00:40:42,734] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 00:40:42,795] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.09307
[2022-12-07 00:40:42,855] [INFO] [controller] EPOCH 2 loss ppo:  -0.04004, loss val: 0.09174
[2022-12-07 00:40:42,908] [INFO] [controller] EPOCH 3 loss ppo:  -0.04802, loss val: 0.08416
[2022-12-07 00:40:42,960] [INFO] [controller] EPOCH 4 loss ppo:  -0.05411, loss val: 0.08361
[2022-12-07 00:40:42,972] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:40:43,294] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:40:43,295] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:40:51,023] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:40:58,725] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:41:06,240] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:41:13,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:41:21,491] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:41:29,132] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:41:36,969] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:41:45,060] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:41:52,697] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:42:00,144] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44422380288043345
[2022-12-07 00:42:00,144] [INFO] [runner_train_mujoco] Average state value: 0.5780548480929186
[2022-12-07 00:42:00,145] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 00:42:00,364] [INFO] [controller] EPOCH 1 loss ppo:  -0.01083, loss val: 0.07363
[2022-12-07 00:42:00,484] [INFO] [controller] EPOCH 2 loss ppo:  -0.03516, loss val: 0.07080
[2022-12-07 00:42:00,598] [INFO] [controller] EPOCH 3 loss ppo:  -0.04851, loss val: 0.06843
[2022-12-07 00:42:00,670] [INFO] [controller] EPOCH 4 loss ppo:  -0.05618, loss val: 0.06572
[2022-12-07 00:42:00,685] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:42:00,932] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:42:00,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:42:08,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:42:16,139] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:42:24,142] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:42:31,571] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:42:39,026] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:42:46,648] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:42:53,741] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:43:00,873] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:43:08,492] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:43:16,113] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.38436775618896024
[2022-12-07 00:43:16,113] [INFO] [runner_train_mujoco] Average state value: 0.5757485871762037
[2022-12-07 00:43:16,113] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 00:43:16,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.01032, loss val: 0.06684
[2022-12-07 00:43:16,231] [INFO] [controller] EPOCH 2 loss ppo:  -0.03214, loss val: 0.06418
[2022-12-07 00:43:16,283] [INFO] [controller] EPOCH 3 loss ppo:  -0.04217, loss val: 0.06281
[2022-12-07 00:43:16,331] [INFO] [controller] EPOCH 4 loss ppo:  -0.05065, loss val: 0.05991
[2022-12-07 00:43:16,342] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:43:16,569] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:43:16,570] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:43:25,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:43:32,550] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:43:39,470] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:43:46,888] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:43:54,227] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:44:01,465] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:44:09,393] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:44:16,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:44:24,469] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:44:31,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2922318982439728
[2022-12-07 00:44:31,484] [INFO] [runner_train_mujoco] Average state value: 0.6338808813119927
[2022-12-07 00:44:31,484] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 00:44:31,562] [INFO] [controller] EPOCH 1 loss ppo:  -0.01134, loss val: 0.06130
[2022-12-07 00:44:31,617] [INFO] [controller] EPOCH 2 loss ppo:  -0.03479, loss val: 0.06170
[2022-12-07 00:44:31,678] [INFO] [controller] EPOCH 3 loss ppo:  -0.04273, loss val: 0.06041
[2022-12-07 00:44:31,729] [INFO] [controller] EPOCH 4 loss ppo:  -0.05104, loss val: 0.05845
[2022-12-07 00:44:31,742] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:44:31,950] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:44:31,950] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:44:39,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:44:46,632] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:44:54,485] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:45:01,984] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:45:09,905] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:45:17,666] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:45:26,154] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:45:35,101] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:45:44,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:45:52,806] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4807051256060464
[2022-12-07 00:45:52,807] [INFO] [runner_train_mujoco] Average state value: 0.64721602627635
[2022-12-07 00:45:52,807] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 00:45:52,912] [INFO] [controller] EPOCH 1 loss ppo:  -0.01025, loss val: 0.06107
[2022-12-07 00:45:52,988] [INFO] [controller] EPOCH 2 loss ppo:  -0.03712, loss val: 0.05824
[2022-12-07 00:45:53,073] [INFO] [controller] EPOCH 3 loss ppo:  -0.04809, loss val: 0.05645
[2022-12-07 00:45:53,164] [INFO] [controller] EPOCH 4 loss ppo:  -0.05335, loss val: 0.05528
[2022-12-07 00:45:53,181] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:45:53,427] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:45:53,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:46:01,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:46:11,203] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:46:19,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:46:28,634] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:46:37,665] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:46:46,561] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:46:55,567] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:47:05,002] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:47:14,262] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:47:22,387] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4692677668918064
[2022-12-07 00:47:22,387] [INFO] [runner_train_mujoco] Average state value: 0.6286527402202288
[2022-12-07 00:47:22,387] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 00:47:22,465] [INFO] [controller] EPOCH 1 loss ppo:  -0.00938, loss val: 0.04958
[2022-12-07 00:47:22,525] [INFO] [controller] EPOCH 2 loss ppo:  -0.03579, loss val: 0.04996
[2022-12-07 00:47:22,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.04827, loss val: 0.04909
[2022-12-07 00:47:22,646] [INFO] [controller] EPOCH 4 loss ppo:  -0.05483, loss val: 0.04797
[2022-12-07 00:47:22,657] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:47:22,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:47:22,898] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:47:31,347] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:47:39,876] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:47:48,077] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:47:56,487] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:48:04,516] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:48:12,838] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:48:21,372] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:48:29,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:48:37,914] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:48:45,523] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39318769674285553
[2022-12-07 00:48:45,524] [INFO] [runner_train_mujoco] Average state value: 0.637558689514796
[2022-12-07 00:48:45,524] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 00:48:45,617] [INFO] [controller] EPOCH 1 loss ppo:  -0.00998, loss val: 0.05516
[2022-12-07 00:48:45,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.02785, loss val: 0.05237
[2022-12-07 00:48:45,742] [INFO] [controller] EPOCH 3 loss ppo:  -0.04123, loss val: 0.05083
[2022-12-07 00:48:45,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.04693, loss val: 0.04815
[2022-12-07 00:48:45,829] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:48:46,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:48:46,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:48:54,270] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:49:02,862] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:49:11,220] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:49:19,252] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:49:27,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:49:34,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:49:42,216] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:49:49,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:49:57,380] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:50:05,406] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.32872258338776217
[2022-12-07 00:50:05,406] [INFO] [runner_train_mujoco] Average state value: 0.5957562348743279
[2022-12-07 00:50:05,406] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 00:50:05,487] [INFO] [controller] EPOCH 1 loss ppo:  -0.00870, loss val: 0.04318
[2022-12-07 00:50:05,567] [INFO] [controller] EPOCH 2 loss ppo:  -0.03096, loss val: 0.04180
[2022-12-07 00:50:05,642] [INFO] [controller] EPOCH 3 loss ppo:  -0.04261, loss val: 0.04093
[2022-12-07 00:50:05,700] [INFO] [controller] EPOCH 4 loss ppo:  -0.05178, loss val: 0.04007
[2022-12-07 00:50:05,711] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:50:05,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:50:05,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:50:13,772] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:50:21,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:50:28,915] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:50:36,266] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:50:43,979] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:50:51,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:50:58,609] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:51:06,420] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:51:14,276] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:51:21,441] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.25470751736979796
[2022-12-07 00:51:21,441] [INFO] [runner_train_mujoco] Average state value: 0.5342056884666284
[2022-12-07 00:51:21,441] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 00:51:21,510] [INFO] [controller] EPOCH 1 loss ppo:  -0.00954, loss val: 0.04714
[2022-12-07 00:51:21,560] [INFO] [controller] EPOCH 2 loss ppo:  -0.02860, loss val: 0.05008
[2022-12-07 00:51:21,616] [INFO] [controller] EPOCH 3 loss ppo:  -0.03995, loss val: 0.04797
[2022-12-07 00:51:21,670] [INFO] [controller] EPOCH 4 loss ppo:  -0.04750, loss val: 0.04498
[2022-12-07 00:51:21,681] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:51:21,899] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:51:21,899] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:51:29,449] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:51:37,013] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:51:44,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:51:51,180] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:51:58,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:52:06,073] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:52:13,434] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:52:21,336] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:52:28,863] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:52:36,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48172484961706735
[2022-12-07 00:52:36,224] [INFO] [runner_train_mujoco] Average state value: 0.5627345234056313
[2022-12-07 00:52:36,224] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 00:52:36,287] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.04501
[2022-12-07 00:52:36,361] [INFO] [controller] EPOCH 2 loss ppo:  -0.03143, loss val: 0.04522
[2022-12-07 00:52:36,413] [INFO] [controller] EPOCH 3 loss ppo:  -0.04297, loss val: 0.04476
[2022-12-07 00:52:36,473] [INFO] [controller] EPOCH 4 loss ppo:  -0.05153, loss val: 0.04407
[2022-12-07 00:52:36,485] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:52:36,699] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:52:36,700] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:52:43,506] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:52:50,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:52:57,408] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:53:04,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:53:11,808] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:53:18,725] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:53:25,647] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:53:32,657] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:53:39,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:53:47,219] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4979771289362788
[2022-12-07 00:53:47,219] [INFO] [runner_train_mujoco] Average state value: 0.6081022311051687
[2022-12-07 00:53:47,219] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 00:53:47,280] [INFO] [controller] EPOCH 1 loss ppo:  -0.01235, loss val: 0.04628
[2022-12-07 00:53:47,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.03813, loss val: 0.04556
[2022-12-07 00:53:47,376] [INFO] [controller] EPOCH 3 loss ppo:  -0.04710, loss val: 0.04454
[2022-12-07 00:53:47,426] [INFO] [controller] EPOCH 4 loss ppo:  -0.05325, loss val: 0.04401
[2022-12-07 00:53:47,437] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:53:47,638] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:53:47,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:53:54,794] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:54:01,687] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:54:09,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:54:16,521] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:54:23,803] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:54:30,828] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:54:37,817] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:54:44,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:54:51,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:54:59,099] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6475382544593327
[2022-12-07 00:54:59,099] [INFO] [runner_train_mujoco] Average state value: 0.5965123748580615
[2022-12-07 00:54:59,099] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 00:54:59,158] [INFO] [controller] EPOCH 1 loss ppo:  -0.01240, loss val: 0.03475
[2022-12-07 00:54:59,206] [INFO] [controller] EPOCH 2 loss ppo:  -0.03192, loss val: 0.03442
[2022-12-07 00:54:59,252] [INFO] [controller] EPOCH 3 loss ppo:  -0.04383, loss val: 0.03441
[2022-12-07 00:54:59,302] [INFO] [controller] EPOCH 4 loss ppo:  -0.05525, loss val: 0.03401
[2022-12-07 00:54:59,313] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:54:59,517] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:54:59,517] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:55:07,168] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:55:14,766] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:55:22,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:55:29,952] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:55:36,893] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:55:44,504] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:55:52,360] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:55:59,744] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:56:07,633] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:56:15,170] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6582838087867786
[2022-12-07 00:56:15,170] [INFO] [runner_train_mujoco] Average state value: 0.5547413943310578
[2022-12-07 00:56:15,170] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 00:56:15,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.04202
[2022-12-07 00:56:15,287] [INFO] [controller] EPOCH 2 loss ppo:  -0.03376, loss val: 0.03989
[2022-12-07 00:56:15,337] [INFO] [controller] EPOCH 3 loss ppo:  -0.04589, loss val: 0.03958
[2022-12-07 00:56:15,386] [INFO] [controller] EPOCH 4 loss ppo:  -0.05467, loss val: 0.03882
[2022-12-07 00:56:15,397] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:56:15,600] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:56:15,601] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:56:23,108] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:56:30,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:56:37,981] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:56:45,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:56:53,283] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:57:00,653] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:57:09,159] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:57:17,999] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:57:25,848] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:57:32,797] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7103342057580581
[2022-12-07 00:57:32,797] [INFO] [runner_train_mujoco] Average state value: 0.5243458986679712
[2022-12-07 00:57:32,797] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 00:57:32,860] [INFO] [controller] EPOCH 1 loss ppo:  -0.01150, loss val: 0.03843
[2022-12-07 00:57:32,912] [INFO] [controller] EPOCH 2 loss ppo:  -0.03195, loss val: 0.03836
[2022-12-07 00:57:32,965] [INFO] [controller] EPOCH 3 loss ppo:  -0.04486, loss val: 0.03836
[2022-12-07 00:57:33,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.05353, loss val: 0.03876
[2022-12-07 00:57:33,026] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:57:33,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:57:33,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:57:40,695] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:57:48,057] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:57:55,282] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:58:02,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:58:09,754] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:58:17,299] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:58:24,576] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:58:31,591] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:58:38,434] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:58:45,265] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8552497502612276
[2022-12-07 00:58:45,265] [INFO] [runner_train_mujoco] Average state value: 0.5213375440835953
[2022-12-07 00:58:45,265] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 00:58:45,325] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.04447
[2022-12-07 00:58:45,375] [INFO] [controller] EPOCH 2 loss ppo:  -0.02817, loss val: 0.03976
[2022-12-07 00:58:45,432] [INFO] [controller] EPOCH 3 loss ppo:  -0.03937, loss val: 0.03737
[2022-12-07 00:58:45,479] [INFO] [controller] EPOCH 4 loss ppo:  -0.04739, loss val: 0.03503
[2022-12-07 00:58:45,489] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:58:45,692] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:58:45,692] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 00:58:53,030] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 00:59:00,314] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 00:59:07,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 00:59:15,119] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 00:59:22,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 00:59:28,870] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 00:59:35,835] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 00:59:44,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 00:59:51,400] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 00:59:57,988] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3031387267654437
[2022-12-07 00:59:57,989] [INFO] [runner_train_mujoco] Average state value: 0.5951087913811206
[2022-12-07 00:59:57,989] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 00:59:58,058] [INFO] [controller] EPOCH 1 loss ppo:  -0.01285, loss val: 0.03488
[2022-12-07 00:59:58,122] [INFO] [controller] EPOCH 2 loss ppo:  -0.03381, loss val: 0.03506
[2022-12-07 00:59:58,191] [INFO] [controller] EPOCH 3 loss ppo:  -0.04570, loss val: 0.03518
[2022-12-07 00:59:58,316] [INFO] [controller] EPOCH 4 loss ppo:  -0.05706, loss val: 0.03627
[2022-12-07 00:59:58,326] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 00:59:58,518] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 00:59:58,519] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:00:05,168] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:00:12,105] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:00:19,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:00:25,660] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:00:32,787] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:00:39,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:00:46,653] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:00:53,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:01:00,042] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:01:06,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0605058433132268
[2022-12-07 01:01:06,634] [INFO] [runner_train_mujoco] Average state value: 0.6476442688107491
[2022-12-07 01:01:06,634] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 01:01:06,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.01204, loss val: 0.04655
[2022-12-07 01:01:06,745] [INFO] [controller] EPOCH 2 loss ppo:  -0.03151, loss val: 0.05053
[2022-12-07 01:01:06,800] [INFO] [controller] EPOCH 3 loss ppo:  -0.04024, loss val: 0.04408
[2022-12-07 01:01:06,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.05052, loss val: 0.04102
[2022-12-07 01:01:06,865] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:01:07,065] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:01:07,065] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:01:13,831] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:01:20,891] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:01:27,715] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:01:34,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:01:40,950] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:01:47,390] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:01:54,174] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:02:00,695] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:02:07,014] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:02:13,754] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5922707898319222
[2022-12-07 01:02:13,755] [INFO] [runner_train_mujoco] Average state value: 0.5901333607832591
[2022-12-07 01:02:13,755] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 01:02:13,817] [INFO] [controller] EPOCH 1 loss ppo:  -0.01663, loss val: 0.04168
[2022-12-07 01:02:13,861] [INFO] [controller] EPOCH 2 loss ppo:  -0.03492, loss val: 0.04058
[2022-12-07 01:02:13,904] [INFO] [controller] EPOCH 3 loss ppo:  -0.04677, loss val: 0.04168
[2022-12-07 01:02:13,964] [INFO] [controller] EPOCH 4 loss ppo:  -0.05818, loss val: 0.04110
[2022-12-07 01:02:13,974] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:02:14,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:02:14,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:02:21,381] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:02:28,349] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:02:35,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:02:41,770] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:02:48,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:02:54,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:03:01,451] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:03:08,151] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:03:14,707] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:03:21,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.879338965070761
[2022-12-07 01:03:21,660] [INFO] [runner_train_mujoco] Average state value: 0.5265598684946696
[2022-12-07 01:03:21,660] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 01:03:21,721] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04028
[2022-12-07 01:03:21,768] [INFO] [controller] EPOCH 2 loss ppo:  -0.03880, loss val: 0.03961
[2022-12-07 01:03:21,821] [INFO] [controller] EPOCH 3 loss ppo:  -0.04884, loss val: 0.03953
[2022-12-07 01:03:21,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.05744, loss val: 0.04077
[2022-12-07 01:03:21,882] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:03:22,077] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:03:22,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:03:28,778] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:03:35,593] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:03:42,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:03:48,614] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:03:55,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:04:02,667] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:04:09,328] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:04:16,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:04:22,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:04:29,552] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1656155007159903
[2022-12-07 01:04:29,552] [INFO] [runner_train_mujoco] Average state value: 0.5042414934138456
[2022-12-07 01:04:29,552] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 01:04:29,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04258
[2022-12-07 01:04:29,688] [INFO] [controller] EPOCH 2 loss ppo:  -0.03342, loss val: 0.04577
[2022-12-07 01:04:29,758] [INFO] [controller] EPOCH 3 loss ppo:  -0.04647, loss val: 0.04821
[2022-12-07 01:04:29,830] [INFO] [controller] EPOCH 4 loss ppo:  -0.05768, loss val: 0.04112
[2022-12-07 01:04:29,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:04:30,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:04:30,032] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:04:36,565] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:04:42,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:04:49,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:04:56,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:05:02,295] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:05:09,009] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:05:15,414] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:05:22,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:05:29,423] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:05:36,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0917674010180414
[2022-12-07 01:05:36,285] [INFO] [runner_train_mujoco] Average state value: 0.5230371062159539
[2022-12-07 01:05:36,285] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 01:05:36,365] [INFO] [controller] EPOCH 1 loss ppo:  -0.01577, loss val: 0.05158
[2022-12-07 01:05:36,446] [INFO] [controller] EPOCH 2 loss ppo:  -0.03460, loss val: 0.05066
[2022-12-07 01:05:36,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.04191, loss val: 0.04966
[2022-12-07 01:05:36,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.05240, loss val: 0.04905
[2022-12-07 01:05:36,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:05:36,806] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:05:36,806] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:05:43,307] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:05:50,105] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:05:56,885] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:06:03,761] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:06:10,140] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:06:16,457] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:06:23,123] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:06:30,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:06:37,743] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:06:45,055] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.596692007326876
[2022-12-07 01:06:45,056] [INFO] [runner_train_mujoco] Average state value: 0.5792833639184634
[2022-12-07 01:06:45,056] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 01:06:45,138] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.04427
[2022-12-07 01:06:45,191] [INFO] [controller] EPOCH 2 loss ppo:  -0.03078, loss val: 0.04497
[2022-12-07 01:06:45,273] [INFO] [controller] EPOCH 3 loss ppo:  -0.04461, loss val: 0.04486
[2022-12-07 01:06:45,323] [INFO] [controller] EPOCH 4 loss ppo:  -0.05596, loss val: 0.04413
[2022-12-07 01:06:45,334] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:06:45,535] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:06:45,535] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:06:52,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:07:00,021] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:07:08,017] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:07:14,631] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:07:21,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:07:28,604] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:07:35,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:07:41,664] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:07:47,693] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:07:53,822] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.764065056580492
[2022-12-07 01:07:53,822] [INFO] [runner_train_mujoco] Average state value: 0.5799090121785799
[2022-12-07 01:07:53,822] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 01:07:53,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04622
[2022-12-07 01:07:53,927] [INFO] [controller] EPOCH 2 loss ppo:  -0.03289, loss val: 0.04441
[2022-12-07 01:07:53,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.04743, loss val: 0.04345
[2022-12-07 01:07:54,019] [INFO] [controller] EPOCH 4 loss ppo:  -0.05908, loss val: 0.04262
[2022-12-07 01:07:54,028] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:07:54,215] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:07:54,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:08:00,477] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:08:06,279] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:08:12,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:08:19,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:08:24,918] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:08:31,603] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:08:38,213] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:08:44,932] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:08:50,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:08:57,001] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.780268892667672
[2022-12-07 01:08:57,001] [INFO] [runner_train_mujoco] Average state value: 0.527394246160984
[2022-12-07 01:08:57,002] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 01:08:57,061] [INFO] [controller] EPOCH 1 loss ppo:  -0.01575, loss val: 0.03350
[2022-12-07 01:08:57,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.03275, loss val: 0.03217
[2022-12-07 01:08:57,228] [INFO] [controller] EPOCH 3 loss ppo:  -0.04377, loss val: 0.03169
[2022-12-07 01:08:57,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.05425, loss val: 0.03155
[2022-12-07 01:08:57,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:08:57,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:08:57,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:09:03,742] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:09:10,369] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:09:16,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:09:22,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:09:28,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:09:35,140] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:09:41,560] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:09:48,530] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:09:55,167] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:10:01,519] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1794948193238546
[2022-12-07 01:10:01,520] [INFO] [runner_train_mujoco] Average state value: 0.47354463942845665
[2022-12-07 01:10:01,520] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 01:10:01,602] [INFO] [controller] EPOCH 1 loss ppo:  -0.01591, loss val: 0.05188
[2022-12-07 01:10:01,658] [INFO] [controller] EPOCH 2 loss ppo:  -0.03281, loss val: 0.05040
[2022-12-07 01:10:01,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.04372, loss val: 0.04951
[2022-12-07 01:10:01,755] [INFO] [controller] EPOCH 4 loss ppo:  -0.05349, loss val: 0.04813
[2022-12-07 01:10:01,765] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:10:01,954] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:10:01,955] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:10:08,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:10:14,974] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:10:21,067] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:10:27,210] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:10:33,955] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:10:40,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:10:46,911] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:10:53,109] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:10:59,003] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:11:05,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6108687561069948
[2022-12-07 01:11:05,054] [INFO] [runner_train_mujoco] Average state value: 0.4884956604639689
[2022-12-07 01:11:05,054] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 01:11:05,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.05707
[2022-12-07 01:11:05,155] [INFO] [controller] EPOCH 2 loss ppo:  -0.02968, loss val: 0.05327
[2022-12-07 01:11:05,201] [INFO] [controller] EPOCH 3 loss ppo:  -0.04068, loss val: 0.05087
[2022-12-07 01:11:05,254] [INFO] [controller] EPOCH 4 loss ppo:  -0.04900, loss val: 0.04885
[2022-12-07 01:11:05,263] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:11:05,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:11:05,455] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:11:11,983] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:11:18,438] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:11:24,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:11:31,787] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:11:38,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:11:45,789] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:11:52,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:11:58,437] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:12:04,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:12:11,116] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8307989444206925
[2022-12-07 01:12:11,117] [INFO] [runner_train_mujoco] Average state value: 0.5681908091306687
[2022-12-07 01:12:11,117] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 01:12:11,171] [INFO] [controller] EPOCH 1 loss ppo:  -0.01576, loss val: 0.04725
[2022-12-07 01:12:11,219] [INFO] [controller] EPOCH 2 loss ppo:  -0.03199, loss val: 0.05056
[2022-12-07 01:12:11,267] [INFO] [controller] EPOCH 3 loss ppo:  -0.04337, loss val: 0.04834
[2022-12-07 01:12:11,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.05081, loss val: 0.04648
[2022-12-07 01:12:11,324] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:12:11,514] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:12:11,514] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:12:17,867] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:12:24,566] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:12:31,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:12:37,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:12:43,702] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:12:49,970] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:12:56,348] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:13:02,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:13:09,059] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:13:15,575] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.890119844379806
[2022-12-07 01:13:15,576] [INFO] [runner_train_mujoco] Average state value: 0.5660517403682073
[2022-12-07 01:13:15,576] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 01:13:15,628] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04421
[2022-12-07 01:13:15,689] [INFO] [controller] EPOCH 2 loss ppo:  -0.03076, loss val: 0.04633
[2022-12-07 01:13:15,744] [INFO] [controller] EPOCH 3 loss ppo:  -0.04458, loss val: 0.04128
[2022-12-07 01:13:15,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.05003, loss val: 0.04049
[2022-12-07 01:13:15,800] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:13:15,988] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:13:15,989] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:13:22,567] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:13:29,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:13:35,605] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:13:42,099] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:13:48,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:13:54,634] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:14:01,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:14:07,756] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:14:14,236] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:14:20,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.068606768984287
[2022-12-07 01:14:20,534] [INFO] [runner_train_mujoco] Average state value: 0.5065539009571076
[2022-12-07 01:14:20,534] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 01:14:20,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04679
[2022-12-07 01:14:20,651] [INFO] [controller] EPOCH 2 loss ppo:  -0.02865, loss val: 0.04787
[2022-12-07 01:14:20,716] [INFO] [controller] EPOCH 3 loss ppo:  -0.03938, loss val: 0.04780
[2022-12-07 01:14:20,765] [INFO] [controller] EPOCH 4 loss ppo:  -0.05103, loss val: 0.04797
[2022-12-07 01:14:20,776] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:14:20,971] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:14:20,971] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:14:27,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:14:33,756] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:14:40,186] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:14:46,944] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:14:53,243] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:14:59,711] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:15:06,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:15:12,633] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:15:19,173] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:15:25,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.130644089153961
[2022-12-07 01:15:25,799] [INFO] [runner_train_mujoco] Average state value: 0.5070663371483485
[2022-12-07 01:15:25,799] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 01:15:25,853] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.04265
[2022-12-07 01:15:25,902] [INFO] [controller] EPOCH 2 loss ppo:  -0.02858, loss val: 0.04217
[2022-12-07 01:15:25,947] [INFO] [controller] EPOCH 3 loss ppo:  -0.03959, loss val: 0.04239
[2022-12-07 01:15:25,993] [INFO] [controller] EPOCH 4 loss ppo:  -0.04952, loss val: 0.04116
[2022-12-07 01:15:26,003] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:15:26,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:15:26,196] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:15:32,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:15:39,804] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:15:46,373] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:15:52,303] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:15:58,483] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:16:05,129] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:16:11,799] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:16:18,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:16:24,438] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:16:30,643] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.194784189206907
[2022-12-07 01:16:30,643] [INFO] [runner_train_mujoco] Average state value: 0.5095580474336943
[2022-12-07 01:16:30,643] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 01:16:30,705] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04538
[2022-12-07 01:16:30,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.02915, loss val: 0.04772
[2022-12-07 01:16:30,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.04112, loss val: 0.04489
[2022-12-07 01:16:30,849] [INFO] [controller] EPOCH 4 loss ppo:  -0.04957, loss val: 0.04585
[2022-12-07 01:16:30,859] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:16:31,054] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:16:31,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:16:37,961] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:16:44,353] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:16:50,958] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:16:57,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:17:03,170] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:17:09,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:17:15,692] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:17:21,767] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:17:27,962] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:17:33,786] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.16248379322837
[2022-12-07 01:17:33,786] [INFO] [runner_train_mujoco] Average state value: 0.5000041647354763
[2022-12-07 01:17:33,786] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 01:17:33,851] [INFO] [controller] EPOCH 1 loss ppo:  -0.01603, loss val: 0.03986
[2022-12-07 01:17:33,905] [INFO] [controller] EPOCH 2 loss ppo:  -0.03313, loss val: 0.03833
[2022-12-07 01:17:33,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.04127, loss val: 0.03871
[2022-12-07 01:17:34,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.05101, loss val: 0.03885
[2022-12-07 01:17:34,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:17:34,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:17:34,232] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:17:41,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:17:47,398] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:17:53,764] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:17:59,922] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:18:05,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:18:12,493] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:18:19,339] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:18:25,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:18:31,831] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:18:38,062] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.693225007332757
[2022-12-07 01:18:38,062] [INFO] [runner_train_mujoco] Average state value: 0.49101091678937275
[2022-12-07 01:18:38,062] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 01:18:38,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.01474, loss val: 0.03555
[2022-12-07 01:18:38,153] [INFO] [controller] EPOCH 2 loss ppo:  -0.02851, loss val: 0.03535
[2022-12-07 01:18:38,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.03911, loss val: 0.03530
[2022-12-07 01:18:38,233] [INFO] [controller] EPOCH 4 loss ppo:  -0.05026, loss val: 0.03946
[2022-12-07 01:18:38,243] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:18:38,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:18:38,419] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:18:44,254] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:18:50,546] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:18:56,040] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:19:01,823] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:19:07,660] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:19:13,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:19:19,087] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:19:25,343] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:19:30,967] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:19:37,032] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.2900798262021045
[2022-12-07 01:19:37,032] [INFO] [runner_train_mujoco] Average state value: 0.4757832265297572
[2022-12-07 01:19:37,032] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 01:19:37,083] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.04551
[2022-12-07 01:19:37,127] [INFO] [controller] EPOCH 2 loss ppo:  -0.03005, loss val: 0.04398
[2022-12-07 01:19:37,170] [INFO] [controller] EPOCH 3 loss ppo:  -0.04217, loss val: 0.04558
[2022-12-07 01:19:37,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.05177, loss val: 0.04375
[2022-12-07 01:19:37,221] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:19:37,406] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:19:37,407] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:19:43,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:19:49,099] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:19:54,524] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:19:59,803] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:20:05,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:20:10,939] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:20:16,809] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:20:22,814] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:20:28,455] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:20:34,186] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.778030584880287
[2022-12-07 01:20:34,186] [INFO] [runner_train_mujoco] Average state value: 0.48458313692609467
[2022-12-07 01:20:34,186] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 01:20:34,239] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.05394
[2022-12-07 01:20:34,283] [INFO] [controller] EPOCH 2 loss ppo:  -0.02761, loss val: 0.05269
[2022-12-07 01:20:34,323] [INFO] [controller] EPOCH 3 loss ppo:  -0.03951, loss val: 0.05175
[2022-12-07 01:20:34,363] [INFO] [controller] EPOCH 4 loss ppo:  -0.05172, loss val: 0.05082
[2022-12-07 01:20:34,373] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:20:34,552] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:20:34,552] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:20:40,248] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:20:45,837] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:20:51,200] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:20:56,915] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:21:02,840] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:21:08,950] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:21:14,610] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:21:20,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:21:25,647] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:21:30,913] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.622851064794842
[2022-12-07 01:21:30,914] [INFO] [runner_train_mujoco] Average state value: 0.5192556716998418
[2022-12-07 01:21:30,914] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 01:21:30,959] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.04422
[2022-12-07 01:21:31,001] [INFO] [controller] EPOCH 2 loss ppo:  -0.02340, loss val: 0.04489
[2022-12-07 01:21:31,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.03297, loss val: 0.04564
[2022-12-07 01:21:31,089] [INFO] [controller] EPOCH 4 loss ppo:  -0.04297, loss val: 0.04485
[2022-12-07 01:21:31,098] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:21:31,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:21:31,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:21:36,870] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:21:42,732] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:21:48,099] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:21:54,658] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:22:02,093] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:22:08,702] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:22:14,771] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:22:21,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:22:27,904] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:22:34,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5745098790015915
[2022-12-07 01:22:34,567] [INFO] [runner_train_mujoco] Average state value: 0.5268688646753629
[2022-12-07 01:22:34,567] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 01:22:34,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04374
[2022-12-07 01:22:34,711] [INFO] [controller] EPOCH 2 loss ppo:  -0.02271, loss val: 0.04069
[2022-12-07 01:22:34,756] [INFO] [controller] EPOCH 3 loss ppo:  -0.03543, loss val: 0.04129
[2022-12-07 01:22:34,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.04847, loss val: 0.03945
[2022-12-07 01:22:34,812] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:22:34,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:22:34,999] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:22:41,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:22:48,256] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:22:54,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:23:00,882] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:23:06,952] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:23:13,782] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:23:20,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:23:27,102] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:23:33,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:23:40,165] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.726516923577524
[2022-12-07 01:23:40,165] [INFO] [runner_train_mujoco] Average state value: 0.5218127767443657
[2022-12-07 01:23:40,165] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 01:23:40,249] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04747
[2022-12-07 01:23:40,306] [INFO] [controller] EPOCH 2 loss ppo:  -0.02721, loss val: 0.04685
[2022-12-07 01:23:40,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.03572, loss val: 0.04688
[2022-12-07 01:23:40,416] [INFO] [controller] EPOCH 4 loss ppo:  -0.04912, loss val: 0.04464
[2022-12-07 01:23:40,428] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:23:40,625] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:23:40,625] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:23:47,074] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:23:53,443] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:23:59,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:24:06,390] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:24:12,767] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:24:19,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:24:26,541] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:24:33,026] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:24:39,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:24:45,569] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.896684827265399
[2022-12-07 01:24:45,569] [INFO] [runner_train_mujoco] Average state value: 0.5321572674512863
[2022-12-07 01:24:45,570] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 01:24:45,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04384
[2022-12-07 01:24:45,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.02438, loss val: 0.04414
[2022-12-07 01:24:45,725] [INFO] [controller] EPOCH 3 loss ppo:  -0.03560, loss val: 0.04406
[2022-12-07 01:24:45,773] [INFO] [controller] EPOCH 4 loss ppo:  -0.04512, loss val: 0.04413
[2022-12-07 01:24:45,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:24:45,976] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:24:45,976] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:24:52,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:24:58,260] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:25:04,384] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:25:10,780] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:25:16,697] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:25:23,289] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:25:29,920] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:25:36,299] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:25:42,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:25:48,980] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.802005716170067
[2022-12-07 01:25:48,980] [INFO] [runner_train_mujoco] Average state value: 0.5300273165106774
[2022-12-07 01:25:48,980] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 01:25:49,031] [INFO] [controller] EPOCH 1 loss ppo:  -0.01539, loss val: 0.04347
[2022-12-07 01:25:49,080] [INFO] [controller] EPOCH 2 loss ppo:  -0.02653, loss val: 0.04340
[2022-12-07 01:25:49,129] [INFO] [controller] EPOCH 3 loss ppo:  -0.03602, loss val: 0.04276
[2022-12-07 01:25:49,177] [INFO] [controller] EPOCH 4 loss ppo:  -0.04556, loss val: 0.04317
[2022-12-07 01:25:49,186] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:25:49,381] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:25:49,382] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:25:56,288] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:26:04,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:26:10,410] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:26:16,921] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:26:23,163] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:26:29,445] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:26:35,667] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:26:42,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:26:49,288] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:26:55,588] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.960655179093659
[2022-12-07 01:26:55,588] [INFO] [runner_train_mujoco] Average state value: 0.5110128236214321
[2022-12-07 01:26:55,589] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 01:26:55,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.04030
[2022-12-07 01:26:55,695] [INFO] [controller] EPOCH 2 loss ppo:  -0.02528, loss val: 0.04020
[2022-12-07 01:26:55,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.03597, loss val: 0.04045
[2022-12-07 01:26:55,787] [INFO] [controller] EPOCH 4 loss ppo:  -0.04246, loss val: 0.03968
[2022-12-07 01:26:55,797] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:26:55,987] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:26:55,988] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:27:02,521] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:27:09,187] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:27:15,499] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:27:21,860] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:27:28,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:27:34,495] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:27:40,708] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:27:47,924] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:27:54,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:28:00,508] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.825635203324061
[2022-12-07 01:28:00,509] [INFO] [runner_train_mujoco] Average state value: 0.48651449729998913
[2022-12-07 01:28:00,509] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 01:28:00,577] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.04042
[2022-12-07 01:28:00,624] [INFO] [controller] EPOCH 2 loss ppo:  -0.02579, loss val: 0.04124
[2022-12-07 01:28:00,687] [INFO] [controller] EPOCH 3 loss ppo:  -0.03473, loss val: 0.04118
[2022-12-07 01:28:00,741] [INFO] [controller] EPOCH 4 loss ppo:  -0.04094, loss val: 0.03800
[2022-12-07 01:28:00,751] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:28:00,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:28:00,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:28:07,753] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:28:14,197] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:28:20,398] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:28:26,511] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:28:33,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:28:39,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:28:45,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:28:51,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:28:57,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:29:04,335] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0330179145994505
[2022-12-07 01:29:04,335] [INFO] [runner_train_mujoco] Average state value: 0.48033104215065636
[2022-12-07 01:29:04,335] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 01:29:04,404] [INFO] [controller] EPOCH 1 loss ppo:  -0.01569, loss val: 0.03808
[2022-12-07 01:29:04,451] [INFO] [controller] EPOCH 2 loss ppo:  -0.02704, loss val: 0.03799
[2022-12-07 01:29:04,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.03537, loss val: 0.03932
[2022-12-07 01:29:04,596] [INFO] [controller] EPOCH 4 loss ppo:  -0.04325, loss val: 0.03895
[2022-12-07 01:29:04,607] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:29:04,801] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:29:04,801] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:29:10,943] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:29:17,406] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:29:23,491] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:29:29,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:29:36,785] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:29:43,357] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:29:50,001] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:29:56,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:30:02,330] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:30:08,620] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.306834524640669
[2022-12-07 01:30:08,620] [INFO] [runner_train_mujoco] Average state value: 0.4903052294254303
[2022-12-07 01:30:08,621] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 01:30:08,684] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.04408
[2022-12-07 01:30:08,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.02270, loss val: 0.04278
[2022-12-07 01:30:08,784] [INFO] [controller] EPOCH 3 loss ppo:  -0.02883, loss val: 0.04334
[2022-12-07 01:30:08,830] [INFO] [controller] EPOCH 4 loss ppo:  -0.03694, loss val: 0.04196
[2022-12-07 01:30:08,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:30:09,029] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:30:09,030] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:30:15,145] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:30:21,851] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:30:27,951] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:30:34,509] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:30:40,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:30:46,883] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:30:53,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:30:59,067] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:31:05,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:31:11,436] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.427168506270382
[2022-12-07 01:31:11,437] [INFO] [runner_train_mujoco] Average state value: 0.4972505842049917
[2022-12-07 01:31:11,437] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 01:31:11,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.05120
[2022-12-07 01:31:11,534] [INFO] [controller] EPOCH 2 loss ppo:  -0.02241, loss val: 0.05117
[2022-12-07 01:31:11,586] [INFO] [controller] EPOCH 3 loss ppo:  -0.03139, loss val: 0.05142
[2022-12-07 01:31:11,640] [INFO] [controller] EPOCH 4 loss ppo:  -0.03897, loss val: 0.05190
[2022-12-07 01:31:11,650] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:31:11,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:31:11,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:31:18,139] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:31:24,305] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:31:30,714] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:31:36,605] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:31:43,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:31:49,393] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:31:55,795] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:32:01,968] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:32:09,211] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:32:15,821] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.404073405248996
[2022-12-07 01:32:15,821] [INFO] [runner_train_mujoco] Average state value: 0.5054851958552996
[2022-12-07 01:32:15,821] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 01:32:15,885] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.03838
[2022-12-07 01:32:15,936] [INFO] [controller] EPOCH 2 loss ppo:  -0.02236, loss val: 0.03819
[2022-12-07 01:32:15,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.02918, loss val: 0.03779
[2022-12-07 01:32:16,038] [INFO] [controller] EPOCH 4 loss ppo:  -0.03614, loss val: 0.03838
[2022-12-07 01:32:16,048] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:32:16,259] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:32:16,259] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:32:22,587] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:32:29,098] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:32:35,698] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:32:41,726] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:32:48,378] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:32:54,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:33:00,853] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:33:07,039] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:33:13,155] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:33:19,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.617433264298046
[2022-12-07 01:33:19,344] [INFO] [runner_train_mujoco] Average state value: 0.5187912749747436
[2022-12-07 01:33:19,344] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 01:33:19,401] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.04945
[2022-12-07 01:33:19,455] [INFO] [controller] EPOCH 2 loss ppo:  -0.02266, loss val: 0.04790
[2022-12-07 01:33:19,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.03054, loss val: 0.04950
[2022-12-07 01:33:19,557] [INFO] [controller] EPOCH 4 loss ppo:  -0.03658, loss val: 0.04851
[2022-12-07 01:33:19,567] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:33:19,759] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:33:19,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:33:26,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:33:32,385] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:33:38,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:33:44,933] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:33:51,575] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:33:57,932] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:34:04,097] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:34:10,632] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:34:16,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:34:22,853] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.548594151146856
[2022-12-07 01:34:22,853] [INFO] [runner_train_mujoco] Average state value: 0.5295742009679476
[2022-12-07 01:34:22,853] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 01:34:22,940] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.06250
[2022-12-07 01:34:22,994] [INFO] [controller] EPOCH 2 loss ppo:  -0.02012, loss val: 0.06244
[2022-12-07 01:34:23,056] [INFO] [controller] EPOCH 3 loss ppo:  -0.02663, loss val: 0.06251
[2022-12-07 01:34:23,115] [INFO] [controller] EPOCH 4 loss ppo:  -0.03309, loss val: 0.06286
[2022-12-07 01:34:23,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:34:23,326] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:34:23,326] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:34:29,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:34:35,383] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:34:41,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:34:47,920] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:34:54,209] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:35:00,632] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:35:07,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:35:13,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:35:20,108] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:35:26,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.318994231960989
[2022-12-07 01:35:26,173] [INFO] [runner_train_mujoco] Average state value: 0.5264089894096056
[2022-12-07 01:35:26,173] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 01:35:26,229] [INFO] [controller] EPOCH 1 loss ppo:  -0.01433, loss val: 0.04585
[2022-12-07 01:35:26,275] [INFO] [controller] EPOCH 2 loss ppo:  -0.01961, loss val: 0.04436
[2022-12-07 01:35:26,319] [INFO] [controller] EPOCH 3 loss ppo:  -0.02747, loss val: 0.04436
[2022-12-07 01:35:26,365] [INFO] [controller] EPOCH 4 loss ppo:  -0.03454, loss val: 0.04507
[2022-12-07 01:35:26,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:35:26,561] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:35:26,562] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:35:32,618] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:35:38,589] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:35:44,669] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:35:50,627] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:35:56,927] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:36:02,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:36:08,926] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:36:14,956] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:36:21,187] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:36:27,455] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.3295957465998445
[2022-12-07 01:36:27,455] [INFO] [runner_train_mujoco] Average state value: 0.5178484065731367
[2022-12-07 01:36:27,456] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 01:36:27,518] [INFO] [controller] EPOCH 1 loss ppo:  -0.01452, loss val: 0.04568
[2022-12-07 01:36:27,569] [INFO] [controller] EPOCH 2 loss ppo:  -0.01936, loss val: 0.04644
[2022-12-07 01:36:27,620] [INFO] [controller] EPOCH 3 loss ppo:  -0.02722, loss val: 0.04507
[2022-12-07 01:36:27,679] [INFO] [controller] EPOCH 4 loss ppo:  -0.03137, loss val: 0.04463
[2022-12-07 01:36:27,691] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:36:27,898] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:36:27,899] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:36:34,427] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:36:41,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:36:47,680] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:36:54,005] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:37:00,393] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:37:06,140] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:37:12,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:37:18,758] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:37:24,693] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:37:31,294] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.63054055352573
[2022-12-07 01:37:31,294] [INFO] [runner_train_mujoco] Average state value: 0.4957250845134258
[2022-12-07 01:37:31,295] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 01:37:31,353] [INFO] [controller] EPOCH 1 loss ppo:  -0.01452, loss val: 0.06690
[2022-12-07 01:37:31,398] [INFO] [controller] EPOCH 2 loss ppo:  -0.01840, loss val: 0.06320
[2022-12-07 01:37:31,446] [INFO] [controller] EPOCH 3 loss ppo:  -0.02532, loss val: 0.06288
[2022-12-07 01:37:31,491] [INFO] [controller] EPOCH 4 loss ppo:  -0.03123, loss val: 0.06315
[2022-12-07 01:37:31,504] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:37:31,689] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:37:31,689] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:37:38,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:37:44,355] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:37:50,513] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:37:56,550] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:38:03,034] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:38:09,187] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:38:15,507] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:38:21,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:38:27,883] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:38:33,960] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.594150253098935
[2022-12-07 01:38:33,960] [INFO] [runner_train_mujoco] Average state value: 0.5365389110048613
[2022-12-07 01:38:33,960] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 01:38:34,016] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.04827
[2022-12-07 01:38:34,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.01667, loss val: 0.04943
[2022-12-07 01:38:34,126] [INFO] [controller] EPOCH 3 loss ppo:  -0.02134, loss val: 0.04846
[2022-12-07 01:38:34,174] [INFO] [controller] EPOCH 4 loss ppo:  -0.02588, loss val: 0.04858
[2022-12-07 01:38:34,184] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:38:34,378] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:38:34,379] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:38:40,826] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:38:47,126] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:38:53,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:38:59,815] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:39:06,024] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:39:12,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:39:18,450] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:39:24,624] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:39:30,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:39:36,906] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.771360421740913
[2022-12-07 01:39:36,906] [INFO] [runner_train_mujoco] Average state value: 0.5378271566232046
[2022-12-07 01:39:36,906] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 01:39:36,964] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.04259
[2022-12-07 01:39:37,011] [INFO] [controller] EPOCH 2 loss ppo:  -0.01556, loss val: 0.04153
[2022-12-07 01:39:37,142] [INFO] [controller] EPOCH 3 loss ppo:  -0.01849, loss val: 0.04192
[2022-12-07 01:39:37,189] [INFO] [controller] EPOCH 4 loss ppo:  -0.02261, loss val: 0.04014
[2022-12-07 01:39:37,200] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:39:37,390] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 01:39:37,390] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 01:39:43,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 01:39:49,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 01:39:55,658] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 01:40:02,015] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 01:40:08,181] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 01:40:14,644] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 01:40:20,735] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 01:40:26,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 01:40:32,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 01:40:38,928] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.753559195050053
[2022-12-07 01:40:38,928] [INFO] [runner_train_mujoco] Average state value: 0.5378059983452161
[2022-12-07 01:40:38,928] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 01:40:38,985] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.04670
[2022-12-07 01:40:39,034] [INFO] [controller] EPOCH 2 loss ppo:  -0.01454, loss val: 0.04776
[2022-12-07 01:40:39,094] [INFO] [controller] EPOCH 3 loss ppo:  -0.01554, loss val: 0.04663
[2022-12-07 01:40:39,142] [INFO] [controller] EPOCH 4 loss ppo:  -0.01694, loss val: 0.04632
[2022-12-07 01:40:39,152] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 01:40:39,276] [INFO] [optimize] Finished learning.
