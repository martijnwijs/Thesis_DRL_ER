[2022-12-06 13:29:23,947] [INFO] [optimize] Starting learning
[2022-12-06 13:29:23,954] [INFO] [optimize] Starting learning process..
[2022-12-06 13:29:24,025] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:29:24,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:29:29,666] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:29:34,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:29:39,546] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:29:44,918] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:29:49,881] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:29:54,125] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:29:58,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:30:03,586] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:30:07,713] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:30:11,978] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42529501125589786
[2022-12-06 13:30:11,978] [INFO] [runner_train_mujoco] Average state value: -0.2699779756255448
[2022-12-06 13:30:11,978] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 13:30:12,025] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.86386
[2022-12-06 13:30:12,055] [INFO] [controller] EPOCH 2 loss ppo:  -0.04061, loss val: 0.77075
[2022-12-06 13:30:12,094] [INFO] [controller] EPOCH 3 loss ppo:  -0.05636, loss val: 0.70146
[2022-12-06 13:30:12,132] [INFO] [controller] EPOCH 4 loss ppo:  -0.06354, loss val: 0.60048
[2022-12-06 13:30:12,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:30:12,258] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:30:12,259] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:30:16,696] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:30:21,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:30:25,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:30:29,638] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:30:33,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:30:40,833] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:30:45,891] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:30:50,885] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:30:58,025] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:31:04,867] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3400209618604094
[2022-12-06 13:31:04,868] [INFO] [runner_train_mujoco] Average state value: -0.12178322234066825
[2022-12-06 13:31:04,868] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 13:31:04,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.59617
[2022-12-06 13:31:04,979] [INFO] [controller] EPOCH 2 loss ppo:  -0.03937, loss val: 0.53075
[2022-12-06 13:31:05,035] [INFO] [controller] EPOCH 3 loss ppo:  -0.05374, loss val: 0.48158
[2022-12-06 13:31:05,080] [INFO] [controller] EPOCH 4 loss ppo:  -0.06293, loss val: 0.42667
[2022-12-06 13:31:05,090] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:31:05,310] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:31:05,311] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:31:12,000] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:31:18,342] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:31:28,097] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:31:37,581] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:31:45,440] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:31:53,979] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:32:03,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:32:12,806] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:32:19,983] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:32:28,081] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37683239132247914
[2022-12-06 13:32:28,081] [INFO] [runner_train_mujoco] Average state value: 0.05158226525907715
[2022-12-06 13:32:28,081] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 13:32:28,146] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.30338
[2022-12-06 13:32:28,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03720, loss val: 0.26741
[2022-12-06 13:32:28,264] [INFO] [controller] EPOCH 3 loss ppo:  -0.04973, loss val: 0.23595
[2022-12-06 13:32:28,332] [INFO] [controller] EPOCH 4 loss ppo:  -0.06063, loss val: 0.20100
[2022-12-06 13:32:28,346] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:32:28,559] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:32:28,559] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:32:36,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:32:44,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:32:52,610] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:33:00,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:33:08,116] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:33:16,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:33:24,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:33:32,190] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:33:40,257] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:33:48,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3401737602020829
[2022-12-06 13:33:48,819] [INFO] [runner_train_mujoco] Average state value: 0.19815006199106575
[2022-12-06 13:33:48,819] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 13:33:48,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01358, loss val: 0.20712
[2022-12-06 13:33:48,946] [INFO] [controller] EPOCH 2 loss ppo:  -0.03804, loss val: 0.17894
[2022-12-06 13:33:49,045] [INFO] [controller] EPOCH 3 loss ppo:  -0.05412, loss val: 0.16094
[2022-12-06 13:33:49,152] [INFO] [controller] EPOCH 4 loss ppo:  -0.06607, loss val: 0.13872
[2022-12-06 13:33:49,166] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:33:49,402] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:33:49,403] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:33:57,653] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:34:06,258] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:34:14,352] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:34:22,751] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:34:31,353] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:34:39,957] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:34:48,191] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:34:57,030] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:35:05,736] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:35:14,029] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3772717774447555
[2022-12-06 13:35:14,030] [INFO] [runner_train_mujoco] Average state value: 0.3309595482889563
[2022-12-06 13:35:14,030] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 13:35:14,100] [INFO] [controller] EPOCH 1 loss ppo:  -0.01326, loss val: 0.13371
[2022-12-06 13:35:14,169] [INFO] [controller] EPOCH 2 loss ppo:  -0.03879, loss val: 0.11736
[2022-12-06 13:35:14,252] [INFO] [controller] EPOCH 3 loss ppo:  -0.05360, loss val: 0.10279
[2022-12-06 13:35:14,320] [INFO] [controller] EPOCH 4 loss ppo:  -0.06247, loss val: 0.08939
[2022-12-06 13:35:14,332] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:35:14,575] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:35:14,576] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:35:23,910] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:35:33,012] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:35:42,138] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:35:51,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:36:00,078] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:36:09,559] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:36:18,988] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:36:27,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:36:36,791] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:36:46,434] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3827936669496306
[2022-12-06 13:36:46,434] [INFO] [runner_train_mujoco] Average state value: 0.4691151417344809
[2022-12-06 13:36:46,434] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 13:36:46,515] [INFO] [controller] EPOCH 1 loss ppo:  -0.00959, loss val: 0.07962
[2022-12-06 13:36:46,576] [INFO] [controller] EPOCH 2 loss ppo:  -0.03123, loss val: 0.07103
[2022-12-06 13:36:46,646] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.06639
[2022-12-06 13:36:46,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.05180, loss val: 0.06228
[2022-12-06 13:36:46,714] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:36:46,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:36:46,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:36:56,195] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:37:04,982] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:37:15,227] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:37:24,365] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:37:33,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:37:41,988] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:37:50,112] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:37:58,801] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:38:07,810] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:38:16,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4827938808961707
[2022-12-06 13:38:16,126] [INFO] [runner_train_mujoco] Average state value: 0.5677264584650595
[2022-12-06 13:38:16,126] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 13:38:16,200] [INFO] [controller] EPOCH 1 loss ppo:  -0.01115, loss val: 0.06512
[2022-12-06 13:38:16,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.03170, loss val: 0.06145
[2022-12-06 13:38:16,322] [INFO] [controller] EPOCH 3 loss ppo:  -0.03993, loss val: 0.05984
[2022-12-06 13:38:16,376] [INFO] [controller] EPOCH 4 loss ppo:  -0.04920, loss val: 0.05725
[2022-12-06 13:38:16,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:38:16,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:38:16,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:38:25,363] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:38:33,801] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:38:42,354] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:38:50,252] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:38:58,518] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:39:06,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:39:14,923] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:39:22,989] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:39:31,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:39:39,431] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46735646512303264
[2022-12-06 13:39:39,432] [INFO] [runner_train_mujoco] Average state value: 0.5917678070118029
[2022-12-06 13:39:39,432] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 13:39:39,501] [INFO] [controller] EPOCH 1 loss ppo:  -0.01049, loss val: 0.06167
[2022-12-06 13:39:39,552] [INFO] [controller] EPOCH 2 loss ppo:  -0.03726, loss val: 0.06098
[2022-12-06 13:39:39,626] [INFO] [controller] EPOCH 3 loss ppo:  -0.04888, loss val: 0.05683
[2022-12-06 13:39:39,706] [INFO] [controller] EPOCH 4 loss ppo:  -0.05811, loss val: 0.05409
[2022-12-06 13:39:39,725] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:39:39,988] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:39:39,988] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:39:47,887] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:39:56,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:40:04,900] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:40:13,631] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:40:22,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:40:30,270] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:40:38,046] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:40:45,911] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:40:53,645] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:41:01,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.501037692610347
[2022-12-06 13:41:01,851] [INFO] [runner_train_mujoco] Average state value: 0.6258153851429621
[2022-12-06 13:41:01,851] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 13:41:01,925] [INFO] [controller] EPOCH 1 loss ppo:  -0.00888, loss val: 0.04648
[2022-12-06 13:41:01,983] [INFO] [controller] EPOCH 2 loss ppo:  -0.02765, loss val: 0.04440
[2022-12-06 13:41:02,038] [INFO] [controller] EPOCH 3 loss ppo:  -0.04110, loss val: 0.04412
[2022-12-06 13:41:02,093] [INFO] [controller] EPOCH 4 loss ppo:  -0.04946, loss val: 0.04395
[2022-12-06 13:41:02,104] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:41:02,325] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:41:02,325] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:41:10,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:41:18,738] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:41:26,946] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:41:35,234] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:41:43,761] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:41:51,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:42:00,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:42:08,599] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:42:16,462] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:42:25,129] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6612802594086846
[2022-12-06 13:42:25,129] [INFO] [runner_train_mujoco] Average state value: 0.6331280294855436
[2022-12-06 13:42:25,129] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 13:42:25,214] [INFO] [controller] EPOCH 1 loss ppo:  -0.01085, loss val: 0.04600
[2022-12-06 13:42:25,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.03824, loss val: 0.04497
[2022-12-06 13:42:25,328] [INFO] [controller] EPOCH 3 loss ppo:  -0.04980, loss val: 0.04336
[2022-12-06 13:42:25,382] [INFO] [controller] EPOCH 4 loss ppo:  -0.05471, loss val: 0.04266
[2022-12-06 13:42:25,401] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:42:25,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:42:25,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:42:33,454] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:42:41,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:42:50,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:42:59,649] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:43:08,436] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:43:17,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:43:25,966] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:43:34,550] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:43:43,164] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:43:51,780] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.692160443555204
[2022-12-06 13:43:51,781] [INFO] [runner_train_mujoco] Average state value: 0.5916980824371179
[2022-12-06 13:43:51,781] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 13:43:51,848] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.04511
[2022-12-06 13:43:51,910] [INFO] [controller] EPOCH 2 loss ppo:  -0.04113, loss val: 0.04577
[2022-12-06 13:43:51,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.05079, loss val: 0.04590
[2022-12-06 13:43:52,038] [INFO] [controller] EPOCH 4 loss ppo:  -0.05670, loss val: 0.04473
[2022-12-06 13:43:52,050] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:43:52,289] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:43:52,290] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:44:01,325] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:44:10,235] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:44:18,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:44:28,761] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:44:37,700] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:44:46,577] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:44:55,650] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:45:04,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:45:14,377] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:45:22,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9176529309862387
[2022-12-06 13:45:22,696] [INFO] [runner_train_mujoco] Average state value: 0.597680461426576
[2022-12-06 13:45:22,696] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 13:45:22,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01215, loss val: 0.03891
[2022-12-06 13:45:22,851] [INFO] [controller] EPOCH 2 loss ppo:  -0.03562, loss val: 0.03901
[2022-12-06 13:45:22,908] [INFO] [controller] EPOCH 3 loss ppo:  -0.04877, loss val: 0.03882
[2022-12-06 13:45:22,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.05671, loss val: 0.03988
[2022-12-06 13:45:22,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:45:23,265] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:45:23,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:45:32,029] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:45:40,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:45:49,359] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:45:58,453] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:46:07,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:46:15,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:46:23,945] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:46:31,846] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:46:39,822] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:46:48,232] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.004251461846218
[2022-12-06 13:46:48,233] [INFO] [runner_train_mujoco] Average state value: 0.6065942041873932
[2022-12-06 13:46:48,233] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 13:46:48,308] [INFO] [controller] EPOCH 1 loss ppo:  -0.01182, loss val: 0.04349
[2022-12-06 13:46:48,378] [INFO] [controller] EPOCH 2 loss ppo:  -0.03231, loss val: 0.04072
[2022-12-06 13:46:48,431] [INFO] [controller] EPOCH 3 loss ppo:  -0.04307, loss val: 0.03935
[2022-12-06 13:46:48,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.05161, loss val: 0.04064
[2022-12-06 13:46:48,495] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:46:48,740] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:46:48,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:46:57,344] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:47:05,759] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:47:13,947] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:47:22,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:47:30,467] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:47:38,201] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:47:46,449] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:47:54,343] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:48:02,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:48:09,895] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8101532227915055
[2022-12-06 13:48:09,895] [INFO] [runner_train_mujoco] Average state value: 0.5769535274704298
[2022-12-06 13:48:09,895] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 13:48:09,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01146, loss val: 0.03326
[2022-12-06 13:48:10,007] [INFO] [controller] EPOCH 2 loss ppo:  -0.03424, loss val: 0.03502
[2022-12-06 13:48:10,063] [INFO] [controller] EPOCH 3 loss ppo:  -0.04298, loss val: 0.03331
[2022-12-06 13:48:10,126] [INFO] [controller] EPOCH 4 loss ppo:  -0.05076, loss val: 0.03360
[2022-12-06 13:48:10,145] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:48:10,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:48:10,358] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:48:18,124] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:48:26,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:48:34,436] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:48:42,324] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:48:50,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:48:57,976] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:49:05,644] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:49:13,402] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:49:21,271] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:49:29,170] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.967310151202423
[2022-12-06 13:49:29,171] [INFO] [runner_train_mujoco] Average state value: 0.5432931115229925
[2022-12-06 13:49:29,171] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 13:49:29,242] [INFO] [controller] EPOCH 1 loss ppo:  -0.01183, loss val: 0.03360
[2022-12-06 13:49:29,299] [INFO] [controller] EPOCH 2 loss ppo:  -0.03456, loss val: 0.03328
[2022-12-06 13:49:29,359] [INFO] [controller] EPOCH 3 loss ppo:  -0.04830, loss val: 0.03322
[2022-12-06 13:49:29,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.05845, loss val: 0.03303
[2022-12-06 13:49:29,439] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:49:29,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:49:29,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:49:37,467] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:49:45,332] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:49:53,577] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:50:01,568] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:50:09,768] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:50:17,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:50:26,086] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:50:34,030] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:50:42,015] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:50:50,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1950596371112732
[2022-12-06 13:50:50,161] [INFO] [runner_train_mujoco] Average state value: 0.5306622331341107
[2022-12-06 13:50:50,161] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 13:50:50,226] [INFO] [controller] EPOCH 1 loss ppo:  -0.01259, loss val: 0.03752
[2022-12-06 13:50:50,283] [INFO] [controller] EPOCH 2 loss ppo:  -0.03654, loss val: 0.03488
[2022-12-06 13:50:50,339] [INFO] [controller] EPOCH 3 loss ppo:  -0.04901, loss val: 0.03500
[2022-12-06 13:50:50,391] [INFO] [controller] EPOCH 4 loss ppo:  -0.05741, loss val: 0.03479
[2022-12-06 13:50:50,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:50:50,619] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:50:50,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:50:59,268] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:51:07,824] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:51:16,243] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:51:24,828] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:51:33,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:51:41,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:51:49,771] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:51:58,368] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:52:07,120] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:52:15,552] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.164668791775251
[2022-12-06 13:52:15,553] [INFO] [runner_train_mujoco] Average state value: 0.5390713907082876
[2022-12-06 13:52:15,553] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 13:52:15,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01200, loss val: 0.03967
[2022-12-06 13:52:15,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.03424, loss val: 0.03910
[2022-12-06 13:52:15,880] [INFO] [controller] EPOCH 3 loss ppo:  -0.04556, loss val: 0.03887
[2022-12-06 13:52:15,964] [INFO] [controller] EPOCH 4 loss ppo:  -0.05527, loss val: 0.03868
[2022-12-06 13:52:15,979] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:52:16,229] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:52:16,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:52:25,112] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:52:33,665] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:52:41,948] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:52:50,584] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:52:58,820] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:53:07,966] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:53:16,716] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:53:26,236] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:53:35,202] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:53:43,905] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4736036406174944
[2022-12-06 13:53:43,905] [INFO] [runner_train_mujoco] Average state value: 0.5525264448722202
[2022-12-06 13:53:43,906] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 13:53:44,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04323
[2022-12-06 13:53:44,100] [INFO] [controller] EPOCH 2 loss ppo:  -0.03136, loss val: 0.04149
[2022-12-06 13:53:44,202] [INFO] [controller] EPOCH 3 loss ppo:  -0.04576, loss val: 0.04174
[2022-12-06 13:53:44,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.05680, loss val: 0.03680
[2022-12-06 13:53:44,306] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:53:44,547] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:53:44,548] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:53:53,190] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:54:02,425] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:54:11,178] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:54:19,910] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:54:28,373] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:54:36,808] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:54:45,058] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:54:53,639] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:55:02,285] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:55:11,011] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.859650746497793
[2022-12-06 13:55:11,012] [INFO] [runner_train_mujoco] Average state value: 0.6162533028324445
[2022-12-06 13:55:11,012] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 13:55:11,083] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04460
[2022-12-06 13:55:11,146] [INFO] [controller] EPOCH 2 loss ppo:  -0.03176, loss val: 0.04651
[2022-12-06 13:55:11,224] [INFO] [controller] EPOCH 3 loss ppo:  -0.04479, loss val: 0.04580
[2022-12-06 13:55:11,309] [INFO] [controller] EPOCH 4 loss ppo:  -0.05669, loss val: 0.04601
[2022-12-06 13:55:11,322] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:55:11,553] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:55:11,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:55:19,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:55:27,949] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:55:36,192] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:55:44,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:55:51,980] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:55:59,641] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:56:07,408] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:56:15,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:56:23,498] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:56:31,858] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7543153686641975
[2022-12-06 13:56:31,858] [INFO] [runner_train_mujoco] Average state value: 0.6538747047384579
[2022-12-06 13:56:31,858] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 13:56:32,011] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04859
[2022-12-06 13:56:32,103] [INFO] [controller] EPOCH 2 loss ppo:  -0.02808, loss val: 0.04721
[2022-12-06 13:56:32,209] [INFO] [controller] EPOCH 3 loss ppo:  -0.04174, loss val: 0.04523
[2022-12-06 13:56:32,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.05180, loss val: 0.04354
[2022-12-06 13:56:32,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:56:32,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:56:32,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:56:40,738] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:56:48,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:56:56,382] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:57:04,296] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:57:11,571] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:57:19,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:57:27,160] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:57:35,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:57:43,439] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:57:51,493] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8882577434406644
[2022-12-06 13:57:51,494] [INFO] [runner_train_mujoco] Average state value: 0.599188587129116
[2022-12-06 13:57:51,494] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 13:57:51,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.01512, loss val: 0.04443
[2022-12-06 13:57:51,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.03635, loss val: 0.03913
[2022-12-06 13:57:51,730] [INFO] [controller] EPOCH 3 loss ppo:  -0.04780, loss val: 0.03605
[2022-12-06 13:57:51,790] [INFO] [controller] EPOCH 4 loss ppo:  -0.05788, loss val: 0.03448
[2022-12-06 13:57:51,802] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:57:52,033] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:57:52,033] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:57:59,985] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:58:10,743] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:58:22,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:58:31,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:58:40,712] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:58:52,581] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:59:04,821] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:59:15,063] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:59:25,795] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:59:37,060] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1286667800061743
[2022-12-06 13:59:37,061] [INFO] [runner_train_mujoco] Average state value: 0.5207336173057556
[2022-12-06 13:59:37,061] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 13:59:38,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04565
[2022-12-06 13:59:39,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.03626, loss val: 0.04700
[2022-12-06 13:59:39,850] [INFO] [controller] EPOCH 3 loss ppo:  -0.04644, loss val: 0.05034
[2022-12-06 13:59:39,914] [INFO] [controller] EPOCH 4 loss ppo:  -0.05821, loss val: 0.04982
[2022-12-06 13:59:39,932] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:59:40,197] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:59:40,197] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:59:51,096] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:00:00,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:00:09,680] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:00:19,437] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:00:28,798] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:00:38,396] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:00:51,876] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:01:05,367] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:01:18,610] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:01:31,110] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0861187771285685
[2022-12-06 14:01:31,111] [INFO] [runner_train_mujoco] Average state value: 0.5093455826342106
[2022-12-06 14:01:31,111] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 14:01:31,255] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.03687
[2022-12-06 14:01:31,353] [INFO] [controller] EPOCH 2 loss ppo:  -0.03452, loss val: 0.03525
[2022-12-06 14:01:31,456] [INFO] [controller] EPOCH 3 loss ppo:  -0.04734, loss val: 0.03693
[2022-12-06 14:01:31,565] [INFO] [controller] EPOCH 4 loss ppo:  -0.05732, loss val: 0.03798
[2022-12-06 14:01:31,591] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:01:31,879] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:01:31,879] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:01:46,698] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:01:59,258] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:02:08,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:02:18,429] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:02:28,801] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:02:39,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:02:49,155] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:02:58,478] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:03:08,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:03:19,326] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5528566610415773
[2022-12-06 14:03:19,326] [INFO] [runner_train_mujoco] Average state value: 0.5211081903378169
[2022-12-06 14:03:19,326] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 14:03:19,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01626, loss val: 0.04341
[2022-12-06 14:03:19,783] [INFO] [controller] EPOCH 2 loss ppo:  -0.03764, loss val: 0.04413
[2022-12-06 14:03:19,946] [INFO] [controller] EPOCH 3 loss ppo:  -0.04510, loss val: 0.04370
[2022-12-06 14:03:20,027] [INFO] [controller] EPOCH 4 loss ppo:  -0.05486, loss val: 0.04354
[2022-12-06 14:03:20,044] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:03:20,373] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:03:20,373] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:03:30,383] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:03:39,366] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:03:48,323] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:03:57,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:04:06,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:04:15,191] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:04:24,169] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:04:32,839] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:04:41,299] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:04:49,783] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4880032541397865
[2022-12-06 14:04:49,784] [INFO] [runner_train_mujoco] Average state value: 0.5275687406559786
[2022-12-06 14:04:49,784] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 14:04:49,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.03988
[2022-12-06 14:04:49,936] [INFO] [controller] EPOCH 2 loss ppo:  -0.03131, loss val: 0.04054
[2022-12-06 14:04:49,994] [INFO] [controller] EPOCH 3 loss ppo:  -0.04745, loss val: 0.04028
[2022-12-06 14:04:50,053] [INFO] [controller] EPOCH 4 loss ppo:  -0.06032, loss val: 0.03962
[2022-12-06 14:04:50,065] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:04:50,324] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:04:50,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:04:58,954] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:05:07,449] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:05:15,925] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:05:24,863] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:05:34,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:05:43,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:05:51,481] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:05:59,156] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:06:06,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:06:15,552] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5361724570713937
[2022-12-06 14:06:15,552] [INFO] [runner_train_mujoco] Average state value: 0.5334802765250206
[2022-12-06 14:06:15,552] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 14:06:15,689] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04019
[2022-12-06 14:06:15,755] [INFO] [controller] EPOCH 2 loss ppo:  -0.03223, loss val: 0.04242
[2022-12-06 14:06:15,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.04479, loss val: 0.04486
[2022-12-06 14:06:15,908] [INFO] [controller] EPOCH 4 loss ppo:  -0.05533, loss val: 0.04310
[2022-12-06 14:06:15,920] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:06:16,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:06:16,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:06:26,804] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:06:38,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:06:48,962] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:07:00,563] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:07:12,993] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:07:22,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:07:34,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:07:45,931] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:07:54,742] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:08:02,843] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.016582021083141
[2022-12-06 14:08:02,843] [INFO] [runner_train_mujoco] Average state value: 0.5317248596151669
[2022-12-06 14:08:02,843] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 14:08:02,968] [INFO] [controller] EPOCH 1 loss ppo:  -0.01171, loss val: 0.04144
[2022-12-06 14:08:03,050] [INFO] [controller] EPOCH 2 loss ppo:  -0.03051, loss val: 0.04074
[2022-12-06 14:08:03,180] [INFO] [controller] EPOCH 3 loss ppo:  -0.04013, loss val: 0.04057
[2022-12-06 14:08:03,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.04984, loss val: 0.03910
[2022-12-06 14:08:03,272] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:08:03,528] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:08:03,529] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:08:12,047] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:08:20,975] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:08:29,969] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:08:38,897] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:08:47,664] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:08:56,236] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:09:04,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:09:13,594] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:09:22,798] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:09:31,539] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0187851720803143
[2022-12-06 14:09:31,540] [INFO] [runner_train_mujoco] Average state value: 0.5041402236620585
[2022-12-06 14:09:31,540] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 14:09:31,626] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.03733
[2022-12-06 14:09:31,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.03640, loss val: 0.03734
[2022-12-06 14:09:31,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.04718, loss val: 0.03752
[2022-12-06 14:09:32,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.05734, loss val: 0.03634
[2022-12-06 14:09:32,043] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:09:32,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:09:32,294] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:09:40,538] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:09:49,649] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:09:58,721] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:10:07,543] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:10:16,645] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:10:25,552] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:10:34,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:10:43,213] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:10:52,287] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:11:00,516] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.554256407064017
[2022-12-06 14:11:00,517] [INFO] [runner_train_mujoco] Average state value: 0.4642601341406505
[2022-12-06 14:11:00,517] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 14:11:00,588] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04617
[2022-12-06 14:11:00,674] [INFO] [controller] EPOCH 2 loss ppo:  -0.03183, loss val: 0.04635
[2022-12-06 14:11:00,736] [INFO] [controller] EPOCH 3 loss ppo:  -0.04503, loss val: 0.04359
[2022-12-06 14:11:00,802] [INFO] [controller] EPOCH 4 loss ppo:  -0.05603, loss val: 0.04406
[2022-12-06 14:11:00,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:11:01,055] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:11:01,056] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:11:09,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:11:17,765] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:11:27,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:11:36,003] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:11:44,441] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:11:53,024] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:12:01,145] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:12:09,324] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:12:17,051] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:12:24,606] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.294609541530046
[2022-12-06 14:12:24,606] [INFO] [runner_train_mujoco] Average state value: 0.48602093601226803
[2022-12-06 14:12:24,606] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 14:12:24,669] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04490
[2022-12-06 14:12:24,725] [INFO] [controller] EPOCH 2 loss ppo:  -0.03037, loss val: 0.04404
[2022-12-06 14:12:24,780] [INFO] [controller] EPOCH 3 loss ppo:  -0.04258, loss val: 0.04339
[2022-12-06 14:12:24,832] [INFO] [controller] EPOCH 4 loss ppo:  -0.05443, loss val: 0.04410
[2022-12-06 14:12:24,843] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:12:25,058] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:12:25,058] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:12:33,133] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:12:41,404] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:12:49,786] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:12:58,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:13:06,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:13:13,879] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:13:21,462] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:13:29,092] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:13:36,881] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:13:44,425] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4556473123956537
[2022-12-06 14:13:44,425] [INFO] [runner_train_mujoco] Average state value: 0.52831385354201
[2022-12-06 14:13:44,425] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 14:13:44,486] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.04007
[2022-12-06 14:13:44,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.03448, loss val: 0.03817
[2022-12-06 14:13:44,613] [INFO] [controller] EPOCH 3 loss ppo:  -0.04520, loss val: 0.03921
[2022-12-06 14:13:44,667] [INFO] [controller] EPOCH 4 loss ppo:  -0.05610, loss val: 0.03815
[2022-12-06 14:13:44,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:13:44,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:13:44,891] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:13:52,699] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:14:00,428] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:14:08,422] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:14:17,213] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:14:26,151] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:14:34,725] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:14:42,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:14:50,606] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:14:58,651] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:15:06,653] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.766779038873465
[2022-12-06 14:15:06,653] [INFO] [runner_train_mujoco] Average state value: 0.5244041477441788
[2022-12-06 14:15:06,653] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 14:15:06,723] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.03808
[2022-12-06 14:15:06,777] [INFO] [controller] EPOCH 2 loss ppo:  -0.03076, loss val: 0.03735
[2022-12-06 14:15:06,837] [INFO] [controller] EPOCH 3 loss ppo:  -0.04103, loss val: 0.03709
[2022-12-06 14:15:06,898] [INFO] [controller] EPOCH 4 loss ppo:  -0.05004, loss val: 0.03629
[2022-12-06 14:15:06,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:15:07,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:15:07,128] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:15:16,222] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:15:25,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:15:33,888] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:15:43,446] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:15:52,596] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:16:01,563] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:16:12,224] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:16:23,441] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:16:34,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:16:45,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8513523163091903
[2022-12-06 14:16:45,485] [INFO] [runner_train_mujoco] Average state value: 0.5066583891908328
[2022-12-06 14:16:45,485] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 14:16:46,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.04609
[2022-12-06 14:16:46,818] [INFO] [controller] EPOCH 2 loss ppo:  -0.03157, loss val: 0.04609
[2022-12-06 14:16:46,911] [INFO] [controller] EPOCH 3 loss ppo:  -0.04116, loss val: 0.04634
[2022-12-06 14:16:46,994] [INFO] [controller] EPOCH 4 loss ppo:  -0.05410, loss val: 0.04586
[2022-12-06 14:16:47,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:16:47,339] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:16:47,348] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:16:59,424] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:17:09,209] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:17:18,527] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:17:27,615] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:17:36,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:17:45,964] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:17:56,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:18:05,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:18:14,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:18:24,501] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7420432413961655
[2022-12-06 14:18:24,501] [INFO] [runner_train_mujoco] Average state value: 0.48646630264570323
[2022-12-06 14:18:24,502] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 14:18:24,718] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.05242
[2022-12-06 14:18:25,112] [INFO] [controller] EPOCH 2 loss ppo:  -0.02672, loss val: 0.05117
[2022-12-06 14:18:25,167] [INFO] [controller] EPOCH 3 loss ppo:  -0.03770, loss val: 0.05502
[2022-12-06 14:18:25,268] [INFO] [controller] EPOCH 4 loss ppo:  -0.05241, loss val: 0.04969
[2022-12-06 14:18:25,280] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:18:25,529] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:18:25,530] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:18:35,080] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:18:45,122] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:18:54,617] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:19:04,062] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:19:13,899] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:19:22,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:19:32,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:19:41,572] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:19:50,448] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:19:59,365] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.116792347124869
[2022-12-06 14:19:59,365] [INFO] [runner_train_mujoco] Average state value: 0.4905795090993245
[2022-12-06 14:19:59,365] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 14:19:59,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01443, loss val: 0.04126
[2022-12-06 14:19:59,644] [INFO] [controller] EPOCH 2 loss ppo:  -0.02844, loss val: 0.04592
[2022-12-06 14:19:59,730] [INFO] [controller] EPOCH 3 loss ppo:  -0.03977, loss val: 0.04241
[2022-12-06 14:19:59,827] [INFO] [controller] EPOCH 4 loss ppo:  -0.04819, loss val: 0.04177
[2022-12-06 14:19:59,839] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:20:00,092] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:20:00,092] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:20:09,317] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:20:19,057] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:20:27,933] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:20:36,588] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:20:45,872] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:20:54,220] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:21:02,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:21:13,470] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:21:25,197] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:21:34,370] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7960990330446647
[2022-12-06 14:21:34,371] [INFO] [runner_train_mujoco] Average state value: 0.5104669609268507
[2022-12-06 14:21:34,371] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 14:21:34,537] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.03998
[2022-12-06 14:21:34,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.03054, loss val: 0.03963
[2022-12-06 14:21:34,746] [INFO] [controller] EPOCH 3 loss ppo:  -0.04086, loss val: 0.03958
[2022-12-06 14:21:34,903] [INFO] [controller] EPOCH 4 loss ppo:  -0.05251, loss val: 0.03936
[2022-12-06 14:21:34,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:21:35,165] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:21:35,166] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:21:46,800] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:21:56,008] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:22:04,593] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:22:12,773] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:22:20,456] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:22:28,965] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:22:36,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:22:45,518] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:22:53,921] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:23:02,540] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.896371627866684
[2022-12-06 14:23:02,541] [INFO] [runner_train_mujoco] Average state value: 0.5274643523097039
[2022-12-06 14:23:02,541] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 14:23:02,636] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04627
[2022-12-06 14:23:02,712] [INFO] [controller] EPOCH 2 loss ppo:  -0.02526, loss val: 0.04621
[2022-12-06 14:23:02,783] [INFO] [controller] EPOCH 3 loss ppo:  -0.03557, loss val: 0.04536
[2022-12-06 14:23:02,872] [INFO] [controller] EPOCH 4 loss ppo:  -0.04599, loss val: 0.04426
[2022-12-06 14:23:02,884] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:23:03,132] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:23:03,132] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:23:11,713] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:23:20,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:23:29,652] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:23:37,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:23:46,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:23:54,163] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:24:02,635] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:24:10,934] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:24:20,405] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:24:29,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.355332327935683
[2022-12-06 14:24:29,345] [INFO] [runner_train_mujoco] Average state value: 0.5147331876655421
[2022-12-06 14:24:29,345] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 14:24:29,585] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.04413
[2022-12-06 14:24:29,668] [INFO] [controller] EPOCH 2 loss ppo:  -0.02644, loss val: 0.04266
[2022-12-06 14:24:29,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.03630, loss val: 0.04168
[2022-12-06 14:24:29,775] [INFO] [controller] EPOCH 4 loss ppo:  -0.04423, loss val: 0.04014
[2022-12-06 14:24:29,786] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:24:30,006] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:24:30,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:24:39,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:24:47,639] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:24:55,514] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:25:05,823] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:25:14,991] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:25:24,750] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:25:35,182] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:25:45,668] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:25:56,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:26:06,286] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.4139479150505165
[2022-12-06 14:26:06,286] [INFO] [runner_train_mujoco] Average state value: 0.466925435423851
[2022-12-06 14:26:06,287] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 14:26:06,387] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.04632
[2022-12-06 14:26:06,455] [INFO] [controller] EPOCH 2 loss ppo:  -0.02547, loss val: 0.04799
[2022-12-06 14:26:06,524] [INFO] [controller] EPOCH 3 loss ppo:  -0.03484, loss val: 0.04837
[2022-12-06 14:26:06,596] [INFO] [controller] EPOCH 4 loss ppo:  -0.04410, loss val: 0.04792
[2022-12-06 14:26:06,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:26:06,854] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:26:06,855] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:26:17,684] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:26:27,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:26:40,279] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:26:51,121] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:27:00,695] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:27:10,413] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:27:20,338] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:27:30,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:27:40,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:27:51,527] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.381569935311486
[2022-12-06 14:27:51,527] [INFO] [runner_train_mujoco] Average state value: 0.45378450488547484
[2022-12-06 14:27:51,527] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 14:27:51,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.04974
[2022-12-06 14:27:51,680] [INFO] [controller] EPOCH 2 loss ppo:  -0.02733, loss val: 0.04897
[2022-12-06 14:27:51,741] [INFO] [controller] EPOCH 3 loss ppo:  -0.03821, loss val: 0.04632
[2022-12-06 14:27:51,804] [INFO] [controller] EPOCH 4 loss ppo:  -0.04692, loss val: 0.04957
[2022-12-06 14:27:51,819] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:27:52,089] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:27:52,090] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:28:02,708] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:28:15,620] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:28:27,538] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:28:39,250] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:28:50,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:29:00,330] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:29:10,870] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:29:21,538] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:29:32,939] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:29:43,911] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.083668255725017
[2022-12-06 14:29:43,912] [INFO] [runner_train_mujoco] Average state value: 0.49570637782414756
[2022-12-06 14:29:43,912] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 14:29:44,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.03604
[2022-12-06 14:29:44,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.02680, loss val: 0.03581
[2022-12-06 14:29:44,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.04136, loss val: 0.03531
[2022-12-06 14:29:44,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.05418, loss val: 0.03542
[2022-12-06 14:29:44,367] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:29:44,671] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:29:44,672] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:29:57,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:30:08,698] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:30:20,478] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:30:32,291] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:30:44,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:30:56,554] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:31:08,435] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:31:19,157] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:31:29,981] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:31:41,945] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.194597760417749
[2022-12-06 14:31:41,945] [INFO] [runner_train_mujoco] Average state value: 0.4971332061017553
[2022-12-06 14:31:41,946] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 14:31:42,122] [INFO] [controller] EPOCH 1 loss ppo:  -0.01549, loss val: 0.06774
[2022-12-06 14:31:42,312] [INFO] [controller] EPOCH 2 loss ppo:  -0.02832, loss val: 0.06733
[2022-12-06 14:31:42,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.03603, loss val: 0.06540
[2022-12-06 14:31:42,518] [INFO] [controller] EPOCH 4 loss ppo:  -0.04403, loss val: 0.06069
[2022-12-06 14:31:42,534] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:31:42,912] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:31:42,927] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:31:54,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:32:04,661] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:32:15,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:32:25,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:32:35,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:32:45,068] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:32:55,142] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:33:04,694] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:33:13,952] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:33:23,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.241154845750773
[2022-12-06 14:33:23,066] [INFO] [runner_train_mujoco] Average state value: 0.5441945357508957
[2022-12-06 14:33:23,066] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 14:33:23,150] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.04310
[2022-12-06 14:33:23,210] [INFO] [controller] EPOCH 2 loss ppo:  -0.02335, loss val: 0.04197
[2022-12-06 14:33:23,279] [INFO] [controller] EPOCH 3 loss ppo:  -0.03472, loss val: 0.04106
[2022-12-06 14:33:23,342] [INFO] [controller] EPOCH 4 loss ppo:  -0.04426, loss val: 0.04064
[2022-12-06 14:33:23,386] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:33:23,671] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:33:23,671] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:33:33,238] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:33:42,532] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:33:52,162] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:34:01,221] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:34:10,496] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:34:20,505] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:34:30,066] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:34:39,637] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:34:50,237] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:35:00,770] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.708776745932071
[2022-12-06 14:35:00,770] [INFO] [runner_train_mujoco] Average state value: 0.5875884230534236
[2022-12-06 14:35:00,771] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 14:35:00,953] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.05379
[2022-12-06 14:35:01,077] [INFO] [controller] EPOCH 2 loss ppo:  -0.02417, loss val: 0.05367
[2022-12-06 14:35:01,145] [INFO] [controller] EPOCH 3 loss ppo:  -0.03388, loss val: 0.05260
[2022-12-06 14:35:01,243] [INFO] [controller] EPOCH 4 loss ppo:  -0.04187, loss val: 0.05194
[2022-12-06 14:35:01,257] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:35:01,542] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:35:01,542] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:35:11,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:35:21,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:35:31,297] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:35:40,575] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:35:49,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:35:57,366] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:36:05,579] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:36:14,143] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:36:25,267] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:36:34,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.368546468182718
[2022-12-06 14:36:34,223] [INFO] [runner_train_mujoco] Average state value: 0.5789494694806635
[2022-12-06 14:36:34,224] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 14:36:34,313] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.04171
[2022-12-06 14:36:34,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.02297, loss val: 0.04102
[2022-12-06 14:36:34,506] [INFO] [controller] EPOCH 3 loss ppo:  -0.03518, loss val: 0.04392
[2022-12-06 14:36:34,608] [INFO] [controller] EPOCH 4 loss ppo:  -0.04339, loss val: 0.04118
[2022-12-06 14:36:34,619] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:36:34,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:36:34,843] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:36:43,128] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:36:51,035] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:36:59,185] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:37:07,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:37:15,668] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:37:23,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:37:32,061] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:37:39,768] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:37:47,783] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:37:55,845] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.306485995104444
[2022-12-06 14:37:55,845] [INFO] [runner_train_mujoco] Average state value: 0.5745286196122568
[2022-12-06 14:37:55,845] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 14:37:55,939] [INFO] [controller] EPOCH 1 loss ppo:  -0.01404, loss val: 0.04231
[2022-12-06 14:37:56,049] [INFO] [controller] EPOCH 2 loss ppo:  -0.02407, loss val: 0.04208
[2022-12-06 14:37:56,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.03136, loss val: 0.04101
[2022-12-06 14:37:56,203] [INFO] [controller] EPOCH 4 loss ppo:  -0.03800, loss val: 0.04089
[2022-12-06 14:37:56,224] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:37:56,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:37:56,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:38:04,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:38:16,380] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:38:24,687] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:38:33,638] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:38:42,072] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:38:49,912] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:38:57,204] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:39:05,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:39:14,030] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:39:23,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.329186871838331
[2022-12-06 14:39:23,149] [INFO] [runner_train_mujoco] Average state value: 0.5708212670435509
[2022-12-06 14:39:23,150] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 14:39:23,251] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.03907
[2022-12-06 14:39:23,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.02428, loss val: 0.03850
[2022-12-06 14:39:23,380] [INFO] [controller] EPOCH 3 loss ppo:  -0.03191, loss val: 0.03926
[2022-12-06 14:39:23,444] [INFO] [controller] EPOCH 4 loss ppo:  -0.03966, loss val: 0.03883
[2022-12-06 14:39:23,460] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:39:23,678] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:39:23,678] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:39:32,482] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:39:41,227] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:39:50,383] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:39:59,864] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:40:09,012] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:40:18,411] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:40:27,570] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:40:37,026] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:40:46,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:40:55,797] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.557985202074409
[2022-12-06 14:40:55,797] [INFO] [runner_train_mujoco] Average state value: 0.5758244697451592
[2022-12-06 14:40:55,797] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 14:40:55,896] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.04197
[2022-12-06 14:40:55,978] [INFO] [controller] EPOCH 2 loss ppo:  -0.02070, loss val: 0.04101
[2022-12-06 14:40:56,068] [INFO] [controller] EPOCH 3 loss ppo:  -0.03207, loss val: 0.04023
[2022-12-06 14:40:56,173] [INFO] [controller] EPOCH 4 loss ppo:  -0.03813, loss val: 0.03995
[2022-12-06 14:40:56,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:40:56,451] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:40:56,451] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:41:07,819] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:41:16,794] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:41:25,237] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:41:34,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:41:43,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:41:51,539] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:42:00,262] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:42:08,934] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:42:17,837] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:42:26,809] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.505360817689779
[2022-12-06 14:42:26,809] [INFO] [runner_train_mujoco] Average state value: 0.5812047738904755
[2022-12-06 14:42:26,810] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 14:42:26,940] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.05202
[2022-12-06 14:42:26,993] [INFO] [controller] EPOCH 2 loss ppo:  -0.02288, loss val: 0.05118
[2022-12-06 14:42:27,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.03450, loss val: 0.05152
[2022-12-06 14:42:27,169] [INFO] [controller] EPOCH 4 loss ppo:  -0.04235, loss val: 0.05104
[2022-12-06 14:42:27,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:42:27,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:42:27,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:42:36,749] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:42:45,715] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:42:54,551] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:43:03,821] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:43:13,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:43:24,095] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:43:32,120] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:43:40,254] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:43:48,496] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:43:56,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.643992649999575
[2022-12-06 14:43:56,634] [INFO] [runner_train_mujoco] Average state value: 0.6132289127111435
[2022-12-06 14:43:56,634] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 14:43:56,801] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.05813
[2022-12-06 14:43:56,886] [INFO] [controller] EPOCH 2 loss ppo:  -0.02312, loss val: 0.05983
[2022-12-06 14:43:57,012] [INFO] [controller] EPOCH 3 loss ppo:  -0.03107, loss val: 0.05764
[2022-12-06 14:43:57,111] [INFO] [controller] EPOCH 4 loss ppo:  -0.03574, loss val: 0.05629
[2022-12-06 14:43:57,129] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:43:57,443] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:43:57,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:44:06,011] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:44:14,290] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:44:22,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:44:30,211] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:44:38,183] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:44:46,462] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:44:54,900] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:45:03,600] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:45:12,348] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:45:22,616] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.761325395730117
[2022-12-06 14:45:22,617] [INFO] [runner_train_mujoco] Average state value: 0.5917145628879468
[2022-12-06 14:45:22,617] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 14:45:22,732] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.03667
[2022-12-06 14:45:22,823] [INFO] [controller] EPOCH 2 loss ppo:  -0.02122, loss val: 0.03685
[2022-12-06 14:45:22,919] [INFO] [controller] EPOCH 3 loss ppo:  -0.03238, loss val: 0.03853
[2022-12-06 14:45:23,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.03991, loss val: 0.03705
[2022-12-06 14:45:23,036] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:45:23,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:45:23,283] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:45:32,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:45:40,487] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:45:48,915] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:45:57,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:46:06,672] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:46:15,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:46:23,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:46:33,080] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:46:42,400] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:46:51,418] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.193086350152813
[2022-12-06 14:46:51,418] [INFO] [runner_train_mujoco] Average state value: 0.598134591281414
[2022-12-06 14:46:51,418] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 14:46:51,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04807
[2022-12-06 14:46:51,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.01920, loss val: 0.04773
[2022-12-06 14:46:51,676] [INFO] [controller] EPOCH 3 loss ppo:  -0.02677, loss val: 0.04687
[2022-12-06 14:46:51,785] [INFO] [controller] EPOCH 4 loss ppo:  -0.03271, loss val: 0.04654
[2022-12-06 14:46:51,798] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:46:52,022] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:46:52,022] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:47:01,046] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:47:09,913] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:47:18,971] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:47:28,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:47:37,324] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:47:46,104] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:47:55,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:48:04,394] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:48:13,504] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:48:21,941] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.782665845029177
[2022-12-06 14:48:21,941] [INFO] [runner_train_mujoco] Average state value: 0.5812595440534254
[2022-12-06 14:48:21,941] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 14:48:22,026] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.04952
[2022-12-06 14:48:22,087] [INFO] [controller] EPOCH 2 loss ppo:  -0.01806, loss val: 0.04920
[2022-12-06 14:48:22,144] [INFO] [controller] EPOCH 3 loss ppo:  -0.02571, loss val: 0.04967
[2022-12-06 14:48:22,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.03390, loss val: 0.04974
[2022-12-06 14:48:22,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:48:22,548] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:48:22,549] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:48:30,710] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:48:38,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:48:47,660] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:48:56,259] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:49:04,592] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:49:13,241] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:49:22,323] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:49:30,724] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:49:39,053] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:49:46,691] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.912932420104226
[2022-12-06 14:49:46,692] [INFO] [runner_train_mujoco] Average state value: 0.5843203782240549
[2022-12-06 14:49:46,692] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 14:49:46,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.05555
[2022-12-06 14:49:46,833] [INFO] [controller] EPOCH 2 loss ppo:  -0.01731, loss val: 0.05708
[2022-12-06 14:49:46,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.02292, loss val: 0.05363
[2022-12-06 14:49:46,993] [INFO] [controller] EPOCH 4 loss ppo:  -0.02902, loss val: 0.05331
[2022-12-06 14:49:47,005] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:49:47,238] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:49:47,239] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:49:55,101] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:50:02,852] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:50:10,583] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:50:18,898] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:50:26,630] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:50:34,091] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:50:42,160] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:50:51,009] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:50:59,224] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:51:07,439] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.509520925332181
[2022-12-06 14:51:07,440] [INFO] [runner_train_mujoco] Average state value: 0.5786241721312205
[2022-12-06 14:51:07,440] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 14:51:07,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.03830
[2022-12-06 14:51:07,741] [INFO] [controller] EPOCH 2 loss ppo:  -0.01782, loss val: 0.03832
[2022-12-06 14:51:07,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.02534, loss val: 0.03799
[2022-12-06 14:51:07,948] [INFO] [controller] EPOCH 4 loss ppo:  -0.03202, loss val: 0.03874
[2022-12-06 14:51:07,959] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:51:08,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:51:08,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:51:16,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:51:24,444] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:51:32,257] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:51:39,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:51:47,223] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:51:54,860] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:52:03,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:52:12,091] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:52:20,055] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:52:28,483] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.733484782398056
[2022-12-06 14:52:28,483] [INFO] [runner_train_mujoco] Average state value: 0.5655539439618587
[2022-12-06 14:52:28,483] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 14:52:28,553] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.02939
[2022-12-06 14:52:28,614] [INFO] [controller] EPOCH 2 loss ppo:  -0.01555, loss val: 0.02953
[2022-12-06 14:52:28,688] [INFO] [controller] EPOCH 3 loss ppo:  -0.01899, loss val: 0.02956
[2022-12-06 14:52:28,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.02366, loss val: 0.02951
[2022-12-06 14:52:28,765] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:52:28,990] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:52:28,990] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:52:37,124] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:52:45,382] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:52:53,875] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:53:02,188] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:53:11,186] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:53:19,965] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:53:30,694] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:53:39,691] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:53:48,285] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:53:56,696] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.74122015657513
[2022-12-06 14:53:56,697] [INFO] [runner_train_mujoco] Average state value: 0.5649957164687415
[2022-12-06 14:53:56,697] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 14:53:56,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.05040
[2022-12-06 14:53:56,825] [INFO] [controller] EPOCH 2 loss ppo:  -0.01403, loss val: 0.05011
[2022-12-06 14:53:56,968] [INFO] [controller] EPOCH 3 loss ppo:  -0.01577, loss val: 0.04989
[2022-12-06 14:53:57,045] [INFO] [controller] EPOCH 4 loss ppo:  -0.01834, loss val: 0.05036
[2022-12-06 14:53:57,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:53:57,325] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:53:57,325] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:54:05,761] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:54:14,242] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:54:23,606] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:54:32,709] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:54:41,676] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:54:50,759] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:54:59,838] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:55:08,676] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:55:17,329] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:55:25,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.830638243931206
[2022-12-06 14:55:25,416] [INFO] [runner_train_mujoco] Average state value: 0.570271979317069
[2022-12-06 14:55:25,416] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 14:55:25,487] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.03128
[2022-12-06 14:55:25,541] [INFO] [controller] EPOCH 2 loss ppo:  -0.01498, loss val: 0.03699
[2022-12-06 14:55:25,592] [INFO] [controller] EPOCH 3 loss ppo:  -0.01682, loss val: 0.03005
[2022-12-06 14:55:25,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.01919, loss val: 0.02993
[2022-12-06 14:55:25,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:55:25,823] [INFO] [optimize] Finished learning.
