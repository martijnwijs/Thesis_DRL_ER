[2022-12-07 06:45:07,751] [INFO] [optimize] Starting learning
[2022-12-07 06:45:07,759] [INFO] [optimize] Starting learning process..
[2022-12-07 06:45:07,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:45:07,905] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:45:15,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:45:21,465] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:45:27,216] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:45:33,700] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:45:39,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:45:46,589] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:45:52,785] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:45:59,118] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:46:05,214] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:46:11,360] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.36212907536028033
[2022-12-07 06:46:11,360] [INFO] [runner_train_mujoco] Average state value: 0.07410481183106701
[2022-12-07 06:46:11,361] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 06:46:11,419] [INFO] [controller] EPOCH 1 loss ppo:  -0.01143, loss val: 0.37707
[2022-12-07 06:46:11,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.04473, loss val: 0.32607
[2022-12-07 06:46:11,515] [INFO] [controller] EPOCH 3 loss ppo:  -0.05775, loss val: 0.32299
[2022-12-07 06:46:11,562] [INFO] [controller] EPOCH 4 loss ppo:  -0.06399, loss val: 0.26732
[2022-12-07 06:46:11,574] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:46:11,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:46:11,766] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:46:17,923] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:46:24,276] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:46:30,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:46:35,677] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:46:42,083] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:46:48,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:46:54,647] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:47:01,776] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:47:09,888] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:47:16,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4572831233877678
[2022-12-07 06:47:16,851] [INFO] [runner_train_mujoco] Average state value: 0.24347929060148696
[2022-12-07 06:47:16,851] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 06:47:16,917] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.29823
[2022-12-07 06:47:16,969] [INFO] [controller] EPOCH 2 loss ppo:  -0.03540, loss val: 0.26545
[2022-12-07 06:47:17,032] [INFO] [controller] EPOCH 3 loss ppo:  -0.05006, loss val: 0.24366
[2022-12-07 06:47:17,120] [INFO] [controller] EPOCH 4 loss ppo:  -0.06012, loss val: 0.21763
[2022-12-07 06:47:17,131] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:47:17,333] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:47:17,333] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:47:24,193] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:47:31,427] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:47:38,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:47:45,860] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:47:52,735] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:47:59,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:48:06,030] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:48:12,535] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:48:19,454] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:48:25,985] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.33461823934538265
[2022-12-07 06:48:25,985] [INFO] [runner_train_mujoco] Average state value: 0.3933666784353554
[2022-12-07 06:48:25,986] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 06:48:26,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.16285
[2022-12-07 06:48:26,086] [INFO] [controller] EPOCH 2 loss ppo:  -0.04102, loss val: 0.14688
[2022-12-07 06:48:26,132] [INFO] [controller] EPOCH 3 loss ppo:  -0.05544, loss val: 0.13314
[2022-12-07 06:48:26,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.06374, loss val: 0.12246
[2022-12-07 06:48:26,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:48:26,381] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:48:26,381] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:48:33,417] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:48:40,208] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:48:46,985] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:48:53,547] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:49:00,670] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:49:07,644] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:49:14,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:49:21,613] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:49:28,210] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:49:35,054] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4999212220384132
[2022-12-07 06:49:35,054] [INFO] [runner_train_mujoco] Average state value: 0.5304668415418515
[2022-12-07 06:49:35,054] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 06:49:35,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.01228, loss val: 0.12024
[2022-12-07 06:49:35,236] [INFO] [controller] EPOCH 2 loss ppo:  -0.03729, loss val: 0.11377
[2022-12-07 06:49:35,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.05018, loss val: 0.10515
[2022-12-07 06:49:35,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.05699, loss val: 0.09779
[2022-12-07 06:49:35,362] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:49:35,560] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:49:35,561] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:49:42,202] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:49:50,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:49:57,286] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:50:04,118] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:50:10,923] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:50:17,564] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:50:24,080] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:50:31,267] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:50:38,168] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:50:44,804] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4178081613485121
[2022-12-07 06:50:44,804] [INFO] [runner_train_mujoco] Average state value: 0.6174575224034489
[2022-12-07 06:50:44,805] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 06:50:44,884] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.10185
[2022-12-07 06:50:44,936] [INFO] [controller] EPOCH 2 loss ppo:  -0.03533, loss val: 0.09499
[2022-12-07 06:50:44,991] [INFO] [controller] EPOCH 3 loss ppo:  -0.04581, loss val: 0.09009
[2022-12-07 06:50:45,041] [INFO] [controller] EPOCH 4 loss ppo:  -0.05442, loss val: 0.08512
[2022-12-07 06:50:45,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:50:45,244] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:50:45,244] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:50:51,983] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:50:58,923] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:51:05,800] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:51:12,816] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:51:19,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:51:26,031] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:51:32,943] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:51:39,741] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:51:46,302] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:51:53,569] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3605627429771155
[2022-12-07 06:51:53,570] [INFO] [runner_train_mujoco] Average state value: 0.6345592270319661
[2022-12-07 06:51:53,570] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 06:51:53,658] [INFO] [controller] EPOCH 1 loss ppo:  -0.01015, loss val: 0.07929
[2022-12-07 06:51:53,714] [INFO] [controller] EPOCH 2 loss ppo:  -0.03364, loss val: 0.07532
[2022-12-07 06:51:53,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.04415, loss val: 0.07063
[2022-12-07 06:51:53,834] [INFO] [controller] EPOCH 4 loss ppo:  -0.05233, loss val: 0.06721
[2022-12-07 06:51:53,845] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:51:54,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:51:54,051] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:52:01,819] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:52:09,366] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:52:16,531] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:52:23,730] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:52:31,001] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:52:37,715] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:52:44,245] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:52:51,310] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:52:57,700] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:53:04,910] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3042223262945019
[2022-12-07 06:53:04,910] [INFO] [runner_train_mujoco] Average state value: 0.6140313097362717
[2022-12-07 06:53:04,910] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 06:53:04,974] [INFO] [controller] EPOCH 1 loss ppo:  -0.00876, loss val: 0.06271
[2022-12-07 06:53:05,024] [INFO] [controller] EPOCH 2 loss ppo:  -0.03045, loss val: 0.06103
[2022-12-07 06:53:05,070] [INFO] [controller] EPOCH 3 loss ppo:  -0.04253, loss val: 0.05848
[2022-12-07 06:53:05,123] [INFO] [controller] EPOCH 4 loss ppo:  -0.05338, loss val: 0.05564
[2022-12-07 06:53:05,133] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:53:05,326] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:53:05,327] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:53:12,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:53:19,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:53:25,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:53:32,083] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:53:38,825] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:53:45,686] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:53:52,638] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:53:59,248] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:54:06,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:54:13,120] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3187822951825465
[2022-12-07 06:54:13,121] [INFO] [runner_train_mujoco] Average state value: 0.6257153863559166
[2022-12-07 06:54:13,121] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 06:54:13,193] [INFO] [controller] EPOCH 1 loss ppo:  -0.01019, loss val: 0.05844
[2022-12-07 06:54:13,248] [INFO] [controller] EPOCH 2 loss ppo:  -0.02965, loss val: 0.05955
[2022-12-07 06:54:13,309] [INFO] [controller] EPOCH 3 loss ppo:  -0.04213, loss val: 0.05155
[2022-12-07 06:54:13,379] [INFO] [controller] EPOCH 4 loss ppo:  -0.05318, loss val: 0.05241
[2022-12-07 06:54:13,390] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:54:13,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:54:13,583] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:54:20,112] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:54:26,664] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:54:33,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:54:39,845] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:54:46,359] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:54:53,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:55:00,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:55:07,338] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:55:13,965] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:55:20,639] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4422205258993689
[2022-12-07 06:55:20,639] [INFO] [runner_train_mujoco] Average state value: 0.5944135536029935
[2022-12-07 06:55:20,639] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 06:55:20,701] [INFO] [controller] EPOCH 1 loss ppo:  -0.00994, loss val: 0.05193
[2022-12-07 06:55:20,746] [INFO] [controller] EPOCH 2 loss ppo:  -0.03271, loss val: 0.05084
[2022-12-07 06:55:20,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.04327, loss val: 0.04929
[2022-12-07 06:55:20,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.05393, loss val: 0.05020
[2022-12-07 06:55:20,853] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:55:21,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:55:21,061] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:55:28,135] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:55:34,475] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:55:41,026] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:55:47,515] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:55:54,224] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:56:00,835] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:56:07,486] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:56:14,468] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:56:21,442] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:56:28,235] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4388459887888561
[2022-12-07 06:56:28,236] [INFO] [runner_train_mujoco] Average state value: 0.545964286784331
[2022-12-07 06:56:28,236] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 06:56:28,305] [INFO] [controller] EPOCH 1 loss ppo:  -0.01020, loss val: 0.05242
[2022-12-07 06:56:28,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.03425, loss val: 0.04919
[2022-12-07 06:56:28,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.04827, loss val: 0.04790
[2022-12-07 06:56:28,499] [INFO] [controller] EPOCH 4 loss ppo:  -0.05425, loss val: 0.04931
[2022-12-07 06:56:28,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:56:28,701] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:56:28,701] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:56:35,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:56:42,521] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:56:50,910] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:56:58,260] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:57:04,863] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:57:11,589] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:57:17,991] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:57:24,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:57:31,652] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:57:38,584] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4066375033012525
[2022-12-07 06:57:38,584] [INFO] [runner_train_mujoco] Average state value: 0.5525924051304658
[2022-12-07 06:57:38,584] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 06:57:38,645] [INFO] [controller] EPOCH 1 loss ppo:  -0.01037, loss val: 0.05096
[2022-12-07 06:57:38,697] [INFO] [controller] EPOCH 2 loss ppo:  -0.03329, loss val: 0.04920
[2022-12-07 06:57:38,755] [INFO] [controller] EPOCH 3 loss ppo:  -0.04488, loss val: 0.04919
[2022-12-07 06:57:38,817] [INFO] [controller] EPOCH 4 loss ppo:  -0.05319, loss val: 0.04614
[2022-12-07 06:57:38,827] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:57:39,020] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:57:39,020] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:57:45,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:57:52,522] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:57:58,732] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:58:05,281] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:58:11,660] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:58:18,601] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:58:25,635] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:58:32,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:58:38,887] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:58:45,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.35693142080110746
[2022-12-07 06:58:45,315] [INFO] [runner_train_mujoco] Average state value: 0.6168575161894162
[2022-12-07 06:58:45,315] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 06:58:45,369] [INFO] [controller] EPOCH 1 loss ppo:  -0.00917, loss val: 0.04376
[2022-12-07 06:58:45,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.03179, loss val: 0.04317
[2022-12-07 06:58:45,459] [INFO] [controller] EPOCH 3 loss ppo:  -0.04059, loss val: 0.04334
[2022-12-07 06:58:45,504] [INFO] [controller] EPOCH 4 loss ppo:  -0.04926, loss val: 0.04237
[2022-12-07 06:58:45,514] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:58:45,717] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:58:45,717] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:58:52,411] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 06:58:59,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 06:59:05,435] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 06:59:11,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 06:59:18,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 06:59:25,511] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 06:59:32,016] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 06:59:38,468] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 06:59:44,970] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 06:59:51,935] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3321954750591479
[2022-12-07 06:59:51,935] [INFO] [runner_train_mujoco] Average state value: 0.6301054836511611
[2022-12-07 06:59:51,935] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 06:59:52,022] [INFO] [controller] EPOCH 1 loss ppo:  -0.00867, loss val: 0.04393
[2022-12-07 06:59:52,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.02584, loss val: 0.04181
[2022-12-07 06:59:52,135] [INFO] [controller] EPOCH 3 loss ppo:  -0.03969, loss val: 0.03916
[2022-12-07 06:59:52,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.04959, loss val: 0.03760
[2022-12-07 06:59:52,226] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 06:59:52,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 06:59:52,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 06:59:59,093] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:00:05,894] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:00:12,267] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:00:19,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:00:25,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:00:31,996] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:00:38,739] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:00:44,965] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:00:51,821] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:00:58,565] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4256509402601686
[2022-12-07 07:00:58,565] [INFO] [runner_train_mujoco] Average state value: 0.5558134793142478
[2022-12-07 07:00:58,566] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 07:00:58,637] [INFO] [controller] EPOCH 1 loss ppo:  -0.01045, loss val: 0.03571
[2022-12-07 07:00:58,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.03111, loss val: 0.03651
[2022-12-07 07:00:58,758] [INFO] [controller] EPOCH 3 loss ppo:  -0.04090, loss val: 0.03659
[2022-12-07 07:00:58,818] [INFO] [controller] EPOCH 4 loss ppo:  -0.04759, loss val: 0.03610
[2022-12-07 07:00:58,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:00:59,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:00:59,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:01:05,820] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:01:12,316] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:01:19,081] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:01:25,863] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:01:31,931] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:01:38,891] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:01:45,465] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:01:51,829] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:01:58,698] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:02:05,261] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4386845099658044
[2022-12-07 07:02:05,261] [INFO] [runner_train_mujoco] Average state value: 0.5225697138309479
[2022-12-07 07:02:05,261] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 07:02:05,324] [INFO] [controller] EPOCH 1 loss ppo:  -0.01073, loss val: 0.03854
[2022-12-07 07:02:05,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.03119, loss val: 0.03798
[2022-12-07 07:02:05,418] [INFO] [controller] EPOCH 3 loss ppo:  -0.04531, loss val: 0.03530
[2022-12-07 07:02:05,466] [INFO] [controller] EPOCH 4 loss ppo:  -0.05459, loss val: 0.03755
[2022-12-07 07:02:05,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:02:05,664] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:02:05,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:02:12,037] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:02:18,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:02:24,990] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:02:31,972] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:02:38,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:02:45,358] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:02:52,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:02:58,697] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:03:05,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:03:12,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40807793389871555
[2022-12-07 07:03:12,105] [INFO] [runner_train_mujoco] Average state value: 0.5429574138919513
[2022-12-07 07:03:12,106] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 07:03:12,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01152, loss val: 0.03873
[2022-12-07 07:03:12,226] [INFO] [controller] EPOCH 2 loss ppo:  -0.03335, loss val: 0.03896
[2022-12-07 07:03:12,272] [INFO] [controller] EPOCH 3 loss ppo:  -0.04172, loss val: 0.03757
[2022-12-07 07:03:12,333] [INFO] [controller] EPOCH 4 loss ppo:  -0.05001, loss val: 0.03679
[2022-12-07 07:03:12,343] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:03:12,537] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:03:12,537] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:03:19,119] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:03:25,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:03:32,207] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:03:39,085] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:03:45,795] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:03:52,295] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:03:58,649] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:04:05,579] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:04:11,774] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:04:18,184] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5993318186990626
[2022-12-07 07:04:18,184] [INFO] [runner_train_mujoco] Average state value: 0.5070643930435181
[2022-12-07 07:04:18,185] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 07:04:18,238] [INFO] [controller] EPOCH 1 loss ppo:  -0.00956, loss val: 0.03686
[2022-12-07 07:04:18,286] [INFO] [controller] EPOCH 2 loss ppo:  -0.03119, loss val: 0.03598
[2022-12-07 07:04:18,345] [INFO] [controller] EPOCH 3 loss ppo:  -0.04457, loss val: 0.03569
[2022-12-07 07:04:18,398] [INFO] [controller] EPOCH 4 loss ppo:  -0.05283, loss val: 0.03753
[2022-12-07 07:04:18,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:04:18,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:04:18,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:04:25,759] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:04:32,596] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:04:39,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:04:45,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:04:51,889] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:04:58,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:05:04,562] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:05:10,612] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:05:17,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:05:24,047] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4926504457542036
[2022-12-07 07:05:24,047] [INFO] [runner_train_mujoco] Average state value: 0.5240530837575594
[2022-12-07 07:05:24,047] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 07:05:24,108] [INFO] [controller] EPOCH 1 loss ppo:  -0.00839, loss val: 0.04262
[2022-12-07 07:05:24,156] [INFO] [controller] EPOCH 2 loss ppo:  -0.02968, loss val: 0.04050
[2022-12-07 07:05:24,208] [INFO] [controller] EPOCH 3 loss ppo:  -0.04230, loss val: 0.03855
[2022-12-07 07:05:24,264] [INFO] [controller] EPOCH 4 loss ppo:  -0.05358, loss val: 0.03739
[2022-12-07 07:05:24,273] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:05:24,462] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:05:24,463] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:05:31,176] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:05:37,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:05:44,457] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:05:51,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:05:57,700] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:06:04,125] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:06:10,643] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:06:17,331] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:06:23,947] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:06:30,535] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4851319057451475
[2022-12-07 07:06:30,536] [INFO] [runner_train_mujoco] Average state value: 0.6010121308167775
[2022-12-07 07:06:30,536] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 07:06:30,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.00950, loss val: 0.04517
[2022-12-07 07:06:30,659] [INFO] [controller] EPOCH 2 loss ppo:  -0.02506, loss val: 0.04670
[2022-12-07 07:06:30,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.03584, loss val: 0.04565
[2022-12-07 07:06:30,784] [INFO] [controller] EPOCH 4 loss ppo:  -0.04481, loss val: 0.04329
[2022-12-07 07:06:30,794] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:06:30,993] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:06:30,993] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:06:37,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:06:44,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:06:51,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:06:57,654] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:07:04,746] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:07:12,285] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:07:19,473] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:07:26,789] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:07:33,568] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:07:40,623] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5201696200086257
[2022-12-07 07:07:40,624] [INFO] [runner_train_mujoco] Average state value: 0.6019298162062963
[2022-12-07 07:07:40,624] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 07:07:40,719] [INFO] [controller] EPOCH 1 loss ppo:  -0.00927, loss val: 0.04255
[2022-12-07 07:07:40,787] [INFO] [controller] EPOCH 2 loss ppo:  -0.03051, loss val: 0.03971
[2022-12-07 07:07:40,850] [INFO] [controller] EPOCH 3 loss ppo:  -0.04465, loss val: 0.03918
[2022-12-07 07:07:40,989] [INFO] [controller] EPOCH 4 loss ppo:  -0.05458, loss val: 0.03885
[2022-12-07 07:07:40,999] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:07:41,203] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:07:41,203] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:07:47,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:07:54,474] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:08:00,809] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:08:07,023] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:08:13,197] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:08:19,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:08:26,011] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:08:32,667] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:08:39,176] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:08:46,374] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6815872487669236
[2022-12-07 07:08:46,374] [INFO] [runner_train_mujoco] Average state value: 0.5471489377816517
[2022-12-07 07:08:46,374] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 07:08:46,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.00992, loss val: 0.03430
[2022-12-07 07:08:46,485] [INFO] [controller] EPOCH 2 loss ppo:  -0.02789, loss val: 0.03392
[2022-12-07 07:08:46,543] [INFO] [controller] EPOCH 3 loss ppo:  -0.03672, loss val: 0.03405
[2022-12-07 07:08:46,590] [INFO] [controller] EPOCH 4 loss ppo:  -0.04150, loss val: 0.03062
[2022-12-07 07:08:46,601] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:08:46,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:08:46,803] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:08:53,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:08:59,626] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:09:05,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:09:11,241] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:09:17,240] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:09:22,796] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:09:29,040] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:09:34,948] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:09:40,568] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:09:46,681] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8831698500012974
[2022-12-07 07:09:46,682] [INFO] [runner_train_mujoco] Average state value: 0.5793559900522232
[2022-12-07 07:09:46,682] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 07:09:46,731] [INFO] [controller] EPOCH 1 loss ppo:  -0.01133, loss val: 0.03409
[2022-12-07 07:09:46,772] [INFO] [controller] EPOCH 2 loss ppo:  -0.03333, loss val: 0.03514
[2022-12-07 07:09:46,814] [INFO] [controller] EPOCH 3 loss ppo:  -0.04537, loss val: 0.03465
[2022-12-07 07:09:46,858] [INFO] [controller] EPOCH 4 loss ppo:  -0.05447, loss val: 0.03507
[2022-12-07 07:09:46,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:09:47,047] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:09:47,047] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:09:52,898] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:09:58,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:10:04,682] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:10:10,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:10:16,840] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:10:22,493] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:10:28,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:10:34,652] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:10:40,203] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:10:46,314] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6556672593658854
[2022-12-07 07:10:46,315] [INFO] [runner_train_mujoco] Average state value: 0.6161629429658254
[2022-12-07 07:10:46,315] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 07:10:46,370] [INFO] [controller] EPOCH 1 loss ppo:  -0.01134, loss val: 0.04759
[2022-12-07 07:10:46,424] [INFO] [controller] EPOCH 2 loss ppo:  -0.02747, loss val: 0.04743
[2022-12-07 07:10:46,468] [INFO] [controller] EPOCH 3 loss ppo:  -0.03719, loss val: 0.04461
[2022-12-07 07:10:46,511] [INFO] [controller] EPOCH 4 loss ppo:  -0.04735, loss val: 0.04315
[2022-12-07 07:10:46,520] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:10:46,702] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:10:46,702] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:10:52,496] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:10:58,561] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:11:04,351] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:11:10,410] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:11:16,177] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:11:21,594] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:11:27,555] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:11:33,471] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:11:39,559] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:11:45,619] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8464320002782395
[2022-12-07 07:11:45,619] [INFO] [runner_train_mujoco] Average state value: 0.561944245437781
[2022-12-07 07:11:45,619] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 07:11:45,678] [INFO] [controller] EPOCH 1 loss ppo:  -0.01057, loss val: 0.03406
[2022-12-07 07:11:45,721] [INFO] [controller] EPOCH 2 loss ppo:  -0.02909, loss val: 0.03394
[2022-12-07 07:11:45,768] [INFO] [controller] EPOCH 3 loss ppo:  -0.04356, loss val: 0.03558
[2022-12-07 07:11:45,809] [INFO] [controller] EPOCH 4 loss ppo:  -0.05303, loss val: 0.03451
[2022-12-07 07:11:45,819] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:11:46,006] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:11:46,006] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:11:52,224] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:11:58,135] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:12:03,963] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:12:09,465] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:12:14,917] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:12:20,505] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:12:26,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:12:32,265] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:12:37,984] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:12:44,251] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9684283361882248
[2022-12-07 07:12:44,252] [INFO] [runner_train_mujoco] Average state value: 0.5283253070314726
[2022-12-07 07:12:44,252] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 07:12:44,316] [INFO] [controller] EPOCH 1 loss ppo:  -0.01104, loss val: 0.03987
[2022-12-07 07:12:44,377] [INFO] [controller] EPOCH 2 loss ppo:  -0.03059, loss val: 0.03964
[2022-12-07 07:12:44,437] [INFO] [controller] EPOCH 3 loss ppo:  -0.03953, loss val: 0.03923
[2022-12-07 07:12:44,484] [INFO] [controller] EPOCH 4 loss ppo:  -0.05282, loss val: 0.03941
[2022-12-07 07:12:44,494] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:12:44,684] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:12:44,685] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:12:50,616] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:12:56,817] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:13:02,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:13:08,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:13:13,966] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:13:19,786] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:13:25,744] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:13:31,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:13:37,604] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:13:43,248] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1505439744516242
[2022-12-07 07:13:43,248] [INFO] [runner_train_mujoco] Average state value: 0.5459090714057288
[2022-12-07 07:13:43,248] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 07:13:43,298] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.03518
[2022-12-07 07:13:43,344] [INFO] [controller] EPOCH 2 loss ppo:  -0.02694, loss val: 0.03477
[2022-12-07 07:13:43,392] [INFO] [controller] EPOCH 3 loss ppo:  -0.04126, loss val: 0.03356
[2022-12-07 07:13:43,454] [INFO] [controller] EPOCH 4 loss ppo:  -0.05130, loss val: 0.03281
[2022-12-07 07:13:43,465] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:13:43,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:13:43,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:13:49,445] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:13:55,347] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:14:01,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:14:07,023] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:14:12,861] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:14:18,533] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:14:24,170] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:14:30,372] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:14:36,319] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:14:41,867] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3883225615200927
[2022-12-07 07:14:41,867] [INFO] [runner_train_mujoco] Average state value: 0.5121662348707516
[2022-12-07 07:14:41,867] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 07:14:41,919] [INFO] [controller] EPOCH 1 loss ppo:  -0.01522, loss val: 0.03715
[2022-12-07 07:14:41,963] [INFO] [controller] EPOCH 2 loss ppo:  -0.03718, loss val: 0.03741
[2022-12-07 07:14:42,012] [INFO] [controller] EPOCH 3 loss ppo:  -0.05060, loss val: 0.03639
[2022-12-07 07:14:42,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.05894, loss val: 0.03764
[2022-12-07 07:14:42,064] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:14:42,241] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:14:42,242] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:14:48,174] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:14:53,965] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:15:00,031] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:15:05,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:15:11,179] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:15:17,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:15:23,022] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:15:28,656] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:15:34,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:15:40,804] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6809735717377943
[2022-12-07 07:15:40,804] [INFO] [runner_train_mujoco] Average state value: 0.4971581556797027
[2022-12-07 07:15:40,804] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 07:15:40,855] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04362
[2022-12-07 07:15:40,966] [INFO] [controller] EPOCH 2 loss ppo:  -0.03279, loss val: 0.04219
[2022-12-07 07:15:41,005] [INFO] [controller] EPOCH 3 loss ppo:  -0.04311, loss val: 0.04248
[2022-12-07 07:15:41,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.05356, loss val: 0.04109
[2022-12-07 07:15:41,059] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:15:41,243] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:15:41,244] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:15:47,376] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:15:53,418] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:15:59,205] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:16:04,719] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:16:10,467] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:16:16,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:16:22,571] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:16:27,977] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:16:33,919] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:16:39,569] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.854699863282582
[2022-12-07 07:16:39,569] [INFO] [runner_train_mujoco] Average state value: 0.5329095857143402
[2022-12-07 07:16:39,569] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 07:16:39,632] [INFO] [controller] EPOCH 1 loss ppo:  -0.01543, loss val: 0.04954
[2022-12-07 07:16:39,677] [INFO] [controller] EPOCH 2 loss ppo:  -0.02960, loss val: 0.04813
[2022-12-07 07:16:39,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.04157, loss val: 0.04985
[2022-12-07 07:16:39,777] [INFO] [controller] EPOCH 4 loss ppo:  -0.04928, loss val: 0.04465
[2022-12-07 07:16:39,787] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:16:39,995] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:16:39,995] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:16:45,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:16:51,575] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:16:57,450] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:17:03,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:17:09,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:17:14,799] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:17:20,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:17:26,043] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:17:31,766] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:17:37,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1613283022964502
[2022-12-07 07:17:37,196] [INFO] [runner_train_mujoco] Average state value: 0.5053965749939283
[2022-12-07 07:17:37,196] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 07:17:37,252] [INFO] [controller] EPOCH 1 loss ppo:  -0.01409, loss val: 0.04046
[2022-12-07 07:17:37,299] [INFO] [controller] EPOCH 2 loss ppo:  -0.03337, loss val: 0.03806
[2022-12-07 07:17:37,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.04553, loss val: 0.03804
[2022-12-07 07:17:37,387] [INFO] [controller] EPOCH 4 loss ppo:  -0.05584, loss val: 0.03825
[2022-12-07 07:17:37,396] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:17:37,576] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:17:37,576] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:17:43,266] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:17:48,999] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:17:55,035] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:18:01,516] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:18:07,768] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:18:13,337] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:18:19,423] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:18:25,444] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:18:31,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:18:36,972] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.461592589563014
[2022-12-07 07:18:36,972] [INFO] [runner_train_mujoco] Average state value: 0.4359083079298337
[2022-12-07 07:18:36,972] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 07:18:37,024] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.04540
[2022-12-07 07:18:37,076] [INFO] [controller] EPOCH 2 loss ppo:  -0.03606, loss val: 0.04611
[2022-12-07 07:18:37,124] [INFO] [controller] EPOCH 3 loss ppo:  -0.04840, loss val: 0.04826
[2022-12-07 07:18:37,170] [INFO] [controller] EPOCH 4 loss ppo:  -0.05497, loss val: 0.04659
[2022-12-07 07:18:37,180] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:18:37,378] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:18:37,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:18:42,940] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:18:48,884] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:18:54,450] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:19:00,076] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:19:05,361] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:19:10,952] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:19:16,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:19:22,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:19:27,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:19:33,641] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9362471362196345
[2022-12-07 07:19:33,641] [INFO] [runner_train_mujoco] Average state value: 0.44752196166912717
[2022-12-07 07:19:33,641] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 07:19:33,690] [INFO] [controller] EPOCH 1 loss ppo:  -0.01542, loss val: 0.04013
[2022-12-07 07:19:33,738] [INFO] [controller] EPOCH 2 loss ppo:  -0.03293, loss val: 0.04181
[2022-12-07 07:19:33,783] [INFO] [controller] EPOCH 3 loss ppo:  -0.04134, loss val: 0.04261
[2022-12-07 07:19:33,823] [INFO] [controller] EPOCH 4 loss ppo:  -0.05590, loss val: 0.04054
[2022-12-07 07:19:33,833] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:19:34,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:19:34,013] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:19:39,616] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:19:45,482] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:19:51,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:19:57,493] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:20:03,135] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:20:08,833] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:20:14,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:20:20,262] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:20:25,866] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:20:31,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1579894689151486
[2022-12-07 07:20:31,548] [INFO] [runner_train_mujoco] Average state value: 0.4579317111770312
[2022-12-07 07:20:31,548] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 07:20:31,602] [INFO] [controller] EPOCH 1 loss ppo:  -0.01505, loss val: 0.03938
[2022-12-07 07:20:31,644] [INFO] [controller] EPOCH 2 loss ppo:  -0.02970, loss val: 0.04008
[2022-12-07 07:20:31,689] [INFO] [controller] EPOCH 3 loss ppo:  -0.04327, loss val: 0.03897
[2022-12-07 07:20:31,731] [INFO] [controller] EPOCH 4 loss ppo:  -0.05304, loss val: 0.03849
[2022-12-07 07:20:31,741] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:20:31,926] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:20:31,927] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:20:37,807] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:20:43,523] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:20:49,563] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:20:55,209] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:21:00,730] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:21:06,626] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:21:12,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:21:18,192] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:21:24,321] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:21:30,269] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.55045628619592
[2022-12-07 07:21:30,270] [INFO] [runner_train_mujoco] Average state value: 0.4767802375952403
[2022-12-07 07:21:30,270] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 07:21:30,324] [INFO] [controller] EPOCH 1 loss ppo:  -0.01559, loss val: 0.04365
[2022-12-07 07:21:30,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.03064, loss val: 0.04402
[2022-12-07 07:21:30,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.04075, loss val: 0.04433
[2022-12-07 07:21:30,458] [INFO] [controller] EPOCH 4 loss ppo:  -0.05284, loss val: 0.04369
[2022-12-07 07:21:30,468] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:21:30,665] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:21:30,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:21:36,601] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:21:42,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:21:47,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:21:53,647] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:21:59,517] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:22:05,174] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:22:10,890] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:22:16,715] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:22:22,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:22:28,251] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5771120406113495
[2022-12-07 07:22:28,252] [INFO] [runner_train_mujoco] Average state value: 0.46908083258072536
[2022-12-07 07:22:28,252] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 07:22:28,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.01292, loss val: 0.04477
[2022-12-07 07:22:28,361] [INFO] [controller] EPOCH 2 loss ppo:  -0.02715, loss val: 0.04345
[2022-12-07 07:22:28,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.03703, loss val: 0.04404
[2022-12-07 07:22:28,448] [INFO] [controller] EPOCH 4 loss ppo:  -0.04799, loss val: 0.04288
[2022-12-07 07:22:28,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:22:28,634] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:22:28,634] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:22:34,397] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:22:40,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:22:45,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:22:50,875] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:22:56,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:23:02,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:23:07,648] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:23:13,137] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:23:18,566] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:23:23,799] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7375687616153273
[2022-12-07 07:23:23,799] [INFO] [runner_train_mujoco] Average state value: 0.4526577538053195
[2022-12-07 07:23:23,799] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 07:23:23,855] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04670
[2022-12-07 07:23:23,902] [INFO] [controller] EPOCH 2 loss ppo:  -0.02835, loss val: 0.04640
[2022-12-07 07:23:23,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.04216, loss val: 0.04627
[2022-12-07 07:23:23,995] [INFO] [controller] EPOCH 4 loss ppo:  -0.05223, loss val: 0.04583
[2022-12-07 07:23:24,006] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:23:24,210] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:23:24,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:23:29,543] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:23:35,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:23:41,097] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:23:46,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:23:53,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:23:58,537] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:04,112] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:24:09,802] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:24:15,121] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:24:20,688] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8990607969187194
[2022-12-07 07:24:20,688] [INFO] [runner_train_mujoco] Average state value: 0.45337127394477533
[2022-12-07 07:24:20,688] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 07:24:20,741] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03868
[2022-12-07 07:24:20,784] [INFO] [controller] EPOCH 2 loss ppo:  -0.02948, loss val: 0.03689
[2022-12-07 07:24:20,824] [INFO] [controller] EPOCH 3 loss ppo:  -0.03987, loss val: 0.03802
[2022-12-07 07:24:20,867] [INFO] [controller] EPOCH 4 loss ppo:  -0.05078, loss val: 0.04069
[2022-12-07 07:24:20,876] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:24:21,059] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:24:21,059] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:24:26,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:24:32,002] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:24:37,408] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:24:42,498] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:24:48,138] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:24:53,558] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:24:59,011] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:25:05,128] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:25:10,829] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:25:16,634] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.1260493504513045
[2022-12-07 07:25:16,634] [INFO] [runner_train_mujoco] Average state value: 0.45228812411427494
[2022-12-07 07:25:16,634] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 07:25:16,699] [INFO] [controller] EPOCH 1 loss ppo:  -0.01505, loss val: 0.03620
[2022-12-07 07:25:16,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.03004, loss val: 0.03516
[2022-12-07 07:25:16,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.03341, loss val: 0.03690
[2022-12-07 07:25:16,841] [INFO] [controller] EPOCH 4 loss ppo:  -0.04405, loss val: 0.03531
[2022-12-07 07:25:16,851] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:25:17,047] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:25:17,047] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:25:22,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:25:28,365] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:25:33,533] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:25:39,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:25:44,685] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:25:50,071] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:25:56,270] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:26:01,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:26:07,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:26:12,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.301195335006359
[2022-12-07 07:26:12,549] [INFO] [runner_train_mujoco] Average state value: 0.4406919665137927
[2022-12-07 07:26:12,549] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 07:26:12,601] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.04757
[2022-12-07 07:26:12,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.02302, loss val: 0.04943
[2022-12-07 07:26:12,689] [INFO] [controller] EPOCH 3 loss ppo:  -0.03338, loss val: 0.04778
[2022-12-07 07:26:12,731] [INFO] [controller] EPOCH 4 loss ppo:  -0.04403, loss val: 0.04836
[2022-12-07 07:26:12,737] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:26:12,921] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:26:12,922] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:26:18,354] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:26:23,602] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:26:29,203] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:26:34,907] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:26:40,868] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:26:46,326] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:26:52,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:26:57,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:27:02,848] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:27:07,959] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.208518231879883
[2022-12-07 07:27:07,959] [INFO] [runner_train_mujoco] Average state value: 0.43965325436989466
[2022-12-07 07:27:07,959] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 07:27:08,011] [INFO] [controller] EPOCH 1 loss ppo:  -0.01554, loss val: 0.04654
[2022-12-07 07:27:08,058] [INFO] [controller] EPOCH 2 loss ppo:  -0.02533, loss val: 0.04644
[2022-12-07 07:27:08,099] [INFO] [controller] EPOCH 3 loss ppo:  -0.03060, loss val: 0.04608
[2022-12-07 07:27:08,141] [INFO] [controller] EPOCH 4 loss ppo:  -0.04404, loss val: 0.04514
[2022-12-07 07:27:08,150] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:27:08,342] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:27:08,342] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:27:13,770] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:27:19,343] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:27:25,019] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:27:30,126] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:27:35,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:27:40,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:27:46,122] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:27:51,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:27:57,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:28:03,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.638530545878151
[2022-12-07 07:28:03,126] [INFO] [runner_train_mujoco] Average state value: 0.42008917837341625
[2022-12-07 07:28:03,126] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 07:28:03,179] [INFO] [controller] EPOCH 1 loss ppo:  -0.01451, loss val: 0.04494
[2022-12-07 07:28:03,228] [INFO] [controller] EPOCH 2 loss ppo:  -0.02177, loss val: 0.04581
[2022-12-07 07:28:03,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.02780, loss val: 0.04559
[2022-12-07 07:28:03,333] [INFO] [controller] EPOCH 4 loss ppo:  -0.04439, loss val: 0.04589
[2022-12-07 07:28:03,343] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:28:03,538] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:28:03,538] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:28:09,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:28:14,493] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:28:20,136] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:28:25,365] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:28:30,425] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:28:35,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:28:41,322] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:28:46,544] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:28:51,962] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:28:57,705] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.301389767779555
[2022-12-07 07:28:57,705] [INFO] [runner_train_mujoco] Average state value: 0.4011634102761746
[2022-12-07 07:28:57,705] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 07:28:57,765] [INFO] [controller] EPOCH 1 loss ppo:  -0.01589, loss val: 0.04536
[2022-12-07 07:28:57,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.02134, loss val: 0.04529
[2022-12-07 07:28:57,852] [INFO] [controller] EPOCH 3 loss ppo:  -0.02712, loss val: 0.04595
[2022-12-07 07:28:57,895] [INFO] [controller] EPOCH 4 loss ppo:  -0.03811, loss val: 0.04466
[2022-12-07 07:28:57,905] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:28:58,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:28:58,099] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:29:03,978] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:29:09,800] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:29:15,401] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:29:20,995] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:29:26,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:29:31,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:29:37,027] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:29:42,493] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:29:47,993] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:29:53,426] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.652453224023313
[2022-12-07 07:29:53,427] [INFO] [runner_train_mujoco] Average state value: 0.40948341256380083
[2022-12-07 07:29:53,427] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 07:29:53,485] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.05209
[2022-12-07 07:29:53,537] [INFO] [controller] EPOCH 2 loss ppo:  -0.02460, loss val: 0.05379
[2022-12-07 07:29:53,597] [INFO] [controller] EPOCH 3 loss ppo:  -0.03218, loss val: 0.05221
[2022-12-07 07:29:53,648] [INFO] [controller] EPOCH 4 loss ppo:  -0.04110, loss val: 0.05220
[2022-12-07 07:29:53,657] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:29:53,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:29:53,839] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:29:58,894] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:30:04,424] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:30:09,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:30:14,912] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:30:20,439] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:30:25,906] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:30:31,364] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:30:37,076] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:30:42,756] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:30:48,182] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.803143083952781
[2022-12-07 07:30:48,182] [INFO] [runner_train_mujoco] Average state value: 0.4246333974003792
[2022-12-07 07:30:48,182] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 07:30:48,237] [INFO] [controller] EPOCH 1 loss ppo:  -0.01436, loss val: 0.05116
[2022-12-07 07:30:48,281] [INFO] [controller] EPOCH 2 loss ppo:  -0.02125, loss val: 0.04997
[2022-12-07 07:30:48,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.02939, loss val: 0.04944
[2022-12-07 07:30:48,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.03751, loss val: 0.05041
[2022-12-07 07:30:48,378] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:30:48,564] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:30:48,567] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:30:54,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:30:59,484] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:31:05,238] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:31:10,764] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:31:15,937] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:31:21,154] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:31:26,871] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:31:31,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:31:38,799] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:31:44,849] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.702236882544187
[2022-12-07 07:31:44,850] [INFO] [runner_train_mujoco] Average state value: 0.44087504621346796
[2022-12-07 07:31:44,850] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 07:31:44,918] [INFO] [controller] EPOCH 1 loss ppo:  -0.01541, loss val: 0.04895
[2022-12-07 07:31:44,970] [INFO] [controller] EPOCH 2 loss ppo:  -0.02134, loss val: 0.04733
[2022-12-07 07:31:45,014] [INFO] [controller] EPOCH 3 loss ppo:  -0.02574, loss val: 0.04732
[2022-12-07 07:31:45,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.03671, loss val: 0.04721
[2022-12-07 07:31:45,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:31:45,254] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:31:45,254] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:31:50,835] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:31:56,043] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:32:01,938] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:32:07,616] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:32:12,796] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:32:17,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:32:23,172] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:32:28,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:32:33,575] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:32:38,668] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.889271617494851
[2022-12-07 07:32:38,668] [INFO] [runner_train_mujoco] Average state value: 0.4573772888978323
[2022-12-07 07:32:38,668] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 07:32:38,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.01224, loss val: 0.05147
[2022-12-07 07:32:38,761] [INFO] [controller] EPOCH 2 loss ppo:  -0.01930, loss val: 0.04994
[2022-12-07 07:32:38,799] [INFO] [controller] EPOCH 3 loss ppo:  -0.02722, loss val: 0.04983
[2022-12-07 07:32:38,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.03699, loss val: 0.04890
[2022-12-07 07:32:38,845] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:32:39,011] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:32:39,012] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:32:44,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:32:49,815] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:32:55,419] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:33:01,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:33:07,904] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:33:13,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:33:18,766] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:33:24,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:33:29,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:33:34,992] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.727093794222432
[2022-12-07 07:33:34,993] [INFO] [runner_train_mujoco] Average state value: 0.46256829498211544
[2022-12-07 07:33:34,993] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 07:33:35,046] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.05239
[2022-12-07 07:33:35,092] [INFO] [controller] EPOCH 2 loss ppo:  -0.02056, loss val: 0.05181
[2022-12-07 07:33:35,133] [INFO] [controller] EPOCH 3 loss ppo:  -0.02265, loss val: 0.05140
[2022-12-07 07:33:35,172] [INFO] [controller] EPOCH 4 loss ppo:  -0.03023, loss val: 0.04988
[2022-12-07 07:33:35,182] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:33:35,352] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:33:35,352] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:33:40,763] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:33:45,747] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:33:51,101] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:33:56,417] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:34:01,472] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:34:06,821] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:34:11,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:34:17,352] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:34:23,249] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:34:28,866] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.900014286327161
[2022-12-07 07:34:28,866] [INFO] [runner_train_mujoco] Average state value: 0.438049430201451
[2022-12-07 07:34:28,867] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 07:34:28,918] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04758
[2022-12-07 07:34:28,962] [INFO] [controller] EPOCH 2 loss ppo:  -0.01868, loss val: 0.04592
[2022-12-07 07:34:29,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.02505, loss val: 0.04399
[2022-12-07 07:34:29,050] [INFO] [controller] EPOCH 4 loss ppo:  -0.03167, loss val: 0.04449
[2022-12-07 07:34:29,057] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:34:29,223] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:34:29,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:34:34,666] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:34:40,296] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:34:45,536] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:34:50,896] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:34:55,950] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:35:01,368] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:35:06,585] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:35:11,908] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:35:17,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:35:22,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.825270542994438
[2022-12-07 07:35:22,535] [INFO] [runner_train_mujoco] Average state value: 0.4015708699027697
[2022-12-07 07:35:22,535] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 07:35:22,591] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.05446
[2022-12-07 07:35:22,630] [INFO] [controller] EPOCH 2 loss ppo:  -0.01910, loss val: 0.05447
[2022-12-07 07:35:22,678] [INFO] [controller] EPOCH 3 loss ppo:  -0.02362, loss val: 0.05562
[2022-12-07 07:35:22,715] [INFO] [controller] EPOCH 4 loss ppo:  -0.03338, loss val: 0.05492
[2022-12-07 07:35:22,722] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:35:22,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:35:22,911] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:35:28,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:35:33,293] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:35:38,411] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:35:44,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:35:49,405] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:35:54,578] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:36:00,272] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:36:05,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:36:11,298] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:36:16,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.959407491074661
[2022-12-07 07:36:16,328] [INFO] [runner_train_mujoco] Average state value: 0.38094965428113936
[2022-12-07 07:36:16,328] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 07:36:16,380] [INFO] [controller] EPOCH 1 loss ppo:  -0.01388, loss val: 0.04511
[2022-12-07 07:36:16,428] [INFO] [controller] EPOCH 2 loss ppo:  -0.02008, loss val: 0.04501
[2022-12-07 07:36:16,471] [INFO] [controller] EPOCH 3 loss ppo:  -0.02241, loss val: 0.04322
[2022-12-07 07:36:16,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.03083, loss val: 0.04485
[2022-12-07 07:36:16,524] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:36:16,710] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:36:16,710] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:36:22,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:36:27,538] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:36:32,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:36:37,956] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:36:43,035] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:36:48,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:36:53,114] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:36:58,584] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:37:04,177] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:37:09,593] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.017921612134257
[2022-12-07 07:37:09,593] [INFO] [runner_train_mujoco] Average state value: 0.3730251455108325
[2022-12-07 07:37:09,593] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 07:37:09,643] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.05032
[2022-12-07 07:37:09,686] [INFO] [controller] EPOCH 2 loss ppo:  -0.01836, loss val: 0.05354
[2022-12-07 07:37:09,728] [INFO] [controller] EPOCH 3 loss ppo:  -0.02128, loss val: 0.05122
[2022-12-07 07:37:09,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.02618, loss val: 0.05321
[2022-12-07 07:37:09,780] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:37:09,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:37:09,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:37:17,058] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:37:23,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:37:28,255] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:37:33,519] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:37:38,596] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:37:43,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:37:48,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:37:53,515] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:37:58,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:38:03,887] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.076003051137205
[2022-12-07 07:38:03,888] [INFO] [runner_train_mujoco] Average state value: 0.3775734182198842
[2022-12-07 07:38:03,888] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 07:38:03,940] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.05106
[2022-12-07 07:38:03,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.01704, loss val: 0.05297
[2022-12-07 07:38:04,027] [INFO] [controller] EPOCH 3 loss ppo:  -0.02644, loss val: 0.05036
[2022-12-07 07:38:04,065] [INFO] [controller] EPOCH 4 loss ppo:  -0.03503, loss val: 0.05012
[2022-12-07 07:38:04,074] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:38:04,254] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:38:04,254] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:38:09,253] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:38:14,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:38:19,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:38:25,252] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:38:30,122] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:38:35,491] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:38:40,803] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:38:46,280] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:38:51,845] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:38:57,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.088487868715513
[2022-12-07 07:38:57,427] [INFO] [runner_train_mujoco] Average state value: 0.3933642429014047
[2022-12-07 07:38:57,427] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 07:38:57,482] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.05213
[2022-12-07 07:38:57,529] [INFO] [controller] EPOCH 2 loss ppo:  -0.02093, loss val: 0.05346
[2022-12-07 07:38:57,578] [INFO] [controller] EPOCH 3 loss ppo:  -0.02589, loss val: 0.05214
[2022-12-07 07:38:57,624] [INFO] [controller] EPOCH 4 loss ppo:  -0.02908, loss val: 0.05361
[2022-12-07 07:38:57,635] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:38:57,830] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:38:57,830] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:39:03,102] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:39:08,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:39:13,596] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:39:18,535] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:39:23,469] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:39:28,796] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:39:33,834] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:39:39,435] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:39:44,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:39:50,763] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.80915958241955
[2022-12-07 07:39:50,763] [INFO] [runner_train_mujoco] Average state value: 0.40440482103824615
[2022-12-07 07:39:50,764] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 07:39:50,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01371, loss val: 0.05208
[2022-12-07 07:39:50,857] [INFO] [controller] EPOCH 2 loss ppo:  -0.01727, loss val: 0.04953
[2022-12-07 07:39:50,899] [INFO] [controller] EPOCH 3 loss ppo:  -0.02384, loss val: 0.04954
[2022-12-07 07:39:50,940] [INFO] [controller] EPOCH 4 loss ppo:  -0.02823, loss val: 0.05081
[2022-12-07 07:39:50,949] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:39:51,135] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:39:51,135] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:39:56,669] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:40:02,247] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:40:07,395] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:40:12,608] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:40:17,589] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:40:23,003] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:40:27,996] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:40:33,168] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:40:38,129] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:40:43,540] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.15450713586028
[2022-12-07 07:40:43,540] [INFO] [runner_train_mujoco] Average state value: 0.40354962949951484
[2022-12-07 07:40:43,540] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 07:40:43,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04900
[2022-12-07 07:40:43,638] [INFO] [controller] EPOCH 2 loss ppo:  -0.01713, loss val: 0.05050
[2022-12-07 07:40:43,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.02197, loss val: 0.05112
[2022-12-07 07:40:43,723] [INFO] [controller] EPOCH 4 loss ppo:  -0.02543, loss val: 0.04981
[2022-12-07 07:40:43,732] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:40:43,916] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:40:43,917] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:40:48,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:40:54,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:40:59,407] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:41:05,039] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:41:10,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:41:15,691] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:41:20,732] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:41:25,928] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:41:31,164] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:41:36,727] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.416198166852747
[2022-12-07 07:41:36,728] [INFO] [runner_train_mujoco] Average state value: 0.4030564900736014
[2022-12-07 07:41:36,728] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 07:41:36,791] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.05392
[2022-12-07 07:41:36,840] [INFO] [controller] EPOCH 2 loss ppo:  -0.01632, loss val: 0.05326
[2022-12-07 07:41:36,882] [INFO] [controller] EPOCH 3 loss ppo:  -0.02059, loss val: 0.05428
[2022-12-07 07:41:36,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.02417, loss val: 0.05380
[2022-12-07 07:41:36,937] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:41:37,132] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:41:37,137] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:41:42,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:41:47,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:41:53,014] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:41:58,105] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:42:03,159] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:42:08,112] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:42:12,972] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:42:17,975] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:42:23,723] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:42:29,303] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.472792956665238
[2022-12-07 07:42:29,303] [INFO] [runner_train_mujoco] Average state value: 0.40164331831534705
[2022-12-07 07:42:29,303] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 07:42:29,371] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.04186
[2022-12-07 07:42:29,417] [INFO] [controller] EPOCH 2 loss ppo:  -0.01616, loss val: 0.04175
[2022-12-07 07:42:29,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.02005, loss val: 0.04184
[2022-12-07 07:42:29,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.02354, loss val: 0.04162
[2022-12-07 07:42:29,586] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:42:29,757] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:42:29,757] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:42:35,457] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:42:40,679] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:42:46,192] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:42:51,228] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:42:56,626] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:43:01,753] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:43:06,958] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:43:11,995] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:43:17,347] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:43:23,553] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.51774495196035
[2022-12-07 07:43:23,553] [INFO] [runner_train_mujoco] Average state value: 0.40054612114032107
[2022-12-07 07:43:23,553] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 07:43:23,627] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.04425
[2022-12-07 07:43:23,672] [INFO] [controller] EPOCH 2 loss ppo:  -0.01431, loss val: 0.04389
[2022-12-07 07:43:23,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.01588, loss val: 0.04257
[2022-12-07 07:43:23,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.01764, loss val: 0.04263
[2022-12-07 07:43:23,778] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:43:23,900] [INFO] [optimize] Finished learning.
