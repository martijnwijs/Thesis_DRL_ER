[2022-12-07 08:47:41,093] [INFO] [optimize] Starting learning
[2022-12-07 08:47:41,104] [INFO] [optimize] Starting learning process..
[2022-12-07 08:47:41,209] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:47:41,214] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:47:49,062] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:47:55,938] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:48:02,235] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:48:08,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:48:14,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:48:20,468] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:48:26,565] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:48:33,006] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:48:38,900] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:48:44,910] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.36880677847626875
[2022-12-07 08:48:44,910] [INFO] [runner_train_mujoco] Average state value: -0.15920044148465
[2022-12-07 08:48:44,910] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 08:48:44,962] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.49994
[2022-12-07 08:48:45,005] [INFO] [controller] EPOCH 2 loss ppo:  -0.04239, loss val: 0.43129
[2022-12-07 08:48:45,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.05631, loss val: 0.38427
[2022-12-07 08:48:45,099] [INFO] [controller] EPOCH 4 loss ppo:  -0.06248, loss val: 0.33453
[2022-12-07 08:48:45,110] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:48:45,316] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:48:45,317] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:48:51,277] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:48:57,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:49:02,882] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:49:08,348] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:49:14,372] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:49:20,490] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:49:26,602] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:49:32,954] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:49:40,899] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:49:47,719] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4590680824310051
[2022-12-07 08:49:47,719] [INFO] [runner_train_mujoco] Average state value: -0.010051591821635763
[2022-12-07 08:49:47,720] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 08:49:47,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.37360
[2022-12-07 08:49:47,826] [INFO] [controller] EPOCH 2 loss ppo:  -0.04110, loss val: 0.32970
[2022-12-07 08:49:47,876] [INFO] [controller] EPOCH 3 loss ppo:  -0.05456, loss val: 0.29838
[2022-12-07 08:49:47,923] [INFO] [controller] EPOCH 4 loss ppo:  -0.06478, loss val: 0.26006
[2022-12-07 08:49:47,934] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:49:48,124] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:49:48,125] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:49:55,166] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:50:02,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:50:09,252] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:50:15,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:50:22,737] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:50:29,316] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:50:36,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:50:42,881] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:50:49,788] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:50:56,331] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3571188939859578
[2022-12-07 08:50:56,331] [INFO] [runner_train_mujoco] Average state value: 0.14645548365327218
[2022-12-07 08:50:56,331] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 08:50:56,393] [INFO] [controller] EPOCH 1 loss ppo:  -0.01278, loss val: 0.23678
[2022-12-07 08:50:56,441] [INFO] [controller] EPOCH 2 loss ppo:  -0.03222, loss val: 0.20799
[2022-12-07 08:50:56,491] [INFO] [controller] EPOCH 3 loss ppo:  -0.04562, loss val: 0.18279
[2022-12-07 08:50:56,539] [INFO] [controller] EPOCH 4 loss ppo:  -0.05447, loss val: 0.16356
[2022-12-07 08:50:56,549] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:50:56,750] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:50:56,750] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:51:03,477] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:51:10,394] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:51:17,299] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:51:24,001] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:51:31,146] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:51:37,733] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:51:44,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:51:51,393] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:51:58,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:52:05,088] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3404856575327433
[2022-12-07 08:52:05,089] [INFO] [runner_train_mujoco] Average state value: 0.2958442867627988
[2022-12-07 08:52:05,089] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 08:52:05,147] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.13082
[2022-12-07 08:52:05,194] [INFO] [controller] EPOCH 2 loss ppo:  -0.04035, loss val: 0.12470
[2022-12-07 08:52:05,255] [INFO] [controller] EPOCH 3 loss ppo:  -0.04999, loss val: 0.10671
[2022-12-07 08:52:05,304] [INFO] [controller] EPOCH 4 loss ppo:  -0.05829, loss val: 0.09753
[2022-12-07 08:52:05,315] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:52:05,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:52:05,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:52:12,716] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:52:19,537] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:52:26,569] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:52:32,904] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:52:39,657] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:52:46,569] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:52:53,230] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:53:00,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:53:06,860] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:53:13,327] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46023931714584243
[2022-12-07 08:53:13,327] [INFO] [runner_train_mujoco] Average state value: 0.43354895613466693
[2022-12-07 08:53:13,327] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 08:53:13,384] [INFO] [controller] EPOCH 1 loss ppo:  -0.01116, loss val: 0.10024
[2022-12-07 08:53:13,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.03238, loss val: 0.09055
[2022-12-07 08:53:13,481] [INFO] [controller] EPOCH 3 loss ppo:  -0.04610, loss val: 0.08297
[2022-12-07 08:53:13,531] [INFO] [controller] EPOCH 4 loss ppo:  -0.05486, loss val: 0.07885
[2022-12-07 08:53:13,542] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:53:13,761] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:53:13,761] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:53:20,939] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:53:27,290] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:53:34,224] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:53:40,729] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:53:47,168] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:53:53,758] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:54:00,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:54:06,496] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:54:13,335] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:54:20,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42378492543164326
[2022-12-07 08:54:20,389] [INFO] [runner_train_mujoco] Average state value: 0.5533515571529667
[2022-12-07 08:54:20,389] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 08:54:20,472] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.06451
[2022-12-07 08:54:20,530] [INFO] [controller] EPOCH 2 loss ppo:  -0.03775, loss val: 0.06134
[2022-12-07 08:54:20,574] [INFO] [controller] EPOCH 3 loss ppo:  -0.05102, loss val: 0.05767
[2022-12-07 08:54:20,623] [INFO] [controller] EPOCH 4 loss ppo:  -0.05743, loss val: 0.05585
[2022-12-07 08:54:20,632] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:54:20,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:54:20,823] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:54:27,402] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:54:34,621] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:54:41,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:54:48,310] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:54:54,854] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:55:01,264] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:55:07,427] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:55:14,061] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:55:20,938] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:55:28,114] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4868781974491034
[2022-12-07 08:55:28,114] [INFO] [runner_train_mujoco] Average state value: 0.6249810306827227
[2022-12-07 08:55:28,114] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 08:55:28,180] [INFO] [controller] EPOCH 1 loss ppo:  -0.01041, loss val: 0.05744
[2022-12-07 08:55:28,230] [INFO] [controller] EPOCH 2 loss ppo:  -0.03469, loss val: 0.05509
[2022-12-07 08:55:28,282] [INFO] [controller] EPOCH 3 loss ppo:  -0.04318, loss val: 0.05310
[2022-12-07 08:55:28,350] [INFO] [controller] EPOCH 4 loss ppo:  -0.05096, loss val: 0.05292
[2022-12-07 08:55:28,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:55:28,557] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:55:28,558] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:55:35,274] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:55:41,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:55:48,628] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:55:54,848] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:56:01,236] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:56:07,841] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:56:14,510] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:56:21,646] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:56:28,752] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:56:35,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6750724944330172
[2022-12-07 08:56:35,515] [INFO] [runner_train_mujoco] Average state value: 0.6384641410807769
[2022-12-07 08:56:35,515] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 08:56:35,573] [INFO] [controller] EPOCH 1 loss ppo:  -0.00990, loss val: 0.05285
[2022-12-07 08:56:35,635] [INFO] [controller] EPOCH 2 loss ppo:  -0.03112, loss val: 0.05143
[2022-12-07 08:56:35,705] [INFO] [controller] EPOCH 3 loss ppo:  -0.04655, loss val: 0.04998
[2022-12-07 08:56:35,778] [INFO] [controller] EPOCH 4 loss ppo:  -0.05523, loss val: 0.04968
[2022-12-07 08:56:35,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:56:35,989] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:56:35,989] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:56:42,650] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:56:49,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:56:55,729] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:57:02,420] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:57:09,031] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:57:15,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:57:22,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:57:29,272] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:57:35,879] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:57:42,734] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6212071714651106
[2022-12-07 08:57:42,734] [INFO] [runner_train_mujoco] Average state value: 0.6324497219721475
[2022-12-07 08:57:42,734] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 08:57:42,809] [INFO] [controller] EPOCH 1 loss ppo:  -0.01049, loss val: 0.05150
[2022-12-07 08:57:42,873] [INFO] [controller] EPOCH 2 loss ppo:  -0.03098, loss val: 0.04870
[2022-12-07 08:57:42,917] [INFO] [controller] EPOCH 3 loss ppo:  -0.04345, loss val: 0.04655
[2022-12-07 08:57:42,962] [INFO] [controller] EPOCH 4 loss ppo:  -0.05259, loss val: 0.04442
[2022-12-07 08:57:42,972] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:57:43,174] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:57:43,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:57:49,770] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:57:56,571] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:58:02,996] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:58:09,512] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:58:16,066] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:58:22,376] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:58:29,422] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:58:36,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:58:42,972] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:58:49,614] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7028389064632876
[2022-12-07 08:58:49,614] [INFO] [runner_train_mujoco] Average state value: 0.567636732717355
[2022-12-07 08:58:49,614] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 08:58:49,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.00927, loss val: 0.04903
[2022-12-07 08:58:49,711] [INFO] [controller] EPOCH 2 loss ppo:  -0.03086, loss val: 0.04917
[2022-12-07 08:58:49,754] [INFO] [controller] EPOCH 3 loss ppo:  -0.04148, loss val: 0.04810
[2022-12-07 08:58:49,806] [INFO] [controller] EPOCH 4 loss ppo:  -0.04863, loss val: 0.04730
[2022-12-07 08:58:49,816] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:58:50,018] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:58:50,019] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:58:56,939] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:59:03,650] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:59:10,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:59:17,171] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:59:23,894] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:59:30,470] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:59:37,139] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:59:44,151] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:59:50,460] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:59:57,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6636032913290492
[2022-12-07 08:59:57,272] [INFO] [runner_train_mujoco] Average state value: 0.5371076984306178
[2022-12-07 08:59:57,272] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 08:59:57,331] [INFO] [controller] EPOCH 1 loss ppo:  -0.00955, loss val: 0.04162
[2022-12-07 08:59:57,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.03319, loss val: 0.04088
[2022-12-07 08:59:57,436] [INFO] [controller] EPOCH 3 loss ppo:  -0.04472, loss val: 0.04027
[2022-12-07 08:59:57,499] [INFO] [controller] EPOCH 4 loss ppo:  -0.05334, loss val: 0.04039
[2022-12-07 08:59:57,508] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:59:57,709] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:59:57,709] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:00:04,434] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:00:11,202] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:00:17,931] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:00:24,683] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:00:31,290] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:00:38,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:00:44,600] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:00:51,578] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:00:58,297] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:01:05,314] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6890224471851212
[2022-12-07 09:01:05,314] [INFO] [runner_train_mujoco] Average state value: 0.5596575641036033
[2022-12-07 09:01:05,314] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 09:01:05,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01243, loss val: 0.04203
[2022-12-07 09:01:05,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.03573, loss val: 0.04171
[2022-12-07 09:01:05,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.04239
[2022-12-07 09:01:05,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.05077, loss val: 0.04090
[2022-12-07 09:01:05,525] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:01:05,729] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:01:05,730] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:01:11,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:01:18,539] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:01:25,215] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:01:31,582] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:01:38,321] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:01:44,981] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:01:51,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:01:58,363] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:02:04,912] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:02:11,671] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.092784944222598
[2022-12-07 09:02:11,672] [INFO] [runner_train_mujoco] Average state value: 0.5892180097897848
[2022-12-07 09:02:11,672] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 09:02:11,728] [INFO] [controller] EPOCH 1 loss ppo:  -0.01069, loss val: 0.03747
[2022-12-07 09:02:11,775] [INFO] [controller] EPOCH 2 loss ppo:  -0.03661, loss val: 0.03763
[2022-12-07 09:02:11,826] [INFO] [controller] EPOCH 3 loss ppo:  -0.05121, loss val: 0.03541
[2022-12-07 09:02:11,873] [INFO] [controller] EPOCH 4 loss ppo:  -0.05922, loss val: 0.03630
[2022-12-07 09:02:11,883] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:02:12,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:02:12,074] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:02:18,876] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:02:25,871] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:02:32,317] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:02:39,285] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:02:45,541] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:02:52,444] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:02:58,983] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:03:05,768] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:03:12,572] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:03:19,532] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2915565092644257
[2022-12-07 09:03:19,532] [INFO] [runner_train_mujoco] Average state value: 0.5854358331461748
[2022-12-07 09:03:19,532] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 09:03:19,616] [INFO] [controller] EPOCH 1 loss ppo:  -0.01247, loss val: 0.03571
[2022-12-07 09:03:19,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.03368, loss val: 0.03545
[2022-12-07 09:03:19,746] [INFO] [controller] EPOCH 3 loss ppo:  -0.04828, loss val: 0.03448
[2022-12-07 09:03:19,796] [INFO] [controller] EPOCH 4 loss ppo:  -0.05954, loss val: 0.03421
[2022-12-07 09:03:19,806] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:03:20,006] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:03:20,006] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:03:26,489] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:03:32,867] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:03:39,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:03:46,630] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:03:53,019] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:03:59,321] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:04:06,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:04:13,098] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:04:19,459] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:04:26,535] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4474169839863813
[2022-12-07 09:04:26,535] [INFO] [runner_train_mujoco] Average state value: 0.571851651608944
[2022-12-07 09:04:26,535] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 09:04:26,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04086
[2022-12-07 09:04:26,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.03725, loss val: 0.04048
[2022-12-07 09:04:26,692] [INFO] [controller] EPOCH 3 loss ppo:  -0.04915, loss val: 0.04009
[2022-12-07 09:04:26,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.05692, loss val: 0.03986
[2022-12-07 09:04:26,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:04:26,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:04:26,957] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:04:33,150] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:04:39,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:04:45,548] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:04:51,789] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:04:57,833] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:05:03,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:05:09,807] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:05:15,877] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:05:21,951] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:05:27,457] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4899224552636863
[2022-12-07 09:05:27,458] [INFO] [runner_train_mujoco] Average state value: 0.5718066231012344
[2022-12-07 09:05:27,458] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 09:05:27,507] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04018
[2022-12-07 09:05:27,550] [INFO] [controller] EPOCH 2 loss ppo:  -0.03436, loss val: 0.03881
[2022-12-07 09:05:27,604] [INFO] [controller] EPOCH 3 loss ppo:  -0.04655, loss val: 0.03939
[2022-12-07 09:05:27,659] [INFO] [controller] EPOCH 4 loss ppo:  -0.05575, loss val: 0.03829
[2022-12-07 09:05:27,669] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:05:27,856] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:05:27,856] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:05:34,007] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:05:40,273] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:05:46,347] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:05:52,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:05:58,498] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:06:04,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:06:10,045] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:06:15,762] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:06:22,000] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:06:28,220] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5587464256393293
[2022-12-07 09:06:28,221] [INFO] [runner_train_mujoco] Average state value: 0.5646564775705337
[2022-12-07 09:06:28,221] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 09:06:28,275] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04199
[2022-12-07 09:06:28,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.03580, loss val: 0.04325
[2022-12-07 09:06:28,355] [INFO] [controller] EPOCH 3 loss ppo:  -0.04364, loss val: 0.04228
[2022-12-07 09:06:28,395] [INFO] [controller] EPOCH 4 loss ppo:  -0.05519, loss val: 0.04198
[2022-12-07 09:06:28,404] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:06:28,588] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:06:28,589] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:06:34,521] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:06:40,279] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:06:46,218] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:06:52,158] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:06:57,456] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:07:03,593] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:07:10,387] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:07:17,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:07:23,938] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:07:29,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7386825710639768
[2022-12-07 09:07:29,719] [INFO] [runner_train_mujoco] Average state value: 0.5617064747810364
[2022-12-07 09:07:29,719] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 09:07:29,776] [INFO] [controller] EPOCH 1 loss ppo:  -0.01203, loss val: 0.04507
[2022-12-07 09:07:29,828] [INFO] [controller] EPOCH 2 loss ppo:  -0.03510, loss val: 0.04329
[2022-12-07 09:07:29,876] [INFO] [controller] EPOCH 3 loss ppo:  -0.04984, loss val: 0.04048
[2022-12-07 09:07:29,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.05979, loss val: 0.04161
[2022-12-07 09:07:29,928] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:07:30,111] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:07:30,111] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:07:36,022] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:07:42,379] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:07:48,187] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:07:54,032] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:07:59,806] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:08:05,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:08:11,688] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:08:17,422] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:08:23,511] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:08:29,487] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9590614380361433
[2022-12-07 09:08:29,487] [INFO] [runner_train_mujoco] Average state value: 0.5880518631140391
[2022-12-07 09:08:29,487] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 09:08:29,537] [INFO] [controller] EPOCH 1 loss ppo:  -0.01206, loss val: 0.03966
[2022-12-07 09:08:29,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.02979, loss val: 0.03879
[2022-12-07 09:08:29,614] [INFO] [controller] EPOCH 3 loss ppo:  -0.04548, loss val: 0.03923
[2022-12-07 09:08:29,655] [INFO] [controller] EPOCH 4 loss ppo:  -0.05307, loss val: 0.03818
[2022-12-07 09:08:29,664] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:08:29,849] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:08:29,850] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:08:35,506] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:08:41,415] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:08:47,081] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:08:53,127] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:08:58,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:09:05,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:09:10,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:09:16,584] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:09:22,135] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:09:28,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.390196999339574
[2022-12-07 09:09:28,111] [INFO] [runner_train_mujoco] Average state value: 0.5770320275028545
[2022-12-07 09:09:28,111] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 09:09:28,212] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.04558
[2022-12-07 09:09:28,265] [INFO] [controller] EPOCH 2 loss ppo:  -0.03214, loss val: 0.04396
[2022-12-07 09:09:28,332] [INFO] [controller] EPOCH 3 loss ppo:  -0.04754, loss val: 0.04173
[2022-12-07 09:09:28,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.05510, loss val: 0.04017
[2022-12-07 09:09:28,479] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:09:28,665] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:09:28,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:09:34,644] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:09:40,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:09:45,883] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:09:51,965] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:09:58,309] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:10:03,967] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:10:09,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:10:15,719] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:10:21,613] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:10:28,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.726770941757981
[2022-12-07 09:10:28,033] [INFO] [runner_train_mujoco] Average state value: 0.5122253278493881
[2022-12-07 09:10:28,033] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 09:10:28,082] [INFO] [controller] EPOCH 1 loss ppo:  -0.01558, loss val: 0.04848
[2022-12-07 09:10:28,125] [INFO] [controller] EPOCH 2 loss ppo:  -0.03545, loss val: 0.04998
[2022-12-07 09:10:28,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.04900, loss val: 0.05042
[2022-12-07 09:10:28,215] [INFO] [controller] EPOCH 4 loss ppo:  -0.05635, loss val: 0.04848
[2022-12-07 09:10:28,224] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:10:28,405] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:10:28,405] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:10:34,583] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:10:40,496] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:10:46,097] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:10:51,939] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:10:57,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:11:03,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:11:09,561] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:11:15,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:11:20,852] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:11:26,397] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9720062856278844
[2022-12-07 09:11:26,397] [INFO] [runner_train_mujoco] Average state value: 0.5167756818532944
[2022-12-07 09:11:26,397] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 09:11:26,454] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04246
[2022-12-07 09:11:26,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.03340, loss val: 0.04164
[2022-12-07 09:11:26,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.04836, loss val: 0.04139
[2022-12-07 09:11:26,616] [INFO] [controller] EPOCH 4 loss ppo:  -0.05813, loss val: 0.04099
[2022-12-07 09:11:26,626] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:11:26,835] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:11:26,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:11:32,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:11:38,715] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:11:44,796] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:11:50,769] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:11:56,488] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:12:02,276] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:12:07,950] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:12:13,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:12:19,956] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:12:26,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3981300476060277
[2022-12-07 09:12:26,005] [INFO] [runner_train_mujoco] Average state value: 0.5636072444121043
[2022-12-07 09:12:26,006] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 09:12:26,057] [INFO] [controller] EPOCH 1 loss ppo:  -0.01588, loss val: 0.04081
[2022-12-07 09:12:26,096] [INFO] [controller] EPOCH 2 loss ppo:  -0.03557, loss val: 0.04281
[2022-12-07 09:12:26,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.04671, loss val: 0.04106
[2022-12-07 09:12:26,179] [INFO] [controller] EPOCH 4 loss ppo:  -0.05971, loss val: 0.04114
[2022-12-07 09:12:26,186] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:12:26,358] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:12:26,359] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:12:32,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:12:37,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:12:43,716] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:12:48,971] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:12:54,786] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:13:00,523] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:13:06,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:13:12,626] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:13:18,521] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:13:24,963] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.182435316162949
[2022-12-07 09:13:24,963] [INFO] [runner_train_mujoco] Average state value: 0.5624743626515071
[2022-12-07 09:13:24,963] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 09:13:25,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04892
[2022-12-07 09:13:25,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.03569, loss val: 0.04750
[2022-12-07 09:13:25,158] [INFO] [controller] EPOCH 3 loss ppo:  -0.04555, loss val: 0.04594
[2022-12-07 09:13:25,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.05701, loss val: 0.04985
[2022-12-07 09:13:25,209] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:13:25,388] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:13:25,389] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:13:30,963] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:13:36,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:13:42,656] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:13:48,600] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:13:54,227] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:13:59,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:14:05,690] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:14:11,816] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:14:17,571] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:14:23,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.412114503045049
[2022-12-07 09:14:23,404] [INFO] [runner_train_mujoco] Average state value: 0.5576674685974916
[2022-12-07 09:14:23,404] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 09:14:23,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01621, loss val: 0.04428
[2022-12-07 09:14:23,495] [INFO] [controller] EPOCH 2 loss ppo:  -0.03658, loss val: 0.04416
[2022-12-07 09:14:23,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.04383, loss val: 0.04417
[2022-12-07 09:14:23,583] [INFO] [controller] EPOCH 4 loss ppo:  -0.05650, loss val: 0.04409
[2022-12-07 09:14:23,593] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:14:23,771] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:14:23,771] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:14:29,374] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:14:35,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:14:41,631] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:14:47,646] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:14:53,766] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:14:59,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:15:05,654] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:15:11,785] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:15:17,377] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:15:23,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.586232751882489
[2022-12-07 09:15:23,005] [INFO] [runner_train_mujoco] Average state value: 0.5273809519559145
[2022-12-07 09:15:23,005] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 09:15:23,136] [INFO] [controller] EPOCH 1 loss ppo:  -0.01645, loss val: 0.07108
[2022-12-07 09:15:23,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.03016, loss val: 0.07300
[2022-12-07 09:15:23,229] [INFO] [controller] EPOCH 3 loss ppo:  -0.03997, loss val: 0.07064
[2022-12-07 09:15:23,274] [INFO] [controller] EPOCH 4 loss ppo:  -0.05454, loss val: 0.06917
[2022-12-07 09:15:23,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:15:23,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:15:23,521] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:15:29,106] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:15:34,738] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:15:40,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:15:46,207] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:15:52,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:15:58,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:16:03,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:16:09,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:16:15,473] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:16:21,162] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.616271027660269
[2022-12-07 09:16:21,162] [INFO] [runner_train_mujoco] Average state value: 0.5862882646322249
[2022-12-07 09:16:21,162] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 09:16:21,221] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04953
[2022-12-07 09:16:21,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.02693, loss val: 0.04945
[2022-12-07 09:16:21,316] [INFO] [controller] EPOCH 3 loss ppo:  -0.03879, loss val: 0.04765
[2022-12-07 09:16:21,362] [INFO] [controller] EPOCH 4 loss ppo:  -0.04696, loss val: 0.04529
[2022-12-07 09:16:21,374] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:16:21,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:16:21,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:16:27,762] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:16:33,552] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:16:39,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:16:45,253] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:16:50,545] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:16:56,122] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:17:01,874] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:17:07,589] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:17:13,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:17:19,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8008200367152414
[2022-12-07 09:17:19,542] [INFO] [runner_train_mujoco] Average state value: 0.5458696548442046
[2022-12-07 09:17:19,543] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 09:17:19,596] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.04776
[2022-12-07 09:17:19,770] [INFO] [controller] EPOCH 2 loss ppo:  -0.03183, loss val: 0.04995
[2022-12-07 09:17:19,825] [INFO] [controller] EPOCH 3 loss ppo:  -0.04089, loss val: 0.05465
[2022-12-07 09:17:19,870] [INFO] [controller] EPOCH 4 loss ppo:  -0.05199, loss val: 0.04975
[2022-12-07 09:17:19,881] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:17:20,069] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:17:20,070] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:17:26,140] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:17:31,851] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:17:37,626] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:17:42,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:17:48,846] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:17:54,478] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:00,217] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:18:06,271] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:18:11,868] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:18:17,309] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.853280867563221
[2022-12-07 09:18:17,309] [INFO] [runner_train_mujoco] Average state value: 0.5404737559954326
[2022-12-07 09:18:17,309] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 09:18:17,365] [INFO] [controller] EPOCH 1 loss ppo:  -0.01582, loss val: 0.04291
[2022-12-07 09:18:17,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.03332, loss val: 0.04315
[2022-12-07 09:18:17,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.03918, loss val: 0.04365
[2022-12-07 09:18:17,517] [INFO] [controller] EPOCH 4 loss ppo:  -0.05140, loss val: 0.04307
[2022-12-07 09:18:17,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:18:17,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:18:17,712] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:18:23,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:18:28,862] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:18:35,063] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:18:40,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:18:46,220] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:18:51,325] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:18:57,030] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:19:02,819] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:19:08,851] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:19:15,201] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.089911083743072
[2022-12-07 09:19:15,201] [INFO] [runner_train_mujoco] Average state value: 0.5478900516033173
[2022-12-07 09:19:15,201] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 09:19:15,285] [INFO] [controller] EPOCH 1 loss ppo:  -0.01283, loss val: 0.03931
[2022-12-07 09:19:15,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.02819, loss val: 0.03953
[2022-12-07 09:19:15,374] [INFO] [controller] EPOCH 3 loss ppo:  -0.04026, loss val: 0.03870
[2022-12-07 09:19:15,434] [INFO] [controller] EPOCH 4 loss ppo:  -0.05403, loss val: 0.03942
[2022-12-07 09:19:15,444] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:19:15,655] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:19:15,664] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:19:21,472] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:19:27,570] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:19:33,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:19:38,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:19:44,630] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:19:50,477] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:19:56,389] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:20:02,607] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:20:08,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:20:14,262] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.293983581139213
[2022-12-07 09:20:14,262] [INFO] [runner_train_mujoco] Average state value: 0.5441994755268097
[2022-12-07 09:20:14,263] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 09:20:14,318] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.03862
[2022-12-07 09:20:14,363] [INFO] [controller] EPOCH 2 loss ppo:  -0.02626, loss val: 0.03817
[2022-12-07 09:20:14,407] [INFO] [controller] EPOCH 3 loss ppo:  -0.03497, loss val: 0.03698
[2022-12-07 09:20:14,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.04739, loss val: 0.03724
[2022-12-07 09:20:14,462] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:20:14,659] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:20:14,660] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:20:20,407] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:20:26,021] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:20:31,587] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:20:37,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:20:43,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:20:49,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:20:54,892] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:21:00,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:21:06,314] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:21:11,761] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0055333933651625
[2022-12-07 09:21:11,761] [INFO] [runner_train_mujoco] Average state value: 0.48311301520218447
[2022-12-07 09:21:11,761] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 09:21:11,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.07611
[2022-12-07 09:21:11,857] [INFO] [controller] EPOCH 2 loss ppo:  -0.02453, loss val: 0.07555
[2022-12-07 09:21:11,901] [INFO] [controller] EPOCH 3 loss ppo:  -0.03641, loss val: 0.07553
[2022-12-07 09:21:11,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.05236, loss val: 0.07480
[2022-12-07 09:21:11,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:21:12,138] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:21:12,139] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:21:17,897] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:21:23,634] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:21:29,248] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:21:34,971] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:21:40,826] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:21:46,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:21:52,028] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:21:58,034] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:22:03,791] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:22:09,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.369939676621703
[2022-12-07 09:22:09,564] [INFO] [runner_train_mujoco] Average state value: 0.5073930472334226
[2022-12-07 09:22:09,564] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 09:22:09,612] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04446
[2022-12-07 09:22:09,653] [INFO] [controller] EPOCH 2 loss ppo:  -0.02564, loss val: 0.04265
[2022-12-07 09:22:09,694] [INFO] [controller] EPOCH 3 loss ppo:  -0.03650, loss val: 0.04144
[2022-12-07 09:22:09,734] [INFO] [controller] EPOCH 4 loss ppo:  -0.05195, loss val: 0.04244
[2022-12-07 09:22:09,741] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:22:09,909] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:22:09,910] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:22:15,737] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:22:21,075] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:22:26,957] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:22:32,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:22:38,717] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:22:44,527] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:22:50,383] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:22:56,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:23:02,401] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:23:07,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.135137998330647
[2022-12-07 09:23:07,836] [INFO] [runner_train_mujoco] Average state value: 0.5113230641682942
[2022-12-07 09:23:07,836] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 09:23:07,886] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.04666
[2022-12-07 09:23:07,926] [INFO] [controller] EPOCH 2 loss ppo:  -0.02844, loss val: 0.04586
[2022-12-07 09:23:07,972] [INFO] [controller] EPOCH 3 loss ppo:  -0.03580, loss val: 0.04517
[2022-12-07 09:23:08,016] [INFO] [controller] EPOCH 4 loss ppo:  -0.04473, loss val: 0.04552
[2022-12-07 09:23:08,026] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:23:08,194] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:23:08,195] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:23:14,027] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:23:20,138] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:23:25,757] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:23:31,529] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:23:36,893] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:23:42,614] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:23:48,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:23:54,404] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:24:00,178] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:24:06,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.223585093454668
[2022-12-07 09:24:06,077] [INFO] [runner_train_mujoco] Average state value: 0.5025856358905634
[2022-12-07 09:24:06,077] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 09:24:06,133] [INFO] [controller] EPOCH 1 loss ppo:  -0.01593, loss val: 0.03739
[2022-12-07 09:24:06,173] [INFO] [controller] EPOCH 2 loss ppo:  -0.02774, loss val: 0.03931
[2022-12-07 09:24:06,217] [INFO] [controller] EPOCH 3 loss ppo:  -0.03551, loss val: 0.03926
[2022-12-07 09:24:06,261] [INFO] [controller] EPOCH 4 loss ppo:  -0.04817, loss val: 0.03695
[2022-12-07 09:24:06,270] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:24:06,446] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:24:06,446] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:24:12,208] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:24:17,855] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:24:23,687] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:24:29,104] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:24:34,680] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:24:40,609] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:24:46,259] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:24:52,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:24:57,340] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:25:03,079] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.254046928281318
[2022-12-07 09:25:03,080] [INFO] [runner_train_mujoco] Average state value: 0.5025875085194905
[2022-12-07 09:25:03,080] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 09:25:03,128] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.04390
[2022-12-07 09:25:03,174] [INFO] [controller] EPOCH 2 loss ppo:  -0.02284, loss val: 0.04217
[2022-12-07 09:25:03,218] [INFO] [controller] EPOCH 3 loss ppo:  -0.03192, loss val: 0.04098
[2022-12-07 09:25:03,261] [INFO] [controller] EPOCH 4 loss ppo:  -0.04504, loss val: 0.03953
[2022-12-07 09:25:03,270] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:25:03,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:25:03,455] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:25:09,177] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:25:14,952] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:25:21,013] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:25:26,972] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:25:32,341] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:25:38,010] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:25:43,516] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:25:49,159] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:25:54,793] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:00,628] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.347543469503766
[2022-12-07 09:26:00,628] [INFO] [runner_train_mujoco] Average state value: 0.5260391457825898
[2022-12-07 09:26:00,628] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 09:26:00,692] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.03875
[2022-12-07 09:26:00,734] [INFO] [controller] EPOCH 2 loss ppo:  -0.02248, loss val: 0.03901
[2022-12-07 09:26:00,781] [INFO] [controller] EPOCH 3 loss ppo:  -0.03600, loss val: 0.04076
[2022-12-07 09:26:00,827] [INFO] [controller] EPOCH 4 loss ppo:  -0.05046, loss val: 0.03901
[2022-12-07 09:26:00,837] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:01,007] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:01,007] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:26:06,947] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:26:12,903] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:26:18,474] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:26:24,289] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:26:29,637] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:26:34,960] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:26:40,893] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:26:47,232] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:26:53,249] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:26:58,834] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.489974203938621
[2022-12-07 09:26:58,835] [INFO] [runner_train_mujoco] Average state value: 0.5587177251043418
[2022-12-07 09:26:58,835] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 09:26:58,894] [INFO] [controller] EPOCH 1 loss ppo:  -0.01446, loss val: 0.05569
[2022-12-07 09:26:58,942] [INFO] [controller] EPOCH 2 loss ppo:  -0.02508, loss val: 0.05540
[2022-12-07 09:26:59,005] [INFO] [controller] EPOCH 3 loss ppo:  -0.03678, loss val: 0.05730
[2022-12-07 09:26:59,060] [INFO] [controller] EPOCH 4 loss ppo:  -0.04934, loss val: 0.05497
[2022-12-07 09:26:59,071] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:26:59,257] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:26:59,257] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:27:05,100] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:27:11,145] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:27:16,684] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:27:22,731] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:27:28,294] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:27:34,279] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:27:39,475] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:27:45,223] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:27:50,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:27:56,699] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.458634534865854
[2022-12-07 09:27:56,699] [INFO] [runner_train_mujoco] Average state value: 0.5921699030598004
[2022-12-07 09:27:56,699] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 09:27:56,752] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.03667
[2022-12-07 09:27:56,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.02322, loss val: 0.03762
[2022-12-07 09:27:56,831] [INFO] [controller] EPOCH 3 loss ppo:  -0.03349, loss val: 0.03649
[2022-12-07 09:27:56,872] [INFO] [controller] EPOCH 4 loss ppo:  -0.04822, loss val: 0.03673
[2022-12-07 09:27:56,881] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:27:57,055] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:27:57,055] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:28:03,040] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:28:08,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:28:14,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:28:19,792] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:28:25,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:28:30,502] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:28:36,237] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:28:41,985] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:28:48,068] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:28:54,280] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.640280255432251
[2022-12-07 09:28:54,281] [INFO] [runner_train_mujoco] Average state value: 0.5595461873114108
[2022-12-07 09:28:54,281] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 09:28:54,336] [INFO] [controller] EPOCH 1 loss ppo:  -0.01301, loss val: 0.04197
[2022-12-07 09:28:54,380] [INFO] [controller] EPOCH 2 loss ppo:  -0.02304, loss val: 0.04171
[2022-12-07 09:28:54,427] [INFO] [controller] EPOCH 3 loss ppo:  -0.03219, loss val: 0.04227
[2022-12-07 09:28:54,473] [INFO] [controller] EPOCH 4 loss ppo:  -0.04012, loss val: 0.04197
[2022-12-07 09:28:54,483] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:28:54,666] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:28:54,667] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:29:00,658] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:29:06,461] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:29:12,047] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:29:17,564] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:29:23,397] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:29:29,403] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:29:35,237] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:29:40,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:29:46,782] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:29:52,418] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.416152488651918
[2022-12-07 09:29:52,418] [INFO] [runner_train_mujoco] Average state value: 0.5254207592358191
[2022-12-07 09:29:52,419] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 09:29:52,484] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.05425
[2022-12-07 09:29:52,537] [INFO] [controller] EPOCH 2 loss ppo:  -0.02492, loss val: 0.05562
[2022-12-07 09:29:52,597] [INFO] [controller] EPOCH 3 loss ppo:  -0.03573, loss val: 0.05318
[2022-12-07 09:29:52,642] [INFO] [controller] EPOCH 4 loss ppo:  -0.04421, loss val: 0.05340
[2022-12-07 09:29:52,652] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:29:52,857] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:29:52,858] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:29:58,664] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:30:04,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:30:10,208] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:30:16,226] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:30:22,039] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:30:27,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:30:32,968] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:30:38,697] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:30:44,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:30:50,011] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.639392699256255
[2022-12-07 09:30:50,011] [INFO] [runner_train_mujoco] Average state value: 0.5442048115730286
[2022-12-07 09:30:50,011] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 09:30:50,058] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04228
[2022-12-07 09:30:50,097] [INFO] [controller] EPOCH 2 loss ppo:  -0.02720, loss val: 0.04284
[2022-12-07 09:30:50,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.03743, loss val: 0.04134
[2022-12-07 09:30:50,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.04589, loss val: 0.04275
[2022-12-07 09:30:50,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:30:50,377] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:30:50,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:30:56,327] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:31:02,299] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:31:07,981] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:31:13,651] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:31:19,417] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:31:25,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:31:31,106] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:31:37,518] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:31:43,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:31:49,263] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.47647199947197
[2022-12-07 09:31:49,263] [INFO] [runner_train_mujoco] Average state value: 0.4475734934968253
[2022-12-07 09:31:49,263] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 09:31:49,313] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.08870
[2022-12-07 09:31:49,362] [INFO] [controller] EPOCH 2 loss ppo:  -0.02806, loss val: 0.08786
[2022-12-07 09:31:49,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.03687, loss val: 0.08637
[2022-12-07 09:31:49,450] [INFO] [controller] EPOCH 4 loss ppo:  -0.04243, loss val: 0.08514
[2022-12-07 09:31:49,459] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:31:49,665] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:31:49,665] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:31:55,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:32:01,307] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:32:07,071] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:32:12,461] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:32:18,517] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:32:23,879] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:32:29,518] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:32:35,523] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:32:41,389] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:32:46,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.474095979260596
[2022-12-07 09:32:46,837] [INFO] [runner_train_mujoco] Average state value: 0.49054798470065003
[2022-12-07 09:32:46,837] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 09:32:46,895] [INFO] [controller] EPOCH 1 loss ppo:  -0.01399, loss val: 0.05207
[2022-12-07 09:32:46,938] [INFO] [controller] EPOCH 2 loss ppo:  -0.02448, loss val: 0.05278
[2022-12-07 09:32:46,982] [INFO] [controller] EPOCH 3 loss ppo:  -0.03336, loss val: 0.05122
[2022-12-07 09:32:47,024] [INFO] [controller] EPOCH 4 loss ppo:  -0.03925, loss val: 0.05448
[2022-12-07 09:32:47,032] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:32:47,211] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:32:47,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:32:52,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:32:58,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:33:06,445] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:33:12,406] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:33:18,011] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:33:23,345] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:33:29,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:33:34,793] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:33:40,771] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:33:47,673] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.5128179567539215
[2022-12-07 09:33:47,673] [INFO] [runner_train_mujoco] Average state value: 0.4789093417028586
[2022-12-07 09:33:47,674] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 09:33:47,723] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04849
[2022-12-07 09:33:47,764] [INFO] [controller] EPOCH 2 loss ppo:  -0.02542, loss val: 0.04937
[2022-12-07 09:33:47,804] [INFO] [controller] EPOCH 3 loss ppo:  -0.03602, loss val: 0.04805
[2022-12-07 09:33:47,843] [INFO] [controller] EPOCH 4 loss ppo:  -0.04549, loss val: 0.04837
[2022-12-07 09:33:47,851] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:33:48,027] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:33:48,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:33:53,668] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:33:58,948] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:34:04,567] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:34:09,996] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:34:15,436] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:34:20,820] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:34:27,301] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:34:32,916] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:34:38,322] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:34:43,406] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.745484169471912
[2022-12-07 09:34:43,406] [INFO] [runner_train_mujoco] Average state value: 0.5367874509990216
[2022-12-07 09:34:43,406] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 09:34:43,456] [INFO] [controller] EPOCH 1 loss ppo:  -0.01479, loss val: 0.05141
[2022-12-07 09:34:43,498] [INFO] [controller] EPOCH 2 loss ppo:  -0.02409, loss val: 0.05110
[2022-12-07 09:34:43,542] [INFO] [controller] EPOCH 3 loss ppo:  -0.03172, loss val: 0.05018
[2022-12-07 09:34:43,586] [INFO] [controller] EPOCH 4 loss ppo:  -0.04037, loss val: 0.05123
[2022-12-07 09:34:43,596] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:34:43,782] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:34:43,782] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:34:49,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:34:55,665] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:35:01,438] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:35:06,920] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:35:12,141] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:35:17,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:35:22,943] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:35:28,229] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:35:33,551] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:35:39,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.662173252098479
[2022-12-07 09:35:39,014] [INFO] [runner_train_mujoco] Average state value: 0.5344223058323065
[2022-12-07 09:35:39,014] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 09:35:39,063] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.05204
[2022-12-07 09:35:39,100] [INFO] [controller] EPOCH 2 loss ppo:  -0.02387, loss val: 0.05142
[2022-12-07 09:35:39,139] [INFO] [controller] EPOCH 3 loss ppo:  -0.03337, loss val: 0.05168
[2022-12-07 09:35:39,178] [INFO] [controller] EPOCH 4 loss ppo:  -0.04513, loss val: 0.05150
[2022-12-07 09:35:39,188] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:35:39,374] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:35:39,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:35:45,327] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:35:50,948] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:35:56,762] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:36:02,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:36:07,584] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:36:13,215] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:36:19,034] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:36:24,836] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:36:30,020] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:36:35,332] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.761205279958125
[2022-12-07 09:36:35,333] [INFO] [runner_train_mujoco] Average state value: 0.5210883652145665
[2022-12-07 09:36:35,333] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 09:36:35,385] [INFO] [controller] EPOCH 1 loss ppo:  -0.01413, loss val: 0.06117
[2022-12-07 09:36:35,428] [INFO] [controller] EPOCH 2 loss ppo:  -0.02339, loss val: 0.06580
[2022-12-07 09:36:35,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.02834, loss val: 0.06363
[2022-12-07 09:36:35,514] [INFO] [controller] EPOCH 4 loss ppo:  -0.03651, loss val: 0.06142
[2022-12-07 09:36:35,524] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:36:35,705] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:36:35,706] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:36:41,373] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:36:46,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:36:51,868] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:36:56,959] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:37:02,743] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:37:08,498] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:37:14,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:37:20,448] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:37:25,815] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:37:31,482] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.18696916226723
[2022-12-07 09:37:31,483] [INFO] [runner_train_mujoco] Average state value: 0.5606930832515161
[2022-12-07 09:37:31,483] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 09:37:31,532] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.03892
[2022-12-07 09:37:31,568] [INFO] [controller] EPOCH 2 loss ppo:  -0.02173, loss val: 0.03946
[2022-12-07 09:37:31,611] [INFO] [controller] EPOCH 3 loss ppo:  -0.03392, loss val: 0.03901
[2022-12-07 09:37:31,657] [INFO] [controller] EPOCH 4 loss ppo:  -0.03963, loss val: 0.03871
[2022-12-07 09:37:31,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:37:31,889] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:37:31,890] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:37:37,647] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:37:43,182] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:37:48,327] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:37:53,757] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:37:58,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:38:04,553] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:38:11,126] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:38:16,732] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:38:21,891] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:38:27,618] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.941352145618444
[2022-12-07 09:38:27,619] [INFO] [runner_train_mujoco] Average state value: 0.5663615296458204
[2022-12-07 09:38:27,619] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 09:38:27,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01503, loss val: 0.05473
[2022-12-07 09:38:27,715] [INFO] [controller] EPOCH 2 loss ppo:  -0.02403, loss val: 0.05538
[2022-12-07 09:38:27,783] [INFO] [controller] EPOCH 3 loss ppo:  -0.03435, loss val: 0.05649
[2022-12-07 09:38:27,835] [INFO] [controller] EPOCH 4 loss ppo:  -0.04005, loss val: 0.05546
[2022-12-07 09:38:27,844] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:38:28,017] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:38:28,017] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:38:33,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:38:39,990] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:38:46,491] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:38:52,569] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:38:58,398] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:39:03,606] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:39:09,493] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:39:14,980] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:39:20,004] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:39:25,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.882495988333356
[2022-12-07 09:39:25,275] [INFO] [runner_train_mujoco] Average state value: 0.5347520143315195
[2022-12-07 09:39:25,275] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 09:39:25,323] [INFO] [controller] EPOCH 1 loss ppo:  -0.01432, loss val: 0.07061
[2022-12-07 09:39:25,364] [INFO] [controller] EPOCH 2 loss ppo:  -0.01939, loss val: 0.06914
[2022-12-07 09:39:25,407] [INFO] [controller] EPOCH 3 loss ppo:  -0.02851, loss val: 0.06916
[2022-12-07 09:39:25,451] [INFO] [controller] EPOCH 4 loss ppo:  -0.03653, loss val: 0.06871
[2022-12-07 09:39:25,458] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:39:25,636] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:39:25,637] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:39:31,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:39:36,493] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:39:41,671] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:39:47,451] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:39:53,080] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:39:58,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:40:04,477] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:40:10,360] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:40:15,669] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:40:21,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.110888088873109
[2022-12-07 09:40:21,237] [INFO] [runner_train_mujoco] Average state value: 0.5651051712830861
[2022-12-07 09:40:21,237] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 09:40:21,296] [INFO] [controller] EPOCH 1 loss ppo:  -0.01382, loss val: 0.03148
[2022-12-07 09:40:21,339] [INFO] [controller] EPOCH 2 loss ppo:  -0.01933, loss val: 0.03064
[2022-12-07 09:40:21,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.02669, loss val: 0.03145
[2022-12-07 09:40:21,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.03311, loss val: 0.03123
[2022-12-07 09:40:21,429] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:40:21,595] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:40:21,596] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:40:27,642] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:40:33,245] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:40:38,943] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:40:49,147] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:41:01,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:41:09,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:41:16,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:41:23,292] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:41:29,572] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:41:36,385] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.293817916619654
[2022-12-07 09:41:36,386] [INFO] [runner_train_mujoco] Average state value: 0.4824907951628168
[2022-12-07 09:41:36,386] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 09:41:36,451] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.08533
[2022-12-07 09:41:36,501] [INFO] [controller] EPOCH 2 loss ppo:  -0.02050, loss val: 0.08693
[2022-12-07 09:41:36,549] [INFO] [controller] EPOCH 3 loss ppo:  -0.02639, loss val: 0.08462
[2022-12-07 09:41:36,601] [INFO] [controller] EPOCH 4 loss ppo:  -0.03272, loss val: 0.08629
[2022-12-07 09:41:36,611] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:41:36,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:41:36,839] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:41:45,054] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:41:51,202] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:41:58,012] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:42:04,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:42:10,740] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:42:16,363] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:42:23,466] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:42:30,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:42:36,469] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:42:42,983] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.484607147615693
[2022-12-07 09:42:42,984] [INFO] [runner_train_mujoco] Average state value: 0.456537521108985
[2022-12-07 09:42:42,984] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 09:42:43,105] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.09491
[2022-12-07 09:42:43,170] [INFO] [controller] EPOCH 2 loss ppo:  -0.01985, loss val: 0.09521
[2022-12-07 09:42:43,369] [INFO] [controller] EPOCH 3 loss ppo:  -0.02629, loss val: 0.09480
[2022-12-07 09:42:43,527] [INFO] [controller] EPOCH 4 loss ppo:  -0.03270, loss val: 0.09292
[2022-12-07 09:42:43,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:42:43,773] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:42:43,774] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:42:53,336] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:43:01,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:43:09,190] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:43:15,167] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:43:22,009] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:43:32,008] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:43:41,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:43:49,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:44:01,088] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:44:12,631] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.848488370533518
[2022-12-07 09:44:12,632] [INFO] [runner_train_mujoco] Average state value: 0.5071956779857476
[2022-12-07 09:44:12,632] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 09:44:12,731] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.05627
[2022-12-07 09:44:12,817] [INFO] [controller] EPOCH 2 loss ppo:  -0.01894, loss val: 0.05585
[2022-12-07 09:44:12,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.02371, loss val: 0.05546
[2022-12-07 09:44:12,993] [INFO] [controller] EPOCH 4 loss ppo:  -0.02908, loss val: 0.05495
[2022-12-07 09:44:13,009] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:44:13,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:44:13,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:44:21,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:44:28,898] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:44:35,278] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:44:41,828] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:44:48,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:44:55,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:45:02,937] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:45:09,738] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:45:16,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:45:23,849] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.452114238375064
[2022-12-07 09:45:23,849] [INFO] [runner_train_mujoco] Average state value: 0.5261365300466616
[2022-12-07 09:45:23,849] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 09:45:24,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.05071
[2022-12-07 09:45:24,095] [INFO] [controller] EPOCH 2 loss ppo:  -0.01631, loss val: 0.05159
[2022-12-07 09:45:24,227] [INFO] [controller] EPOCH 3 loss ppo:  -0.02015, loss val: 0.04996
[2022-12-07 09:45:24,309] [INFO] [controller] EPOCH 4 loss ppo:  -0.02493, loss val: 0.05063
[2022-12-07 09:45:24,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:45:24,619] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:45:24,620] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:45:33,723] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:45:40,673] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:45:47,533] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:45:54,688] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:46:00,699] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:46:07,003] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:46:13,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:46:18,805] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:46:26,014] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:46:33,326] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.979275679594016
[2022-12-07 09:46:33,326] [INFO] [runner_train_mujoco] Average state value: 0.5333062377547224
[2022-12-07 09:46:33,327] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 09:46:33,402] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04509
[2022-12-07 09:46:33,464] [INFO] [controller] EPOCH 2 loss ppo:  -0.01603, loss val: 0.04454
[2022-12-07 09:46:33,604] [INFO] [controller] EPOCH 3 loss ppo:  -0.01904, loss val: 0.04377
[2022-12-07 09:46:33,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.02301, loss val: 0.04534
[2022-12-07 09:46:33,672] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:46:33,882] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:46:33,883] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:46:41,314] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:46:47,600] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:46:53,681] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:46:59,847] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:47:05,849] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:47:12,095] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 09:47:17,950] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 09:47:23,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 09:47:30,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 09:47:36,158] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.243273939203734
[2022-12-07 09:47:36,158] [INFO] [runner_train_mujoco] Average state value: 0.5390878109733264
[2022-12-07 09:47:36,158] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 09:47:36,230] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04752
[2022-12-07 09:47:36,277] [INFO] [controller] EPOCH 2 loss ppo:  -0.01483, loss val: 0.04650
[2022-12-07 09:47:36,324] [INFO] [controller] EPOCH 3 loss ppo:  -0.01604, loss val: 0.04613
[2022-12-07 09:47:36,373] [INFO] [controller] EPOCH 4 loss ppo:  -0.01802, loss val: 0.04734
[2022-12-07 09:47:36,383] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 09:47:36,524] [INFO] [optimize] Finished learning.
