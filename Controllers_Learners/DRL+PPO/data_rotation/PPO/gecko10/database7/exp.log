[2022-12-07 04:43:09,193] [INFO] [optimize] Starting learning
[2022-12-07 04:43:09,203] [INFO] [optimize] Starting learning process..
[2022-12-07 04:43:09,284] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:43:09,284] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:43:17,308] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:43:24,802] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:43:31,102] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:43:36,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:43:44,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:43:50,507] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:43:56,219] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:44:02,557] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:44:08,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:44:15,207] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.32576798754977726
[2022-12-07 04:44:15,207] [INFO] [runner_train_mujoco] Average state value: 0.19585332737863065
[2022-12-07 04:44:15,207] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 04:44:15,270] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.25188
[2022-12-07 04:44:15,319] [INFO] [controller] EPOCH 2 loss ppo:  -0.04331, loss val: 0.22352
[2022-12-07 04:44:15,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.05425, loss val: 0.19112
[2022-12-07 04:44:15,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.06112, loss val: 0.16912
[2022-12-07 04:44:15,425] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:44:15,620] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:44:15,620] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:44:21,670] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:44:27,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:44:34,051] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:44:39,964] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:44:45,903] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:44:52,062] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:44:58,447] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:45:06,869] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:45:13,883] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:45:21,160] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.47185515386212434
[2022-12-07 04:45:21,160] [INFO] [runner_train_mujoco] Average state value: 0.32467287681034457
[2022-12-07 04:45:21,160] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 04:45:21,232] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.21161
[2022-12-07 04:45:21,281] [INFO] [controller] EPOCH 2 loss ppo:  -0.03693, loss val: 0.18089
[2022-12-07 04:45:21,336] [INFO] [controller] EPOCH 3 loss ppo:  -0.05072, loss val: 0.15628
[2022-12-07 04:45:21,390] [INFO] [controller] EPOCH 4 loss ppo:  -0.06015, loss val: 0.13143
[2022-12-07 04:45:21,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:45:21,603] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:45:21,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:45:29,288] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:45:36,907] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:45:44,663] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:45:52,290] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:45:59,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:46:07,242] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:46:15,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:46:22,791] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:46:30,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:46:37,429] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4411072728042208
[2022-12-07 04:46:37,429] [INFO] [runner_train_mujoco] Average state value: 0.5031338189318777
[2022-12-07 04:46:37,429] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 04:46:37,522] [INFO] [controller] EPOCH 1 loss ppo:  -0.01071, loss val: 0.12376
[2022-12-07 04:46:37,599] [INFO] [controller] EPOCH 2 loss ppo:  -0.03328, loss val: 0.11149
[2022-12-07 04:46:37,674] [INFO] [controller] EPOCH 3 loss ppo:  -0.04655, loss val: 0.09795
[2022-12-07 04:46:37,731] [INFO] [controller] EPOCH 4 loss ppo:  -0.05531, loss val: 0.09070
[2022-12-07 04:46:37,741] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:46:37,952] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:46:37,953] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:46:45,908] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:46:53,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:47:01,193] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:47:08,851] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:47:16,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:47:23,984] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:47:31,249] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:47:38,765] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:47:45,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:47:52,930] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44592683754314316
[2022-12-07 04:47:52,931] [INFO] [runner_train_mujoco] Average state value: 0.6292496498723825
[2022-12-07 04:47:52,931] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 04:47:53,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.01058, loss val: 0.08620
[2022-12-07 04:47:53,070] [INFO] [controller] EPOCH 2 loss ppo:  -0.03520, loss val: 0.08248
[2022-12-07 04:47:53,125] [INFO] [controller] EPOCH 3 loss ppo:  -0.04549, loss val: 0.07465
[2022-12-07 04:47:53,182] [INFO] [controller] EPOCH 4 loss ppo:  -0.05091, loss val: 0.06993
[2022-12-07 04:47:53,193] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:47:53,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:47:53,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:48:00,221] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:48:07,289] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:48:13,926] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:48:20,826] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:48:27,805] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:48:34,851] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:48:41,639] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:48:48,852] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:48:55,360] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:49:02,275] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5767832486599432
[2022-12-07 04:49:02,275] [INFO] [runner_train_mujoco] Average state value: 0.697045983672142
[2022-12-07 04:49:02,276] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 04:49:02,340] [INFO] [controller] EPOCH 1 loss ppo:  -0.01030, loss val: 0.06862
[2022-12-07 04:49:02,387] [INFO] [controller] EPOCH 2 loss ppo:  -0.03554, loss val: 0.06624
[2022-12-07 04:49:02,445] [INFO] [controller] EPOCH 3 loss ppo:  -0.04394, loss val: 0.06258
[2022-12-07 04:49:02,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.05441, loss val: 0.05871
[2022-12-07 04:49:02,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:49:02,702] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:49:02,703] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:49:09,623] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:49:16,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:49:23,271] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:49:29,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:49:36,759] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:49:43,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:49:50,647] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:49:57,654] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:50:04,994] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:50:11,552] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5631206404629646
[2022-12-07 04:50:11,553] [INFO] [runner_train_mujoco] Average state value: 0.6797891315122445
[2022-12-07 04:50:11,553] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 04:50:11,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01104, loss val: 0.05587
[2022-12-07 04:50:11,668] [INFO] [controller] EPOCH 2 loss ppo:  -0.03560, loss val: 0.05082
[2022-12-07 04:50:11,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.04782, loss val: 0.04712
[2022-12-07 04:50:11,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.05440, loss val: 0.04520
[2022-12-07 04:50:11,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:50:11,981] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:50:11,982] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:50:18,834] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:50:25,974] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:50:32,469] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:50:39,425] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:50:46,110] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:50:53,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:50:59,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:51:06,911] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:51:13,820] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:51:20,789] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7082421450634757
[2022-12-07 04:51:20,790] [INFO] [runner_train_mujoco] Average state value: 0.5896921362479529
[2022-12-07 04:51:20,790] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 04:51:20,850] [INFO] [controller] EPOCH 1 loss ppo:  -0.01155, loss val: 0.05187
[2022-12-07 04:51:20,900] [INFO] [controller] EPOCH 2 loss ppo:  -0.03331, loss val: 0.04712
[2022-12-07 04:51:20,951] [INFO] [controller] EPOCH 3 loss ppo:  -0.04339, loss val: 0.04510
[2022-12-07 04:51:21,002] [INFO] [controller] EPOCH 4 loss ppo:  -0.05110, loss val: 0.04691
[2022-12-07 04:51:21,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:51:21,226] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:51:21,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:51:28,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:51:34,846] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:51:41,510] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:51:48,493] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:51:55,422] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:52:02,281] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:52:08,971] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:52:16,105] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:52:22,946] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:52:29,767] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8109136389830773
[2022-12-07 04:52:29,767] [INFO] [runner_train_mujoco] Average state value: 0.5103380346099535
[2022-12-07 04:52:29,767] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 04:52:29,841] [INFO] [controller] EPOCH 1 loss ppo:  -0.01223, loss val: 0.04286
[2022-12-07 04:52:29,898] [INFO] [controller] EPOCH 2 loss ppo:  -0.03404, loss val: 0.04590
[2022-12-07 04:52:29,953] [INFO] [controller] EPOCH 3 loss ppo:  -0.04366, loss val: 0.04283
[2022-12-07 04:52:30,004] [INFO] [controller] EPOCH 4 loss ppo:  -0.05151, loss val: 0.04199
[2022-12-07 04:52:30,015] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:52:30,211] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:52:30,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:52:36,985] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:52:43,656] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:52:50,060] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:52:56,633] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:53:03,683] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:53:11,607] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:53:19,276] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:53:25,872] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:53:32,404] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:53:38,708] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7535689104296445
[2022-12-07 04:53:38,708] [INFO] [runner_train_mujoco] Average state value: 0.4980902256766955
[2022-12-07 04:53:38,709] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 04:53:38,768] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.04185
[2022-12-07 04:53:38,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.03681, loss val: 0.04174
[2022-12-07 04:53:38,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.05007, loss val: 0.04007
[2022-12-07 04:53:38,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.05567, loss val: 0.04023
[2022-12-07 04:53:38,931] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:53:39,132] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:53:39,132] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:53:46,123] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:53:52,971] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:53:59,827] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:54:06,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:54:13,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:54:20,407] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:54:27,131] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:54:33,906] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:54:40,330] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:54:47,212] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8798642382383413
[2022-12-07 04:54:47,212] [INFO] [runner_train_mujoco] Average state value: 0.5441215821007888
[2022-12-07 04:54:47,212] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 04:54:47,267] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04771
[2022-12-07 04:54:47,310] [INFO] [controller] EPOCH 2 loss ppo:  -0.03521, loss val: 0.04792
[2022-12-07 04:54:47,357] [INFO] [controller] EPOCH 3 loss ppo:  -0.04836, loss val: 0.04759
[2022-12-07 04:54:47,402] [INFO] [controller] EPOCH 4 loss ppo:  -0.05475, loss val: 0.04754
[2022-12-07 04:54:47,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:54:47,608] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:54:47,609] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:54:54,341] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:55:01,355] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:55:08,365] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:55:14,934] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:55:21,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:55:28,479] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:55:35,232] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:55:41,522] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:55:48,499] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:55:54,752] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9400591548864927
[2022-12-07 04:55:54,752] [INFO] [runner_train_mujoco] Average state value: 0.5789990541636945
[2022-12-07 04:55:54,752] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 04:55:54,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.04466
[2022-12-07 04:55:54,856] [INFO] [controller] EPOCH 2 loss ppo:  -0.03620, loss val: 0.04415
[2022-12-07 04:55:54,901] [INFO] [controller] EPOCH 3 loss ppo:  -0.04675, loss val: 0.04394
[2022-12-07 04:55:54,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.05609, loss val: 0.04442
[2022-12-07 04:55:54,954] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:55:55,154] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:55:55,154] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:56:01,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:56:08,618] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:56:15,433] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:56:22,354] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:56:29,488] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:56:36,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:56:43,053] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:56:49,883] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:56:56,482] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:57:03,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9176503170664174
[2022-12-07 04:57:03,077] [INFO] [runner_train_mujoco] Average state value: 0.5908877286513647
[2022-12-07 04:57:03,078] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 04:57:03,129] [INFO] [controller] EPOCH 1 loss ppo:  -0.01282, loss val: 0.04700
[2022-12-07 04:57:03,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.03086, loss val: 0.04439
[2022-12-07 04:57:03,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.04136, loss val: 0.04390
[2022-12-07 04:57:03,268] [INFO] [controller] EPOCH 4 loss ppo:  -0.05023, loss val: 0.04378
[2022-12-07 04:57:03,277] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:57:03,473] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:57:03,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:57:10,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:57:16,739] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:57:23,545] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:57:30,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:57:36,550] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:57:43,224] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:57:50,374] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:57:57,932] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:58:05,318] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:58:12,132] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0386749487250337
[2022-12-07 04:58:12,132] [INFO] [runner_train_mujoco] Average state value: 0.6123699667652447
[2022-12-07 04:58:12,132] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 04:58:12,203] [INFO] [controller] EPOCH 1 loss ppo:  -0.01178, loss val: 0.03815
[2022-12-07 04:58:12,254] [INFO] [controller] EPOCH 2 loss ppo:  -0.02774, loss val: 0.03796
[2022-12-07 04:58:12,301] [INFO] [controller] EPOCH 3 loss ppo:  -0.04139, loss val: 0.03720
[2022-12-07 04:58:12,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.04828, loss val: 0.03797
[2022-12-07 04:58:12,371] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:58:12,575] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:58:12,575] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:58:19,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:58:26,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:58:33,108] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:58:39,488] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:58:46,347] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 04:58:53,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 04:58:59,149] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 04:59:05,906] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 04:59:12,560] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 04:59:19,240] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1422696799257903
[2022-12-07 04:59:19,240] [INFO] [runner_train_mujoco] Average state value: 0.5864347730875015
[2022-12-07 04:59:19,240] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 04:59:19,303] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.04006
[2022-12-07 04:59:19,346] [INFO] [controller] EPOCH 2 loss ppo:  -0.03233, loss val: 0.04033
[2022-12-07 04:59:19,402] [INFO] [controller] EPOCH 3 loss ppo:  -0.04150, loss val: 0.03988
[2022-12-07 04:59:19,444] [INFO] [controller] EPOCH 4 loss ppo:  -0.05347, loss val: 0.03991
[2022-12-07 04:59:19,453] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 04:59:19,647] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 04:59:19,647] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 04:59:26,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 04:59:33,677] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 04:59:40,297] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 04:59:47,002] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 04:59:53,782] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:00:00,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:00:07,311] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:00:13,618] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:00:19,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:00:26,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3785359710914409
[2022-12-07 05:00:26,416] [INFO] [runner_train_mujoco] Average state value: 0.5485680777182182
[2022-12-07 05:00:26,416] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 05:00:26,475] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.04340
[2022-12-07 05:00:26,527] [INFO] [controller] EPOCH 2 loss ppo:  -0.02921, loss val: 0.04239
[2022-12-07 05:00:26,580] [INFO] [controller] EPOCH 3 loss ppo:  -0.03921, loss val: 0.04124
[2022-12-07 05:00:26,632] [INFO] [controller] EPOCH 4 loss ppo:  -0.05032, loss val: 0.03940
[2022-12-07 05:00:26,644] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:00:26,858] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:00:26,859] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:00:33,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:00:40,195] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:00:46,930] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:00:53,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:01:00,265] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:01:06,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:01:13,747] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:01:20,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:01:26,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:01:33,903] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.623761185765932
[2022-12-07 05:01:33,903] [INFO] [runner_train_mujoco] Average state value: 0.5787176144123078
[2022-12-07 05:01:33,903] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 05:01:33,969] [INFO] [controller] EPOCH 1 loss ppo:  -0.01568, loss val: 0.03854
[2022-12-07 05:01:34,016] [INFO] [controller] EPOCH 2 loss ppo:  -0.03809, loss val: 0.03887
[2022-12-07 05:01:34,077] [INFO] [controller] EPOCH 3 loss ppo:  -0.04738, loss val: 0.03716
[2022-12-07 05:01:34,132] [INFO] [controller] EPOCH 4 loss ppo:  -0.05662, loss val: 0.03763
[2022-12-07 05:01:34,142] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:01:34,353] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:01:34,353] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:01:41,046] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:01:47,770] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:01:54,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:02:00,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:02:06,962] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:02:13,273] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:02:20,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:02:26,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:02:33,685] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:02:40,367] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7397009751831587
[2022-12-07 05:02:40,367] [INFO] [runner_train_mujoco] Average state value: 0.5875996664961181
[2022-12-07 05:02:40,367] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 05:02:40,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.03796
[2022-12-07 05:02:40,475] [INFO] [controller] EPOCH 2 loss ppo:  -0.03173, loss val: 0.03901
[2022-12-07 05:02:40,527] [INFO] [controller] EPOCH 3 loss ppo:  -0.04401, loss val: 0.03877
[2022-12-07 05:02:40,583] [INFO] [controller] EPOCH 4 loss ppo:  -0.05486, loss val: 0.03802
[2022-12-07 05:02:40,592] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:02:40,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:02:40,789] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:02:47,597] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:02:53,971] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:03:00,200] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:03:06,678] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:03:13,699] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:03:20,634] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:03:27,305] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:03:34,017] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:03:40,342] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:03:47,357] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8685682856986336
[2022-12-07 05:03:47,357] [INFO] [runner_train_mujoco] Average state value: 0.5548564269542695
[2022-12-07 05:03:47,357] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 05:03:47,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01104, loss val: 0.03938
[2022-12-07 05:03:47,470] [INFO] [controller] EPOCH 2 loss ppo:  -0.03238, loss val: 0.03974
[2022-12-07 05:03:47,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.04749, loss val: 0.03762
[2022-12-07 05:03:47,565] [INFO] [controller] EPOCH 4 loss ppo:  -0.05526, loss val: 0.03785
[2022-12-07 05:03:47,575] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:03:47,767] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:03:47,768] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:03:53,991] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:04:01,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:04:07,735] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:04:14,084] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:04:21,096] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:04:27,833] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:04:34,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:04:40,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:04:47,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:04:53,917] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.051491662133156
[2022-12-07 05:04:53,917] [INFO] [runner_train_mujoco] Average state value: 0.5341188904245694
[2022-12-07 05:04:53,917] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 05:04:53,986] [INFO] [controller] EPOCH 1 loss ppo:  -0.01566, loss val: 0.04026
[2022-12-07 05:04:54,038] [INFO] [controller] EPOCH 2 loss ppo:  -0.03520, loss val: 0.03999
[2022-12-07 05:04:54,087] [INFO] [controller] EPOCH 3 loss ppo:  -0.04871, loss val: 0.04013
[2022-12-07 05:04:54,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.06335, loss val: 0.03956
[2022-12-07 05:04:54,149] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:04:54,342] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:04:54,343] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:05:00,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:05:07,483] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:05:14,152] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:05:20,893] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:05:27,452] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:05:34,012] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:05:40,583] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:05:47,492] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:05:54,098] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:06:00,726] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1460323026315486
[2022-12-07 05:06:00,726] [INFO] [runner_train_mujoco] Average state value: 0.5546698139111201
[2022-12-07 05:06:00,727] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 05:06:00,788] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04030
[2022-12-07 05:06:00,836] [INFO] [controller] EPOCH 2 loss ppo:  -0.02964, loss val: 0.04102
[2022-12-07 05:06:00,886] [INFO] [controller] EPOCH 3 loss ppo:  -0.04192, loss val: 0.03958
[2022-12-07 05:06:01,022] [INFO] [controller] EPOCH 4 loss ppo:  -0.05093, loss val: 0.04197
[2022-12-07 05:06:01,031] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:06:01,225] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:06:01,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:06:07,625] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:06:14,434] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:06:20,955] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:06:27,570] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:06:34,543] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:06:41,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:06:47,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:06:54,562] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:07:01,123] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:07:09,113] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.277753107354575
[2022-12-07 05:07:09,113] [INFO] [runner_train_mujoco] Average state value: 0.594390892058611
[2022-12-07 05:07:09,113] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 05:07:09,188] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.04618
[2022-12-07 05:07:09,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.03066, loss val: 0.04455
[2022-12-07 05:07:09,353] [INFO] [controller] EPOCH 3 loss ppo:  -0.04166, loss val: 0.04466
[2022-12-07 05:07:09,410] [INFO] [controller] EPOCH 4 loss ppo:  -0.05300, loss val: 0.04362
[2022-12-07 05:07:09,421] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:07:09,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:07:09,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:07:17,036] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:07:24,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:07:31,426] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:07:38,505] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:07:45,479] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:07:52,063] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:07:58,495] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:08:05,064] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:08:11,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:08:17,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.773431622291937
[2022-12-07 05:08:17,661] [INFO] [runner_train_mujoco] Average state value: 0.5718941956758499
[2022-12-07 05:08:17,661] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 05:08:17,731] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.04264
[2022-12-07 05:08:17,796] [INFO] [controller] EPOCH 2 loss ppo:  -0.03256, loss val: 0.04121
[2022-12-07 05:08:17,847] [INFO] [controller] EPOCH 3 loss ppo:  -0.04388, loss val: 0.04143
[2022-12-07 05:08:17,904] [INFO] [controller] EPOCH 4 loss ppo:  -0.05620, loss val: 0.03983
[2022-12-07 05:08:17,916] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:08:18,119] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:08:18,120] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:08:25,032] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:08:31,646] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:08:38,258] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:08:45,397] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:08:52,015] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:08:58,557] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:09:04,573] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:09:11,115] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:09:17,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:09:24,014] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.861028435754384
[2022-12-07 05:09:24,015] [INFO] [runner_train_mujoco] Average state value: 0.5079902054071426
[2022-12-07 05:09:24,015] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 05:09:24,072] [INFO] [controller] EPOCH 1 loss ppo:  -0.01819, loss val: 0.03103
[2022-12-07 05:09:24,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.03642, loss val: 0.02995
[2022-12-07 05:09:24,257] [INFO] [controller] EPOCH 3 loss ppo:  -0.04189, loss val: 0.03046
[2022-12-07 05:09:24,306] [INFO] [controller] EPOCH 4 loss ppo:  -0.05433, loss val: 0.03202
[2022-12-07 05:09:24,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:09:24,512] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:09:24,512] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:09:30,794] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:09:37,400] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:09:44,243] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:09:50,847] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:09:57,423] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:10:03,794] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:10:10,524] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:10:17,172] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:10:23,623] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:10:30,360] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0780116663392745
[2022-12-07 05:10:30,360] [INFO] [runner_train_mujoco] Average state value: 0.4780258456269901
[2022-12-07 05:10:30,360] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 05:10:30,428] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.03455
[2022-12-07 05:10:30,475] [INFO] [controller] EPOCH 2 loss ppo:  -0.03511, loss val: 0.03483
[2022-12-07 05:10:30,535] [INFO] [controller] EPOCH 3 loss ppo:  -0.04604, loss val: 0.03444
[2022-12-07 05:10:30,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.05485, loss val: 0.03474
[2022-12-07 05:10:30,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:10:30,794] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:10:30,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:10:37,404] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:10:43,851] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:10:50,502] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:10:56,928] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:11:03,529] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:11:09,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:11:16,026] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:11:22,268] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:11:28,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:11:35,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2912092831948185
[2022-12-07 05:11:35,004] [INFO] [runner_train_mujoco] Average state value: 0.4708405613104502
[2022-12-07 05:11:35,004] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 05:11:35,064] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.04213
[2022-12-07 05:11:35,114] [INFO] [controller] EPOCH 2 loss ppo:  -0.02941, loss val: 0.04196
[2022-12-07 05:11:35,166] [INFO] [controller] EPOCH 3 loss ppo:  -0.04104, loss val: 0.04093
[2022-12-07 05:11:35,216] [INFO] [controller] EPOCH 4 loss ppo:  -0.05188, loss val: 0.03996
[2022-12-07 05:11:35,227] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:11:35,429] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:11:35,430] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:11:42,243] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:11:49,287] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:11:55,955] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:12:02,486] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:12:08,838] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:12:15,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:12:21,231] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:12:27,508] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:12:33,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:12:40,317] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.415077922693464
[2022-12-07 05:12:40,317] [INFO] [runner_train_mujoco] Average state value: 0.5052963715394339
[2022-12-07 05:12:40,317] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 05:12:40,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01616, loss val: 0.03673
[2022-12-07 05:12:40,433] [INFO] [controller] EPOCH 2 loss ppo:  -0.03378, loss val: 0.03668
[2022-12-07 05:12:40,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.03926, loss val: 0.03689
[2022-12-07 05:12:40,550] [INFO] [controller] EPOCH 4 loss ppo:  -0.05224, loss val: 0.03634
[2022-12-07 05:12:40,560] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:12:40,753] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:12:40,753] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:12:47,207] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:12:53,252] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:12:59,205] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:13:05,156] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:13:10,850] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:13:17,211] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:13:23,368] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:13:28,972] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:13:34,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:13:40,474] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.72089008457539
[2022-12-07 05:13:40,474] [INFO] [runner_train_mujoco] Average state value: 0.5000933703978856
[2022-12-07 05:13:40,474] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 05:13:40,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.03788
[2022-12-07 05:13:40,579] [INFO] [controller] EPOCH 2 loss ppo:  -0.03089, loss val: 0.03744
[2022-12-07 05:13:40,622] [INFO] [controller] EPOCH 3 loss ppo:  -0.04762, loss val: 0.03571
[2022-12-07 05:13:40,668] [INFO] [controller] EPOCH 4 loss ppo:  -0.05564, loss val: 0.03870
[2022-12-07 05:13:40,678] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:13:40,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:13:40,873] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:13:46,629] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:13:52,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:13:58,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:14:04,038] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:14:10,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:14:16,092] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:14:21,547] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:14:27,339] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:14:32,612] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:14:38,272] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.721359828498534
[2022-12-07 05:14:38,272] [INFO] [runner_train_mujoco] Average state value: 0.49972319127122555
[2022-12-07 05:14:38,273] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 05:14:38,329] [INFO] [controller] EPOCH 1 loss ppo:  -0.01618, loss val: 0.04551
[2022-12-07 05:14:38,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.03311, loss val: 0.04427
[2022-12-07 05:14:38,471] [INFO] [controller] EPOCH 3 loss ppo:  -0.04448, loss val: 0.04438
[2022-12-07 05:14:38,514] [INFO] [controller] EPOCH 4 loss ppo:  -0.05677, loss val: 0.04406
[2022-12-07 05:14:38,524] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:14:38,715] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:14:38,716] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:14:44,702] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:14:50,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:14:56,909] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:15:02,706] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:15:08,416] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:15:14,037] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:15:19,907] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:15:25,661] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:15:31,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:15:37,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.532338388464518
[2022-12-07 05:15:37,660] [INFO] [runner_train_mujoco] Average state value: 0.4891143578489621
[2022-12-07 05:15:37,660] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 05:15:37,711] [INFO] [controller] EPOCH 1 loss ppo:  -0.01355, loss val: 0.03673
[2022-12-07 05:15:37,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.02947, loss val: 0.03646
[2022-12-07 05:15:37,795] [INFO] [controller] EPOCH 3 loss ppo:  -0.04145, loss val: 0.03488
[2022-12-07 05:15:37,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.05471, loss val: 0.03409
[2022-12-07 05:15:37,865] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:15:38,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:15:38,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:15:44,195] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:15:50,215] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:15:55,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:16:01,515] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:16:07,513] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:16:13,353] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:16:19,669] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:16:25,216] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:16:31,024] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:16:36,561] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.741451808043491
[2022-12-07 05:16:36,561] [INFO] [runner_train_mujoco] Average state value: 0.44730156503121055
[2022-12-07 05:16:36,561] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 05:16:36,612] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.04651
[2022-12-07 05:16:36,655] [INFO] [controller] EPOCH 2 loss ppo:  -0.03195, loss val: 0.04730
[2022-12-07 05:16:36,703] [INFO] [controller] EPOCH 3 loss ppo:  -0.04157, loss val: 0.04713
[2022-12-07 05:16:36,747] [INFO] [controller] EPOCH 4 loss ppo:  -0.05047, loss val: 0.04936
[2022-12-07 05:16:36,755] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:16:36,956] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:16:36,956] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:16:42,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:16:48,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:16:54,565] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:17:00,455] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:17:06,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:17:11,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:17:17,719] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:17:23,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:17:28,697] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:17:34,237] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.115053369741461
[2022-12-07 05:17:34,237] [INFO] [runner_train_mujoco] Average state value: 0.43483674825231233
[2022-12-07 05:17:34,237] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 05:17:34,293] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.03858
[2022-12-07 05:17:34,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.03272, loss val: 0.04059
[2022-12-07 05:17:34,379] [INFO] [controller] EPOCH 3 loss ppo:  -0.04508, loss val: 0.03832
[2022-12-07 05:17:34,421] [INFO] [controller] EPOCH 4 loss ppo:  -0.05665, loss val: 0.03932
[2022-12-07 05:17:34,431] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:17:34,614] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:17:34,614] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:17:40,610] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:17:46,691] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:17:52,487] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:17:57,882] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:18:03,702] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:18:09,027] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:18:14,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:18:20,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:18:26,550] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:18:32,015] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.328548829512541
[2022-12-07 05:18:32,015] [INFO] [runner_train_mujoco] Average state value: 0.45140741267800333
[2022-12-07 05:18:32,015] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 05:18:32,066] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.05048
[2022-12-07 05:18:32,110] [INFO] [controller] EPOCH 2 loss ppo:  -0.03528, loss val: 0.05094
[2022-12-07 05:18:32,153] [INFO] [controller] EPOCH 3 loss ppo:  -0.04402, loss val: 0.04919
[2022-12-07 05:18:32,197] [INFO] [controller] EPOCH 4 loss ppo:  -0.05277, loss val: 0.04824
[2022-12-07 05:18:32,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:18:32,378] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:18:32,378] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:18:38,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:18:43,684] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:18:49,881] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:18:55,950] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:19:01,783] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:19:07,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:19:13,206] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:19:18,747] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:19:24,192] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:19:30,094] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.343312830930529
[2022-12-07 05:19:30,094] [INFO] [runner_train_mujoco] Average state value: 0.48765447809298834
[2022-12-07 05:19:30,094] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 05:19:30,151] [INFO] [controller] EPOCH 1 loss ppo:  -0.01551, loss val: 0.04023
[2022-12-07 05:19:30,193] [INFO] [controller] EPOCH 2 loss ppo:  -0.03065, loss val: 0.04075
[2022-12-07 05:19:30,237] [INFO] [controller] EPOCH 3 loss ppo:  -0.03816, loss val: 0.04062
[2022-12-07 05:19:30,281] [INFO] [controller] EPOCH 4 loss ppo:  -0.04698, loss val: 0.04126
[2022-12-07 05:19:30,291] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:19:30,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:19:30,472] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:19:36,522] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:19:41,985] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:19:48,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:19:54,017] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:19:59,433] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:20:05,090] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:20:10,430] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:20:16,255] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:20:22,466] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:20:28,513] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.34198793829688
[2022-12-07 05:20:28,514] [INFO] [runner_train_mujoco] Average state value: 0.4928369577924411
[2022-12-07 05:20:28,514] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 05:20:28,570] [INFO] [controller] EPOCH 1 loss ppo:  -0.01715, loss val: 0.04918
[2022-12-07 05:20:28,613] [INFO] [controller] EPOCH 2 loss ppo:  -0.03410, loss val: 0.04782
[2022-12-07 05:20:28,658] [INFO] [controller] EPOCH 3 loss ppo:  -0.03850, loss val: 0.04795
[2022-12-07 05:20:28,701] [INFO] [controller] EPOCH 4 loss ppo:  -0.05044, loss val: 0.04699
[2022-12-07 05:20:28,708] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:20:28,899] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:20:28,900] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:20:34,969] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:20:41,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:20:46,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:20:52,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:20:58,105] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:21:04,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:21:09,647] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:21:15,538] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:21:21,222] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:21:26,573] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.745709894577765
[2022-12-07 05:21:26,573] [INFO] [runner_train_mujoco] Average state value: 0.5044153257807096
[2022-12-07 05:21:26,573] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 05:21:26,623] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.03942
[2022-12-07 05:21:26,660] [INFO] [controller] EPOCH 2 loss ppo:  -0.02620, loss val: 0.04112
[2022-12-07 05:21:26,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.03726, loss val: 0.04073
[2022-12-07 05:21:26,754] [INFO] [controller] EPOCH 4 loss ppo:  -0.05121, loss val: 0.03750
[2022-12-07 05:21:26,763] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:21:26,957] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:21:26,957] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:21:32,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:21:38,703] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:21:44,768] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:21:50,566] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:21:56,350] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:22:02,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:22:08,029] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:22:13,511] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:22:19,304] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:22:25,056] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.861853653624773
[2022-12-07 05:22:25,057] [INFO] [runner_train_mujoco] Average state value: 0.5254225867291292
[2022-12-07 05:22:25,057] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 05:22:25,109] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04430
[2022-12-07 05:22:25,154] [INFO] [controller] EPOCH 2 loss ppo:  -0.02867, loss val: 0.04437
[2022-12-07 05:22:25,200] [INFO] [controller] EPOCH 3 loss ppo:  -0.03907, loss val: 0.04433
[2022-12-07 05:22:25,244] [INFO] [controller] EPOCH 4 loss ppo:  -0.04685, loss val: 0.04407
[2022-12-07 05:22:25,253] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:22:25,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:22:25,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:22:31,117] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:22:37,056] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:22:43,038] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:22:48,608] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:22:54,264] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:22:59,703] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:23:05,343] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:23:11,219] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:23:16,708] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:23:23,022] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.875824997300251
[2022-12-07 05:23:23,022] [INFO] [runner_train_mujoco] Average state value: 0.5245641954739888
[2022-12-07 05:23:23,022] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 05:23:23,075] [INFO] [controller] EPOCH 1 loss ppo:  -0.01536, loss val: 0.04357
[2022-12-07 05:23:23,128] [INFO] [controller] EPOCH 2 loss ppo:  -0.02835, loss val: 0.04486
[2022-12-07 05:23:23,175] [INFO] [controller] EPOCH 3 loss ppo:  -0.03832, loss val: 0.04234
[2022-12-07 05:23:23,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.04879, loss val: 0.04078
[2022-12-07 05:23:23,224] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:23:23,431] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:23:23,431] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:23:29,037] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:23:34,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:23:41,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:23:47,067] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:23:52,573] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:23:58,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:24:03,630] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:24:09,462] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:24:15,089] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:24:20,966] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.868427684700907
[2022-12-07 05:24:20,966] [INFO] [runner_train_mujoco] Average state value: 0.5238203139106432
[2022-12-07 05:24:20,966] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 05:24:21,018] [INFO] [controller] EPOCH 1 loss ppo:  -0.01484, loss val: 0.04669
[2022-12-07 05:24:21,060] [INFO] [controller] EPOCH 2 loss ppo:  -0.02819, loss val: 0.04759
[2022-12-07 05:24:21,098] [INFO] [controller] EPOCH 3 loss ppo:  -0.03733, loss val: 0.04785
[2022-12-07 05:24:21,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.04803, loss val: 0.04669
[2022-12-07 05:24:21,150] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:24:21,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:24:21,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:24:26,911] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:24:32,428] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:24:38,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:24:44,022] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:24:49,471] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:24:54,983] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:25:00,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:25:06,566] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:25:11,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:25:17,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.958793186082674
[2022-12-07 05:25:17,974] [INFO] [runner_train_mujoco] Average state value: 0.5323581236004828
[2022-12-07 05:25:17,974] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 05:25:18,030] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.04901
[2022-12-07 05:25:18,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.02779, loss val: 0.04868
[2022-12-07 05:25:18,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.03983, loss val: 0.04890
[2022-12-07 05:25:18,168] [INFO] [controller] EPOCH 4 loss ppo:  -0.04962, loss val: 0.04800
[2022-12-07 05:25:18,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:25:18,364] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:25:18,364] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:25:23,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:25:29,496] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:25:35,229] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:25:40,788] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:25:46,485] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:25:52,324] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:25:57,793] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:26:03,135] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:26:08,542] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:26:14,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.328461270171716
[2022-12-07 05:26:14,173] [INFO] [runner_train_mujoco] Average state value: 0.5125462266206742
[2022-12-07 05:26:14,173] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 05:26:14,229] [INFO] [controller] EPOCH 1 loss ppo:  -0.01469, loss val: 0.04494
[2022-12-07 05:26:14,290] [INFO] [controller] EPOCH 2 loss ppo:  -0.02702, loss val: 0.04545
[2022-12-07 05:26:14,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.03951, loss val: 0.04642
[2022-12-07 05:26:14,498] [INFO] [controller] EPOCH 4 loss ppo:  -0.04457, loss val: 0.04523
[2022-12-07 05:26:14,509] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:26:14,722] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:26:14,722] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:26:20,642] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:26:26,660] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:26:32,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:26:38,456] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:26:43,941] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:26:49,590] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:26:54,893] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:27:00,351] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:27:05,720] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:27:11,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.336340172746857
[2022-12-07 05:27:11,851] [INFO] [runner_train_mujoco] Average state value: 0.49817265542348227
[2022-12-07 05:27:11,851] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 05:27:11,908] [INFO] [controller] EPOCH 1 loss ppo:  -0.01364, loss val: 0.03996
[2022-12-07 05:27:11,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.02582, loss val: 0.03957
[2022-12-07 05:27:12,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.03418, loss val: 0.03818
[2022-12-07 05:27:12,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.04467, loss val: 0.03889
[2022-12-07 05:27:12,063] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:27:12,246] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:27:12,246] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:27:17,924] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:27:23,738] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:27:29,616] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:27:35,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:27:40,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:27:46,555] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:27:51,733] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:27:57,532] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:28:02,722] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:28:08,815] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.6098201009135416
[2022-12-07 05:28:08,815] [INFO] [runner_train_mujoco] Average state value: 0.5092150938808918
[2022-12-07 05:28:08,816] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 05:28:08,873] [INFO] [controller] EPOCH 1 loss ppo:  -0.01467, loss val: 0.04845
[2022-12-07 05:28:08,916] [INFO] [controller] EPOCH 2 loss ppo:  -0.02778, loss val: 0.04783
[2022-12-07 05:28:08,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.03851, loss val: 0.04824
[2022-12-07 05:28:09,009] [INFO] [controller] EPOCH 4 loss ppo:  -0.04753, loss val: 0.04689
[2022-12-07 05:28:09,018] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:28:09,213] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:28:09,213] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:28:14,745] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:28:20,722] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:28:26,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:28:31,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:28:37,369] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:28:43,122] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:28:48,665] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:28:54,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:28:59,972] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:29:05,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.464189362019164
[2022-12-07 05:29:05,677] [INFO] [runner_train_mujoco] Average state value: 0.49337487355868015
[2022-12-07 05:29:05,677] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 05:29:05,737] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.05173
[2022-12-07 05:29:05,782] [INFO] [controller] EPOCH 2 loss ppo:  -0.02569, loss val: 0.05196
[2022-12-07 05:29:05,830] [INFO] [controller] EPOCH 3 loss ppo:  -0.03209, loss val: 0.05252
[2022-12-07 05:29:05,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.04340, loss val: 0.05263
[2022-12-07 05:29:05,888] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:29:06,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:29:06,112] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:29:11,623] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:29:17,061] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:29:22,817] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:29:28,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:29:33,338] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:29:38,677] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:29:44,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:29:49,643] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:29:55,945] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:30:02,567] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.587910067408794
[2022-12-07 05:30:02,567] [INFO] [runner_train_mujoco] Average state value: 0.48651094019412994
[2022-12-07 05:30:02,567] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 05:30:02,622] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.04531
[2022-12-07 05:30:02,682] [INFO] [controller] EPOCH 2 loss ppo:  -0.02054, loss val: 0.04531
[2022-12-07 05:30:02,738] [INFO] [controller] EPOCH 3 loss ppo:  -0.02628, loss val: 0.04736
[2022-12-07 05:30:02,793] [INFO] [controller] EPOCH 4 loss ppo:  -0.03761, loss val: 0.04400
[2022-12-07 05:30:02,804] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:30:03,008] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:30:03,009] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:30:08,839] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:30:14,053] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:30:19,978] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:30:25,388] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:30:31,526] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:30:36,529] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:30:41,706] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:30:46,973] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:30:52,117] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:30:57,226] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.588344660429861
[2022-12-07 05:30:57,227] [INFO] [runner_train_mujoco] Average state value: 0.4717465514143308
[2022-12-07 05:30:57,227] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 05:30:57,282] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.04285
[2022-12-07 05:30:57,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.02257, loss val: 0.04310
[2022-12-07 05:30:57,374] [INFO] [controller] EPOCH 3 loss ppo:  -0.03330, loss val: 0.04396
[2022-12-07 05:30:57,417] [INFO] [controller] EPOCH 4 loss ppo:  -0.04392, loss val: 0.04214
[2022-12-07 05:30:57,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:30:57,615] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:30:57,615] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:31:03,445] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:31:09,418] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:31:15,000] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:31:20,857] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:31:26,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:31:31,679] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:31:36,993] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:31:42,085] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:31:47,915] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:31:52,981] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.456109088848648
[2022-12-07 05:31:52,981] [INFO] [runner_train_mujoco] Average state value: 0.46135782059033714
[2022-12-07 05:31:52,981] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 05:31:53,035] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.04578
[2022-12-07 05:31:53,078] [INFO] [controller] EPOCH 2 loss ppo:  -0.02435, loss val: 0.04413
[2022-12-07 05:31:53,133] [INFO] [controller] EPOCH 3 loss ppo:  -0.03240, loss val: 0.04388
[2022-12-07 05:31:53,186] [INFO] [controller] EPOCH 4 loss ppo:  -0.04164, loss val: 0.04363
[2022-12-07 05:31:53,196] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:31:53,392] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:31:53,392] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:31:58,994] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:32:04,424] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:32:10,333] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:32:15,521] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:32:20,748] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:32:25,879] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:32:31,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:32:36,466] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:32:42,303] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:32:48,352] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.624812303215454
[2022-12-07 05:32:48,352] [INFO] [runner_train_mujoco] Average state value: 0.47396160348256433
[2022-12-07 05:32:48,352] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 05:32:48,413] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.04025
[2022-12-07 05:32:48,458] [INFO] [controller] EPOCH 2 loss ppo:  -0.02441, loss val: 0.03962
[2022-12-07 05:32:48,502] [INFO] [controller] EPOCH 3 loss ppo:  -0.02994, loss val: 0.04203
[2022-12-07 05:32:48,546] [INFO] [controller] EPOCH 4 loss ppo:  -0.03780, loss val: 0.04120
[2022-12-07 05:32:48,555] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:32:48,743] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:32:48,743] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:32:54,566] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:33:00,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:33:05,958] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:33:11,013] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:33:16,067] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:33:21,315] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:33:26,765] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:33:31,829] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:33:36,948] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:33:41,959] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.670709704779172
[2022-12-07 05:33:41,959] [INFO] [runner_train_mujoco] Average state value: 0.4760388143459955
[2022-12-07 05:33:41,959] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 05:33:42,009] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.03869
[2022-12-07 05:33:42,052] [INFO] [controller] EPOCH 2 loss ppo:  -0.01770, loss val: 0.03869
[2022-12-07 05:33:42,095] [INFO] [controller] EPOCH 3 loss ppo:  -0.02646, loss val: 0.03840
[2022-12-07 05:33:42,136] [INFO] [controller] EPOCH 4 loss ppo:  -0.03317, loss val: 0.03798
[2022-12-07 05:33:42,146] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:33:42,330] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:33:42,331] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:33:47,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:33:53,348] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:33:58,689] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:34:04,415] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:34:09,554] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:34:15,655] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:34:21,594] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:34:26,957] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:34:32,145] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:34:37,233] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.871275337928418
[2022-12-07 05:34:37,233] [INFO] [runner_train_mujoco] Average state value: 0.4869162898262342
[2022-12-07 05:34:37,233] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 05:34:37,285] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.04922
[2022-12-07 05:34:37,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.02306, loss val: 0.04858
[2022-12-07 05:34:37,373] [INFO] [controller] EPOCH 3 loss ppo:  -0.03023, loss val: 0.04574
[2022-12-07 05:34:37,419] [INFO] [controller] EPOCH 4 loss ppo:  -0.03794, loss val: 0.04679
[2022-12-07 05:34:37,428] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:34:37,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:34:37,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:34:43,093] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:34:50,390] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:34:56,254] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:35:01,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:35:06,571] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:35:11,738] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:35:17,025] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:35:22,689] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:35:27,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:35:33,656] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.849225662519668
[2022-12-07 05:35:33,656] [INFO] [runner_train_mujoco] Average state value: 0.5092054663697878
[2022-12-07 05:35:33,656] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 05:35:33,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.04952
[2022-12-07 05:35:33,755] [INFO] [controller] EPOCH 2 loss ppo:  -0.01864, loss val: 0.05189
[2022-12-07 05:35:33,800] [INFO] [controller] EPOCH 3 loss ppo:  -0.02921, loss val: 0.05002
[2022-12-07 05:35:33,844] [INFO] [controller] EPOCH 4 loss ppo:  -0.03855, loss val: 0.04948
[2022-12-07 05:35:33,853] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:35:34,041] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:35:34,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:35:39,608] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:35:45,293] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:35:51,000] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:35:56,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:36:01,248] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:36:06,338] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:36:11,783] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:36:16,983] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:36:22,261] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:36:27,402] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.845089722116307
[2022-12-07 05:36:27,402] [INFO] [runner_train_mujoco] Average state value: 0.5166360356807709
[2022-12-07 05:36:27,402] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 05:36:27,456] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.04480
[2022-12-07 05:36:27,501] [INFO] [controller] EPOCH 2 loss ppo:  -0.01823, loss val: 0.04453
[2022-12-07 05:36:27,543] [INFO] [controller] EPOCH 3 loss ppo:  -0.02417, loss val: 0.04445
[2022-12-07 05:36:27,589] [INFO] [controller] EPOCH 4 loss ppo:  -0.03111, loss val: 0.04367
[2022-12-07 05:36:27,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:36:27,791] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:36:27,792] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:36:33,309] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:36:38,992] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:36:44,914] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:36:50,802] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:36:55,948] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:37:01,364] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:37:06,780] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:37:11,778] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:37:17,052] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:37:22,151] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.053287646217311
[2022-12-07 05:37:22,151] [INFO] [runner_train_mujoco] Average state value: 0.5037077108224233
[2022-12-07 05:37:22,151] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 05:37:22,208] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.04725
[2022-12-07 05:37:22,264] [INFO] [controller] EPOCH 2 loss ppo:  -0.02025, loss val: 0.04719
[2022-12-07 05:37:22,312] [INFO] [controller] EPOCH 3 loss ppo:  -0.02978, loss val: 0.04692
[2022-12-07 05:37:22,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.03453, loss val: 0.04690
[2022-12-07 05:37:22,371] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:37:22,564] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:37:22,564] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:37:28,233] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:37:33,770] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:37:39,475] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:37:44,628] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:37:49,741] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:37:55,173] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:38:00,504] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:38:06,176] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:38:11,572] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:38:17,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.828847216866788
[2022-12-07 05:38:17,257] [INFO] [runner_train_mujoco] Average state value: 0.48737515950202936
[2022-12-07 05:38:17,257] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 05:38:17,309] [INFO] [controller] EPOCH 1 loss ppo:  -0.01428, loss val: 0.04090
[2022-12-07 05:38:17,355] [INFO] [controller] EPOCH 2 loss ppo:  -0.02139, loss val: 0.04103
[2022-12-07 05:38:17,401] [INFO] [controller] EPOCH 3 loss ppo:  -0.02665, loss val: 0.04104
[2022-12-07 05:38:17,444] [INFO] [controller] EPOCH 4 loss ppo:  -0.03136, loss val: 0.04093
[2022-12-07 05:38:17,454] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:38:17,638] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:38:17,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:38:22,773] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:38:28,721] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:38:34,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:38:39,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:38:44,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:38:50,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:38:55,598] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:39:00,518] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:39:05,398] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:39:10,664] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.275823394768444
[2022-12-07 05:39:10,664] [INFO] [runner_train_mujoco] Average state value: 0.4891298577785492
[2022-12-07 05:39:10,664] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 05:39:10,720] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04829
[2022-12-07 05:39:10,762] [INFO] [controller] EPOCH 2 loss ppo:  -0.01712, loss val: 0.04808
[2022-12-07 05:39:10,803] [INFO] [controller] EPOCH 3 loss ppo:  -0.02367, loss val: 0.04930
[2022-12-07 05:39:10,848] [INFO] [controller] EPOCH 4 loss ppo:  -0.03113, loss val: 0.04847
[2022-12-07 05:39:10,857] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:39:11,042] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:39:11,042] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:39:16,171] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:39:22,162] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:39:27,833] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:39:33,551] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:39:38,999] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:39:44,081] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:39:49,351] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:39:54,495] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:39:59,693] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:40:05,042] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.058601886275087
[2022-12-07 05:40:05,042] [INFO] [runner_train_mujoco] Average state value: 0.49106177137295404
[2022-12-07 05:40:05,042] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 05:40:05,097] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.05066
[2022-12-07 05:40:05,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.01796, loss val: 0.04934
[2022-12-07 05:40:05,189] [INFO] [controller] EPOCH 3 loss ppo:  -0.02278, loss val: 0.04936
[2022-12-07 05:40:05,234] [INFO] [controller] EPOCH 4 loss ppo:  -0.02646, loss val: 0.04934
[2022-12-07 05:40:05,244] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:40:05,439] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:40:05,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:40:10,741] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:40:16,358] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:40:21,750] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:40:26,972] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:40:32,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:40:37,692] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:40:42,903] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:40:48,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:40:53,667] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:40:58,569] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.260520998205372
[2022-12-07 05:40:58,569] [INFO] [runner_train_mujoco] Average state value: 0.4866528276999792
[2022-12-07 05:40:58,569] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 05:40:58,616] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04171
[2022-12-07 05:40:58,652] [INFO] [controller] EPOCH 2 loss ppo:  -0.01764, loss val: 0.04327
[2022-12-07 05:40:58,693] [INFO] [controller] EPOCH 3 loss ppo:  -0.02330, loss val: 0.04111
[2022-12-07 05:40:58,736] [INFO] [controller] EPOCH 4 loss ppo:  -0.02803, loss val: 0.04306
[2022-12-07 05:40:58,746] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:40:58,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:40:58,933] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:41:04,029] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:41:09,723] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:41:15,557] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:41:21,106] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:41:26,531] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:41:31,585] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:41:36,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:41:41,470] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:41:46,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:41:51,911] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.2191292559939715
[2022-12-07 05:41:51,911] [INFO] [runner_train_mujoco] Average state value: 0.4863241570790609
[2022-12-07 05:41:51,911] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 05:41:51,962] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.04404
[2022-12-07 05:41:52,006] [INFO] [controller] EPOCH 2 loss ppo:  -0.01668, loss val: 0.04413
[2022-12-07 05:41:52,106] [INFO] [controller] EPOCH 3 loss ppo:  -0.02080, loss val: 0.04427
[2022-12-07 05:41:52,153] [INFO] [controller] EPOCH 4 loss ppo:  -0.02451, loss val: 0.04517
[2022-12-07 05:41:52,164] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:41:52,350] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 05:41:52,350] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 05:41:58,462] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 05:42:05,884] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 05:42:12,409] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 05:42:18,884] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 05:42:24,957] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 05:42:31,158] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 05:42:37,032] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 05:42:42,988] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 05:42:48,950] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 05:42:54,938] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.306868297022577
[2022-12-07 05:42:54,938] [INFO] [runner_train_mujoco] Average state value: 0.4827231697241465
[2022-12-07 05:42:54,939] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 05:42:55,012] [INFO] [controller] EPOCH 1 loss ppo:  -0.01407, loss val: 0.04866
[2022-12-07 05:42:55,066] [INFO] [controller] EPOCH 2 loss ppo:  -0.01484, loss val: 0.04913
[2022-12-07 05:42:55,119] [INFO] [controller] EPOCH 3 loss ppo:  -0.01651, loss val: 0.04764
[2022-12-07 05:42:55,170] [INFO] [controller] EPOCH 4 loss ppo:  -0.01873, loss val: 0.04884
[2022-12-07 05:42:55,184] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 05:42:55,317] [INFO] [optimize] Finished learning.
