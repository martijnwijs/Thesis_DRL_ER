[2022-12-07 02:41:06,498] [INFO] [optimize] Starting learning
[2022-12-07 02:41:06,507] [INFO] [optimize] Starting learning process..
[2022-12-07 02:41:06,597] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:41:06,598] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:41:14,752] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:41:21,079] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:41:27,253] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:41:33,063] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:41:39,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:41:45,953] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:41:51,923] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:41:58,388] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:42:04,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:42:11,383] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.43587017712798415
[2022-12-07 02:42:11,383] [INFO] [runner_train_mujoco] Average state value: 0.22288939480235176
[2022-12-07 02:42:11,384] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 02:42:11,443] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.31609
[2022-12-07 02:42:11,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.04425, loss val: 0.28206
[2022-12-07 02:42:11,540] [INFO] [controller] EPOCH 3 loss ppo:  -0.05684, loss val: 0.25226
[2022-12-07 02:42:11,588] [INFO] [controller] EPOCH 4 loss ppo:  -0.06439, loss val: 0.22511
[2022-12-07 02:42:11,598] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:42:11,774] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:42:11,774] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:42:17,884] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:42:23,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:42:29,780] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:42:36,120] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:42:41,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:42:48,908] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:42:56,480] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:43:03,271] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:43:10,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:43:17,348] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4836588823404295
[2022-12-07 02:43:17,349] [INFO] [runner_train_mujoco] Average state value: 0.3759560494348406
[2022-12-07 02:43:17,349] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 02:43:17,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.17097
[2022-12-07 02:43:17,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.04008, loss val: 0.15361
[2022-12-07 02:43:17,551] [INFO] [controller] EPOCH 3 loss ppo:  -0.05501, loss val: 0.13935
[2022-12-07 02:43:17,606] [INFO] [controller] EPOCH 4 loss ppo:  -0.06123, loss val: 0.13339
[2022-12-07 02:43:17,617] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:43:17,812] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:43:17,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:43:25,421] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:43:32,159] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:43:39,017] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:43:45,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:43:52,568] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:43:58,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:44:05,861] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:44:12,362] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:44:18,607] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:44:25,344] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5205203402796654
[2022-12-07 02:44:25,344] [INFO] [runner_train_mujoco] Average state value: 0.5190352936616788
[2022-12-07 02:44:25,344] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 02:44:25,409] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.12405
[2022-12-07 02:44:25,466] [INFO] [controller] EPOCH 2 loss ppo:  -0.03897, loss val: 0.11377
[2022-12-07 02:44:25,515] [INFO] [controller] EPOCH 3 loss ppo:  -0.05029, loss val: 0.10590
[2022-12-07 02:44:25,563] [INFO] [controller] EPOCH 4 loss ppo:  -0.05741, loss val: 0.09979
[2022-12-07 02:44:25,573] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:44:25,786] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:44:25,786] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:44:33,015] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:44:39,770] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:44:46,754] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:44:53,272] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:45:00,063] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:45:06,855] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:45:13,653] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:45:20,301] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:45:27,337] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:45:34,200] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.344319235242624
[2022-12-07 02:45:34,200] [INFO] [runner_train_mujoco] Average state value: 0.596895870881776
[2022-12-07 02:45:34,200] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 02:45:34,270] [INFO] [controller] EPOCH 1 loss ppo:  -0.01007, loss val: 0.10813
[2022-12-07 02:45:34,356] [INFO] [controller] EPOCH 2 loss ppo:  -0.03267, loss val: 0.10173
[2022-12-07 02:45:34,421] [INFO] [controller] EPOCH 3 loss ppo:  -0.04585, loss val: 0.09791
[2022-12-07 02:45:34,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.05402, loss val: 0.09293
[2022-12-07 02:45:34,499] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:45:34,717] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:45:34,718] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:45:42,216] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:45:48,983] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:45:55,967] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:46:02,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:46:09,776] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:46:16,871] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:46:23,621] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:46:30,581] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:46:37,193] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:46:44,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39218794786506217
[2022-12-07 02:46:44,415] [INFO] [runner_train_mujoco] Average state value: 0.635802068332831
[2022-12-07 02:46:44,415] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 02:46:44,486] [INFO] [controller] EPOCH 1 loss ppo:  -0.01126, loss val: 0.07983
[2022-12-07 02:46:44,542] [INFO] [controller] EPOCH 2 loss ppo:  -0.03873, loss val: 0.08024
[2022-12-07 02:46:44,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.05089, loss val: 0.07632
[2022-12-07 02:46:44,668] [INFO] [controller] EPOCH 4 loss ppo:  -0.05617, loss val: 0.07365
[2022-12-07 02:46:44,680] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:46:44,881] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:46:44,882] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:46:51,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:46:58,807] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:47:05,310] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:47:11,939] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:47:18,817] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:47:25,714] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:47:32,533] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:47:40,001] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:47:46,551] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:47:53,257] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4793704255879502
[2022-12-07 02:47:53,257] [INFO] [runner_train_mujoco] Average state value: 0.6408466174403827
[2022-12-07 02:47:53,257] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 02:47:53,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01107, loss val: 0.07101
[2022-12-07 02:47:53,368] [INFO] [controller] EPOCH 2 loss ppo:  -0.03313, loss val: 0.06858
[2022-12-07 02:47:53,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.04785, loss val: 0.06807
[2022-12-07 02:47:53,483] [INFO] [controller] EPOCH 4 loss ppo:  -0.05565, loss val: 0.06684
[2022-12-07 02:47:53,493] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:47:53,689] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:47:53,689] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:48:00,483] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:48:07,386] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:48:14,399] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:48:21,471] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:48:27,977] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:48:34,715] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:48:41,281] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:48:48,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:48:55,157] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:49:02,198] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5799146683115695
[2022-12-07 02:49:02,199] [INFO] [runner_train_mujoco] Average state value: 0.6239944551686445
[2022-12-07 02:49:02,199] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 02:49:02,263] [INFO] [controller] EPOCH 1 loss ppo:  -0.01101, loss val: 0.06692
[2022-12-07 02:49:02,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.03020, loss val: 0.06453
[2022-12-07 02:49:02,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.04251, loss val: 0.06146
[2022-12-07 02:49:02,422] [INFO] [controller] EPOCH 4 loss ppo:  -0.05015, loss val: 0.05829
[2022-12-07 02:49:02,432] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:49:02,622] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:49:02,623] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:49:09,620] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:49:16,630] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:49:23,476] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:49:30,205] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:49:37,035] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:49:43,982] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:49:50,467] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:49:57,130] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:50:03,686] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:50:10,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4489603827487761
[2022-12-07 02:50:10,127] [INFO] [runner_train_mujoco] Average state value: 0.5782271842757861
[2022-12-07 02:50:10,127] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 02:50:10,197] [INFO] [controller] EPOCH 1 loss ppo:  -0.01090, loss val: 0.05296
[2022-12-07 02:50:10,247] [INFO] [controller] EPOCH 2 loss ppo:  -0.02600, loss val: 0.04924
[2022-12-07 02:50:10,300] [INFO] [controller] EPOCH 3 loss ppo:  -0.03900, loss val: 0.04700
[2022-12-07 02:50:10,346] [INFO] [controller] EPOCH 4 loss ppo:  -0.05159, loss val: 0.04528
[2022-12-07 02:50:10,356] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:50:10,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:50:10,551] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:50:17,249] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:50:24,079] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:50:30,608] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:50:37,121] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:50:44,061] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:50:50,832] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:50:57,790] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:51:04,595] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:51:11,529] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:51:17,965] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.38008479273572404
[2022-12-07 02:51:17,965] [INFO] [runner_train_mujoco] Average state value: 0.5004414345274368
[2022-12-07 02:51:17,965] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 02:51:18,020] [INFO] [controller] EPOCH 1 loss ppo:  -0.01037, loss val: 0.05441
[2022-12-07 02:51:18,067] [INFO] [controller] EPOCH 2 loss ppo:  -0.02960, loss val: 0.05433
[2022-12-07 02:51:18,114] [INFO] [controller] EPOCH 3 loss ppo:  -0.04288, loss val: 0.05620
[2022-12-07 02:51:18,168] [INFO] [controller] EPOCH 4 loss ppo:  -0.05388, loss val: 0.05451
[2022-12-07 02:51:18,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:51:18,373] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:51:18,373] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:51:25,245] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:51:31,902] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:51:38,996] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:51:45,459] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:51:52,340] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:51:59,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:52:05,881] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:52:12,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:52:19,411] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:52:26,392] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5510521543731646
[2022-12-07 02:52:26,392] [INFO] [runner_train_mujoco] Average state value: 0.5065951205814879
[2022-12-07 02:52:26,392] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 02:52:26,469] [INFO] [controller] EPOCH 1 loss ppo:  -0.01068, loss val: 0.06238
[2022-12-07 02:52:26,518] [INFO] [controller] EPOCH 2 loss ppo:  -0.02835, loss val: 0.05991
[2022-12-07 02:52:26,570] [INFO] [controller] EPOCH 3 loss ppo:  -0.03835, loss val: 0.05539
[2022-12-07 02:52:26,622] [INFO] [controller] EPOCH 4 loss ppo:  -0.04851, loss val: 0.05217
[2022-12-07 02:52:26,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:52:26,824] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:52:26,826] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:52:33,893] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:52:40,824] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:52:47,863] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:52:54,365] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:53:01,352] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:53:08,322] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:53:15,375] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:53:22,376] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:53:28,958] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:53:35,735] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6720578305617353
[2022-12-07 02:53:35,735] [INFO] [runner_train_mujoco] Average state value: 0.5989532167216142
[2022-12-07 02:53:35,735] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 02:53:35,802] [INFO] [controller] EPOCH 1 loss ppo:  -0.01013, loss val: 0.04520
[2022-12-07 02:53:35,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.03573, loss val: 0.04664
[2022-12-07 02:53:35,953] [INFO] [controller] EPOCH 3 loss ppo:  -0.05061, loss val: 0.04712
[2022-12-07 02:53:36,015] [INFO] [controller] EPOCH 4 loss ppo:  -0.06127, loss val: 0.04562
[2022-12-07 02:53:36,026] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:53:36,229] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:53:36,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:53:42,946] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:53:49,767] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:53:56,644] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:54:03,237] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:54:10,001] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:54:16,971] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:54:23,792] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:54:30,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:54:37,190] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:54:43,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5099615430328076
[2022-12-07 02:54:43,315] [INFO] [runner_train_mujoco] Average state value: 0.6146223958134651
[2022-12-07 02:54:43,315] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 02:54:43,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01173, loss val: 0.04554
[2022-12-07 02:54:43,421] [INFO] [controller] EPOCH 2 loss ppo:  -0.03395, loss val: 0.04521
[2022-12-07 02:54:43,471] [INFO] [controller] EPOCH 3 loss ppo:  -0.04713, loss val: 0.04347
[2022-12-07 02:54:43,522] [INFO] [controller] EPOCH 4 loss ppo:  -0.05712, loss val: 0.04281
[2022-12-07 02:54:43,531] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:54:43,739] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:54:43,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:54:50,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:54:56,909] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:55:03,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:55:10,289] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:55:17,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:55:24,072] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:55:30,743] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:55:37,482] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:55:44,143] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:55:50,221] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7861753857373005
[2022-12-07 02:55:50,221] [INFO] [runner_train_mujoco] Average state value: 0.5613935693899791
[2022-12-07 02:55:50,221] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 02:55:50,277] [INFO] [controller] EPOCH 1 loss ppo:  -0.01089, loss val: 0.05339
[2022-12-07 02:55:50,324] [INFO] [controller] EPOCH 2 loss ppo:  -0.03029, loss val: 0.05135
[2022-12-07 02:55:50,377] [INFO] [controller] EPOCH 3 loss ppo:  -0.04253, loss val: 0.05271
[2022-12-07 02:55:50,425] [INFO] [controller] EPOCH 4 loss ppo:  -0.05025, loss val: 0.04941
[2022-12-07 02:55:50,435] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:55:50,634] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:55:50,635] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:55:57,348] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:56:04,200] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:56:10,988] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:56:17,713] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:56:24,115] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:56:32,416] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:56:39,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:56:46,139] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:56:52,830] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:56:59,648] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8863969321051929
[2022-12-07 02:56:59,649] [INFO] [runner_train_mujoco] Average state value: 0.5901807380716007
[2022-12-07 02:56:59,649] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 02:56:59,715] [INFO] [controller] EPOCH 1 loss ppo:  -0.00970, loss val: 0.04461
[2022-12-07 02:56:59,788] [INFO] [controller] EPOCH 2 loss ppo:  -0.03217, loss val: 0.04286
[2022-12-07 02:56:59,844] [INFO] [controller] EPOCH 3 loss ppo:  -0.04656, loss val: 0.04403
[2022-12-07 02:56:59,925] [INFO] [controller] EPOCH 4 loss ppo:  -0.05209, loss val: 0.04118
[2022-12-07 02:56:59,935] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:57:00,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:57:00,147] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:57:06,902] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:57:13,630] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:57:21,354] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:57:28,066] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:57:34,771] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:57:42,263] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:57:48,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:57:55,460] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:58:02,075] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:58:09,040] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.900533228060336
[2022-12-07 02:58:09,040] [INFO] [runner_train_mujoco] Average state value: 0.6245208339889844
[2022-12-07 02:58:09,040] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 02:58:09,097] [INFO] [controller] EPOCH 1 loss ppo:  -0.01034, loss val: 0.04467
[2022-12-07 02:58:09,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.03972, loss val: 0.04332
[2022-12-07 02:58:09,198] [INFO] [controller] EPOCH 3 loss ppo:  -0.05097, loss val: 0.04462
[2022-12-07 02:58:09,245] [INFO] [controller] EPOCH 4 loss ppo:  -0.05711, loss val: 0.04295
[2022-12-07 02:58:09,255] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:58:09,455] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:58:09,455] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:58:16,254] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:58:23,257] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:58:29,661] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:58:36,582] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:58:43,339] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:58:50,078] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 02:58:56,492] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 02:59:03,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 02:59:09,572] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 02:59:15,890] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1616816297934622
[2022-12-07 02:59:15,890] [INFO] [runner_train_mujoco] Average state value: 0.6122347077926
[2022-12-07 02:59:15,890] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 02:59:15,955] [INFO] [controller] EPOCH 1 loss ppo:  -0.01227, loss val: 0.04699
[2022-12-07 02:59:15,999] [INFO] [controller] EPOCH 2 loss ppo:  -0.03252, loss val: 0.04783
[2022-12-07 02:59:16,048] [INFO] [controller] EPOCH 3 loss ppo:  -0.04417, loss val: 0.04769
[2022-12-07 02:59:16,121] [INFO] [controller] EPOCH 4 loss ppo:  -0.05237, loss val: 0.04645
[2022-12-07 02:59:16,132] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 02:59:16,323] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 02:59:16,324] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 02:59:22,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 02:59:29,509] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 02:59:36,123] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 02:59:42,922] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 02:59:49,412] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 02:59:56,018] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:00:02,928] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:00:09,527] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:00:16,409] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:00:23,020] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3201242814012493
[2022-12-07 03:00:23,020] [INFO] [runner_train_mujoco] Average state value: 0.5959427601297697
[2022-12-07 03:00:23,020] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 03:00:23,083] [INFO] [controller] EPOCH 1 loss ppo:  -0.01482, loss val: 0.04097
[2022-12-07 03:00:23,127] [INFO] [controller] EPOCH 2 loss ppo:  -0.03727, loss val: 0.04050
[2022-12-07 03:00:23,174] [INFO] [controller] EPOCH 3 loss ppo:  -0.04914, loss val: 0.03940
[2022-12-07 03:00:23,217] [INFO] [controller] EPOCH 4 loss ppo:  -0.06013, loss val: 0.03798
[2022-12-07 03:00:23,227] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:00:23,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:00:23,422] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:00:29,998] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:00:36,832] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:00:43,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:00:50,162] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:00:56,524] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:01:03,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:01:09,643] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:01:16,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:01:23,238] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:01:30,200] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3022101088271252
[2022-12-07 03:01:30,201] [INFO] [runner_train_mujoco] Average state value: 0.5612324040035407
[2022-12-07 03:01:30,201] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 03:01:30,264] [INFO] [controller] EPOCH 1 loss ppo:  -0.01199, loss val: 0.03845
[2022-12-07 03:01:30,321] [INFO] [controller] EPOCH 2 loss ppo:  -0.03044, loss val: 0.03567
[2022-12-07 03:01:30,374] [INFO] [controller] EPOCH 3 loss ppo:  -0.04530, loss val: 0.03379
[2022-12-07 03:01:30,428] [INFO] [controller] EPOCH 4 loss ppo:  -0.05502, loss val: 0.03185
[2022-12-07 03:01:30,440] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:01:30,637] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:01:30,639] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:01:37,439] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:01:44,064] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:01:51,089] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:01:57,311] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:02:03,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:02:10,022] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:02:16,648] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:02:23,081] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:02:29,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:02:36,739] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5703755912744806
[2022-12-07 03:02:36,739] [INFO] [runner_train_mujoco] Average state value: 0.4890484800338745
[2022-12-07 03:02:36,739] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 03:02:36,802] [INFO] [controller] EPOCH 1 loss ppo:  -0.01457, loss val: 0.03763
[2022-12-07 03:02:36,858] [INFO] [controller] EPOCH 2 loss ppo:  -0.03892, loss val: 0.03834
[2022-12-07 03:02:36,920] [INFO] [controller] EPOCH 3 loss ppo:  -0.05049, loss val: 0.03859
[2022-12-07 03:02:36,978] [INFO] [controller] EPOCH 4 loss ppo:  -0.05934, loss val: 0.03875
[2022-12-07 03:02:36,989] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:02:37,189] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:02:37,189] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:02:43,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:02:50,707] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:02:57,359] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:03:04,182] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:03:10,981] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:03:17,424] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:03:24,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:03:30,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:03:37,756] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:03:44,390] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9453927708189642
[2022-12-07 03:03:44,391] [INFO] [runner_train_mujoco] Average state value: 0.47300193776686983
[2022-12-07 03:03:44,391] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 03:03:44,453] [INFO] [controller] EPOCH 1 loss ppo:  -0.01664, loss val: 0.05540
[2022-12-07 03:03:44,505] [INFO] [controller] EPOCH 2 loss ppo:  -0.03261, loss val: 0.05264
[2022-12-07 03:03:44,555] [INFO] [controller] EPOCH 3 loss ppo:  -0.04100, loss val: 0.04974
[2022-12-07 03:03:44,707] [INFO] [controller] EPOCH 4 loss ppo:  -0.05154, loss val: 0.04659
[2022-12-07 03:03:44,717] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:03:44,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:03:44,912] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:03:51,803] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:03:58,396] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:04:04,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:04:11,672] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:04:17,991] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:04:24,971] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:04:31,859] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:04:38,735] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:04:45,498] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:04:52,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9194373594508156
[2022-12-07 03:04:52,420] [INFO] [runner_train_mujoco] Average state value: 0.5446595781048139
[2022-12-07 03:04:52,420] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 03:04:52,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01339, loss val: 0.04567
[2022-12-07 03:04:52,541] [INFO] [controller] EPOCH 2 loss ppo:  -0.03166, loss val: 0.04760
[2022-12-07 03:04:52,609] [INFO] [controller] EPOCH 3 loss ppo:  -0.04362, loss val: 0.04733
[2022-12-07 03:04:52,663] [INFO] [controller] EPOCH 4 loss ppo:  -0.05474, loss val: 0.04701
[2022-12-07 03:04:52,679] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:04:52,927] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:04:52,928] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:04:59,244] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:05:05,647] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:05:12,183] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:05:18,567] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:05:25,305] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:05:31,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:05:38,721] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:05:45,682] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:05:52,380] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:05:58,980] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.167087573582669
[2022-12-07 03:05:58,980] [INFO] [runner_train_mujoco] Average state value: 0.5673047354221343
[2022-12-07 03:05:58,980] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 03:05:59,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.04145
[2022-12-07 03:05:59,095] [INFO] [controller] EPOCH 2 loss ppo:  -0.03709, loss val: 0.04041
[2022-12-07 03:05:59,149] [INFO] [controller] EPOCH 3 loss ppo:  -0.04990, loss val: 0.04114
[2022-12-07 03:05:59,211] [INFO] [controller] EPOCH 4 loss ppo:  -0.05889, loss val: 0.03883
[2022-12-07 03:05:59,221] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:05:59,433] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:05:59,433] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:06:06,199] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:06:13,082] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:06:19,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:06:26,187] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:06:33,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:06:40,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:06:46,608] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:06:52,694] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:06:59,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:07:07,389] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0627646986600494
[2022-12-07 03:07:07,389] [INFO] [runner_train_mujoco] Average state value: 0.5394733269413312
[2022-12-07 03:07:07,390] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 03:07:07,476] [INFO] [controller] EPOCH 1 loss ppo:  -0.01477, loss val: 0.04014
[2022-12-07 03:07:07,534] [INFO] [controller] EPOCH 2 loss ppo:  -0.03654, loss val: 0.03987
[2022-12-07 03:07:07,591] [INFO] [controller] EPOCH 3 loss ppo:  -0.04647, loss val: 0.04023
[2022-12-07 03:07:07,649] [INFO] [controller] EPOCH 4 loss ppo:  -0.05783, loss val: 0.04011
[2022-12-07 03:07:07,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:07:07,855] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:07:07,856] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:07:15,376] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:07:22,562] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:07:29,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:07:36,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:07:42,631] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:07:49,091] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:07:56,273] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:08:02,917] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:08:09,845] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:08:16,258] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.620430033206538
[2022-12-07 03:08:16,259] [INFO] [runner_train_mujoco] Average state value: 0.5160982427497705
[2022-12-07 03:08:16,259] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 03:08:16,311] [INFO] [controller] EPOCH 1 loss ppo:  -0.01473, loss val: 0.04740
[2022-12-07 03:08:16,354] [INFO] [controller] EPOCH 2 loss ppo:  -0.03691, loss val: 0.04510
[2022-12-07 03:08:16,398] [INFO] [controller] EPOCH 3 loss ppo:  -0.04565, loss val: 0.04556
[2022-12-07 03:08:16,443] [INFO] [controller] EPOCH 4 loss ppo:  -0.05861, loss val: 0.04360
[2022-12-07 03:08:16,452] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:08:16,651] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:08:16,652] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:08:23,205] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:08:29,952] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:08:36,479] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:08:42,686] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:08:49,020] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:08:55,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:09:02,438] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:09:09,362] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:09:16,309] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:09:22,878] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.506434218424517
[2022-12-07 03:09:22,878] [INFO] [runner_train_mujoco] Average state value: 0.5413709462384382
[2022-12-07 03:09:22,878] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 03:09:22,936] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.03885
[2022-12-07 03:09:22,988] [INFO] [controller] EPOCH 2 loss ppo:  -0.03250, loss val: 0.03909
[2022-12-07 03:09:23,034] [INFO] [controller] EPOCH 3 loss ppo:  -0.04798, loss val: 0.03931
[2022-12-07 03:09:23,083] [INFO] [controller] EPOCH 4 loss ppo:  -0.05956, loss val: 0.03932
[2022-12-07 03:09:23,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:09:23,280] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:09:23,280] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:09:29,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:09:36,673] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:09:42,779] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:09:49,229] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:09:55,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:10:02,622] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:10:09,748] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:10:16,521] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:10:23,114] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:10:29,421] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8459765303599562
[2022-12-07 03:10:29,421] [INFO] [runner_train_mujoco] Average state value: 0.5612484214504561
[2022-12-07 03:10:29,422] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 03:10:29,487] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.04411
[2022-12-07 03:10:29,545] [INFO] [controller] EPOCH 2 loss ppo:  -0.03318, loss val: 0.04411
[2022-12-07 03:10:29,610] [INFO] [controller] EPOCH 3 loss ppo:  -0.04659, loss val: 0.04374
[2022-12-07 03:10:29,661] [INFO] [controller] EPOCH 4 loss ppo:  -0.06036, loss val: 0.04352
[2022-12-07 03:10:29,670] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:10:29,865] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:10:29,865] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:10:36,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:10:42,730] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:10:49,241] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:10:55,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:11:02,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:11:08,933] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:11:15,535] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:11:21,590] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:11:28,140] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:11:34,557] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.924360691825322
[2022-12-07 03:11:34,557] [INFO] [runner_train_mujoco] Average state value: 0.5437085102299849
[2022-12-07 03:11:34,557] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 03:11:34,613] [INFO] [controller] EPOCH 1 loss ppo:  -0.01511, loss val: 0.04100
[2022-12-07 03:11:34,657] [INFO] [controller] EPOCH 2 loss ppo:  -0.03383, loss val: 0.04121
[2022-12-07 03:11:34,703] [INFO] [controller] EPOCH 3 loss ppo:  -0.04559, loss val: 0.04141
[2022-12-07 03:11:34,766] [INFO] [controller] EPOCH 4 loss ppo:  -0.05758, loss val: 0.04183
[2022-12-07 03:11:34,776] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:11:34,966] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:11:34,967] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:11:41,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:11:48,395] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:11:55,240] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:12:01,662] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:12:07,915] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:12:14,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:12:20,627] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:12:27,462] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:12:34,136] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:12:40,738] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1238246929867506
[2022-12-07 03:12:40,738] [INFO] [runner_train_mujoco] Average state value: 0.5326404163042705
[2022-12-07 03:12:40,738] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 03:12:40,796] [INFO] [controller] EPOCH 1 loss ppo:  -0.01573, loss val: 0.04197
[2022-12-07 03:12:40,917] [INFO] [controller] EPOCH 2 loss ppo:  -0.03431, loss val: 0.04180
[2022-12-07 03:12:40,966] [INFO] [controller] EPOCH 3 loss ppo:  -0.04954, loss val: 0.04166
[2022-12-07 03:12:41,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.06256, loss val: 0.05182
[2022-12-07 03:12:41,039] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:12:41,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:12:41,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:12:47,658] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:12:54,091] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:13:00,354] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:13:06,843] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:13:13,157] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:13:19,863] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:13:26,304] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:13:33,283] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:13:39,971] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:13:46,278] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.188794021480551
[2022-12-07 03:13:46,278] [INFO] [runner_train_mujoco] Average state value: 0.5426104874908924
[2022-12-07 03:13:46,278] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 03:13:46,345] [INFO] [controller] EPOCH 1 loss ppo:  -0.01497, loss val: 0.04361
[2022-12-07 03:13:46,400] [INFO] [controller] EPOCH 2 loss ppo:  -0.03469, loss val: 0.04435
[2022-12-07 03:13:46,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.04679, loss val: 0.04432
[2022-12-07 03:13:46,496] [INFO] [controller] EPOCH 4 loss ppo:  -0.05848, loss val: 0.04235
[2022-12-07 03:13:46,507] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:13:46,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:13:46,712] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:13:52,841] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:13:59,416] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:14:06,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:14:12,629] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:14:19,282] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:14:25,638] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:14:32,096] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:14:38,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:14:44,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:14:51,044] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.2822233567690504
[2022-12-07 03:14:51,044] [INFO] [runner_train_mujoco] Average state value: 0.5627760118941467
[2022-12-07 03:14:51,044] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 03:14:51,098] [INFO] [controller] EPOCH 1 loss ppo:  -0.01613, loss val: 0.03972
[2022-12-07 03:14:51,142] [INFO] [controller] EPOCH 2 loss ppo:  -0.03300, loss val: 0.03727
[2022-12-07 03:14:51,186] [INFO] [controller] EPOCH 3 loss ppo:  -0.04510, loss val: 0.03684
[2022-12-07 03:14:51,234] [INFO] [controller] EPOCH 4 loss ppo:  -0.05709, loss val: 0.03939
[2022-12-07 03:14:51,243] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:14:51,428] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:14:51,428] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:14:57,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:15:04,205] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:15:10,841] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:15:17,506] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:15:24,033] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:15:30,717] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:15:37,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:15:44,164] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:15:50,561] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:15:57,150] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6780032409940295
[2022-12-07 03:15:57,150] [INFO] [runner_train_mujoco] Average state value: 0.5603182417551678
[2022-12-07 03:15:57,150] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 03:15:57,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01729, loss val: 0.04903
[2022-12-07 03:15:57,259] [INFO] [controller] EPOCH 2 loss ppo:  -0.03373, loss val: 0.05251
[2022-12-07 03:15:57,307] [INFO] [controller] EPOCH 3 loss ppo:  -0.04571, loss val: 0.05194
[2022-12-07 03:15:57,355] [INFO] [controller] EPOCH 4 loss ppo:  -0.05542, loss val: 0.04946
[2022-12-07 03:15:57,364] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:15:57,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:15:57,552] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:16:03,999] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:16:10,682] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:16:16,009] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:16:22,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:16:27,567] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:16:33,052] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:16:38,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:16:44,345] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:16:50,481] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:16:56,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.622253197516018
[2022-12-07 03:16:56,091] [INFO] [runner_train_mujoco] Average state value: 0.559377277970314
[2022-12-07 03:16:56,091] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 03:16:56,146] [INFO] [controller] EPOCH 1 loss ppo:  -0.01787, loss val: 0.04649
[2022-12-07 03:16:56,187] [INFO] [controller] EPOCH 2 loss ppo:  -0.03300, loss val: 0.04638
[2022-12-07 03:16:56,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.04394, loss val: 0.04677
[2022-12-07 03:16:56,288] [INFO] [controller] EPOCH 4 loss ppo:  -0.05590, loss val: 0.04729
[2022-12-07 03:16:56,294] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:16:56,473] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:16:56,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:17:02,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:17:08,612] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:17:14,337] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:17:20,117] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:17:25,509] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:17:31,157] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:17:37,113] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:17:42,831] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:17:48,721] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:17:54,554] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.026498574742094
[2022-12-07 03:17:54,554] [INFO] [runner_train_mujoco] Average state value: 0.5612150263984998
[2022-12-07 03:17:54,554] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 03:17:54,606] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.04815
[2022-12-07 03:17:54,650] [INFO] [controller] EPOCH 2 loss ppo:  -0.02870, loss val: 0.04817
[2022-12-07 03:17:54,694] [INFO] [controller] EPOCH 3 loss ppo:  -0.04080, loss val: 0.04810
[2022-12-07 03:17:54,738] [INFO] [controller] EPOCH 4 loss ppo:  -0.05315, loss val: 0.04802
[2022-12-07 03:17:54,748] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:17:54,934] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:17:54,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:18:00,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:18:06,277] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:18:12,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:18:18,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:18:24,488] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:18:30,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:18:35,889] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:18:41,787] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:18:47,273] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:18:52,895] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8383239791677646
[2022-12-07 03:18:52,895] [INFO] [runner_train_mujoco] Average state value: 0.5511137512922287
[2022-12-07 03:18:52,895] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 03:18:52,948] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.04704
[2022-12-07 03:18:52,993] [INFO] [controller] EPOCH 2 loss ppo:  -0.02724, loss val: 0.04671
[2022-12-07 03:18:53,037] [INFO] [controller] EPOCH 3 loss ppo:  -0.04125, loss val: 0.04745
[2022-12-07 03:18:53,080] [INFO] [controller] EPOCH 4 loss ppo:  -0.05224, loss val: 0.04732
[2022-12-07 03:18:53,088] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:18:53,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:18:53,268] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:18:59,152] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:19:05,070] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:19:11,019] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:19:16,622] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:19:22,307] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:19:28,116] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:19:34,035] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:19:40,035] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:19:45,799] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:19:51,935] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.1416023438428535
[2022-12-07 03:19:51,936] [INFO] [runner_train_mujoco] Average state value: 0.5461462443172931
[2022-12-07 03:19:51,936] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 03:19:51,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04475
[2022-12-07 03:19:52,029] [INFO] [controller] EPOCH 2 loss ppo:  -0.02768, loss val: 0.04389
[2022-12-07 03:19:52,074] [INFO] [controller] EPOCH 3 loss ppo:  -0.03798, loss val: 0.04354
[2022-12-07 03:19:52,120] [INFO] [controller] EPOCH 4 loss ppo:  -0.04990, loss val: 0.04341
[2022-12-07 03:19:52,131] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:19:52,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:19:52,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:19:58,280] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:20:04,262] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:20:10,004] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:20:15,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:20:21,410] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:20:26,934] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:20:32,636] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:20:38,133] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:20:44,021] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:20:49,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.297920704446004
[2022-12-07 03:20:49,824] [INFO] [runner_train_mujoco] Average state value: 0.5285591892401378
[2022-12-07 03:20:49,824] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 03:20:49,875] [INFO] [controller] EPOCH 1 loss ppo:  -0.01710, loss val: 0.04717
[2022-12-07 03:20:49,914] [INFO] [controller] EPOCH 2 loss ppo:  -0.03335, loss val: 0.04496
[2022-12-07 03:20:49,957] [INFO] [controller] EPOCH 3 loss ppo:  -0.04483, loss val: 0.04461
[2022-12-07 03:20:50,002] [INFO] [controller] EPOCH 4 loss ppo:  -0.05720, loss val: 0.04394
[2022-12-07 03:20:50,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:20:50,194] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:20:50,194] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:20:56,114] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:21:02,310] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:21:08,402] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:21:14,239] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:21:19,732] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:21:25,376] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:21:30,941] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:21:36,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:21:42,201] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:21:47,964] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.31242119745186
[2022-12-07 03:21:47,964] [INFO] [runner_train_mujoco] Average state value: 0.49325534406304355
[2022-12-07 03:21:47,964] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 03:21:48,021] [INFO] [controller] EPOCH 1 loss ppo:  -0.01578, loss val: 0.05157
[2022-12-07 03:21:48,063] [INFO] [controller] EPOCH 2 loss ppo:  -0.03007, loss val: 0.05287
[2022-12-07 03:21:48,105] [INFO] [controller] EPOCH 3 loss ppo:  -0.04014, loss val: 0.05284
[2022-12-07 03:21:48,145] [INFO] [controller] EPOCH 4 loss ppo:  -0.05068, loss val: 0.05194
[2022-12-07 03:21:48,155] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:21:48,329] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:21:48,329] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:21:54,202] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:22:00,028] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:22:05,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:22:11,386] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:22:16,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:22:22,600] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:22:28,712] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:22:34,274] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:22:40,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:22:45,699] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.289566754973684
[2022-12-07 03:22:45,699] [INFO] [runner_train_mujoco] Average state value: 0.48756665944059685
[2022-12-07 03:22:45,700] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 03:22:45,759] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.05020
[2022-12-07 03:22:45,810] [INFO] [controller] EPOCH 2 loss ppo:  -0.02836, loss val: 0.05025
[2022-12-07 03:22:45,861] [INFO] [controller] EPOCH 3 loss ppo:  -0.03701, loss val: 0.05053
[2022-12-07 03:22:45,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.04856, loss val: 0.05015
[2022-12-07 03:22:45,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:22:46,100] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:22:46,101] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:22:51,666] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:22:57,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:23:03,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:23:09,289] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:23:14,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:23:20,105] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:23:25,671] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:23:31,559] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:23:37,027] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:23:42,944] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.386406191804015
[2022-12-07 03:23:42,945] [INFO] [runner_train_mujoco] Average state value: 0.4914548695286115
[2022-12-07 03:23:42,945] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 03:23:42,997] [INFO] [controller] EPOCH 1 loss ppo:  -0.01663, loss val: 0.04210
[2022-12-07 03:23:43,042] [INFO] [controller] EPOCH 2 loss ppo:  -0.02784, loss val: 0.04211
[2022-12-07 03:23:43,088] [INFO] [controller] EPOCH 3 loss ppo:  -0.03492, loss val: 0.04151
[2022-12-07 03:23:43,138] [INFO] [controller] EPOCH 4 loss ppo:  -0.04697, loss val: 0.04148
[2022-12-07 03:23:43,148] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:23:43,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:23:43,342] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:23:49,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:23:54,631] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:24:00,441] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:24:06,397] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:24:12,111] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:24:17,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:24:23,124] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:24:28,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:24:34,129] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:24:39,323] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.483791318056618
[2022-12-07 03:24:39,323] [INFO] [runner_train_mujoco] Average state value: 0.4990716233750184
[2022-12-07 03:24:39,323] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 03:24:39,372] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.04654
[2022-12-07 03:24:39,415] [INFO] [controller] EPOCH 2 loss ppo:  -0.02734, loss val: 0.04560
[2022-12-07 03:24:39,457] [INFO] [controller] EPOCH 3 loss ppo:  -0.03118, loss val: 0.04494
[2022-12-07 03:24:39,499] [INFO] [controller] EPOCH 4 loss ppo:  -0.04321, loss val: 0.04531
[2022-12-07 03:24:39,509] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:24:39,687] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:24:39,688] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:24:45,284] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:24:51,088] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:24:56,623] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:25:02,331] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:25:08,040] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:25:13,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:25:19,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:25:25,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:25:30,437] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:25:35,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.3796638353240605
[2022-12-07 03:25:35,885] [INFO] [runner_train_mujoco] Average state value: 0.48031071730454766
[2022-12-07 03:25:35,885] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 03:25:35,983] [INFO] [controller] EPOCH 1 loss ppo:  -0.01310, loss val: 0.04005
[2022-12-07 03:25:36,044] [INFO] [controller] EPOCH 2 loss ppo:  -0.02441, loss val: 0.04013
[2022-12-07 03:25:36,095] [INFO] [controller] EPOCH 3 loss ppo:  -0.03662, loss val: 0.03990
[2022-12-07 03:25:36,155] [INFO] [controller] EPOCH 4 loss ppo:  -0.04715, loss val: 0.03942
[2022-12-07 03:25:36,164] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:25:36,364] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:25:36,364] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:25:42,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:25:48,008] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:25:53,487] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:25:59,372] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:26:04,819] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:26:10,535] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:26:15,929] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:26:22,084] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:26:27,598] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:26:33,652] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.594794695871935
[2022-12-07 03:26:33,652] [INFO] [runner_train_mujoco] Average state value: 0.46615982448061316
[2022-12-07 03:26:33,653] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 03:26:33,706] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04727
[2022-12-07 03:26:33,751] [INFO] [controller] EPOCH 2 loss ppo:  -0.02636, loss val: 0.04828
[2022-12-07 03:26:33,793] [INFO] [controller] EPOCH 3 loss ppo:  -0.03586, loss val: 0.04911
[2022-12-07 03:26:33,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.04664, loss val: 0.04800
[2022-12-07 03:26:33,847] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:26:34,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:26:34,033] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:26:40,310] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:26:46,346] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:26:52,085] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:26:57,463] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:27:03,057] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:27:08,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:27:14,095] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:27:20,010] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:27:25,275] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:27:30,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.8303221283934565
[2022-12-07 03:27:30,914] [INFO] [runner_train_mujoco] Average state value: 0.4698153226772944
[2022-12-07 03:27:30,914] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 03:27:30,964] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04538
[2022-12-07 03:27:31,008] [INFO] [controller] EPOCH 2 loss ppo:  -0.02653, loss val: 0.04510
[2022-12-07 03:27:31,053] [INFO] [controller] EPOCH 3 loss ppo:  -0.03481, loss val: 0.04464
[2022-12-07 03:27:31,100] [INFO] [controller] EPOCH 4 loss ppo:  -0.04256, loss val: 0.04561
[2022-12-07 03:27:31,109] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:27:31,274] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:27:31,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:27:36,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:27:42,928] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:27:48,670] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:27:54,437] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:28:00,238] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:28:05,958] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:28:11,960] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:28:17,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:28:23,052] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:28:28,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.859574708022833
[2022-12-07 03:28:28,505] [INFO] [runner_train_mujoco] Average state value: 0.47515002553661667
[2022-12-07 03:28:28,505] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 03:28:28,571] [INFO] [controller] EPOCH 1 loss ppo:  -0.01420, loss val: 0.04300
[2022-12-07 03:28:28,625] [INFO] [controller] EPOCH 2 loss ppo:  -0.02573, loss val: 0.04270
[2022-12-07 03:28:28,679] [INFO] [controller] EPOCH 3 loss ppo:  -0.03369, loss val: 0.04277
[2022-12-07 03:28:28,727] [INFO] [controller] EPOCH 4 loss ppo:  -0.04322, loss val: 0.04170
[2022-12-07 03:28:28,735] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:28:28,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:28:28,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:28:34,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:28:40,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:28:46,302] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:28:52,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:28:57,898] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:29:03,462] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:29:08,954] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:29:14,411] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:29:20,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:29:25,915] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.772486491763582
[2022-12-07 03:29:25,916] [INFO] [runner_train_mujoco] Average state value: 0.48179377173384036
[2022-12-07 03:29:25,916] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 03:29:25,972] [INFO] [controller] EPOCH 1 loss ppo:  -0.01351, loss val: 0.04654
[2022-12-07 03:29:26,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.02318, loss val: 0.04849
[2022-12-07 03:29:26,062] [INFO] [controller] EPOCH 3 loss ppo:  -0.03020, loss val: 0.04848
[2022-12-07 03:29:26,107] [INFO] [controller] EPOCH 4 loss ppo:  -0.04186, loss val: 0.04678
[2022-12-07 03:29:26,114] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:29:26,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:29:26,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:29:31,907] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:29:38,841] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:29:45,226] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:29:51,066] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:29:56,550] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:30:02,178] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:30:07,578] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:30:12,742] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:30:18,814] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:30:24,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.9096175543222325
[2022-12-07 03:30:24,065] [INFO] [runner_train_mujoco] Average state value: 0.4936739472051461
[2022-12-07 03:30:24,065] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 03:30:24,145] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.05438
[2022-12-07 03:30:24,199] [INFO] [controller] EPOCH 2 loss ppo:  -0.02225, loss val: 0.05561
[2022-12-07 03:30:24,241] [INFO] [controller] EPOCH 3 loss ppo:  -0.03165, loss val: 0.05400
[2022-12-07 03:30:24,288] [INFO] [controller] EPOCH 4 loss ppo:  -0.03840, loss val: 0.05393
[2022-12-07 03:30:24,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:30:24,480] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:30:24,481] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:30:30,183] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:30:35,893] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:30:41,806] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:30:47,739] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:30:53,526] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:30:58,866] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:31:04,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:31:10,108] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:31:16,001] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:31:21,526] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.901196510018531
[2022-12-07 03:31:21,526] [INFO] [runner_train_mujoco] Average state value: 0.5105026603341103
[2022-12-07 03:31:21,526] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 03:31:21,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.04931
[2022-12-07 03:31:21,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.02123, loss val: 0.04947
[2022-12-07 03:31:21,665] [INFO] [controller] EPOCH 3 loss ppo:  -0.02893, loss val: 0.04932
[2022-12-07 03:31:21,711] [INFO] [controller] EPOCH 4 loss ppo:  -0.03942, loss val: 0.04908
[2022-12-07 03:31:21,721] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:31:21,893] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:31:21,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:31:26,993] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:31:32,307] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:31:37,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:31:43,369] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:31:49,154] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:31:54,838] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:32:00,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:32:05,936] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:32:11,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:32:17,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.014123676055175
[2022-12-07 03:32:17,052] [INFO] [runner_train_mujoco] Average state value: 0.5156694789230823
[2022-12-07 03:32:17,052] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 03:32:17,111] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04740
[2022-12-07 03:32:17,156] [INFO] [controller] EPOCH 2 loss ppo:  -0.02226, loss val: 0.05072
[2022-12-07 03:32:17,203] [INFO] [controller] EPOCH 3 loss ppo:  -0.03557, loss val: 0.04721
[2022-12-07 03:32:17,246] [INFO] [controller] EPOCH 4 loss ppo:  -0.04168, loss val: 0.04995
[2022-12-07 03:32:17,255] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:32:17,441] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:32:17,441] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:32:23,213] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:32:28,616] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:32:34,749] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:32:40,485] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:32:46,366] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:32:51,608] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:32:57,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:33:02,582] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:33:07,933] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:33:13,419] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.259822159803699
[2022-12-07 03:33:13,419] [INFO] [runner_train_mujoco] Average state value: 0.5089433902700742
[2022-12-07 03:33:13,420] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 03:33:13,478] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04934
[2022-12-07 03:33:13,521] [INFO] [controller] EPOCH 2 loss ppo:  -0.02167, loss val: 0.04849
[2022-12-07 03:33:13,575] [INFO] [controller] EPOCH 3 loss ppo:  -0.03007, loss val: 0.04986
[2022-12-07 03:33:13,621] [INFO] [controller] EPOCH 4 loss ppo:  -0.03732, loss val: 0.04944
[2022-12-07 03:33:13,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:33:13,808] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:33:13,808] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:33:20,655] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:33:27,068] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:33:34,745] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:33:41,371] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:33:47,742] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:33:53,953] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:34:00,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:34:06,093] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:34:12,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:34:18,216] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.173399528042512
[2022-12-07 03:34:18,216] [INFO] [runner_train_mujoco] Average state value: 0.49848761537671094
[2022-12-07 03:34:18,216] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 03:34:18,300] [INFO] [controller] EPOCH 1 loss ppo:  -0.01492, loss val: 0.04708
[2022-12-07 03:34:18,358] [INFO] [controller] EPOCH 2 loss ppo:  -0.02616, loss val: 0.04690
[2022-12-07 03:34:18,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.03004, loss val: 0.04728
[2022-12-07 03:34:18,452] [INFO] [controller] EPOCH 4 loss ppo:  -0.03767, loss val: 0.04813
[2022-12-07 03:34:18,462] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:34:18,650] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:34:18,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:34:24,860] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:34:31,032] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:34:37,430] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:34:44,067] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:34:50,598] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:34:56,968] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:35:03,188] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:35:09,204] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:35:15,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:35:21,655] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.570114523783198
[2022-12-07 03:35:21,655] [INFO] [runner_train_mujoco] Average state value: 0.48573851754268016
[2022-12-07 03:35:21,655] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 03:35:21,717] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.05653
[2022-12-07 03:35:21,766] [INFO] [controller] EPOCH 2 loss ppo:  -0.02053, loss val: 0.05674
[2022-12-07 03:35:21,815] [INFO] [controller] EPOCH 3 loss ppo:  -0.02573, loss val: 0.05546
[2022-12-07 03:35:21,865] [INFO] [controller] EPOCH 4 loss ppo:  -0.03410, loss val: 0.05552
[2022-12-07 03:35:21,877] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:35:22,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:35:22,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:35:27,988] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:35:34,193] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:35:40,462] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:35:46,966] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:35:53,253] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:35:59,173] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:36:05,091] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:36:10,879] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:36:16,765] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:36:22,770] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.360113163061236
[2022-12-07 03:36:22,770] [INFO] [runner_train_mujoco] Average state value: 0.4788863777915638
[2022-12-07 03:36:22,770] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 03:36:22,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.03906
[2022-12-07 03:36:22,872] [INFO] [controller] EPOCH 2 loss ppo:  -0.01900, loss val: 0.04162
[2022-12-07 03:36:22,920] [INFO] [controller] EPOCH 3 loss ppo:  -0.02444, loss val: 0.03903
[2022-12-07 03:36:22,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.03398, loss val: 0.04011
[2022-12-07 03:36:22,977] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:36:23,161] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:36:23,161] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:36:29,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:36:35,142] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:36:41,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:36:47,871] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:36:53,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:37:00,127] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:37:06,320] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:37:12,438] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:37:18,373] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:37:24,002] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.169431018260103
[2022-12-07 03:37:24,003] [INFO] [runner_train_mujoco] Average state value: 0.4713945693274339
[2022-12-07 03:37:24,003] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 03:37:24,067] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04252
[2022-12-07 03:37:24,140] [INFO] [controller] EPOCH 2 loss ppo:  -0.01728, loss val: 0.04122
[2022-12-07 03:37:24,211] [INFO] [controller] EPOCH 3 loss ppo:  -0.02375, loss val: 0.04123
[2022-12-07 03:37:24,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.03270, loss val: 0.04120
[2022-12-07 03:37:24,280] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:37:24,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:37:24,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:37:30,586] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:37:36,569] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:37:42,592] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:37:48,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:37:55,391] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:38:01,633] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:38:07,332] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:38:13,347] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:38:19,468] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:38:25,549] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.756215470870475
[2022-12-07 03:38:25,550] [INFO] [runner_train_mujoco] Average state value: 0.47403457815448446
[2022-12-07 03:38:25,550] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 03:38:25,614] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04676
[2022-12-07 03:38:25,661] [INFO] [controller] EPOCH 2 loss ppo:  -0.01717, loss val: 0.04762
[2022-12-07 03:38:25,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.02220, loss val: 0.04653
[2022-12-07 03:38:25,777] [INFO] [controller] EPOCH 4 loss ppo:  -0.02813, loss val: 0.04631
[2022-12-07 03:38:25,788] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:38:25,988] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:38:25,988] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:38:31,989] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:38:37,881] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:38:43,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:38:49,722] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:38:55,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:39:01,591] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:39:07,530] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:39:13,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:39:19,521] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:39:25,633] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.386680348312231
[2022-12-07 03:39:25,633] [INFO] [runner_train_mujoco] Average state value: 0.4770061712861061
[2022-12-07 03:39:25,633] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 03:39:25,689] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.04508
[2022-12-07 03:39:25,738] [INFO] [controller] EPOCH 2 loss ppo:  -0.01935, loss val: 0.04639
[2022-12-07 03:39:25,784] [INFO] [controller] EPOCH 3 loss ppo:  -0.02510, loss val: 0.04519
[2022-12-07 03:39:25,842] [INFO] [controller] EPOCH 4 loss ppo:  -0.02935, loss val: 0.04543
[2022-12-07 03:39:25,852] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:39:26,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:39:26,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:39:32,089] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:39:38,306] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:39:44,289] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:39:50,658] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:39:56,971] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:40:03,237] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:40:09,274] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:40:15,080] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:40:21,279] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:40:27,289] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.674173420085298
[2022-12-07 03:40:27,289] [INFO] [runner_train_mujoco] Average state value: 0.48496455470720923
[2022-12-07 03:40:27,289] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 03:40:27,353] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04909
[2022-12-07 03:40:27,402] [INFO] [controller] EPOCH 2 loss ppo:  -0.01667, loss val: 0.04882
[2022-12-07 03:40:27,448] [INFO] [controller] EPOCH 3 loss ppo:  -0.02227, loss val: 0.04953
[2022-12-07 03:40:27,493] [INFO] [controller] EPOCH 4 loss ppo:  -0.02611, loss val: 0.04929
[2022-12-07 03:40:27,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:40:27,688] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:40:27,688] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:40:33,823] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:40:39,951] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:40:46,005] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:40:52,308] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:40:58,515] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:41:04,618] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:41:10,796] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:41:17,015] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:41:23,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:41:28,816] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.605816112032327
[2022-12-07 03:41:28,816] [INFO] [runner_train_mujoco] Average state value: 0.49011789832512537
[2022-12-07 03:41:28,816] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 03:41:28,880] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.04318
[2022-12-07 03:41:28,928] [INFO] [controller] EPOCH 2 loss ppo:  -0.01470, loss val: 0.04362
[2022-12-07 03:41:29,057] [INFO] [controller] EPOCH 3 loss ppo:  -0.01707, loss val: 0.04520
[2022-12-07 03:41:29,109] [INFO] [controller] EPOCH 4 loss ppo:  -0.02060, loss val: 0.04554
[2022-12-07 03:41:29,119] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:41:29,305] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 03:41:29,306] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 03:41:35,206] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 03:41:41,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 03:41:47,408] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 03:41:53,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 03:41:59,343] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 03:42:05,582] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 03:42:11,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 03:42:17,787] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 03:42:23,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 03:42:29,318] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.67001048694803
[2022-12-07 03:42:29,318] [INFO] [runner_train_mujoco] Average state value: 0.4948752563198407
[2022-12-07 03:42:29,318] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 03:42:29,375] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04320
[2022-12-07 03:42:29,420] [INFO] [controller] EPOCH 2 loss ppo:  -0.01492, loss val: 0.04461
[2022-12-07 03:42:29,465] [INFO] [controller] EPOCH 3 loss ppo:  -0.01677, loss val: 0.04582
[2022-12-07 03:42:29,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.01928, loss val: 0.04367
[2022-12-07 03:42:29,522] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 03:42:29,643] [INFO] [optimize] Finished learning.
