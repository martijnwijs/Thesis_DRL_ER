[2022-12-06 16:02:26,676] [INFO] [optimize] Starting learning
[2022-12-06 16:02:26,687] [INFO] [optimize] Starting learning process..
[2022-12-06 16:02:26,784] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:02:26,785] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:02:36,996] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:02:46,226] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:02:55,761] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:03:03,695] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:03:11,880] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:03:19,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:03:27,896] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:03:36,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:03:45,083] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:03:53,334] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4123322246037577
[2022-12-06 16:03:53,334] [INFO] [runner_train_mujoco] Average state value: -0.06833304137860736
[2022-12-06 16:03:53,335] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 16:03:53,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01754, loss val: 0.43774
[2022-12-06 16:03:53,481] [INFO] [controller] EPOCH 2 loss ppo:  -0.04514, loss val: 0.39124
[2022-12-06 16:03:53,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.05948, loss val: 0.36887
[2022-12-06 16:03:53,595] [INFO] [controller] EPOCH 4 loss ppo:  -0.06702, loss val: 0.31766
[2022-12-06 16:03:53,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:03:53,841] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:03:53,842] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:04:02,550] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:04:11,240] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:04:20,151] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:04:29,457] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:04:38,322] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:04:47,131] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:04:56,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:05:06,271] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:05:15,022] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:05:23,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39867263262610464
[2022-12-06 16:05:23,072] [INFO] [runner_train_mujoco] Average state value: 0.0866076315616568
[2022-12-06 16:05:23,072] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 16:05:23,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.01616, loss val: 0.27197
[2022-12-06 16:05:23,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.03707, loss val: 0.23820
[2022-12-06 16:05:23,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.04946, loss val: 0.20755
[2022-12-06 16:05:23,417] [INFO] [controller] EPOCH 4 loss ppo:  -0.06040, loss val: 0.18326
[2022-12-06 16:05:23,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:05:23,679] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:05:23,680] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:05:32,824] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:05:41,374] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:05:49,790] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:05:58,091] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:06:06,100] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:06:14,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:06:22,385] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:06:30,577] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:06:38,364] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:06:46,100] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4972869655805942
[2022-12-06 16:06:46,100] [INFO] [runner_train_mujoco] Average state value: 0.230184673688064
[2022-12-06 16:06:46,101] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 16:06:46,178] [INFO] [controller] EPOCH 1 loss ppo:  -0.01113, loss val: 0.18552
[2022-12-06 16:06:46,245] [INFO] [controller] EPOCH 2 loss ppo:  -0.03198, loss val: 0.16238
[2022-12-06 16:06:46,300] [INFO] [controller] EPOCH 3 loss ppo:  -0.04679, loss val: 0.14011
[2022-12-06 16:06:46,356] [INFO] [controller] EPOCH 4 loss ppo:  -0.05658, loss val: 0.12327
[2022-12-06 16:06:46,368] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:06:46,584] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:06:46,585] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:06:54,666] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:07:03,001] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:07:12,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:07:20,894] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:07:28,837] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:07:36,197] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:07:43,697] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:07:50,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:07:58,156] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:08:05,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.405845358194589
[2022-12-06 16:08:05,563] [INFO] [runner_train_mujoco] Average state value: 0.37658810370291274
[2022-12-06 16:08:05,563] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 16:08:05,650] [INFO] [controller] EPOCH 1 loss ppo:  -0.01192, loss val: 0.12693
[2022-12-06 16:08:05,714] [INFO] [controller] EPOCH 2 loss ppo:  -0.03306, loss val: 0.10788
[2022-12-06 16:08:05,775] [INFO] [controller] EPOCH 3 loss ppo:  -0.04612, loss val: 0.09944
[2022-12-06 16:08:05,981] [INFO] [controller] EPOCH 4 loss ppo:  -0.05582, loss val: 0.08750
[2022-12-06 16:08:05,993] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:08:06,213] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:08:06,213] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:08:14,128] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:08:22,025] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:08:29,238] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:08:36,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:08:43,934] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:08:51,445] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:08:58,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:09:05,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:09:12,891] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:09:19,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3699441301679333
[2022-12-06 16:09:19,837] [INFO] [runner_train_mujoco] Average state value: 0.49213199040790406
[2022-12-06 16:09:19,837] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 16:09:19,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01072, loss val: 0.08399
[2022-12-06 16:09:20,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.03217, loss val: 0.07644
[2022-12-06 16:09:20,090] [INFO] [controller] EPOCH 3 loss ppo:  -0.04664, loss val: 0.07221
[2022-12-06 16:09:20,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.05431, loss val: 0.06598
[2022-12-06 16:09:20,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:09:20,401] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:09:20,401] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:09:27,619] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:09:35,115] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:09:42,812] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:09:50,707] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:09:58,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:10:05,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:10:13,020] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:10:20,354] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:10:27,507] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:10:34,714] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46060365476345827
[2022-12-06 16:10:34,714] [INFO] [runner_train_mujoco] Average state value: 0.5892549152423938
[2022-12-06 16:10:34,714] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 16:10:34,787] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.05911
[2022-12-06 16:10:34,837] [INFO] [controller] EPOCH 2 loss ppo:  -0.03917, loss val: 0.05591
[2022-12-06 16:10:34,893] [INFO] [controller] EPOCH 3 loss ppo:  -0.05068, loss val: 0.05347
[2022-12-06 16:10:34,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.05945, loss val: 0.05064
[2022-12-06 16:10:34,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:10:35,173] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:10:35,173] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:10:43,054] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:10:51,529] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:10:59,692] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:11:06,886] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:11:14,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:11:21,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:11:29,259] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:11:37,020] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:11:45,201] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:11:53,715] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5289584118722017
[2022-12-06 16:11:53,715] [INFO] [runner_train_mujoco] Average state value: 0.6234940765798093
[2022-12-06 16:11:53,715] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 16:11:53,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01165, loss val: 0.05000
[2022-12-06 16:11:53,852] [INFO] [controller] EPOCH 2 loss ppo:  -0.03648, loss val: 0.04744
[2022-12-06 16:11:53,910] [INFO] [controller] EPOCH 3 loss ppo:  -0.04656, loss val: 0.04516
[2022-12-06 16:11:53,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.05308, loss val: 0.04404
[2022-12-06 16:11:53,980] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:11:54,233] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:11:54,234] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:12:02,013] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:12:10,072] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:12:17,714] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:12:25,224] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:12:33,022] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:12:40,750] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:12:48,689] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:12:56,612] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:13:03,846] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:13:11,821] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5143090002422753
[2022-12-06 16:13:11,821] [INFO] [runner_train_mujoco] Average state value: 0.5895989583532015
[2022-12-06 16:13:11,821] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 16:13:11,905] [INFO] [controller] EPOCH 1 loss ppo:  -0.00749, loss val: 0.04992
[2022-12-06 16:13:11,988] [INFO] [controller] EPOCH 2 loss ppo:  -0.02772, loss val: 0.04811
[2022-12-06 16:13:12,073] [INFO] [controller] EPOCH 3 loss ppo:  -0.03865, loss val: 0.04806
[2022-12-06 16:13:12,126] [INFO] [controller] EPOCH 4 loss ppo:  -0.04642, loss val: 0.04850
[2022-12-06 16:13:12,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:13:12,361] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:13:12,362] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:13:20,367] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:13:28,447] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:13:36,146] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:13:43,721] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:13:51,546] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:13:58,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:14:06,455] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:14:13,691] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:14:21,353] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:14:28,395] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4676875089434723
[2022-12-06 16:14:28,395] [INFO] [runner_train_mujoco] Average state value: 0.5574342533648015
[2022-12-06 16:14:28,395] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 16:14:28,471] [INFO] [controller] EPOCH 1 loss ppo:  -0.01119, loss val: 0.03832
[2022-12-06 16:14:28,551] [INFO] [controller] EPOCH 2 loss ppo:  -0.03347, loss val: 0.03823
[2022-12-06 16:14:28,650] [INFO] [controller] EPOCH 3 loss ppo:  -0.04611, loss val: 0.03709
[2022-12-06 16:14:28,725] [INFO] [controller] EPOCH 4 loss ppo:  -0.05111, loss val: 0.03559
[2022-12-06 16:14:28,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:14:28,975] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:28,976] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:14:36,162] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:14:43,987] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:14:52,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:15:02,137] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:15:10,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:15:18,639] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:15:26,933] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:15:35,089] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:15:43,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:15:51,716] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41140493176478266
[2022-12-06 16:15:51,716] [INFO] [runner_train_mujoco] Average state value: 0.5800962351063887
[2022-12-06 16:15:51,716] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 16:15:51,778] [INFO] [controller] EPOCH 1 loss ppo:  -0.01024, loss val: 0.04425
[2022-12-06 16:15:51,830] [INFO] [controller] EPOCH 2 loss ppo:  -0.03570, loss val: 0.04320
[2022-12-06 16:15:51,883] [INFO] [controller] EPOCH 3 loss ppo:  -0.04791, loss val: 0.04188
[2022-12-06 16:15:51,941] [INFO] [controller] EPOCH 4 loss ppo:  -0.05569, loss val: 0.04177
[2022-12-06 16:15:51,952] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:15:52,175] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:15:52,176] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:16:00,817] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:16:09,185] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:16:17,966] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:16:26,532] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:16:35,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:16:43,965] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:16:52,686] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:17:01,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:17:10,034] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:17:18,406] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48943762992580114
[2022-12-06 16:17:18,406] [INFO] [runner_train_mujoco] Average state value: 0.6293250523209571
[2022-12-06 16:17:18,406] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 16:17:18,509] [INFO] [controller] EPOCH 1 loss ppo:  -0.00994, loss val: 0.04192
[2022-12-06 16:17:18,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.03214, loss val: 0.04228
[2022-12-06 16:17:18,668] [INFO] [controller] EPOCH 3 loss ppo:  -0.04073, loss val: 0.04037
[2022-12-06 16:17:18,737] [INFO] [controller] EPOCH 4 loss ppo:  -0.04915, loss val: 0.03962
[2022-12-06 16:17:18,751] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:17:19,025] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:17:19,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:17:27,510] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:17:36,305] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:17:44,949] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:17:53,697] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:18:03,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:18:12,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:18:21,017] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:18:29,818] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:18:38,139] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:18:46,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4531783085584464
[2022-12-06 16:18:46,534] [INFO] [runner_train_mujoco] Average state value: 0.6014052624305088
[2022-12-06 16:18:46,534] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 16:18:46,664] [INFO] [controller] EPOCH 1 loss ppo:  -0.00883, loss val: 0.04360
[2022-12-06 16:18:46,754] [INFO] [controller] EPOCH 2 loss ppo:  -0.02838, loss val: 0.03950
[2022-12-06 16:18:46,844] [INFO] [controller] EPOCH 3 loss ppo:  -0.04039, loss val: 0.03936
[2022-12-06 16:18:46,976] [INFO] [controller] EPOCH 4 loss ppo:  -0.04978, loss val: 0.03794
[2022-12-06 16:18:46,991] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:18:47,232] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:18:47,233] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:18:55,779] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:19:04,595] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:13,254] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:19:21,587] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:19:29,591] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:19:37,907] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:19:46,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:19:54,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:20:02,813] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:20:11,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4801376801151222
[2022-12-06 16:20:11,195] [INFO] [runner_train_mujoco] Average state value: 0.5333883893291156
[2022-12-06 16:20:11,195] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 16:20:11,261] [INFO] [controller] EPOCH 1 loss ppo:  -0.00926, loss val: 0.04282
[2022-12-06 16:20:11,330] [INFO] [controller] EPOCH 2 loss ppo:  -0.03133, loss val: 0.03684
[2022-12-06 16:20:11,415] [INFO] [controller] EPOCH 3 loss ppo:  -0.04530, loss val: 0.03718
[2022-12-06 16:20:11,516] [INFO] [controller] EPOCH 4 loss ppo:  -0.05424, loss val: 0.03542
[2022-12-06 16:20:11,527] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:20:11,770] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:20:11,771] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:20:19,971] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:20:28,372] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:20:36,690] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:20:44,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:20:52,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:00,333] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:21:08,404] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:21:16,167] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:21:24,217] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:21:32,284] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5570261608059369
[2022-12-06 16:21:32,285] [INFO] [runner_train_mujoco] Average state value: 0.487907735556364
[2022-12-06 16:21:32,285] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 16:21:32,373] [INFO] [controller] EPOCH 1 loss ppo:  -0.00987, loss val: 0.04630
[2022-12-06 16:21:32,450] [INFO] [controller] EPOCH 2 loss ppo:  -0.03058, loss val: 0.04399
[2022-12-06 16:21:32,516] [INFO] [controller] EPOCH 3 loss ppo:  -0.04383, loss val: 0.04266
[2022-12-06 16:21:32,603] [INFO] [controller] EPOCH 4 loss ppo:  -0.05395, loss val: 0.04105
[2022-12-06 16:21:32,615] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:21:32,842] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:21:32,842] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:21:40,916] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:21:49,420] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:21:57,585] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:22:05,804] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:22:13,655] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:22:21,936] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:22:30,362] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:22:38,388] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:22:46,280] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:22:54,786] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5352310259235343
[2022-12-06 16:22:54,787] [INFO] [runner_train_mujoco] Average state value: 0.5210292147696018
[2022-12-06 16:22:54,787] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 16:22:54,893] [INFO] [controller] EPOCH 1 loss ppo:  -0.00965, loss val: 0.03903
[2022-12-06 16:22:54,947] [INFO] [controller] EPOCH 2 loss ppo:  -0.03182, loss val: 0.03939
[2022-12-06 16:22:55,004] [INFO] [controller] EPOCH 3 loss ppo:  -0.04137, loss val: 0.04062
[2022-12-06 16:22:55,061] [INFO] [controller] EPOCH 4 loss ppo:  -0.05055, loss val: 0.03969
[2022-12-06 16:22:55,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:22:55,304] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:22:55,304] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:23:03,886] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:23:12,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:23:20,935] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:23:29,443] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:23:37,807] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:23:46,105] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:23:54,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:24:03,729] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:24:12,740] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:24:21,610] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8892044213859276
[2022-12-06 16:24:21,610] [INFO] [runner_train_mujoco] Average state value: 0.545557475467523
[2022-12-06 16:24:21,610] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 16:24:21,696] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.03955
[2022-12-06 16:24:21,757] [INFO] [controller] EPOCH 2 loss ppo:  -0.03222, loss val: 0.03918
[2022-12-06 16:24:21,832] [INFO] [controller] EPOCH 3 loss ppo:  -0.04329, loss val: 0.03959
[2022-12-06 16:24:21,960] [INFO] [controller] EPOCH 4 loss ppo:  -0.05422, loss val: 0.04075
[2022-12-06 16:24:21,973] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:24:22,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:24:22,220] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:24:31,195] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:24:40,405] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:24:49,174] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:24:57,943] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:25:06,908] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:25:15,882] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:25:24,595] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:25:33,334] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:25:43,578] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:25:58,822] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9042445637961952
[2022-12-06 16:25:58,823] [INFO] [runner_train_mujoco] Average state value: 0.5395770599941414
[2022-12-06 16:25:58,823] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 16:25:58,941] [INFO] [controller] EPOCH 1 loss ppo:  -0.01219, loss val: 0.03986
[2022-12-06 16:25:59,060] [INFO] [controller] EPOCH 2 loss ppo:  -0.03693, loss val: 0.04154
[2022-12-06 16:25:59,210] [INFO] [controller] EPOCH 3 loss ppo:  -0.04263, loss val: 0.03913
[2022-12-06 16:25:59,317] [INFO] [controller] EPOCH 4 loss ppo:  -0.04997, loss val: 0.04060
[2022-12-06 16:25:59,338] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:25:59,658] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:25:59,659] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:26:12,934] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:26:25,383] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:26:37,770] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:26:49,577] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:27:00,432] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:27:11,546] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:27:20,224] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:27:28,539] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:27:38,776] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:27:49,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1682313964234372
[2022-12-06 16:27:49,987] [INFO] [runner_train_mujoco] Average state value: 0.5360705539385477
[2022-12-06 16:27:49,987] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 16:27:50,214] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04030
[2022-12-06 16:27:50,381] [INFO] [controller] EPOCH 2 loss ppo:  -0.03521, loss val: 0.03753
[2022-12-06 16:27:50,888] [INFO] [controller] EPOCH 3 loss ppo:  -0.04713, loss val: 0.04258
[2022-12-06 16:27:51,731] [INFO] [controller] EPOCH 4 loss ppo:  -0.06083, loss val: 0.03961
[2022-12-06 16:27:51,799] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:27:52,214] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:27:52,217] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:28:04,771] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:28:15,145] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:28:24,362] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:28:33,538] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:28:42,542] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:28:51,485] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:29:00,307] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:29:09,476] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:29:20,312] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:29:30,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4700448923669476
[2022-12-06 16:29:30,052] [INFO] [runner_train_mujoco] Average state value: 0.5457333209911981
[2022-12-06 16:29:30,052] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 16:29:30,145] [INFO] [controller] EPOCH 1 loss ppo:  -0.01472, loss val: 0.03420
[2022-12-06 16:29:30,304] [INFO] [controller] EPOCH 2 loss ppo:  -0.03202, loss val: 0.03416
[2022-12-06 16:29:30,397] [INFO] [controller] EPOCH 3 loss ppo:  -0.04584, loss val: 0.03434
[2022-12-06 16:29:30,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.05865, loss val: 0.03553
[2022-12-06 16:29:30,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:29:30,751] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:29:30,751] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:29:40,013] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:29:49,764] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:29:58,316] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:30:07,079] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:30:15,597] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:30:23,514] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:30:32,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:30:40,776] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:30:49,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:30:58,535] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5509753660632024
[2022-12-06 16:30:58,536] [INFO] [runner_train_mujoco] Average state value: 0.554583840529124
[2022-12-06 16:30:58,536] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 16:30:58,634] [INFO] [controller] EPOCH 1 loss ppo:  -0.01122, loss val: 0.03701
[2022-12-06 16:30:58,699] [INFO] [controller] EPOCH 2 loss ppo:  -0.02981, loss val: 0.03532
[2022-12-06 16:30:58,830] [INFO] [controller] EPOCH 3 loss ppo:  -0.04713, loss val: 0.03749
[2022-12-06 16:30:58,970] [INFO] [controller] EPOCH 4 loss ppo:  -0.05790, loss val: 0.03605
[2022-12-06 16:30:58,992] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:30:59,239] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:30:59,240] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:31:07,860] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:31:16,288] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:31:24,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:31:32,758] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:31:40,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:31:48,715] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:31:57,214] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:32:05,646] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:32:13,542] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:32:21,488] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8174285478691161
[2022-12-06 16:32:21,488] [INFO] [runner_train_mujoco] Average state value: 0.5290464963316917
[2022-12-06 16:32:21,488] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 16:32:21,566] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04462
[2022-12-06 16:32:21,626] [INFO] [controller] EPOCH 2 loss ppo:  -0.03680, loss val: 0.04518
[2022-12-06 16:32:21,693] [INFO] [controller] EPOCH 3 loss ppo:  -0.04904, loss val: 0.04431
[2022-12-06 16:32:21,748] [INFO] [controller] EPOCH 4 loss ppo:  -0.05527, loss val: 0.04405
[2022-12-06 16:32:21,763] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:32:21,985] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:32:21,985] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:32:30,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:32:38,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:32:46,675] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:32:54,892] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:33:02,749] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:33:10,575] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:33:18,832] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:33:26,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:33:34,542] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:33:42,187] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0799315494236015
[2022-12-06 16:33:42,187] [INFO] [runner_train_mujoco] Average state value: 0.5320650232036908
[2022-12-06 16:33:42,187] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 16:33:42,246] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.03443
[2022-12-06 16:33:42,298] [INFO] [controller] EPOCH 2 loss ppo:  -0.03665, loss val: 0.03405
[2022-12-06 16:33:42,362] [INFO] [controller] EPOCH 3 loss ppo:  -0.05039, loss val: 0.03405
[2022-12-06 16:33:42,415] [INFO] [controller] EPOCH 4 loss ppo:  -0.06041, loss val: 0.03336
[2022-12-06 16:33:42,426] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:33:42,643] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:33:42,643] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:33:50,688] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:33:59,097] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:34:07,241] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:34:15,600] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:34:24,621] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:34:34,105] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:34:43,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:34:52,401] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:35:05,142] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:35:15,661] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5051426622592206
[2022-12-06 16:35:15,662] [INFO] [runner_train_mujoco] Average state value: 0.5577054054935773
[2022-12-06 16:35:15,662] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 16:35:15,783] [INFO] [controller] EPOCH 1 loss ppo:  -0.01578, loss val: 0.04760
[2022-12-06 16:35:15,843] [INFO] [controller] EPOCH 2 loss ppo:  -0.03344, loss val: 0.04674
[2022-12-06 16:35:15,913] [INFO] [controller] EPOCH 3 loss ppo:  -0.04550, loss val: 0.04672
[2022-12-06 16:35:15,967] [INFO] [controller] EPOCH 4 loss ppo:  -0.05643, loss val: 0.04554
[2022-12-06 16:35:15,978] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:35:16,222] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:35:16,223] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:35:24,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:35:33,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:35:42,301] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:35:50,263] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:35:58,104] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:36:06,294] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:36:14,985] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:36:26,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:36:38,226] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:36:48,648] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.555874241010195
[2022-12-06 16:36:48,649] [INFO] [runner_train_mujoco] Average state value: 0.5368404507637023
[2022-12-06 16:36:48,649] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 16:36:48,785] [INFO] [controller] EPOCH 1 loss ppo:  -0.01561, loss val: 0.04760
[2022-12-06 16:36:48,916] [INFO] [controller] EPOCH 2 loss ppo:  -0.03595, loss val: 0.04488
[2022-12-06 16:36:49,006] [INFO] [controller] EPOCH 3 loss ppo:  -0.04782, loss val: 0.04256
[2022-12-06 16:36:49,078] [INFO] [controller] EPOCH 4 loss ppo:  -0.05978, loss val: 0.04056
[2022-12-06 16:36:49,091] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:36:49,316] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:36:49,316] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:36:58,465] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:37:08,328] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:37:17,546] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:37:27,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:37:36,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:37:45,633] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:37:54,797] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:38:04,100] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:38:13,398] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:38:23,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5237813648117493
[2022-12-06 16:38:23,842] [INFO] [runner_train_mujoco] Average state value: 0.4730614937742551
[2022-12-06 16:38:23,842] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 16:38:24,276] [INFO] [controller] EPOCH 1 loss ppo:  -0.01502, loss val: 0.04950
[2022-12-06 16:38:24,530] [INFO] [controller] EPOCH 2 loss ppo:  -0.03298, loss val: 0.05101
[2022-12-06 16:38:24,684] [INFO] [controller] EPOCH 3 loss ppo:  -0.04745, loss val: 0.05168
[2022-12-06 16:38:24,939] [INFO] [controller] EPOCH 4 loss ppo:  -0.05581, loss val: 0.05009
[2022-12-06 16:38:24,958] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:38:25,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:38:25,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:38:40,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:38:51,098] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:39:01,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:39:12,248] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:39:24,184] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:39:35,421] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:39:45,294] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:39:55,306] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:40:04,949] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:40:17,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.355224460931042
[2022-12-06 16:40:17,219] [INFO] [runner_train_mujoco] Average state value: 0.47083625556031866
[2022-12-06 16:40:17,219] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 16:40:17,319] [INFO] [controller] EPOCH 1 loss ppo:  -0.01682, loss val: 0.05095
[2022-12-06 16:40:17,378] [INFO] [controller] EPOCH 2 loss ppo:  -0.03725, loss val: 0.04854
[2022-12-06 16:40:17,454] [INFO] [controller] EPOCH 3 loss ppo:  -0.04431, loss val: 0.04594
[2022-12-06 16:40:17,526] [INFO] [controller] EPOCH 4 loss ppo:  -0.05601, loss val: 0.04430
[2022-12-06 16:40:17,538] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:40:17,785] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:40:17,785] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:40:27,544] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:40:36,807] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:40:45,938] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:40:55,404] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:41:04,319] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:12,658] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:41:20,972] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:41:29,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:41:38,506] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:41:47,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.460316664831629
[2022-12-06 16:41:47,070] [INFO] [runner_train_mujoco] Average state value: 0.5392198334534963
[2022-12-06 16:41:47,071] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 16:41:47,160] [INFO] [controller] EPOCH 1 loss ppo:  -0.01522, loss val: 0.04453
[2022-12-06 16:41:47,222] [INFO] [controller] EPOCH 2 loss ppo:  -0.03334, loss val: 0.04672
[2022-12-06 16:41:47,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.04339, loss val: 0.04625
[2022-12-06 16:41:47,368] [INFO] [controller] EPOCH 4 loss ppo:  -0.05508, loss val: 0.04820
[2022-12-06 16:41:47,380] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:41:47,627] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:41:47,627] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:41:56,821] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:42:06,213] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:42:14,571] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:42:23,163] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:42:32,127] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:42:40,130] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:42:48,374] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:42:56,806] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:43:05,815] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:43:14,369] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.4527702231422834
[2022-12-06 16:43:14,370] [INFO] [runner_train_mujoco] Average state value: 0.5625306319197019
[2022-12-06 16:43:14,370] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 16:43:14,562] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.05014
[2022-12-06 16:43:14,723] [INFO] [controller] EPOCH 2 loss ppo:  -0.03131, loss val: 0.04982
[2022-12-06 16:43:14,896] [INFO] [controller] EPOCH 3 loss ppo:  -0.03997, loss val: 0.04947
[2022-12-06 16:43:14,970] [INFO] [controller] EPOCH 4 loss ppo:  -0.05572, loss val: 0.04848
[2022-12-06 16:43:14,982] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:43:15,209] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:43:15,209] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:43:24,919] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:43:33,384] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:43:41,985] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:43:50,086] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:43:58,454] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:44:06,789] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:44:15,711] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:44:25,464] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:44:34,315] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:44:43,315] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.933162720857009
[2022-12-06 16:44:43,315] [INFO] [runner_train_mujoco] Average state value: 0.5336209610501926
[2022-12-06 16:44:43,315] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 16:44:43,427] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.04797
[2022-12-06 16:44:43,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.02592, loss val: 0.04638
[2022-12-06 16:44:43,713] [INFO] [controller] EPOCH 3 loss ppo:  -0.04116, loss val: 0.04857
[2022-12-06 16:44:43,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.05103, loss val: 0.04673
[2022-12-06 16:44:43,834] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:44:44,059] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:44:44,059] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:44:52,891] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:45:01,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:45:10,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:45:20,231] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:45:30,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:45:40,812] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:45:50,805] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:46:00,902] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:46:10,626] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:46:21,140] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.340674209295754
[2022-12-06 16:46:21,141] [INFO] [runner_train_mujoco] Average state value: 0.530622874667247
[2022-12-06 16:46:21,141] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 16:46:21,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04320
[2022-12-06 16:46:21,372] [INFO] [controller] EPOCH 2 loss ppo:  -0.02948, loss val: 0.04434
[2022-12-06 16:46:21,529] [INFO] [controller] EPOCH 3 loss ppo:  -0.03843, loss val: 0.04217
[2022-12-06 16:46:21,613] [INFO] [controller] EPOCH 4 loss ppo:  -0.05094, loss val: 0.04205
[2022-12-06 16:46:21,634] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:46:21,933] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:46:21,934] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:46:31,535] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:46:41,183] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:46:51,138] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:47:01,189] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:47:10,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:47:21,383] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:47:30,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:47:39,713] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:47:48,661] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:47:58,287] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.079452255283366
[2022-12-06 16:47:58,288] [INFO] [runner_train_mujoco] Average state value: 0.5122457673152289
[2022-12-06 16:47:58,288] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 16:47:58,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.03750
[2022-12-06 16:47:58,452] [INFO] [controller] EPOCH 2 loss ppo:  -0.02739, loss val: 0.03644
[2022-12-06 16:47:58,515] [INFO] [controller] EPOCH 3 loss ppo:  -0.03609, loss val: 0.03579
[2022-12-06 16:47:58,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.04805, loss val: 0.03514
[2022-12-06 16:47:58,589] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:47:58,817] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:47:58,817] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:48:08,339] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:48:16,936] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:48:26,100] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:48:37,096] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:48:45,742] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:48:54,293] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:49:02,897] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:49:11,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:49:21,374] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:49:30,576] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.519036753356504
[2022-12-06 16:49:30,577] [INFO] [runner_train_mujoco] Average state value: 0.4694656686981519
[2022-12-06 16:49:30,577] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 16:49:30,675] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04523
[2022-12-06 16:49:30,736] [INFO] [controller] EPOCH 2 loss ppo:  -0.03036, loss val: 0.04509
[2022-12-06 16:49:30,963] [INFO] [controller] EPOCH 3 loss ppo:  -0.03794, loss val: 0.04498
[2022-12-06 16:49:31,038] [INFO] [controller] EPOCH 4 loss ppo:  -0.04977, loss val: 0.04386
[2022-12-06 16:49:31,051] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:49:31,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:49:31,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:49:40,916] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:49:50,169] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:49:58,776] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:50:06,565] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:50:15,056] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:50:25,826] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:50:35,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:50:44,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:50:53,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:51:02,931] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.777675733747219
[2022-12-06 16:51:02,932] [INFO] [runner_train_mujoco] Average state value: 0.4296261707743009
[2022-12-06 16:51:02,932] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 16:51:03,011] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.05224
[2022-12-06 16:51:03,079] [INFO] [controller] EPOCH 2 loss ppo:  -0.02421, loss val: 0.05277
[2022-12-06 16:51:03,152] [INFO] [controller] EPOCH 3 loss ppo:  -0.03542, loss val: 0.05114
[2022-12-06 16:51:03,222] [INFO] [controller] EPOCH 4 loss ppo:  -0.04496, loss val: 0.04986
[2022-12-06 16:51:03,236] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:51:03,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:51:03,480] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:51:12,944] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:51:22,552] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:51:32,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:51:42,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:51:50,957] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:51:59,948] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:52:09,207] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:52:17,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:52:26,682] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:52:35,266] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.06303187851969
[2022-12-06 16:52:35,267] [INFO] [runner_train_mujoco] Average state value: 0.4498188785513242
[2022-12-06 16:52:35,267] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 16:52:35,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01514, loss val: 0.05238
[2022-12-06 16:52:35,408] [INFO] [controller] EPOCH 2 loss ppo:  -0.02730, loss val: 0.05108
[2022-12-06 16:52:35,487] [INFO] [controller] EPOCH 3 loss ppo:  -0.03267, loss val: 0.05024
[2022-12-06 16:52:35,556] [INFO] [controller] EPOCH 4 loss ppo:  -0.04625, loss val: 0.04970
[2022-12-06 16:52:35,573] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:52:35,838] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:52:35,841] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:52:44,455] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:52:52,986] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:53:01,369] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:53:09,736] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:53:18,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:53:26,940] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:53:35,288] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:53:43,693] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:53:51,991] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:54:00,324] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.883806883862703
[2022-12-06 16:54:00,325] [INFO] [runner_train_mujoco] Average state value: 0.4974938126802445
[2022-12-06 16:54:00,325] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 16:54:00,432] [INFO] [controller] EPOCH 1 loss ppo:  -0.01459, loss val: 0.04424
[2022-12-06 16:54:00,544] [INFO] [controller] EPOCH 2 loss ppo:  -0.02984, loss val: 0.04361
[2022-12-06 16:54:00,693] [INFO] [controller] EPOCH 3 loss ppo:  -0.03789, loss val: 0.04210
[2022-12-06 16:54:00,819] [INFO] [controller] EPOCH 4 loss ppo:  -0.04967, loss val: 0.04265
[2022-12-06 16:54:00,831] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:54:01,063] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:54:01,063] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:54:09,683] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:54:18,082] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:54:26,916] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:54:35,309] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:54:43,118] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:54:51,136] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:54:58,866] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:55:06,940] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:55:14,303] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:55:22,726] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.880252597702599
[2022-12-06 16:55:22,727] [INFO] [runner_train_mujoco] Average state value: 0.5360082536339761
[2022-12-06 16:55:22,727] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 16:55:22,807] [INFO] [controller] EPOCH 1 loss ppo:  -0.01234, loss val: 0.05378
[2022-12-06 16:55:22,891] [INFO] [controller] EPOCH 2 loss ppo:  -0.02132, loss val: 0.05415
[2022-12-06 16:55:22,987] [INFO] [controller] EPOCH 3 loss ppo:  -0.03365, loss val: 0.05431
[2022-12-06 16:55:23,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.04617, loss val: 0.05316
[2022-12-06 16:55:23,076] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:55:23,287] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:55:23,288] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:55:31,292] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:55:39,333] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:55:47,243] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:55:55,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:56:02,555] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:56:10,518] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:56:17,913] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:56:25,953] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:56:34,399] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:56:43,023] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.169957324421167
[2022-12-06 16:56:43,024] [INFO] [runner_train_mujoco] Average state value: 0.528772524257501
[2022-12-06 16:56:43,024] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 16:56:43,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.01337, loss val: 0.04010
[2022-12-06 16:56:43,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.02514, loss val: 0.03967
[2022-12-06 16:56:43,247] [INFO] [controller] EPOCH 3 loss ppo:  -0.03515, loss val: 0.04040
[2022-12-06 16:56:43,307] [INFO] [controller] EPOCH 4 loss ppo:  -0.04658, loss val: 0.03954
[2022-12-06 16:56:43,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:56:43,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:56:43,552] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:56:51,456] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:57:00,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:57:08,408] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:57:16,692] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:57:24,517] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:57:33,216] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:57:41,689] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:57:49,634] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:57:58,523] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:58:07,070] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.274541525521515
[2022-12-06 16:58:07,070] [INFO] [runner_train_mujoco] Average state value: 0.499013255238533
[2022-12-06 16:58:07,071] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 16:58:07,155] [INFO] [controller] EPOCH 1 loss ppo:  -0.01468, loss val: 0.04767
[2022-12-06 16:58:07,216] [INFO] [controller] EPOCH 2 loss ppo:  -0.02954, loss val: 0.04796
[2022-12-06 16:58:07,303] [INFO] [controller] EPOCH 3 loss ppo:  -0.03637, loss val: 0.04852
[2022-12-06 16:58:07,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.04674, loss val: 0.04883
[2022-12-06 16:58:07,379] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:58:07,611] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:58:07,612] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:58:16,281] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:58:24,657] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:58:33,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:58:41,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:58:51,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:59:00,391] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:59:09,552] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:59:19,573] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:59:27,764] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:59:36,529] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.32487194565017
[2022-12-06 16:59:36,529] [INFO] [runner_train_mujoco] Average state value: 0.487306662172079
[2022-12-06 16:59:36,530] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 16:59:36,670] [INFO] [controller] EPOCH 1 loss ppo:  -0.01534, loss val: 0.04415
[2022-12-06 16:59:36,840] [INFO] [controller] EPOCH 2 loss ppo:  -0.02728, loss val: 0.04527
[2022-12-06 16:59:37,010] [INFO] [controller] EPOCH 3 loss ppo:  -0.03350, loss val: 0.04485
[2022-12-06 16:59:37,303] [INFO] [controller] EPOCH 4 loss ppo:  -0.04391, loss val: 0.04527
[2022-12-06 16:59:37,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:59:37,596] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:59:37,596] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:59:46,790] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:59:56,037] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:00:05,604] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:00:14,569] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:00:23,548] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:00:32,438] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:00:41,240] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:00:49,983] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:00:58,657] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:01:07,743] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.184296851270312
[2022-12-06 17:01:07,743] [INFO] [runner_train_mujoco] Average state value: 0.4970886702934901
[2022-12-06 17:01:07,743] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 17:01:07,847] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04527
[2022-12-06 17:01:07,909] [INFO] [controller] EPOCH 2 loss ppo:  -0.02339, loss val: 0.04338
[2022-12-06 17:01:07,981] [INFO] [controller] EPOCH 3 loss ppo:  -0.03341, loss val: 0.04709
[2022-12-06 17:01:08,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.04311, loss val: 0.04499
[2022-12-06 17:01:08,058] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:01:08,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:01:08,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:01:16,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:01:25,112] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:01:33,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:01:42,961] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:01:51,812] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:02:00,976] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:02:10,124] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:02:18,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:02:27,843] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:02:36,281] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.184177222759219
[2022-12-06 17:02:36,281] [INFO] [runner_train_mujoco] Average state value: 0.4982725887894629
[2022-12-06 17:02:36,282] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 17:02:36,366] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.03458
[2022-12-06 17:02:36,426] [INFO] [controller] EPOCH 2 loss ppo:  -0.02782, loss val: 0.03531
[2022-12-06 17:02:36,489] [INFO] [controller] EPOCH 3 loss ppo:  -0.03414, loss val: 0.03542
[2022-12-06 17:02:36,573] [INFO] [controller] EPOCH 4 loss ppo:  -0.04550, loss val: 0.03324
[2022-12-06 17:02:36,585] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:02:36,839] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:02:36,840] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:02:45,095] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:02:53,092] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:03:01,329] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:03:10,063] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:03:18,324] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:03:26,630] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:03:34,642] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:03:42,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:03:50,632] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:03:58,251] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4696352056640904
[2022-12-06 17:03:58,251] [INFO] [runner_train_mujoco] Average state value: 0.4795200026830038
[2022-12-06 17:03:58,251] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 17:03:58,339] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.04981
[2022-12-06 17:03:58,407] [INFO] [controller] EPOCH 2 loss ppo:  -0.02524, loss val: 0.05079
[2022-12-06 17:03:58,474] [INFO] [controller] EPOCH 3 loss ppo:  -0.03343, loss val: 0.04885
[2022-12-06 17:03:58,527] [INFO] [controller] EPOCH 4 loss ppo:  -0.04165, loss val: 0.05079
[2022-12-06 17:03:58,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:03:58,754] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:03:58,755] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:04:06,774] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:04:14,626] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:04:22,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:04:30,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:04:38,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:04:47,024] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:04:55,371] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:05:03,774] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:05:11,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:05:19,222] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.549513211378548
[2022-12-06 17:05:19,222] [INFO] [runner_train_mujoco] Average state value: 0.4892316131393115
[2022-12-06 17:05:19,223] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 17:05:19,349] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04398
[2022-12-06 17:05:19,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.02472, loss val: 0.04422
[2022-12-06 17:05:19,534] [INFO] [controller] EPOCH 3 loss ppo:  -0.03444, loss val: 0.04457
[2022-12-06 17:05:19,618] [INFO] [controller] EPOCH 4 loss ppo:  -0.04125, loss val: 0.04540
[2022-12-06 17:05:19,633] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:05:19,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:05:19,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:05:27,786] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:05:36,266] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:05:44,594] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:05:53,466] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:06:02,253] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:06:10,914] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:06:19,942] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:06:29,450] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:06:38,384] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:06:46,469] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.4849864673832025
[2022-12-06 17:06:46,469] [INFO] [runner_train_mujoco] Average state value: 0.4976048801541328
[2022-12-06 17:06:46,470] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 17:06:46,625] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04123
[2022-12-06 17:06:46,713] [INFO] [controller] EPOCH 2 loss ppo:  -0.02419, loss val: 0.03857
[2022-12-06 17:06:46,796] [INFO] [controller] EPOCH 3 loss ppo:  -0.03398, loss val: 0.03818
[2022-12-06 17:06:46,883] [INFO] [controller] EPOCH 4 loss ppo:  -0.04311, loss val: 0.03875
[2022-12-06 17:06:46,901] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:06:47,158] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:06:47,158] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:06:56,733] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:07:07,946] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:07:18,154] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:07:27,765] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:07:41,117] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:07:51,823] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:08:03,125] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:08:13,788] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:08:25,168] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:08:35,221] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.6824244052539985
[2022-12-06 17:08:35,221] [INFO] [runner_train_mujoco] Average state value: 0.4927826954325041
[2022-12-06 17:08:35,222] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 17:08:35,308] [INFO] [controller] EPOCH 1 loss ppo:  -0.01367, loss val: 0.04739
[2022-12-06 17:08:35,384] [INFO] [controller] EPOCH 2 loss ppo:  -0.02031, loss val: 0.04784
[2022-12-06 17:08:35,453] [INFO] [controller] EPOCH 3 loss ppo:  -0.02977, loss val: 0.04837
[2022-12-06 17:08:35,528] [INFO] [controller] EPOCH 4 loss ppo:  -0.03967, loss val: 0.04774
[2022-12-06 17:08:35,541] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:08:35,788] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:08:35,788] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:08:45,838] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:08:55,912] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:09:07,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:09:18,967] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:09:29,123] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:09:38,987] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:09:49,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:10:00,709] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:10:14,070] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:10:25,071] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.932232103725488
[2022-12-06 17:10:25,072] [INFO] [runner_train_mujoco] Average state value: 0.4864094273249308
[2022-12-06 17:10:25,072] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 17:10:25,196] [INFO] [controller] EPOCH 1 loss ppo:  -0.01331, loss val: 0.05148
[2022-12-06 17:10:25,265] [INFO] [controller] EPOCH 2 loss ppo:  -0.02197, loss val: 0.05144
[2022-12-06 17:10:25,331] [INFO] [controller] EPOCH 3 loss ppo:  -0.02855, loss val: 0.05112
[2022-12-06 17:10:25,477] [INFO] [controller] EPOCH 4 loss ppo:  -0.03542, loss val: 0.05200
[2022-12-06 17:10:25,492] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:10:25,789] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:10:25,790] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:10:36,380] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:10:48,788] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:11:01,008] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:11:12,112] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:11:22,999] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:11:35,536] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:11:47,755] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:11:58,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:12:11,576] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:12:23,185] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.735287304911069
[2022-12-06 17:12:23,186] [INFO] [runner_train_mujoco] Average state value: 0.4891453265746435
[2022-12-06 17:12:23,186] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 17:12:23,280] [INFO] [controller] EPOCH 1 loss ppo:  -0.01424, loss val: 0.03940
[2022-12-06 17:12:23,347] [INFO] [controller] EPOCH 2 loss ppo:  -0.02476, loss val: 0.03931
[2022-12-06 17:12:23,416] [INFO] [controller] EPOCH 3 loss ppo:  -0.03247, loss val: 0.03930
[2022-12-06 17:12:23,493] [INFO] [controller] EPOCH 4 loss ppo:  -0.03937, loss val: 0.04041
[2022-12-06 17:12:23,512] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:12:23,772] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:12:23,773] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:12:34,158] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:12:45,486] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:12:58,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:13:10,567] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:13:21,483] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:13:32,879] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:13:43,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:13:53,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:14:02,905] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:14:12,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.9769811514321365
[2022-12-06 17:14:12,819] [INFO] [runner_train_mujoco] Average state value: 0.48833598270018885
[2022-12-06 17:14:12,819] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 17:14:13,323] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.04612
[2022-12-06 17:14:13,402] [INFO] [controller] EPOCH 2 loss ppo:  -0.02024, loss val: 0.04380
[2022-12-06 17:14:13,508] [INFO] [controller] EPOCH 3 loss ppo:  -0.02676, loss val: 0.04554
[2022-12-06 17:14:13,690] [INFO] [controller] EPOCH 4 loss ppo:  -0.03694, loss val: 0.04304
[2022-12-06 17:14:13,709] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:14:14,032] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:14:14,033] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:14:24,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:14:34,263] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:14:43,865] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:14:52,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:15:00,812] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:15:12,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:15:23,288] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:15:31,645] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:15:40,012] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:15:48,118] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.847008444558846
[2022-12-06 17:15:48,119] [INFO] [runner_train_mujoco] Average state value: 0.48259065024058023
[2022-12-06 17:15:48,119] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 17:15:48,213] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.03586
[2022-12-06 17:15:48,306] [INFO] [controller] EPOCH 2 loss ppo:  -0.02156, loss val: 0.03552
[2022-12-06 17:15:48,477] [INFO] [controller] EPOCH 3 loss ppo:  -0.03104, loss val: 0.03517
[2022-12-06 17:15:48,592] [INFO] [controller] EPOCH 4 loss ppo:  -0.03496, loss val: 0.03556
[2022-12-06 17:15:48,617] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:15:48,874] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:15:48,875] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:15:57,113] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:16:05,902] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:16:14,157] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:16:22,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:16:31,061] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:16:39,598] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:16:48,232] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:16:57,342] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:17:05,305] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:17:13,776] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.75255946726872
[2022-12-06 17:17:13,776] [INFO] [runner_train_mujoco] Average state value: 0.4675136289298535
[2022-12-06 17:17:13,777] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 17:17:13,923] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.04632
[2022-12-06 17:17:14,048] [INFO] [controller] EPOCH 2 loss ppo:  -0.02010, loss val: 0.04492
[2022-12-06 17:17:14,132] [INFO] [controller] EPOCH 3 loss ppo:  -0.02915, loss val: 0.04455
[2022-12-06 17:17:14,279] [INFO] [controller] EPOCH 4 loss ppo:  -0.03493, loss val: 0.04595
[2022-12-06 17:17:14,300] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:17:14,529] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:17:14,530] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:17:22,876] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:17:31,817] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:17:41,732] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:17:49,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:17:57,772] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:18:05,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:18:11,877] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:18:18,772] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:18:26,867] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:18:33,902] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.957876588834774
[2022-12-06 17:18:33,902] [INFO] [runner_train_mujoco] Average state value: 0.4687513534824054
[2022-12-06 17:18:33,902] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 17:18:33,964] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.04476
[2022-12-06 17:18:34,013] [INFO] [controller] EPOCH 2 loss ppo:  -0.02136, loss val: 0.04546
[2022-12-06 17:18:34,059] [INFO] [controller] EPOCH 3 loss ppo:  -0.03078, loss val: 0.04581
[2022-12-06 17:18:34,108] [INFO] [controller] EPOCH 4 loss ppo:  -0.03750, loss val: 0.04280
[2022-12-06 17:18:34,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:18:34,335] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:18:34,335] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:18:41,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:18:49,139] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:18:56,448] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:19:03,776] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:19:11,242] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:19:17,990] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:19:26,606] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:19:34,109] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:19:41,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:19:48,122] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.0344338679137435
[2022-12-06 17:19:48,122] [INFO] [runner_train_mujoco] Average state value: 0.47822798488537466
[2022-12-06 17:19:48,123] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 17:19:48,182] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.05234
[2022-12-06 17:19:48,235] [INFO] [controller] EPOCH 2 loss ppo:  -0.02017, loss val: 0.05314
[2022-12-06 17:19:48,287] [INFO] [controller] EPOCH 3 loss ppo:  -0.02819, loss val: 0.05297
[2022-12-06 17:19:48,338] [INFO] [controller] EPOCH 4 loss ppo:  -0.03313, loss val: 0.05194
[2022-12-06 17:19:48,349] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:19:48,569] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:19:48,569] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:19:55,613] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:20:03,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:20:10,867] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:20:17,765] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:20:24,895] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:20:33,336] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:20:42,245] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:20:51,192] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:21:01,364] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:21:08,720] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.374167398594095
[2022-12-06 17:21:08,720] [INFO] [runner_train_mujoco] Average state value: 0.48853155447045954
[2022-12-06 17:21:08,720] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 17:21:08,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.04221
[2022-12-06 17:21:08,973] [INFO] [controller] EPOCH 2 loss ppo:  -0.02007, loss val: 0.04425
[2022-12-06 17:21:09,049] [INFO] [controller] EPOCH 3 loss ppo:  -0.02825, loss val: 0.04410
[2022-12-06 17:21:09,125] [INFO] [controller] EPOCH 4 loss ppo:  -0.03300, loss val: 0.04307
[2022-12-06 17:21:09,138] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:21:09,370] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:21:09,370] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:21:17,384] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:21:25,699] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:21:33,128] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:21:40,030] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:21:47,065] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:21:53,730] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:22:00,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:22:07,729] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:22:14,506] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:22:21,537] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.454439406783811
[2022-12-06 17:22:21,538] [INFO] [runner_train_mujoco] Average state value: 0.4924631202220917
[2022-12-06 17:22:21,538] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 17:22:21,620] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.04442
[2022-12-06 17:22:21,689] [INFO] [controller] EPOCH 2 loss ppo:  -0.01717, loss val: 0.04578
[2022-12-06 17:22:21,747] [INFO] [controller] EPOCH 3 loss ppo:  -0.02318, loss val: 0.04459
[2022-12-06 17:22:21,801] [INFO] [controller] EPOCH 4 loss ppo:  -0.02833, loss val: 0.04338
[2022-12-06 17:22:21,812] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:22:22,033] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:22:22,033] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:22:28,910] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:22:35,688] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:22:42,595] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:22:50,099] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:22:57,697] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:23:05,219] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:23:12,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:23:20,136] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:23:27,984] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:23:35,628] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.494868499006675
[2022-12-06 17:23:35,628] [INFO] [runner_train_mujoco] Average state value: 0.4789429290294647
[2022-12-06 17:23:35,628] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 17:23:35,725] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.05461
[2022-12-06 17:23:35,806] [INFO] [controller] EPOCH 2 loss ppo:  -0.01672, loss val: 0.05635
[2022-12-06 17:23:35,869] [INFO] [controller] EPOCH 3 loss ppo:  -0.02027, loss val: 0.05352
[2022-12-06 17:23:35,929] [INFO] [controller] EPOCH 4 loss ppo:  -0.02431, loss val: 0.05241
[2022-12-06 17:23:35,942] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:23:36,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:23:36,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:23:43,426] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:23:50,888] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:23:58,243] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:24:05,415] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:24:12,478] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:24:19,701] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:24:26,435] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:24:32,973] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:24:40,139] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:24:47,013] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.4680154984326474
[2022-12-06 17:24:47,014] [INFO] [runner_train_mujoco] Average state value: 0.47420127671957013
[2022-12-06 17:24:47,014] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 17:24:47,091] [INFO] [controller] EPOCH 1 loss ppo:  -0.01373, loss val: 0.04186
[2022-12-06 17:24:47,158] [INFO] [controller] EPOCH 2 loss ppo:  -0.01696, loss val: 0.04383
[2022-12-06 17:24:47,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.02229, loss val: 0.04183
[2022-12-06 17:24:47,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.02885, loss val: 0.04331
[2022-12-06 17:24:47,292] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:24:47,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:24:47,521] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:24:54,748] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:25:02,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:25:09,234] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:25:16,401] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:25:23,013] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:25:29,227] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:25:36,094] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:25:42,218] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:25:48,903] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:25:55,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.402221236158491
[2022-12-06 17:25:55,590] [INFO] [runner_train_mujoco] Average state value: 0.4703148181637128
[2022-12-06 17:25:55,590] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 17:25:55,649] [INFO] [controller] EPOCH 1 loss ppo:  -0.01370, loss val: 0.04457
[2022-12-06 17:25:55,700] [INFO] [controller] EPOCH 2 loss ppo:  -0.01519, loss val: 0.04419
[2022-12-06 17:25:55,826] [INFO] [controller] EPOCH 3 loss ppo:  -0.01859, loss val: 0.04386
[2022-12-06 17:25:55,880] [INFO] [controller] EPOCH 4 loss ppo:  -0.02148, loss val: 0.04296
[2022-12-06 17:25:55,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:25:56,104] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:25:56,104] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:26:02,913] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:26:09,707] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:26:17,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:26:23,817] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:26:30,060] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:26:37,241] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:26:44,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:26:50,875] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:26:57,155] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:27:03,789] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.408508071745248
[2022-12-06 17:27:03,789] [INFO] [runner_train_mujoco] Average state value: 0.46456242120265967
[2022-12-06 17:27:03,789] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 17:27:03,858] [INFO] [controller] EPOCH 1 loss ppo:  -0.01344, loss val: 0.04741
[2022-12-06 17:27:03,932] [INFO] [controller] EPOCH 2 loss ppo:  -0.01418, loss val: 0.04834
[2022-12-06 17:27:03,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.01569, loss val: 0.04915
[2022-12-06 17:27:04,041] [INFO] [controller] EPOCH 4 loss ppo:  -0.01771, loss val: 0.04949
[2022-12-06 17:27:04,052] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:27:04,204] [INFO] [optimize] Finished learning.
