[2022-12-07 10:59:14,749] [INFO] [optimize] Starting learning
[2022-12-07 10:59:14,766] [INFO] [optimize] Starting learning process..
[2022-12-07 10:59:14,867] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:59:14,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:59:24,297] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:59:33,011] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:59:41,266] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:59:49,489] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:59:58,049] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:00:06,119] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:00:14,048] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:00:22,624] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:00:31,269] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:00:39,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46139955688460244
[2022-12-07 11:00:39,666] [INFO] [runner_train_mujoco] Average state value: 0.09073626215631762
[2022-12-07 11:00:39,667] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 11:00:39,756] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.27729
[2022-12-07 11:00:39,816] [INFO] [controller] EPOCH 2 loss ppo:  -0.04282, loss val: 0.23913
[2022-12-07 11:00:39,885] [INFO] [controller] EPOCH 3 loss ppo:  -0.05319, loss val: 0.20301
[2022-12-07 11:00:39,940] [INFO] [controller] EPOCH 4 loss ppo:  -0.06146, loss val: 0.17687
[2022-12-07 11:00:39,952] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:00:40,175] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:00:40,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:00:48,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:00:56,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:01:05,241] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:01:13,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:01:21,589] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:01:30,849] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:01:40,975] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:01:49,423] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:01:58,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:02:08,363] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3378940038074504
[2022-12-07 11:02:08,364] [INFO] [runner_train_mujoco] Average state value: 0.25070436726945144
[2022-12-07 11:02:08,364] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 11:02:08,446] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.21136
[2022-12-07 11:02:08,516] [INFO] [controller] EPOCH 2 loss ppo:  -0.03345, loss val: 0.17518
[2022-12-07 11:02:08,590] [INFO] [controller] EPOCH 3 loss ppo:  -0.04856, loss val: 0.16279
[2022-12-07 11:02:08,652] [INFO] [controller] EPOCH 4 loss ppo:  -0.05785, loss val: 0.13131
[2022-12-07 11:02:08,664] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:02:08,891] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:02:08,892] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:02:17,725] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:02:26,614] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:02:35,355] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:02:43,853] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:02:52,747] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:03:01,455] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:03:10,161] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:03:18,429] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:03:27,154] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:03:35,610] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3179081392132726
[2022-12-07 11:03:35,610] [INFO] [runner_train_mujoco] Average state value: 0.39149583075009287
[2022-12-07 11:03:35,610] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 11:03:35,685] [INFO] [controller] EPOCH 1 loss ppo:  -0.01192, loss val: 0.14032
[2022-12-07 11:03:35,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.03245, loss val: 0.12606
[2022-12-07 11:03:35,838] [INFO] [controller] EPOCH 3 loss ppo:  -0.04714, loss val: 0.11253
[2022-12-07 11:03:35,909] [INFO] [controller] EPOCH 4 loss ppo:  -0.05738, loss val: 0.10094
[2022-12-07 11:03:35,921] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:03:36,144] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:03:36,144] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:03:44,689] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:03:53,556] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:04:01,959] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:04:10,276] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:04:18,518] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:04:26,744] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:04:34,532] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:04:42,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:04:50,560] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:04:58,080] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3387791227646749
[2022-12-07 11:04:58,081] [INFO] [runner_train_mujoco] Average state value: 0.5254524624409774
[2022-12-07 11:04:58,081] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 11:04:58,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.07523
[2022-12-07 11:04:58,210] [INFO] [controller] EPOCH 2 loss ppo:  -0.03648, loss val: 0.07169
[2022-12-07 11:04:58,267] [INFO] [controller] EPOCH 3 loss ppo:  -0.04642, loss val: 0.06635
[2022-12-07 11:04:58,327] [INFO] [controller] EPOCH 4 loss ppo:  -0.05407, loss val: 0.06382
[2022-12-07 11:04:58,337] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:04:58,544] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:04:58,544] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:05:06,565] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:05:14,110] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:05:22,396] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:05:30,561] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:05:38,363] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:05:46,158] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:05:53,905] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:06:01,771] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:06:09,605] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:06:17,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.499134998482268
[2022-12-07 11:06:17,126] [INFO] [runner_train_mujoco] Average state value: 0.5961030341970424
[2022-12-07 11:06:17,126] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 11:06:17,201] [INFO] [controller] EPOCH 1 loss ppo:  -0.01069, loss val: 0.06493
[2022-12-07 11:06:17,287] [INFO] [controller] EPOCH 2 loss ppo:  -0.03000, loss val: 0.06073
[2022-12-07 11:06:17,374] [INFO] [controller] EPOCH 3 loss ppo:  -0.04442, loss val: 0.05701
[2022-12-07 11:06:17,453] [INFO] [controller] EPOCH 4 loss ppo:  -0.05307, loss val: 0.05435
[2022-12-07 11:06:17,464] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:06:17,678] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:06:17,678] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:06:26,001] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:06:34,036] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:06:42,560] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:06:50,673] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:06:58,719] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:07:08,803] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:07:19,052] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:07:29,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:07:39,228] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:07:48,305] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5092764900820375
[2022-12-07 11:07:48,305] [INFO] [runner_train_mujoco] Average state value: 0.6088925132056078
[2022-12-07 11:07:48,305] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 11:07:48,451] [INFO] [controller] EPOCH 1 loss ppo:  -0.00884, loss val: 0.05175
[2022-12-07 11:07:48,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.03212, loss val: 0.04757
[2022-12-07 11:07:48,589] [INFO] [controller] EPOCH 3 loss ppo:  -0.04627, loss val: 0.04565
[2022-12-07 11:07:48,684] [INFO] [controller] EPOCH 4 loss ppo:  -0.05451, loss val: 0.04716
[2022-12-07 11:07:48,696] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:07:48,916] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:07:48,917] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:07:57,627] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:08:06,713] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:08:15,923] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:08:24,714] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:08:34,102] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:08:43,572] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:08:52,729] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:09:01,786] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:09:10,674] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:09:20,120] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4991765086311811
[2022-12-07 11:09:20,120] [INFO] [runner_train_mujoco] Average state value: 0.6304460794727008
[2022-12-07 11:09:20,120] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 11:09:20,221] [INFO] [controller] EPOCH 1 loss ppo:  -0.01015, loss val: 0.04425
[2022-12-07 11:09:20,331] [INFO] [controller] EPOCH 2 loss ppo:  -0.03502, loss val: 0.04300
[2022-12-07 11:09:20,396] [INFO] [controller] EPOCH 3 loss ppo:  -0.04707, loss val: 0.04262
[2022-12-07 11:09:20,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.05274, loss val: 0.04100
[2022-12-07 11:09:20,496] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:09:20,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:09:20,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:09:30,491] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:09:40,701] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:09:50,114] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:09:58,399] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:10:06,295] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:10:14,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:10:22,331] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:10:30,796] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:10:38,590] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:10:47,004] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42434373258734903
[2022-12-07 11:10:47,004] [INFO] [runner_train_mujoco] Average state value: 0.6536873468955359
[2022-12-07 11:10:47,004] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 11:10:47,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.00890, loss val: 0.04465
[2022-12-07 11:10:47,143] [INFO] [controller] EPOCH 2 loss ppo:  -0.03331, loss val: 0.04496
[2022-12-07 11:10:47,211] [INFO] [controller] EPOCH 3 loss ppo:  -0.04415, loss val: 0.04128
[2022-12-07 11:10:47,268] [INFO] [controller] EPOCH 4 loss ppo:  -0.05137, loss val: 0.03972
[2022-12-07 11:10:47,282] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:10:47,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:10:47,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:10:55,073] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:11:03,510] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:11:12,940] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:11:21,672] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:11:30,335] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:11:38,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:11:46,298] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:11:54,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:12:02,621] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:12:10,542] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5789855054396482
[2022-12-07 11:12:10,543] [INFO] [runner_train_mujoco] Average state value: 0.6198259161114693
[2022-12-07 11:12:10,543] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 11:12:10,609] [INFO] [controller] EPOCH 1 loss ppo:  -0.00968, loss val: 0.03575
[2022-12-07 11:12:10,655] [INFO] [controller] EPOCH 2 loss ppo:  -0.03528, loss val: 0.03303
[2022-12-07 11:12:10,697] [INFO] [controller] EPOCH 3 loss ppo:  -0.04480, loss val: 0.03290
[2022-12-07 11:12:10,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.04900, loss val: 0.03270
[2022-12-07 11:12:10,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:12:10,956] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:12:10,956] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:12:17,828] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:12:24,731] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:12:31,459] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:12:37,897] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:12:44,781] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:12:51,712] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:12:58,777] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:13:05,491] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:13:11,811] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:13:18,130] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6512557185815713
[2022-12-07 11:13:18,130] [INFO] [runner_train_mujoco] Average state value: 0.5935026734272639
[2022-12-07 11:13:18,131] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 11:13:18,186] [INFO] [controller] EPOCH 1 loss ppo:  -0.01127, loss val: 0.03978
[2022-12-07 11:13:18,240] [INFO] [controller] EPOCH 2 loss ppo:  -0.03188, loss val: 0.04089
[2022-12-07 11:13:18,290] [INFO] [controller] EPOCH 3 loss ppo:  -0.04104, loss val: 0.03849
[2022-12-07 11:13:18,341] [INFO] [controller] EPOCH 4 loss ppo:  -0.04868, loss val: 0.04013
[2022-12-07 11:13:18,351] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:13:18,554] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:13:18,554] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:13:25,222] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:13:31,982] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:13:38,175] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:13:44,296] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:13:50,432] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:13:56,728] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:14:02,760] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:14:09,369] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:14:15,547] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:14:22,348] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8432266213023782
[2022-12-07 11:14:22,349] [INFO] [runner_train_mujoco] Average state value: 0.6013155302007993
[2022-12-07 11:14:22,349] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 11:14:22,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01162, loss val: 0.03593
[2022-12-07 11:14:22,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.03631, loss val: 0.03598
[2022-12-07 11:14:22,509] [INFO] [controller] EPOCH 3 loss ppo:  -0.04784, loss val: 0.03607
[2022-12-07 11:14:22,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.05733, loss val: 0.03652
[2022-12-07 11:14:22,570] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:14:22,780] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:14:22,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:14:29,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:14:36,049] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:14:42,389] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:14:48,525] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:14:54,571] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:15:01,926] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:15:10,299] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:15:17,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:15:24,246] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:15:31,176] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.965790917105576
[2022-12-07 11:15:31,176] [INFO] [runner_train_mujoco] Average state value: 0.60981180336078
[2022-12-07 11:15:31,177] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 11:15:31,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01295, loss val: 0.03963
[2022-12-07 11:15:31,295] [INFO] [controller] EPOCH 2 loss ppo:  -0.03462, loss val: 0.03588
[2022-12-07 11:15:31,346] [INFO] [controller] EPOCH 3 loss ppo:  -0.04596, loss val: 0.03278
[2022-12-07 11:15:31,407] [INFO] [controller] EPOCH 4 loss ppo:  -0.05598, loss val: 0.02988
[2022-12-07 11:15:31,416] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:15:31,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:15:31,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:15:39,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:15:47,044] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:15:54,127] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:16:03,539] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:16:10,906] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:16:18,246] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:16:25,129] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:16:31,651] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:16:38,666] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:16:45,461] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9742092682242817
[2022-12-07 11:16:45,462] [INFO] [runner_train_mujoco] Average state value: 0.5453569131692251
[2022-12-07 11:16:45,462] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 11:16:45,543] [INFO] [controller] EPOCH 1 loss ppo:  -0.01087, loss val: 0.03586
[2022-12-07 11:16:45,603] [INFO] [controller] EPOCH 2 loss ppo:  -0.03377, loss val: 0.03504
[2022-12-07 11:16:45,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.04645, loss val: 0.03564
[2022-12-07 11:16:45,720] [INFO] [controller] EPOCH 4 loss ppo:  -0.05441, loss val: 0.03532
[2022-12-07 11:16:45,734] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:16:45,964] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:16:45,964] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:16:53,867] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:17:01,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:17:08,711] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:17:15,462] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:17:21,820] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:17:29,426] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:17:36,390] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:17:44,949] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:17:53,153] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:18:00,192] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0746047509874734
[2022-12-07 11:18:00,192] [INFO] [runner_train_mujoco] Average state value: 0.5236560440262159
[2022-12-07 11:18:00,192] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 11:18:00,253] [INFO] [controller] EPOCH 1 loss ppo:  -0.01245, loss val: 0.03599
[2022-12-07 11:18:00,307] [INFO] [controller] EPOCH 2 loss ppo:  -0.03482, loss val: 0.03737
[2022-12-07 11:18:00,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.04562, loss val: 0.03516
[2022-12-07 11:18:00,405] [INFO] [controller] EPOCH 4 loss ppo:  -0.05589, loss val: 0.03506
[2022-12-07 11:18:00,417] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:18:00,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:18:00,649] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:18:08,400] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:18:15,496] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:18:22,390] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:18:28,888] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:18:35,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:18:42,255] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:18:49,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:18:56,117] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:19:02,934] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:19:09,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.113018933640839
[2022-12-07 11:19:09,667] [INFO] [runner_train_mujoco] Average state value: 0.5462851329445838
[2022-12-07 11:19:09,667] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 11:19:09,722] [INFO] [controller] EPOCH 1 loss ppo:  -0.01138, loss val: 0.03726
[2022-12-07 11:19:09,771] [INFO] [controller] EPOCH 2 loss ppo:  -0.03735, loss val: 0.03594
[2022-12-07 11:19:09,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.05196, loss val: 0.03396
[2022-12-07 11:19:09,874] [INFO] [controller] EPOCH 4 loss ppo:  -0.06177, loss val: 0.03354
[2022-12-07 11:19:09,885] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:19:10,086] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:19:10,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:19:17,456] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:19:24,771] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:19:31,970] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:19:39,235] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:19:46,816] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:19:54,500] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:20:02,743] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:20:09,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:20:15,902] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:20:22,296] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1322485465798886
[2022-12-07 11:20:22,296] [INFO] [runner_train_mujoco] Average state value: 0.5875615576108296
[2022-12-07 11:20:22,296] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 11:20:22,357] [INFO] [controller] EPOCH 1 loss ppo:  -0.01235, loss val: 0.03964
[2022-12-07 11:20:22,403] [INFO] [controller] EPOCH 2 loss ppo:  -0.03549, loss val: 0.04039
[2022-12-07 11:20:22,443] [INFO] [controller] EPOCH 3 loss ppo:  -0.05073, loss val: 0.04097
[2022-12-07 11:20:22,490] [INFO] [controller] EPOCH 4 loss ppo:  -0.06173, loss val: 0.03872
[2022-12-07 11:20:22,498] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:20:22,716] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:20:22,716] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:20:29,729] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:20:37,473] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:20:44,674] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:20:51,385] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:20:58,422] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:21:05,766] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:21:14,173] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:21:21,341] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:21:28,015] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:21:35,734] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4978605304765973
[2022-12-07 11:21:35,734] [INFO] [runner_train_mujoco] Average state value: 0.5752768473823864
[2022-12-07 11:21:35,734] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 11:21:35,791] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.03369
[2022-12-07 11:21:35,840] [INFO] [controller] EPOCH 2 loss ppo:  -0.03606, loss val: 0.03336
[2022-12-07 11:21:35,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.04658, loss val: 0.03388
[2022-12-07 11:21:35,937] [INFO] [controller] EPOCH 4 loss ppo:  -0.05656, loss val: 0.03339
[2022-12-07 11:21:35,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:21:36,153] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:21:36,154] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:21:44,390] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:21:51,237] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:21:57,233] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:22:03,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:22:09,866] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:22:16,493] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:22:22,857] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:22:30,040] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:22:36,583] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:22:43,803] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4562691461045942
[2022-12-07 11:22:43,804] [INFO] [runner_train_mujoco] Average state value: 0.5388858262499173
[2022-12-07 11:22:43,804] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 11:22:43,863] [INFO] [controller] EPOCH 1 loss ppo:  -0.01516, loss val: 0.03246
[2022-12-07 11:22:43,916] [INFO] [controller] EPOCH 2 loss ppo:  -0.03750, loss val: 0.03226
[2022-12-07 11:22:43,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.04720, loss val: 0.03164
[2022-12-07 11:22:44,029] [INFO] [controller] EPOCH 4 loss ppo:  -0.05584, loss val: 0.03078
[2022-12-07 11:22:44,043] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:22:44,251] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:22:44,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:22:50,766] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:22:57,394] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:23:03,832] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:23:10,638] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:23:17,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:23:24,374] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:23:31,566] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:23:38,049] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:23:44,481] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:23:50,867] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4249984563939335
[2022-12-07 11:23:50,868] [INFO] [runner_train_mujoco] Average state value: 0.5021464318235715
[2022-12-07 11:23:50,868] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 11:23:50,924] [INFO] [controller] EPOCH 1 loss ppo:  -0.01346, loss val: 0.04805
[2022-12-07 11:23:50,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.03950, loss val: 0.04856
[2022-12-07 11:23:51,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.05486, loss val: 0.04860
[2022-12-07 11:23:51,060] [INFO] [controller] EPOCH 4 loss ppo:  -0.06494, loss val: 0.04657
[2022-12-07 11:23:51,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:23:51,272] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:23:51,273] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:23:58,588] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:24:06,084] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:24:13,587] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:24:20,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:24:27,215] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:24:34,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:24:41,252] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:24:48,155] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:24:56,002] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:25:02,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4015562456678146
[2022-12-07 11:25:02,215] [INFO] [runner_train_mujoco] Average state value: 0.5223039285341897
[2022-12-07 11:25:02,215] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 11:25:02,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.03959
[2022-12-07 11:25:02,321] [INFO] [controller] EPOCH 2 loss ppo:  -0.03778, loss val: 0.04081
[2022-12-07 11:25:02,367] [INFO] [controller] EPOCH 3 loss ppo:  -0.04614, loss val: 0.03896
[2022-12-07 11:25:02,485] [INFO] [controller] EPOCH 4 loss ppo:  -0.05309, loss val: 0.03916
[2022-12-07 11:25:02,495] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:25:02,724] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:25:02,725] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:25:09,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:25:16,092] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:25:22,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:25:29,688] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:25:36,698] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:25:44,225] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:25:51,915] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:25:58,974] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:26:05,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:26:13,242] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.7904557216800996
[2022-12-07 11:26:13,243] [INFO] [runner_train_mujoco] Average state value: 0.5545623832941053
[2022-12-07 11:26:13,243] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 11:26:13,347] [INFO] [controller] EPOCH 1 loss ppo:  -0.01338, loss val: 0.03356
[2022-12-07 11:26:13,404] [INFO] [controller] EPOCH 2 loss ppo:  -0.03333, loss val: 0.03189
[2022-12-07 11:26:13,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.04641, loss val: 0.03186
[2022-12-07 11:26:13,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.05706, loss val: 0.03208
[2022-12-07 11:26:13,525] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:26:13,760] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:26:13,760] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:26:21,332] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:26:28,172] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:26:34,986] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:26:41,846] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:26:49,712] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:26:57,626] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:27:04,678] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:27:11,457] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:27:18,168] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:27:24,904] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.025787816445837
[2022-12-07 11:27:24,904] [INFO] [runner_train_mujoco] Average state value: 0.5433044376969337
[2022-12-07 11:27:24,904] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 11:27:24,962] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.04753
[2022-12-07 11:27:25,020] [INFO] [controller] EPOCH 2 loss ppo:  -0.03122, loss val: 0.04704
[2022-12-07 11:27:25,074] [INFO] [controller] EPOCH 3 loss ppo:  -0.04173, loss val: 0.04636
[2022-12-07 11:27:25,140] [INFO] [controller] EPOCH 4 loss ppo:  -0.05365, loss val: 0.04516
[2022-12-07 11:27:25,150] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:27:25,364] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:27:25,365] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:27:32,475] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:27:40,532] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:27:47,121] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:27:53,770] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:28:00,267] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:28:06,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:28:13,008] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:28:19,338] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:28:25,449] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:28:32,232] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.2076006156291514
[2022-12-07 11:28:32,232] [INFO] [runner_train_mujoco] Average state value: 0.568860725303491
[2022-12-07 11:28:32,233] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 11:28:32,333] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.03802
[2022-12-07 11:28:32,385] [INFO] [controller] EPOCH 2 loss ppo:  -0.03272, loss val: 0.03846
[2022-12-07 11:28:32,439] [INFO] [controller] EPOCH 3 loss ppo:  -0.04777, loss val: 0.03868
[2022-12-07 11:28:32,493] [INFO] [controller] EPOCH 4 loss ppo:  -0.05658, loss val: 0.03790
[2022-12-07 11:28:32,504] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:28:32,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:28:32,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:28:39,972] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:28:47,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:28:54,548] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:29:01,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:29:08,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:29:14,830] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:29:20,865] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:29:28,528] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:29:35,158] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:29:44,346] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.285331841580944
[2022-12-07 11:29:44,346] [INFO] [runner_train_mujoco] Average state value: 0.5673637954394023
[2022-12-07 11:29:44,346] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 11:29:44,427] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.04040
[2022-12-07 11:29:44,487] [INFO] [controller] EPOCH 2 loss ppo:  -0.03797, loss val: 0.03758
[2022-12-07 11:29:44,574] [INFO] [controller] EPOCH 3 loss ppo:  -0.04866, loss val: 0.04241
[2022-12-07 11:29:44,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.05861, loss val: 0.04014
[2022-12-07 11:29:44,649] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:29:44,916] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:29:44,918] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:29:52,926] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:29:59,006] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:30:05,268] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:30:13,665] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:30:20,864] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:30:26,999] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:30:33,084] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:30:39,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:30:46,041] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:30:51,994] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.380338400227269
[2022-12-07 11:30:51,994] [INFO] [runner_train_mujoco] Average state value: 0.565044885357221
[2022-12-07 11:30:51,994] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 11:30:52,049] [INFO] [controller] EPOCH 1 loss ppo:  -0.01445, loss val: 0.04006
[2022-12-07 11:30:52,093] [INFO] [controller] EPOCH 2 loss ppo:  -0.03255, loss val: 0.04045
[2022-12-07 11:30:52,137] [INFO] [controller] EPOCH 3 loss ppo:  -0.04185, loss val: 0.03983
[2022-12-07 11:30:52,183] [INFO] [controller] EPOCH 4 loss ppo:  -0.05851, loss val: 0.04030
[2022-12-07 11:30:52,193] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:30:52,396] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:30:52,397] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:30:58,665] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:31:04,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:31:10,709] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:31:16,995] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:31:23,577] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:31:30,410] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:31:37,021] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:31:44,517] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:31:53,548] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:32:01,397] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.5358915023226016
[2022-12-07 11:32:01,398] [INFO] [runner_train_mujoco] Average state value: 0.5587940478920937
[2022-12-07 11:32:01,398] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 11:32:01,464] [INFO] [controller] EPOCH 1 loss ppo:  -0.01465, loss val: 0.03755
[2022-12-07 11:32:01,510] [INFO] [controller] EPOCH 2 loss ppo:  -0.03031, loss val: 0.03806
[2022-12-07 11:32:01,557] [INFO] [controller] EPOCH 3 loss ppo:  -0.04334, loss val: 0.03864
[2022-12-07 11:32:01,604] [INFO] [controller] EPOCH 4 loss ppo:  -0.05576, loss val: 0.03776
[2022-12-07 11:32:01,615] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:32:01,829] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:32:01,829] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:32:09,159] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:32:15,816] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:32:22,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:32:29,560] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:32:37,241] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:32:43,678] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:32:50,184] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:32:59,734] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:33:06,203] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:33:12,547] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.699388624422858
[2022-12-07 11:33:12,547] [INFO] [runner_train_mujoco] Average state value: 0.540339845319589
[2022-12-07 11:33:12,547] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 11:33:12,607] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.04119
[2022-12-07 11:33:12,661] [INFO] [controller] EPOCH 2 loss ppo:  -0.03388, loss val: 0.03881
[2022-12-07 11:33:12,708] [INFO] [controller] EPOCH 3 loss ppo:  -0.04944, loss val: 0.04043
[2022-12-07 11:33:12,755] [INFO] [controller] EPOCH 4 loss ppo:  -0.05853, loss val: 0.03869
[2022-12-07 11:33:12,766] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:33:12,972] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:33:12,973] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:33:19,844] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:33:26,907] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:33:33,723] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:33:40,463] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:33:47,056] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:33:55,169] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:34:05,227] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:34:12,569] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:34:20,395] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:34:28,842] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7665440536935977
[2022-12-07 11:34:28,842] [INFO] [runner_train_mujoco] Average state value: 0.5396522597869238
[2022-12-07 11:34:28,842] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 11:34:28,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01363, loss val: 0.03816
[2022-12-07 11:34:29,138] [INFO] [controller] EPOCH 2 loss ppo:  -0.03127, loss val: 0.03989
[2022-12-07 11:34:29,244] [INFO] [controller] EPOCH 3 loss ppo:  -0.04307, loss val: 0.03807
[2022-12-07 11:34:29,351] [INFO] [controller] EPOCH 4 loss ppo:  -0.05593, loss val: 0.04178
[2022-12-07 11:34:29,364] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:34:29,593] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:34:29,594] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:34:37,414] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:34:44,160] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:34:51,287] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:34:58,143] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:35:05,250] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:35:12,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:35:22,705] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:35:34,389] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:35:41,845] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:35:50,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1333169983673734
[2022-12-07 11:35:50,886] [INFO] [runner_train_mujoco] Average state value: 0.5436460293928782
[2022-12-07 11:35:50,886] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 11:35:50,992] [INFO] [controller] EPOCH 1 loss ppo:  -0.01524, loss val: 0.03482
[2022-12-07 11:35:51,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.03345, loss val: 0.03400
[2022-12-07 11:35:51,220] [INFO] [controller] EPOCH 3 loss ppo:  -0.04445, loss val: 0.03681
[2022-12-07 11:35:51,311] [INFO] [controller] EPOCH 4 loss ppo:  -0.05339, loss val: 0.03540
[2022-12-07 11:35:51,323] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:35:51,571] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:35:51,572] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:35:59,862] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:36:06,344] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:36:14,466] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:36:24,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:36:33,977] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:36:42,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:36:51,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:36:59,244] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:37:05,595] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:37:11,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.313697624464882
[2022-12-07 11:37:11,741] [INFO] [runner_train_mujoco] Average state value: 0.5726019671956697
[2022-12-07 11:37:11,742] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 11:37:11,806] [INFO] [controller] EPOCH 1 loss ppo:  -0.01377, loss val: 0.04265
[2022-12-07 11:37:11,847] [INFO] [controller] EPOCH 2 loss ppo:  -0.03246, loss val: 0.04090
[2022-12-07 11:37:11,892] [INFO] [controller] EPOCH 3 loss ppo:  -0.04504, loss val: 0.04270
[2022-12-07 11:37:11,937] [INFO] [controller] EPOCH 4 loss ppo:  -0.05626, loss val: 0.04304
[2022-12-07 11:37:11,948] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:37:12,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:37:12,149] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:37:18,267] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:37:24,781] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:37:31,874] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:37:38,740] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:37:45,407] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:37:52,108] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:37:58,909] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:38:07,097] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:38:14,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:38:22,810] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.310327012914732
[2022-12-07 11:38:22,810] [INFO] [runner_train_mujoco] Average state value: 0.6068603697419166
[2022-12-07 11:38:22,810] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 11:38:22,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.04178
[2022-12-07 11:38:22,970] [INFO] [controller] EPOCH 2 loss ppo:  -0.03241, loss val: 0.04232
[2022-12-07 11:38:23,045] [INFO] [controller] EPOCH 3 loss ppo:  -0.04279, loss val: 0.04188
[2022-12-07 11:38:23,117] [INFO] [controller] EPOCH 4 loss ppo:  -0.05420, loss val: 0.04093
[2022-12-07 11:38:23,128] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:38:23,342] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:38:23,342] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:38:31,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:38:41,632] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:38:48,341] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:38:54,742] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:39:01,360] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:39:09,385] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:39:19,206] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:39:26,381] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:39:34,061] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:39:41,610] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5599350140568
[2022-12-07 11:39:41,611] [INFO] [runner_train_mujoco] Average state value: 0.6073485274513561
[2022-12-07 11:39:41,611] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 11:39:41,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.04539
[2022-12-07 11:39:41,793] [INFO] [controller] EPOCH 2 loss ppo:  -0.02789, loss val: 0.04366
[2022-12-07 11:39:41,890] [INFO] [controller] EPOCH 3 loss ppo:  -0.03971, loss val: 0.04348
[2022-12-07 11:39:41,997] [INFO] [controller] EPOCH 4 loss ppo:  -0.05047, loss val: 0.04278
[2022-12-07 11:39:42,011] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:39:42,294] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:39:42,297] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:39:49,888] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:39:57,211] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:40:05,011] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:40:12,833] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:40:19,718] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:40:26,615] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:40:34,333] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:40:41,019] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:40:48,165] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:40:54,587] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3697275612851856
[2022-12-07 11:40:54,588] [INFO] [runner_train_mujoco] Average state value: 0.5755884268681208
[2022-12-07 11:40:54,588] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 11:40:54,667] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04094
[2022-12-07 11:40:54,729] [INFO] [controller] EPOCH 2 loss ppo:  -0.02978, loss val: 0.03990
[2022-12-07 11:40:54,786] [INFO] [controller] EPOCH 3 loss ppo:  -0.03826, loss val: 0.03876
[2022-12-07 11:40:54,846] [INFO] [controller] EPOCH 4 loss ppo:  -0.05209, loss val: 0.04128
[2022-12-07 11:40:54,861] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:40:55,095] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:40:55,096] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:41:02,318] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:41:09,573] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:41:17,254] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:41:23,930] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:41:30,387] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:41:37,036] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:41:44,144] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:41:50,046] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:41:56,494] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:42:03,173] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.606610023928637
[2022-12-07 11:42:03,173] [INFO] [runner_train_mujoco] Average state value: 0.548536313354969
[2022-12-07 11:42:03,173] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 11:42:03,238] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.04043
[2022-12-07 11:42:03,289] [INFO] [controller] EPOCH 2 loss ppo:  -0.02845, loss val: 0.03803
[2022-12-07 11:42:03,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.03787, loss val: 0.03890
[2022-12-07 11:42:03,392] [INFO] [controller] EPOCH 4 loss ppo:  -0.05253, loss val: 0.03837
[2022-12-07 11:42:03,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:42:03,627] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:42:03,628] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:42:10,735] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:42:17,168] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:42:23,346] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:42:29,923] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:42:36,319] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:42:42,660] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:42:49,206] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:42:55,895] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:43:02,000] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:43:08,627] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.545748608903417
[2022-12-07 11:43:08,627] [INFO] [runner_train_mujoco] Average state value: 0.537764458934466
[2022-12-07 11:43:08,627] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 11:43:08,682] [INFO] [controller] EPOCH 1 loss ppo:  -0.01487, loss val: 0.03722
[2022-12-07 11:43:08,726] [INFO] [controller] EPOCH 2 loss ppo:  -0.02711, loss val: 0.03539
[2022-12-07 11:43:08,771] [INFO] [controller] EPOCH 3 loss ppo:  -0.03871, loss val: 0.03635
[2022-12-07 11:43:08,815] [INFO] [controller] EPOCH 4 loss ppo:  -0.04781, loss val: 0.03518
[2022-12-07 11:43:08,825] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:43:09,028] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:43:09,028] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:43:15,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:43:22,881] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:43:30,070] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:43:35,997] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:43:42,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:43:48,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:43:53,896] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:44:00,186] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:44:06,630] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:44:13,555] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.980995184038876
[2022-12-07 11:44:13,555] [INFO] [runner_train_mujoco] Average state value: 0.5009924036065738
[2022-12-07 11:44:13,555] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 11:44:13,614] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.05013
[2022-12-07 11:44:13,660] [INFO] [controller] EPOCH 2 loss ppo:  -0.02750, loss val: 0.04987
[2022-12-07 11:44:13,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.03836, loss val: 0.05006
[2022-12-07 11:44:13,753] [INFO] [controller] EPOCH 4 loss ppo:  -0.05053, loss val: 0.04949
[2022-12-07 11:44:13,764] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:44:13,970] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:44:13,970] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:44:22,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:44:32,542] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:44:40,511] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:44:46,581] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:44:52,688] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:44:59,310] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:45:06,067] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:45:12,743] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:45:19,172] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:45:25,672] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.379560887047065
[2022-12-07 11:45:25,672] [INFO] [runner_train_mujoco] Average state value: 0.4954703108668328
[2022-12-07 11:45:25,672] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 11:45:25,759] [INFO] [controller] EPOCH 1 loss ppo:  -0.01131, loss val: 0.05445
[2022-12-07 11:45:25,831] [INFO] [controller] EPOCH 2 loss ppo:  -0.02443, loss val: 0.05536
[2022-12-07 11:45:25,889] [INFO] [controller] EPOCH 3 loss ppo:  -0.04030, loss val: 0.05475
[2022-12-07 11:45:25,949] [INFO] [controller] EPOCH 4 loss ppo:  -0.04814, loss val: 0.05032
[2022-12-07 11:45:25,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:45:26,179] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:45:26,179] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:45:33,220] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:45:41,737] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:45:49,744] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:45:58,205] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:46:06,959] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:46:15,308] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:46:22,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:46:29,933] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:46:36,978] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:46:44,267] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.578136915626134
[2022-12-07 11:46:44,267] [INFO] [runner_train_mujoco] Average state value: 0.5210249489943186
[2022-12-07 11:46:44,267] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 11:46:44,376] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.04270
[2022-12-07 11:46:44,443] [INFO] [controller] EPOCH 2 loss ppo:  -0.03012, loss val: 0.04309
[2022-12-07 11:46:44,523] [INFO] [controller] EPOCH 3 loss ppo:  -0.03535, loss val: 0.04265
[2022-12-07 11:46:44,597] [INFO] [controller] EPOCH 4 loss ppo:  -0.04767, loss val: 0.04329
[2022-12-07 11:46:44,610] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:46:44,846] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:46:44,847] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:46:52,467] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:46:59,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:47:06,874] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:47:14,165] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:47:20,891] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:47:27,619] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:47:34,339] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:47:41,934] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:47:48,800] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:47:56,034] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.760514560639193
[2022-12-07 11:47:56,034] [INFO] [runner_train_mujoco] Average state value: 0.5339726242224375
[2022-12-07 11:47:56,034] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 11:47:56,096] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.04386
[2022-12-07 11:47:56,171] [INFO] [controller] EPOCH 2 loss ppo:  -0.02382, loss val: 0.04466
[2022-12-07 11:47:56,223] [INFO] [controller] EPOCH 3 loss ppo:  -0.03665, loss val: 0.04450
[2022-12-07 11:47:56,283] [INFO] [controller] EPOCH 4 loss ppo:  -0.04898, loss val: 0.04295
[2022-12-07 11:47:56,295] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:47:56,510] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:47:56,511] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:48:04,196] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:48:11,507] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:48:18,108] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:48:24,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:48:30,852] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:48:37,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:48:43,653] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:48:50,175] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:48:56,692] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:49:03,850] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.561878501958011
[2022-12-07 11:49:03,851] [INFO] [runner_train_mujoco] Average state value: 0.5424216986894608
[2022-12-07 11:49:03,851] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 11:49:03,906] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04755
[2022-12-07 11:49:03,957] [INFO] [controller] EPOCH 2 loss ppo:  -0.02839, loss val: 0.04700
[2022-12-07 11:49:04,032] [INFO] [controller] EPOCH 3 loss ppo:  -0.03690, loss val: 0.04726
[2022-12-07 11:49:04,096] [INFO] [controller] EPOCH 4 loss ppo:  -0.04770, loss val: 0.04711
[2022-12-07 11:49:04,106] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:49:04,315] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:49:04,315] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:49:11,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:49:18,457] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:49:24,719] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:49:32,127] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:49:39,045] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:49:45,580] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:49:51,973] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:49:58,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:50:05,553] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:50:11,944] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.759147880575027
[2022-12-07 11:50:11,944] [INFO] [runner_train_mujoco] Average state value: 0.5471358981331189
[2022-12-07 11:50:11,944] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 11:50:12,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.01163, loss val: 0.05962
[2022-12-07 11:50:12,051] [INFO] [controller] EPOCH 2 loss ppo:  -0.02201, loss val: 0.05953
[2022-12-07 11:50:12,097] [INFO] [controller] EPOCH 3 loss ppo:  -0.03510, loss val: 0.05842
[2022-12-07 11:50:12,145] [INFO] [controller] EPOCH 4 loss ppo:  -0.04544, loss val: 0.05776
[2022-12-07 11:50:12,156] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:50:12,359] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:50:12,360] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:50:18,601] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:50:25,031] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:50:30,652] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:50:36,973] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:50:43,221] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:50:49,689] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:50:55,717] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:51:02,074] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:51:08,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:51:14,577] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.883262180177799
[2022-12-07 11:51:14,577] [INFO] [runner_train_mujoco] Average state value: 0.5273972025712331
[2022-12-07 11:51:14,577] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 11:51:14,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04818
[2022-12-07 11:51:14,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.02744, loss val: 0.04607
[2022-12-07 11:51:14,720] [INFO] [controller] EPOCH 3 loss ppo:  -0.03316, loss val: 0.04680
[2022-12-07 11:51:14,768] [INFO] [controller] EPOCH 4 loss ppo:  -0.04206, loss val: 0.04551
[2022-12-07 11:51:14,779] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:51:14,982] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:51:14,982] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:51:21,090] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:51:27,268] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:51:33,300] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:51:39,521] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:51:45,394] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:51:51,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:51:57,484] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:52:03,600] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:52:09,877] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:52:16,072] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7590195780654625
[2022-12-07 11:52:16,072] [INFO] [runner_train_mujoco] Average state value: 0.48543432507912315
[2022-12-07 11:52:16,072] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 11:52:16,130] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.03559
[2022-12-07 11:52:16,182] [INFO] [controller] EPOCH 2 loss ppo:  -0.02444, loss val: 0.03620
[2022-12-07 11:52:16,231] [INFO] [controller] EPOCH 3 loss ppo:  -0.03368, loss val: 0.03686
[2022-12-07 11:52:16,285] [INFO] [controller] EPOCH 4 loss ppo:  -0.04434, loss val: 0.03602
[2022-12-07 11:52:16,297] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:52:16,506] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:52:16,506] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:52:22,330] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:52:29,123] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:52:35,920] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:52:42,123] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:52:47,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:52:53,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:52:59,182] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:53:05,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:53:11,730] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:53:18,415] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.219540912265406
[2022-12-07 11:53:18,416] [INFO] [runner_train_mujoco] Average state value: 0.4759493407209714
[2022-12-07 11:53:18,416] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 11:53:18,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01244, loss val: 0.04255
[2022-12-07 11:53:18,535] [INFO] [controller] EPOCH 2 loss ppo:  -0.02569, loss val: 0.04154
[2022-12-07 11:53:18,588] [INFO] [controller] EPOCH 3 loss ppo:  -0.03440, loss val: 0.04071
[2022-12-07 11:53:18,641] [INFO] [controller] EPOCH 4 loss ppo:  -0.04568, loss val: 0.04184
[2022-12-07 11:53:18,652] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:53:18,853] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:53:18,853] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:53:25,273] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:53:31,431] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:53:37,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:53:44,014] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:53:50,158] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:53:55,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:54:02,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:54:12,563] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:54:20,341] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:54:26,735] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.197085165425294
[2022-12-07 11:54:26,736] [INFO] [runner_train_mujoco] Average state value: 0.44516841060544055
[2022-12-07 11:54:26,736] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 11:54:26,798] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.06805
[2022-12-07 11:54:26,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.02588, loss val: 0.06753
[2022-12-07 11:54:26,899] [INFO] [controller] EPOCH 3 loss ppo:  -0.03489, loss val: 0.06784
[2022-12-07 11:54:26,954] [INFO] [controller] EPOCH 4 loss ppo:  -0.04384, loss val: 0.06682
[2022-12-07 11:54:26,966] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:54:27,174] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:54:27,174] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:54:35,717] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:54:44,996] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:54:53,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:55:01,496] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:55:11,286] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:55:22,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:55:31,553] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:55:40,715] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:55:47,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:55:54,499] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.425279353445005
[2022-12-07 11:55:54,500] [INFO] [runner_train_mujoco] Average state value: 0.48425671668847403
[2022-12-07 11:55:54,500] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 11:55:54,561] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04937
[2022-12-07 11:55:54,610] [INFO] [controller] EPOCH 2 loss ppo:  -0.02394, loss val: 0.04912
[2022-12-07 11:55:54,658] [INFO] [controller] EPOCH 3 loss ppo:  -0.02687, loss val: 0.04842
[2022-12-07 11:55:54,708] [INFO] [controller] EPOCH 4 loss ppo:  -0.03420, loss val: 0.04865
[2022-12-07 11:55:54,719] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:55:54,918] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:55:54,919] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:56:01,743] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:56:08,929] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:56:15,775] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:56:22,238] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:56:28,671] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:56:35,013] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:56:41,731] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:56:48,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:56:55,012] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:57:02,290] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.594265996211824
[2022-12-07 11:57:02,290] [INFO] [runner_train_mujoco] Average state value: 0.493447367767493
[2022-12-07 11:57:02,290] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 11:57:02,360] [INFO] [controller] EPOCH 1 loss ppo:  -0.01322, loss val: 0.04421
[2022-12-07 11:57:02,411] [INFO] [controller] EPOCH 2 loss ppo:  -0.01985, loss val: 0.04478
[2022-12-07 11:57:02,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.02710, loss val: 0.04313
[2022-12-07 11:57:02,513] [INFO] [controller] EPOCH 4 loss ppo:  -0.03658, loss val: 0.04173
[2022-12-07 11:57:02,525] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:57:02,736] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:57:02,737] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:57:09,528] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:57:16,409] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:57:23,193] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:57:29,750] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:57:36,131] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:57:42,993] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:57:49,799] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:57:56,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:58:03,018] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:58:11,159] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.343627000144744
[2022-12-07 11:58:11,160] [INFO] [runner_train_mujoco] Average state value: 0.48114027357101435
[2022-12-07 11:58:11,160] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 11:58:11,228] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.05250
[2022-12-07 11:58:11,280] [INFO] [controller] EPOCH 2 loss ppo:  -0.02313, loss val: 0.05210
[2022-12-07 11:58:11,338] [INFO] [controller] EPOCH 3 loss ppo:  -0.02970, loss val: 0.05080
[2022-12-07 11:58:11,391] [INFO] [controller] EPOCH 4 loss ppo:  -0.04111, loss val: 0.05086
[2022-12-07 11:58:11,401] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:58:11,615] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:58:11,615] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:58:19,223] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:58:27,097] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:58:33,756] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:58:40,481] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:58:46,496] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:58:52,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:58:58,747] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:59:05,275] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:59:17,051] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:59:26,989] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.866325729508512
[2022-12-07 11:59:26,990] [INFO] [runner_train_mujoco] Average state value: 0.46142479360103605
[2022-12-07 11:59:26,990] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 11:59:27,067] [INFO] [controller] EPOCH 1 loss ppo:  -0.01449, loss val: 0.04789
[2022-12-07 11:59:27,137] [INFO] [controller] EPOCH 2 loss ppo:  -0.02322, loss val: 0.04622
[2022-12-07 11:59:27,201] [INFO] [controller] EPOCH 3 loss ppo:  -0.02724, loss val: 0.04588
[2022-12-07 11:59:27,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.03369, loss val: 0.04504
[2022-12-07 11:59:27,284] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:59:27,520] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:59:27,520] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:59:34,858] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:59:43,260] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:59:50,182] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:59:56,038] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:00:02,310] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:00:08,140] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:00:14,002] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:00:19,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:00:26,019] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:00:34,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.816272999955381
[2022-12-07 12:00:34,149] [INFO] [runner_train_mujoco] Average state value: 0.43533189102013903
[2022-12-07 12:00:34,149] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 12:00:34,212] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.04288
[2022-12-07 12:00:34,261] [INFO] [controller] EPOCH 2 loss ppo:  -0.02006, loss val: 0.04203
[2022-12-07 12:00:34,344] [INFO] [controller] EPOCH 3 loss ppo:  -0.02739, loss val: 0.04349
[2022-12-07 12:00:34,400] [INFO] [controller] EPOCH 4 loss ppo:  -0.03370, loss val: 0.04271
[2022-12-07 12:00:34,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:00:34,636] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:00:34,637] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:00:41,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:00:47,910] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:00:54,213] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:01:00,640] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:01:07,292] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:01:13,855] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:01:19,293] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:01:24,699] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:01:30,486] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:01:36,584] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.903566608992161
[2022-12-07 12:01:36,584] [INFO] [runner_train_mujoco] Average state value: 0.4283082555532456
[2022-12-07 12:01:36,584] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 12:01:36,638] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.05542
[2022-12-07 12:01:36,683] [INFO] [controller] EPOCH 2 loss ppo:  -0.01919, loss val: 0.05502
[2022-12-07 12:01:36,728] [INFO] [controller] EPOCH 3 loss ppo:  -0.02217, loss val: 0.05480
[2022-12-07 12:01:36,773] [INFO] [controller] EPOCH 4 loss ppo:  -0.03006, loss val: 0.05461
[2022-12-07 12:01:36,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:01:36,982] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:01:36,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:01:43,519] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:01:49,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:01:54,965] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:02:01,117] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:02:08,730] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:02:16,904] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:02:23,934] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:02:30,575] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:02:36,914] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:02:43,467] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.9759269902567755
[2022-12-07 12:02:43,467] [INFO] [runner_train_mujoco] Average state value: 0.42896038021643956
[2022-12-07 12:02:43,467] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 12:02:43,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.05338
[2022-12-07 12:02:43,575] [INFO] [controller] EPOCH 2 loss ppo:  -0.01977, loss val: 0.05287
[2022-12-07 12:02:43,627] [INFO] [controller] EPOCH 3 loss ppo:  -0.02737, loss val: 0.05315
[2022-12-07 12:02:43,677] [INFO] [controller] EPOCH 4 loss ppo:  -0.03146, loss val: 0.05493
[2022-12-07 12:02:43,687] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:02:43,888] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:02:43,889] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:02:50,015] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:02:56,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:03:05,333] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:03:13,509] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:03:23,014] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:03:31,861] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:03:40,656] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:03:48,723] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:03:59,947] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:04:12,459] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.322935116644803
[2022-12-07 12:04:12,461] [INFO] [runner_train_mujoco] Average state value: 0.43464321530858674
[2022-12-07 12:04:12,461] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 12:04:12,581] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.05254
[2022-12-07 12:04:12,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.01669, loss val: 0.05219
[2022-12-07 12:04:12,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.02300, loss val: 0.05199
[2022-12-07 12:04:12,899] [INFO] [controller] EPOCH 4 loss ppo:  -0.02798, loss val: 0.05362
[2022-12-07 12:04:12,914] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:04:13,199] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:04:13,202] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:04:23,793] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:04:32,127] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:04:40,440] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:04:48,734] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:04:55,722] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:05:02,144] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:05:08,463] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:05:15,574] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:05:22,108] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:05:28,149] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.268581583980562
[2022-12-07 12:05:28,149] [INFO] [runner_train_mujoco] Average state value: 0.44404433031876883
[2022-12-07 12:05:28,150] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 12:05:28,214] [INFO] [controller] EPOCH 1 loss ppo:  -0.01232, loss val: 0.04691
[2022-12-07 12:05:28,260] [INFO] [controller] EPOCH 2 loss ppo:  -0.01558, loss val: 0.05041
[2022-12-07 12:05:28,318] [INFO] [controller] EPOCH 3 loss ppo:  -0.02052, loss val: 0.05001
[2022-12-07 12:05:28,371] [INFO] [controller] EPOCH 4 loss ppo:  -0.02699, loss val: 0.05034
[2022-12-07 12:05:28,379] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:05:28,603] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:05:28,604] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:05:34,905] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:05:41,420] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:05:48,231] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:05:54,598] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:06:01,306] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:06:08,180] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:06:14,948] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:06:21,356] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:06:29,188] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:06:37,870] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.435465808290308
[2022-12-07 12:06:37,870] [INFO] [runner_train_mujoco] Average state value: 0.44496947385867436
[2022-12-07 12:06:37,870] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 12:06:37,949] [INFO] [controller] EPOCH 1 loss ppo:  -0.01317, loss val: 0.04808
[2022-12-07 12:06:38,037] [INFO] [controller] EPOCH 2 loss ppo:  -0.01682, loss val: 0.04753
[2022-12-07 12:06:38,117] [INFO] [controller] EPOCH 3 loss ppo:  -0.02105, loss val: 0.04672
[2022-12-07 12:06:38,191] [INFO] [controller] EPOCH 4 loss ppo:  -0.02381, loss val: 0.04787
[2022-12-07 12:06:38,205] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:06:38,438] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:06:38,439] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:06:46,194] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:06:53,499] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:07:00,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:07:09,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:07:16,390] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:07:23,332] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:07:30,257] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:07:36,500] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:07:42,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:07:49,429] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.512556589287682
[2022-12-07 12:07:49,429] [INFO] [runner_train_mujoco] Average state value: 0.4429496243000031
[2022-12-07 12:07:49,429] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 12:07:49,487] [INFO] [controller] EPOCH 1 loss ppo:  -0.01283, loss val: 0.05744
[2022-12-07 12:07:49,536] [INFO] [controller] EPOCH 2 loss ppo:  -0.01489, loss val: 0.05925
[2022-12-07 12:07:49,586] [INFO] [controller] EPOCH 3 loss ppo:  -0.01923, loss val: 0.05727
[2022-12-07 12:07:49,639] [INFO] [controller] EPOCH 4 loss ppo:  -0.02409, loss val: 0.05846
[2022-12-07 12:07:49,651] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:07:49,868] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:07:49,868] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:07:56,406] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:08:03,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:08:09,306] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:08:15,124] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:08:21,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:08:28,098] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:08:34,527] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:08:40,474] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:08:45,992] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:08:52,026] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.5331148085029485
[2022-12-07 12:08:52,026] [INFO] [runner_train_mujoco] Average state value: 0.44473360695441555
[2022-12-07 12:08:52,026] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 12:08:52,079] [INFO] [controller] EPOCH 1 loss ppo:  -0.01284, loss val: 0.06042
[2022-12-07 12:08:52,128] [INFO] [controller] EPOCH 2 loss ppo:  -0.01529, loss val: 0.06079
[2022-12-07 12:08:52,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.01844, loss val: 0.06072
[2022-12-07 12:08:52,337] [INFO] [controller] EPOCH 4 loss ppo:  -0.02169, loss val: 0.06184
[2022-12-07 12:08:52,350] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:08:52,558] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:08:52,558] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:08:58,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:09:04,954] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:09:10,918] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:09:17,101] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:09:22,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:09:28,878] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:09:34,652] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:09:40,492] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:09:45,901] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:09:52,256] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.396691700235234
[2022-12-07 12:09:52,256] [INFO] [runner_train_mujoco] Average state value: 0.4457464485963185
[2022-12-07 12:09:52,256] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 12:09:52,323] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04881
[2022-12-07 12:09:52,377] [INFO] [controller] EPOCH 2 loss ppo:  -0.01393, loss val: 0.04935
[2022-12-07 12:09:52,423] [INFO] [controller] EPOCH 3 loss ppo:  -0.01570, loss val: 0.04924
[2022-12-07 12:09:52,474] [INFO] [controller] EPOCH 4 loss ppo:  -0.01791, loss val: 0.04852
[2022-12-07 12:09:52,485] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:09:52,618] [INFO] [optimize] Finished learning.
