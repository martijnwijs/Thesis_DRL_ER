[2022-12-06 13:30:55,825] [INFO] [optimize] Starting learning
[2022-12-06 13:30:55,841] [INFO] [optimize] Starting learning process..
[2022-12-06 13:30:55,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:30:55,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:31:04,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:31:11,069] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:31:18,030] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:31:28,462] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:31:38,129] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:31:46,212] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:31:55,275] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:32:05,599] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:32:14,585] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:32:21,940] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4993216238540885
[2022-12-06 13:32:21,940] [INFO] [runner_train_mujoco] Average state value: -0.11709734882786871
[2022-12-06 13:32:21,941] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 13:32:22,033] [INFO] [controller] EPOCH 1 loss ppo:  -0.01654, loss val: 0.50193
[2022-12-06 13:32:22,085] [INFO] [controller] EPOCH 2 loss ppo:  -0.04300, loss val: 0.44750
[2022-12-06 13:32:22,135] [INFO] [controller] EPOCH 3 loss ppo:  -0.05814, loss val: 0.39169
[2022-12-06 13:32:22,223] [INFO] [controller] EPOCH 4 loss ppo:  -0.06572, loss val: 0.34018
[2022-12-06 13:32:22,236] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:32:22,444] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:32:22,444] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:32:31,511] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:32:39,678] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:32:47,946] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:32:55,828] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:33:03,997] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:33:12,589] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:33:20,889] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:33:29,299] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:33:38,030] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:33:46,712] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44700865470151835
[2022-12-06 13:33:46,713] [INFO] [runner_train_mujoco] Average state value: 0.0690004960509638
[2022-12-06 13:33:46,713] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 13:33:46,794] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.32844
[2022-12-06 13:33:46,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.03802, loss val: 0.28899
[2022-12-06 13:33:46,922] [INFO] [controller] EPOCH 3 loss ppo:  -0.05149, loss val: 0.25074
[2022-12-06 13:33:46,989] [INFO] [controller] EPOCH 4 loss ppo:  -0.05987, loss val: 0.22173
[2022-12-06 13:33:47,003] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:33:47,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:33:47,251] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:33:56,058] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:34:04,930] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:34:13,540] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:34:22,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:34:31,655] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:34:41,017] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:34:50,206] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:34:59,400] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:35:08,763] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:35:18,202] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37457992674124363
[2022-12-06 13:35:18,202] [INFO] [runner_train_mujoco] Average state value: 0.23092247124761345
[2022-12-06 13:35:18,202] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 13:35:18,287] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.16202
[2022-12-06 13:35:18,351] [INFO] [controller] EPOCH 2 loss ppo:  -0.04173, loss val: 0.14481
[2022-12-06 13:35:18,410] [INFO] [controller] EPOCH 3 loss ppo:  -0.05522, loss val: 0.12697
[2022-12-06 13:35:18,487] [INFO] [controller] EPOCH 4 loss ppo:  -0.06347, loss val: 0.11728
[2022-12-06 13:35:18,500] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:35:18,739] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:35:18,740] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:35:28,624] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:35:38,017] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:35:47,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:35:57,135] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:36:06,435] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:36:16,061] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:36:25,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:36:35,442] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:36:45,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:36:54,988] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.41700773902811583
[2022-12-06 13:36:54,989] [INFO] [runner_train_mujoco] Average state value: 0.37679545806037884
[2022-12-06 13:36:54,989] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 13:36:55,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.01135, loss val: 0.11128
[2022-12-06 13:36:55,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03924, loss val: 0.09709
[2022-12-06 13:36:55,302] [INFO] [controller] EPOCH 3 loss ppo:  -0.04937, loss val: 0.08628
[2022-12-06 13:36:55,380] [INFO] [controller] EPOCH 4 loss ppo:  -0.05835, loss val: 0.07753
[2022-12-06 13:36:55,393] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:36:55,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:36:55,675] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:37:05,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:37:15,796] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:37:25,242] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:37:34,587] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:37:43,649] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:37:52,858] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:38:01,853] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:38:11,078] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:38:20,223] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:38:29,330] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.46743465883370733
[2022-12-06 13:38:29,330] [INFO] [runner_train_mujoco] Average state value: 0.5155376941214006
[2022-12-06 13:38:29,330] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 13:38:29,406] [INFO] [controller] EPOCH 1 loss ppo:  -0.01202, loss val: 0.07757
[2022-12-06 13:38:29,480] [INFO] [controller] EPOCH 2 loss ppo:  -0.03674, loss val: 0.06937
[2022-12-06 13:38:29,560] [INFO] [controller] EPOCH 3 loss ppo:  -0.04489, loss val: 0.06317
[2022-12-06 13:38:29,674] [INFO] [controller] EPOCH 4 loss ppo:  -0.05623, loss val: 0.05679
[2022-12-06 13:38:29,685] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:38:29,922] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:38:29,922] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:38:39,047] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:38:48,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:38:56,999] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:39:05,605] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:39:14,155] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:39:22,850] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:39:31,853] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:39:40,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:39:48,530] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:39:57,195] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.43531828967724967
[2022-12-06 13:39:57,196] [INFO] [runner_train_mujoco] Average state value: 0.6149128821268678
[2022-12-06 13:39:57,196] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 13:39:57,253] [INFO] [controller] EPOCH 1 loss ppo:  -0.00899, loss val: 0.06000
[2022-12-06 13:39:57,386] [INFO] [controller] EPOCH 2 loss ppo:  -0.02840, loss val: 0.05725
[2022-12-06 13:39:57,441] [INFO] [controller] EPOCH 3 loss ppo:  -0.04414, loss val: 0.05428
[2022-12-06 13:39:57,530] [INFO] [controller] EPOCH 4 loss ppo:  -0.04818, loss val: 0.05252
[2022-12-06 13:39:57,542] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:39:57,769] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:39:57,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:40:06,904] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:40:16,463] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:40:25,050] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:40:33,613] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:40:41,427] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:40:49,147] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:40:57,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:41:06,122] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:41:14,781] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:41:23,163] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3461914775963333
[2022-12-06 13:41:23,163] [INFO] [runner_train_mujoco] Average state value: 0.6732242868542672
[2022-12-06 13:41:23,164] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 13:41:23,247] [INFO] [controller] EPOCH 1 loss ppo:  -0.01026, loss val: 0.04762
[2022-12-06 13:41:23,323] [INFO] [controller] EPOCH 2 loss ppo:  -0.02782, loss val: 0.04669
[2022-12-06 13:41:23,382] [INFO] [controller] EPOCH 3 loss ppo:  -0.04082, loss val: 0.04408
[2022-12-06 13:41:23,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.04904, loss val: 0.04382
[2022-12-06 13:41:23,479] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:41:23,704] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:41:23,705] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:41:32,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:41:41,141] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:41:49,561] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:41:57,937] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:42:06,560] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:42:15,598] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:42:24,564] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:42:33,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:42:42,375] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:42:51,437] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5678285512352462
[2022-12-06 13:42:51,437] [INFO] [runner_train_mujoco] Average state value: 0.6519782954454423
[2022-12-06 13:42:51,437] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 13:42:51,503] [INFO] [controller] EPOCH 1 loss ppo:  -0.00801, loss val: 0.04862
[2022-12-06 13:42:51,574] [INFO] [controller] EPOCH 2 loss ppo:  -0.02758, loss val: 0.04798
[2022-12-06 13:42:51,635] [INFO] [controller] EPOCH 3 loss ppo:  -0.03840, loss val: 0.04679
[2022-12-06 13:42:51,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.04544, loss val: 0.04547
[2022-12-06 13:42:51,708] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:42:51,948] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:42:51,949] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:43:01,189] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:43:09,763] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:43:18,803] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:43:28,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:43:37,469] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:43:46,185] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:43:55,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:44:04,724] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:44:13,748] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:44:22,991] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5227482538447845
[2022-12-06 13:44:22,991] [INFO] [runner_train_mujoco] Average state value: 0.619015418847402
[2022-12-06 13:44:22,991] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 13:44:23,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.00883, loss val: 0.04938
[2022-12-06 13:44:23,181] [INFO] [controller] EPOCH 2 loss ppo:  -0.02812, loss val: 0.04700
[2022-12-06 13:44:23,258] [INFO] [controller] EPOCH 3 loss ppo:  -0.04375, loss val: 0.04598
[2022-12-06 13:44:23,412] [INFO] [controller] EPOCH 4 loss ppo:  -0.05230, loss val: 0.04561
[2022-12-06 13:44:23,427] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:44:23,680] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:44:23,681] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:44:33,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:44:42,769] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:44:52,315] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:45:01,529] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:45:11,385] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:45:21,647] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:45:31,196] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:45:40,595] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:45:50,001] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:45:59,465] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7522211308475835
[2022-12-06 13:45:59,466] [INFO] [runner_train_mujoco] Average state value: 0.6125913968682288
[2022-12-06 13:45:59,466] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 13:45:59,551] [INFO] [controller] EPOCH 1 loss ppo:  -0.01040, loss val: 0.04718
[2022-12-06 13:45:59,616] [INFO] [controller] EPOCH 2 loss ppo:  -0.03105, loss val: 0.04488
[2022-12-06 13:45:59,675] [INFO] [controller] EPOCH 3 loss ppo:  -0.04447, loss val: 0.04360
[2022-12-06 13:45:59,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.05432, loss val: 0.04303
[2022-12-06 13:45:59,752] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:46:00,012] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:46:00,013] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:46:09,296] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:46:18,087] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:46:26,273] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:46:34,727] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:46:43,975] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:46:52,593] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:47:01,526] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:47:10,266] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:47:19,206] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:47:27,812] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44345034813073125
[2022-12-06 13:47:27,813] [INFO] [runner_train_mujoco] Average state value: 0.6572060494820278
[2022-12-06 13:47:27,813] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 13:47:27,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.00793, loss val: 0.05143
[2022-12-06 13:47:27,931] [INFO] [controller] EPOCH 2 loss ppo:  -0.02537, loss val: 0.05057
[2022-12-06 13:47:27,999] [INFO] [controller] EPOCH 3 loss ppo:  -0.04181, loss val: 0.04593
[2022-12-06 13:47:28,055] [INFO] [controller] EPOCH 4 loss ppo:  -0.05306, loss val: 0.04442
[2022-12-06 13:47:28,065] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:47:28,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:47:28,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:47:37,076] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:47:45,600] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:47:53,686] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:48:02,155] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:48:10,638] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:48:19,145] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:48:27,625] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:48:36,055] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:48:44,074] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:48:52,451] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.43350676915190345
[2022-12-06 13:48:52,451] [INFO] [runner_train_mujoco] Average state value: 0.6167242558399837
[2022-12-06 13:48:52,451] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 13:48:52,515] [INFO] [controller] EPOCH 1 loss ppo:  -0.00969, loss val: 0.03799
[2022-12-06 13:48:52,564] [INFO] [controller] EPOCH 2 loss ppo:  -0.03496, loss val: 0.03894
[2022-12-06 13:48:52,707] [INFO] [controller] EPOCH 3 loss ppo:  -0.04446, loss val: 0.04390
[2022-12-06 13:48:52,757] [INFO] [controller] EPOCH 4 loss ppo:  -0.05342, loss val: 0.03962
[2022-12-06 13:48:52,768] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:48:52,998] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:48:52,998] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:49:01,544] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:49:09,506] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:49:17,748] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:49:26,153] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:49:34,708] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:49:43,262] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:49:51,680] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:49:59,512] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:50:07,982] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:50:16,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7547119157437057
[2022-12-06 13:50:16,291] [INFO] [runner_train_mujoco] Average state value: 0.5789215444525083
[2022-12-06 13:50:16,291] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 13:50:16,534] [INFO] [controller] EPOCH 1 loss ppo:  -0.00982, loss val: 0.03749
[2022-12-06 13:50:16,619] [INFO] [controller] EPOCH 2 loss ppo:  -0.03081, loss val: 0.03718
[2022-12-06 13:50:16,674] [INFO] [controller] EPOCH 3 loss ppo:  -0.04497, loss val: 0.03965
[2022-12-06 13:50:16,729] [INFO] [controller] EPOCH 4 loss ppo:  -0.05212, loss val: 0.03590
[2022-12-06 13:50:16,739] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:50:16,975] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:50:16,975] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:50:25,352] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:50:34,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:50:42,335] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:50:51,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:50:59,835] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:51:08,282] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:51:17,373] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:51:25,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:51:34,160] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:51:42,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8479444335094835
[2022-12-06 13:51:42,747] [INFO] [runner_train_mujoco] Average state value: 0.6243803728818893
[2022-12-06 13:51:42,747] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 13:51:42,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01024, loss val: 0.03872
[2022-12-06 13:51:42,866] [INFO] [controller] EPOCH 2 loss ppo:  -0.03517, loss val: 0.03890
[2022-12-06 13:51:42,928] [INFO] [controller] EPOCH 3 loss ppo:  -0.04892, loss val: 0.04031
[2022-12-06 13:51:42,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.05776, loss val: 0.04060
[2022-12-06 13:51:42,994] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:51:43,217] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:51:43,217] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:51:52,039] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:52:01,156] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:52:10,373] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:52:19,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:52:29,327] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:52:38,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:52:47,439] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:52:56,907] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:53:05,963] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:53:15,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7329470775009875
[2022-12-06 13:53:15,105] [INFO] [runner_train_mujoco] Average state value: 0.638302682141463
[2022-12-06 13:53:15,105] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 13:53:15,174] [INFO] [controller] EPOCH 1 loss ppo:  -0.00867, loss val: 0.03648
[2022-12-06 13:53:15,244] [INFO] [controller] EPOCH 2 loss ppo:  -0.03186, loss val: 0.03724
[2022-12-06 13:53:15,304] [INFO] [controller] EPOCH 3 loss ppo:  -0.04465, loss val: 0.03544
[2022-12-06 13:53:15,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.05292, loss val: 0.03556
[2022-12-06 13:53:15,389] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:53:15,646] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:53:15,647] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:53:25,765] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:53:34,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:53:44,755] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:53:53,989] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:54:03,463] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:54:12,742] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:54:21,662] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:54:30,389] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:54:39,189] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:54:47,815] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7936429052530789
[2022-12-06 13:54:47,815] [INFO] [runner_train_mujoco] Average state value: 0.6218357761104901
[2022-12-06 13:54:47,815] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 13:54:47,905] [INFO] [controller] EPOCH 1 loss ppo:  -0.01040, loss val: 0.03862
[2022-12-06 13:54:47,982] [INFO] [controller] EPOCH 2 loss ppo:  -0.03609, loss val: 0.03685
[2022-12-06 13:54:48,072] [INFO] [controller] EPOCH 3 loss ppo:  -0.04484, loss val: 0.03738
[2022-12-06 13:54:48,161] [INFO] [controller] EPOCH 4 loss ppo:  -0.05677, loss val: 0.03949
[2022-12-06 13:54:48,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:54:48,418] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:54:48,419] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:54:57,601] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:55:06,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:55:15,753] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:55:24,899] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:55:33,438] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:55:41,795] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:55:50,153] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:55:58,610] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:56:07,099] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:56:15,475] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8424342751050835
[2022-12-06 13:56:15,475] [INFO] [runner_train_mujoco] Average state value: 0.5956727872689564
[2022-12-06 13:56:15,475] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 13:56:15,535] [INFO] [controller] EPOCH 1 loss ppo:  -0.01011, loss val: 0.03271
[2022-12-06 13:56:15,587] [INFO] [controller] EPOCH 2 loss ppo:  -0.03400, loss val: 0.03246
[2022-12-06 13:56:15,637] [INFO] [controller] EPOCH 3 loss ppo:  -0.04579, loss val: 0.03296
[2022-12-06 13:56:15,696] [INFO] [controller] EPOCH 4 loss ppo:  -0.05599, loss val: 0.03299
[2022-12-06 13:56:15,708] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:56:15,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:56:15,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:56:24,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:56:33,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:56:41,907] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:56:50,235] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:56:58,137] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:57:05,950] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:57:13,720] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:57:22,165] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:57:30,569] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:57:39,106] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8550233886328993
[2022-12-06 13:57:39,106] [INFO] [runner_train_mujoco] Average state value: 0.5756588313579559
[2022-12-06 13:57:39,106] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 13:57:39,164] [INFO] [controller] EPOCH 1 loss ppo:  -0.01157, loss val: 0.04030
[2022-12-06 13:57:39,216] [INFO] [controller] EPOCH 2 loss ppo:  -0.03624, loss val: 0.03851
[2022-12-06 13:57:39,270] [INFO] [controller] EPOCH 3 loss ppo:  -0.04395, loss val: 0.03848
[2022-12-06 13:57:39,361] [INFO] [controller] EPOCH 4 loss ppo:  -0.05348, loss val: 0.03840
[2022-12-06 13:57:39,373] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:57:39,592] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:57:39,593] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:57:47,473] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:57:56,391] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 13:58:06,002] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 13:58:18,575] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 13:58:29,766] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 13:58:38,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 13:58:51,059] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 13:59:04,103] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 13:59:15,257] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 13:59:26,383] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8652020140211633
[2022-12-06 13:59:26,383] [INFO] [runner_train_mujoco] Average state value: 0.5745764354864755
[2022-12-06 13:59:26,383] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 13:59:26,483] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.03518
[2022-12-06 13:59:26,553] [INFO] [controller] EPOCH 2 loss ppo:  -0.03808, loss val: 0.03403
[2022-12-06 13:59:26,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.04679, loss val: 0.03533
[2022-12-06 13:59:26,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.05484, loss val: 0.03405
[2022-12-06 13:59:26,715] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 13:59:27,010] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 13:59:27,011] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 13:59:39,468] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 13:59:51,188] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:00:01,025] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:00:10,569] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:00:20,909] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:00:31,125] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:00:42,593] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:00:57,213] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:01:10,426] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:01:23,951] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0275428547658563
[2022-12-06 14:01:23,952] [INFO] [runner_train_mujoco] Average state value: 0.5832633959452311
[2022-12-06 14:01:23,952] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 14:01:24,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.03689
[2022-12-06 14:01:24,930] [INFO] [controller] EPOCH 2 loss ppo:  -0.03028, loss val: 0.03677
[2022-12-06 14:01:25,027] [INFO] [controller] EPOCH 3 loss ppo:  -0.04428, loss val: 0.03408
[2022-12-06 14:01:25,113] [INFO] [controller] EPOCH 4 loss ppo:  -0.05260, loss val: 0.03493
[2022-12-06 14:01:25,137] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:01:25,477] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:01:25,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:01:39,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:01:55,449] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:02:05,978] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:02:16,329] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:02:27,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:02:38,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:02:48,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:02:58,620] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:03:09,364] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:03:20,317] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0639582587895764
[2022-12-06 14:03:20,317] [INFO] [runner_train_mujoco] Average state value: 0.5400072040955225
[2022-12-06 14:03:20,317] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 14:03:20,448] [INFO] [controller] EPOCH 1 loss ppo:  -0.01158, loss val: 0.04165
[2022-12-06 14:03:20,588] [INFO] [controller] EPOCH 2 loss ppo:  -0.03347, loss val: 0.04216
[2022-12-06 14:03:20,717] [INFO] [controller] EPOCH 3 loss ppo:  -0.04598, loss val: 0.04236
[2022-12-06 14:03:20,871] [INFO] [controller] EPOCH 4 loss ppo:  -0.05177, loss val: 0.04243
[2022-12-06 14:03:20,890] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:03:21,188] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:03:21,188] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:03:31,355] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:03:40,317] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:03:49,905] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:03:59,487] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:04:08,347] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:04:17,602] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:04:26,839] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:04:36,084] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:04:44,754] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:04:53,846] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.2151367751912723
[2022-12-06 14:04:53,846] [INFO] [runner_train_mujoco] Average state value: 0.5544174085855484
[2022-12-06 14:04:53,846] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 14:04:53,908] [INFO] [controller] EPOCH 1 loss ppo:  -0.01229, loss val: 0.03528
[2022-12-06 14:04:53,958] [INFO] [controller] EPOCH 2 loss ppo:  -0.03474, loss val: 0.03633
[2022-12-06 14:04:54,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.04856, loss val: 0.03547
[2022-12-06 14:04:54,061] [INFO] [controller] EPOCH 4 loss ppo:  -0.05821, loss val: 0.03651
[2022-12-06 14:04:54,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:04:54,313] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:04:54,313] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:05:02,820] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:05:11,937] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:05:19,960] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:05:29,588] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:05:39,311] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:05:48,383] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:05:56,587] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:06:04,769] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:06:13,896] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:06:24,364] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.32326347038942
[2022-12-06 14:06:24,369] [INFO] [runner_train_mujoco] Average state value: 0.5471888512273629
[2022-12-06 14:06:24,370] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 14:06:24,746] [INFO] [controller] EPOCH 1 loss ppo:  -0.01141, loss val: 0.03846
[2022-12-06 14:06:24,865] [INFO] [controller] EPOCH 2 loss ppo:  -0.03091, loss val: 0.03728
[2022-12-06 14:06:25,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.04648, loss val: 0.03783
[2022-12-06 14:06:25,182] [INFO] [controller] EPOCH 4 loss ppo:  -0.05810, loss val: 0.03806
[2022-12-06 14:06:25,197] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:06:25,541] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:06:25,549] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:06:38,010] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:06:48,873] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:07:01,188] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:07:14,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:07:23,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:07:36,773] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:07:48,640] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:07:57,524] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:08:06,253] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:08:15,365] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5345600497854184
[2022-12-06 14:08:15,365] [INFO] [runner_train_mujoco] Average state value: 0.5602339688539505
[2022-12-06 14:08:15,366] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 14:08:15,488] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.03824
[2022-12-06 14:08:15,642] [INFO] [controller] EPOCH 2 loss ppo:  -0.03967, loss val: 0.03838
[2022-12-06 14:08:15,733] [INFO] [controller] EPOCH 3 loss ppo:  -0.04841, loss val: 0.03938
[2022-12-06 14:08:15,812] [INFO] [controller] EPOCH 4 loss ppo:  -0.05797, loss val: 0.03879
[2022-12-06 14:08:15,824] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:08:16,058] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:08:16,059] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:08:25,452] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:08:34,598] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:08:44,447] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:08:53,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:09:01,600] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:09:11,142] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:09:20,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:09:29,797] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:09:39,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:09:48,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.6661006307954758
[2022-12-06 14:09:48,050] [INFO] [runner_train_mujoco] Average state value: 0.553660284380118
[2022-12-06 14:09:48,050] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 14:09:48,117] [INFO] [controller] EPOCH 1 loss ppo:  -0.01452, loss val: 0.03675
[2022-12-06 14:09:48,188] [INFO] [controller] EPOCH 2 loss ppo:  -0.03678, loss val: 0.03429
[2022-12-06 14:09:48,330] [INFO] [controller] EPOCH 3 loss ppo:  -0.05197, loss val: 0.03539
[2022-12-06 14:09:48,404] [INFO] [controller] EPOCH 4 loss ppo:  -0.06221, loss val: 0.03710
[2022-12-06 14:09:48,422] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:09:48,641] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:09:48,642] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:09:58,475] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:10:08,194] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:10:17,917] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:10:27,491] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:10:36,386] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:10:45,258] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:10:54,409] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:11:03,399] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:11:12,717] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:11:22,009] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.813333106398361
[2022-12-06 14:11:22,009] [INFO] [runner_train_mujoco] Average state value: 0.5411768469611803
[2022-12-06 14:11:22,010] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 14:11:22,106] [INFO] [controller] EPOCH 1 loss ppo:  -0.01485, loss val: 0.03850
[2022-12-06 14:11:22,178] [INFO] [controller] EPOCH 2 loss ppo:  -0.03443, loss val: 0.03875
[2022-12-06 14:11:22,253] [INFO] [controller] EPOCH 3 loss ppo:  -0.04417, loss val: 0.03747
[2022-12-06 14:11:22,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.05603, loss val: 0.03817
[2022-12-06 14:11:22,352] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:11:22,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:11:22,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:11:32,408] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:11:41,664] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:11:50,264] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:11:59,291] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:12:08,112] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:12:16,385] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:12:24,434] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:12:33,059] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:12:41,537] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:12:50,771] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9762031875099777
[2022-12-06 14:12:50,772] [INFO] [runner_train_mujoco] Average state value: 0.5607926099697749
[2022-12-06 14:12:50,772] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 14:12:50,848] [INFO] [controller] EPOCH 1 loss ppo:  -0.01369, loss val: 0.03953
[2022-12-06 14:12:50,905] [INFO] [controller] EPOCH 2 loss ppo:  -0.03383, loss val: 0.03928
[2022-12-06 14:12:50,975] [INFO] [controller] EPOCH 3 loss ppo:  -0.04489, loss val: 0.03988
[2022-12-06 14:12:51,036] [INFO] [controller] EPOCH 4 loss ppo:  -0.05553, loss val: 0.03949
[2022-12-06 14:12:51,047] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:12:51,281] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:12:51,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:13:00,254] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:13:08,480] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:13:16,702] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:13:25,129] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:13:33,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:13:41,450] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:13:49,476] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:13:57,683] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:14:06,150] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:14:15,471] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3869967237338807
[2022-12-06 14:14:15,471] [INFO] [runner_train_mujoco] Average state value: 0.564262617657582
[2022-12-06 14:14:15,471] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 14:14:15,540] [INFO] [controller] EPOCH 1 loss ppo:  -0.01320, loss val: 0.04300
[2022-12-06 14:14:15,598] [INFO] [controller] EPOCH 2 loss ppo:  -0.03257, loss val: 0.04006
[2022-12-06 14:14:15,672] [INFO] [controller] EPOCH 3 loss ppo:  -0.04483, loss val: 0.03818
[2022-12-06 14:14:15,769] [INFO] [controller] EPOCH 4 loss ppo:  -0.05321, loss val: 0.03644
[2022-12-06 14:14:15,789] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:14:16,026] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:14:16,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:14:25,462] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:14:34,638] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:14:43,363] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:14:51,513] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:14:59,768] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:15:08,663] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:15:18,480] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:15:28,380] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:15:37,935] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:15:47,506] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.140934441267434
[2022-12-06 14:15:47,506] [INFO] [runner_train_mujoco] Average state value: 0.5056157688299815
[2022-12-06 14:15:47,506] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 14:15:47,584] [INFO] [controller] EPOCH 1 loss ppo:  -0.01386, loss val: 0.03891
[2022-12-06 14:15:47,639] [INFO] [controller] EPOCH 2 loss ppo:  -0.03452, loss val: 0.03575
[2022-12-06 14:15:47,699] [INFO] [controller] EPOCH 3 loss ppo:  -0.04913, loss val: 0.03837
[2022-12-06 14:15:47,763] [INFO] [controller] EPOCH 4 loss ppo:  -0.06378, loss val: 0.03850
[2022-12-06 14:15:47,781] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:15:48,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:15:48,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:15:57,901] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:16:08,306] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:16:20,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:16:32,251] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:16:43,014] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:16:56,529] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:17:06,880] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:17:16,967] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:17:26,692] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:17:36,388] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7189864964719934
[2022-12-06 14:17:36,388] [INFO] [runner_train_mujoco] Average state value: 0.45601981959740323
[2022-12-06 14:17:36,388] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 14:17:36,605] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.05778
[2022-12-06 14:17:36,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.02531, loss val: 0.05698
[2022-12-06 14:17:36,859] [INFO] [controller] EPOCH 3 loss ppo:  -0.03628, loss val: 0.05726
[2022-12-06 14:17:36,945] [INFO] [controller] EPOCH 4 loss ppo:  -0.04655, loss val: 0.04985
[2022-12-06 14:17:36,957] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:17:37,209] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:17:37,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:17:46,906] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:17:57,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:18:06,747] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:18:16,546] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:18:27,424] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:18:37,524] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:18:48,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:18:58,601] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:19:09,013] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:19:19,157] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8221263743878184
[2022-12-06 14:19:19,158] [INFO] [runner_train_mujoco] Average state value: 0.498196680645148
[2022-12-06 14:19:19,158] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 14:19:19,229] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.04244
[2022-12-06 14:19:19,294] [INFO] [controller] EPOCH 2 loss ppo:  -0.02988, loss val: 0.04366
[2022-12-06 14:19:19,357] [INFO] [controller] EPOCH 3 loss ppo:  -0.04460, loss val: 0.04444
[2022-12-06 14:19:19,419] [INFO] [controller] EPOCH 4 loss ppo:  -0.05547, loss val: 0.04426
[2022-12-06 14:19:19,433] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:19:19,674] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:19:19,674] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:19:29,265] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:19:39,334] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:19:49,062] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:19:58,044] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:20:07,735] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:20:17,930] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:20:27,552] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:20:36,844] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:20:46,526] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:20:55,348] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.848155586992862
[2022-12-06 14:20:55,348] [INFO] [runner_train_mujoco] Average state value: 0.5199052111109097
[2022-12-06 14:20:55,349] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 14:20:55,415] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.04014
[2022-12-06 14:20:55,469] [INFO] [controller] EPOCH 2 loss ppo:  -0.03655, loss val: 0.03945
[2022-12-06 14:20:55,526] [INFO] [controller] EPOCH 3 loss ppo:  -0.04967, loss val: 0.03882
[2022-12-06 14:20:55,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.05809, loss val: 0.03955
[2022-12-06 14:20:55,590] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:20:55,813] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:20:55,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:21:05,720] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:21:17,087] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:21:28,630] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:21:39,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:21:51,488] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:22:00,795] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:22:09,451] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:22:17,824] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:22:26,484] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:22:35,008] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.189057513888722
[2022-12-06 14:22:35,009] [INFO] [runner_train_mujoco] Average state value: 0.4963953007857005
[2022-12-06 14:22:35,009] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 14:22:35,145] [INFO] [controller] EPOCH 1 loss ppo:  -0.01592, loss val: 0.03905
[2022-12-06 14:22:35,203] [INFO] [controller] EPOCH 2 loss ppo:  -0.03483, loss val: 0.03725
[2022-12-06 14:22:35,269] [INFO] [controller] EPOCH 3 loss ppo:  -0.04702, loss val: 0.03788
[2022-12-06 14:22:35,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.05940, loss val: 0.03774
[2022-12-06 14:22:35,352] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:22:35,581] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:22:35,581] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:22:45,123] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:22:54,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:23:03,896] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:23:13,132] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:23:22,847] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:23:32,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:23:41,044] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:23:49,893] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:23:58,601] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:24:07,513] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3248723099089887
[2022-12-06 14:24:07,513] [INFO] [runner_train_mujoco] Average state value: 0.46987419472138087
[2022-12-06 14:24:07,513] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 14:24:07,587] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04920
[2022-12-06 14:24:07,659] [INFO] [controller] EPOCH 2 loss ppo:  -0.02697, loss val: 0.04914
[2022-12-06 14:24:07,743] [INFO] [controller] EPOCH 3 loss ppo:  -0.03624, loss val: 0.04847
[2022-12-06 14:24:07,795] [INFO] [controller] EPOCH 4 loss ppo:  -0.04554, loss val: 0.04705
[2022-12-06 14:24:07,806] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:24:08,027] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:24:08,027] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:24:17,761] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:24:28,098] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:24:37,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:24:46,265] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:24:54,875] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:25:05,940] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:25:16,198] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:25:26,499] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:25:38,290] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:25:48,420] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.5837430260561733
[2022-12-06 14:25:48,421] [INFO] [runner_train_mujoco] Average state value: 0.4881541231572628
[2022-12-06 14:25:48,421] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 14:25:48,541] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.03950
[2022-12-06 14:25:48,643] [INFO] [controller] EPOCH 2 loss ppo:  -0.03132, loss val: 0.03785
[2022-12-06 14:25:48,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.04637, loss val: 0.03790
[2022-12-06 14:25:48,795] [INFO] [controller] EPOCH 4 loss ppo:  -0.05729, loss val: 0.03649
[2022-12-06 14:25:48,811] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:25:49,077] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:25:49,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:26:00,819] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:26:11,521] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:26:22,903] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:26:36,018] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:26:47,945] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:26:57,913] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:27:08,013] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:27:18,154] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:27:28,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:27:39,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3198651167715596
[2022-12-06 14:27:39,643] [INFO] [runner_train_mujoco] Average state value: 0.5347076779405276
[2022-12-06 14:27:39,643] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 14:27:39,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01488, loss val: 0.05033
[2022-12-06 14:27:39,864] [INFO] [controller] EPOCH 2 loss ppo:  -0.03452, loss val: 0.04888
[2022-12-06 14:27:39,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.04325, loss val: 0.04958
[2022-12-06 14:27:39,999] [INFO] [controller] EPOCH 4 loss ppo:  -0.05496, loss val: 0.04914
[2022-12-06 14:27:40,012] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:27:40,262] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:27:40,262] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:27:51,505] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:28:02,690] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:28:16,017] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:28:29,811] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:28:41,649] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:28:53,081] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:29:05,026] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:29:15,801] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:29:27,146] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:29:38,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6622874052840273
[2022-12-06 14:29:38,769] [INFO] [runner_train_mujoco] Average state value: 0.5746411887009939
[2022-12-06 14:29:38,769] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 14:29:38,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.04761
[2022-12-06 14:29:38,946] [INFO] [controller] EPOCH 2 loss ppo:  -0.02822, loss val: 0.04838
[2022-12-06 14:29:39,047] [INFO] [controller] EPOCH 3 loss ppo:  -0.04039, loss val: 0.04781
[2022-12-06 14:29:39,137] [INFO] [controller] EPOCH 4 loss ppo:  -0.05086, loss val: 0.04811
[2022-12-06 14:29:39,152] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:29:39,479] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:29:39,479] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:29:52,607] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:30:04,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:30:16,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:30:29,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:30:42,369] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:30:55,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:31:08,137] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:31:18,996] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:31:30,317] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:31:43,156] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.827755163002885
[2022-12-06 14:31:43,156] [INFO] [runner_train_mujoco] Average state value: 0.5794551294843355
[2022-12-06 14:31:43,157] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 14:31:43,317] [INFO] [controller] EPOCH 1 loss ppo:  -0.01315, loss val: 0.04443
[2022-12-06 14:31:43,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.02741, loss val: 0.04060
[2022-12-06 14:31:43,731] [INFO] [controller] EPOCH 3 loss ppo:  -0.04000, loss val: 0.04362
[2022-12-06 14:31:43,921] [INFO] [controller] EPOCH 4 loss ppo:  -0.04960, loss val: 0.03977
[2022-12-06 14:31:43,937] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:31:44,225] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:31:44,226] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:31:56,362] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:32:07,557] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:32:18,668] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:32:28,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:32:39,398] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:32:50,230] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:33:00,500] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:33:10,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:33:19,884] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:33:29,783] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.797306902014802
[2022-12-06 14:33:29,783] [INFO] [runner_train_mujoco] Average state value: 0.560658184548219
[2022-12-06 14:33:29,783] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 14:33:29,881] [INFO] [controller] EPOCH 1 loss ppo:  -0.01400, loss val: 0.04814
[2022-12-06 14:33:29,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.02922, loss val: 0.04870
[2022-12-06 14:33:30,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.03915, loss val: 0.04768
[2022-12-06 14:33:30,067] [INFO] [controller] EPOCH 4 loss ppo:  -0.05055, loss val: 0.04752
[2022-12-06 14:33:30,079] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:33:30,350] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:33:30,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:33:40,662] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:33:50,312] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:34:00,001] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:34:10,171] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:34:20,638] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:34:30,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:34:40,416] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:34:51,618] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:35:02,977] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:35:12,847] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8926613059341797
[2022-12-06 14:35:12,848] [INFO] [runner_train_mujoco] Average state value: 0.5379687647223472
[2022-12-06 14:35:12,848] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 14:35:12,996] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04204
[2022-12-06 14:35:13,166] [INFO] [controller] EPOCH 2 loss ppo:  -0.02675, loss val: 0.04146
[2022-12-06 14:35:13,313] [INFO] [controller] EPOCH 3 loss ppo:  -0.03982, loss val: 0.04376
[2022-12-06 14:35:13,410] [INFO] [controller] EPOCH 4 loss ppo:  -0.05037, loss val: 0.04541
[2022-12-06 14:35:13,425] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:35:13,698] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:35:13,698] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:35:24,057] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:35:34,469] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:35:43,877] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:35:53,368] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:36:01,918] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:36:10,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:36:22,085] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:36:31,738] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:36:40,610] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:36:49,133] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9873102494591555
[2022-12-06 14:36:49,134] [INFO] [runner_train_mujoco] Average state value: 0.5288751232624055
[2022-12-06 14:36:49,134] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 14:36:49,204] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.05540
[2022-12-06 14:36:49,257] [INFO] [controller] EPOCH 2 loss ppo:  -0.02759, loss val: 0.05499
[2022-12-06 14:36:49,321] [INFO] [controller] EPOCH 3 loss ppo:  -0.03870, loss val: 0.05440
[2022-12-06 14:36:49,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.04971, loss val: 0.05368
[2022-12-06 14:36:49,400] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:36:49,613] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:36:49,613] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:36:57,793] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:37:06,496] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:37:15,325] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:37:24,257] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:37:33,018] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:37:40,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:37:49,968] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:37:58,979] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:38:08,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:38:19,808] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.164124212910401
[2022-12-06 14:38:19,808] [INFO] [runner_train_mujoco] Average state value: 0.5508760478496552
[2022-12-06 14:38:19,808] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 14:38:19,878] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04604
[2022-12-06 14:38:19,984] [INFO] [controller] EPOCH 2 loss ppo:  -0.02787, loss val: 0.04728
[2022-12-06 14:38:20,054] [INFO] [controller] EPOCH 3 loss ppo:  -0.03729, loss val: 0.04493
[2022-12-06 14:38:20,111] [INFO] [controller] EPOCH 4 loss ppo:  -0.04638, loss val: 0.04556
[2022-12-06 14:38:20,123] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:38:20,374] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:38:20,374] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:38:29,568] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:38:38,571] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:38:47,571] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:38:55,924] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:39:04,565] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:39:13,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:39:23,065] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:39:32,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:39:41,531] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:39:51,200] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.067581930738596
[2022-12-06 14:39:51,200] [INFO] [runner_train_mujoco] Average state value: 0.562483680009842
[2022-12-06 14:39:51,200] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 14:39:51,300] [INFO] [controller] EPOCH 1 loss ppo:  -0.01462, loss val: 0.04821
[2022-12-06 14:39:51,375] [INFO] [controller] EPOCH 2 loss ppo:  -0.02953, loss val: 0.04762
[2022-12-06 14:39:51,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.03831, loss val: 0.04922
[2022-12-06 14:39:51,497] [INFO] [controller] EPOCH 4 loss ppo:  -0.04872, loss val: 0.04763
[2022-12-06 14:39:51,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:39:51,779] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:39:51,780] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:40:01,774] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:40:11,147] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:40:21,043] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:40:30,785] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:40:40,476] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:40:50,778] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:41:01,463] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:41:12,453] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:41:21,946] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:41:31,578] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.0528155103877
[2022-12-06 14:41:31,579] [INFO] [runner_train_mujoco] Average state value: 0.5438442910710971
[2022-12-06 14:41:31,579] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 14:41:31,645] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.04222
[2022-12-06 14:41:31,710] [INFO] [controller] EPOCH 2 loss ppo:  -0.02571, loss val: 0.04119
[2022-12-06 14:41:31,769] [INFO] [controller] EPOCH 3 loss ppo:  -0.03771, loss val: 0.04090
[2022-12-06 14:41:31,826] [INFO] [controller] EPOCH 4 loss ppo:  -0.04813, loss val: 0.04282
[2022-12-06 14:41:31,839] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:41:32,065] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:41:32,065] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:41:41,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:41:50,311] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:41:59,487] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:42:08,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:42:18,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:42:27,428] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:42:37,656] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:42:47,565] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:42:56,944] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:43:06,639] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.2538701452242025
[2022-12-06 14:43:06,639] [INFO] [runner_train_mujoco] Average state value: 0.5168749404748281
[2022-12-06 14:43:06,639] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 14:43:06,705] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04947
[2022-12-06 14:43:06,799] [INFO] [controller] EPOCH 2 loss ppo:  -0.02706, loss val: 0.04920
[2022-12-06 14:43:06,872] [INFO] [controller] EPOCH 3 loss ppo:  -0.03753, loss val: 0.04966
[2022-12-06 14:43:06,971] [INFO] [controller] EPOCH 4 loss ppo:  -0.04395, loss val: 0.04994
[2022-12-06 14:43:06,983] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:43:07,237] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:43:07,237] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:43:16,526] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:43:27,749] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:43:36,160] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:43:44,875] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:43:53,643] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:44:02,760] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:44:11,330] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:44:19,711] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:44:28,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:44:36,947] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.190925177679749
[2022-12-06 14:44:36,948] [INFO] [runner_train_mujoco] Average state value: 0.5074053205450376
[2022-12-06 14:44:36,948] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 14:44:37,060] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.04220
[2022-12-06 14:44:37,149] [INFO] [controller] EPOCH 2 loss ppo:  -0.02562, loss val: 0.04173
[2022-12-06 14:44:37,284] [INFO] [controller] EPOCH 3 loss ppo:  -0.03421, loss val: 0.04123
[2022-12-06 14:44:37,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.04159, loss val: 0.04168
[2022-12-06 14:44:37,353] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:44:37,600] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:44:37,600] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:44:46,158] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:44:55,335] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:45:04,818] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:45:14,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:45:24,806] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:45:33,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:45:42,622] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:45:51,805] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:46:01,169] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:46:10,427] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.341466506201117
[2022-12-06 14:46:10,428] [INFO] [runner_train_mujoco] Average state value: 0.5048536770542462
[2022-12-06 14:46:10,428] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 14:46:10,500] [INFO] [controller] EPOCH 1 loss ppo:  -0.01397, loss val: 0.04542
[2022-12-06 14:46:10,560] [INFO] [controller] EPOCH 2 loss ppo:  -0.02501, loss val: 0.04554
[2022-12-06 14:46:10,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.03516, loss val: 0.04584
[2022-12-06 14:46:10,677] [INFO] [controller] EPOCH 4 loss ppo:  -0.04133, loss val: 0.04520
[2022-12-06 14:46:10,692] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:46:10,966] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:46:10,967] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:46:20,044] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:46:29,738] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:46:39,464] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:46:49,035] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:46:58,536] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:47:08,264] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:47:18,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:47:28,062] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:47:37,554] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:47:47,061] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.53017900621034
[2022-12-06 14:47:47,061] [INFO] [runner_train_mujoco] Average state value: 0.5101799698869388
[2022-12-06 14:47:47,061] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 14:47:47,167] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.05671
[2022-12-06 14:47:47,229] [INFO] [controller] EPOCH 2 loss ppo:  -0.02568, loss val: 0.05707
[2022-12-06 14:47:47,306] [INFO] [controller] EPOCH 3 loss ppo:  -0.03503, loss val: 0.05648
[2022-12-06 14:47:47,379] [INFO] [controller] EPOCH 4 loss ppo:  -0.04224, loss val: 0.05785
[2022-12-06 14:47:47,392] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:47:47,644] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:47:47,645] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:47:57,226] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:48:06,809] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:48:15,866] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:48:25,038] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:48:33,828] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:48:42,588] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:48:51,829] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:49:01,282] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:49:10,584] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:49:19,851] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.627313487471367
[2022-12-06 14:49:19,851] [INFO] [runner_train_mujoco] Average state value: 0.5169434034824373
[2022-12-06 14:49:19,851] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 14:49:19,917] [INFO] [controller] EPOCH 1 loss ppo:  -0.01460, loss val: 0.04688
[2022-12-06 14:49:19,976] [INFO] [controller] EPOCH 2 loss ppo:  -0.02202, loss val: 0.04676
[2022-12-06 14:49:20,033] [INFO] [controller] EPOCH 3 loss ppo:  -0.02689, loss val: 0.04675
[2022-12-06 14:49:20,106] [INFO] [controller] EPOCH 4 loss ppo:  -0.03379, loss val: 0.04667
[2022-12-06 14:49:20,118] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:49:20,369] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:49:20,369] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:49:29,681] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:49:38,625] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:49:46,840] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:49:55,168] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:50:03,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:50:11,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:50:20,109] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:50:28,321] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:50:36,355] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:50:45,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.712142309410611
[2022-12-06 14:50:45,115] [INFO] [runner_train_mujoco] Average state value: 0.5228698851068814
[2022-12-06 14:50:45,116] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 14:50:45,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01405, loss val: 0.04965
[2022-12-06 14:50:45,281] [INFO] [controller] EPOCH 2 loss ppo:  -0.02229, loss val: 0.05007
[2022-12-06 14:50:45,381] [INFO] [controller] EPOCH 3 loss ppo:  -0.02817, loss val: 0.04978
[2022-12-06 14:50:45,485] [INFO] [controller] EPOCH 4 loss ppo:  -0.03561, loss val: 0.04979
[2022-12-06 14:50:45,502] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:50:45,752] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:50:45,753] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:50:55,130] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:51:03,924] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:51:12,875] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:51:21,593] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:51:30,091] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:51:38,389] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:51:46,604] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:51:54,795] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:52:03,875] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:52:13,044] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.536317823037579
[2022-12-06 14:52:13,044] [INFO] [runner_train_mujoco] Average state value: 0.5266679075360299
[2022-12-06 14:52:13,044] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 14:52:13,120] [INFO] [controller] EPOCH 1 loss ppo:  -0.01340, loss val: 0.04510
[2022-12-06 14:52:13,176] [INFO] [controller] EPOCH 2 loss ppo:  -0.02051, loss val: 0.04570
[2022-12-06 14:52:13,246] [INFO] [controller] EPOCH 3 loss ppo:  -0.02974, loss val: 0.04494
[2022-12-06 14:52:13,315] [INFO] [controller] EPOCH 4 loss ppo:  -0.03563, loss val: 0.04486
[2022-12-06 14:52:13,326] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:52:13,557] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:52:13,558] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:52:21,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:52:31,016] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:52:39,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:52:48,298] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:52:57,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:53:06,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:53:15,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:53:27,178] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:53:36,612] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:53:45,512] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.758734846020047
[2022-12-06 14:53:45,512] [INFO] [runner_train_mujoco] Average state value: 0.5305127936204275
[2022-12-06 14:53:45,512] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 14:53:45,590] [INFO] [controller] EPOCH 1 loss ppo:  -0.01411, loss val: 0.05118
[2022-12-06 14:53:45,666] [INFO] [controller] EPOCH 2 loss ppo:  -0.02126, loss val: 0.05122
[2022-12-06 14:53:45,746] [INFO] [controller] EPOCH 3 loss ppo:  -0.02919, loss val: 0.05074
[2022-12-06 14:53:45,807] [INFO] [controller] EPOCH 4 loss ppo:  -0.03548, loss val: 0.05230
[2022-12-06 14:53:45,818] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:53:46,072] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:53:46,072] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:53:54,548] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:54:03,965] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:54:13,065] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:54:23,507] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:54:33,284] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:54:42,579] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:54:52,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:55:01,841] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:55:11,306] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:55:20,435] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.663243332884961
[2022-12-06 14:55:20,435] [INFO] [runner_train_mujoco] Average state value: 0.5287355344891548
[2022-12-06 14:55:20,436] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 14:55:20,525] [INFO] [controller] EPOCH 1 loss ppo:  -0.01375, loss val: 0.04432
[2022-12-06 14:55:20,618] [INFO] [controller] EPOCH 2 loss ppo:  -0.01926, loss val: 0.04321
[2022-12-06 14:55:20,686] [INFO] [controller] EPOCH 3 loss ppo:  -0.02737, loss val: 0.04369
[2022-12-06 14:55:20,740] [INFO] [controller] EPOCH 4 loss ppo:  -0.03172, loss val: 0.04304
[2022-12-06 14:55:20,752] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:55:20,997] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:55:20,998] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:55:29,088] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:55:37,236] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:55:44,617] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:55:51,696] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:55:58,549] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:56:05,765] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:56:13,167] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:56:20,234] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:56:27,207] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:56:34,535] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.83065976847575
[2022-12-06 14:56:34,535] [INFO] [runner_train_mujoco] Average state value: 0.5181015972097714
[2022-12-06 14:56:34,535] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 14:56:34,596] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.04485
[2022-12-06 14:56:34,641] [INFO] [controller] EPOCH 2 loss ppo:  -0.01988, loss val: 0.04349
[2022-12-06 14:56:34,692] [INFO] [controller] EPOCH 3 loss ppo:  -0.02786, loss val: 0.04348
[2022-12-06 14:56:34,735] [INFO] [controller] EPOCH 4 loss ppo:  -0.03374, loss val: 0.04356
[2022-12-06 14:56:34,745] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:56:34,993] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:56:34,994] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:56:42,638] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:56:50,150] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:56:56,894] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:57:04,344] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:57:11,614] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:57:17,868] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:57:24,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:57:30,324] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:57:36,057] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:57:41,718] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.883838759607928
[2022-12-06 14:57:41,718] [INFO] [runner_train_mujoco] Average state value: 0.5126640132069588
[2022-12-06 14:57:41,718] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 14:57:41,767] [INFO] [controller] EPOCH 1 loss ppo:  -0.01417, loss val: 0.04770
[2022-12-06 14:57:41,811] [INFO] [controller] EPOCH 2 loss ppo:  -0.01760, loss val: 0.04782
[2022-12-06 14:57:41,851] [INFO] [controller] EPOCH 3 loss ppo:  -0.02321, loss val: 0.04784
[2022-12-06 14:57:41,894] [INFO] [controller] EPOCH 4 loss ppo:  -0.02823, loss val: 0.04786
[2022-12-06 14:57:41,905] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:57:42,112] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:57:42,112] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:57:48,208] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:57:53,876] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:57:59,424] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:58:05,368] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:58:11,432] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:58:17,581] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:58:23,668] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:58:29,588] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:58:35,648] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:58:41,867] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.709017169929399
[2022-12-06 14:58:41,867] [INFO] [runner_train_mujoco] Average state value: 0.5134754207928975
[2022-12-06 14:58:41,867] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 14:58:41,919] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04766
[2022-12-06 14:58:41,961] [INFO] [controller] EPOCH 2 loss ppo:  -0.01757, loss val: 0.04983
[2022-12-06 14:58:42,007] [INFO] [controller] EPOCH 3 loss ppo:  -0.02273, loss val: 0.04911
[2022-12-06 14:58:42,051] [INFO] [controller] EPOCH 4 loss ppo:  -0.02845, loss val: 0.04768
[2022-12-06 14:58:42,063] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:58:42,270] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:58:42,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:58:48,385] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:58:54,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 14:59:00,119] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 14:59:06,244] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 14:59:12,077] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 14:59:18,213] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 14:59:24,233] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 14:59:30,520] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 14:59:36,653] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 14:59:42,971] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.757337623585459
[2022-12-06 14:59:42,972] [INFO] [runner_train_mujoco] Average state value: 0.5151230905254682
[2022-12-06 14:59:42,972] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 14:59:43,028] [INFO] [controller] EPOCH 1 loss ppo:  -0.01356, loss val: 0.04385
[2022-12-06 14:59:43,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.01593, loss val: 0.04459
[2022-12-06 14:59:43,122] [INFO] [controller] EPOCH 3 loss ppo:  -0.02040, loss val: 0.04587
[2022-12-06 14:59:43,167] [INFO] [controller] EPOCH 4 loss ppo:  -0.02401, loss val: 0.04346
[2022-12-06 14:59:43,178] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 14:59:43,376] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 14:59:43,377] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 14:59:49,493] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 14:59:56,054] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 15:00:02,355] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 15:00:09,021] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 15:00:14,831] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 15:00:20,832] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 15:00:26,604] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 15:00:32,511] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 15:00:38,368] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 15:00:44,247] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.076614078013164
[2022-12-06 15:00:44,247] [INFO] [runner_train_mujoco] Average state value: 0.5131173972487449
[2022-12-06 15:00:44,247] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 15:00:44,295] [INFO] [controller] EPOCH 1 loss ppo:  -0.01368, loss val: 0.04670
[2022-12-06 15:00:44,333] [INFO] [controller] EPOCH 2 loss ppo:  -0.01462, loss val: 0.04585
[2022-12-06 15:00:44,374] [INFO] [controller] EPOCH 3 loss ppo:  -0.01599, loss val: 0.04538
[2022-12-06 15:00:44,414] [INFO] [controller] EPOCH 4 loss ppo:  -0.01789, loss val: 0.04476
[2022-12-06 15:00:44,425] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 15:00:44,563] [INFO] [optimize] Finished learning.
