[2022-12-06 18:59:48,418] [INFO] [optimize] Starting learning
[2022-12-06 18:59:48,438] [INFO] [optimize] Starting learning process..
[2022-12-06 18:59:48,630] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 18:59:48,636] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:00:00,561] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:00:13,942] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:00:25,262] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:00:36,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:00:48,531] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:01:00,349] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:01:12,343] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:01:23,802] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:01:35,343] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:01:46,792] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3553938618115892
[2022-12-06 19:01:46,793] [INFO] [runner_train_mujoco] Average state value: -0.1416696610276898
[2022-12-06 19:01:46,793] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 19:01:46,901] [INFO] [controller] EPOCH 1 loss ppo:  -0.01734, loss val: 0.66066
[2022-12-06 19:01:46,974] [INFO] [controller] EPOCH 2 loss ppo:  -0.04777, loss val: 0.59548
[2022-12-06 19:01:47,075] [INFO] [controller] EPOCH 3 loss ppo:  -0.05615, loss val: 0.53569
[2022-12-06 19:01:47,190] [INFO] [controller] EPOCH 4 loss ppo:  -0.06425, loss val: 0.47928
[2022-12-06 19:01:47,204] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:01:47,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:01:47,473] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:01:59,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:02:11,101] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:02:22,369] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:02:34,411] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:02:47,286] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:02:58,835] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:03:10,222] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:03:21,890] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:03:33,352] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:03:45,007] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.33678571319788186
[2022-12-06 19:03:45,007] [INFO] [runner_train_mujoco] Average state value: 0.054800881917277965
[2022-12-06 19:03:45,008] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 19:03:45,149] [INFO] [controller] EPOCH 1 loss ppo:  -0.01542, loss val: 0.32007
[2022-12-06 19:03:45,308] [INFO] [controller] EPOCH 2 loss ppo:  -0.04139, loss val: 0.28253
[2022-12-06 19:03:45,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.05082, loss val: 0.24825
[2022-12-06 19:03:45,494] [INFO] [controller] EPOCH 4 loss ppo:  -0.05799, loss val: 0.22611
[2022-12-06 19:03:45,511] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:03:45,777] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:03:45,778] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:03:58,028] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:04:10,204] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:04:21,607] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:04:33,075] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:04:44,645] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:04:56,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:05:08,333] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:05:19,898] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:05:31,936] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:05:43,650] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.44763772273870933
[2022-12-06 19:05:43,650] [INFO] [runner_train_mujoco] Average state value: 0.24288824891299007
[2022-12-06 19:05:43,651] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 19:05:43,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.19011
[2022-12-06 19:05:43,881] [INFO] [controller] EPOCH 2 loss ppo:  -0.03735, loss val: 0.16792
[2022-12-06 19:05:43,970] [INFO] [controller] EPOCH 3 loss ppo:  -0.04668, loss val: 0.14735
[2022-12-06 19:05:44,057] [INFO] [controller] EPOCH 4 loss ppo:  -0.05435, loss val: 0.12938
[2022-12-06 19:05:44,076] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:05:44,350] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:05:44,351] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:05:55,149] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:06:05,524] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:06:15,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:06:25,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:06:35,581] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:06:46,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:06:58,069] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:07:11,905] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:07:24,334] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:07:36,659] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.29396219926473033
[2022-12-06 19:07:36,660] [INFO] [runner_train_mujoco] Average state value: 0.3695267154090106
[2022-12-06 19:07:36,660] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 19:07:36,766] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.11542
[2022-12-06 19:07:36,848] [INFO] [controller] EPOCH 2 loss ppo:  -0.03957, loss val: 0.10443
[2022-12-06 19:07:36,924] [INFO] [controller] EPOCH 3 loss ppo:  -0.05053, loss val: 0.09210
[2022-12-06 19:07:37,076] [INFO] [controller] EPOCH 4 loss ppo:  -0.05795, loss val: 0.08671
[2022-12-06 19:07:37,091] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:07:37,365] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:07:37,366] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:07:49,040] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:08:00,488] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:08:11,950] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:08:23,757] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:08:36,132] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:08:48,154] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:09:00,028] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:09:11,688] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:09:23,220] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:09:35,038] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40961136286510885
[2022-12-06 19:09:35,039] [INFO] [runner_train_mujoco] Average state value: 0.4886380437302093
[2022-12-06 19:09:35,039] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 19:09:35,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.10674
[2022-12-06 19:09:35,258] [INFO] [controller] EPOCH 2 loss ppo:  -0.03606, loss val: 0.09680
[2022-12-06 19:09:35,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.04896, loss val: 0.08883
[2022-12-06 19:09:35,461] [INFO] [controller] EPOCH 4 loss ppo:  -0.05811, loss val: 0.08207
[2022-12-06 19:09:35,477] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:09:35,758] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:09:35,759] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:09:47,822] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:09:59,417] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:10:11,020] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:10:22,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:10:34,602] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:10:46,256] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:10:58,033] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:11:09,139] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:11:20,680] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:11:32,057] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3019731902157279
[2022-12-06 19:11:32,058] [INFO] [runner_train_mujoco] Average state value: 0.5983946288848917
[2022-12-06 19:11:32,058] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 19:11:32,192] [INFO] [controller] EPOCH 1 loss ppo:  -0.00942, loss val: 0.06728
[2022-12-06 19:11:32,335] [INFO] [controller] EPOCH 2 loss ppo:  -0.03693, loss val: 0.06267
[2022-12-06 19:11:32,408] [INFO] [controller] EPOCH 3 loss ppo:  -0.04687, loss val: 0.06030
[2022-12-06 19:11:32,502] [INFO] [controller] EPOCH 4 loss ppo:  -0.05372, loss val: 0.05785
[2022-12-06 19:11:32,515] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:11:32,814] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:11:32,815] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:11:44,862] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:11:56,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:12:07,760] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:12:19,706] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:12:31,606] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:12:43,114] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:12:54,089] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:13:05,472] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:13:17,239] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:13:28,292] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4085981901903238
[2022-12-06 19:13:28,292] [INFO] [runner_train_mujoco] Average state value: 0.6397723389665286
[2022-12-06 19:13:28,292] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 19:13:28,387] [INFO] [controller] EPOCH 1 loss ppo:  -0.00954, loss val: 0.06876
[2022-12-06 19:13:28,472] [INFO] [controller] EPOCH 2 loss ppo:  -0.02601, loss val: 0.06437
[2022-12-06 19:13:28,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.03555, loss val: 0.05867
[2022-12-06 19:13:28,648] [INFO] [controller] EPOCH 4 loss ppo:  -0.04804, loss val: 0.05265
[2022-12-06 19:13:28,661] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:13:28,930] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:13:28,931] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:13:40,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:13:52,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:14:03,879] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:14:15,493] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:14:26,742] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:14:38,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:14:49,419] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:15:00,345] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:15:11,346] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:15:22,905] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5073097784311493
[2022-12-06 19:15:22,905] [INFO] [runner_train_mujoco] Average state value: 0.5874103412379822
[2022-12-06 19:15:22,905] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 19:15:23,004] [INFO] [controller] EPOCH 1 loss ppo:  -0.00780, loss val: 0.05604
[2022-12-06 19:15:23,074] [INFO] [controller] EPOCH 2 loss ppo:  -0.03251, loss val: 0.05143
[2022-12-06 19:15:23,169] [INFO] [controller] EPOCH 3 loss ppo:  -0.04335, loss val: 0.05061
[2022-12-06 19:15:23,389] [INFO] [controller] EPOCH 4 loss ppo:  -0.04971, loss val: 0.05162
[2022-12-06 19:15:23,403] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:15:23,682] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:15:23,682] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:15:35,896] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:15:47,840] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:15:58,849] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:16:12,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:16:24,394] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:16:35,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:16:47,281] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:16:59,732] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:17:11,513] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:17:23,606] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6757638265716468
[2022-12-06 19:17:23,607] [INFO] [runner_train_mujoco] Average state value: 0.5280435147086779
[2022-12-06 19:17:23,607] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 19:17:24,812] [INFO] [controller] EPOCH 1 loss ppo:  -0.01049, loss val: 0.05120
[2022-12-06 19:17:26,039] [INFO] [controller] EPOCH 2 loss ppo:  -0.03413, loss val: 0.04816
[2022-12-06 19:17:26,706] [INFO] [controller] EPOCH 3 loss ppo:  -0.04752, loss val: 0.04738
[2022-12-06 19:17:26,969] [INFO] [controller] EPOCH 4 loss ppo:  -0.05398, loss val: 0.04571
[2022-12-06 19:17:26,988] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:17:27,349] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:17:27,355] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:17:39,741] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:17:52,918] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:18:05,327] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:18:16,315] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:18:26,496] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:18:37,318] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:19:05,226] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:19:22,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:19:33,498] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:19:43,955] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5532392705768843
[2022-12-06 19:19:43,955] [INFO] [runner_train_mujoco] Average state value: 0.5532971252202988
[2022-12-06 19:19:43,955] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 19:19:44,017] [INFO] [controller] EPOCH 1 loss ppo:  -0.01085, loss val: 0.04397
[2022-12-06 19:19:44,066] [INFO] [controller] EPOCH 2 loss ppo:  -0.03300, loss val: 0.04348
[2022-12-06 19:19:44,111] [INFO] [controller] EPOCH 3 loss ppo:  -0.04328, loss val: 0.04332
[2022-12-06 19:19:44,204] [INFO] [controller] EPOCH 4 loss ppo:  -0.04998, loss val: 0.04398
[2022-12-06 19:19:44,213] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:19:44,413] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:19:44,413] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:19:52,930] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:20:00,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:20:08,428] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:20:15,951] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:20:23,373] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:20:30,986] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:20:38,718] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:20:46,434] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:20:54,247] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:21:02,016] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6509141770473821
[2022-12-06 19:21:02,016] [INFO] [runner_train_mujoco] Average state value: 0.5736174573600292
[2022-12-06 19:21:02,016] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 19:21:02,094] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04974
[2022-12-06 19:21:02,149] [INFO] [controller] EPOCH 2 loss ppo:  -0.03810, loss val: 0.04444
[2022-12-06 19:21:02,212] [INFO] [controller] EPOCH 3 loss ppo:  -0.04957, loss val: 0.04369
[2022-12-06 19:21:02,277] [INFO] [controller] EPOCH 4 loss ppo:  -0.05689, loss val: 0.04271
[2022-12-06 19:21:02,287] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:21:02,493] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:21:02,493] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:21:10,240] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:21:18,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:21:25,622] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:21:33,092] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:21:40,801] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:21:48,194] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:21:55,934] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:22:03,582] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:22:11,455] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:22:19,168] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7413991192301628
[2022-12-06 19:22:19,169] [INFO] [runner_train_mujoco] Average state value: 0.5864626192649206
[2022-12-06 19:22:19,169] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 19:22:19,253] [INFO] [controller] EPOCH 1 loss ppo:  -0.01259, loss val: 0.04335
[2022-12-06 19:22:19,303] [INFO] [controller] EPOCH 2 loss ppo:  -0.03097, loss val: 0.04390
[2022-12-06 19:22:19,418] [INFO] [controller] EPOCH 3 loss ppo:  -0.04130, loss val: 0.04373
[2022-12-06 19:22:19,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.04997, loss val: 0.04313
[2022-12-06 19:22:19,478] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:22:19,694] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:22:19,694] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:22:27,426] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:22:35,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:22:43,845] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:22:51,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:22:59,364] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:23:07,384] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:23:15,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:23:23,930] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:23:32,495] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:23:40,736] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.7835357537237431
[2022-12-06 19:23:40,736] [INFO] [runner_train_mujoco] Average state value: 0.5738717026313147
[2022-12-06 19:23:40,737] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 19:23:40,811] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.04193
[2022-12-06 19:23:40,867] [INFO] [controller] EPOCH 2 loss ppo:  -0.03730, loss val: 0.04395
[2022-12-06 19:23:40,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.04749, loss val: 0.04277
[2022-12-06 19:23:40,989] [INFO] [controller] EPOCH 4 loss ppo:  -0.05483, loss val: 0.04164
[2022-12-06 19:23:41,000] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:23:41,228] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:23:41,228] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:23:49,713] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:23:58,355] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:24:06,947] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:24:15,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:24:23,615] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:24:32,115] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:24:40,471] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:24:48,987] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:24:57,433] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:25:06,015] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.070291842036346
[2022-12-06 19:25:06,016] [INFO] [runner_train_mujoco] Average state value: 0.5625214281280836
[2022-12-06 19:25:06,016] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 19:25:06,095] [INFO] [controller] EPOCH 1 loss ppo:  -0.01332, loss val: 0.04563
[2022-12-06 19:25:06,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.03449, loss val: 0.04540
[2022-12-06 19:25:06,206] [INFO] [controller] EPOCH 3 loss ppo:  -0.04388, loss val: 0.04462
[2022-12-06 19:25:06,280] [INFO] [controller] EPOCH 4 loss ppo:  -0.05428, loss val: 0.04435
[2022-12-06 19:25:06,292] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:25:06,532] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:25:06,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:25:15,086] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:25:23,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:25:32,364] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:25:41,599] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:25:51,076] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:26:00,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:26:08,961] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:26:18,169] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:26:26,663] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:26:35,126] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.043482604587511
[2022-12-06 19:26:35,127] [INFO] [runner_train_mujoco] Average state value: 0.5977997913360596
[2022-12-06 19:26:35,127] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 19:26:35,194] [INFO] [controller] EPOCH 1 loss ppo:  -0.01302, loss val: 0.03765
[2022-12-06 19:26:35,266] [INFO] [controller] EPOCH 2 loss ppo:  -0.03738, loss val: 0.03842
[2022-12-06 19:26:35,322] [INFO] [controller] EPOCH 3 loss ppo:  -0.04870, loss val: 0.03886
[2022-12-06 19:26:35,383] [INFO] [controller] EPOCH 4 loss ppo:  -0.05719, loss val: 0.03787
[2022-12-06 19:26:35,395] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:26:35,626] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:26:35,626] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:26:44,821] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:26:53,944] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:27:03,425] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:27:12,759] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:27:21,731] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:27:31,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:27:40,225] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:27:49,873] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:27:59,367] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:28:09,362] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1688241396388621
[2022-12-06 19:28:09,362] [INFO] [runner_train_mujoco] Average state value: 0.6142515842119853
[2022-12-06 19:28:09,362] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 19:28:09,458] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.04204
[2022-12-06 19:28:09,520] [INFO] [controller] EPOCH 2 loss ppo:  -0.03392, loss val: 0.04195
[2022-12-06 19:28:09,587] [INFO] [controller] EPOCH 3 loss ppo:  -0.04194, loss val: 0.04093
[2022-12-06 19:28:09,653] [INFO] [controller] EPOCH 4 loss ppo:  -0.05183, loss val: 0.04086
[2022-12-06 19:28:09,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:28:09,937] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:28:09,937] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:28:19,871] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:28:29,640] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:28:39,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:28:49,230] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:28:59,110] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:29:10,083] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:29:20,505] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:29:30,902] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:29:41,146] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:29:51,595] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4344002527496522
[2022-12-06 19:29:51,596] [INFO] [runner_train_mujoco] Average state value: 0.597921932776769
[2022-12-06 19:29:51,596] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 19:29:51,677] [INFO] [controller] EPOCH 1 loss ppo:  -0.01325, loss val: 0.04283
[2022-12-06 19:29:51,738] [INFO] [controller] EPOCH 2 loss ppo:  -0.03303, loss val: 0.04382
[2022-12-06 19:29:51,815] [INFO] [controller] EPOCH 3 loss ppo:  -0.04451, loss val: 0.04385
[2022-12-06 19:29:51,881] [INFO] [controller] EPOCH 4 loss ppo:  -0.05432, loss val: 0.04309
[2022-12-06 19:29:51,894] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:29:52,165] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:29:52,166] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:30:03,015] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:30:14,494] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:30:26,126] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:30:37,558] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:30:49,188] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:31:00,149] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:31:11,755] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:31:23,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:31:35,811] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:31:48,988] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.604896010363171
[2022-12-06 19:31:48,988] [INFO] [runner_train_mujoco] Average state value: 0.5934162819782893
[2022-12-06 19:31:48,989] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 19:31:49,107] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04219
[2022-12-06 19:31:49,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03911, loss val: 0.04022
[2022-12-06 19:31:49,282] [INFO] [controller] EPOCH 3 loss ppo:  -0.05261, loss val: 0.04079
[2022-12-06 19:31:49,391] [INFO] [controller] EPOCH 4 loss ppo:  -0.05967, loss val: 0.03930
[2022-12-06 19:31:49,408] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:31:49,720] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:31:49,721] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:32:03,582] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:32:17,315] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:32:30,355] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:32:44,612] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:32:58,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:33:12,650] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:33:27,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:33:43,010] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:33:58,812] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:34:14,045] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8468405050634604
[2022-12-06 19:34:14,046] [INFO] [runner_train_mujoco] Average state value: 0.5787499140898387
[2022-12-06 19:34:14,046] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 19:34:14,202] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.04304
[2022-12-06 19:34:14,326] [INFO] [controller] EPOCH 2 loss ppo:  -0.03621, loss val: 0.04301
[2022-12-06 19:34:14,419] [INFO] [controller] EPOCH 3 loss ppo:  -0.04792, loss val: 0.04294
[2022-12-06 19:34:14,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.05648, loss val: 0.04403
[2022-12-06 19:34:14,534] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:34:14,895] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:34:14,895] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:34:29,244] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:34:42,354] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:34:56,545] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:35:09,897] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:35:22,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:35:34,685] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:35:47,432] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:35:59,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:36:10,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:36:22,563] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8890194661507338
[2022-12-06 19:36:22,563] [INFO] [runner_train_mujoco] Average state value: 0.5605495721300443
[2022-12-06 19:36:22,563] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 19:36:22,699] [INFO] [controller] EPOCH 1 loss ppo:  -0.01379, loss val: 0.04022
[2022-12-06 19:36:22,842] [INFO] [controller] EPOCH 2 loss ppo:  -0.03695, loss val: 0.04153
[2022-12-06 19:36:22,960] [INFO] [controller] EPOCH 3 loss ppo:  -0.05444, loss val: 0.04011
[2022-12-06 19:36:23,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.06577, loss val: 0.03911
[2022-12-06 19:36:23,061] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:36:23,367] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:36:23,368] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:36:34,676] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:36:46,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:36:58,141] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:37:08,917] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:37:19,700] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:37:30,195] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:37:40,763] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:37:50,898] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:38:00,975] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:38:11,170] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.064916353423928
[2022-12-06 19:38:11,171] [INFO] [runner_train_mujoco] Average state value: 0.5795737206538518
[2022-12-06 19:38:11,171] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 19:38:11,261] [INFO] [controller] EPOCH 1 loss ppo:  -0.01671, loss val: 0.04338
[2022-12-06 19:38:11,350] [INFO] [controller] EPOCH 2 loss ppo:  -0.03267, loss val: 0.04338
[2022-12-06 19:38:11,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.04305, loss val: 0.04279
[2022-12-06 19:38:11,515] [INFO] [controller] EPOCH 4 loss ppo:  -0.05232, loss val: 0.04194
[2022-12-06 19:38:11,529] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:38:11,801] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:38:11,802] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:38:21,504] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:38:31,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:38:41,169] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:38:50,715] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:38:59,874] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:39:09,708] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:39:19,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:39:29,284] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:39:39,441] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:39:49,836] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3115058050426005
[2022-12-06 19:39:49,837] [INFO] [runner_train_mujoco] Average state value: 0.5710778208772341
[2022-12-06 19:39:49,837] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 19:39:50,062] [INFO] [controller] EPOCH 1 loss ppo:  -0.01533, loss val: 0.04651
[2022-12-06 19:39:50,147] [INFO] [controller] EPOCH 2 loss ppo:  -0.03655, loss val: 0.04593
[2022-12-06 19:39:50,308] [INFO] [controller] EPOCH 3 loss ppo:  -0.04697, loss val: 0.04559
[2022-12-06 19:39:50,496] [INFO] [controller] EPOCH 4 loss ppo:  -0.05566, loss val: 0.04416
[2022-12-06 19:39:50,516] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:39:50,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:39:50,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:40:00,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:40:11,089] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:40:21,232] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:40:32,142] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:40:43,247] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:40:55,002] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:41:06,738] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:41:20,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:41:30,869] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:41:42,724] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3621884983708568
[2022-12-06 19:41:42,724] [INFO] [runner_train_mujoco] Average state value: 0.5570077618757884
[2022-12-06 19:41:42,724] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 19:41:42,856] [INFO] [controller] EPOCH 1 loss ppo:  -0.01564, loss val: 0.04344
[2022-12-06 19:41:42,942] [INFO] [controller] EPOCH 2 loss ppo:  -0.03884, loss val: 0.04147
[2022-12-06 19:41:43,043] [INFO] [controller] EPOCH 3 loss ppo:  -0.05054, loss val: 0.04145
[2022-12-06 19:41:43,125] [INFO] [controller] EPOCH 4 loss ppo:  -0.06280, loss val: 0.04319
[2022-12-06 19:41:43,140] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:41:43,443] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:41:43,444] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:41:55,591] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:42:07,754] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:42:19,890] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:42:31,903] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:42:44,397] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:42:57,184] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:43:10,864] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:43:25,830] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:43:39,897] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:43:53,134] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3979171954342418
[2022-12-06 19:43:53,134] [INFO] [runner_train_mujoco] Average state value: 0.5370194427172343
[2022-12-06 19:43:53,134] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 19:43:53,271] [INFO] [controller] EPOCH 1 loss ppo:  -0.01336, loss val: 0.04423
[2022-12-06 19:43:53,355] [INFO] [controller] EPOCH 2 loss ppo:  -0.03426, loss val: 0.04426
[2022-12-06 19:43:53,439] [INFO] [controller] EPOCH 3 loss ppo:  -0.04728, loss val: 0.04385
[2022-12-06 19:43:53,521] [INFO] [controller] EPOCH 4 loss ppo:  -0.05749, loss val: 0.04454
[2022-12-06 19:43:53,537] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:43:53,914] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:43:53,915] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:44:07,672] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:44:18,624] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:44:28,742] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:44:38,746] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:44:48,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:44:58,951] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:45:08,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:45:18,773] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:45:29,170] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:45:38,529] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.797466315789807
[2022-12-06 19:45:38,529] [INFO] [runner_train_mujoco] Average state value: 0.525731621692578
[2022-12-06 19:45:38,530] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 19:45:38,605] [INFO] [controller] EPOCH 1 loss ppo:  -0.01796, loss val: 0.04203
[2022-12-06 19:45:38,692] [INFO] [controller] EPOCH 2 loss ppo:  -0.03852, loss val: 0.04228
[2022-12-06 19:45:38,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.04958, loss val: 0.04153
[2022-12-06 19:45:38,916] [INFO] [controller] EPOCH 4 loss ppo:  -0.06056, loss val: 0.04091
[2022-12-06 19:45:38,931] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:45:39,185] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:45:39,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:45:48,561] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:45:58,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:46:09,305] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:46:18,716] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:46:27,797] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:46:36,603] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:46:45,287] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:46:54,708] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:47:03,200] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:47:13,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.096930864340611
[2022-12-06 19:47:13,091] [INFO] [runner_train_mujoco] Average state value: 0.5307828003764152
[2022-12-06 19:47:13,091] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 19:47:13,173] [INFO] [controller] EPOCH 1 loss ppo:  -0.01457, loss val: 0.04426
[2022-12-06 19:47:13,238] [INFO] [controller] EPOCH 2 loss ppo:  -0.03172, loss val: 0.04371
[2022-12-06 19:47:13,309] [INFO] [controller] EPOCH 3 loss ppo:  -0.04666, loss val: 0.04376
[2022-12-06 19:47:13,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.05767, loss val: 0.04253
[2022-12-06 19:47:13,390] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:47:13,633] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:47:13,634] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:47:22,109] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:47:30,945] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:47:39,248] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:47:47,701] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:47:56,595] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:48:07,260] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:48:16,781] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:48:25,589] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:48:34,047] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:48:42,642] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.347668166793251
[2022-12-06 19:48:42,643] [INFO] [runner_train_mujoco] Average state value: 0.5567719624241194
[2022-12-06 19:48:42,643] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 19:48:42,719] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.03654
[2022-12-06 19:48:42,784] [INFO] [controller] EPOCH 2 loss ppo:  -0.03690, loss val: 0.03689
[2022-12-06 19:48:42,854] [INFO] [controller] EPOCH 3 loss ppo:  -0.04457, loss val: 0.03761
[2022-12-06 19:48:42,918] [INFO] [controller] EPOCH 4 loss ppo:  -0.05495, loss val: 0.03696
[2022-12-06 19:48:42,930] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:48:43,179] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:48:43,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:48:51,967] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:49:01,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:49:09,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:49:18,579] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:49:27,047] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:49:36,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:49:44,740] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:49:54,197] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:50:03,615] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:50:13,020] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.252404745241094
[2022-12-06 19:50:13,021] [INFO] [runner_train_mujoco] Average state value: 0.5616180691520374
[2022-12-06 19:50:13,021] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 19:50:13,154] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.04440
[2022-12-06 19:50:13,247] [INFO] [controller] EPOCH 2 loss ppo:  -0.03087, loss val: 0.04385
[2022-12-06 19:50:13,335] [INFO] [controller] EPOCH 3 loss ppo:  -0.04374, loss val: 0.04329
[2022-12-06 19:50:13,413] [INFO] [controller] EPOCH 4 loss ppo:  -0.05315, loss val: 0.04367
[2022-12-06 19:50:13,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:50:13,690] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:50:13,691] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:50:22,558] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:50:31,310] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:50:39,853] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:50:47,981] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:50:56,042] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:51:04,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:51:12,038] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:51:20,371] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:51:28,662] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:51:36,720] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3849719000918137
[2022-12-06 19:51:36,720] [INFO] [runner_train_mujoco] Average state value: 0.5459547729094822
[2022-12-06 19:51:36,720] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 19:51:36,781] [INFO] [controller] EPOCH 1 loss ppo:  -0.01453, loss val: 0.04203
[2022-12-06 19:51:36,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.03046, loss val: 0.04209
[2022-12-06 19:51:36,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.04346, loss val: 0.04278
[2022-12-06 19:51:36,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.05589, loss val: 0.04511
[2022-12-06 19:51:36,956] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:51:37,209] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:51:37,210] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:51:45,372] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:51:53,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:52:01,995] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:52:10,203] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:52:18,087] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:52:25,700] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:52:32,963] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:52:40,606] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:52:47,827] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:52:55,293] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6250198131124796
[2022-12-06 19:52:55,293] [INFO] [runner_train_mujoco] Average state value: 0.5420815467039743
[2022-12-06 19:52:55,294] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 19:52:55,358] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04532
[2022-12-06 19:52:55,410] [INFO] [controller] EPOCH 2 loss ppo:  -0.03231, loss val: 0.04467
[2022-12-06 19:52:55,472] [INFO] [controller] EPOCH 3 loss ppo:  -0.04526, loss val: 0.04462
[2022-12-06 19:52:55,536] [INFO] [controller] EPOCH 4 loss ppo:  -0.05637, loss val: 0.04452
[2022-12-06 19:52:55,547] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:52:55,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:52:55,766] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:53:03,973] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:53:11,694] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:53:19,161] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:53:26,781] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:53:34,328] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:53:41,687] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:53:49,599] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:53:56,786] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:54:04,029] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:54:11,127] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.7822034356040795
[2022-12-06 19:54:11,128] [INFO] [runner_train_mujoco] Average state value: 0.5347086610198021
[2022-12-06 19:54:11,128] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 19:54:11,196] [INFO] [controller] EPOCH 1 loss ppo:  -0.01316, loss val: 0.04796
[2022-12-06 19:54:11,255] [INFO] [controller] EPOCH 2 loss ppo:  -0.03094, loss val: 0.04592
[2022-12-06 19:54:11,328] [INFO] [controller] EPOCH 3 loss ppo:  -0.04428, loss val: 0.04749
[2022-12-06 19:54:11,392] [INFO] [controller] EPOCH 4 loss ppo:  -0.05705, loss val: 0.04699
[2022-12-06 19:54:11,403] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:54:11,621] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:54:11,622] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:54:19,056] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:54:26,704] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:54:33,767] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:54:40,729] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:54:47,925] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:54:55,062] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:55:01,912] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:55:09,022] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:55:16,173] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:55:23,779] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8074270265441923
[2022-12-06 19:55:23,780] [INFO] [runner_train_mujoco] Average state value: 0.5376195683677991
[2022-12-06 19:55:23,780] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 19:55:23,849] [INFO] [controller] EPOCH 1 loss ppo:  -0.01570, loss val: 0.03848
[2022-12-06 19:55:23,911] [INFO] [controller] EPOCH 2 loss ppo:  -0.03333, loss val: 0.03803
[2022-12-06 19:55:23,991] [INFO] [controller] EPOCH 3 loss ppo:  -0.04343, loss val: 0.03828
[2022-12-06 19:55:24,046] [INFO] [controller] EPOCH 4 loss ppo:  -0.05554, loss val: 0.03791
[2022-12-06 19:55:24,059] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:55:24,273] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:55:24,273] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:55:31,435] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:55:38,676] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:55:45,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:55:52,992] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:56:00,069] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:56:06,973] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:56:13,895] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:56:20,662] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:56:27,712] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:56:34,813] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.746986100941613
[2022-12-06 19:56:34,813] [INFO] [runner_train_mujoco] Average state value: 0.5189967199563981
[2022-12-06 19:56:34,813] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 19:56:34,925] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03770
[2022-12-06 19:56:34,971] [INFO] [controller] EPOCH 2 loss ppo:  -0.02860, loss val: 0.03695
[2022-12-06 19:56:35,017] [INFO] [controller] EPOCH 3 loss ppo:  -0.04121, loss val: 0.03707
[2022-12-06 19:56:35,063] [INFO] [controller] EPOCH 4 loss ppo:  -0.05192, loss val: 0.03751
[2022-12-06 19:56:35,073] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:56:35,277] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:56:35,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:56:42,442] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:56:49,888] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:56:57,168] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:57:04,369] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:57:11,086] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:57:17,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:57:24,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:57:31,518] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:57:38,259] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:57:44,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8634157232067374
[2022-12-06 19:57:44,285] [INFO] [runner_train_mujoco] Average state value: 0.4903866301675638
[2022-12-06 19:57:44,285] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 19:57:44,337] [INFO] [controller] EPOCH 1 loss ppo:  -0.01476, loss val: 0.04682
[2022-12-06 19:57:44,382] [INFO] [controller] EPOCH 2 loss ppo:  -0.03027, loss val: 0.04718
[2022-12-06 19:57:44,424] [INFO] [controller] EPOCH 3 loss ppo:  -0.03889, loss val: 0.04693
[2022-12-06 19:57:44,467] [INFO] [controller] EPOCH 4 loss ppo:  -0.04875, loss val: 0.04604
[2022-12-06 19:57:44,477] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:57:44,686] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:57:44,687] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:57:50,614] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:57:56,679] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:58:02,553] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:58:08,157] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:58:14,006] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:58:19,848] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:58:25,286] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:58:30,856] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:58:36,186] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:58:41,620] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.007470277760901
[2022-12-06 19:58:41,620] [INFO] [runner_train_mujoco] Average state value: 0.4996632071336111
[2022-12-06 19:58:41,621] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 19:58:41,669] [INFO] [controller] EPOCH 1 loss ppo:  -0.01533, loss val: 0.03238
[2022-12-06 19:58:41,710] [INFO] [controller] EPOCH 2 loss ppo:  -0.02853, loss val: 0.03242
[2022-12-06 19:58:41,763] [INFO] [controller] EPOCH 3 loss ppo:  -0.03988, loss val: 0.03369
[2022-12-06 19:58:41,803] [INFO] [controller] EPOCH 4 loss ppo:  -0.05226, loss val: 0.03275
[2022-12-06 19:58:41,813] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:58:41,995] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:58:41,995] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:58:47,372] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:58:52,546] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:58:58,088] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:59:03,291] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 19:59:08,528] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 19:59:13,636] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 19:59:18,751] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 19:59:24,296] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 19:59:29,593] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 19:59:34,936] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.783318911016817
[2022-12-06 19:59:34,937] [INFO] [runner_train_mujoco] Average state value: 0.5149453158378601
[2022-12-06 19:59:34,937] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 19:59:34,990] [INFO] [controller] EPOCH 1 loss ppo:  -0.01606, loss val: 0.03628
[2022-12-06 19:59:35,030] [INFO] [controller] EPOCH 2 loss ppo:  -0.03255, loss val: 0.03777
[2022-12-06 19:59:35,066] [INFO] [controller] EPOCH 3 loss ppo:  -0.04325, loss val: 0.03746
[2022-12-06 19:59:35,107] [INFO] [controller] EPOCH 4 loss ppo:  -0.05071, loss val: 0.03610
[2022-12-06 19:59:35,117] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 19:59:35,301] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 19:59:35,301] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 19:59:40,784] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 19:59:46,482] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 19:59:52,007] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 19:59:57,147] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:00:02,458] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:00:08,098] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:00:13,359] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:00:18,517] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:00:23,865] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:00:29,083] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.104762275467025
[2022-12-06 20:00:29,083] [INFO] [runner_train_mujoco] Average state value: 0.5115156938234964
[2022-12-06 20:00:29,083] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 20:00:29,134] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.03797
[2022-12-06 20:00:29,175] [INFO] [controller] EPOCH 2 loss ppo:  -0.02831, loss val: 0.03789
[2022-12-06 20:00:29,214] [INFO] [controller] EPOCH 3 loss ppo:  -0.04004, loss val: 0.03788
[2022-12-06 20:00:29,256] [INFO] [controller] EPOCH 4 loss ppo:  -0.05061, loss val: 0.03627
[2022-12-06 20:00:29,266] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:00:29,440] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:00:29,440] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:00:35,024] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:00:40,482] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:00:45,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:00:51,375] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:00:57,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:01:02,693] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:01:08,453] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:01:13,976] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:01:19,174] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:01:24,470] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.053646590490427
[2022-12-06 20:01:24,471] [INFO] [runner_train_mujoco] Average state value: 0.4886530887881915
[2022-12-06 20:01:24,471] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 20:01:24,521] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04504
[2022-12-06 20:01:24,558] [INFO] [controller] EPOCH 2 loss ppo:  -0.02543, loss val: 0.04617
[2022-12-06 20:01:24,596] [INFO] [controller] EPOCH 3 loss ppo:  -0.03700, loss val: 0.04548
[2022-12-06 20:01:24,638] [INFO] [controller] EPOCH 4 loss ppo:  -0.04937, loss val: 0.04683
[2022-12-06 20:01:24,646] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:01:24,795] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:01:24,795] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:01:30,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:01:35,896] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:01:41,418] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:01:47,201] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:01:52,681] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:01:58,628] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:02:04,112] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:02:10,154] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:02:15,552] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:02:21,763] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.154383925332335
[2022-12-06 20:02:21,764] [INFO] [runner_train_mujoco] Average state value: 0.4785125481486321
[2022-12-06 20:02:21,764] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 20:02:21,822] [INFO] [controller] EPOCH 1 loss ppo:  -0.01505, loss val: 0.04111
[2022-12-06 20:02:21,863] [INFO] [controller] EPOCH 2 loss ppo:  -0.03236, loss val: 0.04102
[2022-12-06 20:02:21,908] [INFO] [controller] EPOCH 3 loss ppo:  -0.04063, loss val: 0.04090
[2022-12-06 20:02:21,959] [INFO] [controller] EPOCH 4 loss ppo:  -0.05116, loss val: 0.04200
[2022-12-06 20:02:21,971] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:02:22,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:02:22,184] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:02:27,942] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:02:33,649] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:02:39,435] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:02:45,071] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:02:50,648] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:02:56,060] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:03:01,556] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:03:07,188] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:03:12,930] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:03:18,296] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.335446689221707
[2022-12-06 20:03:18,296] [INFO] [runner_train_mujoco] Average state value: 0.4891251502633095
[2022-12-06 20:03:18,297] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 20:03:18,352] [INFO] [controller] EPOCH 1 loss ppo:  -0.01298, loss val: 0.04679
[2022-12-06 20:03:18,397] [INFO] [controller] EPOCH 2 loss ppo:  -0.02451, loss val: 0.04646
[2022-12-06 20:03:18,442] [INFO] [controller] EPOCH 3 loss ppo:  -0.03787, loss val: 0.04652
[2022-12-06 20:03:18,486] [INFO] [controller] EPOCH 4 loss ppo:  -0.05050, loss val: 0.04754
[2022-12-06 20:03:18,494] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:03:18,687] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:03:18,688] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:03:24,295] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:03:30,318] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:03:35,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:03:41,675] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:03:47,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:03:52,864] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:03:58,112] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:04:03,564] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:04:09,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:04:14,439] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.540019221052551
[2022-12-06 20:04:14,440] [INFO] [runner_train_mujoco] Average state value: 0.4904599711497625
[2022-12-06 20:04:14,440] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 20:04:14,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.05814
[2022-12-06 20:04:14,533] [INFO] [controller] EPOCH 2 loss ppo:  -0.02583, loss val: 0.05775
[2022-12-06 20:04:14,577] [INFO] [controller] EPOCH 3 loss ppo:  -0.03633, loss val: 0.05739
[2022-12-06 20:04:14,621] [INFO] [controller] EPOCH 4 loss ppo:  -0.04534, loss val: 0.05738
[2022-12-06 20:04:14,631] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:04:14,809] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:04:14,810] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:04:20,493] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:04:26,118] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:04:31,550] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:04:36,747] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:04:42,287] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:04:47,653] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:04:53,378] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:04:58,942] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:05:04,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:05:09,842] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.408296655915903
[2022-12-06 20:05:09,842] [INFO] [runner_train_mujoco] Average state value: 0.5105977739493052
[2022-12-06 20:05:09,842] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 20:05:09,889] [INFO] [controller] EPOCH 1 loss ppo:  -0.01392, loss val: 0.04426
[2022-12-06 20:05:09,932] [INFO] [controller] EPOCH 2 loss ppo:  -0.02764, loss val: 0.04375
[2022-12-06 20:05:09,976] [INFO] [controller] EPOCH 3 loss ppo:  -0.03503, loss val: 0.04453
[2022-12-06 20:05:10,021] [INFO] [controller] EPOCH 4 loss ppo:  -0.04348, loss val: 0.04538
[2022-12-06 20:05:10,030] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:05:10,227] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:05:10,227] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:05:15,739] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:05:21,290] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:05:26,513] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:05:31,854] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:05:36,982] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:05:42,314] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:05:47,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:05:52,452] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:05:57,808] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:06:03,020] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.4294584098634955
[2022-12-06 20:06:03,020] [INFO] [runner_train_mujoco] Average state value: 0.5156322457591693
[2022-12-06 20:06:03,020] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 20:06:03,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01244, loss val: 0.04184
[2022-12-06 20:06:03,107] [INFO] [controller] EPOCH 2 loss ppo:  -0.02414, loss val: 0.04090
[2022-12-06 20:06:03,149] [INFO] [controller] EPOCH 3 loss ppo:  -0.03785, loss val: 0.04067
[2022-12-06 20:06:03,190] [INFO] [controller] EPOCH 4 loss ppo:  -0.04804, loss val: 0.04101
[2022-12-06 20:06:03,200] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:06:03,375] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:06:03,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:06:08,935] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:06:14,419] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:06:19,590] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:06:24,679] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:06:29,707] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:06:34,737] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:06:40,076] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:06:45,290] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:06:50,283] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:06:55,269] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.736813065150066
[2022-12-06 20:06:55,269] [INFO] [runner_train_mujoco] Average state value: 0.5296332266628744
[2022-12-06 20:06:55,269] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 20:06:55,320] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.04501
[2022-12-06 20:06:55,363] [INFO] [controller] EPOCH 2 loss ppo:  -0.02376, loss val: 0.04625
[2022-12-06 20:06:55,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.03385, loss val: 0.04615
[2022-12-06 20:06:55,453] [INFO] [controller] EPOCH 4 loss ppo:  -0.04418, loss val: 0.04544
[2022-12-06 20:06:55,463] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:06:55,652] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:06:55,652] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:07:00,727] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:07:07,083] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:07:13,006] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:07:18,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:07:23,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:07:29,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:07:34,805] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:07:40,144] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:07:45,747] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:07:51,038] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.598539689400316
[2022-12-06 20:07:51,038] [INFO] [runner_train_mujoco] Average state value: 0.5197107961773872
[2022-12-06 20:07:51,039] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 20:07:51,087] [INFO] [controller] EPOCH 1 loss ppo:  -0.01307, loss val: 0.04286
[2022-12-06 20:07:51,128] [INFO] [controller] EPOCH 2 loss ppo:  -0.02336, loss val: 0.04194
[2022-12-06 20:07:51,172] [INFO] [controller] EPOCH 3 loss ppo:  -0.03517, loss val: 0.04205
[2022-12-06 20:07:51,214] [INFO] [controller] EPOCH 4 loss ppo:  -0.04182, loss val: 0.04264
[2022-12-06 20:07:51,221] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:07:51,415] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:07:51,415] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:07:56,920] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:08:02,238] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:08:07,587] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:08:12,774] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:08:17,947] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:08:23,199] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:08:28,521] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:08:33,911] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:08:39,055] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:08:44,381] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.662910501753563
[2022-12-06 20:08:44,381] [INFO] [runner_train_mujoco] Average state value: 0.5143289580543836
[2022-12-06 20:08:44,381] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 20:08:44,430] [INFO] [controller] EPOCH 1 loss ppo:  -0.01447, loss val: 0.04278
[2022-12-06 20:08:44,472] [INFO] [controller] EPOCH 2 loss ppo:  -0.02525, loss val: 0.04176
[2022-12-06 20:08:44,577] [INFO] [controller] EPOCH 3 loss ppo:  -0.03344, loss val: 0.04186
[2022-12-06 20:08:44,621] [INFO] [controller] EPOCH 4 loss ppo:  -0.04173, loss val: 0.04163
[2022-12-06 20:08:44,630] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:08:44,793] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:08:44,793] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:08:50,294] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:08:55,662] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:09:00,926] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:09:06,151] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:09:11,882] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:09:17,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:09:22,571] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:09:27,996] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:09:33,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:09:38,874] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7790108391256
[2022-12-06 20:09:38,875] [INFO] [runner_train_mujoco] Average state value: 0.513669486939907
[2022-12-06 20:09:38,875] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 20:09:38,926] [INFO] [controller] EPOCH 1 loss ppo:  -0.01483, loss val: 0.04438
[2022-12-06 20:09:38,965] [INFO] [controller] EPOCH 2 loss ppo:  -0.02452, loss val: 0.04383
[2022-12-06 20:09:39,005] [INFO] [controller] EPOCH 3 loss ppo:  -0.03150, loss val: 0.04438
[2022-12-06 20:09:39,048] [INFO] [controller] EPOCH 4 loss ppo:  -0.03997, loss val: 0.04383
[2022-12-06 20:09:39,061] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:09:39,265] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:09:39,265] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:09:44,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:09:50,294] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:09:55,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:10:01,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:10:06,659] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:10:12,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:10:17,402] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:10:22,982] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:10:28,354] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:10:33,626] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.7005749623359865
[2022-12-06 20:10:33,627] [INFO] [runner_train_mujoco] Average state value: 0.5179958644310634
[2022-12-06 20:10:33,627] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 20:10:33,680] [INFO] [controller] EPOCH 1 loss ppo:  -0.01294, loss val: 0.05397
[2022-12-06 20:10:33,725] [INFO] [controller] EPOCH 2 loss ppo:  -0.01960, loss val: 0.05371
[2022-12-06 20:10:33,771] [INFO] [controller] EPOCH 3 loss ppo:  -0.03045, loss val: 0.05334
[2022-12-06 20:10:33,820] [INFO] [controller] EPOCH 4 loss ppo:  -0.03881, loss val: 0.05300
[2022-12-06 20:10:33,830] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:10:34,026] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:10:34,026] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:10:39,675] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:10:45,368] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:10:50,930] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:10:56,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:11:02,796] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:11:08,417] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:11:14,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:11:20,062] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:11:25,681] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:11:31,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.908223720376487
[2022-12-06 20:11:31,440] [INFO] [runner_train_mujoco] Average state value: 0.5104291168848674
[2022-12-06 20:11:31,440] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 20:11:31,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.04999
[2022-12-06 20:11:31,535] [INFO] [controller] EPOCH 2 loss ppo:  -0.02512, loss val: 0.04968
[2022-12-06 20:11:31,579] [INFO] [controller] EPOCH 3 loss ppo:  -0.03481, loss val: 0.04852
[2022-12-06 20:11:31,627] [INFO] [controller] EPOCH 4 loss ppo:  -0.04251, loss val: 0.04759
[2022-12-06 20:11:31,634] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:11:31,836] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:11:31,836] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:11:37,960] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:11:44,652] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:11:50,095] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:11:55,705] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:12:01,039] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:12:06,436] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:12:11,982] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:12:17,425] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:12:23,030] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:12:28,609] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.911911924501
[2022-12-06 20:12:28,609] [INFO] [runner_train_mujoco] Average state value: 0.49760439850886656
[2022-12-06 20:12:28,609] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 20:12:28,661] [INFO] [controller] EPOCH 1 loss ppo:  -0.01383, loss val: 0.04856
[2022-12-06 20:12:28,708] [INFO] [controller] EPOCH 2 loss ppo:  -0.01928, loss val: 0.04796
[2022-12-06 20:12:28,757] [INFO] [controller] EPOCH 3 loss ppo:  -0.02756, loss val: 0.04765
[2022-12-06 20:12:28,801] [INFO] [controller] EPOCH 4 loss ppo:  -0.03503, loss val: 0.04772
[2022-12-06 20:12:28,810] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:12:29,001] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:12:29,001] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:12:34,495] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:12:40,090] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:12:45,529] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:12:50,902] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:12:56,564] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:13:01,949] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:13:07,354] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:13:12,575] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:13:18,102] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:13:23,223] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.055073355640629
[2022-12-06 20:13:23,223] [INFO] [runner_train_mujoco] Average state value: 0.48149502366781227
[2022-12-06 20:13:23,223] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 20:13:23,274] [INFO] [controller] EPOCH 1 loss ppo:  -0.01434, loss val: 0.04470
[2022-12-06 20:13:23,317] [INFO] [controller] EPOCH 2 loss ppo:  -0.02146, loss val: 0.04378
[2022-12-06 20:13:23,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.03085, loss val: 0.04567
[2022-12-06 20:13:23,403] [INFO] [controller] EPOCH 4 loss ppo:  -0.03619, loss val: 0.04338
[2022-12-06 20:13:23,413] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:13:23,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:13:23,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:13:29,053] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:13:34,326] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:13:39,572] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:13:44,582] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:13:49,703] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:13:55,301] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:14:00,831] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:14:06,495] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:14:13,096] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:14:18,273] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.0992902951863055
[2022-12-06 20:14:18,273] [INFO] [runner_train_mujoco] Average state value: 0.4649872899452845
[2022-12-06 20:14:18,273] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 20:14:18,319] [INFO] [controller] EPOCH 1 loss ppo:  -0.01422, loss val: 0.05308
[2022-12-06 20:14:18,362] [INFO] [controller] EPOCH 2 loss ppo:  -0.02092, loss val: 0.05311
[2022-12-06 20:14:18,405] [INFO] [controller] EPOCH 3 loss ppo:  -0.02780, loss val: 0.05480
[2022-12-06 20:14:18,448] [INFO] [controller] EPOCH 4 loss ppo:  -0.03421, loss val: 0.05634
[2022-12-06 20:14:18,456] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:14:18,637] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:14:18,638] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:14:23,701] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:14:28,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:14:33,781] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:14:38,772] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:14:44,174] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:14:49,513] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:14:54,676] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:14:59,602] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:15:04,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:15:09,791] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.30947967152388
[2022-12-06 20:15:09,791] [INFO] [runner_train_mujoco] Average state value: 0.46864248834053673
[2022-12-06 20:15:09,791] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 20:15:09,854] [INFO] [controller] EPOCH 1 loss ppo:  -0.01455, loss val: 0.04287
[2022-12-06 20:15:09,891] [INFO] [controller] EPOCH 2 loss ppo:  -0.02212, loss val: 0.04283
[2022-12-06 20:15:09,934] [INFO] [controller] EPOCH 3 loss ppo:  -0.02730, loss val: 0.04304
[2022-12-06 20:15:09,978] [INFO] [controller] EPOCH 4 loss ppo:  -0.03267, loss val: 0.04397
[2022-12-06 20:15:09,988] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:15:10,171] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:15:10,171] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:15:15,707] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:15:21,175] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:15:26,763] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:15:32,468] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:15:37,543] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:15:42,893] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:15:47,856] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:15:52,986] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:15:58,091] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:16:03,580] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.179853507351227
[2022-12-06 20:16:03,580] [INFO] [runner_train_mujoco] Average state value: 0.46910453919569645
[2022-12-06 20:16:03,580] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 20:16:03,632] [INFO] [controller] EPOCH 1 loss ppo:  -0.01396, loss val: 0.05202
[2022-12-06 20:16:03,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.01763, loss val: 0.04953
[2022-12-06 20:16:03,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.02177, loss val: 0.05120
[2022-12-06 20:16:03,771] [INFO] [controller] EPOCH 4 loss ppo:  -0.02778, loss val: 0.05144
[2022-12-06 20:16:03,779] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:16:03,954] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:16:03,954] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:16:09,388] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:16:14,622] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:16:19,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:16:24,987] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:16:30,886] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:16:36,245] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:16:41,836] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:16:47,086] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:16:52,374] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:16:57,754] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.935953981750561
[2022-12-06 20:16:57,754] [INFO] [runner_train_mujoco] Average state value: 0.4676460719505946
[2022-12-06 20:16:57,754] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 20:16:57,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.05476
[2022-12-06 20:16:57,849] [INFO] [controller] EPOCH 2 loss ppo:  -0.01701, loss val: 0.05701
[2022-12-06 20:16:57,891] [INFO] [controller] EPOCH 3 loss ppo:  -0.02200, loss val: 0.05451
[2022-12-06 20:16:57,933] [INFO] [controller] EPOCH 4 loss ppo:  -0.02688, loss val: 0.05339
[2022-12-06 20:16:57,943] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:16:58,130] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:16:58,131] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:17:03,564] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:17:09,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:17:14,520] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:17:20,088] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:17:25,316] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:17:30,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:17:35,810] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:17:41,415] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:17:47,084] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:17:52,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.277026013524288
[2022-12-06 20:17:52,440] [INFO] [runner_train_mujoco] Average state value: 0.47249613688389464
[2022-12-06 20:17:52,440] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 20:17:52,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01464, loss val: 0.04177
[2022-12-06 20:17:52,537] [INFO] [controller] EPOCH 2 loss ppo:  -0.01809, loss val: 0.04212
[2022-12-06 20:17:52,584] [INFO] [controller] EPOCH 3 loss ppo:  -0.02387, loss val: 0.04297
[2022-12-06 20:17:52,630] [INFO] [controller] EPOCH 4 loss ppo:  -0.02949, loss val: 0.04227
[2022-12-06 20:17:52,640] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:17:52,844] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:17:52,844] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:17:58,346] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:18:03,892] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:18:09,507] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:18:14,792] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:18:20,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:18:25,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:18:31,157] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:18:36,461] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:18:41,873] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:18:47,271] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.057836000452044
[2022-12-06 20:18:47,271] [INFO] [runner_train_mujoco] Average state value: 0.4719914252758026
[2022-12-06 20:18:47,271] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 20:18:47,323] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04285
[2022-12-06 20:18:47,365] [INFO] [controller] EPOCH 2 loss ppo:  -0.01595, loss val: 0.04169
[2022-12-06 20:18:47,414] [INFO] [controller] EPOCH 3 loss ppo:  -0.01899, loss val: 0.04167
[2022-12-06 20:18:47,460] [INFO] [controller] EPOCH 4 loss ppo:  -0.02352, loss val: 0.04192
[2022-12-06 20:18:47,471] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:18:47,668] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 20:18:47,668] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 20:18:53,091] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 20:18:58,879] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 20:19:04,911] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 20:19:10,697] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 20:19:16,489] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 20:19:22,070] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 20:19:27,825] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 20:19:33,272] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 20:19:38,611] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 20:19:44,115] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.136034437140467
[2022-12-06 20:19:44,115] [INFO] [runner_train_mujoco] Average state value: 0.4734205813010533
[2022-12-06 20:19:44,115] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 20:19:44,167] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.04893
[2022-12-06 20:19:44,207] [INFO] [controller] EPOCH 2 loss ppo:  -0.01639, loss val: 0.05011
[2022-12-06 20:19:44,251] [INFO] [controller] EPOCH 3 loss ppo:  -0.01922, loss val: 0.05088
[2022-12-06 20:19:44,293] [INFO] [controller] EPOCH 4 loss ppo:  -0.02243, loss val: 0.04989
[2022-12-06 20:19:44,304] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 20:19:44,448] [INFO] [optimize] Finished learning.
