[2022-12-07 12:27:51,852] [INFO] [optimize] Starting learning
[2022-12-07 12:27:51,866] [INFO] [optimize] Starting learning process..
[2022-12-07 12:27:51,963] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:27:51,964] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:27:58,901] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:28:04,467] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:28:10,245] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:28:16,056] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:28:22,074] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:28:27,635] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:28:33,146] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:28:39,030] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:28:44,806] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:28:50,218] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.33457063009313515
[2022-12-07 12:28:50,218] [INFO] [runner_train_mujoco] Average state value: 0.13018759683892128
[2022-12-07 12:28:50,218] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 12:28:50,283] [INFO] [controller] EPOCH 1 loss ppo:  -0.01098, loss val: 0.34588
[2022-12-07 12:28:50,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.04256, loss val: 0.30265
[2022-12-07 12:28:50,376] [INFO] [controller] EPOCH 3 loss ppo:  -0.05422, loss val: 0.27196
[2022-12-07 12:28:50,418] [INFO] [controller] EPOCH 4 loss ppo:  -0.06299, loss val: 0.23750
[2022-12-07 12:28:50,428] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:28:50,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:28:50,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:28:56,260] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:29:01,806] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:29:07,488] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:29:12,620] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:29:18,377] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:29:23,951] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:29:29,260] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:29:34,582] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:29:40,422] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:29:46,548] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.49016907323436165
[2022-12-07 12:29:46,549] [INFO] [runner_train_mujoco] Average state value: 0.3216388743420442
[2022-12-07 12:29:46,549] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 12:29:46,602] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.19518
[2022-12-07 12:29:46,648] [INFO] [controller] EPOCH 2 loss ppo:  -0.04087, loss val: 0.17511
[2022-12-07 12:29:46,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.05273, loss val: 0.16078
[2022-12-07 12:29:46,742] [INFO] [controller] EPOCH 4 loss ppo:  -0.06128, loss val: 0.14772
[2022-12-07 12:29:46,753] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:29:46,929] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:29:46,929] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:29:52,451] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:29:58,047] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:30:04,102] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:30:09,544] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:30:15,110] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:30:20,702] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:30:26,586] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:30:32,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:30:38,317] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:30:43,986] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4919078189661844
[2022-12-07 12:30:43,986] [INFO] [runner_train_mujoco] Average state value: 0.4505587229790787
[2022-12-07 12:30:43,986] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 12:30:44,040] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.15627
[2022-12-07 12:30:44,085] [INFO] [controller] EPOCH 2 loss ppo:  -0.03930, loss val: 0.14564
[2022-12-07 12:30:44,121] [INFO] [controller] EPOCH 3 loss ppo:  -0.05091, loss val: 0.13660
[2022-12-07 12:30:44,166] [INFO] [controller] EPOCH 4 loss ppo:  -0.05725, loss val: 0.12737
[2022-12-07 12:30:44,176] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:30:44,370] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:30:44,370] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:30:50,453] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:30:56,059] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:31:02,039] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:31:07,722] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:31:13,208] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:31:19,350] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:31:25,039] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:31:30,785] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:31:36,702] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:31:42,838] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48605328644340584
[2022-12-07 12:31:42,838] [INFO] [runner_train_mujoco] Average state value: 0.5318426495039215
[2022-12-07 12:31:42,839] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 12:31:42,892] [INFO] [controller] EPOCH 1 loss ppo:  -0.01150, loss val: 0.12004
[2022-12-07 12:31:42,941] [INFO] [controller] EPOCH 2 loss ppo:  -0.03369, loss val: 0.11258
[2022-12-07 12:31:42,997] [INFO] [controller] EPOCH 3 loss ppo:  -0.04687, loss val: 0.10402
[2022-12-07 12:31:43,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.05543, loss val: 0.09601
[2022-12-07 12:31:43,053] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:31:43,253] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:31:43,254] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:31:49,279] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:31:54,908] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:32:01,017] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:32:06,711] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:32:12,900] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:32:19,255] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:32:25,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:32:31,364] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:32:37,066] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:32:42,807] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42146038028745963
[2022-12-07 12:32:42,807] [INFO] [runner_train_mujoco] Average state value: 0.5474242181815206
[2022-12-07 12:32:42,807] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 12:32:42,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01166, loss val: 0.09517
[2022-12-07 12:32:42,897] [INFO] [controller] EPOCH 2 loss ppo:  -0.03580, loss val: 0.09026
[2022-12-07 12:32:42,931] [INFO] [controller] EPOCH 3 loss ppo:  -0.04662, loss val: 0.08498
[2022-12-07 12:32:42,971] [INFO] [controller] EPOCH 4 loss ppo:  -0.05510, loss val: 0.08057
[2022-12-07 12:32:42,981] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:32:43,166] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:32:43,167] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:32:49,356] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:32:55,601] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:33:01,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:33:07,528] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:33:13,481] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:33:19,495] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:33:24,998] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:33:30,740] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:33:36,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:33:41,901] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5167280897228008
[2022-12-07 12:33:41,901] [INFO] [runner_train_mujoco] Average state value: 0.5932459835310777
[2022-12-07 12:33:41,901] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 12:33:41,956] [INFO] [controller] EPOCH 1 loss ppo:  -0.01132, loss val: 0.07373
[2022-12-07 12:33:41,998] [INFO] [controller] EPOCH 2 loss ppo:  -0.03232, loss val: 0.07064
[2022-12-07 12:33:42,038] [INFO] [controller] EPOCH 3 loss ppo:  -0.04330, loss val: 0.06635
[2022-12-07 12:33:42,082] [INFO] [controller] EPOCH 4 loss ppo:  -0.05289, loss val: 0.06380
[2022-12-07 12:33:42,092] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:33:42,282] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:33:42,282] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:33:48,116] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:33:54,230] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:33:59,857] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:34:05,926] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:34:11,671] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:34:17,381] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:34:23,006] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:34:28,748] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:34:34,182] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:34:39,741] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4608980534892015
[2022-12-07 12:34:39,741] [INFO] [runner_train_mujoco] Average state value: 0.6222286935547988
[2022-12-07 12:34:39,741] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 12:34:39,788] [INFO] [controller] EPOCH 1 loss ppo:  -0.01097, loss val: 0.06655
[2022-12-07 12:34:39,823] [INFO] [controller] EPOCH 2 loss ppo:  -0.03647, loss val: 0.06469
[2022-12-07 12:34:39,867] [INFO] [controller] EPOCH 3 loss ppo:  -0.04568, loss val: 0.06151
[2022-12-07 12:34:39,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.05256, loss val: 0.05992
[2022-12-07 12:34:39,920] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:34:40,099] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:34:40,099] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:34:46,264] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:34:51,906] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:34:57,499] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:35:03,283] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:35:08,687] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:35:14,610] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:35:19,944] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:35:25,660] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:35:31,061] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:35:36,935] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4023069850010291
[2022-12-07 12:35:36,936] [INFO] [runner_train_mujoco] Average state value: 0.6516510078708331
[2022-12-07 12:35:36,936] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 12:35:36,979] [INFO] [controller] EPOCH 1 loss ppo:  -0.00943, loss val: 0.06625
[2022-12-07 12:35:37,031] [INFO] [controller] EPOCH 2 loss ppo:  -0.03168, loss val: 0.06581
[2022-12-07 12:35:37,078] [INFO] [controller] EPOCH 3 loss ppo:  -0.04227, loss val: 0.06310
[2022-12-07 12:35:37,123] [INFO] [controller] EPOCH 4 loss ppo:  -0.05103, loss val: 0.05899
[2022-12-07 12:35:37,133] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:35:37,334] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:35:37,334] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:35:42,985] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:35:48,577] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:35:54,032] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:35:59,800] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:36:05,337] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:36:11,048] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:36:16,368] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:36:22,123] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:36:28,109] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:36:34,066] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4100792239748504
[2022-12-07 12:36:34,067] [INFO] [runner_train_mujoco] Average state value: 0.6002966785232225
[2022-12-07 12:36:34,067] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 12:36:34,118] [INFO] [controller] EPOCH 1 loss ppo:  -0.00842, loss val: 0.05645
[2022-12-07 12:36:34,155] [INFO] [controller] EPOCH 2 loss ppo:  -0.03072, loss val: 0.05522
[2022-12-07 12:36:34,200] [INFO] [controller] EPOCH 3 loss ppo:  -0.04162, loss val: 0.05468
[2022-12-07 12:36:34,244] [INFO] [controller] EPOCH 4 loss ppo:  -0.04793, loss val: 0.05437
[2022-12-07 12:36:34,254] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:36:34,436] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:36:34,437] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:36:40,520] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:36:46,222] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:36:51,978] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:36:57,432] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:37:03,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:37:08,972] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:37:14,949] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:37:20,861] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:37:26,597] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:37:32,912] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3298856578180674
[2022-12-07 12:37:32,912] [INFO] [runner_train_mujoco] Average state value: 0.5829777830441794
[2022-12-07 12:37:32,912] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 12:37:32,971] [INFO] [controller] EPOCH 1 loss ppo:  -0.00893, loss val: 0.04938
[2022-12-07 12:37:33,017] [INFO] [controller] EPOCH 2 loss ppo:  -0.03071, loss val: 0.04652
[2022-12-07 12:37:33,061] [INFO] [controller] EPOCH 3 loss ppo:  -0.04103, loss val: 0.04594
[2022-12-07 12:37:33,101] [INFO] [controller] EPOCH 4 loss ppo:  -0.04948, loss val: 0.04497
[2022-12-07 12:37:33,109] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:37:33,288] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:37:33,288] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:37:38,952] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:37:44,466] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:37:50,240] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:37:55,862] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:38:01,327] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:38:07,281] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:38:13,087] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:38:18,667] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:38:24,375] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:38:30,442] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5221987296165608
[2022-12-07 12:38:30,442] [INFO] [runner_train_mujoco] Average state value: 0.6270437687635422
[2022-12-07 12:38:30,442] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 12:38:30,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.00716, loss val: 0.05792
[2022-12-07 12:38:30,534] [INFO] [controller] EPOCH 2 loss ppo:  -0.02397, loss val: 0.05662
[2022-12-07 12:38:30,577] [INFO] [controller] EPOCH 3 loss ppo:  -0.03490, loss val: 0.05135
[2022-12-07 12:38:30,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.04567, loss val: 0.05192
[2022-12-07 12:38:30,622] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:38:30,814] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:38:30,815] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:38:36,873] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:38:43,024] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:38:48,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:38:54,635] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:39:00,729] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:39:07,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:39:12,822] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:39:18,891] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:39:25,182] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:39:31,163] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6652121521402574
[2022-12-07 12:39:31,163] [INFO] [runner_train_mujoco] Average state value: 0.5670305479168891
[2022-12-07 12:39:31,163] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 12:39:31,221] [INFO] [controller] EPOCH 1 loss ppo:  -0.01026, loss val: 0.04281
[2022-12-07 12:39:31,267] [INFO] [controller] EPOCH 2 loss ppo:  -0.03424, loss val: 0.04275
[2022-12-07 12:39:31,376] [INFO] [controller] EPOCH 3 loss ppo:  -0.04827, loss val: 0.04336
[2022-12-07 12:39:31,420] [INFO] [controller] EPOCH 4 loss ppo:  -0.05603, loss val: 0.04370
[2022-12-07 12:39:31,430] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:39:31,629] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:39:31,629] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:39:37,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:39:43,435] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:39:49,429] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:39:55,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:40:01,436] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:40:07,548] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:40:13,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:40:18,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:40:24,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:40:30,174] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.706910475401646
[2022-12-07 12:40:30,174] [INFO] [runner_train_mujoco] Average state value: 0.5248157568176588
[2022-12-07 12:40:30,174] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 12:40:30,248] [INFO] [controller] EPOCH 1 loss ppo:  -0.01112, loss val: 0.03683
[2022-12-07 12:40:30,302] [INFO] [controller] EPOCH 2 loss ppo:  -0.03302, loss val: 0.03687
[2022-12-07 12:40:30,350] [INFO] [controller] EPOCH 3 loss ppo:  -0.04984, loss val: 0.03508
[2022-12-07 12:40:30,401] [INFO] [controller] EPOCH 4 loss ppo:  -0.05753, loss val: 0.03369
[2022-12-07 12:40:30,411] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:40:30,617] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:40:30,617] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:40:36,387] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:40:42,014] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:40:48,400] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:40:54,411] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:41:00,645] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:41:06,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:41:13,208] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:41:19,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:41:24,898] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:41:30,715] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6403129990417126
[2022-12-07 12:41:30,715] [INFO] [runner_train_mujoco] Average state value: 0.5056968219478926
[2022-12-07 12:41:30,716] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 12:41:30,765] [INFO] [controller] EPOCH 1 loss ppo:  -0.01264, loss val: 0.05080
[2022-12-07 12:41:30,809] [INFO] [controller] EPOCH 2 loss ppo:  -0.03580, loss val: 0.05097
[2022-12-07 12:41:30,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.04719, loss val: 0.04889
[2022-12-07 12:41:30,887] [INFO] [controller] EPOCH 4 loss ppo:  -0.05423, loss val: 0.04897
[2022-12-07 12:41:30,896] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:41:31,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:41:31,088] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:41:36,890] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:41:43,789] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:41:49,454] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:41:55,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:42:01,355] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:42:07,402] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:42:13,212] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:42:19,487] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:42:25,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:42:31,787] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.857161713920377
[2022-12-07 12:42:31,787] [INFO] [runner_train_mujoco] Average state value: 0.5443434851964315
[2022-12-07 12:42:31,787] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 12:42:31,841] [INFO] [controller] EPOCH 1 loss ppo:  -0.01186, loss val: 0.04240
[2022-12-07 12:42:31,887] [INFO] [controller] EPOCH 2 loss ppo:  -0.03559, loss val: 0.04082
[2022-12-07 12:42:31,935] [INFO] [controller] EPOCH 3 loss ppo:  -0.04810, loss val: 0.04026
[2022-12-07 12:42:31,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.05651, loss val: 0.04132
[2022-12-07 12:42:31,992] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:42:32,193] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:42:32,194] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:42:38,446] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:42:46,350] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:42:53,811] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:43:00,915] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:43:07,175] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:43:13,209] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:43:19,526] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:43:27,699] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:43:34,098] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:43:40,058] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8719914874084905
[2022-12-07 12:43:40,058] [INFO] [runner_train_mujoco] Average state value: 0.6126613513628641
[2022-12-07 12:43:40,058] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 12:43:40,113] [INFO] [controller] EPOCH 1 loss ppo:  -0.01017, loss val: 0.04415
[2022-12-07 12:43:40,337] [INFO] [controller] EPOCH 2 loss ppo:  -0.03201, loss val: 0.04274
[2022-12-07 12:43:40,429] [INFO] [controller] EPOCH 3 loss ppo:  -0.04417, loss val: 0.04305
[2022-12-07 12:43:40,488] [INFO] [controller] EPOCH 4 loss ppo:  -0.05681, loss val: 0.04279
[2022-12-07 12:43:40,500] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:43:40,735] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:43:40,735] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:43:47,742] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:43:54,043] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:44:00,254] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:44:06,857] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:44:13,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:44:19,033] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:44:25,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:44:31,694] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:44:37,693] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:44:43,952] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9495145959898382
[2022-12-07 12:44:43,952] [INFO] [runner_train_mujoco] Average state value: 0.6015467099348704
[2022-12-07 12:44:43,953] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 12:44:44,021] [INFO] [controller] EPOCH 1 loss ppo:  -0.01264, loss val: 0.04114
[2022-12-07 12:44:44,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.03248, loss val: 0.03835
[2022-12-07 12:44:44,138] [INFO] [controller] EPOCH 3 loss ppo:  -0.04435, loss val: 0.03759
[2022-12-07 12:44:44,189] [INFO] [controller] EPOCH 4 loss ppo:  -0.05429, loss val: 0.03536
[2022-12-07 12:44:44,201] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:44:44,471] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:44:44,471] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:44:50,754] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:44:56,853] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:45:03,554] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:45:10,790] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:45:17,208] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:45:24,388] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:45:32,156] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:45:39,892] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:45:47,388] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:45:54,742] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.212268333860446
[2022-12-07 12:45:54,742] [INFO] [runner_train_mujoco] Average state value: 0.5404911214510599
[2022-12-07 12:45:54,742] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 12:45:54,805] [INFO] [controller] EPOCH 1 loss ppo:  -0.01205, loss val: 0.04321
[2022-12-07 12:45:54,858] [INFO] [controller] EPOCH 2 loss ppo:  -0.03519, loss val: 0.04839
[2022-12-07 12:45:54,918] [INFO] [controller] EPOCH 3 loss ppo:  -0.05023, loss val: 0.04599
[2022-12-07 12:45:54,977] [INFO] [controller] EPOCH 4 loss ppo:  -0.05856, loss val: 0.04433
[2022-12-07 12:45:54,990] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:45:55,224] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:45:55,224] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:46:04,020] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:46:12,167] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:46:19,652] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:46:27,178] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:46:35,066] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:46:43,190] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:46:50,866] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:46:59,148] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:47:06,989] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:47:14,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1289981203229584
[2022-12-07 12:47:14,146] [INFO] [runner_train_mujoco] Average state value: 0.5466521658301353
[2022-12-07 12:47:14,146] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 12:47:14,211] [INFO] [controller] EPOCH 1 loss ppo:  -0.01108, loss val: 0.03771
[2022-12-07 12:47:14,268] [INFO] [controller] EPOCH 2 loss ppo:  -0.02965, loss val: 0.03734
[2022-12-07 12:47:14,323] [INFO] [controller] EPOCH 3 loss ppo:  -0.04224, loss val: 0.03736
[2022-12-07 12:47:14,378] [INFO] [controller] EPOCH 4 loss ppo:  -0.05143, loss val: 0.03734
[2022-12-07 12:47:14,388] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:47:14,606] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:47:14,607] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:47:22,259] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:47:28,855] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:47:36,121] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:47:43,371] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:47:50,549] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:47:57,434] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:48:04,531] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:48:12,041] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:48:18,871] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:48:26,751] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5983777204470466
[2022-12-07 12:48:26,751] [INFO] [runner_train_mujoco] Average state value: 0.561582995712757
[2022-12-07 12:48:26,751] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 12:48:26,815] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.03677
[2022-12-07 12:48:26,865] [INFO] [controller] EPOCH 2 loss ppo:  -0.03338, loss val: 0.03555
[2022-12-07 12:48:26,916] [INFO] [controller] EPOCH 3 loss ppo:  -0.04816, loss val: 0.03568
[2022-12-07 12:48:26,968] [INFO] [controller] EPOCH 4 loss ppo:  -0.06003, loss val: 0.03617
[2022-12-07 12:48:26,978] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:48:27,192] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:48:27,193] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:48:34,360] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:48:41,733] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:48:48,785] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:48:55,624] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:49:02,440] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:49:09,250] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:49:15,870] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:49:21,766] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:49:27,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:49:33,855] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4985681414970977
[2022-12-07 12:49:33,855] [INFO] [runner_train_mujoco] Average state value: 0.5619493402838708
[2022-12-07 12:49:33,856] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 12:49:33,908] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.05017
[2022-12-07 12:49:33,950] [INFO] [controller] EPOCH 2 loss ppo:  -0.03477, loss val: 0.04985
[2022-12-07 12:49:33,996] [INFO] [controller] EPOCH 3 loss ppo:  -0.04554, loss val: 0.05053
[2022-12-07 12:49:34,041] [INFO] [controller] EPOCH 4 loss ppo:  -0.05360, loss val: 0.04936
[2022-12-07 12:49:34,051] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:49:34,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:49:34,248] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:49:40,750] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:49:47,397] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:49:53,985] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:50:00,316] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:50:06,331] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:50:12,760] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:50:18,996] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:50:25,246] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:50:31,415] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:50:37,832] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.713772017817543
[2022-12-07 12:50:37,832] [INFO] [runner_train_mujoco] Average state value: 0.5722781855066618
[2022-12-07 12:50:37,832] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 12:50:37,887] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.03387
[2022-12-07 12:50:37,936] [INFO] [controller] EPOCH 2 loss ppo:  -0.03781, loss val: 0.03371
[2022-12-07 12:50:37,985] [INFO] [controller] EPOCH 3 loss ppo:  -0.05136, loss val: 0.03531
[2022-12-07 12:50:38,031] [INFO] [controller] EPOCH 4 loss ppo:  -0.06062, loss val: 0.03714
[2022-12-07 12:50:38,041] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:50:38,249] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:50:38,249] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:50:44,837] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:50:51,423] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:50:58,248] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:51:04,385] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:51:10,747] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:51:16,922] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:51:23,270] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:51:29,424] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:51:35,474] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:51:41,422] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.194254520121528
[2022-12-07 12:51:41,423] [INFO] [runner_train_mujoco] Average state value: 0.576782386124134
[2022-12-07 12:51:41,423] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 12:51:41,477] [INFO] [controller] EPOCH 1 loss ppo:  -0.01594, loss val: 0.04182
[2022-12-07 12:51:41,523] [INFO] [controller] EPOCH 2 loss ppo:  -0.03987, loss val: 0.04206
[2022-12-07 12:51:41,569] [INFO] [controller] EPOCH 3 loss ppo:  -0.05341, loss val: 0.04196
[2022-12-07 12:51:41,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.06539, loss val: 0.04210
[2022-12-07 12:51:41,626] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:51:41,808] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:51:41,809] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:51:48,065] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:51:54,191] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:52:00,148] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:52:06,019] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:52:12,453] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:52:18,517] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:52:24,544] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:52:30,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:52:36,513] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:52:42,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.222659856127611
[2022-12-07 12:52:42,746] [INFO] [runner_train_mujoco] Average state value: 0.5668323980371157
[2022-12-07 12:52:42,746] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 12:52:42,797] [INFO] [controller] EPOCH 1 loss ppo:  -0.01187, loss val: 0.04663
[2022-12-07 12:52:42,839] [INFO] [controller] EPOCH 2 loss ppo:  -0.03303, loss val: 0.04621
[2022-12-07 12:52:42,881] [INFO] [controller] EPOCH 3 loss ppo:  -0.04492, loss val: 0.04653
[2022-12-07 12:52:42,927] [INFO] [controller] EPOCH 4 loss ppo:  -0.05886, loss val: 0.04647
[2022-12-07 12:52:42,938] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:52:43,125] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:52:43,125] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:52:49,257] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:52:55,086] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:53:00,637] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:53:06,179] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:53:11,666] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:53:17,433] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:53:23,213] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:53:29,261] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:53:34,625] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:53:40,111] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3900652386918706
[2022-12-07 12:53:40,111] [INFO] [runner_train_mujoco] Average state value: 0.571432753264904
[2022-12-07 12:53:40,112] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 12:53:40,162] [INFO] [controller] EPOCH 1 loss ppo:  -0.01517, loss val: 0.03775
[2022-12-07 12:53:40,206] [INFO] [controller] EPOCH 2 loss ppo:  -0.03727, loss val: 0.03748
[2022-12-07 12:53:40,314] [INFO] [controller] EPOCH 3 loss ppo:  -0.04755, loss val: 0.03784
[2022-12-07 12:53:40,356] [INFO] [controller] EPOCH 4 loss ppo:  -0.06073, loss val: 0.03545
[2022-12-07 12:53:40,363] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:53:40,533] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:53:40,533] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:53:46,139] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:53:51,671] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:53:56,987] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:54:03,075] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:54:08,609] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:54:14,501] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:54:19,964] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:54:25,409] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:54:30,931] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:54:36,863] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.722912979781048
[2022-12-07 12:54:36,864] [INFO] [runner_train_mujoco] Average state value: 0.5839261024196942
[2022-12-07 12:54:36,864] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 12:54:36,909] [INFO] [controller] EPOCH 1 loss ppo:  -0.01299, loss val: 0.03713
[2022-12-07 12:54:36,945] [INFO] [controller] EPOCH 2 loss ppo:  -0.03557, loss val: 0.03742
[2022-12-07 12:54:36,981] [INFO] [controller] EPOCH 3 loss ppo:  -0.04624, loss val: 0.03547
[2022-12-07 12:54:37,012] [INFO] [controller] EPOCH 4 loss ppo:  -0.05357, loss val: 0.03642
[2022-12-07 12:54:37,022] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:54:37,208] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:54:37,208] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:54:43,079] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:54:48,586] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:54:53,826] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:54:59,202] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:55:05,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:55:10,699] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:55:16,687] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:55:22,189] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:55:27,603] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:55:33,186] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8659252136961983
[2022-12-07 12:55:33,186] [INFO] [runner_train_mujoco] Average state value: 0.5664133553902307
[2022-12-07 12:55:33,186] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 12:55:33,241] [INFO] [controller] EPOCH 1 loss ppo:  -0.01268, loss val: 0.05130
[2022-12-07 12:55:33,282] [INFO] [controller] EPOCH 2 loss ppo:  -0.02621, loss val: 0.04802
[2022-12-07 12:55:33,333] [INFO] [controller] EPOCH 3 loss ppo:  -0.03925, loss val: 0.04503
[2022-12-07 12:55:33,377] [INFO] [controller] EPOCH 4 loss ppo:  -0.05245, loss val: 0.04178
[2022-12-07 12:55:33,387] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:55:33,583] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:55:33,584] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:55:39,512] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:55:45,479] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:55:51,197] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:55:56,975] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:56:02,604] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:56:08,228] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:56:13,545] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:56:18,978] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:56:24,593] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:56:30,128] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.191959216867611
[2022-12-07 12:56:30,128] [INFO] [runner_train_mujoco] Average state value: 0.4904952961007754
[2022-12-07 12:56:30,129] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 12:56:30,175] [INFO] [controller] EPOCH 1 loss ppo:  -0.01478, loss val: 0.03132
[2022-12-07 12:56:30,220] [INFO] [controller] EPOCH 2 loss ppo:  -0.03346, loss val: 0.03157
[2022-12-07 12:56:30,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.04708, loss val: 0.03215
[2022-12-07 12:56:30,294] [INFO] [controller] EPOCH 4 loss ppo:  -0.05554, loss val: 0.03244
[2022-12-07 12:56:30,304] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:56:30,482] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:56:30,482] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:56:36,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:56:42,774] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:56:48,787] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:56:54,426] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:57:00,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:57:06,447] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:57:12,142] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:57:17,770] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:57:23,462] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:57:28,968] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.221022321382084
[2022-12-07 12:57:28,968] [INFO] [runner_train_mujoco] Average state value: 0.4458975634276867
[2022-12-07 12:57:28,968] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 12:57:29,021] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.03500
[2022-12-07 12:57:29,068] [INFO] [controller] EPOCH 2 loss ppo:  -0.03024, loss val: 0.03497
[2022-12-07 12:57:29,112] [INFO] [controller] EPOCH 3 loss ppo:  -0.04227, loss val: 0.03505
[2022-12-07 12:57:29,160] [INFO] [controller] EPOCH 4 loss ppo:  -0.05492, loss val: 0.03452
[2022-12-07 12:57:29,175] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:57:29,380] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:57:29,380] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:57:35,600] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:57:41,647] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:57:47,493] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:57:53,520] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:57:59,767] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:58:05,767] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:58:12,051] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:58:18,220] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:58:24,292] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:58:30,779] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3927631734318324
[2022-12-07 12:58:30,779] [INFO] [runner_train_mujoco] Average state value: 0.44119628963867824
[2022-12-07 12:58:30,779] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 12:58:30,836] [INFO] [controller] EPOCH 1 loss ppo:  -0.01549, loss val: 0.04046
[2022-12-07 12:58:30,882] [INFO] [controller] EPOCH 2 loss ppo:  -0.02838, loss val: 0.03767
[2022-12-07 12:58:30,931] [INFO] [controller] EPOCH 3 loss ppo:  -0.04470, loss val: 0.03813
[2022-12-07 12:58:30,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.05126, loss val: 0.03627
[2022-12-07 12:58:30,994] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:58:31,179] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:58:31,179] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:58:37,639] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:58:43,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:58:49,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:58:54,723] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:59:00,321] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 12:59:06,065] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 12:59:11,630] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 12:59:17,238] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 12:59:23,210] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 12:59:29,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.54076978662532
[2022-12-07 12:59:29,508] [INFO] [runner_train_mujoco] Average state value: 0.45832943841815005
[2022-12-07 12:59:29,508] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 12:59:29,562] [INFO] [controller] EPOCH 1 loss ppo:  -0.01561, loss val: 0.03924
[2022-12-07 12:59:29,609] [INFO] [controller] EPOCH 2 loss ppo:  -0.03370, loss val: 0.04058
[2022-12-07 12:59:29,657] [INFO] [controller] EPOCH 3 loss ppo:  -0.04179, loss val: 0.03987
[2022-12-07 12:59:29,702] [INFO] [controller] EPOCH 4 loss ppo:  -0.05421, loss val: 0.04019
[2022-12-07 12:59:29,712] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 12:59:29,914] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 12:59:29,914] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 12:59:36,043] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 12:59:41,608] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 12:59:47,275] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 12:59:52,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 12:59:58,272] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:00:04,233] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:00:09,661] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:00:15,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:00:21,293] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:00:26,584] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.732198422380962
[2022-12-07 13:00:26,584] [INFO] [runner_train_mujoco] Average state value: 0.48094223347306253
[2022-12-07 13:00:26,584] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 13:00:26,630] [INFO] [controller] EPOCH 1 loss ppo:  -0.01471, loss val: 0.03863
[2022-12-07 13:00:26,675] [INFO] [controller] EPOCH 2 loss ppo:  -0.02627, loss val: 0.03928
[2022-12-07 13:00:26,714] [INFO] [controller] EPOCH 3 loss ppo:  -0.04115, loss val: 0.03872
[2022-12-07 13:00:26,760] [INFO] [controller] EPOCH 4 loss ppo:  -0.05328, loss val: 0.03768
[2022-12-07 13:00:26,770] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:00:26,955] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:00:26,956] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:00:32,541] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:00:38,651] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:00:44,618] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:00:50,322] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:00:55,848] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:01:01,179] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:01:06,932] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:01:12,412] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:01:17,832] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:01:23,311] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8703238375443467
[2022-12-07 13:01:23,311] [INFO] [runner_train_mujoco] Average state value: 0.47622303634881985
[2022-12-07 13:01:23,311] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 13:01:23,408] [INFO] [controller] EPOCH 1 loss ppo:  -0.01546, loss val: 0.05409
[2022-12-07 13:01:23,446] [INFO] [controller] EPOCH 2 loss ppo:  -0.02761, loss val: 0.05337
[2022-12-07 13:01:23,486] [INFO] [controller] EPOCH 3 loss ppo:  -0.03977, loss val: 0.05206
[2022-12-07 13:01:23,529] [INFO] [controller] EPOCH 4 loss ppo:  -0.05177, loss val: 0.05200
[2022-12-07 13:01:23,539] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:01:23,726] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:01:23,726] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:01:29,191] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:01:34,878] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:01:40,537] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:01:45,881] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:01:51,654] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:01:57,499] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:02:02,877] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:02:08,727] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:02:14,204] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:02:19,776] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.974889454936111
[2022-12-07 13:02:19,777] [INFO] [runner_train_mujoco] Average state value: 0.5069726427793503
[2022-12-07 13:02:19,777] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 13:02:19,828] [INFO] [controller] EPOCH 1 loss ppo:  -0.01189, loss val: 0.04856
[2022-12-07 13:02:19,871] [INFO] [controller] EPOCH 2 loss ppo:  -0.02399, loss val: 0.04869
[2022-12-07 13:02:19,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.03630, loss val: 0.04843
[2022-12-07 13:02:19,957] [INFO] [controller] EPOCH 4 loss ppo:  -0.04685, loss val: 0.04905
[2022-12-07 13:02:19,967] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:02:20,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:02:20,160] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:02:25,892] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:02:31,429] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:02:36,884] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:02:42,559] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:02:48,051] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:02:53,369] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:02:58,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:03:04,637] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:03:10,483] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:03:16,005] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.121547058629867
[2022-12-07 13:03:16,005] [INFO] [runner_train_mujoco] Average state value: 0.5311110790769258
[2022-12-07 13:03:16,006] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 13:03:16,056] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.04059
[2022-12-07 13:03:16,100] [INFO] [controller] EPOCH 2 loss ppo:  -0.02091, loss val: 0.03677
[2022-12-07 13:03:16,152] [INFO] [controller] EPOCH 3 loss ppo:  -0.03545, loss val: 0.03466
[2022-12-07 13:03:16,200] [INFO] [controller] EPOCH 4 loss ppo:  -0.04271, loss val: 0.03397
[2022-12-07 13:03:16,211] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:03:16,421] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:03:16,421] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:03:22,501] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:03:28,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:03:34,484] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:03:40,242] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:03:45,859] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:03:51,303] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:03:56,811] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:04:02,483] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:04:08,054] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:04:14,068] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.293238934932709
[2022-12-07 13:04:14,069] [INFO] [runner_train_mujoco] Average state value: 0.4919999878406524
[2022-12-07 13:04:14,069] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 13:04:14,119] [INFO] [controller] EPOCH 1 loss ppo:  -0.01104, loss val: 0.04500
[2022-12-07 13:04:14,157] [INFO] [controller] EPOCH 2 loss ppo:  -0.02319, loss val: 0.04600
[2022-12-07 13:04:14,197] [INFO] [controller] EPOCH 3 loss ppo:  -0.03514, loss val: 0.04597
[2022-12-07 13:04:14,239] [INFO] [controller] EPOCH 4 loss ppo:  -0.04497, loss val: 0.04657
[2022-12-07 13:04:14,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:04:14,452] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:04:14,453] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:04:20,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:04:26,695] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:04:32,660] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:04:38,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:04:44,370] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:04:50,107] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:04:55,580] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:05:01,122] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:05:06,963] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:05:12,682] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.620723581156778
[2022-12-07 13:05:12,682] [INFO] [runner_train_mujoco] Average state value: 0.4603828195830186
[2022-12-07 13:05:12,682] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 13:05:12,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01615, loss val: 0.04008
[2022-12-07 13:05:12,790] [INFO] [controller] EPOCH 2 loss ppo:  -0.02626, loss val: 0.03950
[2022-12-07 13:05:12,838] [INFO] [controller] EPOCH 3 loss ppo:  -0.03879, loss val: 0.03642
[2022-12-07 13:05:12,885] [INFO] [controller] EPOCH 4 loss ppo:  -0.04825, loss val: 0.03810
[2022-12-07 13:05:12,896] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:05:13,120] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:05:13,121] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:05:19,458] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:05:25,453] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:05:31,746] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:05:37,488] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:05:43,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:05:48,876] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:05:54,414] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:06:00,317] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:06:06,775] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:06:13,145] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.868264469242203
[2022-12-07 13:06:13,146] [INFO] [runner_train_mujoco] Average state value: 0.48175398528575897
[2022-12-07 13:06:13,146] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 13:06:13,198] [INFO] [controller] EPOCH 1 loss ppo:  -0.01530, loss val: 0.04144
[2022-12-07 13:06:13,244] [INFO] [controller] EPOCH 2 loss ppo:  -0.02626, loss val: 0.04024
[2022-12-07 13:06:13,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.03494, loss val: 0.04022
[2022-12-07 13:06:13,339] [INFO] [controller] EPOCH 4 loss ppo:  -0.04588, loss val: 0.04107
[2022-12-07 13:06:13,350] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:06:13,557] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:06:13,558] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:06:19,668] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:06:25,683] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:06:31,330] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:06:36,799] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:06:42,758] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:06:48,613] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:06:54,204] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:06:59,840] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:07:06,908] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:07:13,534] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.885800676412411
[2022-12-07 13:07:13,535] [INFO] [runner_train_mujoco] Average state value: 0.48432637109359106
[2022-12-07 13:07:13,535] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 13:07:13,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.03516
[2022-12-07 13:07:13,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.02436, loss val: 0.03579
[2022-12-07 13:07:13,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.03453, loss val: 0.03557
[2022-12-07 13:07:13,745] [INFO] [controller] EPOCH 4 loss ppo:  -0.04765, loss val: 0.03451
[2022-12-07 13:07:13,756] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:07:13,983] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:07:13,983] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:07:20,481] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:07:26,994] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:07:32,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:07:38,460] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:07:43,919] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:07:49,367] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:07:55,035] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:08:01,142] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:08:06,805] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:08:12,262] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.098564920052739
[2022-12-07 13:08:12,262] [INFO] [runner_train_mujoco] Average state value: 0.4565972313483556
[2022-12-07 13:08:12,262] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 13:08:12,314] [INFO] [controller] EPOCH 1 loss ppo:  -0.01306, loss val: 0.04559
[2022-12-07 13:08:12,358] [INFO] [controller] EPOCH 2 loss ppo:  -0.02480, loss val: 0.04665
[2022-12-07 13:08:12,401] [INFO] [controller] EPOCH 3 loss ppo:  -0.03056, loss val: 0.04613
[2022-12-07 13:08:12,450] [INFO] [controller] EPOCH 4 loss ppo:  -0.04242, loss val: 0.04503
[2022-12-07 13:08:12,460] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:08:12,662] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:08:12,662] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:08:18,319] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:08:24,191] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:08:29,417] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:08:34,573] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:08:39,816] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:08:45,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:08:51,747] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:08:57,071] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:09:02,503] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:09:08,091] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.945831018186622
[2022-12-07 13:09:08,092] [INFO] [runner_train_mujoco] Average state value: 0.45971091582377754
[2022-12-07 13:09:08,092] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 13:09:08,146] [INFO] [controller] EPOCH 1 loss ppo:  -0.01353, loss val: 0.03915
[2022-12-07 13:09:08,190] [INFO] [controller] EPOCH 2 loss ppo:  -0.02187, loss val: 0.04025
[2022-12-07 13:09:08,239] [INFO] [controller] EPOCH 3 loss ppo:  -0.02789, loss val: 0.03899
[2022-12-07 13:09:08,290] [INFO] [controller] EPOCH 4 loss ppo:  -0.04069, loss val: 0.04042
[2022-12-07 13:09:08,301] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:09:08,594] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:09:08,595] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:09:14,056] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:09:19,434] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:09:24,957] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:09:30,193] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:09:35,935] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:09:41,219] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:09:46,681] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:09:51,893] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:09:57,553] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:10:03,053] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.013764442817808
[2022-12-07 13:10:03,054] [INFO] [runner_train_mujoco] Average state value: 0.4518238040606182
[2022-12-07 13:10:03,054] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 13:10:03,108] [INFO] [controller] EPOCH 1 loss ppo:  -0.01312, loss val: 0.04464
[2022-12-07 13:10:03,151] [INFO] [controller] EPOCH 2 loss ppo:  -0.02352, loss val: 0.04367
[2022-12-07 13:10:03,194] [INFO] [controller] EPOCH 3 loss ppo:  -0.02901, loss val: 0.04299
[2022-12-07 13:10:03,239] [INFO] [controller] EPOCH 4 loss ppo:  -0.03970, loss val: 0.04201
[2022-12-07 13:10:03,249] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:10:03,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:10:03,446] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:10:09,005] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:10:14,388] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:10:20,185] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:10:26,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:10:31,530] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:10:37,085] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:10:42,424] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:10:47,827] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:10:53,167] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:10:58,507] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.206893971723666
[2022-12-07 13:10:58,508] [INFO] [runner_train_mujoco] Average state value: 0.41666587400436395
[2022-12-07 13:10:58,508] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 13:10:58,561] [INFO] [controller] EPOCH 1 loss ppo:  -0.01415, loss val: 0.04719
[2022-12-07 13:10:58,605] [INFO] [controller] EPOCH 2 loss ppo:  -0.01887, loss val: 0.04950
[2022-12-07 13:10:58,652] [INFO] [controller] EPOCH 3 loss ppo:  -0.02202, loss val: 0.05011
[2022-12-07 13:10:58,697] [INFO] [controller] EPOCH 4 loss ppo:  -0.03819, loss val: 0.04714
[2022-12-07 13:10:58,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:10:58,903] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:10:58,904] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:11:04,696] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:11:10,246] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:11:16,501] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:11:22,572] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:11:28,486] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:11:34,401] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:11:40,163] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:11:45,758] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:11:51,097] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:11:56,974] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.893787925144538
[2022-12-07 13:11:56,974] [INFO] [runner_train_mujoco] Average state value: 0.4196769323547681
[2022-12-07 13:11:56,975] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 13:11:57,031] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04643
[2022-12-07 13:11:57,080] [INFO] [controller] EPOCH 2 loss ppo:  -0.02240, loss val: 0.04667
[2022-12-07 13:11:57,130] [INFO] [controller] EPOCH 3 loss ppo:  -0.02864, loss val: 0.04576
[2022-12-07 13:11:57,180] [INFO] [controller] EPOCH 4 loss ppo:  -0.04159, loss val: 0.04580
[2022-12-07 13:11:57,191] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:11:57,394] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:11:57,395] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:12:03,594] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:12:10,026] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:12:15,835] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:12:21,324] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:12:27,696] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:12:33,756] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:12:40,045] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:12:46,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:12:51,252] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:12:56,550] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.311971093893256
[2022-12-07 13:12:56,551] [INFO] [runner_train_mujoco] Average state value: 0.43936637938022616
[2022-12-07 13:12:56,551] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 13:12:56,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01093, loss val: 0.04860
[2022-12-07 13:12:56,640] [INFO] [controller] EPOCH 2 loss ppo:  -0.01979, loss val: 0.04927
[2022-12-07 13:12:56,685] [INFO] [controller] EPOCH 3 loss ppo:  -0.02699, loss val: 0.04870
[2022-12-07 13:12:56,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.03765, loss val: 0.04975
[2022-12-07 13:12:56,740] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:12:56,932] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:12:56,932] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:13:02,583] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:13:08,030] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:13:13,360] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:13:18,694] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:13:23,908] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:13:28,898] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:13:34,129] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:13:39,268] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:13:44,272] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:13:49,841] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.3230238976239725
[2022-12-07 13:13:49,842] [INFO] [runner_train_mujoco] Average state value: 0.4578073154787222
[2022-12-07 13:13:49,842] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 13:13:49,888] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03751
[2022-12-07 13:13:49,926] [INFO] [controller] EPOCH 2 loss ppo:  -0.02163, loss val: 0.03888
[2022-12-07 13:13:50,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.02329, loss val: 0.03746
[2022-12-07 13:13:50,083] [INFO] [controller] EPOCH 4 loss ppo:  -0.03062, loss val: 0.03749
[2022-12-07 13:13:50,095] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:13:50,303] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:13:50,303] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:13:55,807] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:14:00,947] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:14:05,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:14:10,123] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:14:14,661] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:14:19,030] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:14:23,402] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:14:28,062] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:14:32,706] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:14:37,307] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.34695328209691
[2022-12-07 13:14:37,308] [INFO] [runner_train_mujoco] Average state value: 0.4583124488492807
[2022-12-07 13:14:37,308] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 13:14:37,344] [INFO] [controller] EPOCH 1 loss ppo:  -0.01241, loss val: 0.04624
[2022-12-07 13:14:37,377] [INFO] [controller] EPOCH 2 loss ppo:  -0.01877, loss val: 0.04663
[2022-12-07 13:14:37,406] [INFO] [controller] EPOCH 3 loss ppo:  -0.02521, loss val: 0.04429
[2022-12-07 13:14:37,445] [INFO] [controller] EPOCH 4 loss ppo:  -0.03334, loss val: 0.04363
[2022-12-07 13:14:37,455] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:14:37,616] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:14:37,616] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:14:42,282] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:14:46,785] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:14:51,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:14:55,418] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:14:59,863] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:15:04,328] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:15:08,866] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:15:13,481] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:15:17,769] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:15:22,197] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.581843451806309
[2022-12-07 13:15:22,198] [INFO] [runner_train_mujoco] Average state value: 0.43860676017403605
[2022-12-07 13:15:22,198] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 13:15:22,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.05258
[2022-12-07 13:15:22,271] [INFO] [controller] EPOCH 2 loss ppo:  -0.02329, loss val: 0.05423
[2022-12-07 13:15:22,310] [INFO] [controller] EPOCH 3 loss ppo:  -0.02725, loss val: 0.05255
[2022-12-07 13:15:22,352] [INFO] [controller] EPOCH 4 loss ppo:  -0.03535, loss val: 0.05278
[2022-12-07 13:15:22,361] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:15:22,507] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:15:22,507] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:15:27,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:15:31,554] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:15:35,860] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:15:40,302] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:15:44,454] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:15:48,880] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:15:53,292] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:15:57,630] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:16:02,659] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:16:06,957] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.397763675020326
[2022-12-07 13:16:06,957] [INFO] [runner_train_mujoco] Average state value: 0.4297859462598959
[2022-12-07 13:16:06,957] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 13:16:06,996] [INFO] [controller] EPOCH 1 loss ppo:  -0.01349, loss val: 0.04719
[2022-12-07 13:16:07,029] [INFO] [controller] EPOCH 2 loss ppo:  -0.02172, loss val: 0.04759
[2022-12-07 13:16:07,065] [INFO] [controller] EPOCH 3 loss ppo:  -0.03035, loss val: 0.04705
[2022-12-07 13:16:07,098] [INFO] [controller] EPOCH 4 loss ppo:  -0.03718, loss val: 0.04684
[2022-12-07 13:16:07,107] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:16:07,220] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:16:07,220] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:16:11,685] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:16:15,931] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:16:20,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:16:24,198] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:16:28,789] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:16:33,134] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:16:37,603] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:16:41,865] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:16:46,237] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:16:50,460] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.585599343701434
[2022-12-07 13:16:50,460] [INFO] [runner_train_mujoco] Average state value: 0.42715518574913336
[2022-12-07 13:16:50,460] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 13:16:50,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01289, loss val: 0.04515
[2022-12-07 13:16:50,526] [INFO] [controller] EPOCH 2 loss ppo:  -0.01706, loss val: 0.04622
[2022-12-07 13:16:50,567] [INFO] [controller] EPOCH 3 loss ppo:  -0.02303, loss val: 0.04469
[2022-12-07 13:16:50,611] [INFO] [controller] EPOCH 4 loss ppo:  -0.03071, loss val: 0.04467
[2022-12-07 13:16:50,621] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:16:50,804] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:16:50,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:16:55,523] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:16:59,810] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:17:04,059] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:17:08,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:17:13,029] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:17:17,451] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:17:21,656] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:17:25,881] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:17:30,130] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:17:34,393] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.651465529928757
[2022-12-07 13:17:34,394] [INFO] [runner_train_mujoco] Average state value: 0.4156858448088169
[2022-12-07 13:17:34,394] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 13:17:34,431] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.04440
[2022-12-07 13:17:34,464] [INFO] [controller] EPOCH 2 loss ppo:  -0.01771, loss val: 0.04547
[2022-12-07 13:17:34,502] [INFO] [controller] EPOCH 3 loss ppo:  -0.02739, loss val: 0.04849
[2022-12-07 13:17:34,539] [INFO] [controller] EPOCH 4 loss ppo:  -0.03129, loss val: 0.04627
[2022-12-07 13:17:34,545] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:17:34,650] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:17:34,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:17:39,181] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:17:43,413] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:17:48,055] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:17:53,320] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:17:57,656] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:18:02,386] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:18:06,845] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:18:11,313] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:18:15,891] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:18:20,432] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.8079384494509645
[2022-12-07 13:18:20,432] [INFO] [runner_train_mujoco] Average state value: 0.40299549173315363
[2022-12-07 13:18:20,433] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 13:18:20,471] [INFO] [controller] EPOCH 1 loss ppo:  -0.01257, loss val: 0.05912
[2022-12-07 13:18:20,511] [INFO] [controller] EPOCH 2 loss ppo:  -0.01840, loss val: 0.05930
[2022-12-07 13:18:20,549] [INFO] [controller] EPOCH 3 loss ppo:  -0.02516, loss val: 0.05793
[2022-12-07 13:18:20,581] [INFO] [controller] EPOCH 4 loss ppo:  -0.02866, loss val: 0.05831
[2022-12-07 13:18:20,591] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:18:20,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:18:20,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:18:25,165] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:18:29,540] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:18:34,073] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:18:38,381] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:18:42,478] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:18:46,760] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:18:51,106] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:18:55,710] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:18:59,840] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:19:04,202] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.082455926214853
[2022-12-07 13:19:04,203] [INFO] [runner_train_mujoco] Average state value: 0.4129508018990358
[2022-12-07 13:19:04,203] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 13:19:04,237] [INFO] [controller] EPOCH 1 loss ppo:  -0.01242, loss val: 0.05143
[2022-12-07 13:19:04,267] [INFO] [controller] EPOCH 2 loss ppo:  -0.01722, loss val: 0.05174
[2022-12-07 13:19:04,295] [INFO] [controller] EPOCH 3 loss ppo:  -0.02493, loss val: 0.05295
[2022-12-07 13:19:04,328] [INFO] [controller] EPOCH 4 loss ppo:  -0.02938, loss val: 0.05054
[2022-12-07 13:19:04,337] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:19:04,450] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:19:04,450] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:19:09,173] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:19:13,343] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:19:17,736] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:19:22,333] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:19:26,939] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:19:31,629] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:19:35,965] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:19:40,294] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:19:44,968] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:19:49,663] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.088632824726223
[2022-12-07 13:19:49,663] [INFO] [runner_train_mujoco] Average state value: 0.4176981954673925
[2022-12-07 13:19:49,663] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 13:19:49,705] [INFO] [controller] EPOCH 1 loss ppo:  -0.01266, loss val: 0.04737
[2022-12-07 13:19:49,740] [INFO] [controller] EPOCH 2 loss ppo:  -0.01681, loss val: 0.04813
[2022-12-07 13:19:49,773] [INFO] [controller] EPOCH 3 loss ppo:  -0.02192, loss val: 0.04728
[2022-12-07 13:19:49,814] [INFO] [controller] EPOCH 4 loss ppo:  -0.02556, loss val: 0.04881
[2022-12-07 13:19:49,821] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:19:49,946] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:19:49,947] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:19:54,560] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:19:59,416] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:20:04,244] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:20:08,755] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:20:13,121] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:20:17,881] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:20:22,539] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:20:27,152] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:20:31,600] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:20:36,342] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.106700322160892
[2022-12-07 13:20:36,342] [INFO] [runner_train_mujoco] Average state value: 0.4128768088618914
[2022-12-07 13:20:36,342] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 13:20:36,387] [INFO] [controller] EPOCH 1 loss ppo:  -0.01250, loss val: 0.05483
[2022-12-07 13:20:36,419] [INFO] [controller] EPOCH 2 loss ppo:  -0.01579, loss val: 0.05395
[2022-12-07 13:20:36,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.02182, loss val: 0.05394
[2022-12-07 13:20:36,503] [INFO] [controller] EPOCH 4 loss ppo:  -0.02682, loss val: 0.05383
[2022-12-07 13:20:36,510] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:20:36,656] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:20:36,657] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:20:41,348] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:20:45,874] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:20:50,536] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:20:55,315] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:20:59,876] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:21:04,937] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:21:09,587] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:21:14,299] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:21:18,935] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:21:23,518] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.036091120864628
[2022-12-07 13:21:23,518] [INFO] [runner_train_mujoco] Average state value: 0.40649025621016815
[2022-12-07 13:21:23,518] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 13:21:23,564] [INFO] [controller] EPOCH 1 loss ppo:  -0.01246, loss val: 0.06325
[2022-12-07 13:21:23,600] [INFO] [controller] EPOCH 2 loss ppo:  -0.01589, loss val: 0.06328
[2022-12-07 13:21:23,635] [INFO] [controller] EPOCH 3 loss ppo:  -0.02005, loss val: 0.06295
[2022-12-07 13:21:23,677] [INFO] [controller] EPOCH 4 loss ppo:  -0.02288, loss val: 0.06378
[2022-12-07 13:21:23,683] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:21:23,825] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:21:23,826] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:21:28,647] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:21:33,343] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:21:38,131] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:21:42,811] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:21:47,521] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:21:52,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:21:56,776] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:22:01,197] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:22:05,810] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:22:10,350] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.266849646560703
[2022-12-07 13:22:10,350] [INFO] [runner_train_mujoco] Average state value: 0.40822592182954154
[2022-12-07 13:22:10,351] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 13:22:10,390] [INFO] [controller] EPOCH 1 loss ppo:  -0.01238, loss val: 0.05255
[2022-12-07 13:22:10,422] [INFO] [controller] EPOCH 2 loss ppo:  -0.01348, loss val: 0.05134
[2022-12-07 13:22:10,451] [INFO] [controller] EPOCH 3 loss ppo:  -0.01522, loss val: 0.05343
[2022-12-07 13:22:10,483] [INFO] [controller] EPOCH 4 loss ppo:  -0.01813, loss val: 0.04846
[2022-12-07 13:22:10,490] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:22:10,647] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 13:22:10,648] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 13:22:15,635] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 13:22:20,183] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 13:22:24,806] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 13:22:29,174] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 13:22:33,736] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 13:22:38,280] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 13:22:42,510] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 13:22:46,935] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 13:22:51,300] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 13:22:55,690] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.262220206170456
[2022-12-07 13:22:55,691] [INFO] [runner_train_mujoco] Average state value: 0.4092732889950276
[2022-12-07 13:22:55,691] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 13:22:55,739] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.05868
[2022-12-07 13:22:55,777] [INFO] [controller] EPOCH 2 loss ppo:  -0.01333, loss val: 0.05989
[2022-12-07 13:22:55,819] [INFO] [controller] EPOCH 3 loss ppo:  -0.01452, loss val: 0.05729
[2022-12-07 13:22:55,855] [INFO] [controller] EPOCH 4 loss ppo:  -0.01627, loss val: 0.05690
[2022-12-07 13:22:55,863] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 13:22:55,955] [INFO] [optimize] Finished learning.
