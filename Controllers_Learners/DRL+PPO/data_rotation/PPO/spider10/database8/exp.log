[2022-12-07 07:49:05,987] [INFO] [optimize] Starting learning
[2022-12-07 07:49:06,002] [INFO] [optimize] Starting learning process..
[2022-12-07 07:49:06,088] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:49:06,089] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:49:12,668] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:49:18,497] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:49:24,634] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:49:29,891] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:49:35,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:49:40,840] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:49:46,440] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:49:52,150] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:49:57,898] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:50:03,440] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4658041650520682
[2022-12-07 07:50:03,440] [INFO] [runner_train_mujoco] Average state value: 0.12051531057308118
[2022-12-07 07:50:03,440] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 07:50:03,493] [INFO] [controller] EPOCH 1 loss ppo:  -0.01122, loss val: 0.28704
[2022-12-07 07:50:03,536] [INFO] [controller] EPOCH 2 loss ppo:  -0.03960, loss val: 0.26378
[2022-12-07 07:50:03,571] [INFO] [controller] EPOCH 3 loss ppo:  -0.05168, loss val: 0.22439
[2022-12-07 07:50:03,616] [INFO] [controller] EPOCH 4 loss ppo:  -0.05736, loss val: 0.19189
[2022-12-07 07:50:03,626] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:50:03,805] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:50:03,806] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:50:09,602] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:50:15,283] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:50:21,036] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:50:26,275] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:50:31,910] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:50:37,721] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:50:43,158] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:50:48,549] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:50:54,065] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:50:59,768] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4677534607458803
[2022-12-07 07:50:59,769] [INFO] [runner_train_mujoco] Average state value: 0.26426963168444734
[2022-12-07 07:50:59,769] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 07:50:59,818] [INFO] [controller] EPOCH 1 loss ppo:  -0.01394, loss val: 0.21142
[2022-12-07 07:50:59,860] [INFO] [controller] EPOCH 2 loss ppo:  -0.03743, loss val: 0.18585
[2022-12-07 07:50:59,900] [INFO] [controller] EPOCH 3 loss ppo:  -0.05328, loss val: 0.15830
[2022-12-07 07:50:59,936] [INFO] [controller] EPOCH 4 loss ppo:  -0.06283, loss val: 0.13989
[2022-12-07 07:50:59,947] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:51:00,168] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:51:00,169] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:51:06,256] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:51:11,989] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:51:17,520] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:51:23,166] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:51:28,616] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:51:34,477] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:51:40,537] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:51:46,178] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:51:51,653] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:51:57,221] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3068386007198903
[2022-12-07 07:51:57,221] [INFO] [runner_train_mujoco] Average state value: 0.44858396392315625
[2022-12-07 07:51:57,221] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 07:51:57,269] [INFO] [controller] EPOCH 1 loss ppo:  -0.01196, loss val: 0.11967
[2022-12-07 07:51:57,315] [INFO] [controller] EPOCH 2 loss ppo:  -0.03556, loss val: 0.10553
[2022-12-07 07:51:57,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.04951, loss val: 0.09495
[2022-12-07 07:51:57,394] [INFO] [controller] EPOCH 4 loss ppo:  -0.05918, loss val: 0.08972
[2022-12-07 07:51:57,404] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:51:57,579] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:51:57,579] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:52:03,018] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:52:08,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:52:14,539] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:52:20,178] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:52:25,971] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:52:31,148] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:52:37,004] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:52:42,543] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:52:48,543] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:52:53,822] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4147344372788962
[2022-12-07 07:52:53,822] [INFO] [runner_train_mujoco] Average state value: 0.5508808476453025
[2022-12-07 07:52:53,822] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 07:52:53,874] [INFO] [controller] EPOCH 1 loss ppo:  -0.01304, loss val: 0.08820
[2022-12-07 07:52:53,920] [INFO] [controller] EPOCH 2 loss ppo:  -0.03272, loss val: 0.08385
[2022-12-07 07:52:53,964] [INFO] [controller] EPOCH 3 loss ppo:  -0.04423, loss val: 0.07943
[2022-12-07 07:52:54,008] [INFO] [controller] EPOCH 4 loss ppo:  -0.05320, loss val: 0.07439
[2022-12-07 07:52:54,017] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:52:54,184] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:52:54,184] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:53:00,093] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:53:05,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:53:11,399] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:53:17,143] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:53:22,582] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:53:28,227] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:53:33,882] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:53:39,212] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:53:44,920] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:53:50,999] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3822912496471977
[2022-12-07 07:53:51,000] [INFO] [runner_train_mujoco] Average state value: 0.6049690181414286
[2022-12-07 07:53:51,000] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 07:53:51,067] [INFO] [controller] EPOCH 1 loss ppo:  -0.01118, loss val: 0.07219
[2022-12-07 07:53:51,115] [INFO] [controller] EPOCH 2 loss ppo:  -0.03244, loss val: 0.06929
[2022-12-07 07:53:51,170] [INFO] [controller] EPOCH 3 loss ppo:  -0.04631, loss val: 0.06511
[2022-12-07 07:53:51,215] [INFO] [controller] EPOCH 4 loss ppo:  -0.05187, loss val: 0.06075
[2022-12-07 07:53:51,225] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:53:51,414] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:53:51,414] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:53:56,912] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:54:03,132] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:54:09,299] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:54:15,128] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:54:20,918] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:54:26,507] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:54:31,851] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:54:37,476] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:54:42,954] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:54:48,552] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3949916308212952
[2022-12-07 07:54:48,552] [INFO] [runner_train_mujoco] Average state value: 0.5637973437855641
[2022-12-07 07:54:48,552] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 07:54:48,604] [INFO] [controller] EPOCH 1 loss ppo:  -0.00984, loss val: 0.05690
[2022-12-07 07:54:48,647] [INFO] [controller] EPOCH 2 loss ppo:  -0.03341, loss val: 0.05463
[2022-12-07 07:54:48,689] [INFO] [controller] EPOCH 3 loss ppo:  -0.04701, loss val: 0.05122
[2022-12-07 07:54:48,730] [INFO] [controller] EPOCH 4 loss ppo:  -0.05586, loss val: 0.05000
[2022-12-07 07:54:48,739] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:54:48,884] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:54:48,884] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:54:54,632] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:55:00,585] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:55:06,476] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:55:12,412] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:55:18,016] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:55:23,588] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:55:29,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:55:34,355] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:55:40,110] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:55:45,404] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4278080975082377
[2022-12-07 07:55:45,404] [INFO] [runner_train_mujoco] Average state value: 0.5252992253055175
[2022-12-07 07:55:45,404] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 07:55:45,452] [INFO] [controller] EPOCH 1 loss ppo:  -0.01003, loss val: 0.04347
[2022-12-07 07:55:45,495] [INFO] [controller] EPOCH 2 loss ppo:  -0.03622, loss val: 0.04587
[2022-12-07 07:55:45,536] [INFO] [controller] EPOCH 3 loss ppo:  -0.04488, loss val: 0.04075
[2022-12-07 07:55:45,578] [INFO] [controller] EPOCH 4 loss ppo:  -0.04996, loss val: 0.03939
[2022-12-07 07:55:45,588] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:55:45,768] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:55:45,769] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:55:51,742] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:55:57,196] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:56:03,155] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:56:08,612] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:56:14,190] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:56:19,761] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:56:25,419] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:56:31,254] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:56:36,830] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:56:42,616] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48211375624316555
[2022-12-07 07:56:42,616] [INFO] [runner_train_mujoco] Average state value: 0.5324273300121228
[2022-12-07 07:56:42,616] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 07:56:42,666] [INFO] [controller] EPOCH 1 loss ppo:  -0.01003, loss val: 0.03884
[2022-12-07 07:56:42,705] [INFO] [controller] EPOCH 2 loss ppo:  -0.03265, loss val: 0.03772
[2022-12-07 07:56:42,750] [INFO] [controller] EPOCH 3 loss ppo:  -0.04523, loss val: 0.03757
[2022-12-07 07:56:42,791] [INFO] [controller] EPOCH 4 loss ppo:  -0.05368, loss val: 0.03791
[2022-12-07 07:56:42,799] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:56:42,960] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:56:42,961] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:56:48,506] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:56:54,477] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:57:00,044] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:57:06,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:57:11,674] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:57:17,394] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:57:23,335] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:57:29,168] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:57:34,748] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:57:40,352] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.48594610381038406
[2022-12-07 07:57:40,353] [INFO] [runner_train_mujoco] Average state value: 0.5352547971010208
[2022-12-07 07:57:40,353] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 07:57:40,447] [INFO] [controller] EPOCH 1 loss ppo:  -0.01065, loss val: 0.04823
[2022-12-07 07:57:40,491] [INFO] [controller] EPOCH 2 loss ppo:  -0.02854, loss val: 0.04750
[2022-12-07 07:57:40,530] [INFO] [controller] EPOCH 3 loss ppo:  -0.03587, loss val: 0.04799
[2022-12-07 07:57:40,577] [INFO] [controller] EPOCH 4 loss ppo:  -0.04989, loss val: 0.04422
[2022-12-07 07:57:40,586] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:57:40,747] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:57:40,747] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:57:46,590] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:57:52,565] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:57:57,868] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:58:03,228] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:58:08,925] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:58:14,192] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:58:20,120] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:58:25,990] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:58:31,614] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:58:37,104] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6108004048528219
[2022-12-07 07:58:37,104] [INFO] [runner_train_mujoco] Average state value: 0.5789562629063925
[2022-12-07 07:58:37,104] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 07:58:37,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.01021, loss val: 0.03943
[2022-12-07 07:58:37,198] [INFO] [controller] EPOCH 2 loss ppo:  -0.02989, loss val: 0.04021
[2022-12-07 07:58:37,238] [INFO] [controller] EPOCH 3 loss ppo:  -0.04247, loss val: 0.03927
[2022-12-07 07:58:37,284] [INFO] [controller] EPOCH 4 loss ppo:  -0.05284, loss val: 0.03963
[2022-12-07 07:58:37,293] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:58:37,464] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:58:37,464] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:58:43,273] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:58:48,872] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:58:54,809] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:59:00,273] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 07:59:05,633] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 07:59:11,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 07:59:16,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 07:59:22,300] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 07:59:28,080] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 07:59:33,660] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6998995470306036
[2022-12-07 07:59:33,661] [INFO] [runner_train_mujoco] Average state value: 0.5937666121919951
[2022-12-07 07:59:33,661] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 07:59:33,708] [INFO] [controller] EPOCH 1 loss ppo:  -0.01123, loss val: 0.03998
[2022-12-07 07:59:33,750] [INFO] [controller] EPOCH 2 loss ppo:  -0.02908, loss val: 0.03974
[2022-12-07 07:59:33,791] [INFO] [controller] EPOCH 3 loss ppo:  -0.04082, loss val: 0.03792
[2022-12-07 07:59:33,835] [INFO] [controller] EPOCH 4 loss ppo:  -0.05177, loss val: 0.03714
[2022-12-07 07:59:33,844] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 07:59:34,023] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 07:59:34,024] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 07:59:39,914] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 07:59:46,339] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 07:59:52,363] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 07:59:57,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:00:03,867] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:00:09,495] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:00:15,275] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:00:20,810] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:00:26,116] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:00:32,027] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6286579910276603
[2022-12-07 08:00:32,027] [INFO] [runner_train_mujoco] Average state value: 0.5489645791451137
[2022-12-07 08:00:32,027] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 08:00:32,074] [INFO] [controller] EPOCH 1 loss ppo:  -0.01079, loss val: 0.03117
[2022-12-07 08:00:32,116] [INFO] [controller] EPOCH 2 loss ppo:  -0.03444, loss val: 0.03034
[2022-12-07 08:00:32,222] [INFO] [controller] EPOCH 3 loss ppo:  -0.04722, loss val: 0.03337
[2022-12-07 08:00:32,269] [INFO] [controller] EPOCH 4 loss ppo:  -0.05722, loss val: 0.03018
[2022-12-07 08:00:32,277] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:00:32,454] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:00:32,454] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:00:37,976] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:00:43,802] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:00:49,397] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:00:55,185] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:01:00,510] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:01:06,051] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:01:11,631] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:01:17,344] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:01:23,325] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:01:28,853] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8332542598147882
[2022-12-07 08:01:28,853] [INFO] [runner_train_mujoco] Average state value: 0.5143805912733078
[2022-12-07 08:01:28,853] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 08:01:28,903] [INFO] [controller] EPOCH 1 loss ppo:  -0.01109, loss val: 0.03896
[2022-12-07 08:01:28,947] [INFO] [controller] EPOCH 2 loss ppo:  -0.03202, loss val: 0.03851
[2022-12-07 08:01:28,989] [INFO] [controller] EPOCH 3 loss ppo:  -0.04244, loss val: 0.04063
[2022-12-07 08:01:29,037] [INFO] [controller] EPOCH 4 loss ppo:  -0.05320, loss val: 0.03932
[2022-12-07 08:01:29,047] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:01:29,212] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:01:29,212] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:01:34,777] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:01:40,590] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:01:46,029] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:01:51,404] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:01:57,095] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:02:03,041] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:02:08,745] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:02:14,669] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:02:20,201] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:02:25,824] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9720985926414464
[2022-12-07 08:02:25,825] [INFO] [runner_train_mujoco] Average state value: 0.5254715727567673
[2022-12-07 08:02:25,825] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 08:02:25,871] [INFO] [controller] EPOCH 1 loss ppo:  -0.01124, loss val: 0.04125
[2022-12-07 08:02:25,915] [INFO] [controller] EPOCH 2 loss ppo:  -0.02918, loss val: 0.03936
[2022-12-07 08:02:25,958] [INFO] [controller] EPOCH 3 loss ppo:  -0.04242, loss val: 0.03906
[2022-12-07 08:02:26,004] [INFO] [controller] EPOCH 4 loss ppo:  -0.05059, loss val: 0.03794
[2022-12-07 08:02:26,014] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:02:26,196] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:02:26,197] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:02:31,606] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:02:37,838] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:02:43,195] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:02:48,606] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:02:54,324] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:02:59,630] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:03:05,310] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:03:10,807] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:03:16,916] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:03:22,346] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.172093257522297
[2022-12-07 08:03:22,346] [INFO] [runner_train_mujoco] Average state value: 0.5438332364559174
[2022-12-07 08:03:22,346] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 08:03:22,399] [INFO] [controller] EPOCH 1 loss ppo:  -0.01343, loss val: 0.03565
[2022-12-07 08:03:22,444] [INFO] [controller] EPOCH 2 loss ppo:  -0.03651, loss val: 0.03512
[2022-12-07 08:03:22,489] [INFO] [controller] EPOCH 3 loss ppo:  -0.04940, loss val: 0.03517
[2022-12-07 08:03:22,542] [INFO] [controller] EPOCH 4 loss ppo:  -0.05833, loss val: 0.03409
[2022-12-07 08:03:22,551] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:03:22,765] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:03:22,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:03:28,657] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:03:34,150] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:03:39,964] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:03:45,467] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:03:51,228] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:03:56,398] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:04:01,869] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:04:07,349] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:04:13,158] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:04:18,369] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.56019220870505
[2022-12-07 08:04:18,369] [INFO] [runner_train_mujoco] Average state value: 0.5179824157953262
[2022-12-07 08:04:18,369] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 08:04:18,420] [INFO] [controller] EPOCH 1 loss ppo:  -0.01441, loss val: 0.04589
[2022-12-07 08:04:18,460] [INFO] [controller] EPOCH 2 loss ppo:  -0.03360, loss val: 0.04614
[2022-12-07 08:04:18,503] [INFO] [controller] EPOCH 3 loss ppo:  -0.04521, loss val: 0.04470
[2022-12-07 08:04:18,545] [INFO] [controller] EPOCH 4 loss ppo:  -0.05718, loss val: 0.04288
[2022-12-07 08:04:18,553] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:04:18,718] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:04:18,718] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:04:24,626] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:04:30,526] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:04:36,136] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:04:41,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:04:47,605] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:04:52,947] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:04:58,456] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:05:04,129] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:05:09,298] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:05:14,855] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.5159663628613593
[2022-12-07 08:05:14,855] [INFO] [runner_train_mujoco] Average state value: 0.5498900467157365
[2022-12-07 08:05:14,855] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 08:05:14,909] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.03574
[2022-12-07 08:05:14,965] [INFO] [controller] EPOCH 2 loss ppo:  -0.03468, loss val: 0.03598
[2022-12-07 08:05:15,014] [INFO] [controller] EPOCH 3 loss ppo:  -0.04817, loss val: 0.03726
[2022-12-07 08:05:15,060] [INFO] [controller] EPOCH 4 loss ppo:  -0.05848, loss val: 0.03646
[2022-12-07 08:05:15,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:05:15,237] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:05:15,238] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:05:20,550] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:05:26,258] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:05:31,523] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:05:36,972] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:05:42,296] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:05:48,049] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:05:53,734] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:05:59,204] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:06:04,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:06:10,409] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.722546914008722
[2022-12-07 08:06:10,409] [INFO] [runner_train_mujoco] Average state value: 0.5908392261266708
[2022-12-07 08:06:10,409] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 08:06:10,461] [INFO] [controller] EPOCH 1 loss ppo:  -0.01329, loss val: 0.03594
[2022-12-07 08:06:10,509] [INFO] [controller] EPOCH 2 loss ppo:  -0.03165, loss val: 0.03629
[2022-12-07 08:06:10,554] [INFO] [controller] EPOCH 3 loss ppo:  -0.04649, loss val: 0.03623
[2022-12-07 08:06:10,600] [INFO] [controller] EPOCH 4 loss ppo:  -0.05534, loss val: 0.03559
[2022-12-07 08:06:10,608] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:06:10,781] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:06:10,781] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:06:16,473] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:06:22,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:06:27,585] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:06:32,831] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:06:38,320] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:06:43,985] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:06:49,363] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:06:55,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:07:00,929] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:07:07,651] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.9208376101460156
[2022-12-07 08:07:07,651] [INFO] [runner_train_mujoco] Average state value: 0.5852056540052095
[2022-12-07 08:07:07,651] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 08:07:07,704] [INFO] [controller] EPOCH 1 loss ppo:  -0.01592, loss val: 0.03851
[2022-12-07 08:07:07,748] [INFO] [controller] EPOCH 2 loss ppo:  -0.03592, loss val: 0.04078
[2022-12-07 08:07:07,793] [INFO] [controller] EPOCH 3 loss ppo:  -0.04685, loss val: 0.03954
[2022-12-07 08:07:07,838] [INFO] [controller] EPOCH 4 loss ppo:  -0.05594, loss val: 0.03807
[2022-12-07 08:07:07,848] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:07:08,039] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:07:08,039] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:07:14,501] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:07:20,717] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:07:26,309] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:07:31,743] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:07:37,306] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:07:42,847] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:07:48,738] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:07:54,146] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:07:59,718] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:08:05,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3129330262508088
[2022-12-07 08:08:05,505] [INFO] [runner_train_mujoco] Average state value: 0.5837326524655023
[2022-12-07 08:08:05,505] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 08:08:05,562] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.03340
[2022-12-07 08:08:05,613] [INFO] [controller] EPOCH 2 loss ppo:  -0.03135, loss val: 0.03234
[2022-12-07 08:08:05,655] [INFO] [controller] EPOCH 3 loss ppo:  -0.04203, loss val: 0.03503
[2022-12-07 08:08:05,700] [INFO] [controller] EPOCH 4 loss ppo:  -0.05321, loss val: 0.03038
[2022-12-07 08:08:05,707] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:08:05,892] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:08:05,893] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:08:11,580] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:08:19,004] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:08:25,659] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:08:32,007] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:08:38,237] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:08:44,743] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:08:50,849] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:08:57,482] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:09:03,904] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:09:10,148] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.1692707071174135
[2022-12-07 08:09:10,149] [INFO] [runner_train_mujoco] Average state value: 0.5409076796770096
[2022-12-07 08:09:10,149] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 08:09:10,203] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.04380
[2022-12-07 08:09:10,247] [INFO] [controller] EPOCH 2 loss ppo:  -0.03439, loss val: 0.04395
[2022-12-07 08:09:10,291] [INFO] [controller] EPOCH 3 loss ppo:  -0.04704, loss val: 0.04497
[2022-12-07 08:09:10,335] [INFO] [controller] EPOCH 4 loss ppo:  -0.05923, loss val: 0.04412
[2022-12-07 08:09:10,344] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:09:10,541] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:09:10,542] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:09:17,232] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:09:24,075] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:09:30,412] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:09:36,108] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:09:42,196] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:09:48,123] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:09:54,235] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:10:00,506] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:10:06,885] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:10:13,154] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.7581997946688843
[2022-12-07 08:10:13,154] [INFO] [runner_train_mujoco] Average state value: 0.5390905914107958
[2022-12-07 08:10:13,154] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 08:10:13,218] [INFO] [controller] EPOCH 1 loss ppo:  -0.01248, loss val: 0.03748
[2022-12-07 08:10:13,262] [INFO] [controller] EPOCH 2 loss ppo:  -0.03559, loss val: 0.03739
[2022-12-07 08:10:13,315] [INFO] [controller] EPOCH 3 loss ppo:  -0.05201, loss val: 0.03860
[2022-12-07 08:10:13,374] [INFO] [controller] EPOCH 4 loss ppo:  -0.06300, loss val: 0.03722
[2022-12-07 08:10:13,384] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:10:13,578] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:10:13,578] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:10:19,958] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:10:26,451] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:10:32,615] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:10:38,631] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:10:44,817] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:10:50,440] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:10:56,210] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:11:02,227] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:11:08,595] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:11:15,081] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9760907491299524
[2022-12-07 08:11:15,081] [INFO] [runner_train_mujoco] Average state value: 0.5556158896485963
[2022-12-07 08:11:15,081] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 08:11:15,135] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.03726
[2022-12-07 08:11:15,180] [INFO] [controller] EPOCH 2 loss ppo:  -0.03712, loss val: 0.03916
[2022-12-07 08:11:15,226] [INFO] [controller] EPOCH 3 loss ppo:  -0.04655, loss val: 0.03698
[2022-12-07 08:11:15,272] [INFO] [controller] EPOCH 4 loss ppo:  -0.05403, loss val: 0.04022
[2022-12-07 08:11:15,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:11:15,472] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:11:15,478] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:11:21,987] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:11:28,401] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:11:34,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:11:40,227] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:11:46,185] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:11:52,177] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:11:58,337] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:12:04,344] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:12:10,792] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:12:17,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0796573144557557
[2022-12-07 08:12:17,230] [INFO] [runner_train_mujoco] Average state value: 0.5772841426531474
[2022-12-07 08:12:17,230] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 08:12:17,282] [INFO] [controller] EPOCH 1 loss ppo:  -0.01384, loss val: 0.04045
[2022-12-07 08:12:17,323] [INFO] [controller] EPOCH 2 loss ppo:  -0.03141, loss val: 0.04036
[2022-12-07 08:12:17,365] [INFO] [controller] EPOCH 3 loss ppo:  -0.04473, loss val: 0.03938
[2022-12-07 08:12:17,409] [INFO] [controller] EPOCH 4 loss ppo:  -0.05593, loss val: 0.03791
[2022-12-07 08:12:17,419] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:12:17,611] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:12:17,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:12:23,536] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:12:29,744] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:12:35,785] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:12:41,781] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:12:47,586] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:12:53,583] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:12:59,406] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:13:06,015] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:13:12,193] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:13:18,776] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0997519498130393
[2022-12-07 08:13:18,776] [INFO] [runner_train_mujoco] Average state value: 0.5509357376694679
[2022-12-07 08:13:18,776] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 08:13:18,825] [INFO] [controller] EPOCH 1 loss ppo:  -0.01491, loss val: 0.03987
[2022-12-07 08:13:18,870] [INFO] [controller] EPOCH 2 loss ppo:  -0.03428, loss val: 0.04025
[2022-12-07 08:13:18,983] [INFO] [controller] EPOCH 3 loss ppo:  -0.04969, loss val: 0.04006
[2022-12-07 08:13:19,025] [INFO] [controller] EPOCH 4 loss ppo:  -0.05716, loss val: 0.03967
[2022-12-07 08:13:19,034] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:13:19,230] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:13:19,230] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:13:25,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:13:31,501] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:13:37,228] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:13:43,008] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:13:49,246] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:13:55,439] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:14:01,535] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:14:07,720] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:14:13,571] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:14:19,328] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6104623069111974
[2022-12-07 08:14:19,328] [INFO] [runner_train_mujoco] Average state value: 0.5288361843228341
[2022-12-07 08:14:19,328] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 08:14:19,378] [INFO] [controller] EPOCH 1 loss ppo:  -0.01431, loss val: 0.03988
[2022-12-07 08:14:19,419] [INFO] [controller] EPOCH 2 loss ppo:  -0.02995, loss val: 0.03927
[2022-12-07 08:14:19,461] [INFO] [controller] EPOCH 3 loss ppo:  -0.04535, loss val: 0.04080
[2022-12-07 08:14:19,500] [INFO] [controller] EPOCH 4 loss ppo:  -0.05226, loss val: 0.03820
[2022-12-07 08:14:19,509] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:14:19,691] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:14:19,692] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:14:25,870] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:14:31,970] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:14:38,089] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:14:44,036] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:14:50,237] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:14:56,042] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:15:01,925] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:15:08,158] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:15:14,319] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:15:19,979] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.722579268961952
[2022-12-07 08:15:19,979] [INFO] [runner_train_mujoco] Average state value: 0.5170165223876635
[2022-12-07 08:15:19,979] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 08:15:20,037] [INFO] [controller] EPOCH 1 loss ppo:  -0.01678, loss val: 0.03833
[2022-12-07 08:15:20,082] [INFO] [controller] EPOCH 2 loss ppo:  -0.03205, loss val: 0.03821
[2022-12-07 08:15:20,127] [INFO] [controller] EPOCH 3 loss ppo:  -0.04216, loss val: 0.03816
[2022-12-07 08:15:20,168] [INFO] [controller] EPOCH 4 loss ppo:  -0.05376, loss val: 0.03887
[2022-12-07 08:15:20,177] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:15:20,354] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:15:20,354] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:15:26,750] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:15:32,905] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:15:38,620] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:15:44,708] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:15:51,299] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:15:57,569] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:16:03,394] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:16:09,459] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:16:15,171] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:16:21,399] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6039202995190465
[2022-12-07 08:16:21,399] [INFO] [runner_train_mujoco] Average state value: 0.5029134449561437
[2022-12-07 08:16:21,399] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 08:16:21,459] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.03455
[2022-12-07 08:16:21,507] [INFO] [controller] EPOCH 2 loss ppo:  -0.02696, loss val: 0.03357
[2022-12-07 08:16:21,556] [INFO] [controller] EPOCH 3 loss ppo:  -0.03806, loss val: 0.03271
[2022-12-07 08:16:21,602] [INFO] [controller] EPOCH 4 loss ppo:  -0.04937, loss val: 0.03151
[2022-12-07 08:16:21,612] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:16:21,800] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:16:21,801] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:16:27,945] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:16:34,304] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:16:40,334] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:16:46,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:16:52,776] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:16:58,402] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:17:04,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:17:10,616] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:17:16,516] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:17:22,677] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.673823147095777
[2022-12-07 08:17:22,677] [INFO] [runner_train_mujoco] Average state value: 0.4716813716888428
[2022-12-07 08:17:22,678] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 08:17:22,728] [INFO] [controller] EPOCH 1 loss ppo:  -0.01256, loss val: 0.04144
[2022-12-07 08:17:22,772] [INFO] [controller] EPOCH 2 loss ppo:  -0.02787, loss val: 0.04214
[2022-12-07 08:17:22,818] [INFO] [controller] EPOCH 3 loss ppo:  -0.04099, loss val: 0.04160
[2022-12-07 08:17:22,865] [INFO] [controller] EPOCH 4 loss ppo:  -0.05266, loss val: 0.04223
[2022-12-07 08:17:22,875] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:17:23,076] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:17:23,077] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:17:28,851] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:17:34,655] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:17:40,672] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:17:46,462] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:17:52,651] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:17:58,670] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:18:05,132] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:18:11,531] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:18:18,533] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:18:24,590] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.012259777838713
[2022-12-07 08:18:24,591] [INFO] [runner_train_mujoco] Average state value: 0.4527415679991246
[2022-12-07 08:18:24,591] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 08:18:24,647] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04407
[2022-12-07 08:18:24,687] [INFO] [controller] EPOCH 2 loss ppo:  -0.02546, loss val: 0.04337
[2022-12-07 08:18:24,729] [INFO] [controller] EPOCH 3 loss ppo:  -0.03678, loss val: 0.04040
[2022-12-07 08:18:24,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.04537, loss val: 0.03986
[2022-12-07 08:18:24,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:18:24,967] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:18:24,968] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:18:31,149] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:18:37,433] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:18:43,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:18:49,702] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:18:55,373] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:19:01,489] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:19:07,452] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:19:13,426] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:19:19,495] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:19:25,905] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.935277570518352
[2022-12-07 08:19:25,905] [INFO] [runner_train_mujoco] Average state value: 0.477076954583327
[2022-12-07 08:19:25,905] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 08:19:25,970] [INFO] [controller] EPOCH 1 loss ppo:  -0.01689, loss val: 0.04662
[2022-12-07 08:19:26,015] [INFO] [controller] EPOCH 2 loss ppo:  -0.02283, loss val: 0.04647
[2022-12-07 08:19:26,058] [INFO] [controller] EPOCH 3 loss ppo:  -0.03774, loss val: 0.04651
[2022-12-07 08:19:26,102] [INFO] [controller] EPOCH 4 loss ppo:  -0.05314, loss val: 0.04588
[2022-12-07 08:19:26,111] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:19:26,275] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:19:26,275] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:19:32,516] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:19:38,600] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:19:44,713] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:19:51,052] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:19:56,803] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:20:03,206] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:20:09,128] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:20:14,733] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:20:20,416] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:20:26,544] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.175341053656384
[2022-12-07 08:20:26,545] [INFO] [runner_train_mujoco] Average state value: 0.5120319128831227
[2022-12-07 08:20:26,545] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 08:20:26,595] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.03855
[2022-12-07 08:20:26,636] [INFO] [controller] EPOCH 2 loss ppo:  -0.02557, loss val: 0.03879
[2022-12-07 08:20:26,677] [INFO] [controller] EPOCH 3 loss ppo:  -0.03668, loss val: 0.03870
[2022-12-07 08:20:26,717] [INFO] [controller] EPOCH 4 loss ppo:  -0.04606, loss val: 0.03716
[2022-12-07 08:20:26,726] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:20:26,911] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:20:26,911] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:20:33,014] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:20:39,295] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:20:45,793] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:20:52,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:20:58,596] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:21:04,845] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:21:10,959] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:21:16,921] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:21:22,835] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:21:28,769] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.2010415044614655
[2022-12-07 08:21:28,770] [INFO] [runner_train_mujoco] Average state value: 0.4995699793895086
[2022-12-07 08:21:28,770] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 08:21:28,868] [INFO] [controller] EPOCH 1 loss ppo:  -0.01378, loss val: 0.03834
[2022-12-07 08:21:28,908] [INFO] [controller] EPOCH 2 loss ppo:  -0.02904, loss val: 0.03895
[2022-12-07 08:21:28,950] [INFO] [controller] EPOCH 3 loss ppo:  -0.03735, loss val: 0.04094
[2022-12-07 08:21:28,992] [INFO] [controller] EPOCH 4 loss ppo:  -0.04784, loss val: 0.03872
[2022-12-07 08:21:29,001] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:21:29,182] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:21:29,182] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:21:34,889] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:21:41,372] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:21:47,383] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:21:53,535] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:21:59,289] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:22:05,296] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:22:11,016] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:22:17,421] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:22:23,402] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:22:29,587] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.562169569309155
[2022-12-07 08:22:29,587] [INFO] [runner_train_mujoco] Average state value: 0.4842589684327444
[2022-12-07 08:22:29,587] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 08:22:29,647] [INFO] [controller] EPOCH 1 loss ppo:  -0.01509, loss val: 0.03590
[2022-12-07 08:22:29,691] [INFO] [controller] EPOCH 2 loss ppo:  -0.02836, loss val: 0.03634
[2022-12-07 08:22:29,740] [INFO] [controller] EPOCH 3 loss ppo:  -0.03887, loss val: 0.03715
[2022-12-07 08:22:29,787] [INFO] [controller] EPOCH 4 loss ppo:  -0.04906, loss val: 0.03702
[2022-12-07 08:22:29,797] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:22:29,990] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:22:29,990] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:22:36,029] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:22:42,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:22:48,375] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:22:53,869] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:22:59,643] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:23:05,469] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:23:11,291] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:23:17,325] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:23:23,053] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:23:29,105] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.53063877073447
[2022-12-07 08:23:29,105] [INFO] [runner_train_mujoco] Average state value: 0.48155089451869326
[2022-12-07 08:23:29,105] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 08:23:29,153] [INFO] [controller] EPOCH 1 loss ppo:  -0.01410, loss val: 0.04010
[2022-12-07 08:23:29,191] [INFO] [controller] EPOCH 2 loss ppo:  -0.02199, loss val: 0.03998
[2022-12-07 08:23:29,233] [INFO] [controller] EPOCH 3 loss ppo:  -0.03250, loss val: 0.04129
[2022-12-07 08:23:29,276] [INFO] [controller] EPOCH 4 loss ppo:  -0.04189, loss val: 0.03991
[2022-12-07 08:23:29,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:23:29,470] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:23:29,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:23:35,955] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:23:41,977] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:23:48,398] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:23:54,462] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:24:00,214] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:24:06,484] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:24:12,215] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:24:18,327] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:24:24,326] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:24:30,638] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.564081506190421
[2022-12-07 08:24:30,638] [INFO] [runner_train_mujoco] Average state value: 0.4908542872865995
[2022-12-07 08:24:30,638] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 08:24:30,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.01148, loss val: 0.04047
[2022-12-07 08:24:30,737] [INFO] [controller] EPOCH 2 loss ppo:  -0.02017, loss val: 0.04017
[2022-12-07 08:24:30,780] [INFO] [controller] EPOCH 3 loss ppo:  -0.02930, loss val: 0.03934
[2022-12-07 08:24:30,831] [INFO] [controller] EPOCH 4 loss ppo:  -0.04157, loss val: 0.04068
[2022-12-07 08:24:30,842] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:24:31,046] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:24:31,046] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:24:36,755] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:24:42,943] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:24:48,979] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:24:54,948] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:25:01,127] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:25:07,150] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:25:13,239] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:25:19,007] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:25:25,265] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:25:31,103] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.47382979031824
[2022-12-07 08:25:31,103] [INFO] [runner_train_mujoco] Average state value: 0.49846703036626183
[2022-12-07 08:25:31,103] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 08:25:31,152] [INFO] [controller] EPOCH 1 loss ppo:  -0.01504, loss val: 0.04732
[2022-12-07 08:25:31,193] [INFO] [controller] EPOCH 2 loss ppo:  -0.02471, loss val: 0.04814
[2022-12-07 08:25:31,232] [INFO] [controller] EPOCH 3 loss ppo:  -0.03483, loss val: 0.04705
[2022-12-07 08:25:31,273] [INFO] [controller] EPOCH 4 loss ppo:  -0.04388, loss val: 0.04766
[2022-12-07 08:25:31,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:25:31,471] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:25:31,471] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:25:37,500] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:25:43,298] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:25:49,602] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:25:55,363] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:26:01,190] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:26:07,222] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:26:13,488] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:26:19,736] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:26:25,872] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:26:31,447] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.658272648520938
[2022-12-07 08:26:31,447] [INFO] [runner_train_mujoco] Average state value: 0.4951756554245949
[2022-12-07 08:26:31,447] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 08:26:31,497] [INFO] [controller] EPOCH 1 loss ppo:  -0.01563, loss val: 0.04170
[2022-12-07 08:26:31,542] [INFO] [controller] EPOCH 2 loss ppo:  -0.02622, loss val: 0.04242
[2022-12-07 08:26:31,586] [INFO] [controller] EPOCH 3 loss ppo:  -0.03591, loss val: 0.04109
[2022-12-07 08:26:31,629] [INFO] [controller] EPOCH 4 loss ppo:  -0.04573, loss val: 0.04062
[2022-12-07 08:26:31,638] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:26:31,823] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:26:31,824] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:26:38,288] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:26:44,015] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:26:50,336] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:26:56,604] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:27:02,618] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:27:08,467] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:27:14,218] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:27:20,066] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:27:26,487] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:27:32,338] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.747050484850241
[2022-12-07 08:27:32,338] [INFO] [runner_train_mujoco] Average state value: 0.5092626573642095
[2022-12-07 08:27:32,338] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 08:27:32,414] [INFO] [controller] EPOCH 1 loss ppo:  -0.01545, loss val: 0.04309
[2022-12-07 08:27:32,466] [INFO] [controller] EPOCH 2 loss ppo:  -0.02510, loss val: 0.04283
[2022-12-07 08:27:32,518] [INFO] [controller] EPOCH 3 loss ppo:  -0.03135, loss val: 0.04437
[2022-12-07 08:27:32,569] [INFO] [controller] EPOCH 4 loss ppo:  -0.04333, loss val: 0.04370
[2022-12-07 08:27:32,578] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:27:32,776] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:27:32,777] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:27:39,136] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:27:45,500] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:27:51,219] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:27:57,361] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:28:03,479] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:28:09,514] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:28:15,619] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:28:21,581] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:28:27,723] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:28:33,393] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.696103858484749
[2022-12-07 08:28:33,393] [INFO] [runner_train_mujoco] Average state value: 0.520223017513752
[2022-12-07 08:28:33,393] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 08:28:33,444] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04756
[2022-12-07 08:28:33,488] [INFO] [controller] EPOCH 2 loss ppo:  -0.02458, loss val: 0.04747
[2022-12-07 08:28:33,533] [INFO] [controller] EPOCH 3 loss ppo:  -0.03331, loss val: 0.04754
[2022-12-07 08:28:33,573] [INFO] [controller] EPOCH 4 loss ppo:  -0.04429, loss val: 0.04772
[2022-12-07 08:28:33,584] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:28:33,764] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:28:33,765] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:28:39,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:28:45,574] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:28:52,094] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:28:58,160] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:29:04,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:29:09,896] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:29:15,894] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:29:22,001] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:29:27,963] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:29:33,778] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.907621191425738
[2022-12-07 08:29:33,778] [INFO] [runner_train_mujoco] Average state value: 0.51254214600722
[2022-12-07 08:29:33,779] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 08:29:33,829] [INFO] [controller] EPOCH 1 loss ppo:  -0.01168, loss val: 0.04390
[2022-12-07 08:29:33,874] [INFO] [controller] EPOCH 2 loss ppo:  -0.02087, loss val: 0.04434
[2022-12-07 08:29:33,914] [INFO] [controller] EPOCH 3 loss ppo:  -0.02642, loss val: 0.04205
[2022-12-07 08:29:33,959] [INFO] [controller] EPOCH 4 loss ppo:  -0.03337, loss val: 0.04401
[2022-12-07 08:29:33,968] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:29:34,133] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:29:34,134] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:29:40,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:29:46,248] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:29:52,348] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:29:58,592] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:30:04,775] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:30:11,180] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:30:17,104] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:30:23,337] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:30:29,189] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:30:35,557] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.870617861299545
[2022-12-07 08:30:35,557] [INFO] [runner_train_mujoco] Average state value: 0.5043060889840126
[2022-12-07 08:30:35,557] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 08:30:35,619] [INFO] [controller] EPOCH 1 loss ppo:  -0.01274, loss val: 0.04720
[2022-12-07 08:30:35,664] [INFO] [controller] EPOCH 2 loss ppo:  -0.02574, loss val: 0.04577
[2022-12-07 08:30:35,710] [INFO] [controller] EPOCH 3 loss ppo:  -0.03280, loss val: 0.04635
[2022-12-07 08:30:35,759] [INFO] [controller] EPOCH 4 loss ppo:  -0.04264, loss val: 0.04359
[2022-12-07 08:30:35,769] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:30:35,958] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:30:35,959] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:30:41,968] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:30:47,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:30:53,549] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:30:59,069] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:31:04,967] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:31:10,836] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:31:17,384] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:31:23,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:31:29,263] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:31:35,114] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.981920354456329
[2022-12-07 08:31:35,114] [INFO] [runner_train_mujoco] Average state value: 0.5085839225252469
[2022-12-07 08:31:35,114] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 08:31:35,165] [INFO] [controller] EPOCH 1 loss ppo:  -0.01231, loss val: 0.04359
[2022-12-07 08:31:35,208] [INFO] [controller] EPOCH 2 loss ppo:  -0.02238, loss val: 0.04426
[2022-12-07 08:31:35,252] [INFO] [controller] EPOCH 3 loss ppo:  -0.02931, loss val: 0.04357
[2022-12-07 08:31:35,296] [INFO] [controller] EPOCH 4 loss ppo:  -0.03792, loss val: 0.04366
[2022-12-07 08:31:35,305] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:31:35,493] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:31:35,494] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:31:41,417] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:31:47,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:31:53,780] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:31:59,848] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:32:05,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:32:11,688] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:32:17,759] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:32:23,919] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:32:29,940] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:32:35,858] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.084518298812199
[2022-12-07 08:32:35,858] [INFO] [runner_train_mujoco] Average state value: 0.5171887979110081
[2022-12-07 08:32:35,858] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 08:32:35,915] [INFO] [controller] EPOCH 1 loss ppo:  -0.01381, loss val: 0.04303
[2022-12-07 08:32:35,962] [INFO] [controller] EPOCH 2 loss ppo:  -0.02053, loss val: 0.04340
[2022-12-07 08:32:36,011] [INFO] [controller] EPOCH 3 loss ppo:  -0.02736, loss val: 0.04359
[2022-12-07 08:32:36,058] [INFO] [controller] EPOCH 4 loss ppo:  -0.03916, loss val: 0.04376
[2022-12-07 08:32:36,067] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:32:36,270] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:32:36,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:32:41,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:32:48,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:32:54,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:33:00,473] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:33:06,994] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:33:13,202] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:33:19,395] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:33:25,145] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:33:31,260] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:33:37,124] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.942417925364723
[2022-12-07 08:33:37,124] [INFO] [runner_train_mujoco] Average state value: 0.5140534744064013
[2022-12-07 08:33:37,124] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 08:33:37,178] [INFO] [controller] EPOCH 1 loss ppo:  -0.01395, loss val: 0.03220
[2022-12-07 08:33:37,220] [INFO] [controller] EPOCH 2 loss ppo:  -0.02077, loss val: 0.03171
[2022-12-07 08:33:37,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.02654, loss val: 0.03155
[2022-12-07 08:33:37,310] [INFO] [controller] EPOCH 4 loss ppo:  -0.03818, loss val: 0.03354
[2022-12-07 08:33:37,319] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:33:37,489] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:33:37,489] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:33:43,314] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:33:49,905] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:33:56,180] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:34:02,315] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:34:07,954] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:34:13,752] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:34:19,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:34:26,163] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:34:32,192] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:34:37,840] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.351991835683766
[2022-12-07 08:34:37,840] [INFO] [runner_train_mujoco] Average state value: 0.49771798692146946
[2022-12-07 08:34:37,841] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 08:34:37,891] [INFO] [controller] EPOCH 1 loss ppo:  -0.01287, loss val: 0.04448
[2022-12-07 08:34:37,936] [INFO] [controller] EPOCH 2 loss ppo:  -0.02131, loss val: 0.04432
[2022-12-07 08:34:38,043] [INFO] [controller] EPOCH 3 loss ppo:  -0.02982, loss val: 0.04443
[2022-12-07 08:34:38,090] [INFO] [controller] EPOCH 4 loss ppo:  -0.03917, loss val: 0.04443
[2022-12-07 08:34:38,099] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:34:38,286] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:34:38,286] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:34:44,535] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:34:50,939] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:34:57,364] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:35:03,436] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:35:09,268] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:35:15,251] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:35:21,275] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:35:27,455] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:35:33,415] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:35:39,666] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.449389066636348
[2022-12-07 08:35:39,666] [INFO] [runner_train_mujoco] Average state value: 0.4796169061859448
[2022-12-07 08:35:39,666] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 08:35:39,718] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.04309
[2022-12-07 08:35:39,761] [INFO] [controller] EPOCH 2 loss ppo:  -0.02051, loss val: 0.04216
[2022-12-07 08:35:39,808] [INFO] [controller] EPOCH 3 loss ppo:  -0.02826, loss val: 0.04195
[2022-12-07 08:35:39,858] [INFO] [controller] EPOCH 4 loss ppo:  -0.03607, loss val: 0.04261
[2022-12-07 08:35:39,868] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:35:40,056] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:35:40,056] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:35:46,323] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:35:52,970] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:35:59,036] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:36:05,286] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:36:11,289] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:36:17,626] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:36:23,492] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:36:29,686] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:36:35,312] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:36:41,707] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.6626043271986335
[2022-12-07 08:36:41,707] [INFO] [runner_train_mujoco] Average state value: 0.46280228450894356
[2022-12-07 08:36:41,707] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 08:36:41,761] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.04291
[2022-12-07 08:36:41,804] [INFO] [controller] EPOCH 2 loss ppo:  -0.01845, loss val: 0.04315
[2022-12-07 08:36:41,848] [INFO] [controller] EPOCH 3 loss ppo:  -0.02231, loss val: 0.04251
[2022-12-07 08:36:41,894] [INFO] [controller] EPOCH 4 loss ppo:  -0.02993, loss val: 0.04320
[2022-12-07 08:36:41,900] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:36:42,085] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:36:42,085] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:36:48,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:36:54,634] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:37:00,548] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:37:06,475] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:37:12,576] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:37:18,205] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:37:24,524] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:37:30,959] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:37:37,343] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:37:43,430] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.419010945778519
[2022-12-07 08:37:43,430] [INFO] [runner_train_mujoco] Average state value: 0.4549450798432032
[2022-12-07 08:37:43,431] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 08:37:43,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.04806
[2022-12-07 08:37:43,545] [INFO] [controller] EPOCH 2 loss ppo:  -0.02098, loss val: 0.04743
[2022-12-07 08:37:43,594] [INFO] [controller] EPOCH 3 loss ppo:  -0.02567, loss val: 0.04845
[2022-12-07 08:37:43,639] [INFO] [controller] EPOCH 4 loss ppo:  -0.03109, loss val: 0.04815
[2022-12-07 08:37:43,649] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:37:43,824] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:37:43,824] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:37:50,177] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:37:58,062] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:38:04,867] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:38:10,913] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:38:16,912] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:38:24,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:38:31,176] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:38:37,690] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:38:43,256] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:38:49,909] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.584900404666307
[2022-12-07 08:38:49,910] [INFO] [runner_train_mujoco] Average state value: 0.4611249405145645
[2022-12-07 08:38:49,910] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 08:38:50,190] [INFO] [controller] EPOCH 1 loss ppo:  -0.01360, loss val: 0.05317
[2022-12-07 08:38:50,250] [INFO] [controller] EPOCH 2 loss ppo:  -0.01931, loss val: 0.05246
[2022-12-07 08:38:50,623] [INFO] [controller] EPOCH 3 loss ppo:  -0.02405, loss val: 0.05359
[2022-12-07 08:38:50,823] [INFO] [controller] EPOCH 4 loss ppo:  -0.03055, loss val: 0.05225
[2022-12-07 08:38:50,836] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:38:51,040] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:38:51,041] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:38:57,494] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:39:03,559] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:39:09,692] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:39:15,861] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:39:21,889] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:39:27,789] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:39:34,269] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:39:39,974] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:39:45,823] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:39:52,107] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.77994308145019
[2022-12-07 08:39:52,108] [INFO] [runner_train_mujoco] Average state value: 0.4755896218220393
[2022-12-07 08:39:52,108] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 08:39:52,412] [INFO] [controller] EPOCH 1 loss ppo:  -0.01210, loss val: 0.04864
[2022-12-07 08:39:52,462] [INFO] [controller] EPOCH 2 loss ppo:  -0.01650, loss val: 0.05032
[2022-12-07 08:39:52,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.02467, loss val: 0.04801
[2022-12-07 08:39:52,562] [INFO] [controller] EPOCH 4 loss ppo:  -0.03197, loss val: 0.04881
[2022-12-07 08:39:52,572] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:39:52,826] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:39:52,831] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:39:58,915] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:40:05,264] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:40:11,388] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:40:17,517] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:40:23,400] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:40:29,488] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:40:36,150] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:40:41,950] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:40:47,756] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:40:53,672] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.602427614775861
[2022-12-07 08:40:53,672] [INFO] [runner_train_mujoco] Average state value: 0.4822162635922432
[2022-12-07 08:40:53,673] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 08:40:53,733] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.05166
[2022-12-07 08:40:53,778] [INFO] [controller] EPOCH 2 loss ppo:  -0.01841, loss val: 0.05243
[2022-12-07 08:40:53,823] [INFO] [controller] EPOCH 3 loss ppo:  -0.02156, loss val: 0.05295
[2022-12-07 08:40:53,867] [INFO] [controller] EPOCH 4 loss ppo:  -0.02598, loss val: 0.05250
[2022-12-07 08:40:53,878] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:40:54,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:40:54,069] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:40:59,836] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:41:05,860] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:41:12,238] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:41:18,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:41:24,326] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:41:30,111] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:41:36,662] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:41:43,104] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:41:49,856] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:41:56,177] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.746694141448178
[2022-12-07 08:41:56,178] [INFO] [runner_train_mujoco] Average state value: 0.4753178636034329
[2022-12-07 08:41:56,178] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 08:41:56,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01341, loss val: 0.04819
[2022-12-07 08:41:56,297] [INFO] [controller] EPOCH 2 loss ppo:  -0.01796, loss val: 0.04839
[2022-12-07 08:41:56,346] [INFO] [controller] EPOCH 3 loss ppo:  -0.02238, loss val: 0.04818
[2022-12-07 08:41:56,393] [INFO] [controller] EPOCH 4 loss ppo:  -0.02662, loss val: 0.04961
[2022-12-07 08:41:56,402] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:41:56,596] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:41:56,596] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:42:02,392] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:42:08,283] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:42:14,124] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:42:20,029] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:42:26,357] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:42:32,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:42:38,605] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:42:44,926] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:42:50,974] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:42:57,297] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.686497764896906
[2022-12-07 08:42:57,297] [INFO] [runner_train_mujoco] Average state value: 0.4718063381512961
[2022-12-07 08:42:57,297] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 08:42:57,356] [INFO] [controller] EPOCH 1 loss ppo:  -0.01263, loss val: 0.04106
[2022-12-07 08:42:57,400] [INFO] [controller] EPOCH 2 loss ppo:  -0.01566, loss val: 0.04063
[2022-12-07 08:42:57,443] [INFO] [controller] EPOCH 3 loss ppo:  -0.02064, loss val: 0.04071
[2022-12-07 08:42:57,501] [INFO] [controller] EPOCH 4 loss ppo:  -0.02454, loss val: 0.04005
[2022-12-07 08:42:57,511] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:42:57,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:42:57,708] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:43:04,097] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:43:10,138] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:43:16,597] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:43:23,647] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:43:29,593] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:43:35,449] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:43:41,290] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:43:47,204] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:43:53,172] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:43:58,819] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.883689258140149
[2022-12-07 08:43:58,819] [INFO] [runner_train_mujoco] Average state value: 0.48278066269556674
[2022-12-07 08:43:58,819] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 08:43:58,862] [INFO] [controller] EPOCH 1 loss ppo:  -0.01335, loss val: 0.04631
[2022-12-07 08:43:58,909] [INFO] [controller] EPOCH 2 loss ppo:  -0.01617, loss val: 0.04815
[2022-12-07 08:43:58,951] [INFO] [controller] EPOCH 3 loss ppo:  -0.02106, loss val: 0.04795
[2022-12-07 08:43:58,992] [INFO] [controller] EPOCH 4 loss ppo:  -0.02631, loss val: 0.04664
[2022-12-07 08:43:59,001] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:43:59,186] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:43:59,186] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:44:05,300] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:44:12,045] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:44:18,018] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:44:24,282] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:44:29,924] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:44:36,025] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:44:42,039] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:44:47,969] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:44:53,728] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:44:59,382] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.92092220512918
[2022-12-07 08:44:59,382] [INFO] [runner_train_mujoco] Average state value: 0.48880415374040603
[2022-12-07 08:44:59,383] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 08:44:59,435] [INFO] [controller] EPOCH 1 loss ppo:  -0.01352, loss val: 0.04990
[2022-12-07 08:44:59,478] [INFO] [controller] EPOCH 2 loss ppo:  -0.01650, loss val: 0.04846
[2022-12-07 08:44:59,522] [INFO] [controller] EPOCH 3 loss ppo:  -0.02132, loss val: 0.04845
[2022-12-07 08:44:59,570] [INFO] [controller] EPOCH 4 loss ppo:  -0.02590, loss val: 0.04917
[2022-12-07 08:44:59,579] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:44:59,771] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:44:59,771] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:45:05,825] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:45:11,936] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:45:18,416] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:45:25,393] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:45:34,205] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:45:40,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:45:47,107] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:45:54,090] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:46:00,450] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:46:07,316] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.018220775902898
[2022-12-07 08:46:07,316] [INFO] [runner_train_mujoco] Average state value: 0.48433604697386423
[2022-12-07 08:46:07,317] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 08:46:07,384] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.05135
[2022-12-07 08:46:07,430] [INFO] [controller] EPOCH 2 loss ppo:  -0.01387, loss val: 0.05127
[2022-12-07 08:46:07,487] [INFO] [controller] EPOCH 3 loss ppo:  -0.01551, loss val: 0.05047
[2022-12-07 08:46:07,534] [INFO] [controller] EPOCH 4 loss ppo:  -0.01782, loss val: 0.05045
[2022-12-07 08:46:07,543] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:46:07,761] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 08:46:07,762] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 08:46:14,819] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 08:46:22,077] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 08:46:29,120] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 08:46:36,090] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 08:46:42,254] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 08:46:48,902] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 08:46:55,774] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 08:47:02,783] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 08:47:09,538] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 08:47:16,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.956983952404059
[2022-12-07 08:47:16,462] [INFO] [runner_train_mujoco] Average state value: 0.4791236315369606
[2022-12-07 08:47:16,462] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 08:47:16,555] [INFO] [controller] EPOCH 1 loss ppo:  -0.01319, loss val: 0.04857
[2022-12-07 08:47:16,616] [INFO] [controller] EPOCH 2 loss ppo:  -0.01366, loss val: 0.04836
[2022-12-07 08:47:16,669] [INFO] [controller] EPOCH 3 loss ppo:  -0.01500, loss val: 0.04852
[2022-12-07 08:47:16,723] [INFO] [controller] EPOCH 4 loss ppo:  -0.01648, loss val: 0.04833
[2022-12-07 08:47:16,733] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 08:47:16,899] [INFO] [optimize] Finished learning.
