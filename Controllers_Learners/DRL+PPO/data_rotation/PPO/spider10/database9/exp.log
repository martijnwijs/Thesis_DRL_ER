[2022-12-07 09:59:23,165] [INFO] [optimize] Starting learning
[2022-12-07 09:59:23,174] [INFO] [optimize] Starting learning process..
[2022-12-07 09:59:23,268] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 09:59:23,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 09:59:30,179] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 09:59:36,922] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 09:59:42,586] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 09:59:48,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 09:59:53,974] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 09:59:59,929] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:00:06,164] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:00:12,830] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:00:19,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:00:25,691] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.458729443922251
[2022-12-07 10:00:25,691] [INFO] [runner_train_mujoco] Average state value: 0.0833487232774496
[2022-12-07 10:00:25,691] [INFO] [controller] ITERATION NUM: 1
[2022-12-07 10:00:25,745] [INFO] [controller] EPOCH 1 loss ppo:  -0.01269, loss val: 0.34553
[2022-12-07 10:00:25,788] [INFO] [controller] EPOCH 2 loss ppo:  -0.04337, loss val: 0.29016
[2022-12-07 10:00:25,825] [INFO] [controller] EPOCH 3 loss ppo:  -0.05442, loss val: 0.24582
[2022-12-07 10:00:25,871] [INFO] [controller] EPOCH 4 loss ppo:  -0.06318, loss val: 0.20766
[2022-12-07 10:00:25,882] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:00:26,070] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:00:26,070] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:00:32,553] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:00:39,111] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:00:45,314] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:00:51,370] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:00:57,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:01:03,181] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:01:08,989] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:01:15,105] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:01:21,703] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:01:28,504] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.39278568588934604
[2022-12-07 10:01:28,505] [INFO] [runner_train_mujoco] Average state value: 0.24187933345201115
[2022-12-07 10:01:28,505] [INFO] [controller] ITERATION NUM: 2
[2022-12-07 10:01:28,558] [INFO] [controller] EPOCH 1 loss ppo:  -0.01440, loss val: 0.21594
[2022-12-07 10:01:28,602] [INFO] [controller] EPOCH 2 loss ppo:  -0.03971, loss val: 0.17569
[2022-12-07 10:01:28,647] [INFO] [controller] EPOCH 3 loss ppo:  -0.05197, loss val: 0.15173
[2022-12-07 10:01:28,691] [INFO] [controller] EPOCH 4 loss ppo:  -0.06154, loss val: 0.12534
[2022-12-07 10:01:28,701] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:01:28,897] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:01:28,898] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:01:34,918] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:01:41,758] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:01:48,439] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:01:54,819] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:02:01,455] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:02:08,311] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:02:15,306] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:02:21,964] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:02:28,362] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:02:34,445] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5182308815192929
[2022-12-07 10:02:34,445] [INFO] [runner_train_mujoco] Average state value: 0.39662644547596576
[2022-12-07 10:02:34,446] [INFO] [controller] ITERATION NUM: 3
[2022-12-07 10:02:34,506] [INFO] [controller] EPOCH 1 loss ppo:  -0.01330, loss val: 0.12363
[2022-12-07 10:02:34,553] [INFO] [controller] EPOCH 2 loss ppo:  -0.03572, loss val: 0.11126
[2022-12-07 10:02:34,600] [INFO] [controller] EPOCH 3 loss ppo:  -0.04941, loss val: 0.09107
[2022-12-07 10:02:34,654] [INFO] [controller] EPOCH 4 loss ppo:  -0.06088, loss val: 0.08062
[2022-12-07 10:02:34,667] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:02:34,876] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:02:34,876] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:02:41,496] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:02:48,243] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:02:54,555] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:03:01,040] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:03:07,566] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:03:13,617] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:03:20,081] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:03:27,115] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:03:33,934] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:03:40,485] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4305494241056249
[2022-12-07 10:03:40,486] [INFO] [runner_train_mujoco] Average state value: 0.5431281228115161
[2022-12-07 10:03:40,486] [INFO] [controller] ITERATION NUM: 4
[2022-12-07 10:03:40,538] [INFO] [controller] EPOCH 1 loss ppo:  -0.01081, loss val: 0.06969
[2022-12-07 10:03:40,581] [INFO] [controller] EPOCH 2 loss ppo:  -0.03486, loss val: 0.06532
[2022-12-07 10:03:40,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.04786, loss val: 0.06197
[2022-12-07 10:03:40,666] [INFO] [controller] EPOCH 4 loss ppo:  -0.05600, loss val: 0.06257
[2022-12-07 10:03:40,676] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:03:40,871] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:03:40,871] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:03:47,252] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:03:54,399] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:04:00,959] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:04:07,514] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:04:14,059] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:04:19,943] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:04:25,894] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:04:31,898] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:04:38,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:04:45,265] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.358736687805994
[2022-12-07 10:04:45,265] [INFO] [runner_train_mujoco] Average state value: 0.617976402234907
[2022-12-07 10:04:45,265] [INFO] [controller] ITERATION NUM: 5
[2022-12-07 10:04:45,326] [INFO] [controller] EPOCH 1 loss ppo:  -0.00851, loss val: 0.05829
[2022-12-07 10:04:45,371] [INFO] [controller] EPOCH 2 loss ppo:  -0.03275, loss val: 0.05257
[2022-12-07 10:04:45,412] [INFO] [controller] EPOCH 3 loss ppo:  -0.04514, loss val: 0.05055
[2022-12-07 10:04:45,461] [INFO] [controller] EPOCH 4 loss ppo:  -0.05290, loss val: 0.04742
[2022-12-07 10:04:45,470] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:04:45,649] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:04:45,650] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:04:51,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:04:57,783] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:05:03,482] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:05:09,269] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:05:14,940] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:05:21,042] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:05:26,949] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:05:33,503] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:05:39,336] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:05:44,739] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.37332469651308986
[2022-12-07 10:05:44,740] [INFO] [runner_train_mujoco] Average state value: 0.6384700268507004
[2022-12-07 10:05:44,740] [INFO] [controller] ITERATION NUM: 6
[2022-12-07 10:05:44,791] [INFO] [controller] EPOCH 1 loss ppo:  -0.01075, loss val: 0.04923
[2022-12-07 10:05:44,831] [INFO] [controller] EPOCH 2 loss ppo:  -0.03384, loss val: 0.04815
[2022-12-07 10:05:44,871] [INFO] [controller] EPOCH 3 loss ppo:  -0.04589, loss val: 0.04634
[2022-12-07 10:05:44,911] [INFO] [controller] EPOCH 4 loss ppo:  -0.05348, loss val: 0.04476
[2022-12-07 10:05:44,920] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:05:45,108] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:05:45,109] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:05:51,230] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:05:57,485] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:06:04,096] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:06:10,954] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:06:17,121] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:06:22,946] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:06:29,000] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:06:34,933] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:06:40,960] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:06:47,146] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.42938715487028933
[2022-12-07 10:06:47,146] [INFO] [runner_train_mujoco] Average state value: 0.653332347681125
[2022-12-07 10:06:47,146] [INFO] [controller] ITERATION NUM: 7
[2022-12-07 10:06:47,197] [INFO] [controller] EPOCH 1 loss ppo:  -0.00860, loss val: 0.04848
[2022-12-07 10:06:47,236] [INFO] [controller] EPOCH 2 loss ppo:  -0.03059, loss val: 0.04734
[2022-12-07 10:06:47,278] [INFO] [controller] EPOCH 3 loss ppo:  -0.04278, loss val: 0.04651
[2022-12-07 10:06:47,317] [INFO] [controller] EPOCH 4 loss ppo:  -0.05081, loss val: 0.04278
[2022-12-07 10:06:47,326] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:06:47,500] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:06:47,500] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:06:53,484] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:06:59,981] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:07:07,557] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:07:14,875] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:07:22,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:07:29,506] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:07:39,325] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:07:47,254] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:07:54,589] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:08:01,665] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.38466810315337857
[2022-12-07 10:08:01,666] [INFO] [runner_train_mujoco] Average state value: 0.6168464631239574
[2022-12-07 10:08:01,666] [INFO] [controller] ITERATION NUM: 8
[2022-12-07 10:08:01,730] [INFO] [controller] EPOCH 1 loss ppo:  -0.00931, loss val: 0.04446
[2022-12-07 10:08:01,779] [INFO] [controller] EPOCH 2 loss ppo:  -0.03375, loss val: 0.04262
[2022-12-07 10:08:01,847] [INFO] [controller] EPOCH 3 loss ppo:  -0.04596, loss val: 0.04469
[2022-12-07 10:08:01,896] [INFO] [controller] EPOCH 4 loss ppo:  -0.05295, loss val: 0.04472
[2022-12-07 10:08:01,908] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:08:02,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:08:02,127] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:08:09,366] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:08:16,660] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:08:24,344] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:08:31,312] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:08:38,420] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:08:45,350] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:08:52,606] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:09:00,091] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:09:09,677] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:09:22,102] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.537919939836571
[2022-12-07 10:09:22,102] [INFO] [runner_train_mujoco] Average state value: 0.589697598407666
[2022-12-07 10:09:22,102] [INFO] [controller] ITERATION NUM: 9
[2022-12-07 10:09:22,289] [INFO] [controller] EPOCH 1 loss ppo:  -0.01181, loss val: 0.03622
[2022-12-07 10:09:22,494] [INFO] [controller] EPOCH 2 loss ppo:  -0.03518, loss val: 0.03598
[2022-12-07 10:09:22,617] [INFO] [controller] EPOCH 3 loss ppo:  -0.04752, loss val: 0.03563
[2022-12-07 10:09:22,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.05758, loss val: 0.03579
[2022-12-07 10:09:22,767] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:09:23,160] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:09:23,175] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:09:34,605] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:09:42,508] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:09:50,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:10:00,622] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:10:08,828] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:10:16,910] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:10:25,182] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:10:33,734] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:10:40,647] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:10:49,208] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5089728511248633
[2022-12-07 10:10:49,209] [INFO] [runner_train_mujoco] Average state value: 0.579003426373005
[2022-12-07 10:10:49,210] [INFO] [controller] ITERATION NUM: 10
[2022-12-07 10:10:49,294] [INFO] [controller] EPOCH 1 loss ppo:  -0.00964, loss val: 0.04230
[2022-12-07 10:10:49,373] [INFO] [controller] EPOCH 2 loss ppo:  -0.02666, loss val: 0.04196
[2022-12-07 10:10:49,485] [INFO] [controller] EPOCH 3 loss ppo:  -0.03914, loss val: 0.04388
[2022-12-07 10:10:49,555] [INFO] [controller] EPOCH 4 loss ppo:  -0.04747, loss val: 0.04002
[2022-12-07 10:10:49,568] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:10:49,812] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:10:49,813] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:11:00,802] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:11:08,288] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:11:15,766] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:11:23,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:11:30,827] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:11:39,346] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:11:49,634] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:11:56,757] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:12:03,159] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:12:09,762] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5956525926993843
[2022-12-07 10:12:09,763] [INFO] [runner_train_mujoco] Average state value: 0.6053638423283895
[2022-12-07 10:12:09,763] [INFO] [controller] ITERATION NUM: 11
[2022-12-07 10:12:09,816] [INFO] [controller] EPOCH 1 loss ppo:  -0.01188, loss val: 0.04640
[2022-12-07 10:12:09,857] [INFO] [controller] EPOCH 2 loss ppo:  -0.03740, loss val: 0.04680
[2022-12-07 10:12:09,899] [INFO] [controller] EPOCH 3 loss ppo:  -0.04811, loss val: 0.04583
[2022-12-07 10:12:09,944] [INFO] [controller] EPOCH 4 loss ppo:  -0.05389, loss val: 0.04581
[2022-12-07 10:12:09,955] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:12:10,159] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:12:10,159] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:12:16,712] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:12:23,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:12:30,418] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:12:38,150] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:12:47,428] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:12:55,173] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:13:02,278] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:13:08,647] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:13:14,761] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:13:21,247] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.8430144714500045
[2022-12-07 10:13:21,248] [INFO] [runner_train_mujoco] Average state value: 0.6315020051002502
[2022-12-07 10:13:21,248] [INFO] [controller] ITERATION NUM: 12
[2022-12-07 10:13:21,296] [INFO] [controller] EPOCH 1 loss ppo:  -0.01408, loss val: 0.04479
[2022-12-07 10:13:21,341] [INFO] [controller] EPOCH 2 loss ppo:  -0.03717, loss val: 0.04438
[2022-12-07 10:13:21,460] [INFO] [controller] EPOCH 3 loss ppo:  -0.04586, loss val: 0.04377
[2022-12-07 10:13:21,504] [INFO] [controller] EPOCH 4 loss ppo:  -0.05512, loss val: 0.04137
[2022-12-07 10:13:21,513] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:13:21,712] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:13:21,712] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:13:28,389] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:13:35,228] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:13:41,851] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:13:48,262] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:13:54,272] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:14:00,724] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:14:06,966] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:14:13,131] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:14:19,889] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:14:26,304] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6609860770924068
[2022-12-07 10:14:26,304] [INFO] [runner_train_mujoco] Average state value: 0.5866010201573372
[2022-12-07 10:14:26,305] [INFO] [controller] ITERATION NUM: 13
[2022-12-07 10:14:26,355] [INFO] [controller] EPOCH 1 loss ppo:  -0.01157, loss val: 0.04502
[2022-12-07 10:14:26,401] [INFO] [controller] EPOCH 2 loss ppo:  -0.03563, loss val: 0.04363
[2022-12-07 10:14:26,444] [INFO] [controller] EPOCH 3 loss ppo:  -0.05139, loss val: 0.04475
[2022-12-07 10:14:26,486] [INFO] [controller] EPOCH 4 loss ppo:  -0.05895, loss val: 0.04351
[2022-12-07 10:14:26,497] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:14:26,701] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:14:26,702] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:14:33,446] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:14:40,202] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:14:46,386] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:14:52,437] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:14:58,770] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:15:05,277] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:15:11,513] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:15:17,757] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:15:25,476] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:15:32,874] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9694098548362986
[2022-12-07 10:15:32,875] [INFO] [runner_train_mujoco] Average state value: 0.5792547596295675
[2022-12-07 10:15:32,875] [INFO] [controller] ITERATION NUM: 14
[2022-12-07 10:15:32,933] [INFO] [controller] EPOCH 1 loss ppo:  -0.01216, loss val: 0.04029
[2022-12-07 10:15:32,981] [INFO] [controller] EPOCH 2 loss ppo:  -0.03854, loss val: 0.03915
[2022-12-07 10:15:33,029] [INFO] [controller] EPOCH 3 loss ppo:  -0.05107, loss val: 0.04148
[2022-12-07 10:15:33,075] [INFO] [controller] EPOCH 4 loss ppo:  -0.05481, loss val: 0.03963
[2022-12-07 10:15:33,085] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:15:33,293] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:15:33,293] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:15:41,791] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:15:50,108] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:15:57,647] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:16:03,968] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:16:10,428] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:16:16,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:16:23,950] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:16:31,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:16:39,279] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:16:46,249] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.1813461983137974
[2022-12-07 10:16:46,249] [INFO] [runner_train_mujoco] Average state value: 0.6051618858774502
[2022-12-07 10:16:46,250] [INFO] [controller] ITERATION NUM: 15
[2022-12-07 10:16:46,330] [INFO] [controller] EPOCH 1 loss ppo:  -0.01303, loss val: 0.03816
[2022-12-07 10:16:46,389] [INFO] [controller] EPOCH 2 loss ppo:  -0.03443, loss val: 0.03916
[2022-12-07 10:16:46,434] [INFO] [controller] EPOCH 3 loss ppo:  -0.04705, loss val: 0.03821
[2022-12-07 10:16:46,482] [INFO] [controller] EPOCH 4 loss ppo:  -0.05416, loss val: 0.03757
[2022-12-07 10:16:46,493] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:16:46,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:16:46,711] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:16:53,470] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:17:00,811] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:17:08,312] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:17:15,522] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:17:22,897] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:17:29,859] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:17:37,588] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:17:45,822] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:17:53,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:18:04,556] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.3950846439835485
[2022-12-07 10:18:04,556] [INFO] [runner_train_mujoco] Average state value: 0.5871396407683691
[2022-12-07 10:18:04,557] [INFO] [controller] ITERATION NUM: 16
[2022-12-07 10:18:04,779] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.03994
[2022-12-07 10:18:04,878] [INFO] [controller] EPOCH 2 loss ppo:  -0.03239, loss val: 0.04107
[2022-12-07 10:18:04,962] [INFO] [controller] EPOCH 3 loss ppo:  -0.04520, loss val: 0.03978
[2022-12-07 10:18:05,042] [INFO] [controller] EPOCH 4 loss ppo:  -0.05434, loss val: 0.03885
[2022-12-07 10:18:05,055] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:18:05,374] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:18:05,375] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:18:12,949] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:18:20,088] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:18:27,081] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:18:34,307] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:18:41,448] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:18:48,673] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:18:56,582] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:19:04,447] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:19:11,493] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:19:18,033] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.4358654893858123
[2022-12-07 10:19:18,033] [INFO] [runner_train_mujoco] Average state value: 0.5528186869124572
[2022-12-07 10:19:18,033] [INFO] [controller] ITERATION NUM: 17
[2022-12-07 10:19:18,091] [INFO] [controller] EPOCH 1 loss ppo:  -0.01361, loss val: 0.03691
[2022-12-07 10:19:18,140] [INFO] [controller] EPOCH 2 loss ppo:  -0.03308, loss val: 0.03667
[2022-12-07 10:19:18,186] [INFO] [controller] EPOCH 3 loss ppo:  -0.04722, loss val: 0.03542
[2022-12-07 10:19:18,232] [INFO] [controller] EPOCH 4 loss ppo:  -0.05418, loss val: 0.03496
[2022-12-07 10:19:18,241] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:19:18,445] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:19:18,445] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:19:25,699] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:19:32,821] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:19:39,637] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:19:46,139] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:19:52,679] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:19:59,725] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:20:06,736] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:20:14,187] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:20:21,083] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:20:27,789] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8179682117765732
[2022-12-07 10:20:27,789] [INFO] [runner_train_mujoco] Average state value: 0.5099008289972942
[2022-12-07 10:20:27,789] [INFO] [controller] ITERATION NUM: 18
[2022-12-07 10:20:27,845] [INFO] [controller] EPOCH 1 loss ppo:  -0.01561, loss val: 0.04307
[2022-12-07 10:20:27,888] [INFO] [controller] EPOCH 2 loss ppo:  -0.03751, loss val: 0.04367
[2022-12-07 10:20:27,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.05117, loss val: 0.04295
[2022-12-07 10:20:27,976] [INFO] [controller] EPOCH 4 loss ppo:  -0.06081, loss val: 0.04256
[2022-12-07 10:20:27,984] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:20:28,202] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:20:28,203] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:20:34,848] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:20:41,528] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:20:47,588] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:20:53,532] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:21:00,262] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:21:06,909] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:21:13,300] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:21:19,704] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:21:25,947] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:21:32,468] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8040626057565476
[2022-12-07 10:21:32,469] [INFO] [runner_train_mujoco] Average state value: 0.5243363081216812
[2022-12-07 10:21:32,469] [INFO] [controller] ITERATION NUM: 19
[2022-12-07 10:21:32,525] [INFO] [controller] EPOCH 1 loss ppo:  -0.01489, loss val: 0.03677
[2022-12-07 10:21:32,580] [INFO] [controller] EPOCH 2 loss ppo:  -0.03781, loss val: 0.03781
[2022-12-07 10:21:32,624] [INFO] [controller] EPOCH 3 loss ppo:  -0.04666, loss val: 0.03840
[2022-12-07 10:21:32,671] [INFO] [controller] EPOCH 4 loss ppo:  -0.05663, loss val: 0.03724
[2022-12-07 10:21:32,682] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:21:32,886] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:21:32,886] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:21:40,068] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:21:47,313] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:21:53,856] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:22:01,526] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:22:08,414] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:22:14,498] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:22:20,882] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:22:27,411] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:22:33,451] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:22:39,858] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.0470032257685005
[2022-12-07 10:22:39,858] [INFO] [runner_train_mujoco] Average state value: 0.5620870212813218
[2022-12-07 10:22:39,858] [INFO] [controller] ITERATION NUM: 20
[2022-12-07 10:22:39,914] [INFO] [controller] EPOCH 1 loss ppo:  -0.01357, loss val: 0.04390
[2022-12-07 10:22:39,968] [INFO] [controller] EPOCH 2 loss ppo:  -0.03298, loss val: 0.04328
[2022-12-07 10:22:40,014] [INFO] [controller] EPOCH 3 loss ppo:  -0.04650, loss val: 0.04171
[2022-12-07 10:22:40,062] [INFO] [controller] EPOCH 4 loss ppo:  -0.05990, loss val: 0.03927
[2022-12-07 10:22:40,072] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:22:40,278] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:22:40,278] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:22:46,291] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:22:52,541] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:22:59,283] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:23:06,680] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:23:16,182] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:23:24,834] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:23:31,372] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:23:38,145] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:23:44,743] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:23:51,285] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.3681748150044086
[2022-12-07 10:23:51,286] [INFO] [runner_train_mujoco] Average state value: 0.5193709557950495
[2022-12-07 10:23:51,286] [INFO] [controller] ITERATION NUM: 21
[2022-12-07 10:23:51,491] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.04447
[2022-12-07 10:23:51,558] [INFO] [controller] EPOCH 2 loss ppo:  -0.03407, loss val: 0.04678
[2022-12-07 10:23:51,605] [INFO] [controller] EPOCH 3 loss ppo:  -0.04724, loss val: 0.04856
[2022-12-07 10:23:51,656] [INFO] [controller] EPOCH 4 loss ppo:  -0.05580, loss val: 0.04423
[2022-12-07 10:23:51,666] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:23:51,872] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:23:51,872] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:23:58,948] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:24:05,866] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:24:12,751] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:24:19,080] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:24:26,204] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:24:33,034] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:24:39,967] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:24:47,004] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:24:53,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:25:00,017] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4716503809108232
[2022-12-07 10:25:00,018] [INFO] [runner_train_mujoco] Average state value: 0.5223644894460838
[2022-12-07 10:25:00,018] [INFO] [controller] ITERATION NUM: 22
[2022-12-07 10:25:00,089] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.04210
[2022-12-07 10:25:00,135] [INFO] [controller] EPOCH 2 loss ppo:  -0.04055, loss val: 0.04204
[2022-12-07 10:25:00,178] [INFO] [controller] EPOCH 3 loss ppo:  -0.05089, loss val: 0.04062
[2022-12-07 10:25:00,236] [INFO] [controller] EPOCH 4 loss ppo:  -0.06250, loss val: 0.04257
[2022-12-07 10:25:00,247] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:25:00,469] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:25:00,470] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:25:07,407] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:25:14,445] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:25:21,514] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:25:28,609] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:25:35,169] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:25:41,956] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:25:48,615] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:25:55,567] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:26:02,756] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:26:10,153] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.714967673694573
[2022-12-07 10:26:10,153] [INFO] [runner_train_mujoco] Average state value: 0.5453981655240059
[2022-12-07 10:26:10,154] [INFO] [controller] ITERATION NUM: 23
[2022-12-07 10:26:10,221] [INFO] [controller] EPOCH 1 loss ppo:  -0.01406, loss val: 0.03946
[2022-12-07 10:26:10,272] [INFO] [controller] EPOCH 2 loss ppo:  -0.03582, loss val: 0.03893
[2022-12-07 10:26:10,320] [INFO] [controller] EPOCH 3 loss ppo:  -0.05022, loss val: 0.03812
[2022-12-07 10:26:10,367] [INFO] [controller] EPOCH 4 loss ppo:  -0.05998, loss val: 0.03705
[2022-12-07 10:26:10,377] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:26:10,594] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:26:10,595] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:26:17,746] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:26:24,849] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:26:31,321] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:26:37,932] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:26:44,539] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:26:50,945] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:26:57,726] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:27:04,242] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:27:11,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:27:17,796] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.9816971024153065
[2022-12-07 10:27:17,797] [INFO] [runner_train_mujoco] Average state value: 0.5110763674974441
[2022-12-07 10:27:17,797] [INFO] [controller] ITERATION NUM: 24
[2022-12-07 10:27:17,849] [INFO] [controller] EPOCH 1 loss ppo:  -0.01788, loss val: 0.04241
[2022-12-07 10:27:17,892] [INFO] [controller] EPOCH 2 loss ppo:  -0.03681, loss val: 0.04132
[2022-12-07 10:27:17,939] [INFO] [controller] EPOCH 3 loss ppo:  -0.04932, loss val: 0.04173
[2022-12-07 10:27:17,982] [INFO] [controller] EPOCH 4 loss ppo:  -0.05681, loss val: 0.04149
[2022-12-07 10:27:17,992] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:27:18,180] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:27:18,180] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:27:25,574] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:27:33,206] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:27:40,953] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:27:47,808] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:27:54,333] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:28:01,011] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:28:08,433] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:28:15,983] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:28:23,443] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:28:30,636] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.1630146663731282
[2022-12-07 10:28:30,636] [INFO] [runner_train_mujoco] Average state value: 0.4732627123892307
[2022-12-07 10:28:30,636] [INFO] [controller] ITERATION NUM: 25
[2022-12-07 10:28:30,699] [INFO] [controller] EPOCH 1 loss ppo:  -0.01466, loss val: 0.04577
[2022-12-07 10:28:30,753] [INFO] [controller] EPOCH 2 loss ppo:  -0.03355, loss val: 0.04600
[2022-12-07 10:28:30,897] [INFO] [controller] EPOCH 3 loss ppo:  -0.04825, loss val: 0.05030
[2022-12-07 10:28:30,950] [INFO] [controller] EPOCH 4 loss ppo:  -0.05968, loss val: 0.04369
[2022-12-07 10:28:30,961] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:28:31,167] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:28:31,167] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:28:37,964] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:28:44,966] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:28:51,575] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:28:58,871] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:29:05,725] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:29:12,770] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:29:19,356] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:29:26,029] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:29:32,594] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:29:39,162] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.149913365491641
[2022-12-07 10:29:39,162] [INFO] [runner_train_mujoco] Average state value: 0.4899738777279854
[2022-12-07 10:29:39,162] [INFO] [controller] ITERATION NUM: 26
[2022-12-07 10:29:39,238] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.05086
[2022-12-07 10:29:39,288] [INFO] [controller] EPOCH 2 loss ppo:  -0.03193, loss val: 0.04939
[2022-12-07 10:29:39,339] [INFO] [controller] EPOCH 3 loss ppo:  -0.04045, loss val: 0.04590
[2022-12-07 10:29:39,383] [INFO] [controller] EPOCH 4 loss ppo:  -0.05293, loss val: 0.04562
[2022-12-07 10:29:39,394] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:29:39,623] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:29:39,624] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:29:47,269] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:29:54,847] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:30:02,133] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:30:09,114] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:30:15,874] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:30:22,721] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:30:29,958] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:30:36,711] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:30:43,461] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:30:50,515] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.6756155097114864
[2022-12-07 10:30:50,515] [INFO] [runner_train_mujoco] Average state value: 0.5480776666402817
[2022-12-07 10:30:50,515] [INFO] [controller] ITERATION NUM: 27
[2022-12-07 10:30:50,574] [INFO] [controller] EPOCH 1 loss ppo:  -0.01321, loss val: 0.04470
[2022-12-07 10:30:50,621] [INFO] [controller] EPOCH 2 loss ppo:  -0.02768, loss val: 0.04690
[2022-12-07 10:30:50,679] [INFO] [controller] EPOCH 3 loss ppo:  -0.04304, loss val: 0.04524
[2022-12-07 10:30:50,732] [INFO] [controller] EPOCH 4 loss ppo:  -0.05109, loss val: 0.04609
[2022-12-07 10:30:50,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:30:50,963] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:30:50,963] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:30:58,685] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:31:06,407] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:31:13,460] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:31:20,382] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:31:27,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:31:34,526] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:31:42,297] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:31:50,201] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:31:58,295] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:32:06,052] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.585230319772986
[2022-12-07 10:32:06,053] [INFO] [runner_train_mujoco] Average state value: 0.5662165213227273
[2022-12-07 10:32:06,053] [INFO] [controller] ITERATION NUM: 28
[2022-12-07 10:32:06,137] [INFO] [controller] EPOCH 1 loss ppo:  -0.01398, loss val: 0.04800
[2022-12-07 10:32:06,208] [INFO] [controller] EPOCH 2 loss ppo:  -0.02841, loss val: 0.04706
[2022-12-07 10:32:06,260] [INFO] [controller] EPOCH 3 loss ppo:  -0.03841, loss val: 0.04655
[2022-12-07 10:32:06,314] [INFO] [controller] EPOCH 4 loss ppo:  -0.04636, loss val: 0.04731
[2022-12-07 10:32:06,325] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:32:06,569] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:32:06,569] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:32:13,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:32:21,310] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:32:28,547] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:32:36,350] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:32:43,851] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:32:51,695] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:32:59,741] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:33:07,177] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:33:14,317] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:33:21,643] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9206611141539605
[2022-12-07 10:33:21,643] [INFO] [runner_train_mujoco] Average state value: 0.5813804132938386
[2022-12-07 10:33:21,643] [INFO] [controller] ITERATION NUM: 29
[2022-12-07 10:33:21,709] [INFO] [controller] EPOCH 1 loss ppo:  -0.01598, loss val: 0.04523
[2022-12-07 10:33:21,757] [INFO] [controller] EPOCH 2 loss ppo:  -0.03197, loss val: 0.04493
[2022-12-07 10:33:21,801] [INFO] [controller] EPOCH 3 loss ppo:  -0.04626, loss val: 0.04403
[2022-12-07 10:33:21,848] [INFO] [controller] EPOCH 4 loss ppo:  -0.05456, loss val: 0.04209
[2022-12-07 10:33:21,859] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:33:22,064] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:33:22,064] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:33:29,493] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:33:36,220] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:33:43,425] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:33:50,748] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:33:58,109] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:34:05,704] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:34:12,784] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:34:20,060] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:34:27,298] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:34:33,826] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.9509155570339245
[2022-12-07 10:34:33,826] [INFO] [runner_train_mujoco] Average state value: 0.5581857049663863
[2022-12-07 10:34:33,826] [INFO] [controller] ITERATION NUM: 30
[2022-12-07 10:34:33,895] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04345
[2022-12-07 10:34:33,940] [INFO] [controller] EPOCH 2 loss ppo:  -0.03140, loss val: 0.04112
[2022-12-07 10:34:33,993] [INFO] [controller] EPOCH 3 loss ppo:  -0.04492, loss val: 0.03988
[2022-12-07 10:34:34,045] [INFO] [controller] EPOCH 4 loss ppo:  -0.05696, loss val: 0.03848
[2022-12-07 10:34:34,069] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:34:34,270] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:34:34,270] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:34:40,747] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:34:49,059] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:34:56,537] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:35:03,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:35:10,128] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:35:16,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:35:24,088] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:35:30,501] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:35:37,147] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:35:43,884] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.16460510688877
[2022-12-07 10:35:43,884] [INFO] [runner_train_mujoco] Average state value: 0.490411637087663
[2022-12-07 10:35:43,884] [INFO] [controller] ITERATION NUM: 31
[2022-12-07 10:35:43,951] [INFO] [controller] EPOCH 1 loss ppo:  -0.01419, loss val: 0.04783
[2022-12-07 10:35:44,009] [INFO] [controller] EPOCH 2 loss ppo:  -0.02983, loss val: 0.04821
[2022-12-07 10:35:44,059] [INFO] [controller] EPOCH 3 loss ppo:  -0.04529, loss val: 0.04865
[2022-12-07 10:35:44,114] [INFO] [controller] EPOCH 4 loss ppo:  -0.05422, loss val: 0.05103
[2022-12-07 10:35:44,125] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:35:44,337] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:35:44,337] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:35:52,049] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:35:59,527] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:36:06,919] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:36:14,433] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:36:21,318] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:36:27,740] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:36:33,714] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:36:40,436] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:36:46,828] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:36:53,683] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.219001410919611
[2022-12-07 10:36:53,683] [INFO] [runner_train_mujoco] Average state value: 0.48248855227231974
[2022-12-07 10:36:53,684] [INFO] [controller] ITERATION NUM: 32
[2022-12-07 10:36:53,737] [INFO] [controller] EPOCH 1 loss ppo:  -0.01508, loss val: 0.04287
[2022-12-07 10:36:53,790] [INFO] [controller] EPOCH 2 loss ppo:  -0.03306, loss val: 0.04344
[2022-12-07 10:36:53,845] [INFO] [controller] EPOCH 3 loss ppo:  -0.04121, loss val: 0.04296
[2022-12-07 10:36:53,897] [INFO] [controller] EPOCH 4 loss ppo:  -0.05064, loss val: 0.04194
[2022-12-07 10:36:53,909] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:36:54,127] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:36:54,127] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:37:01,092] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:37:08,235] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:37:14,890] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:37:21,266] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:37:28,059] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:37:34,877] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:37:41,745] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:37:48,763] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:37:55,758] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:38:02,560] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.61870301649913
[2022-12-07 10:38:02,560] [INFO] [runner_train_mujoco] Average state value: 0.46297465090950335
[2022-12-07 10:38:02,560] [INFO] [controller] ITERATION NUM: 33
[2022-12-07 10:38:02,671] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.05206
[2022-12-07 10:38:02,715] [INFO] [controller] EPOCH 2 loss ppo:  -0.02562, loss val: 0.05300
[2022-12-07 10:38:02,762] [INFO] [controller] EPOCH 3 loss ppo:  -0.04090, loss val: 0.05247
[2022-12-07 10:38:02,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.05005, loss val: 0.05199
[2022-12-07 10:38:02,824] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:38:03,035] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:38:03,035] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:38:09,575] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:38:16,670] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:38:23,670] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:38:30,349] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:38:37,078] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:38:44,099] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:38:51,067] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:38:58,432] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:39:05,855] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:39:12,570] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.648884727128041
[2022-12-07 10:39:12,570] [INFO] [runner_train_mujoco] Average state value: 0.4641615448991458
[2022-12-07 10:39:12,570] [INFO] [controller] ITERATION NUM: 34
[2022-12-07 10:39:12,627] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.03939
[2022-12-07 10:39:12,673] [INFO] [controller] EPOCH 2 loss ppo:  -0.02273, loss val: 0.03846
[2022-12-07 10:39:12,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.03479, loss val: 0.03825
[2022-12-07 10:39:12,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.04748, loss val: 0.03859
[2022-12-07 10:39:12,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:39:12,995] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:39:12,996] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:39:19,633] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:39:26,336] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:39:33,143] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:39:39,832] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:39:46,806] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:39:53,298] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:39:59,981] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:40:06,886] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:40:13,592] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:40:20,361] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.835710882698684
[2022-12-07 10:40:20,361] [INFO] [runner_train_mujoco] Average state value: 0.5058892968098323
[2022-12-07 10:40:20,362] [INFO] [controller] ITERATION NUM: 35
[2022-12-07 10:40:20,426] [INFO] [controller] EPOCH 1 loss ppo:  -0.01311, loss val: 0.03385
[2022-12-07 10:40:20,478] [INFO] [controller] EPOCH 2 loss ppo:  -0.02706, loss val: 0.03423
[2022-12-07 10:40:20,524] [INFO] [controller] EPOCH 3 loss ppo:  -0.03740, loss val: 0.03510
[2022-12-07 10:40:20,575] [INFO] [controller] EPOCH 4 loss ppo:  -0.04558, loss val: 0.03775
[2022-12-07 10:40:20,587] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:40:20,803] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:40:20,804] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:40:27,752] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:40:34,512] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:40:41,026] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:40:48,200] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:40:54,646] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:41:01,181] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:41:07,729] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:41:13,870] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:41:20,076] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:41:26,182] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.915476096660285
[2022-12-07 10:41:26,183] [INFO] [runner_train_mujoco] Average state value: 0.5242755359609922
[2022-12-07 10:41:26,183] [INFO] [controller] ITERATION NUM: 36
[2022-12-07 10:41:26,240] [INFO] [controller] EPOCH 1 loss ppo:  -0.01557, loss val: 0.04327
[2022-12-07 10:41:26,282] [INFO] [controller] EPOCH 2 loss ppo:  -0.03007, loss val: 0.04395
[2022-12-07 10:41:26,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.03936, loss val: 0.04360
[2022-12-07 10:41:26,369] [INFO] [controller] EPOCH 4 loss ppo:  -0.04985, loss val: 0.04166
[2022-12-07 10:41:26,379] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:41:26,580] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:41:26,581] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:41:33,340] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:41:41,146] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:41:47,726] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:41:55,125] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:42:02,263] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:42:09,025] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:42:15,256] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:42:21,526] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:42:27,817] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:42:34,035] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.992444253424184
[2022-12-07 10:42:34,035] [INFO] [runner_train_mujoco] Average state value: 0.5026146514614422
[2022-12-07 10:42:34,035] [INFO] [controller] ITERATION NUM: 37
[2022-12-07 10:42:34,088] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04087
[2022-12-07 10:42:34,131] [INFO] [controller] EPOCH 2 loss ppo:  -0.02559, loss val: 0.04351
[2022-12-07 10:42:34,178] [INFO] [controller] EPOCH 3 loss ppo:  -0.03817, loss val: 0.04083
[2022-12-07 10:42:34,220] [INFO] [controller] EPOCH 4 loss ppo:  -0.04725, loss val: 0.04510
[2022-12-07 10:42:34,227] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:42:34,427] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:42:34,427] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:42:40,439] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:42:47,048] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:42:53,872] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:43:00,930] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:43:07,678] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:43:14,417] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:43:21,786] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:43:29,462] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:43:35,986] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:43:42,492] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.005465995033885
[2022-12-07 10:43:42,493] [INFO] [runner_train_mujoco] Average state value: 0.510019166946411
[2022-12-07 10:43:42,493] [INFO] [controller] ITERATION NUM: 38
[2022-12-07 10:43:42,545] [INFO] [controller] EPOCH 1 loss ppo:  -0.01365, loss val: 0.04817
[2022-12-07 10:43:42,583] [INFO] [controller] EPOCH 2 loss ppo:  -0.02670, loss val: 0.04861
[2022-12-07 10:43:42,630] [INFO] [controller] EPOCH 3 loss ppo:  -0.03662, loss val: 0.04762
[2022-12-07 10:43:42,684] [INFO] [controller] EPOCH 4 loss ppo:  -0.04607, loss val: 0.04738
[2022-12-07 10:43:42,694] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:43:42,886] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:43:42,886] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:43:49,414] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:43:56,020] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:44:02,697] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:44:09,415] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:44:16,085] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:44:22,792] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:44:29,698] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:44:36,583] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:44:43,627] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:44:50,506] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.978296391139901
[2022-12-07 10:44:50,506] [INFO] [runner_train_mujoco] Average state value: 0.5011361231009166
[2022-12-07 10:44:50,506] [INFO] [controller] ITERATION NUM: 39
[2022-12-07 10:44:50,560] [INFO] [controller] EPOCH 1 loss ppo:  -0.01463, loss val: 0.04113
[2022-12-07 10:44:50,606] [INFO] [controller] EPOCH 2 loss ppo:  -0.02706, loss val: 0.04183
[2022-12-07 10:44:50,651] [INFO] [controller] EPOCH 3 loss ppo:  -0.03351, loss val: 0.03856
[2022-12-07 10:44:50,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.04763, loss val: 0.03764
[2022-12-07 10:44:50,704] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:44:50,907] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:44:50,908] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:44:58,448] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:45:05,511] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:45:12,365] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:45:19,178] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:45:25,886] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:45:32,727] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:45:41,578] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:45:48,973] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:45:57,207] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:46:04,185] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.295936687919013
[2022-12-07 10:46:04,185] [INFO] [runner_train_mujoco] Average state value: 0.4567233609358469
[2022-12-07 10:46:04,185] [INFO] [controller] ITERATION NUM: 40
[2022-12-07 10:46:04,243] [INFO] [controller] EPOCH 1 loss ppo:  -0.01480, loss val: 0.04324
[2022-12-07 10:46:04,295] [INFO] [controller] EPOCH 2 loss ppo:  -0.02249, loss val: 0.04321
[2022-12-07 10:46:04,343] [INFO] [controller] EPOCH 3 loss ppo:  -0.03162, loss val: 0.04344
[2022-12-07 10:46:04,396] [INFO] [controller] EPOCH 4 loss ppo:  -0.04397, loss val: 0.04391
[2022-12-07 10:46:04,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:46:04,619] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:46:04,619] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:46:13,148] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:46:20,859] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:46:27,951] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:46:34,908] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:46:42,493] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:46:50,286] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:46:57,144] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:47:04,378] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:47:11,424] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:47:18,511] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.2266017291435425
[2022-12-07 10:47:18,511] [INFO] [runner_train_mujoco] Average state value: 0.4319540506899357
[2022-12-07 10:47:18,511] [INFO] [controller] ITERATION NUM: 41
[2022-12-07 10:47:18,575] [INFO] [controller] EPOCH 1 loss ppo:  -0.01421, loss val: 0.04587
[2022-12-07 10:47:18,623] [INFO] [controller] EPOCH 2 loss ppo:  -0.02529, loss val: 0.04649
[2022-12-07 10:47:18,673] [INFO] [controller] EPOCH 3 loss ppo:  -0.03162, loss val: 0.04609
[2022-12-07 10:47:18,743] [INFO] [controller] EPOCH 4 loss ppo:  -0.04065, loss val: 0.04541
[2022-12-07 10:47:18,754] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:47:18,969] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:47:18,970] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:47:25,736] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:47:32,888] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:47:40,107] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:47:47,110] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:47:54,921] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:48:02,016] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:48:09,306] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:48:16,534] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:48:23,793] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:48:30,627] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.075540325078002
[2022-12-07 10:48:30,627] [INFO] [runner_train_mujoco] Average state value: 0.44537170783678687
[2022-12-07 10:48:30,627] [INFO] [controller] ITERATION NUM: 42
[2022-12-07 10:48:30,681] [INFO] [controller] EPOCH 1 loss ppo:  -0.01286, loss val: 0.04211
[2022-12-07 10:48:30,730] [INFO] [controller] EPOCH 2 loss ppo:  -0.02200, loss val: 0.04299
[2022-12-07 10:48:30,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.03545, loss val: 0.04088
[2022-12-07 10:48:30,825] [INFO] [controller] EPOCH 4 loss ppo:  -0.04510, loss val: 0.04072
[2022-12-07 10:48:30,835] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:48:31,050] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:48:31,050] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:48:38,289] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:48:45,177] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:48:52,544] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:48:59,184] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:49:05,813] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:49:13,017] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:49:21,019] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:49:28,794] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:49:35,891] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:49:43,214] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.356344880600423
[2022-12-07 10:49:43,214] [INFO] [runner_train_mujoco] Average state value: 0.4715084390640259
[2022-12-07 10:49:43,214] [INFO] [controller] ITERATION NUM: 43
[2022-12-07 10:49:43,268] [INFO] [controller] EPOCH 1 loss ppo:  -0.01423, loss val: 0.04792
[2022-12-07 10:49:43,313] [INFO] [controller] EPOCH 2 loss ppo:  -0.02548, loss val: 0.04924
[2022-12-07 10:49:43,358] [INFO] [controller] EPOCH 3 loss ppo:  -0.03264, loss val: 0.04784
[2022-12-07 10:49:43,399] [INFO] [controller] EPOCH 4 loss ppo:  -0.04456, loss val: 0.04764
[2022-12-07 10:49:43,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:49:43,610] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:49:43,611] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:49:52,212] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:50:00,513] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:50:07,496] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:50:14,306] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:50:21,165] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:50:27,953] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:50:35,417] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:50:45,417] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:50:54,249] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:51:01,687] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.487979941863734
[2022-12-07 10:51:01,688] [INFO] [runner_train_mujoco] Average state value: 0.49291058661540355
[2022-12-07 10:51:01,688] [INFO] [controller] ITERATION NUM: 44
[2022-12-07 10:51:01,742] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.04400
[2022-12-07 10:51:01,792] [INFO] [controller] EPOCH 2 loss ppo:  -0.02291, loss val: 0.04444
[2022-12-07 10:51:01,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.02840, loss val: 0.04343
[2022-12-07 10:51:01,892] [INFO] [controller] EPOCH 4 loss ppo:  -0.03566, loss val: 0.04394
[2022-12-07 10:51:01,902] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:51:02,101] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:51:02,102] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:51:09,507] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:51:16,531] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:51:23,891] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:51:31,087] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:51:38,507] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:51:46,461] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:51:53,255] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:51:59,896] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:52:06,307] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:52:13,646] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.461711926939811
[2022-12-07 10:52:13,647] [INFO] [runner_train_mujoco] Average state value: 0.48663188735644025
[2022-12-07 10:52:13,647] [INFO] [controller] ITERATION NUM: 45
[2022-12-07 10:52:13,737] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.04679
[2022-12-07 10:52:13,788] [INFO] [controller] EPOCH 2 loss ppo:  -0.02807, loss val: 0.04560
[2022-12-07 10:52:13,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.03429, loss val: 0.04623
[2022-12-07 10:52:13,898] [INFO] [controller] EPOCH 4 loss ppo:  -0.04274, loss val: 0.04551
[2022-12-07 10:52:13,910] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:52:14,126] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:52:14,126] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:52:21,552] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:52:29,932] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:52:37,885] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:52:46,271] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:52:53,119] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:52:59,798] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:53:07,036] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:53:13,986] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:53:21,470] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:53:28,556] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.572606853912707
[2022-12-07 10:53:28,556] [INFO] [runner_train_mujoco] Average state value: 0.4650570856730143
[2022-12-07 10:53:28,556] [INFO] [controller] ITERATION NUM: 46
[2022-12-07 10:53:28,621] [INFO] [controller] EPOCH 1 loss ppo:  -0.01309, loss val: 0.04824
[2022-12-07 10:53:28,679] [INFO] [controller] EPOCH 2 loss ppo:  -0.02330, loss val: 0.04390
[2022-12-07 10:53:28,814] [INFO] [controller] EPOCH 3 loss ppo:  -0.03285, loss val: 0.04479
[2022-12-07 10:53:28,863] [INFO] [controller] EPOCH 4 loss ppo:  -0.03831, loss val: 0.04453
[2022-12-07 10:53:28,873] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:53:29,075] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:53:29,075] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:53:36,628] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:53:44,487] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:53:51,816] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:53:58,836] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:54:05,364] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:54:11,814] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:54:18,330] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:54:25,446] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:54:32,141] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:54:38,760] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.620995431291952
[2022-12-07 10:54:38,760] [INFO] [runner_train_mujoco] Average state value: 0.4452400490045547
[2022-12-07 10:54:38,760] [INFO] [controller] ITERATION NUM: 47
[2022-12-07 10:54:38,814] [INFO] [controller] EPOCH 1 loss ppo:  -0.01454, loss val: 0.04655
[2022-12-07 10:54:38,858] [INFO] [controller] EPOCH 2 loss ppo:  -0.02486, loss val: 0.04738
[2022-12-07 10:54:38,904] [INFO] [controller] EPOCH 3 loss ppo:  -0.03008, loss val: 0.04668
[2022-12-07 10:54:38,955] [INFO] [controller] EPOCH 4 loss ppo:  -0.03655, loss val: 0.04663
[2022-12-07 10:54:38,965] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:54:39,169] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:54:39,170] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:54:46,513] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:54:53,491] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:54:59,812] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:55:06,162] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:55:12,728] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:55:19,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:55:26,497] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:55:33,250] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:55:39,576] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:55:46,722] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.759667724645508
[2022-12-07 10:55:46,722] [INFO] [runner_train_mujoco] Average state value: 0.443299179037412
[2022-12-07 10:55:46,722] [INFO] [controller] ITERATION NUM: 48
[2022-12-07 10:55:46,776] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04804
[2022-12-07 10:55:46,821] [INFO] [controller] EPOCH 2 loss ppo:  -0.02196, loss val: 0.04645
[2022-12-07 10:55:46,866] [INFO] [controller] EPOCH 3 loss ppo:  -0.02733, loss val: 0.04604
[2022-12-07 10:55:46,912] [INFO] [controller] EPOCH 4 loss ppo:  -0.03448, loss val: 0.04631
[2022-12-07 10:55:46,922] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:55:47,093] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:55:47,093] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:55:53,682] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:56:00,327] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:56:06,864] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:56:13,557] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:56:22,578] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:56:30,355] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:56:37,003] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:56:43,851] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:56:50,386] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:56:57,139] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.574055401628066
[2022-12-07 10:56:57,139] [INFO] [runner_train_mujoco] Average state value: 0.45432409423589704
[2022-12-07 10:56:57,140] [INFO] [controller] ITERATION NUM: 49
[2022-12-07 10:56:57,192] [INFO] [controller] EPOCH 1 loss ppo:  -0.01438, loss val: 0.04943
[2022-12-07 10:56:57,237] [INFO] [controller] EPOCH 2 loss ppo:  -0.02336, loss val: 0.05098
[2022-12-07 10:56:57,282] [INFO] [controller] EPOCH 3 loss ppo:  -0.02860, loss val: 0.04924
[2022-12-07 10:56:57,340] [INFO] [controller] EPOCH 4 loss ppo:  -0.03802, loss val: 0.04939
[2022-12-07 10:56:57,350] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:56:57,551] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:56:57,552] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:57:04,204] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:57:11,046] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:57:17,437] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:57:23,523] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:57:30,194] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:57:37,815] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:57:45,200] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:57:52,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:58:00,196] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:58:10,087] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.782426309773925
[2022-12-07 10:58:10,087] [INFO] [runner_train_mujoco] Average state value: 0.46586184245347984
[2022-12-07 10:58:10,088] [INFO] [controller] ITERATION NUM: 50
[2022-12-07 10:58:10,169] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.04964
[2022-12-07 10:58:10,229] [INFO] [controller] EPOCH 2 loss ppo:  -0.02080, loss val: 0.04900
[2022-12-07 10:58:10,289] [INFO] [controller] EPOCH 3 loss ppo:  -0.02748, loss val: 0.05003
[2022-12-07 10:58:10,343] [INFO] [controller] EPOCH 4 loss ppo:  -0.03392, loss val: 0.04897
[2022-12-07 10:58:10,357] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:58:10,586] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:58:10,586] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:58:17,105] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:58:23,745] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:58:30,212] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 10:58:36,860] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 10:58:43,649] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 10:58:51,797] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 10:58:58,877] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 10:59:06,603] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 10:59:14,516] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 10:59:24,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.848263968176776
[2022-12-07 10:59:24,676] [INFO] [runner_train_mujoco] Average state value: 0.4649513401687145
[2022-12-07 10:59:24,677] [INFO] [controller] ITERATION NUM: 51
[2022-12-07 10:59:24,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01290, loss val: 0.05219
[2022-12-07 10:59:24,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.01909, loss val: 0.05129
[2022-12-07 10:59:24,971] [INFO] [controller] EPOCH 3 loss ppo:  -0.02698, loss val: 0.05267
[2022-12-07 10:59:25,037] [INFO] [controller] EPOCH 4 loss ppo:  -0.03501, loss val: 0.05301
[2022-12-07 10:59:25,049] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 10:59:25,280] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 10:59:25,281] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 10:59:34,231] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 10:59:42,622] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 10:59:51,265] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:00:00,028] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:00:08,448] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:00:16,822] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:00:25,869] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:00:34,660] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:00:43,965] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:00:52,082] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.83818954136764
[2022-12-07 11:00:52,082] [INFO] [runner_train_mujoco] Average state value: 0.46059712910652156
[2022-12-07 11:00:52,082] [INFO] [controller] ITERATION NUM: 52
[2022-12-07 11:00:52,148] [INFO] [controller] EPOCH 1 loss ppo:  -0.01429, loss val: 0.04954
[2022-12-07 11:00:52,208] [INFO] [controller] EPOCH 2 loss ppo:  -0.02227, loss val: 0.04964
[2022-12-07 11:00:52,269] [INFO] [controller] EPOCH 3 loss ppo:  -0.02534, loss val: 0.05077
[2022-12-07 11:00:52,332] [INFO] [controller] EPOCH 4 loss ppo:  -0.03133, loss val: 0.04950
[2022-12-07 11:00:52,345] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:00:52,593] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:00:52,594] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:01:01,348] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:01:09,946] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:01:18,132] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:01:27,255] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:01:37,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:01:46,719] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:01:55,917] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:02:05,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:02:14,566] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:02:23,446] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.6668661911226215
[2022-12-07 11:02:23,446] [INFO] [runner_train_mujoco] Average state value: 0.4653957575360934
[2022-12-07 11:02:23,446] [INFO] [controller] ITERATION NUM: 53
[2022-12-07 11:02:23,529] [INFO] [controller] EPOCH 1 loss ppo:  -0.01416, loss val: 0.04341
[2022-12-07 11:02:23,621] [INFO] [controller] EPOCH 2 loss ppo:  -0.02171, loss val: 0.04277
[2022-12-07 11:02:23,677] [INFO] [controller] EPOCH 3 loss ppo:  -0.02859, loss val: 0.04266
[2022-12-07 11:02:23,732] [INFO] [controller] EPOCH 4 loss ppo:  -0.03332, loss val: 0.04214
[2022-12-07 11:02:23,744] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:02:23,966] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:02:23,967] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:02:32,797] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:02:41,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:02:51,154] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:02:59,650] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:03:08,723] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:03:17,069] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:03:25,931] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:03:34,441] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:03:42,824] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:03:51,953] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.791819718083187
[2022-12-07 11:03:51,953] [INFO] [runner_train_mujoco] Average state value: 0.4744466530283292
[2022-12-07 11:03:51,954] [INFO] [controller] ITERATION NUM: 54
[2022-12-07 11:03:52,051] [INFO] [controller] EPOCH 1 loss ppo:  -0.01448, loss val: 0.04676
[2022-12-07 11:03:52,118] [INFO] [controller] EPOCH 2 loss ppo:  -0.02024, loss val: 0.04527
[2022-12-07 11:03:52,195] [INFO] [controller] EPOCH 3 loss ppo:  -0.02668, loss val: 0.04666
[2022-12-07 11:03:52,264] [INFO] [controller] EPOCH 4 loss ppo:  -0.03090, loss val: 0.04611
[2022-12-07 11:03:52,289] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:03:52,519] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:03:52,519] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:04:01,544] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:04:10,328] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:04:18,633] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:04:27,293] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:04:35,379] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:04:43,513] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:04:51,680] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:04:59,646] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:05:07,662] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:05:15,589] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.84844630620543
[2022-12-07 11:05:15,589] [INFO] [runner_train_mujoco] Average state value: 0.48097737121582024
[2022-12-07 11:05:15,589] [INFO] [controller] ITERATION NUM: 55
[2022-12-07 11:05:15,716] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.04412
[2022-12-07 11:05:15,778] [INFO] [controller] EPOCH 2 loss ppo:  -0.01864, loss val: 0.04647
[2022-12-07 11:05:15,842] [INFO] [controller] EPOCH 3 loss ppo:  -0.02361, loss val: 0.04728
[2022-12-07 11:05:15,913] [INFO] [controller] EPOCH 4 loss ppo:  -0.02908, loss val: 0.04755
[2022-12-07 11:05:15,924] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:05:16,148] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:05:16,154] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:05:24,957] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:05:33,255] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:05:41,285] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:05:49,134] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:05:57,004] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:06:04,847] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:06:12,483] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:06:20,398] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:06:29,075] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:06:37,520] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.963935183078062
[2022-12-07 11:06:37,520] [INFO] [runner_train_mujoco] Average state value: 0.48007765311002737
[2022-12-07 11:06:37,520] [INFO] [controller] ITERATION NUM: 56
[2022-12-07 11:06:37,598] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04818
[2022-12-07 11:06:37,696] [INFO] [controller] EPOCH 2 loss ppo:  -0.01645, loss val: 0.04757
[2022-12-07 11:06:37,777] [INFO] [controller] EPOCH 3 loss ppo:  -0.02161, loss val: 0.04749
[2022-12-07 11:06:37,854] [INFO] [controller] EPOCH 4 loss ppo:  -0.02731, loss val: 0.04833
[2022-12-07 11:06:37,865] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:06:38,087] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:06:38,087] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:06:47,084] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:06:55,493] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:07:04,649] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:07:15,449] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:07:26,275] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:07:36,543] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:07:45,619] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:07:54,268] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:08:03,381] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:08:12,505] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 6.014889592169578
[2022-12-07 11:08:12,505] [INFO] [runner_train_mujoco] Average state value: 0.48167917197942733
[2022-12-07 11:08:12,505] [INFO] [controller] ITERATION NUM: 57
[2022-12-07 11:08:12,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.01354, loss val: 0.05104
[2022-12-07 11:08:12,651] [INFO] [controller] EPOCH 2 loss ppo:  -0.01528, loss val: 0.05338
[2022-12-07 11:08:12,718] [INFO] [controller] EPOCH 3 loss ppo:  -0.01803, loss val: 0.05083
[2022-12-07 11:08:12,779] [INFO] [controller] EPOCH 4 loss ppo:  -0.02153, loss val: 0.05095
[2022-12-07 11:08:12,806] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:08:13,051] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-07 11:08:13,051] [INFO] [runner_train_mujoco] Environment 0
[2022-12-07 11:08:22,222] [INFO] [runner_train_mujoco] Environment 1
[2022-12-07 11:08:31,925] [INFO] [runner_train_mujoco] Environment 2
[2022-12-07 11:08:41,490] [INFO] [runner_train_mujoco] Environment 3
[2022-12-07 11:08:50,929] [INFO] [runner_train_mujoco] Environment 4
[2022-12-07 11:09:00,291] [INFO] [runner_train_mujoco] Environment 5
[2022-12-07 11:09:09,162] [INFO] [runner_train_mujoco] Environment 6
[2022-12-07 11:09:18,632] [INFO] [runner_train_mujoco] Environment 7
[2022-12-07 11:09:28,528] [INFO] [runner_train_mujoco] Environment 8
[2022-12-07 11:09:38,848] [INFO] [runner_train_mujoco] Environment 9
[2022-12-07 11:09:48,416] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.983663100004483
[2022-12-07 11:09:48,416] [INFO] [runner_train_mujoco] Average state value: 0.47791968139012664
[2022-12-07 11:09:48,417] [INFO] [controller] ITERATION NUM: 58
[2022-12-07 11:09:48,509] [INFO] [controller] EPOCH 1 loss ppo:  -0.01374, loss val: 0.04398
[2022-12-07 11:09:48,596] [INFO] [controller] EPOCH 2 loss ppo:  -0.01508, loss val: 0.04326
[2022-12-07 11:09:48,661] [INFO] [controller] EPOCH 3 loss ppo:  -0.01730, loss val: 0.04412
[2022-12-07 11:09:48,727] [INFO] [controller] EPOCH 4 loss ppo:  -0.02025, loss val: 0.04264
[2022-12-07 11:09:48,739] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-07 11:09:48,916] [INFO] [optimize] Finished learning.
