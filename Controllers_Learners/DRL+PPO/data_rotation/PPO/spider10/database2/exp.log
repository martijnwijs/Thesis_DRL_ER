[2022-12-06 16:14:53,675] [INFO] [optimize] Starting learning
[2022-12-06 16:14:53,686] [INFO] [optimize] Starting learning process..
[2022-12-06 16:14:53,870] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:14:53,882] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:15:04,396] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:15:12,797] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:15:21,721] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:15:30,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:15:38,523] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:15:47,235] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:15:56,449] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:16:05,614] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:16:14,704] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:16:23,728] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.3919774227545469
[2022-12-06 16:16:23,728] [INFO] [runner_train_mujoco] Average state value: -0.13803663702309132
[2022-12-06 16:16:23,728] [INFO] [controller] ITERATION NUM: 1
[2022-12-06 16:16:23,816] [INFO] [controller] EPOCH 1 loss ppo:  -0.01393, loss val: 0.51364
[2022-12-06 16:16:23,877] [INFO] [controller] EPOCH 2 loss ppo:  -0.04380, loss val: 0.46013
[2022-12-06 16:16:23,933] [INFO] [controller] EPOCH 3 loss ppo:  -0.05533, loss val: 0.37403
[2022-12-06 16:16:23,992] [INFO] [controller] EPOCH 4 loss ppo:  -0.05978, loss val: 0.34421
[2022-12-06 16:16:24,008] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:16:24,237] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:16:24,238] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:16:32,970] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:16:42,190] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:16:51,474] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:17:00,872] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:17:10,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:17:19,306] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:17:28,608] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:17:38,079] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:17:47,604] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:17:57,493] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4569705073844797
[2022-12-06 16:17:57,494] [INFO] [runner_train_mujoco] Average state value: 0.010713590327960749
[2022-12-06 16:17:57,494] [INFO] [controller] ITERATION NUM: 2
[2022-12-06 16:17:57,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.01527, loss val: 0.32803
[2022-12-06 16:17:57,659] [INFO] [controller] EPOCH 2 loss ppo:  -0.04042, loss val: 0.28790
[2022-12-06 16:17:57,716] [INFO] [controller] EPOCH 3 loss ppo:  -0.05382, loss val: 0.25639
[2022-12-06 16:17:57,814] [INFO] [controller] EPOCH 4 loss ppo:  -0.06017, loss val: 0.21710
[2022-12-06 16:17:57,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:17:58,060] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:17:58,060] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:18:07,679] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:18:16,706] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:18:25,944] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:18:34,653] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:18:43,344] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:18:52,684] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:19:02,082] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:19:11,058] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:19:20,138] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:19:28,746] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.4013665107810307
[2022-12-06 16:19:28,746] [INFO] [runner_train_mujoco] Average state value: 0.19638837891072033
[2022-12-06 16:19:28,746] [INFO] [controller] ITERATION NUM: 3
[2022-12-06 16:19:28,826] [INFO] [controller] EPOCH 1 loss ppo:  -0.01475, loss val: 0.20267
[2022-12-06 16:19:28,889] [INFO] [controller] EPOCH 2 loss ppo:  -0.04047, loss val: 0.17063
[2022-12-06 16:19:28,948] [INFO] [controller] EPOCH 3 loss ppo:  -0.05264, loss val: 0.14879
[2022-12-06 16:19:29,006] [INFO] [controller] EPOCH 4 loss ppo:  -0.06129, loss val: 0.13009
[2022-12-06 16:19:29,019] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:19:29,247] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:19:29,247] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:19:38,111] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:19:47,402] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:19:56,271] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:20:04,829] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:20:13,323] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:20:21,924] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:20:30,766] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:20:39,199] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:20:47,951] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:20:56,230] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.40223708509168976
[2022-12-06 16:20:56,230] [INFO] [runner_train_mujoco] Average state value: 0.3656254474806289
[2022-12-06 16:20:56,231] [INFO] [controller] ITERATION NUM: 4
[2022-12-06 16:20:56,304] [INFO] [controller] EPOCH 1 loss ppo:  -0.01128, loss val: 0.09938
[2022-12-06 16:20:56,358] [INFO] [controller] EPOCH 2 loss ppo:  -0.04014, loss val: 0.08693
[2022-12-06 16:20:56,422] [INFO] [controller] EPOCH 3 loss ppo:  -0.05109, loss val: 0.08327
[2022-12-06 16:20:56,492] [INFO] [controller] EPOCH 4 loss ppo:  -0.06008, loss val: 0.08153
[2022-12-06 16:20:56,503] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:20:56,716] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:20:56,717] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:21:05,412] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:21:13,563] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:21:22,097] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:21:30,557] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:21:39,322] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:21:47,942] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:21:56,512] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:22:05,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:22:14,558] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:22:23,779] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.32001308282057106
[2022-12-06 16:22:23,779] [INFO] [runner_train_mujoco] Average state value: 0.46582936765315636
[2022-12-06 16:22:23,780] [INFO] [controller] ITERATION NUM: 5
[2022-12-06 16:22:23,852] [INFO] [controller] EPOCH 1 loss ppo:  -0.01308, loss val: 0.09735
[2022-12-06 16:22:23,906] [INFO] [controller] EPOCH 2 loss ppo:  -0.03359, loss val: 0.08727
[2022-12-06 16:22:23,985] [INFO] [controller] EPOCH 3 loss ppo:  -0.04887, loss val: 0.07623
[2022-12-06 16:22:24,039] [INFO] [controller] EPOCH 4 loss ppo:  -0.05865, loss val: 0.06787
[2022-12-06 16:22:24,050] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:22:24,269] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:22:24,269] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:22:33,161] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:22:41,676] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:22:50,386] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:22:59,617] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:23:09,279] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:23:18,469] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:23:27,522] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:23:36,387] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:23:45,518] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:23:54,647] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2728568216317553
[2022-12-06 16:23:54,647] [INFO] [runner_train_mujoco] Average state value: 0.5899763321777185
[2022-12-06 16:23:54,647] [INFO] [controller] ITERATION NUM: 6
[2022-12-06 16:23:54,731] [INFO] [controller] EPOCH 1 loss ppo:  -0.00941, loss val: 0.06154
[2022-12-06 16:23:54,790] [INFO] [controller] EPOCH 2 loss ppo:  -0.03805, loss val: 0.06050
[2022-12-06 16:23:54,858] [INFO] [controller] EPOCH 3 loss ppo:  -0.04833, loss val: 0.06367
[2022-12-06 16:23:54,924] [INFO] [controller] EPOCH 4 loss ppo:  -0.05517, loss val: 0.05689
[2022-12-06 16:23:54,949] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:23:55,183] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:23:55,183] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:24:04,465] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:24:13,934] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:24:23,288] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:24:32,394] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:24:42,171] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:24:51,714] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:25:01,061] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:25:10,809] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:25:20,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:25:30,078] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5560854107362241
[2022-12-06 16:25:30,078] [INFO] [runner_train_mujoco] Average state value: 0.6451718530555567
[2022-12-06 16:25:30,079] [INFO] [controller] ITERATION NUM: 7
[2022-12-06 16:25:30,199] [INFO] [controller] EPOCH 1 loss ppo:  -0.01101, loss val: 0.05505
[2022-12-06 16:25:30,259] [INFO] [controller] EPOCH 2 loss ppo:  -0.03555, loss val: 0.05314
[2022-12-06 16:25:30,334] [INFO] [controller] EPOCH 3 loss ppo:  -0.04554, loss val: 0.05102
[2022-12-06 16:25:30,397] [INFO] [controller] EPOCH 4 loss ppo:  -0.04929, loss val: 0.04979
[2022-12-06 16:25:30,409] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:25:30,651] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:25:30,652] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:25:39,847] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:25:55,455] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:26:09,825] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:26:23,052] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:26:36,776] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:26:49,213] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:27:00,721] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:27:12,069] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:27:20,924] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:27:30,290] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.2781616280409053
[2022-12-06 16:27:30,290] [INFO] [runner_train_mujoco] Average state value: 0.6062145533959071
[2022-12-06 16:27:30,290] [INFO] [controller] ITERATION NUM: 8
[2022-12-06 16:27:30,416] [INFO] [controller] EPOCH 1 loss ppo:  -0.00905, loss val: 0.04384
[2022-12-06 16:27:30,471] [INFO] [controller] EPOCH 2 loss ppo:  -0.02975, loss val: 0.03795
[2022-12-06 16:27:30,529] [INFO] [controller] EPOCH 3 loss ppo:  -0.04021, loss val: 0.03956
[2022-12-06 16:27:30,585] [INFO] [controller] EPOCH 4 loss ppo:  -0.05111, loss val: 0.03622
[2022-12-06 16:27:30,597] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:27:30,831] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:27:30,831] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:27:41,581] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:27:54,963] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:28:07,276] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:28:17,563] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:28:27,364] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:28:37,183] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:28:47,083] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:28:56,369] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:29:06,446] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:29:16,784] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6328914574633999
[2022-12-06 16:29:16,785] [INFO] [runner_train_mujoco] Average state value: 0.5990609934031964
[2022-12-06 16:29:16,785] [INFO] [controller] ITERATION NUM: 9
[2022-12-06 16:29:16,943] [INFO] [controller] EPOCH 1 loss ppo:  -0.01128, loss val: 0.04382
[2022-12-06 16:29:17,059] [INFO] [controller] EPOCH 2 loss ppo:  -0.03140, loss val: 0.04327
[2022-12-06 16:29:17,256] [INFO] [controller] EPOCH 3 loss ppo:  -0.04376, loss val: 0.04132
[2022-12-06 16:29:17,336] [INFO] [controller] EPOCH 4 loss ppo:  -0.05299, loss val: 0.04074
[2022-12-06 16:29:17,352] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:29:17,663] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:29:17,663] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:29:28,229] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:29:38,518] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:29:49,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:29:58,287] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:30:07,545] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:30:16,788] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:30:25,854] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:30:35,119] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:30:44,431] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:30:53,528] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.5931579189758428
[2022-12-06 16:30:53,528] [INFO] [runner_train_mujoco] Average state value: 0.5886915019551913
[2022-12-06 16:30:53,528] [INFO] [controller] ITERATION NUM: 10
[2022-12-06 16:30:53,603] [INFO] [controller] EPOCH 1 loss ppo:  -0.01225, loss val: 0.04279
[2022-12-06 16:30:53,658] [INFO] [controller] EPOCH 2 loss ppo:  -0.03426, loss val: 0.03962
[2022-12-06 16:30:53,756] [INFO] [controller] EPOCH 3 loss ppo:  -0.04488, loss val: 0.04020
[2022-12-06 16:30:53,811] [INFO] [controller] EPOCH 4 loss ppo:  -0.05374, loss val: 0.03971
[2022-12-06 16:30:53,822] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:30:54,074] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:30:54,075] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:31:03,528] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:31:12,265] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:31:20,878] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:31:29,534] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:31:38,501] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:31:47,092] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:31:56,304] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:32:05,230] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:32:13,344] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:32:22,050] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.6672475854425541
[2022-12-06 16:32:22,051] [INFO] [runner_train_mujoco] Average state value: 0.5527961859305699
[2022-12-06 16:32:22,051] [INFO] [controller] ITERATION NUM: 11
[2022-12-06 16:32:22,154] [INFO] [controller] EPOCH 1 loss ppo:  -0.01254, loss val: 0.04396
[2022-12-06 16:32:22,252] [INFO] [controller] EPOCH 2 loss ppo:  -0.03869, loss val: 0.04249
[2022-12-06 16:32:22,322] [INFO] [controller] EPOCH 3 loss ppo:  -0.05058, loss val: 0.04109
[2022-12-06 16:32:22,427] [INFO] [controller] EPOCH 4 loss ppo:  -0.05520, loss val: 0.03751
[2022-12-06 16:32:22,447] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:32:22,670] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:32:22,671] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:32:31,787] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:32:40,796] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:32:50,024] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:32:58,480] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:33:06,884] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:33:15,414] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:33:23,826] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:33:31,882] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:33:39,672] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:33:47,639] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0057320120589957
[2022-12-06 16:33:47,639] [INFO] [runner_train_mujoco] Average state value: 0.512771887977918
[2022-12-06 16:33:47,640] [INFO] [controller] ITERATION NUM: 12
[2022-12-06 16:33:47,723] [INFO] [controller] EPOCH 1 loss ppo:  -0.01300, loss val: 0.03871
[2022-12-06 16:33:47,781] [INFO] [controller] EPOCH 2 loss ppo:  -0.03714, loss val: 0.04135
[2022-12-06 16:33:47,921] [INFO] [controller] EPOCH 3 loss ppo:  -0.04738, loss val: 0.03920
[2022-12-06 16:33:47,988] [INFO] [controller] EPOCH 4 loss ppo:  -0.05613, loss val: 0.03908
[2022-12-06 16:33:47,999] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:33:48,215] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:33:48,216] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:33:56,780] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:34:05,488] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:34:14,082] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:34:23,471] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:34:33,325] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:34:43,283] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:34:53,631] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:35:07,560] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:35:17,858] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:35:27,175] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 0.9807410780262666
[2022-12-06 16:35:27,176] [INFO] [runner_train_mujoco] Average state value: 0.5053164765636124
[2022-12-06 16:35:27,176] [INFO] [controller] ITERATION NUM: 13
[2022-12-06 16:35:27,273] [INFO] [controller] EPOCH 1 loss ppo:  -0.01213, loss val: 0.03895
[2022-12-06 16:35:27,336] [INFO] [controller] EPOCH 2 loss ppo:  -0.03681, loss val: 0.03858
[2022-12-06 16:35:27,401] [INFO] [controller] EPOCH 3 loss ppo:  -0.05003, loss val: 0.03672
[2022-12-06 16:35:27,485] [INFO] [controller] EPOCH 4 loss ppo:  -0.05643, loss val: 0.03800
[2022-12-06 16:35:27,499] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:35:27,723] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:35:27,723] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:35:36,853] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:35:45,961] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:35:54,688] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:36:03,499] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:36:12,471] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:36:23,679] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:36:35,881] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:36:47,656] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:36:57,296] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:37:07,814] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.0262651329234556
[2022-12-06 16:37:07,814] [INFO] [runner_train_mujoco] Average state value: 0.5397056564688683
[2022-12-06 16:37:07,814] [INFO] [controller] ITERATION NUM: 14
[2022-12-06 16:37:07,898] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.03890
[2022-12-06 16:37:07,966] [INFO] [controller] EPOCH 2 loss ppo:  -0.03819, loss val: 0.03957
[2022-12-06 16:37:08,076] [INFO] [controller] EPOCH 3 loss ppo:  -0.04871, loss val: 0.04001
[2022-12-06 16:37:08,146] [INFO] [controller] EPOCH 4 loss ppo:  -0.05543, loss val: 0.03932
[2022-12-06 16:37:08,159] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:37:08,417] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:37:08,417] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:37:18,263] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:37:28,447] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:37:37,913] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:37:47,861] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:37:57,520] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:38:07,573] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:38:17,117] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:38:31,409] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:38:46,239] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:38:57,065] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.441955557234666
[2022-12-06 16:38:57,065] [INFO] [runner_train_mujoco] Average state value: 0.53566608329614
[2022-12-06 16:38:57,065] [INFO] [controller] ITERATION NUM: 15
[2022-12-06 16:38:57,189] [INFO] [controller] EPOCH 1 loss ppo:  -0.01359, loss val: 0.04271
[2022-12-06 16:38:57,299] [INFO] [controller] EPOCH 2 loss ppo:  -0.03680, loss val: 0.04426
[2022-12-06 16:38:57,399] [INFO] [controller] EPOCH 3 loss ppo:  -0.04721, loss val: 0.04286
[2022-12-06 16:38:57,462] [INFO] [controller] EPOCH 4 loss ppo:  -0.05905, loss val: 0.04269
[2022-12-06 16:38:57,475] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:38:57,714] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:38:57,715] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:39:08,687] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:39:21,081] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:39:33,410] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:39:43,945] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:39:54,517] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:40:04,715] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:40:17,707] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:40:28,080] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:40:38,124] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:40:47,546] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8593374732440922
[2022-12-06 16:40:47,546] [INFO] [runner_train_mujoco] Average state value: 0.5354902531504631
[2022-12-06 16:40:47,546] [INFO] [controller] ITERATION NUM: 16
[2022-12-06 16:40:47,636] [INFO] [controller] EPOCH 1 loss ppo:  -0.01372, loss val: 0.03913
[2022-12-06 16:40:47,714] [INFO] [controller] EPOCH 2 loss ppo:  -0.03264, loss val: 0.04150
[2022-12-06 16:40:47,790] [INFO] [controller] EPOCH 3 loss ppo:  -0.04243, loss val: 0.03959
[2022-12-06 16:40:47,878] [INFO] [controller] EPOCH 4 loss ppo:  -0.05534, loss val: 0.03884
[2022-12-06 16:40:47,892] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:40:48,184] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:40:48,184] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:40:57,941] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:41:07,157] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:41:15,907] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:41:25,591] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:41:34,868] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:41:43,975] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:41:53,631] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:42:03,544] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:42:12,791] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:42:21,484] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.8894524397285308
[2022-12-06 16:42:21,484] [INFO] [runner_train_mujoco] Average state value: 0.5310021374126275
[2022-12-06 16:42:21,485] [INFO] [controller] ITERATION NUM: 17
[2022-12-06 16:42:21,592] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.03972
[2022-12-06 16:42:21,689] [INFO] [controller] EPOCH 2 loss ppo:  -0.03416, loss val: 0.04016
[2022-12-06 16:42:21,767] [INFO] [controller] EPOCH 3 loss ppo:  -0.04367, loss val: 0.03968
[2022-12-06 16:42:21,829] [INFO] [controller] EPOCH 4 loss ppo:  -0.05333, loss val: 0.03737
[2022-12-06 16:42:21,842] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:42:22,137] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:42:22,138] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:42:31,960] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:42:40,539] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:42:48,946] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:42:57,950] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:43:07,363] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:43:16,689] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:43:26,808] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:43:35,895] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:43:45,203] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:43:53,818] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 1.802532461588131
[2022-12-06 16:43:53,818] [INFO] [runner_train_mujoco] Average state value: 0.5046182003815969
[2022-12-06 16:43:53,818] [INFO] [controller] ITERATION NUM: 18
[2022-12-06 16:43:53,911] [INFO] [controller] EPOCH 1 loss ppo:  -0.01578, loss val: 0.04777
[2022-12-06 16:43:53,972] [INFO] [controller] EPOCH 2 loss ppo:  -0.03636, loss val: 0.04799
[2022-12-06 16:43:54,026] [INFO] [controller] EPOCH 3 loss ppo:  -0.04640, loss val: 0.04761
[2022-12-06 16:43:54,080] [INFO] [controller] EPOCH 4 loss ppo:  -0.05819, loss val: 0.04718
[2022-12-06 16:43:54,091] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:43:54,317] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:43:54,318] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:44:03,548] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:44:12,705] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:44:22,181] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:44:31,768] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:44:41,525] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:44:51,055] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:45:00,448] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:45:09,995] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:45:20,646] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:45:31,740] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.267798879027144
[2022-12-06 16:45:31,741] [INFO] [runner_train_mujoco] Average state value: 0.5252983143726985
[2022-12-06 16:45:31,741] [INFO] [controller] ITERATION NUM: 19
[2022-12-06 16:45:31,857] [INFO] [controller] EPOCH 1 loss ppo:  -0.01362, loss val: 0.04196
[2022-12-06 16:45:31,955] [INFO] [controller] EPOCH 2 loss ppo:  -0.03286, loss val: 0.04070
[2022-12-06 16:45:32,051] [INFO] [controller] EPOCH 3 loss ppo:  -0.04729, loss val: 0.04033
[2022-12-06 16:45:32,141] [INFO] [controller] EPOCH 4 loss ppo:  -0.05749, loss val: 0.04086
[2022-12-06 16:45:32,156] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:45:32,449] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:45:32,449] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:45:43,034] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:45:53,926] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:46:04,582] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:46:15,868] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:46:26,811] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:46:36,782] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:46:47,303] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:46:58,636] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:47:08,698] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:47:19,735] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4281938302113764
[2022-12-06 16:47:19,735] [INFO] [runner_train_mujoco] Average state value: 0.5088175498247146
[2022-12-06 16:47:19,735] [INFO] [controller] ITERATION NUM: 20
[2022-12-06 16:47:19,883] [INFO] [controller] EPOCH 1 loss ppo:  -0.01636, loss val: 0.04192
[2022-12-06 16:47:20,026] [INFO] [controller] EPOCH 2 loss ppo:  -0.03985, loss val: 0.04064
[2022-12-06 16:47:20,159] [INFO] [controller] EPOCH 3 loss ppo:  -0.05421, loss val: 0.03984
[2022-12-06 16:47:20,271] [INFO] [controller] EPOCH 4 loss ppo:  -0.06400, loss val: 0.04050
[2022-12-06 16:47:20,286] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:47:20,571] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:47:20,572] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:47:30,796] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:47:40,497] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:47:50,335] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:48:00,364] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:48:10,474] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:48:20,352] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:48:31,261] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:48:41,731] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:48:51,136] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:48:59,866] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.4791214280753295
[2022-12-06 16:48:59,866] [INFO] [runner_train_mujoco] Average state value: 0.46870837465922044
[2022-12-06 16:48:59,866] [INFO] [controller] ITERATION NUM: 21
[2022-12-06 16:48:59,984] [INFO] [controller] EPOCH 1 loss ppo:  -0.01605, loss val: 0.05416
[2022-12-06 16:49:00,179] [INFO] [controller] EPOCH 2 loss ppo:  -0.03652, loss val: 0.05552
[2022-12-06 16:49:00,325] [INFO] [controller] EPOCH 3 loss ppo:  -0.04456, loss val: 0.05324
[2022-12-06 16:49:00,433] [INFO] [controller] EPOCH 4 loss ppo:  -0.05955, loss val: 0.05283
[2022-12-06 16:49:00,449] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:49:00,711] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:49:00,711] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:49:10,071] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:49:20,638] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:49:30,298] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:49:40,930] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:49:51,005] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:50:00,341] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:50:08,540] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:50:18,065] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:50:29,485] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:50:39,462] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 2.8867805495689183
[2022-12-06 16:50:39,462] [INFO] [runner_train_mujoco] Average state value: 0.4929721051007509
[2022-12-06 16:50:39,462] [INFO] [controller] ITERATION NUM: 22
[2022-12-06 16:50:39,534] [INFO] [controller] EPOCH 1 loss ppo:  -0.01333, loss val: 0.03932
[2022-12-06 16:50:39,601] [INFO] [controller] EPOCH 2 loss ppo:  -0.03184, loss val: 0.03828
[2022-12-06 16:50:39,695] [INFO] [controller] EPOCH 3 loss ppo:  -0.04521, loss val: 0.03742
[2022-12-06 16:50:39,770] [INFO] [controller] EPOCH 4 loss ppo:  -0.05567, loss val: 0.03848
[2022-12-06 16:50:39,782] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:50:40,047] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:50:40,054] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:50:49,553] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:50:59,702] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:51:09,601] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:51:19,641] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:51:30,274] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:51:41,577] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:51:51,070] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:52:00,765] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:52:10,497] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:52:19,914] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.0090044213495593
[2022-12-06 16:52:19,914] [INFO] [runner_train_mujoco] Average state value: 0.5416906312902768
[2022-12-06 16:52:19,914] [INFO] [controller] ITERATION NUM: 23
[2022-12-06 16:52:20,015] [INFO] [controller] EPOCH 1 loss ppo:  -0.01560, loss val: 0.04922
[2022-12-06 16:52:20,094] [INFO] [controller] EPOCH 2 loss ppo:  -0.03821, loss val: 0.05018
[2022-12-06 16:52:20,160] [INFO] [controller] EPOCH 3 loss ppo:  -0.04940, loss val: 0.04910
[2022-12-06 16:52:20,224] [INFO] [controller] EPOCH 4 loss ppo:  -0.05985, loss val: 0.05011
[2022-12-06 16:52:20,237] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:52:20,491] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:52:20,492] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:52:29,543] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:52:38,969] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:52:48,157] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:52:57,336] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:53:05,935] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:53:15,175] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:53:24,529] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:53:33,451] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:53:42,456] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:53:51,077] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3975003018711996
[2022-12-06 16:53:51,077] [INFO] [runner_train_mujoco] Average state value: 0.5654490145246187
[2022-12-06 16:53:51,077] [INFO] [controller] ITERATION NUM: 24
[2022-12-06 16:53:51,142] [INFO] [controller] EPOCH 1 loss ppo:  -0.01493, loss val: 0.04752
[2022-12-06 16:53:51,201] [INFO] [controller] EPOCH 2 loss ppo:  -0.03040, loss val: 0.04666
[2022-12-06 16:53:51,265] [INFO] [controller] EPOCH 3 loss ppo:  -0.04224, loss val: 0.04686
[2022-12-06 16:53:51,325] [INFO] [controller] EPOCH 4 loss ppo:  -0.05475, loss val: 0.04473
[2022-12-06 16:53:51,337] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:53:51,576] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:53:51,577] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:54:00,404] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:54:09,530] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:54:18,873] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:54:28,247] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:54:36,863] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:54:45,473] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:54:53,968] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:55:02,796] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:55:11,358] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:55:19,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.3277961378863123
[2022-12-06 16:55:19,677] [INFO] [runner_train_mujoco] Average state value: 0.5268958103656768
[2022-12-06 16:55:19,677] [INFO] [controller] ITERATION NUM: 25
[2022-12-06 16:55:19,750] [INFO] [controller] EPOCH 1 loss ppo:  -0.01571, loss val: 0.04472
[2022-12-06 16:55:19,798] [INFO] [controller] EPOCH 2 loss ppo:  -0.03527, loss val: 0.04255
[2022-12-06 16:55:19,974] [INFO] [controller] EPOCH 3 loss ppo:  -0.04696, loss val: 0.04313
[2022-12-06 16:55:20,056] [INFO] [controller] EPOCH 4 loss ppo:  -0.05683, loss val: 0.04393
[2022-12-06 16:55:20,066] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:55:20,292] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:55:20,292] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:55:29,031] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:55:37,432] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:55:45,677] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:55:54,234] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:56:02,361] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:56:10,822] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:56:19,327] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:56:27,862] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:56:37,153] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:56:46,129] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.682241283503312
[2022-12-06 16:56:46,130] [INFO] [runner_train_mujoco] Average state value: 0.48880866047739985
[2022-12-06 16:56:46,130] [INFO] [controller] ITERATION NUM: 26
[2022-12-06 16:56:46,229] [INFO] [controller] EPOCH 1 loss ppo:  -0.01737, loss val: 0.03873
[2022-12-06 16:56:46,431] [INFO] [controller] EPOCH 2 loss ppo:  -0.03832, loss val: 0.04097
[2022-12-06 16:56:46,528] [INFO] [controller] EPOCH 3 loss ppo:  -0.04889, loss val: 0.03749
[2022-12-06 16:56:46,640] [INFO] [controller] EPOCH 4 loss ppo:  -0.05819, loss val: 0.03703
[2022-12-06 16:56:46,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:56:46,901] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:56:46,901] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:56:55,477] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:57:04,746] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:57:13,685] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:57:21,919] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:57:30,799] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:57:40,046] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:57:48,445] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:57:57,681] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:58:06,913] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:58:16,341] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.8761337620623593
[2022-12-06 16:58:16,341] [INFO] [runner_train_mujoco] Average state value: 0.5097352537413439
[2022-12-06 16:58:16,341] [INFO] [controller] ITERATION NUM: 27
[2022-12-06 16:58:16,423] [INFO] [controller] EPOCH 1 loss ppo:  -0.01450, loss val: 0.04147
[2022-12-06 16:58:16,495] [INFO] [controller] EPOCH 2 loss ppo:  -0.03421, loss val: 0.04162
[2022-12-06 16:58:16,555] [INFO] [controller] EPOCH 3 loss ppo:  -0.04675, loss val: 0.04058
[2022-12-06 16:58:16,637] [INFO] [controller] EPOCH 4 loss ppo:  -0.05923, loss val: 0.04045
[2022-12-06 16:58:16,658] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:58:16,905] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:58:16,905] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 16:58:25,990] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 16:58:35,270] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 16:58:44,681] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 16:58:54,577] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 16:59:04,321] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 16:59:14,095] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 16:59:23,955] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 16:59:33,202] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 16:59:43,077] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 16:59:53,371] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 3.939808140745619
[2022-12-06 16:59:53,372] [INFO] [runner_train_mujoco] Average state value: 0.513759425898393
[2022-12-06 16:59:53,372] [INFO] [controller] ITERATION NUM: 28
[2022-12-06 16:59:53,490] [INFO] [controller] EPOCH 1 loss ppo:  -0.01456, loss val: 0.04348
[2022-12-06 16:59:53,561] [INFO] [controller] EPOCH 2 loss ppo:  -0.03352, loss val: 0.04829
[2022-12-06 16:59:53,622] [INFO] [controller] EPOCH 3 loss ppo:  -0.04109, loss val: 0.04394
[2022-12-06 16:59:53,695] [INFO] [controller] EPOCH 4 loss ppo:  -0.05421, loss val: 0.04360
[2022-12-06 16:59:53,709] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 16:59:53,941] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 16:59:53,941] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:00:04,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:00:13,623] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:00:22,565] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:00:32,089] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:00:41,597] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:00:51,029] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:01:00,742] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:01:10,551] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:01:19,429] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:01:28,632] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.080738241184342
[2022-12-06 17:01:28,633] [INFO] [runner_train_mujoco] Average state value: 0.4963042109211286
[2022-12-06 17:01:28,633] [INFO] [controller] ITERATION NUM: 29
[2022-12-06 17:01:28,714] [INFO] [controller] EPOCH 1 loss ppo:  -0.01435, loss val: 0.04823
[2022-12-06 17:01:28,791] [INFO] [controller] EPOCH 2 loss ppo:  -0.03320, loss val: 0.04653
[2022-12-06 17:01:28,869] [INFO] [controller] EPOCH 3 loss ppo:  -0.04452, loss val: 0.04877
[2022-12-06 17:01:28,962] [INFO] [controller] EPOCH 4 loss ppo:  -0.05717, loss val: 0.04652
[2022-12-06 17:01:28,986] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:01:29,239] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:01:29,239] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:01:38,390] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:01:48,539] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:01:57,543] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:02:07,533] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:02:17,155] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:02:27,086] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:02:36,036] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:02:45,236] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:02:54,026] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:03:02,559] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.273650378783286
[2022-12-06 17:03:02,559] [INFO] [runner_train_mujoco] Average state value: 0.4892364261547725
[2022-12-06 17:03:02,560] [INFO] [controller] ITERATION NUM: 30
[2022-12-06 17:03:02,787] [INFO] [controller] EPOCH 1 loss ppo:  -0.01525, loss val: 0.04292
[2022-12-06 17:03:02,857] [INFO] [controller] EPOCH 2 loss ppo:  -0.03372, loss val: 0.04291
[2022-12-06 17:03:03,062] [INFO] [controller] EPOCH 3 loss ppo:  -0.04948, loss val: 0.04315
[2022-12-06 17:03:03,131] [INFO] [controller] EPOCH 4 loss ppo:  -0.06015, loss val: 0.04367
[2022-12-06 17:03:03,151] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:03:03,403] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:03:03,403] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:03:12,483] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:03:21,551] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:03:30,167] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:03:38,596] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:03:47,235] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:03:55,560] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:04:04,175] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:04:12,726] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:04:21,201] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:04:29,442] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.351635474443383
[2022-12-06 17:04:29,442] [INFO] [runner_train_mujoco] Average state value: 0.49805035697420436
[2022-12-06 17:04:29,442] [INFO] [controller] ITERATION NUM: 31
[2022-12-06 17:04:29,548] [INFO] [controller] EPOCH 1 loss ppo:  -0.01639, loss val: 0.05101
[2022-12-06 17:04:29,645] [INFO] [controller] EPOCH 2 loss ppo:  -0.03018, loss val: 0.04981
[2022-12-06 17:04:29,724] [INFO] [controller] EPOCH 3 loss ppo:  -0.03682, loss val: 0.05013
[2022-12-06 17:04:29,814] [INFO] [controller] EPOCH 4 loss ppo:  -0.04713, loss val: 0.05017
[2022-12-06 17:04:29,826] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:04:30,062] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:04:30,062] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:04:39,185] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:04:48,478] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:04:58,091] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:05:06,160] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:05:14,281] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:05:22,757] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:05:32,061] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:05:41,008] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:05:50,187] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:05:59,524] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.252211656302818
[2022-12-06 17:05:59,524] [INFO] [runner_train_mujoco] Average state value: 0.5057506555517514
[2022-12-06 17:05:59,524] [INFO] [controller] ITERATION NUM: 32
[2022-12-06 17:05:59,709] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.04970
[2022-12-06 17:05:59,874] [INFO] [controller] EPOCH 2 loss ppo:  -0.03156, loss val: 0.04969
[2022-12-06 17:05:59,986] [INFO] [controller] EPOCH 3 loss ppo:  -0.04127, loss val: 0.05147
[2022-12-06 17:06:00,103] [INFO] [controller] EPOCH 4 loss ppo:  -0.05337, loss val: 0.04924
[2022-12-06 17:06:00,116] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:06:00,341] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:06:00,341] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:06:09,487] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:06:19,096] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:06:29,896] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:06:39,350] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:06:48,492] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:06:59,073] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:07:11,866] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:07:22,144] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:07:33,193] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:07:47,512] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.280669566874581
[2022-12-06 17:07:47,513] [INFO] [runner_train_mujoco] Average state value: 0.5037580490310987
[2022-12-06 17:07:47,513] [INFO] [controller] ITERATION NUM: 33
[2022-12-06 17:07:47,783] [INFO] [controller] EPOCH 1 loss ppo:  -0.01342, loss val: 0.03861
[2022-12-06 17:07:48,413] [INFO] [controller] EPOCH 2 loss ppo:  -0.02363, loss val: 0.03952
[2022-12-06 17:07:48,594] [INFO] [controller] EPOCH 3 loss ppo:  -0.03633, loss val: 0.03846
[2022-12-06 17:07:48,752] [INFO] [controller] EPOCH 4 loss ppo:  -0.04796, loss val: 0.03837
[2022-12-06 17:07:48,765] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:07:49,055] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:07:49,056] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:08:00,717] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:08:12,304] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:08:24,477] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:08:35,222] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:08:46,197] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:08:57,399] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:09:10,056] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:09:22,293] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:09:32,369] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:09:43,413] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.782424953986618
[2022-12-06 17:09:43,414] [INFO] [runner_train_mujoco] Average state value: 0.4853118369380633
[2022-12-06 17:09:43,414] [INFO] [controller] ITERATION NUM: 34
[2022-12-06 17:09:43,579] [INFO] [controller] EPOCH 1 loss ppo:  -0.01564, loss val: 0.04586
[2022-12-06 17:09:43,678] [INFO] [controller] EPOCH 2 loss ppo:  -0.02810, loss val: 0.04594
[2022-12-06 17:09:43,793] [INFO] [controller] EPOCH 3 loss ppo:  -0.04076, loss val: 0.04702
[2022-12-06 17:09:43,876] [INFO] [controller] EPOCH 4 loss ppo:  -0.05294, loss val: 0.04599
[2022-12-06 17:09:43,891] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:09:44,163] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:09:44,164] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:09:56,178] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:10:10,398] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:10:22,695] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:10:34,223] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:10:47,911] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:11:01,020] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:11:13,151] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:11:25,393] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:11:39,789] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:11:52,755] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.655352883574404
[2022-12-06 17:11:52,755] [INFO] [runner_train_mujoco] Average state value: 0.4847644365827242
[2022-12-06 17:11:52,756] [INFO] [controller] ITERATION NUM: 35
[2022-12-06 17:11:52,863] [INFO] [controller] EPOCH 1 loss ppo:  -0.01568, loss val: 0.04569
[2022-12-06 17:11:52,944] [INFO] [controller] EPOCH 2 loss ppo:  -0.03392, loss val: 0.04656
[2022-12-06 17:11:53,013] [INFO] [controller] EPOCH 3 loss ppo:  -0.04377, loss val: 0.04465
[2022-12-06 17:11:53,092] [INFO] [controller] EPOCH 4 loss ppo:  -0.05565, loss val: 0.04434
[2022-12-06 17:11:53,112] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:11:53,428] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:11:53,428] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:12:06,649] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:12:19,302] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:12:30,570] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:12:42,164] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:12:55,748] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:13:09,472] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:13:21,360] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:13:33,507] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:13:44,294] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:13:55,622] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.4867555745593135
[2022-12-06 17:13:55,622] [INFO] [runner_train_mujoco] Average state value: 0.4668039076725642
[2022-12-06 17:13:55,622] [INFO] [controller] ITERATION NUM: 36
[2022-12-06 17:13:55,727] [INFO] [controller] EPOCH 1 loss ppo:  -0.01251, loss val: 0.04137
[2022-12-06 17:13:55,812] [INFO] [controller] EPOCH 2 loss ppo:  -0.02506, loss val: 0.04067
[2022-12-06 17:13:55,879] [INFO] [controller] EPOCH 3 loss ppo:  -0.03926, loss val: 0.04017
[2022-12-06 17:13:55,962] [INFO] [controller] EPOCH 4 loss ppo:  -0.05074, loss val: 0.03983
[2022-12-06 17:13:55,977] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:13:56,250] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:13:56,250] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:14:07,479] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:14:18,033] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:14:29,446] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:14:40,357] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:14:49,705] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:14:59,109] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:15:11,559] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:15:23,073] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:15:32,221] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:15:41,179] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.664596332537003
[2022-12-06 17:15:41,180] [INFO] [runner_train_mujoco] Average state value: 0.4242149284581343
[2022-12-06 17:15:41,180] [INFO] [controller] ITERATION NUM: 37
[2022-12-06 17:15:41,270] [INFO] [controller] EPOCH 1 loss ppo:  -0.01528, loss val: 0.04994
[2022-12-06 17:15:41,328] [INFO] [controller] EPOCH 2 loss ppo:  -0.02984, loss val: 0.05005
[2022-12-06 17:15:41,391] [INFO] [controller] EPOCH 3 loss ppo:  -0.03859, loss val: 0.04907
[2022-12-06 17:15:41,448] [INFO] [controller] EPOCH 4 loss ppo:  -0.05107, loss val: 0.04750
[2022-12-06 17:15:41,460] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:15:41,708] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:15:41,709] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:15:51,052] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:15:59,772] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:16:09,532] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:16:18,338] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:16:27,286] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:16:36,373] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:16:46,134] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:16:55,511] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:17:04,439] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:17:13,628] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.9373120052617505
[2022-12-06 17:17:13,629] [INFO] [runner_train_mujoco] Average state value: 0.4442225016156832
[2022-12-06 17:17:13,629] [INFO] [controller] ITERATION NUM: 38
[2022-12-06 17:17:13,693] [INFO] [controller] EPOCH 1 loss ppo:  -0.01380, loss val: 0.04359
[2022-12-06 17:17:13,749] [INFO] [controller] EPOCH 2 loss ppo:  -0.02242, loss val: 0.04417
[2022-12-06 17:17:13,809] [INFO] [controller] EPOCH 3 loss ppo:  -0.03690, loss val: 0.04491
[2022-12-06 17:17:13,902] [INFO] [controller] EPOCH 4 loss ppo:  -0.05085, loss val: 0.04426
[2022-12-06 17:17:13,917] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:17:14,195] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:17:14,202] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:17:23,218] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:17:33,008] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:17:43,465] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:17:52,147] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:18:00,336] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:18:08,304] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:18:15,863] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:18:24,653] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:18:32,013] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:18:39,476] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.639085367165567
[2022-12-06 17:18:39,476] [INFO] [runner_train_mujoco] Average state value: 0.45969664876659716
[2022-12-06 17:18:39,476] [INFO] [controller] ITERATION NUM: 39
[2022-12-06 17:18:39,564] [INFO] [controller] EPOCH 1 loss ppo:  -0.01692, loss val: 0.05253
[2022-12-06 17:18:39,674] [INFO] [controller] EPOCH 2 loss ppo:  -0.03325, loss val: 0.05189
[2022-12-06 17:18:39,764] [INFO] [controller] EPOCH 3 loss ppo:  -0.04142, loss val: 0.05240
[2022-12-06 17:18:39,837] [INFO] [controller] EPOCH 4 loss ppo:  -0.05232, loss val: 0.05238
[2022-12-06 17:18:39,848] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:18:40,110] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:18:40,111] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:18:48,104] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:18:56,028] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:19:03,998] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:19:11,783] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:19:19,601] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:19:28,716] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:19:36,429] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:19:43,883] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:19:51,045] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:19:58,759] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 4.975749367379911
[2022-12-06 17:19:58,760] [INFO] [runner_train_mujoco] Average state value: 0.4529260134597619
[2022-12-06 17:19:58,760] [INFO] [controller] ITERATION NUM: 40
[2022-12-06 17:19:58,855] [INFO] [controller] EPOCH 1 loss ppo:  -0.01389, loss val: 0.04632
[2022-12-06 17:19:58,907] [INFO] [controller] EPOCH 2 loss ppo:  -0.02545, loss val: 0.04799
[2022-12-06 17:19:58,959] [INFO] [controller] EPOCH 3 loss ppo:  -0.03347, loss val: 0.04430
[2022-12-06 17:19:59,008] [INFO] [controller] EPOCH 4 loss ppo:  -0.04296, loss val: 0.04294
[2022-12-06 17:19:59,019] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:19:59,239] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:19:59,239] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:20:07,757] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:20:15,197] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:20:22,856] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:20:31,430] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:20:41,270] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:20:50,708] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:21:01,431] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:21:09,784] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:21:18,390] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:21:27,519] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.030839302512556
[2022-12-06 17:21:27,520] [INFO] [runner_train_mujoco] Average state value: 0.43782130477825804
[2022-12-06 17:21:27,520] [INFO] [controller] ITERATION NUM: 41
[2022-12-06 17:21:27,581] [INFO] [controller] EPOCH 1 loss ppo:  -0.01418, loss val: 0.04434
[2022-12-06 17:21:27,629] [INFO] [controller] EPOCH 2 loss ppo:  -0.02665, loss val: 0.04430
[2022-12-06 17:21:27,681] [INFO] [controller] EPOCH 3 loss ppo:  -0.03685, loss val: 0.04454
[2022-12-06 17:21:27,746] [INFO] [controller] EPOCH 4 loss ppo:  -0.04496, loss val: 0.04268
[2022-12-06 17:21:27,757] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:21:27,995] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:21:27,996] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:21:35,847] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:21:43,613] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:21:50,556] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:21:58,020] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:22:05,406] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:22:13,252] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:22:20,996] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:22:28,700] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:22:36,410] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:22:43,969] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.099666467244297
[2022-12-06 17:22:43,970] [INFO] [runner_train_mujoco] Average state value: 0.4461784578462441
[2022-12-06 17:22:43,970] [INFO] [controller] ITERATION NUM: 42
[2022-12-06 17:22:44,032] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.05524
[2022-12-06 17:22:44,084] [INFO] [controller] EPOCH 2 loss ppo:  -0.02475, loss val: 0.05570
[2022-12-06 17:22:44,143] [INFO] [controller] EPOCH 3 loss ppo:  -0.03435, loss val: 0.05580
[2022-12-06 17:22:44,194] [INFO] [controller] EPOCH 4 loss ppo:  -0.04399, loss val: 0.05689
[2022-12-06 17:22:44,206] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:22:44,423] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:22:44,424] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:22:52,732] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:23:00,901] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:23:08,678] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:23:16,682] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:23:24,540] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:23:32,580] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:23:40,695] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:23:48,555] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:23:55,987] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:24:04,190] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.151261473772421
[2022-12-06 17:24:04,191] [INFO] [runner_train_mujoco] Average state value: 0.47963238890965776
[2022-12-06 17:24:04,191] [INFO] [controller] ITERATION NUM: 43
[2022-12-06 17:24:04,257] [INFO] [controller] EPOCH 1 loss ppo:  -0.01437, loss val: 0.04015
[2022-12-06 17:24:04,307] [INFO] [controller] EPOCH 2 loss ppo:  -0.02528, loss val: 0.04077
[2022-12-06 17:24:04,356] [INFO] [controller] EPOCH 3 loss ppo:  -0.03345, loss val: 0.04020
[2022-12-06 17:24:04,405] [INFO] [controller] EPOCH 4 loss ppo:  -0.04174, loss val: 0.04076
[2022-12-06 17:24:04,417] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:24:04,636] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:24:04,637] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:24:12,558] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:24:20,516] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:24:28,019] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:24:35,428] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:24:43,080] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:24:50,861] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:24:58,841] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:25:06,764] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:25:14,512] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:25:21,605] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.1428438095332885
[2022-12-06 17:25:21,605] [INFO] [runner_train_mujoco] Average state value: 0.48665062253673863
[2022-12-06 17:25:21,605] [INFO] [controller] ITERATION NUM: 44
[2022-12-06 17:25:21,681] [INFO] [controller] EPOCH 1 loss ppo:  -0.01535, loss val: 0.04450
[2022-12-06 17:25:21,756] [INFO] [controller] EPOCH 2 loss ppo:  -0.02690, loss val: 0.04702
[2022-12-06 17:25:21,846] [INFO] [controller] EPOCH 3 loss ppo:  -0.03533, loss val: 0.04411
[2022-12-06 17:25:21,904] [INFO] [controller] EPOCH 4 loss ppo:  -0.04669, loss val: 0.04392
[2022-12-06 17:25:21,915] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:25:22,147] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:25:22,148] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:25:29,593] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:25:36,280] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:25:43,019] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:25:50,144] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:25:57,478] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:26:05,371] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:26:12,978] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:26:20,055] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:26:27,317] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:26:34,506] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.287982088277967
[2022-12-06 17:26:34,506] [INFO] [runner_train_mujoco] Average state value: 0.469159162123998
[2022-12-06 17:26:34,507] [INFO] [controller] ITERATION NUM: 45
[2022-12-06 17:26:34,575] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04160
[2022-12-06 17:26:34,621] [INFO] [controller] EPOCH 2 loss ppo:  -0.02186, loss val: 0.04091
[2022-12-06 17:26:34,670] [INFO] [controller] EPOCH 3 loss ppo:  -0.03263, loss val: 0.04064
[2022-12-06 17:26:34,715] [INFO] [controller] EPOCH 4 loss ppo:  -0.04249, loss val: 0.04014
[2022-12-06 17:26:34,724] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:26:34,938] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:26:34,938] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:26:42,691] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:26:50,231] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:26:57,431] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:27:04,744] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:27:11,154] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:27:17,525] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:27:23,667] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:27:29,473] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:27:35,121] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:27:40,825] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.2844493351804
[2022-12-06 17:27:40,825] [INFO] [runner_train_mujoco] Average state value: 0.45467704079548515
[2022-12-06 17:27:40,825] [INFO] [controller] ITERATION NUM: 46
[2022-12-06 17:27:40,885] [INFO] [controller] EPOCH 1 loss ppo:  -0.01444, loss val: 0.04543
[2022-12-06 17:27:40,929] [INFO] [controller] EPOCH 2 loss ppo:  -0.02505, loss val: 0.04754
[2022-12-06 17:27:41,037] [INFO] [controller] EPOCH 3 loss ppo:  -0.03403, loss val: 0.04531
[2022-12-06 17:27:41,086] [INFO] [controller] EPOCH 4 loss ppo:  -0.04000, loss val: 0.04501
[2022-12-06 17:27:41,097] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:27:41,310] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:27:41,310] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:27:47,417] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:27:53,587] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:27:59,303] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:28:06,377] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:28:18,680] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:28:25,959] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:28:31,802] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:28:37,818] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:28:45,629] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:28:54,395] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.25749752093087
[2022-12-06 17:28:54,395] [INFO] [runner_train_mujoco] Average state value: 0.44580859479308127
[2022-12-06 17:28:54,396] [INFO] [controller] ITERATION NUM: 47
[2022-12-06 17:28:54,450] [INFO] [controller] EPOCH 1 loss ppo:  -0.01376, loss val: 0.04909
[2022-12-06 17:28:54,497] [INFO] [controller] EPOCH 2 loss ppo:  -0.02172, loss val: 0.04901
[2022-12-06 17:28:54,544] [INFO] [controller] EPOCH 3 loss ppo:  -0.03147, loss val: 0.04941
[2022-12-06 17:28:54,589] [INFO] [controller] EPOCH 4 loss ppo:  -0.03967, loss val: 0.04985
[2022-12-06 17:28:54,600] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:28:54,798] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:28:54,799] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:29:02,499] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:29:08,282] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:29:13,761] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:29:20,058] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:29:25,860] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:29:31,640] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:29:37,413] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:29:43,312] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:29:49,397] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:29:55,090] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.38178430308275
[2022-12-06 17:29:55,091] [INFO] [runner_train_mujoco] Average state value: 0.4489760522941748
[2022-12-06 17:29:55,091] [INFO] [controller] ITERATION NUM: 48
[2022-12-06 17:29:55,144] [INFO] [controller] EPOCH 1 loss ppo:  -0.01461, loss val: 0.05302
[2022-12-06 17:29:55,189] [INFO] [controller] EPOCH 2 loss ppo:  -0.02302, loss val: 0.05268
[2022-12-06 17:29:55,235] [INFO] [controller] EPOCH 3 loss ppo:  -0.03316, loss val: 0.05314
[2022-12-06 17:29:55,275] [INFO] [controller] EPOCH 4 loss ppo:  -0.04007, loss val: 0.05224
[2022-12-06 17:29:55,283] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:29:55,475] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:29:55,476] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:30:01,764] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:30:07,967] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:30:14,041] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:30:19,484] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:30:25,348] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:30:31,152] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:30:37,247] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:30:43,301] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:30:49,179] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:30:55,421] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.491629276916873
[2022-12-06 17:30:55,421] [INFO] [runner_train_mujoco] Average state value: 0.4590563779075941
[2022-12-06 17:30:55,421] [INFO] [controller] ITERATION NUM: 49
[2022-12-06 17:30:55,473] [INFO] [controller] EPOCH 1 loss ppo:  -0.01439, loss val: 0.04358
[2022-12-06 17:30:55,517] [INFO] [controller] EPOCH 2 loss ppo:  -0.02376, loss val: 0.04356
[2022-12-06 17:30:55,571] [INFO] [controller] EPOCH 3 loss ppo:  -0.03259, loss val: 0.04481
[2022-12-06 17:30:55,615] [INFO] [controller] EPOCH 4 loss ppo:  -0.04156, loss val: 0.04320
[2022-12-06 17:30:55,625] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:30:55,840] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:30:55,841] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:31:02,533] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:31:09,006] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:31:15,277] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:31:21,383] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:31:27,215] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:31:33,101] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:31:39,234] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:31:45,264] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:31:51,332] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:31:57,562] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.497423692185478
[2022-12-06 17:31:57,563] [INFO] [runner_train_mujoco] Average state value: 0.4519707369903724
[2022-12-06 17:31:57,563] [INFO] [controller] ITERATION NUM: 50
[2022-12-06 17:31:57,624] [INFO] [controller] EPOCH 1 loss ppo:  -0.01481, loss val: 0.03258
[2022-12-06 17:31:57,673] [INFO] [controller] EPOCH 2 loss ppo:  -0.02264, loss val: 0.03248
[2022-12-06 17:31:57,722] [INFO] [controller] EPOCH 3 loss ppo:  -0.02579, loss val: 0.03240
[2022-12-06 17:31:57,772] [INFO] [controller] EPOCH 4 loss ppo:  -0.03262, loss val: 0.03232
[2022-12-06 17:31:57,783] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:31:57,977] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:31:57,977] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:32:04,108] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:32:10,436] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:32:16,324] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:32:22,169] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:32:27,964] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:32:34,059] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:32:40,078] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:32:46,272] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:32:51,922] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:32:58,028] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.624241259194524
[2022-12-06 17:32:58,028] [INFO] [runner_train_mujoco] Average state value: 0.4384863249262175
[2022-12-06 17:32:58,029] [INFO] [controller] ITERATION NUM: 51
[2022-12-06 17:32:58,077] [INFO] [controller] EPOCH 1 loss ppo:  -0.01426, loss val: 0.04253
[2022-12-06 17:32:58,121] [INFO] [controller] EPOCH 2 loss ppo:  -0.02009, loss val: 0.04374
[2022-12-06 17:32:58,165] [INFO] [controller] EPOCH 3 loss ppo:  -0.02884, loss val: 0.04287
[2022-12-06 17:32:58,205] [INFO] [controller] EPOCH 4 loss ppo:  -0.03651, loss val: 0.04276
[2022-12-06 17:32:58,212] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:32:58,422] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:32:58,423] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:33:04,182] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:33:09,976] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:33:16,116] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:33:22,131] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:33:27,980] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:33:33,360] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:33:40,677] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:33:46,644] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:33:52,655] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:33:58,640] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.719419137686115
[2022-12-06 17:33:58,640] [INFO] [runner_train_mujoco] Average state value: 0.44045779286821685
[2022-12-06 17:33:58,640] [INFO] [controller] ITERATION NUM: 52
[2022-12-06 17:33:58,709] [INFO] [controller] EPOCH 1 loss ppo:  -0.01501, loss val: 0.04820
[2022-12-06 17:33:58,754] [INFO] [controller] EPOCH 2 loss ppo:  -0.02296, loss val: 0.04764
[2022-12-06 17:33:58,792] [INFO] [controller] EPOCH 3 loss ppo:  -0.02371, loss val: 0.04777
[2022-12-06 17:33:58,834] [INFO] [controller] EPOCH 4 loss ppo:  -0.03014, loss val: 0.04694
[2022-12-06 17:33:58,840] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:33:59,031] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:33:59,031] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:34:04,986] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:34:10,920] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:34:16,681] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:34:22,664] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:34:28,110] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:34:33,617] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:34:39,165] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:34:44,755] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:34:50,121] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:34:55,378] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.650994691220964
[2022-12-06 17:34:55,378] [INFO] [runner_train_mujoco] Average state value: 0.44497840438286457
[2022-12-06 17:34:55,378] [INFO] [controller] ITERATION NUM: 53
[2022-12-06 17:34:55,431] [INFO] [controller] EPOCH 1 loss ppo:  -0.01473, loss val: 0.04570
[2022-12-06 17:34:55,472] [INFO] [controller] EPOCH 2 loss ppo:  -0.02120, loss val: 0.04430
[2022-12-06 17:34:55,514] [INFO] [controller] EPOCH 3 loss ppo:  -0.02463, loss val: 0.04512
[2022-12-06 17:34:55,559] [INFO] [controller] EPOCH 4 loss ppo:  -0.03202, loss val: 0.04379
[2022-12-06 17:34:55,569] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:34:55,770] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:34:55,771] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:35:01,646] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:35:07,410] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:35:13,263] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:35:19,170] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:35:24,747] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:35:30,451] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:35:36,037] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:35:41,509] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:35:46,786] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:35:52,674] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.657012697882633
[2022-12-06 17:35:52,674] [INFO] [runner_train_mujoco] Average state value: 0.452705341676871
[2022-12-06 17:35:52,675] [INFO] [controller] ITERATION NUM: 54
[2022-12-06 17:35:52,729] [INFO] [controller] EPOCH 1 loss ppo:  -0.01402, loss val: 0.04499
[2022-12-06 17:35:52,774] [INFO] [controller] EPOCH 2 loss ppo:  -0.01763, loss val: 0.04492
[2022-12-06 17:35:52,817] [INFO] [controller] EPOCH 3 loss ppo:  -0.02544, loss val: 0.04551
[2022-12-06 17:35:52,862] [INFO] [controller] EPOCH 4 loss ppo:  -0.03117, loss val: 0.04449
[2022-12-06 17:35:52,872] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:35:53,047] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:35:53,047] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:35:58,995] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:36:04,823] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:36:10,542] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:36:16,111] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:36:21,969] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:36:27,813] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:36:33,646] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:36:39,998] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:36:45,918] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:36:51,837] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.579843996169525
[2022-12-06 17:36:51,837] [INFO] [runner_train_mujoco] Average state value: 0.45475794143478077
[2022-12-06 17:36:51,837] [INFO] [controller] ITERATION NUM: 55
[2022-12-06 17:36:51,891] [INFO] [controller] EPOCH 1 loss ppo:  -0.01430, loss val: 0.05027
[2022-12-06 17:36:51,932] [INFO] [controller] EPOCH 2 loss ppo:  -0.01832, loss val: 0.05058
[2022-12-06 17:36:51,973] [INFO] [controller] EPOCH 3 loss ppo:  -0.02422, loss val: 0.05025
[2022-12-06 17:36:52,020] [INFO] [controller] EPOCH 4 loss ppo:  -0.02912, loss val: 0.04960
[2022-12-06 17:36:52,029] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:36:52,211] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:36:52,211] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:36:58,251] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:37:04,609] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:37:10,788] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:37:17,026] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:37:23,065] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:37:28,883] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:37:34,679] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:37:40,526] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:37:46,531] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:37:52,922] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.683293224274047
[2022-12-06 17:37:52,922] [INFO] [runner_train_mujoco] Average state value: 0.4485152908960979
[2022-12-06 17:37:52,922] [INFO] [controller] ITERATION NUM: 56
[2022-12-06 17:37:52,982] [INFO] [controller] EPOCH 1 loss ppo:  -0.01425, loss val: 0.05127
[2022-12-06 17:37:53,025] [INFO] [controller] EPOCH 2 loss ppo:  -0.01733, loss val: 0.05152
[2022-12-06 17:37:53,071] [INFO] [controller] EPOCH 3 loss ppo:  -0.02277, loss val: 0.05291
[2022-12-06 17:37:53,116] [INFO] [controller] EPOCH 4 loss ppo:  -0.02813, loss val: 0.05235
[2022-12-06 17:37:53,126] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:37:53,317] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:37:53,317] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:37:59,025] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:38:05,479] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:38:11,170] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:38:17,010] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:38:22,513] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:38:28,283] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:38:34,080] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:38:39,801] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:38:45,252] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:38:50,676] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.768718315074972
[2022-12-06 17:38:50,676] [INFO] [runner_train_mujoco] Average state value: 0.4424139917989572
[2022-12-06 17:38:50,676] [INFO] [controller] ITERATION NUM: 57
[2022-12-06 17:38:50,727] [INFO] [controller] EPOCH 1 loss ppo:  -0.01414, loss val: 0.05690
[2022-12-06 17:38:50,770] [INFO] [controller] EPOCH 2 loss ppo:  -0.01637, loss val: 0.05638
[2022-12-06 17:38:50,812] [INFO] [controller] EPOCH 3 loss ppo:  -0.02101, loss val: 0.05627
[2022-12-06 17:38:50,860] [INFO] [controller] EPOCH 4 loss ppo:  -0.02621, loss val: 0.05621
[2022-12-06 17:38:50,870] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:38:51,068] [INFO] [runner_train_mujoco] Starting simulation batch with mujoco.
[2022-12-06 17:38:51,069] [INFO] [runner_train_mujoco] Environment 0
[2022-12-06 17:38:56,753] [INFO] [runner_train_mujoco] Environment 1
[2022-12-06 17:39:02,375] [INFO] [runner_train_mujoco] Environment 2
[2022-12-06 17:39:08,233] [INFO] [runner_train_mujoco] Environment 3
[2022-12-06 17:39:14,274] [INFO] [runner_train_mujoco] Environment 4
[2022-12-06 17:39:19,713] [INFO] [runner_train_mujoco] Environment 5
[2022-12-06 17:39:25,566] [INFO] [runner_train_mujoco] Environment 6
[2022-12-06 17:39:31,342] [INFO] [runner_train_mujoco] Environment 7
[2022-12-06 17:39:37,113] [INFO] [runner_train_mujoco] Environment 8
[2022-12-06 17:39:42,735] [INFO] [runner_train_mujoco] Environment 9
[2022-12-06 17:39:48,291] [INFO] [runner_train_mujoco] Average cumulative reward after 150 steps: 5.693499484586354
[2022-12-06 17:39:48,291] [INFO] [runner_train_mujoco] Average state value: 0.44789968070387837
[2022-12-06 17:39:48,291] [INFO] [controller] ITERATION NUM: 58
[2022-12-06 17:39:48,350] [INFO] [controller] EPOCH 1 loss ppo:  -0.01391, loss val: 0.04614
[2022-12-06 17:39:48,391] [INFO] [controller] EPOCH 2 loss ppo:  -0.01551, loss val: 0.04628
[2022-12-06 17:39:48,433] [INFO] [controller] EPOCH 3 loss ppo:  -0.01775, loss val: 0.04704
[2022-12-06 17:39:48,477] [INFO] [controller] EPOCH 4 loss ppo:  -0.02030, loss val: 0.04616
[2022-12-06 17:39:48,486] [INFO] [runner_train_mujoco] Finished batch.
[2022-12-06 17:39:48,605] [INFO] [optimize] Finished learning.
